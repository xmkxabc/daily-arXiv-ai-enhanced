# AI-Enhanced arXiv Daily 2025-06-27

<a id='toc'></a>
## 今日总计: 450 篇论文
### 目录
- [cs.CR](#cscr) (12 篇)
- [cs.AI](#csai) (13 篇)
- [cs.LG](#cslg) (77 篇)
- [cs.RO](#csro) (18 篇)
- [cs.CV](#cscv) (113 篇)
- [cs.HC](#cshc) (11 篇)
- [cs.SE](#csse) (11 篇)
- [cs.SI](#cssi) (4 篇)
- [cs.NI](#csni) (2 篇)
- [cs.IT](#csit) (4 篇)
- [cs.AR](#csar) (3 篇)
- [cs.DC](#csdc) (11 篇)
- [cs.CY](#cscy) (2 篇)
- [cs.CE](#csce) (3 篇)
- [eess.SY](#eesssy) (8 篇)
- [eess.SP](#eesssp) (12 篇)
- [eess.IV](#eessiv) (9 篇)
- [eess.AS](#eessas) (5 篇)
- [cs.CL](#cscl) (39 篇)
- [cs.DS](#csds) (10 篇)
- [cs.GR](#csgr) (6 篇)
- [cs.IR](#csir) (7 篇)
- [cs.NE](#csne) (4 篇)
- [math.NA](#mathna) (18 篇)
- [cs.SD](#cssd) (8 篇)
- [cs.DL](#csdl) (2 篇)
- [econ.GN](#econgn) (2 篇)
- [q-fin.PM](#q-finpm) (1 篇)
- [quant-ph](#quant-ph) (3 篇)
- [cond-mat.soft](#cond-matsoft) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (1 篇)
- [math.CO](#mathco) (1 篇)
- [math.DS](#mathds) (1 篇)
- [math.ST](#mathst) (1 篇)
- [math.PR](#mathpr) (1 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [cs.CG](#cscg) (1 篇)
- [physics.acc-ph](#physicsacc-ph) (1 篇)
- [cs.MM](#csmm) (1 篇)
- [q-bio.BM](#q-biobm) (2 篇)
- [math.OC](#mathoc) (3 篇)
- [physics.ins-det](#physicsins-det) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [q-bio.QM](#q-bioqm) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (1 篇)
- [stat.ME](#statme) (1 篇)
- [stat.ML](#statml) (9 篇)
- [q-bio.CB](#q-biocb) (1 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [Perry: A High-level Framework for Accelerating Cyber Deception Experimentation](https://arxiv.org/abs/2506.20770)
> *Perry：一个加速网络欺骗实验的高级框架*

*Brian Singer, Yusuf Saquib, Lujo Bauer, Vyas Sekar* | **Category: cs.CR**

**Keywords:** 网络欺骗, 实验框架, 高级抽象, 安全操作, 模拟网络

**Comment:** 

> **TL;DR:** Perry是一个高级框架，旨在通过提供抽象层和实验模块来加速网络欺骗实验的设计和探索，解决了现有工具难以修改和扩展的问题。

**AI_Comments:** Perry框架的创新之处在于其高层次的抽象和模块化设计，极大地简化了网络欺骗实验的复杂性。它提供了一个统一的平台来设计、探索和评估不同的欺骗策略，这对于网络安全研究和实践具有重要意义。通过减少实现工作量并支持大规模实验，Perry有望加速网络欺骗领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 网络欺骗旨在通过虚假资产分散、延迟和检测网络攻击者。然而，目前操作员难以实验、探索和评估欺骗方法，因为现有工具和平台实现复杂且不可移植，难以修改和扩展。

**Method:** Perry框架通过引入两个主要组件来解决问题：一个用于安全操作员指定攻击者和欺骗策略的高级抽象层，以及一个在真实模拟网络中运行这些攻击者和防御者的实验模块。为了将高级规范转换为低级实现，Perry设计了四个关键模块：1) 一个将高级操作转换为低级实现的行动规划器，2) 一个将低级遥测数据转换为高级观察的可观察性模块，3) 一个实现环境无关策略的环境状态服务，以及4) 一个推断攻击者如何探索环境的攻击图服务。

**Result:** Perry的抽象减少了探索各种欺骗防御、攻击者和环境的实现工作。通过模拟55个独特的欺骗假设情景，展示了Perry的价值，并说明了这些实验如何帮助操作员揭示细微的权衡。

**Conclusion:** Perry框架通过其高级抽象和模块化设计，显著加速了网络欺骗实验的设计和探索，并帮助操作员理解欺骗策略中的复杂权衡。

> **ai_Abstract:** Perry是一个为加速网络欺骗实验而设计的高级框架。它通过提供一个高级抽象层，使安全操作员能够轻松定义攻击者和欺骗策略，并结合一个实验模块在模拟网络中运行这些场景。Perry包含行动规划器、可观察性模块、环境状态服务和攻击图服务，以实现高级规范到低级实现的转换。该框架显著降低了实验实现难度，并通过55个模拟情景验证了其在揭示欺骗策略权衡方面的有效性。

> **摘要翻译:** 网络欺骗旨在通过虚假资产（如蜜罐、诱饵凭证或诱饵文件）分散、延迟和检测网络攻击者。然而，目前操作员难以实验、探索和评估欺骗方法。现有工具和平台实现复杂且不可移植，难以修改和扩展。我们通过引入Perry来解决这一痛点，Perry是一个高级框架，可加速欺骗“假设”场景的设计和探索。Perry有两个组件：一个用于安全操作员指定攻击者和欺骗策略的高级抽象层，以及一个在真实模拟网络中运行这些攻击者和防御者的实验模块。为了转换这些高级规范，我们为Perry设计了四个关键模块：1) 一个将高级操作转换为低级实现的行动规划器，2) 一个将低级遥测数据转换为高级观察的可观察性模块，3) 一个实现环境无关策略的环境状态服务，以及4) 一个推断攻击者如何探索环境的攻击图服务。我们证明了Perry的抽象减少了探索各种欺骗防御、攻击者和环境的实现工作。我们通过模拟55个独特的欺骗假设情景来展示Perry的价值，并说明这些实验如何使操作员能够揭示细微的权衡。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [2] [SIMulator: SIM Tracing on a (Pico-)Budget](https://arxiv.org/abs/2506.20800)
> *SIMulator：低成本SIM卡追踪*

*Gabriel K. Gegenhuber, Philipp É. Frenzel, Adrian Dabrowski* | **Category: cs.CR**

**Keywords:** SIM卡追踪, 蜂窝网络, 低成本, 树莓派Pico, 硬件简化

**Comment:** Accepted Poster at WiSec 2025

> **TL;DR:** 本文介绍了一种使用低成本、易得组件（如树莓派Pico）实现SIM卡追踪功能的方法，大大降低了硬件复杂性和成本，使SIM卡追踪技术更易于获取。

**AI_Comments:** 这项工作的创新之处在于，它通过利用低成本、现成的组件（如树莓派Pico）实现了通常需要昂贵专用硬件才能完成的SIM卡追踪功能，极大地降低了研究门槛和成本。其重要性在于，它使更广泛的研究人员和爱好者能够进行蜂窝网络安全和开发相关的实验，从而可能加速该领域的创新。通过电气解耦SIM卡和调制解调器并在APDU级别传输数据，该方法有效地简化了硬件设计。

<details>
  <summary>Details</summary>

**Motivation:** 传统的SIM卡追踪依赖于专用硬件，这给研究人员，尤其是新入门者，带来了经济和物流负担。

**Method:** 通过使用UART接口和GPIO端口等简单、广泛可用的组件，在低成本微控制器（例如树莓派Pico）上实现了完整的SIM卡追踪功能。该方法通过电气隔离SIM卡和调制解调器，并仅在APDU级别传输数据，从而显著降低了硬件复杂性。

**Result:** 实现了使用简单、广泛可用的组件（如树莓派Pico，4美元）进行完整的SIM卡追踪功能，显著降低了硬件要求和相关成本。

**Conclusion:** 通过显著降低硬件要求和相关成本，本工作旨在使SIM卡追踪技术更广泛地应用于研究人员和爱好者社区，从而促进蜂窝网络研究中更广泛的探索和实验。

> **ai_Abstract:** 本文提出了一种名为“SIMulator”的低成本SIM卡追踪解决方案，旨在解决传统SIM卡追踪依赖昂贵专用硬件的问题。研究人员展示了如何利用UART接口和GPIO端口等通用组件，在如树莓派Pico（4美元）之类的低成本微控制器上实现完整的SIM卡追踪功能。该方法通过电气隔离SIM卡和调制解调器并在APDU级别传输数据，显著降低了硬件复杂性。这项工作旨在使SIM卡追踪技术更易于获取，从而促进蜂窝网络研究的广泛探索和实验。

> **摘要翻译:** SIM卡追踪——检查、修改和转发SIM卡与调制解调器之间通信的能力——已成为蜂窝网络研究中的一项重要技术。它支持重要的安全和开发相关应用，例如模糊测试通信接口、提取会话密钥、监控隐藏的SIM活动（例如主动SIM命令或空中更新），并通过SIM卡复用促进可扩展的分布式测量平台。传统上，实现这些功能依赖于专用硬件，这可能给研究人员，特别是新入门者带来经济和物流负担。在这项工作中，我们展示了仅使用简单、广泛可用的组件（如UART接口和GPIO端口）即可实现完整的SIM卡追踪功能。我们将这些功能移植到低成本微控制器上，例如树莓派Pico（4美元）。与其他方法不同，它通过电气隔离SIM卡和调制解调器并仅在APDU级别传输数据，从而显著降低了硬件复杂性。通过显著降低硬件要求和相关成本，我们旨在使SIM卡追踪技术更广泛地应用于研究人员和爱好者社区，从而促进蜂窝网络研究中更广泛的探索和实验。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [3] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
> *海报：通过基于代理的分析增强GNN在网络入侵检测中的鲁棒性*

*Zhonghao Zhan, Huichi Zhou, Hamed Haddadi* | **Category: cs.CR, cs.AI**

**Keywords:** 图神经网络, 网络入侵检测, 鲁棒性, 大型语言模型, 对抗性攻击

**Comment:** Poster accepted at the 10th IEEE European Symposium on Security and
  Privacy (Euro S&P 2025)

> **TL;DR:** 本研究提出一种新方法，通过使用大型语言模型（LLMs）作为模拟网络安全专家代理，提高图神经网络（GNNs）在网络入侵检测系统（NIDS）中的鲁棒性和泛化能力，实验证明该方法能显著提升GNN-NIDS的韧性。

**AI_Comments:** 该论文的创新点在于将大型语言模型（LLMs）引入到图神经网络（GNNs）的鲁棒性增强中，特别是通过模拟网络安全专家代理的方式，在GNN处理前进行预分析和缓解。这种代理式的方法为提升GNN在对抗性环境下的性能提供了一个新颖的视角，且其在真实数据集上的验证增加了研究的可信度。该方法有望为未来的入侵检测系统提供更强的防御能力。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在网络入侵检测系统（NIDS）中显示出巨大潜力，尤其是在物联网环境中，但由于分布漂移和缺乏对真实对抗性攻击的鲁棒性而导致性能下降。目前的鲁棒性评估通常依赖不切实际的合成扰动，并且缺乏对不同类型对抗性攻击（包括黑盒和白盒场景）进行系统分析的演示。

**Method:** 本研究提出一种新颖的方法，通过在代理管道中利用大型语言模型（LLMs）作为模拟网络安全专家代理，以增强GNN的鲁棒性和泛化能力。这些代理在GNN处理之前，审查从网络流数据中导出的图结构，识别并可能缓解可疑或受对抗性扰动的元素。

**Result:** 我们的实验使用为真实评估设计的框架，并结合多种对抗性攻击（包括从物理测试台实验中收集的数据集），证明集成LLM分析可以显著提高基于GNN的NIDS对抗挑战的韧性。

**Conclusion:** 将LLM代理作为入侵检测架构中的补充层，具有增强GNN-NIDS鲁棒性和泛化能力的潜力。

> **ai_Abstract:** 本研究旨在解决图神经网络（GNNs）在网络入侵检测系统（NIDS）中面临的鲁棒性和泛化能力不足的问题。作者提出一种创新方法，利用大型语言模型（LLMs）作为网络安全专家代理，在GNN处理网络流数据之前，对其图结构进行审查，识别并减轻对抗性扰动。实验结果表明，这种LLM与GNN的集成显著提升了NIDS在面对真实对抗性攻击时的韧性，突显了LLM代理在入侵检测架构中的潜在价值。

> **摘要翻译:** 图神经网络（GNNs）在网络入侵检测系统（NIDS）中显示出巨大潜力，尤其是在物联网环境中，但由于分布漂移和缺乏对真实对抗性攻击的鲁棒性而导致性能下降。目前的鲁棒性评估通常依赖不切实际的合成扰动，并且缺乏对不同类型对抗性攻击（包括黑盒和白盒场景）进行系统分析的演示。本研究提出一种新颖的方法，通过在代理管道中利用大型语言模型（LLMs）作为模拟网络安全专家代理，以增强GNN的鲁棒性和泛化能力。这些代理在GNN处理之前，审查从网络流数据中导出的图结构，识别并可能缓解可疑或受对抗性扰动的元素。我们的实验使用为真实评估设计的框架，并结合多种对抗性攻击（包括从物理测试台实验中收集的数据集），证明集成LLM分析可以显著提高基于GNN的NIDS对抗挑战的韧性，展示了LLM代理作为入侵检测架构中补充层的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [4] [Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research](https://arxiv.org/abs/2506.20872)
> *赋能数字农业：一个用于数据共享和协作研究的隐私保护框架*

*Osama Zafar, Rosemarie Santa González, Mina Namazi, Alfonso Morales, Erman Ayday* | **Category: cs.CR, cs.LG**

**Keywords:** 数字农业, 隐私保护, 数据共享, 差分隐私, 联邦学习

**Comment:** arXiv admin note: text overlap with arXiv:2409.06069

> **TL;DR:** 该研究提出了一个隐私保护框架，通过结合降维技术和差分隐私，解决农业数据共享中的隐私问题，并支持安全的协作研究和个性化模型训练。

**AI_Comments:** 该论文的创新点在于将降维技术与差分隐私相结合，构建了一个实用的隐私保护框架，专门应对数字农业数据共享的挑战。它不仅关注数据安全，还考虑了实际应用中的协作和个性化模型训练需求。其重要性在于能够促进农业数据的负责任利用，克服阻碍数据驱动农业发展的关键隐私瓶颈，对推动农业智能化和可持续发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据驱动的农业有潜力提高作物产量、疾病抵抗力和土壤健康，但隐私问题（如不利定价、歧视和资源操纵）阻碍了农民共享数据，因为数据可能被用来对付他们。为解决这一障碍，论文提出了一个隐私保护框架。

**Method:** 该框架结合了降维技术（如主成分分析PCA）和差分隐私，通过引入拉普拉斯噪声来保护敏感信息。它允许研究人员为目标农民识别潜在合作者，并通过联邦学习或直接在聚合的隐私保护数据上训练个性化机器学习模型。它还允许农民根据相似性识别潜在合作者。

**Result:** 该框架已在真实数据集上得到验证，证明了对对抗性攻击的强大隐私保护能力，并且实用性表现与中心化系统相当。它能够促进农民之间的协作，并帮助研究人员实现更广泛的研究目标。

**Conclusion:** 通过解决关键的隐私挑战，该框架支持安全的数据集成，从而促进农业系统的创新和可持续性，并赋能研究人员和政策制定者负责任地利用农业数据，为数据驱动农业的变革性进步铺平道路。

> **ai_Abstract:** 该论文提出了一个隐私保护框架，旨在解决数字农业中数据共享的隐私障碍。该框架结合了降维技术（如PCA）和差分隐私（通过拉普拉斯噪声），以保护敏感农业数据。它支持研究人员识别合作者、训练个性化机器学习模型（通过联邦学习或聚合数据），并允许农民基于相似性进行协作。在真实数据集上的验证表明，该框架提供了强大的隐私保护，且性能与中心化系统相当，从而促进了安全的数据集成和数字农业的创新。

> **摘要翻译:** 数据驱动的农业将技术和数据融入农业实践，有潜力提高作物产量、疾病抵抗力和长期土壤健康。然而，隐私担忧，如不利定价、歧视和资源操纵，阻碍了农民分享数据，因为这些数据可能被用来对付他们。为了解决这一障碍，我们提出了一个隐私保护框架，该框架能够实现安全的数据共享和研究开发协作，同时减轻隐私风险。该框架结合了降维技术（如主成分分析（PCA））和差分隐私，通过引入拉普拉斯噪声来保护敏感信息。所提出的框架允许研究人员为目标农民识别潜在合作者，并通过联邦学习或直接在聚合的隐私保护数据上，利用已识别合作者的数据训练个性化机器学习模型。它还允许农民根据相似性识别潜在合作者。我们已在真实数据集上验证了这一点，证明了其对对抗性攻击的强大隐私保护能力，并且实用性表现与中心化系统相当。我们展示了该框架如何促进农民之间的协作，并帮助研究人员追求更广泛的研究目标。该框架的采用可以赋能研究人员和政策制定者负责任地利用农业数据，为数据驱动农业的变革性进步铺平道路。通过解决关键的隐私挑战，这项工作支持安全的数据集成，促进农业系统的创新和可持续性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [21] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
> *ZKPROV: 大语言模型数据集溯源的零知识方法*

*Mina Namazi, Alexander Nemecek, Erman Ayday* | **Category: cs.CR, cs.AI, cs.LG**

**Keywords:** 零知识证明, 数据集溯源, 大型语言模型, 隐私保护, 计算完整性

**Comment:** 12 pages, 1 figure

> **TL;DR:** ZKPROV使用零知识证明验证LLM的数据集来源，无需泄露敏感信息，比现有方法更高效且实用。

**AI_Comments:** ZKPROV的创新之处在于其在LLM溯源验证中引入了零知识证明，有效解决了隐私保护和计算成本之间的矛盾。它避免了传统方法中对整个训练过程的昂贵验证，也摆脱了对可信执行环境的依赖，提供了一个更实用且可扩展的解决方案。这对于LLM在医疗、金融等高度敏感且受监管领域的应用具有重要意义，因为它能在不牺牲数据隐私的前提下，增强模型的透明度和可信度。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）在敏感领域（如医疗保健）的部署日益增长，确保其计算溯源的完整性成为一项关键挑战，特别是在对数据集使用有严格要求的受监管行业。

**Method:** ZKPROV是一个新颖的密码学框架，它通过零知识证明实现LLM溯源。该方法通过数据集签名的元数据和紧凑的模型参数承诺，将训练好的模型与其授权训练数据集进行密码学绑定，同时避免证明每个训练步骤，从而允许用户在不泄露敏感信息的情况下验证模型是否在可靠数据集上训练。

**Result:** 实验结果表明ZKPROV在生成和验证证明方面具有效率和可扩展性，为实际部署提供了实用解决方案。论文还提供了形式化的安全保障，证明该方法在确保可信数据集溯源的同时保留了数据集机密性。

**Conclusion:** ZKPROV提供了一种实用、高效且隐私保护的零知识方法来验证LLM的数据集溯源，解决了在敏感领域部署LLM时的关键完整性挑战。

> **ai_Abstract:** ZKPROV是一种新颖的零知识密码学框架，旨在解决大型语言模型在敏感领域部署时的数据集溯源完整性问题。它允许用户在不泄露敏感数据集或模型参数信息的情况下，验证LLM是否在授权且可靠的数据集上训练。通过密码学绑定模型与数据集，并避免对每个训练步骤进行证明，ZKPROV在效率和隐私保护之间取得了平衡。实验证明其在实际应用中的高效性和可扩展性，并提供了形式化的安全保障，确保了数据集的机密性和溯源的可靠性。

> **摘要翻译:** 随着大型语言模型（LLM）在敏感领域的部署日益增长，确保其计算溯源的完整性成为一项关键挑战，特别是在医疗保健等受监管行业，这些行业对数据集的使用有严格要求。我们引入了ZKPROV，一个新颖的密码学框架，能够实现LLM溯源的零知识证明。它允许用户验证模型是否在可靠数据集上训练，而无需泄露有关数据集或其参数的敏感信息。与之前侧重于训练过程完整验证（导致显著的计算成本）或依赖可信执行环境的方法不同，ZKPROV提供了一种独特的平衡。我们的方法通过零知识证明，将训练好的模型与其授权训练数据集进行密码学绑定，同时避免证明每个训练步骤。通过利用数据集签名的元数据和紧凑的模型参数承诺，ZKPROV提供了可靠且隐私保护的保证，即LLM的结果源自于在声明的授权和相关数据集上训练的模型。实验结果表明ZKPROV在生成和验证此证明方面的效率和可扩展性，为实际部署提供了实用解决方案。我们还提供了形式化的安全保障，证明我们的方法在确保可信数据集溯源的同时保留了数据集机密性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [45] [CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](https://arxiv.org/abs/2506.20926)
> *CodeGuard：一种用于生成式代码模型的通用隐蔽后门水印技术*

*Haoxuan Li, Jiale Zhang, Xiaobing Sun, Xiapu Luo* | **Category: cs.CR**

**Keywords:** CodeGuard, 后门水印, 生成式代码模型, 版权保护, 隐蔽性

**Comment:** 13 pages

> **TL;DR:** CodeGuard是一种新型后门水印技术，通过结合注意力机制和分布式触发器嵌入策略，解决了现有技术在生成式代码模型版权保护中面临的通用性和隐蔽性不足问题，实现了高验证率和极低的检测率。

**AI_Comments:** CodeGuard的创新之处在于其结合了注意力机制和分布式触发器嵌入策略，有效解决了现有后门水印技术在通用性和隐蔽性上的痛点。特别是同形字符替换的应用，提升了水印对人工检测的抵抗力，而分布式触发器则增强了对自动化检测的鲁棒性。该研究对于生成式代码模型的知识产权保护具有重要意义，为AI模型版权保护提供了新的思路和高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 生成式代码模型（GCMs）的开发和训练成本高昂，需要有效的数字版权保护来防止未经授权的泄露和滥用。现有后门水印技术面临两大挑战：一是泛化能力有限，导致验证率波动；二是隐蔽性不足，容易被自动检测和移除。

**Method:** CodeGuard提出了一种结合注意力机制和分布式触发器嵌入策略的新型水印方法。它利用注意力机制识别水印嵌入位置以确保可验证性；通过同形字符替换避免人工检测；通过分布式触发器嵌入降低自动检测的可能性。

**Result:** CodeGuard在代码摘要和代码生成任务中均实现了高达100%的水印验证率，且不影响主任务性能。在隐蔽性方面表现出色，对抗ONION检测方法的最大检测率仅为0.078，远低于基线方法。

**Conclusion:** CodeGuard成功解决了生成式代码模型后门水印技术在泛化性和隐蔽性方面的挑战，提供了一种高效且难以检测的版权保护方案。

> **ai_Abstract:** 本论文提出了CodeGuard，一种针对生成式代码模型的新型后门水印技术，旨在解决现有方法在版权保护方面存在的泛化能力和隐蔽性不足的问题。CodeGuard通过结合注意力机制识别水印嵌入位置，并利用同形字符替换和分布式触发器嵌入策略来增强隐蔽性。实验证明，CodeGuard在代码摘要和代码生成任务中均能达到100%的水印验证率，且不影响模型主任务性能，同时其对抗自动检测的隐蔽性远超现有基线方法。

> **摘要翻译:** 生成式代码模型（GCMs）通过自动化代码生成和代码摘要显著提高了开发效率。然而，构建和训练这些模型需要大量的计算资源和时间，因此需要有效的数字版权保护来防止未经授权的泄露和滥用。后门水印技术通过嵌入隐藏标识符，打破了模型的黑盒性质，从而简化了版权验证。当前后门水印技术面临两大主要挑战：首先，在不同任务和数据集上的泛化能力有限，导致验证率波动；其次，隐蔽性不足，水印容易被自动化方法检测和移除。为了解决这些问题，我们提出了CodeGuard，一种结合注意力机制和分布式触发器嵌入策略的新型水印方法。具体来说，CodeGuard采用注意力机制来识别水印嵌入位置，确保可验证性。此外，通过使用同形字符替换，它避免了人工检测，而分布式触发器嵌入则降低了自动检测的可能性。实验结果表明，CodeGuard在代码摘要和代码生成任务中均实现了高达100%的水印验证率，且对主要任务性能没有影响。在隐蔽性方面，CodeGuard表现异常出色，对抗ONION检测方法的最大检测率仅为0.078，显著低于基线方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [69] [SPA: Towards More Stealth and Persistent Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2506.20931)
> *SPA：迈向联邦学习中更隐蔽和持久的后门攻击*

*Chengcheng Zhu, Ye Li, Bosen Rao, Jiale Zhang, Yunlong Mao, Sheng Zhong* | **Category: cs.CR**

**Keywords:** 联邦学习, 后门攻击, 特征空间对齐, 隐蔽性, 持久性

**Comment:** 18 pages

> **TL;DR:** SPA是一种新的联邦学习后门攻击框架，通过特征空间对齐实现更隐蔽和持久的攻击，优于传统方法。

**AI_Comments:** 这项工作创新性地将后门攻击从传统的标签监督转向特征空间对齐，显著提高了攻击的隐蔽性和持久性。其提出的自适应对抗性触发优化机制也增强了攻击的鲁棒性。这项研究揭示了联邦学习中新的安全漏洞，对未来防御策略的开发具有重要指导意义，特别是需要关注特征层面的防御。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）作为隐私保护分布式机器学习的领先范式，面临独特的安全挑战，尤其是后门攻击的威胁。现有后门策略主要依赖于端到端标签监督，但这通常导致可检测的特征解缠和有限的攻击持久性。

**Method:** 本文提出了一种名为SPA的新型隐蔽后门攻击框架，它通过利用特征空间对齐而非直接触发-标签关联，从根本上区别于传统方法。具体而言，SPA通过减少后门触发特征与目标类特征之间的表征距离，使全局模型能够以高隐蔽性和持久性错误分类嵌入触发器的输入。此外，引入了一种自适应的对抗性触发优化机制，利用特征空间中的边界搜索来增强攻击的持久性和有效性。

**Result:** 在各种FL基准测试上的广泛实验表明，SPA始终实现高攻击成功率，对模型效用影响最小。它在挑战性参与和数据异质性条件下保持鲁棒性，并展现出远超传统技术的持久后门效应。

**Conclusion:** 研究结果呼吁紧急关注联邦学习中后门威胁的演变复杂性，并强调迫切需要先进的特征级防御技术。

> **ai_Abstract:** 本论文提出了一种名为SPA的新型联邦学习后门攻击框架，旨在解决现有攻击中特征可检测性和持久性不足的问题。SPA通过在特征空间中对齐后门触发特征与目标类特征，而非传统的标签关联，实现了更隐蔽和持久的攻击。此外，该框架引入了自适应对抗性触发优化机制以增强攻击寿命和有效性。实验证明，SPA在多种FL场景下表现出高攻击成功率、低模型影响、强鲁棒性以及优越的持久性，揭示了联邦学习中后门威胁的日益复杂性，并强调了对特征级防御的迫切需求。

> **摘要翻译:** 联邦学习（FL）已成为保护隐私的分布式机器学习的领先范式，但FL的分布式特性带来了独特的安全挑战，特别是后门攻击的威胁。现有的后门策略主要依赖于端到端标签监督，尽管它们有效，但通常会导致可检测的特征解缠和有限的持久性。在这项工作中，我们提出了一种新颖且隐蔽的后门攻击框架，名为SPA，它通过利用特征空间对齐而非直接的触发-标签关联，从根本上脱离了传统方法。具体而言，SPA减少了后门触发特征和目标类特征之间的表征距离，使全局模型能够以高度隐蔽性和持久性错误分类嵌入触发器的输入。我们进一步引入了一种自适应的对抗性触发优化机制，利用特征空间中的边界搜索来增强攻击的持久性和有效性，即使在防御性FL场景和非IID数据分布下也是如此。在各种FL基准测试上的广泛实验表明，SPA始终实现高攻击成功率，对模型效用影响最小，在挑战性参与和数据异质性条件下保持鲁棒性，并展现出远超传统技术的持久后门效应。我们的结果呼吁紧急关注FL中后门威胁的演变复杂性，并强调迫切需要先进的特征级防御技术。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [75] [Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations](https://arxiv.org/abs/2506.21134)
> *内部工作：防御Kubernetes集群的网络错误配置*

*Jacopo Bufalino, Jose Luis Martin-Navarro, Mario Di Francesco, Tuomas Aura* | **Category: cs.CR, cs.NI**

**Keywords:** Kubernetes, 网络配置, 安全, 错误配置, 横向移动

**Comment:** 

> **TL;DR:** 本文分析了Kubernetes集群中的网络错误配置，发现大量现有工具未能识别的漏洞，并协助相关组织进行了修复。

**AI_Comments:** 这篇论文通过对大量实际开源应用的分析，揭示了Kubernetes网络配置中普遍存在的安全漏洞。其发现的数量远超现有工具，具有重要的实践意义。研究不仅停留在发现问题，还负责任地披露并协助修复，体现了很强的实用性和影响力，对提升Kubernetes集群的实际安全性具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对Kubernetes的安全研究广泛，但很少有研究关注网络配置对应用程序部署安全的影响，特别是与横向移动相关的部分，本文旨在填补这一空白。

**Method:** 研究人员对来自六个不同组织（包括IT公司、公共实体和非营利组织）的287个开源应用程序进行了广泛评估，以分析Kubernetes集群中的网络错误配置。

**Result:** 识别出634个网络错误配置，远超现有解决方案的发现能力。研究人员已负责任地向相关组织披露了发现，并已促使30多个应用程序的错误配置得到修复。

**Conclusion:** 通过对Kubernetes集群中网络错误配置的全面分析和发现披露，本文强调了网络配置对应用安全的重要性，并证明了其方法在识别和解决这些漏洞方面的有效性。

> **ai_Abstract:** 本文针对Kubernetes集群中网络配置对应用安全的影响这一研究空白，进行了全面的网络错误配置分析，尤其关注横向移动。通过对287个开源应用的评估，发现了634个错误配置，远超现有工具的发现能力。研究团队已将发现告知相关组织，并成功推动了30多个应用程序的错误配置修复，突显了网络配置安全的重要性及现有工具的不足。

> **摘要翻译:** Kubernetes已成为容器编排的事实标准。不幸的是，其日益增长的普及也使其成为恶意攻击者的诱人目标。尽管对Kubernetes的安全研究广泛，但很少有研究关注网络配置对应用程序部署安全的影响。本文通过对Kubernetes集群中的网络错误配置进行全面分析，特别提及横向移动，来弥补这一空白。因此，我们对来自六个不同组织（包括IT公司、公共实体和非营利组织）的287个开源应用程序进行了广泛评估。结果，我们识别出634个错误配置，远超现有解决方案所能发现的数量。我们负责任地向相关组织披露了我们的发现，并进行了讨论以评估其严重性。截至目前，受我们提出的缓解措施影响的30多个应用程序的错误配置已得到修复。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [93] [PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection](https://arxiv.org/abs/2506.20981)
> *PrivacyGo：基于多维交集分析的隐私保护广告衡量*

*Jian Du, Haohao Qian, Shikun Zhang, Wen-jie Lu, Donghang Lu, Yongchuan Niu, Bo Jiang, Yongjun Zhao, Qiang Yan* | **Category: cs.CR**

**Keywords:** 隐私保护, 广告衡量, 多标识符匹配, 不经意伪随机函数, 差分隐私

**Comment:** 

> **TL;DR:** 本文提出PrivacyGo，一个使用反向不经意伪随机函数和盲密钥轮换技术，实现多标识符隐私保护广告衡量的加密框架。

**AI_Comments:** 本文的创新之处在于结合了反向不经意伪随机函数、盲密钥轮换技术和差分隐私，以解决多标识符广告衡量中的隐私挑战。其重要性在于为广告行业提供了可扩展且高效率的隐私保护方案，为该领域设定了新标准，有效缓解了用户隐私泄露的风险。

<details>
  <summary>Details</summary>

**Motivation:** 解决现代广告分析中多标识符私人用户画像匹配的挑战性问题，即隐私保护广告衡量。

**Method:** 引入一个综合的加密框架，利用反向不经意伪随机函数（OPRF）和新颖的盲密钥轮换技术，支持跨多个标识符的安全匹配。设计上防止跨标识符链接，并包含一个差分隐私机制来混淆交集大小，以减轻成员推断攻击等风险。

**Result:** 实现了强大的隐私保证和高效率，能够扩展到大型数据集，为安全广告转化跟踪等以隐私为中心的应用提供实用且可扩展的解决方案。

**Conclusion:** 通过结合严格的密码学原理和差分隐私，解决了广告行业的一个关键需求，为隐私保护广告衡量框架设定了新标准。

> **ai_Abstract:** PrivacyGo提出一个创新的加密框架，利用反向不经意伪随机函数和盲密钥轮换技术，实现隐私保护的多标识符用户画像匹配和广告衡量。该框架通过差分隐私机制防止跨标识符链接和成员推断攻击，同时保证了高效率和可扩展性，为广告行业提供了一个实用的隐私保护解决方案。

> **摘要翻译:** 本文解决了多标识符隐私用户画像匹配这一具有挑战性且实用的问题，该问题是现代广告分析的基石。我们引入了一个综合的加密框架，利用反向不经意伪随机函数（OPRF）和新颖的盲密钥轮换技术，以支持跨多个标识符的安全匹配。我们的设计阻止了跨标识符链接，并包含一个差分隐私机制来混淆交集大小，从而减轻了诸如成员推断攻击等风险。
我们提出了一个具体的协议构造，该构造实现了强大的隐私保证和高效率。它能够扩展到大型数据集，为诸如安全广告转化跟踪等以隐私为中心的应用提供了一个实用且可扩展的解决方案。通过将严格的密码学原理与差分隐私相结合，我们的工作解决了广告行业的一个关键需求，为隐私保护广告衡量框架设定了新标准。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [116] [TEMPEST-LoRa: Cross-Technology Covert Communication](https://arxiv.org/abs/2506.21069)
> *TEMPEST-LoRa：跨技术隐蔽通信*

*Xieyang Sun, Yuanqing Zheng, Wei Xi, Zuhao Chen, Zhizhen Chen, Han Hao, Zhiping Jiang, Sheng Zhong* | **Category: cs.CR**

**Keywords:** TEMPEST, LoRa, 隐蔽通信, 跨技术, 气隙网络

**Comment:** 15 pages, 19 figures, and this paper has been accepted to ACM CCS
  2025

> **TL;DR:** 本文提出了一种名为TEMPEST-LoRa的跨技术隐蔽通信方法，通过操纵视频线缆产生的电磁泄漏，将气隙网络中的秘密数据远距离传输到商用LoRa接收器，揭示了潜在的安全风险。

**AI_Comments:** 该研究的创新之处在于利用了普遍部署的LoRa技术作为接收端，并通过操纵常见的视频线缆来产生电磁泄漏，克服了以往电磁隐蔽信道对特殊接收设备和近距离传输的限制。这使得隐蔽通信更具实际威胁性，对气隙网络的安全防护提出了新的挑战。其能够远距离、高速率传输数据且能在显示器关闭时进行，进一步凸显了其潜在的危害性。

<details>
  <summary>Details</summary>

**Motivation:** 电磁（EM）隐蔽信道对气隙网络中的计算机和通信安全构成重大威胁。以往的工作利用各种组件（如视频线缆、内存总线、CPU）的电磁辐射秘密发送敏感信息，但这些方法通常要求攻击者在受害者附近部署高度专业化的接收器，这限制了它们的实际影响。本文旨在克服这一限制，展示一种更具实际影响力的电磁隐蔽信道。

**Method:** 本文提出了一种新的电磁隐蔽信道TEMPEST-LoRa，其基于跨技术隐蔽通信（CTCC）。该方法通过操纵视频线缆精确生成电磁泄漏，这些泄漏可以被广泛部署的商用LoRa接收器从远处接收，从而实现从气隙网络中隐蔽传输电磁调制秘密数据。

**Result:** 实验结果表明，攻击者可以可靠地解码来自视频线缆电磁泄漏调制的秘密数据，最大距离可达87.5米，或传输速率达到21.6 kbps。此外，秘密数据传输可以在显示器关闭的情况下进行，从而实现隐蔽性。

**Conclusion:** 本文成功揭示了利用跨技术隐蔽通信（CTCC）将气隙网络中的数据通过电磁泄漏传输到商用LoRa接收器的潜在风险和可行性，证明了这种新型隐蔽信道的实用性和有效性。

> **ai_Abstract:** 本文介绍了一种名为TEMPEST-LoRa的新型电磁隐蔽信道，该信道利用跨技术隐蔽通信（CTCC）原理。与传统方法需要专业接收器不同，TEMPEST-LoRa通过操纵视频线缆产生电磁泄漏，使商用LoRa接收器能够远距离接收来自气隙网络的秘密数据。实验证明，该方法在最大87.5米距离或21.6 kbps速率下可可靠传输数据，且可在显示器关闭时进行，揭示了气隙网络通信中潜在的严重安全威胁。

> **摘要翻译:** 电磁（EM）隐蔽信道对气隙网络中的计算机和通信安全构成重大威胁。以往的工作利用各种组件（如视频线缆、内存总线、CPU）的电磁辐射秘密发送敏感信息。这些方法通常要求攻击者在受害者附近部署高度专业化的接收器，这限制了它们的实际影响。本文报告了一种新的电磁隐蔽信道TEMPEST-LoRa，它建立在跨技术隐蔽通信（CTCC）的基础上，可以使攻击者将电磁调制的秘密数据从气隙网络隐蔽地传输到远处广泛部署的LoRa接收器。我们通过解决操纵视频线缆精确生成电磁泄漏所涉及的实际挑战，揭示了CTCC的潜在风险并证明了其可行性，这些泄漏可以很容易地被第三方商用LoRa节点/网关接收。实验结果表明，攻击者可以可靠地解码来自视频线缆电磁泄漏调制的秘密数据，最大距离可达87.5米，或传输速率达到21.6 kbps。我们注意到秘密数据传输可以在显示器关闭的情况下进行（因此是隐蔽的）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [136] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
> *PhishKey：一种基于新型质心的方法，用于通过自适应HTML组件提取增强网络钓鱼检测*

*Felipe Castaño, Eduardo Fidalgo, Enrique Alegre, Rocio Alaiz-Rodríguez, Raul Orduna, Francesco Zola* | **Category: cs.CR, cs.AI**

**Keywords:** 网络钓鱼检测, 质心方法, HTML组件提取, 卷积神经网络, 对抗性鲁棒性

**Comment:** 

> **TL;DR:** PhishKey是一种新颖的网络钓鱼检测方法，结合了基于CNN的URL分类和基于质心的HTML内容提取（CAPE），通过软投票集成实现高精度，并在对抗性攻击下表现出强大的鲁棒性。

**AI_Comments:** PhishKey的创新之处在于其混合方法，结合了URL的字符级CNN分析和HTML内容的词级质心提取，这种双管齐下的策略增强了检测的全面性。特别值得注意的是CAPE模块，它通过避免裁剪操作来减少噪声并确保完整样本处理，这对于保持数据完整性至关重要。此外，软投票集成策略提高了分类的可靠性。该方法在对抗性操纵下的鲁棒性是其重要优势，表明其在实际部署中具有潜力。

<details>
  <summary>Details</summary>

**Motivation:** 网络钓鱼攻击对网络安全构成重大威胁，且快速演变以规避检测机制并利用人类弱点。本文引入PhishKey旨在解决网络钓鱼检测中适应性、鲁棒性和效率的挑战。

**Method:** PhishKey是一种新颖的网络钓鱼检测方法，采用混合源的自动特征提取。它结合了字符级处理与卷积神经网络（CNN）进行URL分类，并使用基于质心的关键组件网络钓鱼提取器（CAPE）处理词级的HTML内容。CAPE减少了噪音并确保完整样本处理，避免对输入数据进行裁剪操作。两个模块的预测通过软投票集成进行整合，以实现更准确和可靠的分类。

**Result:** 在四个最先进的数据集上进行的实验评估证明了PhishKey的有效性。它实现了高达98.70%的F1分数，并显示出对注入攻击等对抗性操纵的强大抵抗力，性能下降最小。

**Conclusion:** PhishKey通过结合URL和HTML内容分析的混合方法，有效提高了网络钓鱼检测的准确性和鲁棒性，即使在面对对抗性攻击时也能保持高性能。

> **ai_Abstract:** PhishKey是一种针对网络钓鱼攻击的新型检测方法，旨在提高适应性、鲁棒性和效率。它通过结合CNN进行URL字符级分类和基于质心的CAPE进行HTML词级内容提取来实现自动特征提取。PhishKey利用软投票集成整合两者的预测以提高准确性。实验结果表明，PhishKey在多个数据集上表现出色，F1分数高达98.70%，并对对抗性攻击具有很强的抵抗力。

> **摘要翻译:** 网络钓鱼攻击构成了重大的网络安全威胁，其快速演变以规避检测机制并利用人类的弱点。本文引入PhishKey，旨在解决适应性、鲁棒性和效率方面的挑战。PhishKey是一种新颖的网络钓鱼检测方法，利用混合源的自动特征提取。PhishKey结合了字符级处理与卷积神经网络（CNN）进行URL分类，以及用于词级HTML内容的基于质心的关键组件网络钓鱼提取器（CAPE）。CAPE减少了噪音并确保完整样本处理，避免对输入数据进行裁剪操作。来自两个模块的预测通过软投票集成进行整合，以实现更准确和可靠的分类。在四个最先进的数据集上进行的实验评估证明了PhishKey的有效性。它实现了高达98.70%的F1分数，并显示出对注入攻击等对抗性操纵的强大抵抗力，性能下降最小。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [143] [Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy](https://arxiv.org/abs/2506.21308)
> *相关数据中隐私与效用的平衡：一项关于贝叶斯差分隐私的研究*

*Martin Lange, Patricia Guerra-Balboa, Javier Parra-Arnau, Thorsten Strufe* | **Category: cs.CR, cs.IT, math.IT, 68P27**

**Keywords:** 贝叶斯差分隐私, 相关数据, 隐私保护, 效用平衡, 差分隐私

**Comment:** This is the extended version of the paper accepted in the Proceedings
  of the VLDB Endowment (PVLDB), 2025. The code used for our experiments is
  accessible in https://github.com/lange-martin/privacy-utility-bdp

> **TL;DR:** 本研究探讨了如何在相关数据中实现贝叶斯差分隐私（BDP），同时保持竞争力的数据效用，解决了现有BDP机制中效用损失的问题，为实际应用铺平了道路。

**AI_Comments:** 该论文解决了差分隐私在处理相关数据时的核心挑战，即如何平衡隐私保护和数据效用。通过提出新的理论和方法，使得贝叶斯差分隐私在实际应用中更具可行性，解决了现有BDP机制效用损失过大的问题，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当数据存在相关性时，差分隐私（DP）系统中的隐私风险显著增加，因为标准的DP度量通常会低估由此产生的隐私泄露，使敏感信息面临风险。鉴于现实世界数据库中依赖关系的普遍性，这种疏忽对隐私保护构成了严峻挑战。贝叶斯差分隐私（BDP）扩展了DP以解释这些相关性，但当前的BDP机制表现出显著的效用损失，限制了其采用。本研究旨在解决BDP是否能在不牺牲效用的情况下实际应用于常见数据结构的问题。

**Method:** 通过分析任意和结构化的相关模型，包括高斯多元分布和马尔可夫链，推导出BDP的实用效用保证。贡献包括建立DP和BDP之间的理论联系，以及提出一种新颖的方法，用于调整DP机制以满足BDP要求。通过在真实世界数据库上进行评估。

**Result:** 研究证明，他们的新颖定理能够设计出保持竞争性效用的BDP机制。

**Conclusion:** 这为在相关设置中实现实用的隐私保护数据实践铺平了道路。

> **ai_Abstract:** 本研究旨在解决贝叶斯差分隐私（BDP）在相关数据中应用时面临的效用损失挑战。鉴于标准差分隐私在处理相关数据时存在隐私泄露低估的问题，BDP被提出以更好地考虑数据相关性。通过分析高斯多元分布和马尔可夫链等相关模型，本研究推导了BDP的实用效用保证，并建立了DP与BDP之间的理论联系。此外，还提出了一种新颖的方法来调整DP机制以满足BDP要求。在真实世界数据库上的评估表明，所提出的新定理能够设计出具有竞争性效用的BDP机制，从而促进了在相关数据环境中实际的隐私保护实践。

> **摘要翻译:** 当数据存在相关性时，差分隐私（DP）系统中的隐私风险显著增加，因为标准的DP度量通常会低估由此产生的隐私泄露，使敏感信息面临风险。鉴于现实世界数据库中依赖关系的普遍性，这种疏忽对隐私保护构成了严峻挑战。贝叶斯差分隐私（BDP）扩展了DP以解释这些相关性，但当前的BDP机制表现出显著的效用损失，限制了其采用。
在这项工作中，我们探讨了BDP是否能在不牺牲效用的情况下在常见数据结构中实际实现——这是其适用性的关键因素。通过分析任意和结构化的相关模型，包括高斯多元分布和马尔可夫链，我们推导了BDP的实用效用保证。我们的贡献包括建立DP和BDP之间的理论联系，以及提出一种新颖的方法，用于调整DP机制以满足BDP要求。通过在真实世界数据库上的评估，我们证明了我们的新颖定理能够设计出保持竞争性效用的BDP机制，为在相关设置中实现实用的隐私保护数据实践铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [7] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
> *即时人机协作挑战*

*Tin Dizdarević, Ravi Hammond, Tobias Gessler, Anisoara Calinescu, Jonathan Cook, Matteo Gallici, Andrei Lupu, Jakob Nicolaus Foerster* | **Category: cs.AI, cs.HC, cs.MA**

**Keywords:** 人机协作, AI代理, Hanabi, 评估, 数据集

**Comment:** Published at ICML 2025

> **TL;DR:** 本文提出了即时人机协作挑战（AH2AC2），通过开发人类代理智能体和开放数据集来克服人类评估的挑战，旨在促进人机协作领域的发展。

**AI_Comments:** 这项工作具有重要的创新性，它通过引入“人类代理智能体”解决了人机协作研究中昂贵且难以重现的人类评估这一核心挑战。这种方法为开发和测试人机协作AI提供了一个高效且可扩展的平台。通过开源有限数据量的数据集，该论文还巧妙地鼓励了数据高效型AI算法的开发，这在实际应用中具有重要意义。其贡献在于为未来的人机协作研究奠定了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 实现AI智能体与人类之间的无缝协作对于实际应用至关重要，但目前仍是一个重大的开放挑战。现有人机交互中对Hanabi游戏的使用受限于昂贵且难以重现的人类评估。

**Method:** 本文引入了即时人机协作挑战（AH2AC2），以克服昂贵且难以重现的人类评估限制。研究人员在一个大规模人类数据集上开发了“人类代理智能体”，这些智能体可以作为AH2AC2中稳健、廉价且可复现的类人评估伙伴。为了鼓励开发数据高效的方法，他们开源了一个包含3,079场游戏的数据集，并故意限制了可用的人类游戏数据量。为了确保公平评估，代理智能体通过受控评估系统托管，而不是公开发布。

**Result:** 本文为两人和三人Hanabi场景提供了基线结果。开源了一个包含3,079场游戏的数据集。

**Conclusion:** 本文通过引入AH2AC2挑战、开发人类代理智能体和提供有限但有价值的数据集，为解决人机协作评估难题提供了一个创新且可扩展的解决方案，从而促进了该领域数据高效方法的发展。

> **ai_Abstract:** 本文提出了即时人机协作挑战（AH2AC2），旨在通过克服传统人类评估的局限性来促进人机协作领域的发展。研究人员在合作纸牌游戏Hanabi中，利用大规模人类数据集开发了“人类代理智能体”，这些智能体可作为廉价、可复现的类人评估伙伴。此外，他们开源了一个有限规模的数据集，以鼓励开发数据高效的AI方法，并提供了基线结果，通过受控系统确保公平评估。

> **摘要翻译:** 在实际应用中，实现AI智能体与人类之间的无缝协作至关重要，但这仍然是一个重大的开放挑战。Hanabi是一款具有不完美信息、受限通信、心智理论要求和协调行动的合作纸牌游戏——这使其成为人机协作的理想试验平台。然而，其在人机交互中的使用一直受到人类评估挑战的限制。在这项工作中，我们引入了即时人机协作挑战（AH2AC2），以克服昂贵且难以重现的人类评估限制。我们在一个大规模人类数据集上开发了“人类代理智能体”，它们在AH2AC2中可以作为稳健、廉价且可复现的类人评估伙伴。为了鼓励开发数据高效的方法，我们开源了一个包含3,079场游戏的数据集，并故意限制了可用的人类游戏数据量。我们展示了两人和三人Hanabi场景的基线结果。为了确保公平评估，我们通过受控评估系统托管代理智能体，而不是公开发布它们。代码可在https://github.com/FLAIROx/ah2ac2获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [14] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
> *全球AI安全研究重点的新加坡共识*

*Yoshua Bengio, Tegan Maharaj, Luke Ong, Stuart Russell, Dawn Song, Max Tegmark, Lan Xue, Ya-Qin Zhang, Stephen Casper, Wan Sie Lee, Sören Mindermann, Vanessa Wilfred, Vidhisha Balachandran, Fazl Barez, Michael Belinsky, Imane Bello, Malo Bourgon, Mark Brakel, Siméon Campos, Duncan Cass-Beggs, Jiahao Chen, Rumman Chowdhury, Kuan Chua Seah, Jeff Clune, Juntao Dai, Agnes Delaborde, Nouha Dziri, Francisco Eiras, Joshua Engels, Jinyu Fan, Adam Gleave, Noah Goodman, Fynn Heide, Dan Hendrycks, Cyrus Hodes, Bryan Low Kian Hsiang, Minlie Huang, Sami Jawhar, Wang Jingyu, Adam Tauman Kalai, Meindert Kamphuis, Mohan Kankanhalli, Subhash Kantamneni, Mathias Bonde Kirk, Thomas Kwa, Jeffrey Ladish, Kwok-Yan Lam, Wan Lee Sie, Taewhi Lee, Xiaojian Li, Jiajun Liu, Chaochao Lu, Yifan Mai, Richard Mallah, Julian Michael, Nick Moës, Simon Möller, Kihyuk Nam, Kwan Yee Ng, Mark Nitzberg, Besmira Nushi, Seán O hÉigeartaigh, Alejandro Ortega, Pierre Peigné, James Petrie, Benjamin Prud'Homme, Reihaneh Rabbany, Nayat Sanchez-Pi, Sarah Schwettmann, Buck Shlegeris, Saad Siddiqui, Aradhana Sinha, Martín Soto, Cheston Tan, Dong Ting, Robert Trager, Brian Tse, Anthony Tung K. H., Vanessa Wilfred, John Willes, Denise Wong, Wei Xu, Rongwu Xu, Yi Zeng, HongJiang Zhang, Djordje Žikelić* | **Category: cs.AI, cs.CY**

**Keywords:** AI安全, 研究重点, 新加坡共识, 深度防御, 可信AI

**Comment:** Final report from the "2025 Singapore Conference on AI (SCAI)" held
  April 26: https://www.scai.gov.sg/2025/scai2025-report

> **TL;DR:** AI能力快速提升，AI安全至关重要。2025年新加坡AI会议旨在汇集全球AI科学家，识别并综合AI安全研究重点，将挑战分为开发、评估和控制三类。

**AI_Comments:** 这篇报告的重要性在于它汇集了全球AI科学家的共识，并为AI安全研究提供了一个结构化的框架（开发、评估、控制）。它强调了在AI快速发展背景下，确保AI可信、可靠和安全的重要性，并为未来的研究指明了方向。其创新之处在于提出了一个“深度防御模型”来组织AI安全研究。

<details>
  <summary>Details</summary>

**Motivation:** 快速发展的AI能力带来巨大潜力，但也引发了关于如何确保AI安全（可信、可靠、安全）的激烈辩论。建立一个可信的AI生态系统至关重要，以促进AI的自信采纳和创新，同时避免负面影响。因此，需要支持AI安全领域的研究。

**Method:** 2025年新加坡AI会议（SCAI）通过汇集全球AI科学家，旨在识别和综合AI安全研究重点。该报告基于Yoshua Bengio主持并由33个政府支持的国际AI安全报告，并采用了深度防御模型，将AI安全研究领域组织成三类：创建可信AI系统面临的挑战（开发）、评估其风险面临的挑战（评估）、以及部署后监控和干预面临的挑战（控制）。

**Result:** 该报告组织了AI安全研究领域，将其挑战分为开发、评估和控制三类。

**Conclusion:** 该报告的结论是将AI安全研究领域划分为开发、评估和控制三大类挑战，以构建可信赖的AI生态系统。

> **ai_Abstract:** 本文介绍了“2025年新加坡AI会议”的成果，该会议旨在汇集全球AI科学家，识别并综合AI安全研究重点。报告在国际AI安全报告的基础上，采用深度防御模型，将AI安全研究挑战分为三大类：开发可信AI系统、评估AI系统风险以及部署后监控和干预。

> **摘要翻译:** 快速提升的AI能力和自主性带来了巨大的变革前景，但也引发了关于如何确保AI安全，即值得信赖、可靠和安全的激烈辩论。因此，建立一个值得信赖的生态系统至关重要——它有助于人们自信地拥抱AI，为创新提供最大的空间，同时避免反弹。
“2025年新加坡AI会议（SCAI）：AI安全国际科学交流”旨在通过汇集全球AI科学家，识别和综合AI安全研究重点，从而支持该领域的研究。这份报告建立在由Yoshua Bengio主持并由33个政府支持的国际AI安全报告的基础上。通过采用深度防御模型，本报告将AI安全研究领域组织为三类：创建可信AI系统面临的挑战（开发）、评估其风险面临的挑战（评估）、以及部署后监控和干预面临的挑战（控制）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [30] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
> *MAGPIE：一个用于多智能体情境隐私评估的数据集*

*Gurusha Juneja, Alon Albalak, Wenyue Hua, William Yang Wang* | **Category: cs.AI, cs.CL**

**Keywords:** LLM智能体, 情境隐私, 多智能体系统, 数据集, 隐私评估

**Comment:** 

> **TL;DR:** 本研究提出了MAGPIE数据集，用于评估基于LLM的多智能体在情境隐私方面的表现。结果表明，当前最先进的模型在理解和保护情境隐私方面表现不佳，且在多轮对话中仍会泄露私有信息。

**AI_Comments:** 本文通过引入MAGPIE数据集，填补了LLM多智能体情境隐私评估领域的空白，尤其关注了高风险和复杂场景，这具有重要的创新性。研究结果清晰地揭示了当前LLM在处理情境隐私方面的显著局限性，即使是顶级模型也无法有效应对，这对于未来LLM模型的设计和部署具有重要的指导意义。该研究强调了在追求模型能力的同时，隐私保护对齐的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 随着基于大型语言模型（LLM）的智能体在日程安排、谈判、资源分配等任务中进行跨智能体协作的部署日益增多，隐私问题变得至关重要，因为智能体经常访问需要严格保密的专有工具和领域特定数据库。现有评估LLM智能体情境隐私的基准主要评估单轮、低复杂度的任务，其中私有信息可以轻易排除。因此，本文旨在探究LLM智能体是否理解情境隐私，以及在收到指示后，这些系统在非对抗性多轮对话中是否能保护推断时期的用户隐私。

**Method:** 本文首先提出了一个名为MAGPIE的基准数据集，该数据集包含158个跨越15个领域的真实世界高风险场景。这些场景的设计使得完全排除私有数据会阻碍任务完成，但无限制的信息共享又可能导致重大损失。然后，研究人员评估了当前最先进的LLM模型（包括GPT-4o和Claude-2.7-Sonnet）在(a)其对情境私有数据的理解和(b)其在不违反用户隐私的情况下进行协作的能力。

**Result:** 实证实验表明，当前模型（包括GPT-4o和Claude-2.7-Sonnet）缺乏对情境隐私的鲁棒理解，将私有数据错误分类为可共享数据的比例分别为25.2%和43.6%。在多轮对话中，即使有明确的隐私指令，这些模型仍有59.9%和50.5%的案例会泄露私有信息。此外，多智能体系统在71%的场景中未能完成任务。

**Conclusion:** 这些结果强调，当前模型尚未实现情境隐私保护与协作任务解决的同步对齐。

> **ai_Abstract:** 本文针对基于LLM的多智能体协作中情境隐私的挑战，提出了一个名为MAGPIE的新基准数据集。该数据集包含158个高风险真实场景，旨在评估智能体对情境隐私的理解及其在不泄露私有信息前提下完成协作任务的能力。通过对当前最先进LLM模型（如GPT-4o和Claude-2.7-Sonnet）的评估，研究发现，现有模型在识别和保护情境隐私方面表现不佳，即使在明确指示下，仍频繁泄露私有信息，并导致多智能体系统任务完成率低下。这表明当前模型在隐私保护和协作任务解决之间存在对齐问题。

> **摘要翻译:** 基于LLM的智能体日益普及，导致跨智能体协作在日程安排、谈判、资源分配等任务中的部署不断增加。在此类系统中，隐私至关重要，因为智能体通常访问需要严格保密的专有工具和领域特定数据库。本文研究LLM智能体是否能理解情境隐私。并且，如果受到指示，这些系统是否能在非对抗性多轮对话中保护推理时的用户隐私。现有评估LLM智能体情境隐私的基准主要评估单轮、低复杂度的任务，其中私有信息可以轻易排除。我们首先提出了一个基准——MAGPIE，它包含15个领域中158个真实世界的高风险场景。这些场景的设计使得完全排除私有数据会阻碍任务完成，而无限制的信息共享可能导致重大损失。然后，我们评估了当前最先进的LLM模型在(a)它们对情境私有数据的理解和(b)它们在不违反用户隐私的情况下进行协作的能力。实证实验表明，当前模型，包括GPT-4o和Claude-2.7-Sonnet，缺乏对情境隐私的鲁棒理解，将私有数据错误分类为可共享的比例分别为25.2%和43.6%。在多轮对话中，即使在明确的隐私指令下，这些模型在59.9%和50.5%的案例中披露了私有信息。此外，多智能体系统在71%的场景中未能完成任务。这些结果强调，当前模型尚未实现情境隐私保护与协作任务解决的同步对齐。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [54] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
> *面向领域特定AI应用的动态上下文感知提示推荐*

*Xinye Tang, Haijun Zhai, Chaitanya Belwal, Vineeth Thayanithi, Philip Baumann, Yogesh K Roy* | **Category: cs.AI**

**Keywords:** 提示推荐, 领域特定AI, LLM应用, 上下文感知, 检索增强

**Comment:** 

> **TL;DR:** 本文提出了一种动态上下文感知的提示推荐系统，用于解决领域特定AI应用中高质量提示的生成难题，并通过实验证明了其有效性和实用性。

**AI_Comments:** 该论文的创新点在于其提出的动态上下文感知提示推荐系统，它通过多方面技术结合（如检索增强、分层技能组织和自适应排序）来解决领域特定AI应用中提示质量的痛点。这对于提升LLM在专业领域应用的可用性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** LLM（大型语言模型）驱动的应用极易受到用户提示质量的影响，尤其对于领域特定的应用，创建高质量的提示往往具有挑战性。

**Method:** 本系统结合了上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排序来生成相关且可操作的提示建议。它利用行为遥测和两阶段分层推理过程来动态选择和排序相关技能，并使用预定义和通过少量学习增强的自适应模板来合成提示。

**Result:** 在真实世界数据集上的实验表明，该方法实现了高实用性和相关性，并通过自动化和专家评估得到了验证。

**Conclusion:** 该动态上下文感知提示推荐系统有效解决了领域特定AI应用中高质量提示的生成挑战，显著提升了LLM应用的表现。

> **ai_Abstract:** 本文提出了一种新颖的动态上下文感知提示推荐系统，专为领域特定AI应用设计。该系统通过整合上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排序，旨在生成高质量、相关且可操作的提示建议。它利用行为遥测和两阶段分层推理过程动态选择和排序技能，并通过结合预定义与少量学习增强的自适应模板来合成提示。实验结果表明，该方法在实用性和相关性方面表现出色，有效提升了LLM驱动应用的性能。

> **摘要翻译:** LLM驱动的应用极易受到用户提示质量的影响，尤其对于领域特定的应用，创建高质量的提示往往具有挑战性。本文提出了一种新颖的面向领域特定AI应用的动态上下文感知提示推荐系统。我们的解决方案结合了上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排序，以生成相关且可操作的提示建议。该系统利用行为遥测和两阶段分层推理过程来动态选择和排序相关技能，并使用预定义和通过少量学习增强的自适应模板来合成提示。在真实世界数据集上的实验表明，我们的方法实现了高实用性和相关性，并通过自动化和专家评估得到了验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [77] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
> *超越被动安全：通过长周期模拟实现风险感知LLM对齐*

*Chenkai Sun, Denghui Zhang, ChengXiang Zhai, Heng Ji* | **Category: cs.AI, cs.CL**

**Keywords:** 语言模型对齐, 风险感知, 长周期模拟, AI安全, 间接危害

**Comment:** 

> **TL;DR:** 本文提出了一个概念验证框架和新的数据集，旨在通过长周期模拟来提升语言模型的风险感知和长期安全对齐，并在新旧安全基准上取得了显著改进。

**AI_Comments:** 这项工作创新性地将LLM安全对齐的视角从即时、被动的响应扩展到对长期、间接社会影响的风险感知和预测。通过引入长周期模拟和间接危害数据集，解决了现有安全评估可能忽视的复杂链式反应问题，对于开发真正负责任和安全的AI具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于语言模型代理在公共政策和医疗保健等高风险社会决策中日益增长的影响力，确保其有益影响需要理解其建议的深远影响。现有安全措施可能过于被动，未能充分考虑长期、间接的风险。

**Method:** 提出一个概念验证框架，用于宏观尺度上模拟模型生成建议在社会系统中随时间传播的方式，以实现更稳健的对齐。此外，引入了一个包含100个间接危害场景的数据集，用于评估模型预测看似无害的用户提示可能导致的负面、不明显结果的能力。

**Result:** 该方法在新数据集上实现了超过20%的改进，并且在现有安全基准（AdvBench、SafeRLHF、WildGuardMix）上，相对于强基线取得了超过70%的平均胜率。

**Conclusion:** 这项工作为开发更安全的代理提供了一个有前景的方向，通过超越被动安全，转向通过长周期模拟实现风险感知的LLM对齐。

> **ai_Abstract:** 本文提出了一个超越传统被动安全的风险感知LLM对齐框架，通过长周期模拟来预测语言模型建议在社会系统中的长期影响。为评估模型的长期安全意识，还引入了一个包含100个间接危害场景的新数据集。实验结果表明，该方法在新数据集上表现显著，并在现有安全基准上超越了强基线，为构建更安全的AI代理提供了有价值的方向。

> **摘要翻译:** 鉴于基于语言模型的代理在公共政策到医疗保健等高风险社会决策中日益增长的影响力，确保其有益影响需要理解其建议的深远影响。我们提出了一个概念验证框架，该框架预测模型生成的建议如何随时间在宏观层面上传播到社会系统中，从而实现更稳健的对齐。为了评估语言模型的长期安全意识，我们还引入了一个包含100个间接危害场景的数据集，测试模型预测看似无害的用户提示可能导致的负面、不明显结果的能力。我们的方法不仅在新数据集上取得了超过20%的改进，而且在现有安全基准（AdvBench、SafeRLHF、WildGuardMix）上，相对于强基线，平均胜率超过70%，这表明了开发更安全代理的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [100] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
> *揭示大型语言模型中的因果推理：现实还是海市蜃楼？*

*Haoang Chi, He Li, Wenjing Yang, Feng Liu, Long Lan, Xiaoguang Ren, Tongliang Liu, Bo Han* | **Category: cs.AI, cs.CL, cs.LG**

**Keywords:** 大型语言模型, 因果推理, CausalProbe-2024, G^2-Reasoner, 人工智能

**Comment:** 24 pages, accepted at NeurIPS 2024

> **TL;DR:** 大型语言模型目前仅能进行浅层（一级）因果推理，缺乏类人（二级）能力。新基准CausalProbe-2024证实了这一点。提出的G^2-Reasoner方法通过引入通用知识和目标导向提示，显著提升了LLM的因果推理能力，使其向二级推理迈进。

**AI_Comments:** 本文创新性地提出了LLM因果推理的“一级”和“二级”区分，并通过新颖的基准CausalProbe-2024揭示了LLM在未见数据上因果推理能力的局限性。G^2-Reasoner方法为提升LLM的深层因果推理能力提供了有益的探索方向，强调了通用知识和目标导向提示的重要性。这项工作对于推动LLM向更强人工智能发展具有重要意义，同时也指出了当前LLM在真正理解因果关系方面的不足。

<details>
  <summary>Details</summary>

**Motivation:** 探讨大型语言模型是否具备真正的类人因果推理能力，现有证据表明其仅限于浅层（一级）因果推理，缺乏深层（二级）能力。

**Method:** 方法论上，分析了基于Transformer的LLM的自回归机制，指出其并非内在地具有因果性。经验上，引入了新的因果问答基准CausalProbe-2024，其语料对LLM是新鲜的。为弥补一级到二级因果推理的差距，提出了G^2-Reasoner方法，将通用知识和目标导向提示融入LLM的因果推理过程。

**Result:** LLM在CausalProbe-2024上的表现显著下降，表明其主要进行一级因果推理。G^2-Reasoner显著提升了LLM的因果推理能力，尤其是在新鲜和反事实语境中。

**Conclusion:** 本工作为LLM迈向真正的因果推理、超越一级并向二级发展指明了新路径。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）的因果推理能力，指出当前LLM主要进行浅层（一级）因果推理，缺乏真正的类人（二级）能力。通过分析Transformer的自回归机制和引入新的因果问答基准CausalProbe-2024，验证了LLM在未见过数据上的表现下降，证实其一级推理的局限性。为弥补这一差距，论文提出了G^2-Reasoner方法，该方法将通用知识和目标导向提示融入LLM的因果推理过程，实验证明其能显著提升LLM在新鲜和反事实语境下的因果推理能力，为LLM向更高级的因果推理发展提供了新途径。

> **摘要翻译:** 因果推理能力对于推动大型语言模型（LLM）向强人工智能发展至关重要。尽管多功能LLM似乎已展现出理解语境因果关系并提供符合因果律的响应的能力，但它们是否进行着类似人类的真正因果推理仍不清楚。然而，现有证据表明情况恰恰相反。具体而言，LLM仅能进行浅层（一级）因果推理，这主要归因于其参数中嵌入的因果知识，但它们缺乏真正类人（二级）因果推理的能力。为了支持这一假设，在方法论上，我们深入研究了基于Transformer的LLM的自回归机制，揭示其并非内在地具有因果性。在经验上，我们引入了一个新的因果问答基准CausalProbe-2024，其语料对于所研究的LLM是新鲜且几乎未曾见过的。与早期基准相比，LLM在CausalProbe-2024上的表现显著下降，这表明它们主要进行一级因果推理。为了弥合向二级因果推理的差距，我们从人类推理通常由通用知识和预期目标促进这一事实中获得灵感。我们提出了G^2-Reasoner，这是一种将通用知识和目标导向提示融入LLM因果推理过程的方法。实验表明，G^2-Reasoner显著增强了LLM的因果推理能力，特别是在新鲜和反事实的语境中。这项工作为LLM迈向真正的因果推理、超越一级并向二级发展指明了新路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [121] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
> *世界感知规划叙事增强大型视觉-语言模型规划器*

*Junhao Shi, Zhaoye Fei, Siyin Wang, Qipeng Guo, Jingjing Gong, Xipeng QIu* | **Category: cs.AI, cs.RO**

**Keywords:** 大型视觉-语言模型, 具身规划, 世界感知规划, 认知能力, 课程学习

**Comment:** 

> **TL;DR:** 大型视觉-语言模型（LVLMs）在复杂具身规划任务中表现不佳；本文提出世界感知规划叙事增强（WAP）框架，通过注入全面的环境理解来显著提升LVLMs的性能，并在基准测试中超越了专有模型。

**AI_Comments:** 本文的创新之处在于，它通过明确注入“世界感知”的认知能力，超越了以往与环境无关的模仿学习范式，显著提升了大型视觉-语言模型在具身规划中的表现。其重要性体现在，不仅大幅提高了任务成功率，更令人瞩目的是，其增强的开源模型能够超越顶级的专有系统，这对于推动具身AI领域的发展和实际应用具有深远意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大型视觉-语言模型（LVLMs）在处理涉及不熟悉环境和多步骤目标的复杂具身规划任务时面临困难。现有方法依赖于与环境无关的模仿学习，导致指令与环境背景脱节，模型难以处理上下文敏感的指令，并在长时间交互中过度依赖补充线索而非视觉推理。

**Method:** 本文提出了世界感知规划叙事增强（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和句法接地）为大型视觉-语言模型（LVLMs）注入全面的环境理解。模型仅使用原始视觉观测数据，并通过课程学习进行开发和评估。

**Result:** 在EB-ALFRED基准测试中取得了显著改进，Qwen2.5-VL在任务成功率上实现了60.7的绝对提升，尤其在常识推理（+60.0）和长时程规划（+70.0）方面。值得注意的是，本文增强的开源模型大幅优于GPT-4o和Claude-3.5-Sonnet等专有系统。

**Conclusion:** 世界感知规划叙事增强（WAP）框架通过整合全面的环境理解，显著提升了大型视觉-语言模型（LVLMs）在复杂具身规划任务中的性能，使其能够超越现有的先进专有模型。

> **ai_Abstract:** 本文提出了一种名为世界感知规划叙事增强（WAP）的框架，旨在提升大型视觉-语言模型（LVLMs）在复杂具身规划任务中的表现。该框架通过注入视觉外观建模、空间推理、功能抽象和句法接地这四种认知能力，解决了现有LVLMs因环境无关学习而导致的上下文理解和视觉推理不足的问题。WAP利用课程学习，仅通过原始视觉观测数据进行模型开发和评估。在EB-ALFRED基准测试中，WAP展示了显著的性能提升，其中Qwen2.5-VL的任务成功率绝对提高了60.7%，特别是在常识推理和长时程规划方面表现突出。此外，增强后的开源模型甚至超越了GPT-4o和Claude-3.5-Sonnet等专有系统。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在具身规划任务中展现出潜力，但在涉及不熟悉环境和多步骤目标的复杂场景中表现不佳。当前的方法依赖于与环境无关的模仿学习，这使得指令与环境上下文脱节，导致模型难以处理上下文敏感的指令，并在长时间交互中过度依赖补充线索而非视觉推理。在这项工作中，我们提出了世界感知规划叙事增强（WAP），这是一个通过四种认知能力（视觉外观建模、空间推理、功能抽象和句法接地）为LVLMs注入全面环境理解的框架，同时仅通过课程学习使用原始视觉观测数据开发和评估模型。在EB-ALFRED基准测试上的评估显示出显著的改进，Qwen2.5-VL在任务成功率上实现了60.7的绝对提升，特别是在常识推理（+60.0）和长时程规划（+70.0）方面。值得注意的是，我们增强的开源模型大幅优于GPT-4o和Claude-3.5-Sonnet等专有系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [140] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
> *IXAII：一个用于决策支持系统的交互式可解释人工智能界面*

*Pauline Speckmann, Mario Nadj, Christian Janiesch* | **Category: cs.AI, cs.SE, K.6.3 Software Management**

**Keywords:** 可解释AI, 交互式界面, 决策支持系统, 透明度, 用户中心设计

**Comment:** 9 pages, 2 figures, accepted to DESRIST 2025 Prototype Track

> **TL;DR:** IXAII是一个交互式可解释人工智能系统，它整合了多种解释方法，为不同用户群体提供定制化的解释视图和内容控制，旨在提高AI决策支持系统的透明度。

**AI_Comments:** IXAII的创新之处在于其强调交互性和用户中心设计，通过整合多种解释方法并提供定制化视图，显著提升了可解释AI的实用性和用户接受度。它解决了传统XAI方法缺乏灵活性和用户参与度的问题，为AI决策支持系统的透明化提供了有力的工具。这项工作在人机交互和可解释AI的实际应用方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的事后可解释AI方法大多是静态的，并且忽视了用户视角，限制了它们对目标受众的有效性。

**Method:** 开发了一个名为IXAII的交互式可解释智能系统，该系统集成了LIME、SHAP、Anchors和DiCE四种可解释AI方法，为五种用户群体提供定制化视图，并允许用户控制解释内容和格式。通过专家和普通用户的访谈对IXAII进行了评估。

**Result:** 评估结果表明，IXAII通过提供具有多种可视化选项的不同解释，被认为有助于提高透明度。

**Conclusion:** 该研究通过弥合可解释AI方法、交互性和实际实现之间的差距，为AI解释实践和人机交互提供了新颖的视角。

> **ai_Abstract:** 本文介绍了一个名为IXAII的交互式可解释人工智能（XAI）系统，旨在解决现有XAI方法静态且忽视用户视角的问题。IXAII整合了LIME、SHAP、Anchors和DiCE等四种XAI方法，为五类用户提供定制化的解释视图，并赋予用户控制解释内容和格式的权力。通过对专家和普通用户的访谈评估，结果显示IXAII通过提供多样化的解释和可视化选项，有效提高了AI决策支持系统的透明度，为AI解释实践和人机交互带来了新的视角。

> **摘要翻译:** 尽管已经开发了几种事后可解释AI方法，但大多数都是静态的，并且忽视了用户视角，限制了它们对目标受众的有效性。为此，我们开发了一个名为IXAII的交互式可解释智能系统，它提供了来自LIME、SHAP、Anchors和DiCE四种可解释AI方法的解释。我们的原型为五种用户群体提供了定制化的视图，并赋予用户对解释内容和格式的自主权。我们通过对专家和普通用户的访谈评估了IXAII。我们的结果表明，IXAII通过提供具有多种可视化选项的不同解释，被认为有助于提高透明度。通过弥合可解释AI方法、交互性和实际实现之间的差距，我们为AI解释实践和人机交互提供了新颖的视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [157] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
> *科学发现的主动推理AI系统*

*Karthik Duraisamy* | **Category: cs.AI, physics.soc-ph, 68, I.2**

**Keywords:** 主动推理AI, 科学发现, 知识图谱, 因果模型, 人类判断

**Comment:** 

> **TL;DR:** 本文提出了一种主动推理AI系统架构，旨在通过弥合抽象、推理和现实差距，克服当前AI在科学发现中的局限性，并强调人类判断的不可或缺性。

**AI_Comments:** 本文提出了一种新颖的AI系统概念架构，旨在克服现有AI在科学发现中的核心局限。其创新之处在于将主动推理框架、因果模型、知识图谱与人机闭环交互深度融合，特别是强调了人类判断作为核心组件的重要性，而非临时工具。这为未来构建更强大、更可靠的科学发现AI系统提供了重要的理论指导和设计思路，但其具体实现和效果仍有待进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工智能系统在科学发现中受到其操作架构、脆弱的推理机制以及与实验现实脱节的根本限制。为了在AI驱动的科学领域取得进展，需要弥合抽象差距、推理差距和现实差距，而不是仅仅依赖模型大小、数据或测试时间计算。

**Method:** 本文定义了用于科学发现的主动推理AI系统，该系统具备以下特征：(i) 维护基于因果自监督基础模型的长期研究记忆；(ii) 配备贝叶斯护栏的符号或神经符号规划器；(iii) 发展持久的知识图谱，其中思考生成新的概念节点，推理建立因果边缘，并通过真实世界交互修剪错误连接并强化验证路径；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来完善其内部表征，形成一个操作循环，即心理模拟指导行动，经验惊喜重塑理解。本质上，该架构通过使能反事实推理的内部模型与将假设根植于现实的外部验证之间的相互作用来促进发现。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出了一种新的AI架构，旨在通过内部模型与外部验证的相互作用来实现科学发现，并强调由于模拟和实验反馈固有的模糊性以及潜在的不确定性，人类判断作为永久性架构组件是不可或缺的。

> **ai_Abstract:** 本文提出了一种主动推理AI系统架构，旨在弥补当前AI在科学发现中存在的抽象、推理和现实差距。该系统通过整合基于因果自监督模型的长期研究记忆、带有贝叶斯护栏的规划器、能够动态演化的知识图谱以及与模拟器和自动化实验室的闭环交互来运作。该架构强调内部模型进行反事实推理与外部验证相结合，以实现科学发现。此外，文章指出，由于反馈的模糊性和不确定性，人类判断在系统中扮演着不可或缺的永久性角色。

> **摘要翻译:** 人工智能的快速发展引发了对变革性科学发现的期待，然而当前的系统在操作架构、脆弱的推理机制以及与实验现实的分离方面仍存在根本性限制。在早期工作的基础上，我们认为AI驱动的科学进步现在取决于弥合三个基本差距——抽象差距、推理差距和现实差距——而不是依赖模型大小/数据/测试时间计算。科学推理需要支持行动和响应模拟的内部表征，区分相关性与机制的因果结构，以及持续校准。我们将用于科学发现的主动推理AI系统定义为：(i) 维护基于因果自监督基础模型的长期研究记忆；(ii) 配备贝叶斯护栏的符号或神经符号规划器；(iii) 发展持久的知识图谱，其中思考生成新的概念节点，推理建立因果边缘，真实世界交互修剪错误连接同时强化验证路径；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来完善其内部表征——这是一个操作循环，其中心理模拟指导行动，经验惊喜重塑理解。本质上，我们概述了一种架构，其中发现产生于使能反事实推理的内部模型与将假设根植于现实的外部验证之间的相互作用。文章还认为，模拟和实验反馈中固有的模糊性以及潜在的不确定性使得人类判断不可或缺，它不是一个临时支架，而是一个永久的架构组成部分。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [176] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
> *TableMoE：用于多模态表格理解中结构化专家推理的神经符号路由*

*Junwen Zhang, Pu Chen, Yin Zhang* | **Category: cs.AI, 68T07 (Primary), 68T50, 68T30, 68T45 (Secondary), F.2.2; I.2.7; I.2.10**

**Keywords:** 多模态表格理解, 神经符号路由, 专家混合, TableMoE, WildStruct

**Comment:** 43 pages and 11 figures

> **TL;DR:** TableMoE通过神经符号路由将表格元素动态路由到专业专家，显著提升了在复杂真实世界条件下对多模态表格的理解能力，并超越了现有SOTA模型。

**AI_Comments:** 本文的创新点在于提出了TableMoE架构，特别是其神经符号路由机制，能够根据语义角色动态路由表格元素到专门专家，这在处理复杂和视觉退化的真实世界表格数据方面具有重要意义。此外，构建大规模的TableMoE-Align数据集和四个挑战性的WildStruct基准测试也为该领域的研究提供了宝贵的资源。其重要性在于有效提升了多模态表格理解在“野外结构”条件下的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 在现实世界中，由于结构复杂性、符号密度和视觉退化（即WildStruct条件），对表格进行多模态理解极具挑战性。现有的多模态大型语言模型（MLLMs）在这种条件下表现不佳，导致性能受限和泛化能力差。

**Method:** 提出了TableMoE，这是一种神经符号专家连接器混合（MoCE）架构。它通过创新的神经符号路由机制，预测潜在的语义令牌角色（如表头、数据单元格），并利用符号推理图指导的置信度感知门控策略，将表格元素动态路由到专业专家（Table-to-HTML、Table-to-JSON、Table-to-Code）。为促进预训练，引入了大规模TableMoE-Align数据集（120万个表格-HTML-JSON-代码四元组）。为评估模型，策划并发布了四个挑战性的WildStruct基准测试：WMMFinQA、WMMTatQA、WMMTabDialog和WMMFinanceMath。

**Result:** TableMoE显著超越了现有最先进的模型。广泛的消融研究验证了其核心组件，强调了神经符号路由和结构化专家对齐的关键作用。定性分析展示了TableMoE的可解释性和增强的鲁棒性。

**Conclusion:** 集成神经符号推理对于多模态表格理解是有效的，TableMoE通过这种方法增强了模型的鲁棒性和可解释性。

> **ai_Abstract:** 本论文提出了TableMoE，一种神经符号专家连接器混合（MoCE）架构，旨在解决真实世界中复杂多模态表格理解的挑战。TableMoE引入创新的神经符号路由机制，根据预测的语义角色和符号推理图，将表格元素动态路由至专门专家。为支持模型训练和评估，论文还发布了大规模的TableMoE-Align数据集和四个全新的WildStruct基准测试。实验结果表明，TableMoE显著优于现有最先进的模型，验证了其神经符号推理集成在提升多模态表格理解能力方面的有效性。

> **摘要翻译:** 在现实世界中对表格进行多模态理解具有挑战性，这是由于其结构复杂性、符号密度和视觉退化（模糊、倾斜、水印、不完整的结构或字体、多跨度或分层嵌套布局）。现有的多模态大型语言模型（MLLMs）在处理此类野外结构（WildStruct）条件时表现不佳，导致性能有限和泛化能力差。为了解决这些挑战，我们提出了TableMoE，这是一种神经符号专家连接器混合（MoCE）架构，专门用于对多模态表格数据进行鲁棒的结构化推理。TableMoE具有创新的神经符号路由机制，该机制预测潜在的语义令牌角色（例如，标题、数据单元格、轴、公式），并利用由符号推理图指导的置信度感知门控策略，将表格元素动态路由到专业专家（Table-to-HTML、Table-to-JSON、Table-to-Code）。为了促进有效的对齐驱动预训练，我们引入了大规模的TableMoE-Align数据集，该数据集包含来自金融、科学、生物医学和工业领域的120万个表格-HTML-JSON-代码四元组，专门用于模型预训练。为了进行评估，我们整理并发布了四个具有挑战性的WildStruct基准测试：WMMFinQA、WMMTatQA、WMMTabDialog和WMMFinanceMath，这些基准测试专门设计用于在现实世界的多模态退化和结构复杂性下对模型进行压力测试。实验结果表明，TableMoE显著超越了现有最先进的模型。广泛的消融研究验证了每个核心组件，强调了神经符号路由和结构化专家对齐的关键作用。通过定性分析，我们进一步展示了TableMoE的可解释性和增强的鲁棒性，强调了集成神经符号推理对多模态表格理解的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [191] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
> *有限视角下的空间心理建模*

*Baiqiao Yin, Qineng Wang, Pingyue Zhang, Jianshu Zhang, Kangrui Wang, Zihan Wang, Jieyu Zhang, Keshigeyan Chandrasegaran, Han Liu, Ranjay Krishna, Saining Xie, Manling Li, Jiajun Wu, Li Fei-Fei* | **Category: cs.AI, cs.CL, cs.CV**

**Keywords:** 空间心理模型, 视觉语言模型, MindCube, 认知映射, 强化学习

**Comment:** Preprint version

> **TL;DR:** 本文引入了MindCube基准测试，揭示了视觉语言模型在构建空间心理模型方面的不足，并提出“先映射后推理”方法结合强化学习显著提升了模型理解不可见空间的能力。

**AI_Comments:** 这篇论文的创新点在于提出了一个全新的基准测试MindCube，有效揭示了现有VLMs在空间心理建模方面的不足。其提出的“先映射后推理”方法，特别是结合强化学习，为VLMs学习更高级的空间推理能力提供了有效途径。这对于推动VLM在复杂真实世界场景理解和交互方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉语言模型（VLMs）在仅通过有限视角来想象完整场景方面存在显著缺陷，无法像人类那样形成空间心理模型来推断布局、透视和运动。现有的VLMs在此类任务上表现接近随机水平，因此需要一个专门的基准来暴露并解决这一关键差距。

**Method:** 研究引入了MindCube基准测试（包含21,154个问题和3,268张图像），系统评估了VLMs在构建鲁棒空间心理模型方面的表现，包括表征位置（认知映射）、方向（透视采纳）和动态（心理模拟）。为弥补不足，研究探索了三种方法：未见过的中间视图、自然语言推理链和认知地图。最终采用了一种协同方法——“先映射后推理”（map-then-reason），该方法联合训练模型首先生成认知地图，然后在此基础上进行推理。此外，还引入了强化学习进一步提升性能。

**Result:** MindCube基准测试表明现有VLMs在此任务上表现接近随机。通过“先映射后推理”方法，模型准确率从37.8%显著提升至60.8%（提高了23.0%）。加入强化学习后，性能进一步提升至70.7%（总共提高了32.9%）。

**Conclusion:** 核心发现是，通过主动构建和利用内部结构化空间表征并结合灵活的推理过程来构建空间心理模型（即支架式方法），可以显著提高模型对不可观测空间的理解能力。

> **ai_Abstract:** 本文研究视觉语言模型（VLMs）在仅凭有限视角构建完整场景空间心理模型的能力。通过引入MindCube基准测试，作者发现现有VLMs在此任务上表现不佳。为解决此问题，论文提出并验证了多种方法，其中“先映射后推理”的协同方法，即先生成认知地图再进行推理，结合强化学习，显著提升了VLMs理解不可观测空间的能力，将准确率从37.8%提升至70.7%。研究强调了构建和利用内部结构化空间表征对空间理解的重要性。

> **摘要翻译:** 人类能否像视觉语言模型（VLMs）一样，仅凭少量视图就能想象出完整的场景？人类会形成空间心理模型，即对不可见空间的内部表征，以便推断布局、透视和运动。我们新的MindCube基准测试包含3,268张图像上的21,154个问题，揭示了这一关键差距，现有VLMs在此基准上表现接近随机。我们使用MindCube系统评估了VLMs在构建鲁棒空间心理模型方面的能力，包括表征位置（认知映射）、方向（透视采纳）和动态（“假设”运动的心理模拟）。然后，我们探索了三种方法来帮助VLMs近似空间心理模型，包括未见过的中间视图、自然语言推理链和认知地图。显著的改进来自于一种协同方法，“先映射后推理”，该方法联合训练模型首先生成认知地图，然后在此基础上进行推理。通过训练模型对这些内部地图进行推理，我们将准确率从37.8%提高到60.8%（+23.0%）。添加强化学习将性能进一步推高到70.7%（+32.9%）。我们的关键见解是，这种空间心理模型的支架式构建方式——主动构建和利用内部结构化空间表征与灵活的推理过程相结合，显著提高了对不可观测空间的理解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [219] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
> *Mind2Web 2：使用智能体作为评判者评估智能体搜索*

*Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su* | **Category: cs.AI, cs.CL**

**Keywords:** 智能体搜索, 评估基准, Agent-as-a-Judge, Mind2Web 2, 大型语言模型

**Comment:** Project Homepage: https://osu-nlp-group.github.io/Mind2Web2/

> **TL;DR:** Mind2Web 2是一个新的基准，用于评估复杂的智能体搜索系统，并引入了“智能体作为评判者”框架来自动评估答案。

**AI_Comments:** 本文通过引入Mind2Web 2基准和“智能体作为评判者”评估框架，解决了智能体搜索系统评估中的关键挑战，即现有方法无法应对其复杂性和开放性。其创新之处在于构建了大规模、真实场景的任务集以及自动化的评估机制，这对于推动该领域的发展至关重要。研究结果也提供了关于当前系统性能的宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的评估基准和方法已无法满足日益复杂的智能体搜索系统的评估需求，这些系统需要长时间的搜索和信息综合。

**Method:** 论文引入了Mind2Web 2，一个包含130个真实、高质量、长周期任务的基准，需要实时网页浏览和大量信息综合。同时，提出了“智能体作为评判者”框架，该框架基于树状评分标准设计，构建任务特定的评判智能体，以自动评估答案的正确性和来源归属。

**Result:** 对九个前沿智能体搜索系统和人类表现进行了全面评估。最佳系统OpenAI Deep Research在花费一半时间的情况下，能达到人类表现的50-70%。

**Conclusion:** Mind2Web 2为开发和评估下一代智能体搜索系统提供了严谨的基础，并展示了当前智能体搜索系统的巨大潜力。

> **ai_Abstract:** 本文介绍了Mind2Web 2，一个用于评估复杂智能体搜索系统的新基准，包含130个需要实时网页浏览和信息综合的长周期任务。为解决评估挑战，论文提出了“智能体作为评判者”框架，通过构建任务特定评判智能体自动评估答案的正确性和来源归属。研究评估了九个前沿系统，发现最佳系统能达到人类表现的50-70%，表明智能体搜索潜力巨大，Mind2Web 2为未来研究奠定基础。

> **摘要翻译:** 智能体搜索系统，如深度研究系统，其中大型语言模型自主浏览网页、综合信息并返回带有全面引用的答案，代表着用户与网络规模信息交互方式的重大转变。尽管智能体搜索有望提高效率和认知卸载，但其日益增长的复杂性和开放性已超越了现有的评估基准和方法，这些基准和方法主要假设搜索范围短且答案是静态的。在本文中，我们引入了Mind2Web 2，这是一个包含130个真实、高质量、长周期任务的基准，需要实时网页浏览和大量信息综合，耗费了超过1000小时的人工劳动构建而成。为了解决评估时变和复杂答案的挑战，我们提出了一种新颖的“智能体作为评判者”框架。我们的方法基于树状评分标准设计构建任务特定的评判智能体，以自动评估答案的正确性和来源归属。我们对九个前沿智能体搜索系统和人类表现进行了全面评估，并进行了详细的错误分析，为未来的发展提供了见解。表现最佳的系统OpenAI Deep Research已经可以在花费一半时间的情况下达到人类表现的50-70%，显示出巨大的潜力。总而言之，Mind2Web 2为开发和评估下一代智能体搜索系统提供了严谨的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [231] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
> *PsyLite 技术报告*

*Fangjun Ding, Renyu Zhang, Xinyu Feng, Chengye Xie, Zheng Zhang, Yanting Zhang* | **Category: cs.AI, cs.HC**

**Keywords:** 心理咨询, 大语言模型, 轻量化部署, 对话安全, 条件RAG

**Comment:** 

> **TL;DR:** 针对现有AI心理咨询模型在安全性、场景处理和轻量化部署方面的不足，本研究提出了PsyLite，一个基于InternLM2.5-7B-chat的轻量级心理咨询大语言模型，通过两阶段训练和创新性条件RAG，显著提升了专业性和安全性，并实现低内存部署。

**AI_Comments:** 该论文提出了一种创新的轻量级心理咨询大语言模型PsyLite，其亮点在于结合了两阶段训练策略和条件RAG机制，不仅提升了模型的专业性和安全性，还通过引入幽默元素增强了用户体验。更重要的是，它实现了极低的硬件部署要求，解决了资源受限环境下的实际应用难题，具有重要的实用价值和推广潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI驱动的心理咨询模型在对话安全、详细场景处理和轻量化部署方面存在不足。

**Method:** 本研究提出了PsyLite，一个基于InternLM2.5-7B-chat的轻量级心理咨询大语言模型代理。它采用两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化）来增强模型的深度推理、心理咨询和安全对话能力。部署时使用Ollama和Open WebUI，并通过Pipelines创建自定义工作流。此外，设计了一种创新的条件RAG机制，在心理咨询中适时引入相声幽默元素以提升用户体验，并拒绝危险请求以加强对话安全。模型还使用量化技术（GGUF q4_k_m）实现低硬件部署。

**Result:** PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中均优于基线模型。尤其在心理咨询专业性方面（CPsyCounE得分提高47.6%）和对话安全方面（安全得分提高2.4%）表现突出。模型通过量化技术仅需5GB内存即可运行，实现了低硬件部署。

**Conclusion:** PsyLite为资源受限环境下的心理咨询应用提供了一个可行的解决方案，显著提升了AI心理咨询模型的专业性和安全性，同时实现了轻量化部署。

> **ai_Abstract:** 本技术报告介绍了PsyLite，一个基于InternLM2.5-7B-chat的轻量级AI心理咨询大语言模型。针对现有模型在对话安全、场景处理和部署上的不足，PsyLite通过两阶段训练（混合蒸馏微调和ORPO优化）提升了推理、咨询和安全对话能力。其创新的条件RAG机制能适时引入幽默元素并拒绝不安全请求。评估显示，PsyLite在中文通用、心理咨询专业性和对话安全评估中均表现优异，尤其在专业性上提升显著。通过量化技术，该模型仅需5GB内存即可运行，为资源受限环境下的心理咨询应用提供了高效可行的方案。

> **摘要翻译:** 随着数字技术的快速发展，AI驱动的心理咨询已逐渐成为心理健康领域的重要研究方向。然而，现有模型在对话安全、详细场景处理和轻量化部署方面仍存在不足。为解决这些问题，本研究提出了PsyLite，一个基于InternLM2.5-7B-chat基础模型开发的轻量级心理咨询大语言模型代理。通过两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），PsyLite增强了模型的深度推理能力、心理咨询能力和安全对话能力。部署时使用Ollama和Open WebUI，并使用Pipelines创建自定义工作流。创新性地设计了条件RAG机制，在心理咨询过程中适时引入相声幽默元素以提升用户体验，并拒绝危险请求以加强对话安全。评估结果表明，PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中均优于基线模型，尤其在心理咨询专业性（CPsyCounE得分提高47.6%）和对话安全（安全得分提高2.4%）方面表现突出。此外，该模型采用量化技术（GGUF q4_k_m）实现了低硬件部署（5GB内存即可运行），为资源受限环境下的心理咨询应用提供了可行的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [18] [Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems](https://arxiv.org/abs/2506.20685)
> *渐进式尺寸自适应联邦学习：异构多模态数据系统的综合框架*

*Sajid Hussain, Muhammad Sohail, Nauman Ali Khan, Naima Iltaf, Ihtesham ul Islam* | **Category: cs.LG, cs.AI**

**Keywords:** 联邦学习, 数据集大小, 多模态数据, 尺寸自适应, 异构系统

**Comment:** 

> **TL;DR:** 本文提出了SAFL，一个渐进式训练框架，根据数据集大小组织联邦学习，并在13个数据集上展示了数据大小和模态对联邦学习性能的关键影响，SAFL在准确性、通信效率和资源利用方面表现出色。

**AI_Comments:** 该论文的创新点在于首次系统性地探究了数据集大小和模态对联邦学习性能的影响，并提出了尺寸自适应联邦学习（SAFL）框架来优化训练过程。其重要性体现在填补了联邦学习领域对数据特性驱动策略的理解空白，并为实际部署提供了具体的数据大小和模态选择指导。SAFL在多模态数据上的广泛验证及其在通信效率和性能上的提升，使其成为联邦学习发展中的一个重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦学习方法主要关注模型异构性和聚合技术，但忽视了数据集大小特性对联邦训练动态的根本影响，这导致了理解数据特性如何驱动联邦学习策略方面的关键空白。

**Method:** 本文提出了尺寸自适应联邦学习（SAFL），一个新颖的渐进式训练框架，系统地根据异构多模态数据的数据集大小特性来组织联邦学习。该框架通过对13个不同数据集（涵盖7种模态）进行全面实验评估。

**Result:** 1. 联邦学习有效性的最佳数据集大小范围为1000-1500个样本。
2. 存在明显的模态性能等级：结构化数据（时间序列、传感器）显著优于非结构化数据（文本、多模态）。
3. 超过2000个样本的大数据集性能系统性下降。
4. SAFL在所有数据集上平均准确率达到87.68%，结构化数据模态达到99%+准确率。
5. 框架展现出卓越的通信效率，在558次通信中将总数据传输量减少到7.38 GB。
6. 实时监控框架提供了对系统资源利用、网络效率和训练动态的深入洞察。

**Conclusion:** 本研究填补了理解数据特性如何驱动联邦学习策略方面的关键空白，为真实世界的联邦学习部署提供了理论见解和实践指导。

> **ai_Abstract:** 本文提出了尺寸自适应联邦学习（SAFL），一个新颖的渐进式训练框架，旨在解决现有联邦学习方法忽视数据集大小影响的问题。SAFL根据数据集大小特性组织联邦学习，并在13个多模态数据集上进行了全面评估。研究发现，联邦学习的最佳数据集大小范围为1000-1500样本，结构化数据性能优于非结构化数据，且大数据集性能会下降。SAFL在准确性、通信效率和资源监控方面表现出色，为理解数据特性如何影响联邦学习策略提供了理论和实践指导。

> **摘要翻译:** 联邦学习（FL）已成为一种在保留数据隐私的同时实现分布式机器学习的变革性范式。然而，现有方法主要侧重于模型异构性和聚合技术，在很大程度上忽视了数据集大小特性对联邦训练动态的根本影响。本文引入了基于大小的自适应联邦学习（SAFL），这是一种新颖的渐进式训练框架，它根据异构多模态数据的数据集大小特性系统地组织联邦学习。我们对涵盖7种模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）的13个不同数据集进行的全面实验评估揭示了关键见解：1）联邦学习有效性的最佳数据集大小范围为1000-1500个样本；2）存在明显的模态性能等级，结构化数据（时间序列、传感器）显著优于非结构化数据（文本、多模态）；3）超过2000个样本的大数据集性能系统性下降。SAFL在所有数据集上的平均准确率达到87.68%，其中结构化数据模态达到99%+的准确率。该框架展示了卓越的通信效率，在558次通信中将总数据传输量减少到7.38 GB，同时保持了高性能。我们的实时监控框架提供了对系统资源利用、网络效率和训练动态前所未有的洞察。这项工作填补了理解数据特性如何驱动联邦学习策略方面的关键空白，为神经网络和学习系统中的真实世界联邦学习部署提供了理论见解和实践指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [33] [E-ABIN: an Explainable module for Anomaly detection in BIological Networks](https://arxiv.org/abs/2506.20693)
> *E-ABIN：一种用于生物网络异常检测的可解释模块*

*Ugo Lomoio, Tommaso Mazza, Pierangelo Veltri, Pietro Hiram Guzzi* | **Category: cs.LG**

**Keywords:** 异常检测, 生物网络, 可解释性, 机器学习, 深度学习

**Comment:** 

> **TL;DR:** E-ABIN是一个可解释的框架，结合了传统机器学习和图深度学习技术，用于在基因表达或甲基化网络中检测和解释异常，并通过膀胱癌和乳糜泻案例研究验证了其有效性。

**AI_Comments:** E-ABIN的创新之处在于其结合了传统机器学习和图深度学习的混合方法，并特别强调了结果的可解释性，这在复杂的生物网络分析中至关重要。其用户友好的平台设计也降低了使用门槛。该框架通过整合多种算法，旨在实现高预测准确性和可解释性的平衡，这对于生物医学研究具有重要意义，有助于推动对疾病机制的理解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的组学数据分析框架需要更强的可解释性。当前基因异常检测方法通常仅限于单一数据集，且缺乏易于访问的图形界面，限制了其应用范围和用户友好性。

**Method:** 本文介绍了E-ABIN，一个通用、可解释的生物网络异常检测框架。E-ABIN在一个统一、用户友好的平台中结合了经典机器学习（如支持向量机、随机森林）和基于图的深度学习技术（如图自编码器、图对抗属性网络），能够从基因表达或甲基化衍生的网络中检测和解释异常。

**Result:** E-ABIN在膀胱癌和乳糜泻的案例研究中展示了其效用，有效地揭示了生物学相关的异常，并为疾病机制提供了见解。该框架在保持可解释性的同时，确保了高预测准确性。

**Conclusion:** E-ABIN提供了一个通用、可解释的框架，能够有效地从生物网络中检测并解释异常，为疾病机制研究提供了新的工具和见解，解决了当前方法在可解释性和用户界面方面的局限性。

> **ai_Abstract:** E-ABIN是一个新颖的、可解释的生物网络异常检测框架，旨在解决现有方法在处理大规模组学数据时可解释性和用户界面的不足。它整合了传统机器学习和图深度学习算法（如SVM、RF、GAEs、GAANs），在一个用户友好的平台中实现对基因表达或甲基化网络中异常的检测与解释。该框架在膀胱癌和乳糜泻的案例研究中被证明能够准确识别生物学相关异常，并提供疾病机制的深入见解。

> **摘要翻译:** 随着大规模组学数据可用性的增加，需要强大的分析框架来处理复杂的基因表达数据集，同时提供可解释的结果。人工智能的最新进展使得识别区分疾病状态与健康对照的异常分子模式成为可能。结合模型可解释性的改进，这些工具现在支持识别可能驱动疾病表型的基因。然而，当前的基因异常检测方法往往仅限于单一数据集，并且缺乏易于访问的图形界面。在此，我们引入了E-ABIN，一个用于生物网络异常检测的通用、可解释框架。E-ABIN在一个统一、用户友好的平台中结合了经典机器学习和基于图的深度学习技术，能够检测和解释来自基因表达或甲基化衍生网络的异常。通过整合支持向量机、随机森林、图自编码器（GAEs）和图对抗属性网络（GAANs）等算法，E-ABIN在保持可解释性的同时，确保了高预测准确性。我们通过膀胱癌和乳糜泻的案例研究展示了E-ABIN的实用性，它有效地揭示了生物学相关的异常，并为疾病机制提供了见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [57] [On Context-Content Uncertainty Principle](https://arxiv.org/abs/2506.20699)
> *关于上下文-内容不确定性原理*

*Xin Li* | **Category: cs.LG**

**Keywords:** 上下文-内容不确定性原理, 熵不对称性, 推断, 计算框架, 不确定性最小化

**Comment:** 

> **TL;DR:** 上下文-内容不确定性原理（CCUP）提出，不确定性下的推断受上下文与内容之间的熵不对称性支配。本文开发了一个分层计算框架，从这一不对称性中推导出操作原则，为大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了统一的理论基础。

**AI_Comments:** 本文提出了一个新颖的理论框架——CCUP，为生物和人工智能中的不确定性最小化提供了一个统一的视角。其创新之处在于从一个基本的熵不对称性中推导出具体的、分层的操作原则，为理解复杂的认知过程提供了一种结构化的方法。其中“方向性熵最小化”的概念以及所识别的层级原则尤为创新，可能为未来设计更高效、更具类脑特性的AI系统提供指导。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是基于上下文-内容不确定性原理（CCUP），该原理认为不确定性下的推断受上下文和内容之间熵不对称性的支配，即高熵上下文必须通过与低熵、结构化内容的对齐来解释。研究旨在开发一个分层计算框架，从这一基本不对称性中推导出操作原则，并为大脑和机器如何最小化不确定性提供统一的理论基础。

**Method:** 本文开发了一个分层计算框架，该框架源自上下文-内容不确定性原理（CCUP）。它将推断形式化为方向性熵最小化，建立了一个有利于内容优先结构化的变分梯度。在此基础上，研究确定了四个操作原则的层次结构层：核心推断约束（L1）、资源分配原则（L2）、时间自举动力学（L3）和空间分层组合（L4）。

**Result:** 本文提出了形式等价定理，展示了原则之间的依赖关系格，并通过计算模拟证明了与CCUP对齐的推断具有效率增益。这项工作为理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了一个统一的理论基础。

**Conclusion:** 这项工作为理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了一个统一的理论基础。它将大脑重新定义为一个循环一致的熵梯度解析器，通过路径依赖的、内容引导的模拟来对齐结构和特异性。

> **ai_Abstract:** 本文引入了上下文-内容不确定性原理（CCUP），该原理认为不确定性下的推断依赖于熵不对称性，即高熵上下文需与低熵、结构化内容对齐。作者开发了一个分层计算框架，将推断形式化为方向性熵最小化。他们从CCUP中推导并确定了四个层次的操作原则：核心推断约束、资源分配原则、时间自举动力学和空间分层组合。该工作提出了形式定理和模拟结果，证明了效率增益，为大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了统一的理论基础。

> **摘要翻译:** 上下文-内容不确定性原理（CCUP）提出，不确定性下的推断受制于上下文与内容之间的熵不对称性：高熵的上下文必须通过与低熵、结构化内容的对齐来解释。在本文中，我们开发了一个分层计算框架，从这一基本不对称性中推导出操作原则。在基础层面，CCUP 将推断形式化为方向性熵最小化，建立了一个有利于内容优先结构化的变分梯度。在此基础上，我们确定了四个操作原则的层次结构层：（L1）核心推断约束，包括结构优先于特异性、非对称推断流、循环一致性自举和条件压缩，所有这些都被证明可以相互归约；（L2）资源分配原则，例如精度加权注意力、非对称学习率和基于吸引子的记忆编码；（L3）时间自举动力学，通过结构引导的课程组织随时间的学习；以及（L4）空间分层组合，它将这些机制整合到记忆、推断和规划的自组织循环中。我们提出了形式等价定理、原则之间的依赖关系格以及计算模拟，展示了与CCUP对齐的推断的效率增益。这项工作为理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了统一的理论基础。大脑不仅仅是一个推断机器。它是一个循环一致的熵梯度解析器，通过路径依赖的、内容引导的模拟来对齐结构和特异性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [76] [A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools](https://arxiv.org/abs/2506.20743)
> *材料科学中的人工智能综述：基础模型、LLM智能体、数据集和工具*

*Minh-Hao Van, Prateek Verma, Chen Zhao, Xintao Wu* | **Category: cs.LG, cs.CE**

**Keywords:** 基础模型, 材料科学, 人工智能, LLM智能体, 综述

**Comment:** 

> **TL;DR:** 这篇综述全面概述了基础模型（FMs）如何通过其通用性和新兴能力，在材料科学（MatSci）中实现可扩展、通用和多模态的人工智能系统，并讨论了其应用、挑战和未来方向。

**AI_Comments:** 这篇综述非常及时且全面，它系统地梳理了基础模型在材料科学领域的应用现状、挑战和未来趋势。其提出的任务驱动分类法有助于理解FMs的广泛适用性。同时，文章不仅关注了技术进展，还强调了数据治理和可信度等重要非技术因素，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型（FMs）正在推动材料科学的变革，实现可扩展、通用和多模态的AI系统，以加速科学发现。与传统机器学习模型不同，FMs具有跨领域泛化和新兴能力，特别适用于材料科学中多样化的数据类型和尺度的挑战。因此，需要一份全面的综述来概述这一领域的发展。

**Method:** 这篇综述提供了一个全面的概述，涵盖基础模型、智能体系统、数据集和支持该领域的计算工具。它引入了一个任务驱动的分类法，包括六个广泛的应用领域：数据提取、解释和问答；原子模拟；属性预测；材料结构、设计和发现；过程规划、发现和优化；以及多尺度建模。它讨论了单模态和多模态FMs以及新兴LLM智能体的最新进展，并审查了标准化数据集、开源工具和自主实验平台。

**Result:** 综述评估了基础模型的早期成功，并指出了持续存在的局限性，包括泛化性、可解释性、数据不平衡、安全问题和有限的多模态融合方面的挑战。

**Conclusion:** 综述最后阐述了未来的研究方向，重点是可扩展的预训练、持续学习、数据治理和可信度。

> **ai_Abstract:** 这篇综述探讨了基础模型（FMs）如何通过其通用性和新兴能力变革材料科学。它全面概述了FMs、LLM智能体、数据集和工具在材料科学中的应用，并提出了一个任务驱动的分类法，涵盖六个主要应用领域。文章讨论了FMs的最新进展，审查了相关资源，评估了其早期成功，并指出了泛化性、可解释性、数据不平衡等局限性。最后，它提出了可扩展预训练、持续学习、数据治理和可信度等未来研究方向。

> **摘要翻译:** 基础模型（FMs）正在通过实现可扩展、通用和多模态的人工智能系统，为科学发现催化材料科学（MatSci）的变革性转变。与通常范围狭窄且需要针对特定任务进行工程设计的传统机器学习模型不同，FMs提供跨领域泛化并展现出涌现能力。它们的通用性特别适合材料科学，因为材料科学的研究挑战涵盖多样的数据类型和尺度。本综述全面概述了支持这一不断发展领域的基础模型、智能体系统、数据集和计算工具。我们引入了一个任务驱动的分类法，涵盖六个广泛的应用领域：数据提取、解释和问答；原子模拟；属性预测；材料结构、设计和发现；过程规划、发现和优化；以及多尺度建模。我们讨论了单模态和多模态FMs的最新进展，以及新兴的大型语言模型（LLM）智能体。此外，我们审查了标准化数据集、开源工具和自主实验平台，它们共同推动了FMs在研究工作流程中的开发和整合。我们评估了基础模型的早期成功，并指出了持续存在的局限性，包括泛化性、可解释性、数据不平衡、安全问题和有限的多模态融合方面的挑战。最后，我们阐明了以可扩展预训练、持续学习、数据治理和可信度为中心的未来研究方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [80] [Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models](https://arxiv.org/abs/2506.20701)
> *扩散树采样：扩散模型可扩展的推理时对齐*

*Vineet Jain, Kusha Sareen, Mohammad Pedramfar, Siamak Ravanbakhsh* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 扩散模型, 推理时对齐, 树采样, 计算效率, 生成模型

**Comment:** 

> **TL;DR:** 本文提出了一种名为扩散树采样（DTS）的新方法，通过将推理时对齐视为一个搜索问题并重用过去的计算，解决了现有扩散模型推理时自适应方法的局限性。DTS在计算效率显著提高的情况下，实现了与现有最佳方法相当或更好的性能。

**AI_Comments:** 本文创新性地将蒙特卡洛树搜索的思想引入到扩散模型的推理时对齐问题中，通过构建决策树和重用计算，有效解决了现有方法在价值估计不准确和计算效率低下的问题。其“随时可用”的特性和显著的计算效率提升（高达10倍）是其重要贡献，为扩散模型在实际应用中的部署提供了更具扩展性的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 预训练扩散模型在推理时适应新目标仍是一个开放问题。现有引导方法在噪声水平较高时存在不准确的价值估计，导致偏差。此外，它们不重用过去运行的信息来提高样本质量，导致计算效率低下。

**Method:** 受蒙特卡洛树搜索的启发，本文将推理时对齐问题转化为一个搜索问题，并重用过去的计算。提出了一种基于树的方法，通过将最终奖励反向传播回扩散链，并随着每次额外生成迭代地细化价值估计，从奖励对齐的目标密度中采样。所提出的方法包括扩散树采样（DTS）和其贪婪变体扩散树搜索（DTS*）。

**Result:** 在MNIST和CIFAR-10类条件生成任务中，DTS以高达10倍的计算量减少匹配了最佳基线的FID。在文本到图像生成和语言补全任务中，DTS*有效地搜索高奖励样本，以高达5倍的计算量减少匹配了best-of-N的结果。通过重用前几代的信息，该算法可以随时将额外的计算转化为持续改进的样本。

**Conclusion:** 扩散树采样（DTS）提供了一种可扩展的扩散模型推理时对齐方法。通过将推理时对齐视为一个搜索问题并重用过去计算，DTS解决了现有方法的局限性，实现了计算效率的显著提升，同时保持了样本质量，甚至在某些任务上表现更优。

> **ai_Abstract:** 本文提出了一种新颖的扩散树采样（DTS）方法，用于解决预训练扩散模型在推理时自适应新目标的挑战。现有方法面临价值估计不准确和计算效率低下的问题。受蒙特卡洛树搜索的启发，DTS将推理时对齐问题重新定义为一种搜索，通过树状结构重用过去的计算，并迭代优化价值估计。DTS在理论上能产生渐近精确的样本，其贪婪变体DTS*则专注于寻找高奖励样本。实验证明，DTS在图像生成任务中能以显著更少的计算量（高达10倍）达到与最佳基线相当的性能，而在文本到图像和语言补全任务中，DTS*也能以高达5倍的计算量减少匹配最佳结果。该方法通过重用信息，实现了可伸缩且计算高效的扩散模型推理时对齐。

> **摘要翻译:** 将预训练的扩散模型在推理时适应新的目标仍然是生成建模中的一个开放问题。现有的引导方法存在价值估计不准确的问题，尤其是在高噪声水平下，这会导致引导偏差。此外，过去运行的信息没有被重用来提高样本质量，导致计算使用效率低下。受蒙特卡洛树搜索成功的启发，我们通过将推理时对齐视为一个重用过去计算的搜索问题来解决这些限制。我们引入了一种基于树的方法，通过将最终奖励反向传播回扩散链，并随着每次额外生成迭代地细化价值估计，从奖励对齐的目标密度中采样。我们提出的方法，扩散树采样（DTS），在无限次展开的极限下，可以从目标分布中产生渐近精确的样本，其贪婪变体，扩散树搜索（DTS*），则执行全局搜索以寻找高奖励样本。在MNIST和CIFAR-10类条件生成任务中，DTS以高达10倍的计算量减少匹配了表现最佳基线的FID。在文本到图像生成和语言补全任务中，DTS*有效地搜索高奖励样本，以高达5倍的计算量减少匹配了best-of-N的结果。通过重用前几代的信息，我们获得了一个随时可用的算法，可以将额外的计算转化为持续更好的样本，为扩散模型的推理时对齐提供了一种可扩展的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [103] [On Convolutions, Intrinsic Dimension, and Diffusion Models](https://arxiv.org/abs/2506.20705)
> *关于卷积、内蕴维度和扩散模型*

*Kin Kwan Leung, Rasa Hosseinzadeh, Gabriel Loaiza-Ganem* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 扩散模型, 局部内蕴维度, FLIPD, 卷积, 流形假设

**Comment:** 

> **TL;DR:** 本文在现实假设下正式证明了扩散模型中局部内蕴维度（LID）估计器FLIPD的正确性，并探讨了均匀卷积的类似结果。

**AI_Comments:** 这项工作的重要创新在于它解决了LID估计器FLIPD在理论证明上的一个关键限制，即将其正确性扩展到更现实的非仿射子流形情况。这极大地增强了FLIPD的适用性和可信度，对于利用LID进行数据复杂性量化、异常检测和AI生成内容识别等应用具有重要意义。同时，对均匀卷积的探讨也拓宽了对扩散模型中卷积操作与内蕴维度关系的理解。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型中的局部内蕴维度（LID）估计器FLIPD虽然性能卓越，但其理论基础不完整，此前仅在高度不现实的仿射子流形假设下证明了其正确性，这限制了其理论严谨性和实际应用范围。

**Method:** 本文通过形式化证明，在现实假设下验证了FLIPD的正确性。此外，研究还表明当高斯卷积被均匀卷积替换时，一个类似的结论仍然成立。

**Result:** 1. 在现实假设下正式证明了LID估计器FLIPD的正确性。2. 证明了当高斯卷积被均匀卷积替换时，一个类似的LID估计结论也成立。

**Conclusion:** 本文弥补了局部内蕴维度（LID）估计器FLIPD在理论基础上的不足，为其在更广泛的应用中提供了坚实的理论支撑，并扩展了卷积类型对LID估计影响的理解。

> **ai_Abstract:** 本文弥补了扩散模型中局部内蕴维度（LID）估计器FLIPD的理论空白。此前的研究仅在非现实的仿射子流形假设下证明了FLIPD的正确性。本研究在现实假设下正式证明了FLIPD的正确性，并进一步展示了当高斯卷积被均匀卷积替换时，一个类似的LID估计结果依然成立。这些发现为FLIPD的广泛应用提供了更坚实的理论基础。

> **摘要翻译:** 高维环境空间（如图像数据）中的数据位于未知的低维子流形上，这是流形假设的核心。扩散模型（DM）——通过将数据与逐渐增大的高斯噪声进行卷积，然后学习逆转这个过程——已成为性能最优的生成模型，并已知能够学习具有低维支持的分布。因此，对于这些子流形中的给定数据，我们应该直观地期望DM能够隐式地学习到其对应的局部内蕴维度（LID），即其所属子流形的维度。Kamkari 等人（2024b）最近通过将LID与DM的对数边际密度随添加噪声量的变化率联系起来，证明了确实如此，从而产生了一个名为FLIPD的LID估计器。FLIPD 等LID估计器用途广泛，它们可以量化给定数据的复杂性，并可用于检测异常值、对抗性样本和AI生成文本。FLIPD 在LID估计方面取得了最先进的性能，但其理论基础不完整，因为Kamkari 等人（2024b）仅在高度不现实的仿射子流形假设下证明了其正确性。在这项工作中，我们通过在现实假设下正式证明FLIPD的正确性来弥补这一空白。此外，我们还表明，当高斯卷积被均匀卷积替换时，一个类似的结论仍然成立，并讨论了这一结果的相关性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [104] [Optimal Single-Policy Sample Complexity and Transient Coverage for Average-Reward Offline RL](https://arxiv.org/abs/2506.20904)
> *平均奖励离线强化学习中的最优单策略样本复杂度和瞬态覆盖*

*Matthew Zurek, Guy Zamir, Yudong Chen* | **Category: cs.LG, cs.IT, math.IT, math.OC, stat.ML**

**Keywords:** 离线强化学习, 平均奖励MDPs, 样本复杂度, 单策略, 弱通信MDPs

**Comment:** 

> **TL;DR:** 该论文首次为平均奖励离线强化学习提供了完全单策略样本复杂度边界，并处理了一般弱通信MDPs，提出了一种新的具有尖锐保证的算法。

**AI_Comments:** 这篇论文在离线强化学习领域做出了重要的理论贡献，首次为平均奖励MDPs提供了单策略样本复杂度边界，这是一个较少探索的领域。引入目标策略特定的复杂性度量（偏差跨度、策略命中半径）是创新之处，超越了限制性的统一假设。该算法能够处理一般弱通信MDPs且无需参数知识，具有实际优势。研究发现单策略学习需要超出平稳分布的覆盖假设，这挑战了现有的一些假设。

<details>
  <summary>Details</summary>

**Motivation:** 平均奖励MDPs中的离线强化学习在分布偏移和非均匀覆盖方面具有挑战性，且理论研究不足。现有工作依赖于统一的复杂性度量（如统一混合时间），而非针对特定策略。本文旨在开发仅依赖于目标策略的更尖锐的保证，并处理一般弱通信MDPs。

**Method:** 作者提出了一种基于悲观折扣值迭代的算法，该算法通过新颖的分位数裁剪技术得到增强，从而能够使用更尖锐的基于经验跨度的惩罚函数。该算法无需任何先验参数知识。

**Result:** 本文首次获得了平均奖励离线RL的完全单策略样本复杂度边界。它也是第一个处理一般弱通信MDPs的研究。通过困难示例，作者表明在他们的条件下学习需要超出目标策略的平稳分布的覆盖假设。他们还开发了几乎与主要结果匹配的下限。

**Conclusion:** 本文首次建立了平均奖励离线强化学习的完全单策略样本复杂度边界，证明了单策略复杂性度量需要超出平稳分布的特定覆盖假设，并提供了一种有效的算法。

> **ai_Abstract:** 本文旨在解决平均奖励离线强化学习中理论研究不足的问题，该领域存在分布偏移和非均匀覆盖的挑战。文章首次提出了针对平均奖励离线RL的完全单策略样本复杂度边界，其保证仅依赖于目标策略特定的度量（如偏差跨度和新颖的策略命中半径），而非统一复杂性度量。该工作还首次处理了一般弱通信MDPs。为此，作者提出了一种基于悲观折扣值迭代并结合分位数裁剪技术的新算法，该算法无需先验参数知识且使用了更尖锐的惩罚函数。研究表明，单策略学习需要超出目标策略平稳分布的覆盖假设，并提供了匹配的下限。

> **摘要翻译:** 我们研究平均奖励MDPs中的离线强化学习，这在分布偏移和非均匀覆盖方面带来了更大的挑战，并且从理论角度来看相对未被充分研究。虽然之前的工作在单策略数据覆盖假设下获得了性能保证，但这些保证利用了对所有策略统一的额外复杂性度量，例如统一混合时间。我们开发了仅依赖于目标策略的尖锐保证，特别是偏差跨度和一种新颖的策略命中半径，从而首次获得了平均奖励离线RL的完全单策略样本复杂度边界。我们也是第一个处理一般弱通信MDPs的研究，这与先前工作中做出的限制性结构假设形成对比。为了实现这一点，我们引入了一种基于悲观折扣值迭代的算法，该算法通过一种新颖的分位数裁剪技术得到增强，从而能够使用更尖锐的基于经验跨度的惩罚函数。我们的算法也不需要任何先验参数知识即可实现。值得注意的是，我们通过困难示例表明，在我们的条件下学习需要超出目标策略的平稳分布的覆盖假设，从而将单策略复杂性度量与先前研究的案例区分开来。我们还开发了几乎与我们主要结果匹配的下限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [124] [Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset](https://arxiv.org/abs/2506.20729)
> *理论物理中的测试时缩放技术——TPBench数据集上的方法比较*

*Zhiqi Gao, Tianyi Li, Yurii Kvasiuk, Sai Chaitanya Tadepalli, Maja Rudolph, Daniel J. H. Chung, Frederic Sala, Moritz Münchmeyer* | **Category: cs.LG, astro-ph.CO, cs.AI, hep-ph, hep-th**

**Keywords:** 测试时缩放, 大型语言模型, 理论物理, 符号验证, TPBench

**Comment:** 23 pages, 6 figures

> **TL;DR:** 本文研究了大型语言模型（LLMs）在理论物理问题上的测试时缩放技术，并在TPBench数据集上比较了现有方法。论文引入了一种新颖的符号弱验证器框架，该框架在TPBench上显著优于现有方法，并在数学问题（AIME）上也表现出有效性。

**AI_Comments:** 本文的创新之处在于将通常用于数学推理的测试时缩放技术应用于理论物理领域，并引入了一种专门针对物理问题结构的新型符号弱验证器框架。该框架在TPBench上显著优于现有方法，并在AIME上同样表现出色，这表明其具有广泛的适用性和提升LLM在科学领域推理能力的重要性。对“分步符号验证”的关注是其关键洞察。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在复杂推理方面表现出色，而测试时缩放技术能以较低成本提升其性能。许多此类方法已在数学推理基准（如AIME）上开发和评估。本文旨在探究这些经验是否能推广到高级理论物理领域，并提升LLMs在该领域的表现。

**Method:** 论文在TPBench物理数据集上评估了一系列常见的测试时缩放方法，并将其有效性与AIME上的结果进行比较。为更好地利用物理问题的结构，本文开发了一种新颖的、符号化的弱验证器框架，以改善并行缩放结果。该方法在TPBench和AIME上进行了实证评估。

**Result:** 所提出的新型符号弱验证器方法在TPBench数据集上显著优于现有的测试时缩放方法。该方法在AIME数据集上也得到了验证，证实了其在解决高级数学问题方面的有效性。

**Conclusion:** 研究结果强调了分步符号验证在解决复杂科学问题方面的强大能力。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）的测试时缩放技术从数学推理向高级理论物理领域的泛化能力，并使用TPBench数据集进行了评估。论文比较了现有方法，并提出了一种新颖的符号弱验证器框架。该框架利用物理问题的结构，经验证明在TPBench上显著优于现有方法，并在AIME数学基准上也表现出有效性。这项研究强调了分步符号验证对于解决复杂科学问题的有效性。

> **摘要翻译:** 大型语言模型（LLMs）在复杂推理方面展现出强大的能力，而测试时缩放技术能以相对较低的成本提升其性能。许多此类方法已在AIME等数学推理基准上开发和评估。本文研究了从这些基准中学到的经验是否能推广到高级理论物理领域。我们评估了TPBench物理数据集上的一系列常见测试时缩放方法，并将其有效性与AIME上的结果进行比较。为了更好地利用物理问题的结构，我们开发了一种新颖的符号弱验证器框架，以改善并行缩放结果。我们的实证结果表明，该方法在TPBench上显著优于现有测试时缩放方法。我们还在AIME上评估了我们的方法，证实了其在解决高级数学问题方面的有效性。我们的发现强调了分步符号验证在解决复杂科学问题方面的强大能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [125] [Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection](https://arxiv.org/abs/2506.21093)
> *思维链增强型浅层Transformer用于无线符号检测*

*Li Fan, Peng Wang, Jing Yang, Cong Shen* | **Category: cs.LG, cs.IT, eess.SP, math.IT, stat.ML**

**Keywords:** 无线符号检测, 浅层Transformer, 思维链, 上下文学习, 资源受限设备

**Comment:** 

> **TL;DR:** 本文提出了CHOOSE，一种思维链增强型浅层（1-2层）Transformer，通过引入自回归潜在推理步骤，在无线符号检测中实现了与深层Transformer相当的性能，同时保持高效率，适用于资源受限设备。

**AI_Comments:** 该论文的创新之处在于通过思维链增强，特别是引入自回归潜在推理步骤，使浅层Transformer能够达到深层Transformer的性能。这对于在资源受限的无线设备上部署先进模型至关重要，解决了重要的实际挑战。论文成功展示了一种平衡性能与计算效率的方法，为无线通信中的边缘AI开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 此前的基于上下文学习（ICL）的Transformer模型依赖于深层架构才能达到满意性能，导致高昂的存储和计算成本，不适用于资源受限设备。

**Method:** 本文提出了CHOOSE（思维链符号检测），一个思维链增强型浅层Transformer框架，用于无线符号检测。通过在隐藏空间中引入自回归潜在推理步骤，CHOOSE显著提高了浅层模型（1-2层）的推理能力，而无需增加模型深度。

**Result:** 实验结果表明，CHOOSE优于传统的浅层Transformer，并实现了与深层Transformer相当的检测性能，同时保持了存储和计算效率。

**Conclusion:** 该研究为在计算资源有限的无线接收器中实现基于Transformer的算法提供了一个有前景的方向。

> **ai_Abstract:** 本文介绍了CHOOSE，一种思维链增强型浅层Transformer，专为高效无线符号检测而设计。为解决深层Transformer的高计算成本问题，CHOOSE将自回归潜在推理步骤整合到浅层架构（1-2层）中，显著提升了其推理能力而未增加深度。这使得轻量级模型能够匹敌更深层模型的性能，适用于资源受限的移动设备。实验证实，CHOOSE的性能优于传统浅层Transformer，并与深层Transformer相当，同时保持了高效率。

> **摘要翻译:** Transformer在解决无线通信问题，特别是通过上下文学习（ICL）方面，展现了巨大潜力。ICL允许模型通过提示适应新任务，而无需更新模型。然而，此前基于ICL的Transformer模型依赖于多层深层架构才能达到满意性能，导致高昂的存储和计算成本。本文提出了CHOOSE（思维链符号检测），一个用于无线符号检测的思维链增强型浅层Transformer框架。通过在隐藏空间中引入自回归潜在推理步骤，CHOOSE显著提高了浅层模型（1-2层）的推理能力，而无需增加模型深度。这种设计使得轻量级Transformer能够实现与更深层模型相当的检测性能，非常适合部署在资源受限的移动设备上。实验结果表明，我们的方法优于传统的浅层Transformer，并实现了与深层Transformer相当的性能，同时保持了存储和计算效率。这为在计算资源有限的无线接收器中实现基于Transformer的算法提供了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [156] [LLM-guided Chemical Process Optimization with a Multi-Agent Approach](https://arxiv.org/abs/2506.20921)
> *LLM引导的多智能体化学过程优化*

*Tong Zeng, Srivathsan Badrinarayanan, Janghoon Ock, Cheng-Kai Lai, Amir Barati Farimani* | **Category: cs.LG, cs.AI, cs.CE**

**Keywords:** 化学过程优化, 大型语言模型, 多智能体系统, 约束推断, 自动化优化

**Comment:** 16 pages (main manuscript without references), 2 figures

> **TL;DR:** 本文提出了一个基于LLM的多智能体框架，用于解决化学过程优化中操作约束不明确的问题。该框架能够自主推断约束并协作指导优化，无需预定义操作边界，实现了高效且性能优越的优化。

**AI_Comments:** 该论文的创新点在于将LLM和多智能体系统应用于传统上依赖精确约束的化学过程优化，特别是解决了“约束定义瓶颈”问题。通过LLM的推理能力和多智能体的协作，实现了在信息不完全情况下的高效优化，为新兴和复杂过程的优化提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 传统的化学过程优化方法在操作约束定义不清或不可用时效率低下，工程师需依赖主观经验。本文旨在解决这一“约束定义瓶颈”。

**Method:** 本文提出了一个基于AutoGen、采用OpenAI o3模型的多智能体LLM框架。该框架包含专门的智能体负责约束生成、参数验证、模拟执行和优化指导。它通过自主约束生成和迭代多智能体优化两个阶段，从最少的工艺描述中推断约束并指导优化，从而消除对预定义操作边界的需求。

**Result:** 在加氢脱烷基过程中的验证表明，该框架与传统优化方法性能相当，但计算效率更高，收敛所需的迭代次数更少。它在不到20分钟内收敛，比网格搜索加速31倍。此外，该框架展现出对过程的复杂理解，能正确识别效用权衡并应用领域知情的启发式方法。

**Conclusion:** 该方法在操作约束不明确或不可用的优化场景中，特别是对于新兴工艺和改造应用，显示出巨大的潜力。

> **ai_Abstract:** 本文提出了一个基于大型语言模型（LLM）的多智能体框架，旨在解决化学过程优化中操作约束定义不清的难题。该框架利用LLM智能体自主推断约束，并通过协作优化指导过程，无需预先定义操作边界。在加氢脱烷基过程中的验证表明，该方法在计算效率和性能上均优于传统方法，并能展现出对过程的深刻理解，尤其适用于约束信息不足的新兴或改造过程。

> **摘要翻译:** 化学过程优化对于最大化生产效率和经济效益至关重要。传统方法，包括基于梯度的求解器、进化算法和参数网格搜索，在操作约束定义不清或不可用时变得不切实际，需要工程师依赖主观启发式方法来估计可行的参数范围。为了解决这个约束定义瓶颈，我们提出了一个大型语言模型（LLM）智能体多智能体框架，该框架能够从最少的工艺描述中自主推断操作约束，然后协同指导使用推断出的约束进行优化。我们基于AutoGen的智能体框架采用了OpenAI的o3模型，并设有专门的智能体用于约束生成、参数验证、模拟执行和优化指导。通过两个阶段——利用嵌入式领域知识进行自主约束生成，然后进行迭代多智能体优化——该框架消除了对预定义操作边界的需求。在加氢脱烷基过程的成本、产率和产率成本比指标上进行了验证，该框架表现出与传统优化方法相当的性能，同时实现了更好的计算效率，需要更少的迭代次数才能收敛。我们的方法在不到20分钟内收敛，比网格搜索加速了31倍。除了计算效率外，该框架的推理引导搜索展现了复杂的工艺理解，正确识别了效用权衡，并应用了领域知情的启发式方法。这种方法在操作约束特征不明确或不可用的优化场景中，特别是对于新兴工艺和改造应用，显示出巨大的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [158] [Artificial Delegates Resolve Fairness Issues in Perpetual Voting with Partial Turnout](https://arxiv.org/abs/2506.21186)
> *人工代表解决部分投票率下永久投票的公平性问题*

*Apurva Shah, Axel Abels, Ann Nowé, Tom Lenaerts* | **Category: cs.LG, cs.CY**

**Keywords:** 永久投票, 公平性, 部分投票率, 人工代表, 偏好学习

**Comment:** The paper has been accepted at the ACM Collective Intelligence
  Conference (CI 2025), August 4 to 6, 2025, San Diego, CA, USA

> **TL;DR:** 现有永久投票系统在部分投票率下存在公平性问题，本文提出人工代表来解决，并证明其能有效缓解不公平影响。

**AI_Comments:** 这项工作通过引入“人工代表”的概念，为解决现实世界中永久投票系统因部分投票率而导致的公平性问题提供了一种创新性的解决方案，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有永久投票规则依赖于完全参与和完整的批准信息，这在实践中很少实现，因为部分投票率是常态，导致公平性问题。

**Method:** 研究了将“人工代表”（经过偏好学习训练以代表缺席选民的代理）整合到永久投票系统中。考察了缺席如何影响各种投票方法下的公平性和代表性，并评估了人工代表弥补缺失参与的程度。

**Result:** 缺席显著影响公平性，而人工代表能可靠地减轻这些影响并增强在不同情景下的鲁棒性。

**Conclusion:** 人工代表是解决永久投票中部分投票率导致的公平性问题的有效方法，能够提高系统的鲁棒性和公平性。

> **ai_Abstract:** 本文探讨了在实际中常见的投票率不足情况下，永久投票系统面临的公平性挑战。为解决现有系统依赖完全参与的局限性，作者引入了“人工代表”——一种学习缺席选民偏好的智能代理。研究发现，尽管缺席会严重影响公平性，但人工代表能够有效缓解这些负面影响，并在多种场景下提升系统的稳健性。

> **摘要翻译:** 永久投票通过评估随时间变化的代表性公平性来解决顺序集体决策中的公平性问题。然而，现有的永久投票规则依赖于完全参与和完整的批准信息，这些假设在实践中很少成立，因为部分投票率是常态。在这项工作中，我们研究了将“人工代表”（即经过偏好学习训练以代表缺席选民的代理）整合到永久投票系统中。我们考察了缺席如何影响各种投票方法下的公平性和代表性，并评估了人工代表在多大程度上可以弥补缺失的参与。我们的研究结果表明，虽然缺席显著影响公平性，但人工代表能够可靠地减轻这些影响，并增强在不同情景下的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [161] [Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers](https://arxiv.org/abs/2506.20746)
> *关系抽取的多流机制：Transformer中的信息丰富与召回*

*Todd Nief, David Reber, Sean Richardson, Ari Holtzman* | **Category: cs.LG**

**Keywords:** 关系抽取, Transformer, 微调, 语言模型, 信息流

**Comment:** 

> **TL;DR:** 本文通过动态权重嫁接方法，揭示了微调后的语言模型在处理实体时会提取关系信息，并在后续层中召回这些信息以进行预测，有时两种机制并存，有时单一机制即可。

**AI_Comments:** 本文创新性地提出了动态权重嫁接方法来剖析Transformer中关系信息的流向，解决了现有定位方法无法避免信息删除的局限性。其发现的“丰富”和“召回”双重信息途径，对于理解大型语言模型的内部机制及其微调后的行为具有重要意义，对未来模型设计和可解释性研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有定位方法（如激活补丁）不适用于分析大型语言模型（LLM）在微调过程中学习到的关系信息去向，因为它们可能会删除信息，从而无法准确揭示信息是在处理实体时被提取、在预测前被即时召回，还是存在多种独立的启发式方法。

**Method:** 本文提出了一种在微调模型和预训练模型之间进行“动态权重嫁接”的方法，以分析微调后的语言模型中关系信息的处理机制。

**Result:** 研究发现，微调后的语言模型在处理实体时会提取关系信息（“丰富”途径），并在生成预测时在后续层中“召回”这些信息。在某些情况下，模型需要这两种途径才能正确生成微调信息，而在其他情况下，单一的“丰富”或“召回”途径就足够了。此外，“召回”途径通过任务特定的注意力机制以及在最终层中注意力输出和前馈网络的输出中的关系抽取步骤发生。

**Conclusion:** 本文证明了微调后的语言模型通过“丰富”和“召回”这两种独立但有时协同的信息途径来处理和利用关系信息，并详细阐述了这些途径的发生位置、冗余度以及涉及的模型组件。

> **ai_Abstract:** 本文探讨了大型语言模型在微调后如何处理关系信息。通过引入动态权重嫁接方法，研究发现模型在处理实体时会“提取”关系信息，并在后续层“召回”这些信息以进行预测。有时这两种“丰富”和“召回”途径都必需，有时其中一种就足够。研究还详细分析了这些信息途径发生的层级、冗余性以及相关模型组件，揭示了“召回”途径通过注意力机制和最终层的网络输出进行关系抽取。

> **摘要翻译:** 当LLM在微调期间学习到一种关系（例如，新电影上映、公司合并等）时，这些信息去了哪里？它是在模型处理实体时被提取，在预测前即时召回，还是存在多种独立的启发式方法？现有定位方法（例如激活补丁）不适合这种分析，因为它们倾向于替换残差流的一部分，可能会删除信息。为了填补这一空白，我们提出了在微调语言模型和预训练语言模型之间进行动态权重嫁接，以表明微调语言模型（1）在处理实体时提取了微调期间学到的关系信息，并且（2）在生成预测时在后续层中“召回”了这些信息。在某些情况下，模型需要这两种途径才能正确生成微调信息，而在其他情况下，单一的“丰富”或“召回”途径就足够了。我们研究了这些信息途径的必要性和充分性，检查了它们发生的层、表现出的冗余量以及涉及的模型组件——发现“召回”途径通过任务特定的注意力机制以及在下一词元预测之前的最终层中注意力输出和前馈网络的输出中的关系抽取步骤发生。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [179] [Characterization and Mitigation of Training Instabilities in Microscaling Formats](https://arxiv.org/abs/2506.20752)
> *微缩格式训练不稳定性表征与缓解*

*Huangyuan Su, Mujin Kwun, Stephanie Gil, Sham Kakade, Nikhil Anand* | **Category: cs.LG, cs.AR**

**Keywords:** 微缩格式, 训练不稳定性, 低精度训练, 大型语言模型, 梯度偏差

**Comment:** 14 pages + appendices

> **TL;DR:** 本文研究了在NVIDIA Blackwell架构中引入的微缩（MX）格式训练大型语言模型时出现的训练不稳定性问题，并发现这些不稳定性是由层归一化仿射参数和少量激活的量化引入的乘法梯度偏差引起的。研究提出并验证了通过在训练中途修改精度方案或采用混合配置可以有效缓解这些不稳定性，使其性能与全精度训练相当。

**AI_Comments:** 这项工作在理解和解决低精度训练（特别是微缩格式）中的不稳定性方面具有重要意义。其创新之处在于通过大规模实验和受控消融研究，精确地定位了不稳定的根本原因——量化引入的梯度偏差。此外，提出的通过中途修改精度方案或混合配置来缓解不稳定性，为实际应用提供了具体的指导。这项研究对于推动下一代硬件加速器在大型模型训练中的高效利用至关重要，有助于降低计算成本并加速模型开发。其局限性可能在于，所提出的缓解策略是否在所有可能的模型架构和数据集上都能普遍有效，以及它们对最终模型质量的长期影响。

<details>
  <summary>Details</summary>

**Motivation:** 训练大型语言模型成本高昂且计算密集，随着模型规模、算法改进和新数据收集，需要重复进行。为了解决这一问题，下一代硬件加速器越来越多地支持低精度算术格式，例如NVIDIA Blackwell架构中引入的微缩（MX）格式。本文旨在研究在模型训练中使用块缩放精度格式的挑战和可行性。

**Method:** 研究人员训练了近千个大型语言模型，涵盖了从 $2 \times 10^{17}$ 到 $4.8 \times 10^{19}$ FLOPs 的计算预算，并扫描了广泛的权重-激活精度组合，以观察训练中的行为。为了解释观察到的现象，他们在一个表现出类似行为的较小代理模型上进行了受控实验和消融研究，遍历了架构设置、超参数和精度格式。通过原位干预实验，验证了修改精度方案的效果。最后，在LLM设置中评估了稳定策略。

**Result:** 研究一致观察到，在MX格式下训练时，损失函数会出现剧烈、随机的不稳定性，尤其是在较大的计算规模下。受控实验和消融研究表明，不稳定性是由层归一化仿射参数和少量激活的量化引入的乘法梯度偏差触发的。通过在代理模型上进行原位干预实验，证明了通过在训练中途修改精度方案可以避免或延迟不稳定性。在LLM设置中，某些混合配置能够恢复与全精度训练相当的性能。

**Conclusion:** 在微缩（MX）格式下训练大型语言模型会引入由量化引起的乘法梯度偏差导致的不稳定性。通过在训练中途调整精度方案或采用特定的混合配置，可以有效缓解这些不稳定性，从而在保持计算效率的同时，实现与全精度训练相媲美的性能。

> **ai_Abstract:** 本文深入探讨了在NVIDIA Blackwell架构中引入的微缩（MX）格式训练大型语言模型时所面临的训练不稳定性问题。通过对近千个语言模型的广泛实验，研究人员发现MX格式训练会导致损失函数出现剧烈的不稳定性，特别是在大规模计算下。进一步的受控实验揭示，这些不稳定性源于层归一化仿射参数和少量激活的量化引入的乘法梯度偏差。研究证明，通过在训练过程中动态调整精度方案或采用混合精度配置，可以有效缓解或消除这些不稳定性，从而使低精度训练的性能与全精度训练相媲美，为高效训练大型模型提供了解决方案。

> **摘要翻译:** 训练大型语言模型是一个昂贵且受计算限制的过程，随着模型的扩展、算法的改进和新数据的收集，这一过程必须重复进行。为了解决这个问题，下一代硬件加速器越来越多地支持低精度算术格式，例如NVIDIA Blackwell架构中引入的微缩（MX）格式。这些格式在参数块内使用共享比例来扩展可表示范围，并以降低的精度执行前向/后向GEMM操作以提高效率。在这项工作中，我们研究了模型训练过程中块缩放精度格式的挑战和可行性。我们从头开始训练了近千个语言模型——涵盖了从 $2 \times 10^{17}$ 到 $4.8 \times 10^{19}$ FLOPs 的计算预算，并扫描了广泛的权重-激活精度组合——我们一致观察到，在MX格式下训练时，损失函数会出现剧烈、随机的不稳定性，尤其是在较大的计算规模下。为了解释这种现象，我们对一个表现出与语言模型相似行为的较小代理模型进行了受控实验和消融研究，遍历了架构设置、超参数和精度格式。这些实验促使我们建立了一个简单的模型，其中层归一化仿射参数和少量激活的量化引入的乘法梯度偏差可以触发失控发散。通过对我们的代理模型进行原位干预实验，我们证明通过在训练中途修改精度方案可以避免或延迟不稳定性。受这些发现的指导，我们在LLM设置中评估了稳定策略，并表明某些混合配置可以恢复与全精度训练相当的性能。我们的代码已在 https://github.com/Hither1/systems-scaling 发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [180] [Lipschitz Bounds for Persistent Laplacian Eigenvalues under One-Simplex Insertions](https://arxiv.org/abs/2506.21352)
> *单形插入下持久拉普拉斯特征值的Lipschitz界*

*Le Vu Anh, Mehmet Dik, Nguyen Viet Anh* | **Category: cs.LG, cs.IT, math.IT, math.MG**

**Keywords:** 持久拉普拉斯, 特征值, Lipschitz界, 单形插入, 拓扑数据分析

**Comment:** 16 pages, 4 figures

> **TL;DR:** 本文证明了在插入一个单形后，每个向上持久拉普拉斯特征值的变化量最多是该单形边界欧几里得范数的两倍，与过滤尺度和复形大小无关，为谱拓扑数据分析提供了首个特征值层面的鲁棒性保证。

**AI_Comments:** 这项工作在拓扑数据分析领域具有重要意义，首次为持久拉普拉斯特征值在局部更新下的稳定性提供了量化保证。其创新之处在于建立了具体的Lipschitz界，解决了长期以来关于单个特征值精确变化的未决问题。这对于依赖谱特征进行下游分析（如热核签名和谱神经网络）的工具至关重要，能够提高动态数据分析的可靠性和误差控制能力。

<details>
  <summary>Details</summary>

**Motivation:** 持久拉普拉斯算子在生物学、物理学和机器学习中被广泛采用，其特征值是几何和拓扑特征的简洁描述符。尽管早期工作建立了这些算子的全局代数稳定性，但当插入一个单形（如顶点、边或三角形）时，单个特征值的精确变化仍然未知。这很重要，因为下游工具（包括热核签名和谱神经网络）直接依赖于这些特征值。

**Method:** 通过数学证明，建立了统一的Lipschitz界。

**Result:** 证明了在插入一个单形后，每个向上持久拉普拉斯特征值的变化量最多是该单形边界欧几里得范数的两倍，且与过滤尺度和复形大小无关。

**Conclusion:** 该结果为谱拓扑数据分析提供了首个特征值层面的鲁棒性保证，确保了谱特征在局部更新下保持稳定，并使得动态数据设置中的误差控制变得可靠。

> **ai_Abstract:** 本文研究了在数据中插入单个单形（如顶点、边或三角形）时，持久拉普拉斯特征值的变化。尽管持久拉普拉斯算子在多个领域有广泛应用，且其全局稳定性已知，但单个特征值的精确变化此前未被量化。作者通过数学证明，建立了统一的Lipschitz界，表明插入一个单形后，每个向上持久拉普拉斯特征值的变化量最大为该单形边界欧几里得范数的两倍，且与过滤尺度和复形大小无关。这一发现为谱拓扑数据分析提供了首个特征值层面的鲁棒性保证，确保了谱特征在数据动态更新时的稳定性，并有助于实现可靠的误差控制。

> **摘要翻译:** 持久拉普拉斯算子是跟踪数据形状和结构如何跨尺度转换的矩阵算子，在生物学、物理学和机器学习中被广泛采用。它们的特征值是过滤中几何和拓扑特征的简洁描述符。尽管早期工作建立了这些算子的全局代数稳定性，但当插入一个单形（如顶点、边或三角形）时，单个特征值的精确变化仍然未知。这很重要，因为下游工具（包括热核签名和谱神经网络）直接依赖于这些特征值。我们通过证明一个统一的Lipschitz界来弥补这一空白：在插入一个单形后，每个向上持久拉普拉斯特征值的变化量最多是该单形边界欧几里得范数的两倍，与过滤尺度和复形大小无关。这一结果为谱拓扑数据分析提供了首个特征值层面的鲁棒性保证。它保证了谱特征在局部更新下保持稳定，并使得动态数据设置中的误差控制变得可靠。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [188] [Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers](https://arxiv.org/abs/2506.20816)
> *通过网络层非均匀影响实现对抗性数据的通用高效检测*

*Furkan Mumcu, Yasin Yilmaz* | **Category: cs.LG, cs.CR, cs.CV**

**Keywords:** 对抗性样本检测, 深度神经网络, 非均匀影响, 轻量级回归模型, 实时处理

**Comment:** arXiv admin note: substantial text overlap with arXiv:2410.17442

> **TL;DR:** 本文提出了一种新颖的通用高效方法，通过分析对抗性攻击对不同深度神经网络层的影响差异，来检测对抗性样本。

**AI_Comments:** 该论文提出了一种新颖的对抗性样本检测视角，即利用攻击对网络层影响的非均匀性。其创新点在于通过轻量级回归模型预测层间特征并利用预测误差进行检测，显著提升了检测的效率和通用性，使其适用于实时处理和多种DNN架构及数据类型，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络容易受到对抗性攻击，现有防御方法要么侧重于提高鲁棒性，要么使用次级模型检测对抗性数据，但这些方法对于最先进的攻击效果不佳或计算效率低下。本文旨在提供一种更实用、高效的攻击检测方法。

**Method:** 该方法训练一个轻量级回归模型，该模型从早期层特征预测更深层特征，并利用预测误差来检测对抗性样本。

**Result:** 实验证明，所提出的检测方法高效、计算效率高，适用于实时处理，兼容任何DNN架构，并可应用于图像、视频和音频等不同领域。

**Conclusion:** 本文提出了一种通过分析对抗性攻击对不同DNN层非均匀影响来检测对抗性样本的通用高效方法，该方法在理论和实验上均被证明是有效且实用的。

> **ai_Abstract:** 本文针对深度神经网络易受对抗性攻击的问题，提出了一种通用且高效的对抗性样本检测方法。该方法通过分析对抗性攻击对神经网络不同层产生的非均匀影响，训练一个轻量级回归模型，利用早期层特征预测更深层特征，并通过预测误差来识别对抗性数据。研究表明，该方法在效率、计算成本、兼容性和跨领域适用性方面均表现出色，为实时检测对抗性攻击提供了实用的解决方案。

> **摘要翻译:** 深度神经网络（DNNs）以其对有限噪声预算的对抗性输入设计的脆弱性而闻名。虽然已经提出了许多通过对原始输入进行细微修改的成功攻击，但针对这些攻击的防御技术相对研究不足。现有的防御方法要么通过抵消扰动的影响来提高DNN的鲁棒性，要么使用辅助模型来检测对抗性数据。尽管同样重要，但本研究中探讨的攻击检测方法与鲁棒性方法相比，提供了一种更实用的防御。我们发现，现有检测方法要么对最先进的攻击技术无效，要么在实时处理方面计算效率低下。我们提出了一种新颖的通用高效方法，通过分析攻击对不同DNN层影响程度的差异来检测对抗性样本。我们的方法训练一个轻量级回归模型，该模型从早期层特征预测更深层特征，并利用预测误差来检测对抗性样本。通过理论论证和大量实验，我们证明了我们的检测方法高效、计算效率高，适用于实时处理，兼容任何DNN架构，并可应用于图像、视频和音频等不同领域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [192] [Devising a solution to the problems of Cancer awareness in Telangana](https://arxiv.org/abs/2506.21500)
> *在特伦甘纳邦设计癌症意识问题的解决方案*

*Priyanka Avhad, Vedanti Kshirsagar, Urvi Ranjan, Mahek Nakhua* | **Category: cs.LG, cs.CY, q-bio.QM**

**Keywords:** 癌症意识, 机器学习, 特伦甘纳邦, 早期检测, 公共卫生

**Comment:** 

> **TL;DR:** 该研究开发了一个机器学习模型和系统，旨在提高特伦甘纳邦的癌症意识并降低死亡率。

**AI_Comments:** 该论文提出了一种结合机器学习预测和地理位置服务的实用解决方案，以应对印度特定地区癌症意识不足的挑战。其创新性在于将技术应用于公共卫生领域，旨在通过提高意识和提供便捷的医疗资源信息来改善癌症早期筛查和管理。

<details>
  <summary>Details</summary>

**Motivation:** 特伦甘纳邦宫颈癌、乳腺癌和口腔癌筛查率极低（分别为3.3%、0.3%和2.3%），尽管早期发现是降低发病率和死亡率的唯一途径，但人们对癌症症状和筛查实践的意识非常低。

**Method:** 开发了一个机器学习分类模型，用于根据人口统计学因素预测个人对乳腺癌或宫颈癌的易感性。使用决策树分类和支持向量分类算法分别用于宫颈癌和乳腺癌易感性预测。此外，设计了一个系统，根据用户位置提供最近的医院或癌症治疗中心建议，并可集成健康卡以维护医疗记录和开展宣传活动。

**Result:** 通过开发的机器学习模型可以预测个人对乳腺癌或宫颈癌的易感性。设计的系统能够根据用户位置提供最近的医院或癌症治疗中心建议，并有助于维护医疗记录和开展宣传活动。

**Conclusion:** 通过设计这个解决方案，可以更接近于实现传播癌症意识、降低癌症死亡率和提高特伦甘纳邦人民癌症知识的目标。

> **ai_Abstract:** 本研究旨在解决印度特伦甘纳邦癌症意识低下导致筛查率极低的问题。作者开发了一个机器学习分类模型，利用人口统计学因素预测个人对乳腺癌或宫颈癌的易感性，其中宫颈癌采用决策树分类，乳腺癌采用支持向量分类。此外，还设计了一个系统，根据用户位置提供最近的癌症治疗中心建议，并计划集成健康卡以管理医疗记录和组织癌症宣传活动。该解决方案旨在提高癌症意识，从而降低死亡率并提高当地居民的癌症知识水平。

> **摘要翻译:** 根据数据显示，2020年特伦甘纳邦接受宫颈癌、乳腺癌和口腔癌筛查的女性比例分别为3.3%、0.3%和2.3%。尽管早期发现是降低发病率和死亡率的唯一途径，但人们对宫颈癌和乳腺癌的体征、症状以及筛查实践的意识非常低。我们开发了一个机器学习分类模型，根据人口统计学因素预测一个人是否易患乳腺癌或宫颈癌。我们设计了一个系统，根据用户的位置或地址提供最近的医院或癌症治疗中心的建议。除此之外，我们还可以整合健康卡以维护所有个人的医疗记录并开展宣传活动。对于机器学习分类模型，我们分别使用了决策树分类和支持向量分类算法来预测宫颈癌易感性和乳腺癌易感性。因此，通过设计这个解决方案，我们离我们的目标更近了一步，即传播癌症意识，从而降低癌症死亡率并提高特伦甘纳邦人民的癌症知识水平。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [195] [Stochastic and Non-local Closure Modeling for Nonlinear Dynamical Systems via Latent Score-based Generative Models](https://arxiv.org/abs/2506.20771)
> *随机和非局部闭合建模，用于通过潜在分数生成模型的非线性动力系统*

*Xinghao Dong, Huchen Yang, Jin-Long Wu* | **Category: cs.LG, math.DS, physics.comp-ph**

**Keywords:** 随机闭合建模, 潜在分数模型, 非线性动力系统, 扩散模型, 计算力学

**Comment:** 

> **TL;DR:** 该研究提出了一种基于潜在分数的生成式人工智能框架，用于非线性动力系统中的随机、非局部闭合建模，通过在潜在空间中联合训练扩散模型，显著降低了计算成本并保持了精度。

**AI_Comments:** 这项工作的创新之处在于通过利用潜在空间来解决扩散模型在闭合建模中的计算瓶颈，从而使其适用于湍流等复杂系统。联合训练方法对于发现最优潜在空间至关重要，为多尺度动力系统建模提供了一种更高效和准确的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理没有明确尺度分离的复杂多尺度动力系统时，面临计算成本过高（如湍流）或假设过于严格的挑战。特别是，基于扩散的随机模型虽然有前景，但其计算推理成本过高限制了实际应用。

**Method:** 提出了一种潜在分数生成式AI框架。通过在潜在空间中联合训练卷积自编码器和条件扩散模型，显著降低了采样过程的维度，同时保留了重要的物理特性。

**Result:** 联合训练方法有助于发现一个合适的潜在空间，该空间不仅保证了小的重建误差，而且确保了扩散模型在潜在空间中的良好性能。当集成到数值模拟中时，所提出的随机建模框架实现了显著的计算加速，同时保持了与物理空间中标准扩散模型相当的预测精度。

**Conclusion:** 所提出的通过潜在条件扩散模型的随机建模框架，为非线性动力系统中的闭合建模提供了一种计算效率高且预测准确的解决方案，克服了现有方法的局限性，使其适用于实际应用。

> **ai_Abstract:** 本论文提出了一种基于潜在分数的生成式人工智能框架，用于复杂非线性动力系统中的随机、非局部闭合建模。该框架通过在潜在空间中联合训练自编码器和条件扩散模型，解决了多尺度建模和现有扩散模型计算成本高昂的问题。这种方法显著降低了采样维度，实现了显著的计算加速，并保持了与标准方法相当的精度，使其适用于湍流等实际应用。

> **摘要翻译:** 我们提出了一种基于潜在分数的生成式人工智能框架，用于计算力学非线性动力系统中随机、非局部闭合模型和本构律的学习。这项工作解决了对没有明确尺度分离的复杂多尺度动力系统进行建模的关键挑战，因为数值求解所有尺度会非常昂贵，例如工程湍流。虽然经典的闭合建模方法利用领域知识来近似亚网格尺度现象，但其确定性和局部假设在缺乏明确尺度分离的区域可能过于严格。最近基于扩散的随机模型在闭合建模方面已显示出前景，但其过高的计算推理成本限制了在许多实际应用中的实际应用。这项工作通过在潜在空间中联合训练卷积自编码器和条件扩散模型来解决这一限制，显著降低了采样过程的维度，同时保留了重要的物理特性。数值结果表明，联合训练方法有助于发现一个合适的潜在空间，该空间不仅保证了小的重建误差，而且确保了扩散模型在潜在空间中的良好性能。当集成到数值模拟中时，所提出的通过潜在条件扩散模型的随机建模框架实现了显著的计算加速，同时保持了与物理空间中标准扩散模型相当的预测精度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [207] [Stochastic Parameter Decomposition](https://arxiv.org/abs/2506.20790)
> *随机参数分解*

*Lucius Bushnaq, Dan Braun, Lee Sharkey* | **Category: cs.LG, cs.AI**

**Keywords:** 神经网络分解, 随机参数分解, 机制可解释性, 线性参数分解, 因果中介分析

**Comment:** 

> **TL;DR:** 本文引入了随机参数分解（SPD），一种比现有方法更具可扩展性和鲁棒性的神经网络参数分解方法，有助于机制可解释性研究。

**AI_Comments:** 本文的创新点在于提出了随机参数分解（SPD），有效解决了现有线性参数分解方法（如APD）在可扩展性和鲁棒性方面的局限性。通过引入SPD，并将其与因果中介分析相结合，该工作为神经网络的机制可解释性研究提供了实用的工具和新的方向，尤其是在处理大型复杂模型方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 逆向工程神经网络的关键一步是将其分解为更简单的部分。现有的线性参数分解框架中的主要方法（APD）存在计算成本高和对超参数敏感的问题，限制了其在大模型上的应用。

**Method:** 本文提出了随机参数分解（SPD），该方法通过将神经网络参数分解为参数空间中稀疏使用的向量之和，并结合因果中介分析和网络分解方法，提高了可扩展性和对超参数的鲁棒性。

**Result:** SPD比APD在计算上更具可扩展性和鲁棒性，能够分解比APD稍大和更复杂的模型。SPD还避免了学习参数的收缩等问题，并在玩具模型中更好地识别了真实机制。

**Conclusion:** 通过引入SPD并连接因果中介分析与网络分解方法，本文消除了线性参数分解方法扩展到更大模型的障碍，为机制可解释性研究开辟了新的可能性。

> **ai_Abstract:** 本文提出了一种名为随机参数分解（SPD）的新方法，旨在解决现有神经网络参数分解方法（如APD）的计算成本和超参数敏感性问题。SPD能够更有效地分解大型复杂模型，避免了参数收缩，并提高了真实机制的识别能力。这项工作通过将因果中介分析与网络分解相结合，为机制可解释性领域提供了新的研究途径，并发布了相应的代码库。

> **摘要翻译:** 逆向工程神经网络的一个关键步骤是将其分解为可以相对独立研究的更简单部分。线性参数分解——一个旨在解决当前分解方法中若干问题的框架——将神经网络参数分解为参数空间中稀疏使用向量的总和。然而，该框架中当前的主要方法，基于归因的参数分解（APD），因其计算成本和对超参数的敏感性而不切实际。在这项工作中，我们引入了“随机参数分解”（SPD），这是一种比APD更具可扩展性和对超参数更鲁棒的方法，我们通过分解比APD可能分解的模型稍大和更复杂的模型来证明了这一点。我们还表明，SPD避免了其他问题，例如学习参数的收缩，并且在玩具模型中更好地识别了真实机制。通过连接因果中介分析和网络分解方法，这一演示通过消除将线性参数分解方法扩展到更大模型的障碍，为机制可解释性开辟了新的研究可能性。我们发布了一个用于运行SPD和重现我们实验的库，网址为https://github.com/goodfire-ai/spd。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
> *更精简的训练，更低的泄露：重新审视LoRA微调中大型语言模型的记忆化*

*Fei Wang, Baochun Li* | **Category: cs.LG, cs.CL, cs.CR**

**Keywords:** LLM, 记忆化, LoRA, 微调, 数据泄露

**Comment:** 

> **TL;DR:** 本研究发现LoRA微调显著降低了大型语言模型的记忆化风险，同时保持了强大的任务性能，这与全量微调和预训练的记忆化趋势不同。

**AI_Comments:** 这篇论文的创新之处在于它首次系统地深入探讨了LoRA微调中的记忆化问题，并揭示了其与传统微调和预训练的显著差异。其重要性在于为LLM的隐私和安全提供了新的见解，并指出LoRA不仅是参数高效的方法，也是一种有助于降低数据泄露风险的有效策略。这对于开发更安全、更可靠的LLM具有实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的记忆化使其容易受到数据提取攻击。虽然预训练中的记忆化已被广泛研究，但很少有工作探索其在微调中的影响，特别是对于广泛采用的参数高效方法LoRA微调。

**Method:** 本研究重新审视了微调中的记忆化，并使用了一种更宽松的基于相似度的记忆化度量标准。研究比较了LoRA微调与全量微调，并分析了模型规模和数据重复等因素对记忆化的影响。

**Result:** 研究发现LoRA微调的记忆化趋势与预训练和全量微调中的记忆化趋势存在显著差异。模型规模和数据重复等在预训练和全量微调中强烈影响记忆化的因素，在LoRA微调中不遵循相同的趋势。LoRA与全量微调相比显著降低了记忆化风险，同时仍保持了强大的任务性能。

**Conclusion:** LoRA微调是一种有效的方法，可以显著降低大型语言模型的记忆化风险，同时不牺牲任务性能，这表明LoRA是提高模型安全性的有前途的策略。

> **ai_Abstract:** 本研究深入探讨了大型语言模型（LLMs）在微调过程中的记忆化现象，特别关注了参数高效的LoRA微调方法。研究发现，LoRA微调的记忆化行为与预训练及全量微调存在显著差异，例如模型规模和数据重复等因素的影响趋势不同。通过采用更宽松的相似度记忆化度量，研究证明LoRA微调能够显著降低记忆化风险，同时保持优异的任务性能，从而为LLM的安全性提供了新的视角。

> **摘要翻译:** 大型语言模型（LLMs）的记忆化使其容易受到数据提取攻击。虽然预训练中的记忆化已被广泛研究，但很少有工作探索其在微调中的影响，特别是对于广泛采用的参数高效方法LoRA微调。
在本工作中，我们重新审视了微调中的记忆化，并揭示了不同微调策略下与先前发现的惊人差异。模型规模和数据重复等在预训练和全量微调中强烈影响记忆化的因素，在LoRA微调中不遵循相同的趋势。使用一种更宽松的基于相似度的记忆化度量标准，我们证明LoRA与全量微调相比显著降低了记忆化风险，同时仍保持了强大的任务性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [217] [GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization](https://arxiv.org/abs/2506.20807)
> *GPU核科学家：一个LLM驱动的迭代核优化框架*

*Martin Andrews, Sam Witteveen* | **Category: cs.LG, cs.AI, cs.PF, cs.SE**

**Keywords:** GPU优化, LLM, 核优化, 自动化, AMD MI300

**Comment:** 4 page paper plus Appendices. Accepted to the ES-FoMo "Efficient
  Systems for Foundation Models" workshop at ICML 2025

> **TL;DR:** 本文介绍了一个名为“GPU核科学家”的LLM驱动框架，用于自动化和迭代优化GPU核，尤其是在缺乏文档的新架构上。它通过LLM选择代码版本、生成优化假设并自主实现实验。

**AI_Comments:** 这篇论文提出了一种创新性的方法，利用LLM自动化GPU核优化，尤其是在新架构下缺乏专业知识的挑战性场景中。其多阶段、演化式的优化流程具有很强的实用价值。虽然缺乏具体的定量性能数据是一个遗憾，但其对LLM在复杂系统优化中作用的探索，以及对AMD MI300等新兴架构的关注，显示了其前瞻性和重要性。该框架有望降低GPU性能优化的门槛，加速新硬件的开发和应用。

<details>
  <summary>Details</summary>

**Motivation:** 优化GPU核以获得高性能是一项复杂的任务，需要深入的架构知识、广泛的分析和迭代实验。当针对较新或文档较少的GPU架构时，这一挑战更加突出，因为传统开发辅助工具稀缺。

**Method:** 本文提出了一个LLM驱动的“GPU核科学家”自动化方法，用于迭代优化加速器核。该方法采用多阶段、演化过程：(a) 战略性地选择有前景的现有代码版本作为新迭代的基础；(b) 基于现有代码和从通用GPU文献中吸收的知识生成优化实验假设；(c) 通过代码修改自主实施这些实验，并提交给外部评估系统，仅使用观察到的时间数据作为性能反馈。该方法应对AMD MI300目标架构的挑战，并利用LLM弥补领域特定人类专业知识的不足。

**Result:** 由于正在进行的性能竞赛的定量结果在论文提交日期被禁运，本文主要介绍了架构设计、操作工作流程和定性见解。它强调了LLM驱动的代理在普及和加速GPU核优化方面的潜力，特别是在资源受限或快速发展的硬件环境中。

**Conclusion:** LLM驱动的代理有潜力使GPU核优化民主化并加速，尤其是在资源受限或快速发展的硬件环境中，通过自动化迭代优化过程来弥补领域特定人类专业知识的不足。

> **ai_Abstract:** 本文提出了一个名为“GPU核科学家”的LLM驱动框架，旨在自动化和加速GPU核优化过程。该框架通过LLM在多阶段演化过程中选择最佳代码版本、生成优化假设并自主执行实验。它特别适用于缺乏文档的新兴GPU架构，通过利用LLM弥补人类专业知识的不足。尽管定量结果因竞赛禁运而未公开，但论文详细描述了其架构设计、操作流程及定性潜力，强调了LLM在GPU优化领域的民主化和加速作用。

> **摘要翻译:** 优化GPU核以获得高性能是一项复杂的任务，通常需要深厚的架构知识、广泛的性能分析和迭代实验。当针对较新或文档较少的GPU架构时，这一挑战会加剧，因为传统开发辅助工具稀缺。本文介绍了一个由大型语言模型（LLM）驱动的“GPU核科学家”，这是一种自动化方法，用于迭代地优化加速器核。
我们的方法采用LLM进行多阶段的演化过程：(a) 战略性地选择有前景的先前代码版本作为新迭代的基础；(b) 基于现有代码和从通用GPU文献中吸收的知识生成优化实验假设；(c) 通过代码修改自主实施这些实验，并随后提交给外部评估系统，仅使用观察到的时间数据作为性能反馈。我们详细介绍了这种方法如何应对AMD MI300目标架构的挑战，并利用LLM来弥补有限的领域特定人类专业知识。
由于正在进行的性能竞赛的定量结果在论文提交日期被禁运，我们展示了架构设计、操作工作流程和定性见解，强调了LLM驱动代理在普及和加速GPU核优化方面的潜力，特别是在资源受限或快速发展的硬件环境中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [234] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
> *FINN-GL: 面向FPGA加速LSTM的广义混合精度扩展*

*Shashwat Khandelwal, Jakoba Petri-Koenig, Thomas B. Preußer, Michaela Blott, Shreejith Shanker* | **Category: cs.LG, cs.AI, cs.AR, eess.SP**

**Keywords:** FPGA加速, LSTM, 混合精度, FINN框架, 循环神经网络

**Comment:** 9 pages, 6 figures, 5 tables, Accepted for publication in IEEE
  FPL-2025 (https://2025.fpl.org/)

> **TL;DR:** 该论文提出FINN-GL，一个基于FINN框架的工具流，用于在FPGA上部署混合精度量化的LSTM，解决了RNN在资源受限环境中实时部署的计算复杂性挑战，并在股票预测任务中展示了性能、资源效率和准确性的平衡。

**AI_Comments:** 本文的创新点在于将FINN框架扩展到支持复杂循环结构如LSTM的混合精度量化和FPGA部署，通过利用ONNX的Scan操作符和自定义编译器转换，解决了现有工具对RNN支持不足的问题。其重要性在于为资源受限环境中的实时AI应用提供了高效的硬件加速方案，有望推动FPGA在RNN领域的广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 循环神经网络（RNN），特别是LSTM，在时间序列任务中表现出色，但其计算复杂性阻碍了在资源受限环境中的实时部署。现有FPGA加速工具主要针对前馈网络，LSTM加速通常需要完全定制实现，这构成了研究空白。

**Method:** 作者利用开源可扩展的FINN框架，通过ONNX规范中的Scan操作符来建模LSTM计算的循环特性，以支持混合精度量化和功能验证。此外，他们还在FINN编译器中引入了自定义转换，将量化的ONNX计算图映射到FINN编译器和Vitis HLS的HLS核库中的硬件块。

**Result:** 通过使用提出的工具流，为中期股票预测任务训练了一个量化的ConvLSTM模型，并生成了针对XCZU7EV设备的相应硬件IP。结果表明，生成的量化ConvLSTM加速器在性能（延迟）和资源消耗之间取得了平衡，同时在降低精度的前提下，其推理精度与最先进的模型相当或更优。

**Conclusion:** 本研究提出的广义工具流有望为FPGA上资源高效的RNN加速器设计铺平道路，解决了RNN在资源受限环境下实时部署的挑战。

> **ai_Abstract:** 该论文介绍了FINN-GL，一个基于FINN框架的工具流，旨在解决循环神经网络（如LSTM）在FPGA上实时部署的计算复杂性挑战。它通过利用ONNX的Scan操作符来支持LSTM的混合精度量化，并引入自定义编译器转换将量化图映射到硬件。实验结果表明，该工具流生成的量化ConvLSTM加速器在性能、资源消耗和推理精度之间取得了良好平衡，为FPGA上资源高效的RNN加速器设计提供了通用方法。

> **摘要翻译:** 循环神经网络（RNN），特别是长短期记忆网络（LSTM），在情感分析和短期股票预测等时间序列任务中表现出色。然而，它们的计算复杂性给资源受限环境中的实时部署带来了挑战。尽管FPGA为节能AI加速提供了有前景的平台，但现有工具主要针对前馈网络，且LSTM加速通常需要完全定制实现。在本文中，我们通过利用开源和可扩展的FINN框架，弥补了这一空白，实现了LSTM在FPGA上的广义部署。具体来说，我们利用开放神经网络交换（ONNX）规范中的Scan操作符来建模LSTM计算的循环特性，从而支持其中的混合量化和基于LSTM模型的功能验证。此外，我们在FINN编译器中引入了自定义转换，将量化的ONNX计算图映射到FINN编译器和Vitis HLS的HLS核库中的硬件块。我们通过使用广泛使用的数据集训练一个用于中期股票预测任务的量化ConvLSTM模型，并使用我们的流程生成该模型的相应硬件IP，目标设备为XCZU7EV，从而验证了所提出的工具流。我们展示了通过我们的流程生成的量化ConvLSTM加速器在性能（延迟）和资源消耗之间取得了平衡，同时在降低精度的前提下，其推理精度与最先进的模型相当（或更优）。我们相信，所提出流程的通用性将为FPGA上资源高效的RNN加速器设计铺平道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [243] [An Information-Theoretic Analysis for Federated Learning under Concept Drift](https://arxiv.org/abs/2506.21036)
> *联邦学习中概念漂移的信息论分析*

*Fu Peng, Meng Zhang, Ming Tang* | **Category: cs.LG, cs.DC**

**Keywords:** 联邦学习, 概念漂移, 信息论, KL散度, 互信息

**Comment:** 

> **TL;DR:** 本文使用信息论分析了联邦学习在概念漂移下的性能，并提出了一种基于KL散度和互信息的算法来缓解性能下降，实验证明其优于现有方法。

**AI_Comments:** 本文的创新点在于首次将信息论引入联邦学习中的概念漂移分析，并提出了基于信息论度量的正则化方法。通过理论分析和实际验证相结合，增强了研究的严谨性。其对性能-成本权衡的探索也具有实际意义。该工作为联邦学习在真实动态环境下的应用提供了新的视角和解决方案，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦学习研究多基于静态数据集，但真实世界数据常伴随分布变化（概念漂移），导致性能下降。本文旨在分析并解决联邦学习在概念漂移下的性能退化问题。

**Method:** 本文将概念漂移建模为马尔可夫链，引入“稳态泛化误差”来评估模型捕获未来未见数据的能力，并使用KL散度和互信息推导出其上限。研究了三种漂移模式（周期性、渐进式、随机），并提出一种算法，通过KL散度和互信息对经验风险最小化方法进行正则化。此外，还通过识别帕累托前沿来探索性能-成本权衡。使用Raspberry Pi4设备构建了FL测试平台进行验证。

**Result:** 实验结果与理论发现一致，证实了漂移模式显著影响性能。所提出的方法在三种漂移模式下均持续优于现有方法。

**Conclusion:** 本文提出的基于信息论的方法能有效缓解联邦学习在概念漂移下的性能下降，并在实际测试中表现出优越性。

> **ai_Abstract:** 本文针对联邦学习在概念漂移下性能下降的问题，提出了一种基于信息论的分析框架和相应的算法。通过将概念漂移建模为马尔可夫链，并引入稳态泛化误差，利用KL散度和互信息推导其上界。研究了周期性、渐进式和随机三种漂移模式的影响，并提出一种结合KL散度和互信息的正则化经验风险最小化算法。实验结果表明，该方法在多种漂移模式下均优于现有方法，有效提升了联邦学习在动态环境中的长期性能。

> **摘要翻译:** 最近的联邦学习 (FL) 研究通常在静态数据集上训练模型。然而，现实世界的数据通常以流的形式到达，并伴随着分布变化，这会导致性能下降，即概念漂移。本文使用信息论分析了概念漂移下 FL 的性能，并提出了一种算法来缓解性能下降。我们将概念漂移建模为马尔可夫链，并引入“稳态泛化误差”来评估模型捕获未来未见数据特征的能力。其上限使用 KL 散度和互信息推导得出。我们研究了三种漂移模式（周期性、渐进式和随机）及其对 FL 性能的影响。受此启发，我们提出了一种算法，通过 KL 散度和互信息对经验风险最小化方法进行正则化，从而提高长期性能。我们还通过识别帕累托前沿来探索性能-成本权衡。为了验证我们的方法，我们使用 Raspberry Pi4 设备构建了一个 FL 测试平台。实验结果与理论发现相符，证实了漂移模式显著影响性能。我们的方法在这三种模式下始终优于现有方法，证明了其在 FL 中适应概念漂移的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [245] [Divide, Specialize, and Route: A New Approach to Efficient Ensemble Learning](https://arxiv.org/abs/2506.20814)
> *分而治之、专业化与路由：一种高效集成学习的新方法*

*Jakub Piwko, Jędrzej Ruciński, Dawid Płudowski, Antoni Zajko, Patryzja Żak, Mateusz Zacharecki, Anna Kozak, Katarzyna Woźnica* | **Category: cs.LG**

**Keywords:** 集成学习, 二元分类, 复杂性, 路由, 可解释性

**Comment:** 14 pages, 6 figures

> **TL;DR:** Hellsemble是一种新的集成学习框架，通过根据数据复杂性划分数据集并训练专业化模型，实现高效、准确且可解释的二元分类，优于传统方法。

**AI_Comments:** Hellsemble的创新点在于其“分而治之”的策略，通过实例级难度划分数据并训练专业化模型，以及引入路由机制，这为提高集成学习的效率、准确性和可解释性提供了一个新颖的视角。其对“实例级难度”的利用是值得关注的突破。

<details>
  <summary>Details</summary>

**Motivation:** 传统的集成学习方法（如Bagging、Boosting和DES）存在计算成本高和对异构数据分布适应性有限的问题。

**Method:** 本文提出了Hellsemble，一种新颖且可解释的二元分类集成框架。它在训练和推理过程中利用数据集复杂性，通过迭代地将简单模型错误分类的实例传递给后续模型，逐步将数据集划分为不同难度的“圈子”，从而形成一个由专业化基础学习器组成的委员会。每个模型都在难度递增的子集上进行训练，同时一个独立的路由模型学习根据推断的难度将新实例分配给最合适的基础模型。

**Result:** Hellsemble在保持计算效率和可解释性的同时，实现了强大的分类准确性。在OpenML-CC18和Tabzilla基准测试上的实验结果表明，Hellsemble通常优于经典的集成方法。

**Conclusion:** 研究结果表明，利用实例级别的难度为构建高效且鲁棒的集成系统提供了一个有前景的方向。

> **ai_Abstract:** Hellsemble是一种用于二元分类的新型可解释集成学习框架，旨在解决传统方法计算成本高和适应性差的问题。它通过根据数据复杂性将数据集逐步划分为不同难度的子集，并训练专门的基础学习器委员会，同时使用路由模型将新实例分配给最合适的模型。实验证明，Hellsemble在保持效率和可解释性的同时，在分类准确性方面优于经典集成方法。

> **摘要翻译:** 集成学习已被证明在提高预测性能方面是有效的，但Bagging、Boosting和动态集成选择（DES）等传统方法存在计算成本高和对异构数据分布适应性有限的问题。为了解决这些限制，我们提出了Hellsemble，一种新颖且可解释的二元分类集成框架，该框架在训练和推理过程中利用数据集复杂性。Hellsemble通过迭代地将简单模型错误分类的实例传递给后续模型，逐步将数据集划分为不同难度的“圈子”，从而形成一个由专业化基础学习器组成的委员会。每个模型都在难度递增的子集上进行训练，同时一个独立的路由模型学习根据推断的难度将新实例分配给最合适的基础模型。Hellsemble在保持计算效率和可解释性的同时，实现了强大的分类准确性。在OpenML-CC18和Tabzilla基准测试上的实验结果表明，Hellsemble通常优于经典的集成方法。我们的研究结果表明，利用实例级别的难度为构建高效且鲁棒的集成系统提供了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [252] [AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification](https://arxiv.org/abs/2506.21338)
> *AGTCNet: 一种用于规范运动想象脑电图分类的图时域方法*

*Galvin Brice S. Lim, Brian Godwin S. Lim, Argel A. Bandala, John Anthony C. Jose, Timothy Scott C. Chu, Edwin Sybingco* | **Category: cs.LG, cs.HC**

**Keywords:** 运动想象脑电图, 脑机接口, 图卷积网络, 时空表示, AGTCNet

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** AGTCNet是一种新型图时域模型，用于运动想象脑电图分类，解决了现有方法在捕捉复杂时空依赖方面的不足，实现了SOTA性能，且模型更小、推理更快，适合BCI部署。

**AI_Comments:** AGTCNet的创新点在于结合了图神经网络和时域卷积，并利用EEG电极的拓扑结构作为归纳偏置，有效捕捉了EEG信号的复杂时空依赖。其在性能提升的同时，显著减小了模型尺寸并加快了推理速度，这对于BCI设备的实际部署具有重要意义。该研究为开发更高效、更实用的BCI系统提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 脑机接口（BCI）技术尽管潜力巨大，但由于个体间和时间上的神经活动固有的复杂性和变异性，以及脑电图硬件的限制，开发主体不变和会话不变的BCI系统仍然是一个重大挑战。现有方法在捕捉多通道脑电图信号中复杂的时空依赖方面效率低下。

**Method:** 本研究引入了注意力图时域卷积网络（AGTCNet），这是一种新颖的图时域模型，用于运动想象EEG（MI-EEG）分类。AGTCNet利用EEG电极的地形配置作为归纳偏置，并整合图卷积注意力网络（GCAT）以共同学习富有表现力的时空EEG表示。

**Result:** AGTCNet显著优于现有MI-EEG分类器，实现了最先进的性能，同时采用了紧凑的架构。模型尺寸减少49.87%，推理时间加快64.65%，输入EEG信号更短。在BCI Competition IV Dataset 2a上，主体独立分类的移动平均准确率为66.82%，主体特定分类微调后提高到82.88%。在EEG Motor Movement/Imagery Dataset上，4类和2类主体独立分类的移动平均准确率分别为64.14%和85.22%，主体特定分类进一步提高到72.13%和90.54%。

**Conclusion:** AGTCNet在运动想象EEG分类中表现出卓越的性能和实用性，其紧凑的架构和高效的推理速度使其非常适合BCI部署。

> **ai_Abstract:** 本文提出了一种名为AGTCNet的注意力图时域卷积网络，用于运动想象EEG分类，旨在解决现有BCI系统在捕获复杂EEG时空依赖方面的不足。AGTCNet利用EEG电极的拓扑结构和图卷积注意力网络来学习有效的时空表示。实验结果表明，AGTCNet在多个数据集上均显著优于现有MI-EEG分类器，取得了最先进的性能，同时具有更小的模型尺寸和更快的推理速度，证明了其在BCI应用中的有效性和实用性。

> **摘要翻译:** 利用脑电图（EEG）的脑机接口（BCI）技术标志着一项变革性创新，使运动障碍个体能够平等地与环境互动。尽管其潜力巨大，但由于个体间和时间上的神经活动固有的复杂性和变异性，以及脑电图硬件的限制，开发主体不变和会话不变的BCI系统仍然是一个重大挑战。虽然先前的研究试图开发鲁棒的BCI系统，但现有方法在捕捉多通道脑电图信号中复杂的时空依赖方面仍然无效。本研究通过引入注意力图时域卷积网络（AGTCNet）解决了这一空白，AGTCNet是一种用于运动想象脑电图（MI-EEG）分类的新颖图时域模型。具体而言，AGTCNet利用脑电图电极的地形配置作为归纳偏置，并整合图卷积注意力网络（GCAT）以共同学习富有表现力的时空脑电图表示。所提出的模型显著优于现有MI-EEG分类器，实现了最先进的性能，同时采用了紧凑的架构，突显了其在BCI部署中的有效性和实用性。通过将模型尺寸减小49.87%，推理时间加快64.65%，以及更短的输入脑电图信号，AGTCNet在BCI Competition IV Dataset 2a上实现了主体独立分类的移动平均准确率为66.82%，当针对主体特定分类进行微调时，准确率进一步提高到82.88%。在EEG Motor Movement/Imagery Dataset上，AGTCNet在4类和2类主体独立分类中分别达到了64.14%和85.22%的移动平均准确率，对于主体特定分类，准确率进一步提高到72.13%和90.54%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [262] [Demystifying Distributed Training of Graph Neural Networks for Link Prediction](https://arxiv.org/abs/2506.20818)
> *揭秘用于链接预测的图神经网络分布式训练*

*Xin Huang, Chul-Ho Lee* | **Category: cs.LG**

**Keywords:** 图神经网络, 分布式训练, 链接预测, 图稀疏化, 性能下降

**Comment:** Accepted by IEEE ICDCS 2025

> **TL;DR:** 本文揭示了分布式图神经网络在链接预测中性能下降的原因，并提出了SpLPG方法，通过图稀疏化有效降低通信成本并保持预测精度。

**AI_Comments:** 本文深入分析了分布式GNN在链接预测中特有的性能下降问题，并提出了创新的图稀疏化方法SpLPG来解决通信开销与准确性之间的平衡。其贡献在于不仅揭示了问题根源（信息丢失和负采样），还提供了一个实用的、高效的解决方案，对大规模图数据上的链接预测任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分布式图神经网络框架大多针对节点分类进行优化，而其在链接预测任务上的性能尚未得到充分探索。当每个工作节点在没有完整图访问权限的情况下，仅在其分配的子图上训练GNN时，会遇到性能下降的问题。

**Method:** 本文首先研究了分布式GNN训练中链接预测性能下降的问题，发现其主要原因不仅包括图划分导致的信息丢失，还包括负样本的抽取方式。为了解决这个问题，本文提出了SpLPG方法，该方法有效利用图稀疏化来缓解性能下降问题，同时降低了通信成本。

**Result:** 在多个公共真实世界数据集上的实验结果表明，SpLPG方法有效降低了高达约80%的通信开销，同时基本保持了链接预测的准确性。

**Conclusion:** 通过揭示分布式GNN在链接预测中性能下降的原因，并提出SpLPG方法，本文成功地在保持链接预测准确性的同时，显著降低了分布式训练的通信成本。

> **ai_Abstract:** 本文探讨了分布式图神经网络（GNNs）在链接预测任务中遇到的性能下降问题。研究发现，性能下降主要源于图划分导致的信息丢失以及负样本抽取方式。虽然共享完整图信息可保持准确性，但通信成本高昂。为此，文章提出了SpLPG方法，该方法利用图稀疏化有效缓解了性能下降，同时显著降低了通信开销，在实验中将通信量减少了约80%并基本保持了链接预测的准确性。

> **摘要翻译:** 图神经网络（GNN）是解决图相关问题的强大工具。分布式GNN框架和系统增强了GNN的可扩展性并加速了模型训练，但大多数都针对节点分类进行了优化。它们在链接预测上的性能仍未得到充分探索。本文通过研究当每个工作节点在没有访问整个图的情况下，在其分配的子图上训练GNN时出现的性能下降问题，揭示了用于链接预测的GNN分布式训练。我们发现，该问题的主要来源不仅来自图划分造成的信息丢失，还来自模型训练过程中负样本的抽取方式。虽然与每个工作节点共享完整的图信息可以解决该问题并保持链接预测的准确性，但这会产生高昂的通信成本。我们提出了SpLPG，它有效地利用图稀疏化来缓解性能下降问题，同时降低了通信成本。在多个公共真实世界数据集上的实验结果表明了SpLPG的有效性，它将通信开销降低了约80%，同时基本保持了链接预测的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [263] [Towards an Optimal Control Perspective of ResNet Training](https://arxiv.org/abs/2506.21453)
> *ResNet训练的最优控制视角*

*Jens Püttschneider, Simon Heilig, Asja Fischer, Timm Faulwasser* | **Category: cs.LG, cs.SY, eess.SY, math.OC**

**Keywords:** ResNet, 最优控制, 层剪枝, 训练动态, 深度学习

**Comment:** Accepted for presentation at the High-dimensional Learning Dynamics
  (HiLD) workshop at ICML 2025

> **TL;DR:** 该论文提出了一种将ResNet训练视为最优控制问题的新方法，能够使不必要的深层权重消失，为理论驱动的层剪枝提供了潜力。

**AI_Comments:** 该论文的创新之处在于将ResNet训练置于最优控制的框架下，这为理解和潜在改进网络架构，特别是在层剪枝方面，提供了理论基础。这种方法提供了一种超越经验剪枝方法的新颖视角。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为ResNet训练提出一种反映最优控制问题的公式，该公式适用于标准架构和通用损失函数，并有望实现基于理论的层剪枝策略。

**Method:** 提出了一种反映最优控制问题的ResNet训练公式。通过惩罚隐藏状态的中间输出来连接ResNet训练与最优控制，这些中间输出对应于最优控制中的阶段成本项。对于标准ResNet，中间输出通过后续的跳跃连接和输出层传播状态来获得。

**Result:** 训练动态促使不必要的更深残差层的权重消失。

**Conclusion:** 权重消失的现象表明了开发理论基础层剪枝策略的潜力。

> **ai_Abstract:** 本文提出了一种将ResNet训练表述为最优控制问题的新颖方法。通过将中间隐藏状态的输出作为阶段成本进行惩罚，所提出的训练动态使得不必要的深层残差层权重消失，这为开发一种具有理论基础的层剪枝策略提供了可能性。

> **摘要翻译:** 我们提出了一种ResNet训练公式，它反映了一个适用于标准架构和通用损失函数的最优控制问题。我们建议通过惩罚对应于最优控制中阶段成本项的隐藏状态的中间输出来连接这两个领域。对于标准ResNet，我们通过将状态通过后续的跳跃连接和输出层传播来获得中间输出。我们证明了我们的训练动态偏向于使不必要的更深残差层的权重消失。这表明了理论基础层剪枝策略的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [269] [Learning-Based Resource Management in Integrated Sensing and Communication Systems](https://arxiv.org/abs/2506.20849)
> *集成感知与通信系统中基于学习的资源管理*

*Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney* | **Category: cs.LG**

**Keywords:** 集成感知与通信, 资源管理, 深度强化学习, 时间分配, 雷达通信

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的约束深度强化学习（CDRL）方法，用于优化集成感知与通信系统中雷达跟踪与数据传输之间的时间分配，以提高通信质量。

**AI_Comments:** 本文的创新点在于将约束深度强化学习应用于集成感知与通信系统中的时间资源管理问题，有效地平衡了雷达跟踪和数据传输的需求。这种方法有望在未来动态和资源受限的通信系统中发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 在集成感知与通信系统中，需要解决自适应时间分配的任务，特别是在雷达和通信单元之间。目标是优化跟踪和通信之间的资源分配，以在时间预算限制下增强目标通信质量。

**Method:** 本文引入了一种新颖的约束深度强化学习（CDRL）方法，旨在优化在时间预算约束下跟踪和通信之间的资源分配。

**Result:** 数值结果表明，所提出的CDRL框架是有效的，并证实了它在高度动态环境中遵守时间限制的同时最大化通信质量的能力。

**Conclusion:** 所提出的CDRL框架能够有效地在集成感知与通信系统中，在时间约束下最大化通信质量，从而优化雷达跟踪与数据传输的资源分配。

> **ai_Abstract:** 本研究提出了一种创新的约束深度强化学习（CDRL）方法，以解决集成感知与通信系统中的自适应时间分配问题。该方法旨在优化雷达跟踪和数据传输之间的时间资源分配，确保在时间预算限制下最大限度地提高目标通信质量。数值结果验证了该CDRL框架的有效性，证明了其在动态环境中实现高效资源管理和提升通信性能的能力。

> **摘要翻译:** 在本文中，我们解决了配备雷达和通信单元的集成感知与通信系统中的自适应时间分配任务。双功能雷达通信系统的任务涉及为跟踪多个目标分配驻留时间，并利用剩余时间向估计的目标位置进行数据传输。我们引入了一种新颖的约束深度强化学习（CDRL）方法，旨在优化在时间预算约束下跟踪和通信之间的资源分配，从而提高目标通信质量。我们的数值结果证明了我们提出的CDRL框架的效率，证实了它在高度动态环境中遵守时间限制的同时最大化通信质量的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [275] [Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management](https://arxiv.org/abs/2506.20853)
> *认知雷达资源管理中的多目标强化学习*

*Ziyang Lu, Subodh Kalia, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney* | **Category: cs.LG, eess.SP**

**Keywords:** 认知雷达, 多目标强化学习, 时间分配, 帕累托优化, 深度强化学习

**Comment:** 

> **TL;DR:** 该研究将认知雷达时间分配问题建模为多目标优化问题，并使用深度强化学习（DDPG和SAC）寻找帕累托最优解，发现SAC在稳定性方面优于DDPG，并利用NSGA-II估计帕累托前沿。

**AI_Comments:** 这项工作创新性地将多目标强化学习应用于认知雷达资源管理，解决了扫描和跟踪之间的权衡问题。通过比较DDPG和SAC算法，并指出SAC的优势，为实际系统部署提供了有价值的参考。结合NSGA-II估计帕累托前沿，进一步增强了解决方案的理论完整性。

<details>
  <summary>Details</summary>

**Motivation:** 解决多功能认知雷达系统中时间分配问题，即在扫描新目标和跟踪已检测目标之间进行权衡。

**Method:** 将问题表述为多目标优化问题，并采用深度强化学习方法（DDPG和SAC算法）寻找帕累托最优解。此外，使用NSGA-II算法估计帕累托前沿的上限。

**Result:** 两种算法（DDPG和SAC）在适应不同场景方面均有效，其中SAC在稳定性和样本效率方面优于DDPG。

**Conclusion:** 本工作有助于开发更高效、自适应的认知雷达系统，这些系统能够在动态环境中平衡多个相互竞争的目标。

> **ai_Abstract:** 本文研究了多功能认知雷达系统中的时间分配问题，将其建模为多目标优化问题，并利用深度强化学习（DDPG和SAC）寻找帕累托最优解。研究发现SAC算法在稳定性与样本效率上优于DDPG。此外，本文还使用NSGA-II算法估算了帕累托前沿的上限，旨在开发更高效、自适应的认知雷达系统。

> **摘要翻译:** 多功能认知雷达系统中的时间分配问题侧重于新出现目标的扫描与先前检测目标的跟踪之间的权衡。我们将此问题表述为多目标优化问题，并采用深度强化学习来寻找帕累托最优解，并比较了深度确定性策略梯度（DDPG）和软行动者-评论家（SAC）算法。我们的结果表明，两种算法在适应各种场景方面均有效，其中SAC与DDPG相比，显示出更高的稳定性和样本效率。我们进一步采用NSGA-II算法来估计所考虑问题的帕累托前沿的上限。这项工作有助于开发更高效、自适应的认知雷达系统，这些系统能够在动态环境中平衡多个相互竞争的目标。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [283] [Omniwise: Predicting GPU Kernels Performance with LLMs](https://arxiv.org/abs/2506.20886)
> *Omniwise：使用大型语言模型预测GPU核性能*

*Zixian Wang, Cole Ramos, Muhammad A. Awad, Keith Lowery* | **Category: cs.LG, cs.AI**

**Keywords:** GPU性能预测, 大型语言模型, Omniwise, 性能分析, 深度学习

**Comment:** 

> **TL;DR:** Omniwise利用大型语言模型（LLMs）无需执行代码即可预测GPU核性能，准确率高，且轻量级。

**AI_Comments:** 本文创新性地将LLMs应用于GPU性能预测，提供了一种无需代码执行的轻量级解决方案，显著提高了性能分析的效率和可访问性。其模型无关的特性和高精度是其重要亮点，同时提供的开发工具也极大地方便了实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络(DNNs)的快速发展需要高效的GPU性能，但现有的性能分析方法可能需要代码执行或特定工具。本文旨在提供一种新的、无需执行的预测方法。

**Method:** 本文引入了Omniwise，这是首个端到端、自监督的微调管道，将大型语言模型（LLMs）应用于GPU核性能预测。Omniwise模型无关且轻量级，即使使用小型3B参数模型也能获得良好结果。它能够直接从核代码预测关键性能指标，如内存带宽、缓存命中率、GFLOPs和算术强度，而无需代码执行或使用分析工具。

**Result:** Omniwise在AMD MI250和MI300X架构上对GPU核的预测，有超过90%的预测在10%相对误差范围内。此外，还开发了在线推理服务器和Visual Studio Code插件，将基于LLM的性能预测无缝集成到开发人员的工作流程中。

**Conclusion:** Omniwise提供了一种高效、准确且易于集成的GPU核性能预测新方法，通过利用大型语言模型显著简化了开发者的工作流程，无需代码执行即可获得关键性能指标。

> **ai_Abstract:** Omniwise是一个创新的端到端、自监督微调管道，首次将大型语言模型（LLMs）应用于GPU核性能预测。该系统无需代码执行或分析工具，可直接从核代码预测内存带宽、缓存命中率等关键性能指标。Omniwise模型无关且轻量级，即使小型模型也能在AMD GPU上实现超过90%的预测在10%相对误差内的准确率。此外，还提供了在线推理服务器和VS Code插件以方便集成到开发工作流中。

> **摘要翻译:** 近年来，深度神经网络（DNNs）的快速发展彻底改变了人工智能，使模型在理解、生成和处理复杂数据方面具备了前所未有的能力。这些强大的架构已经改变了广泛的下游应用，解决了人类难以企及的任务。在本文中，我们介绍了Omniwise，这是第一个端到端、自监督的微调管道，将大型语言模型（LLMs）应用于GPU核性能预测——这是性能分析领域的一个新颖用例。Omniwise是模型无关且轻量级的，即使使用小型3B参数模型也能取得显著成果。它可以直接从核代码预测关键性能指标，包括内存带宽、缓存命中率、GFLOPs和算术强度，无需代码执行或分析工具。我们的方法在AMD MI250和MI300X架构上执行的GPU核上，实现了超过90%的预测在10%相对误差范围内。除了该管道，我们还开发了一个在线推理服务器和一个Visual Studio Code插件，将基于LLM的性能预测无缝集成到开发人员的工作流程中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [286] [On the Necessity of Output Distribution Reweighting for Effective Class Unlearning](https://arxiv.org/abs/2506.20893)
> *论输出分布重新加权对于有效类别遗忘的必要性*

*Yian Wang, Ali Ebrahimpour-Boroojeny, Hari Sundaram* | **Category: cs.LG**

**Keywords:** 类别遗忘, 输出重加权, 成员推断攻击, 模型隐私, RWFT

**Comment:** 

> **TL;DR:** 本文提出了一种名为RWFT的轻量级输出重加权遗忘方法，用于在不进行完全重新训练的情况下从分类器中删除整个类别。该方法通过重新分配被遗忘类别的预测概率质量来抵御成员推断攻击，并在实验中表现出与完全重新训练相当的性能，并显著优于现有最先进方法。

**AI_Comments:** 该论文的创新点在于提出了输出分布重新加权这一概念，并设计了RWFT方法来解决现有类别遗忘技术在隐私（抵抗成员推断攻击）和有效性（复制完全重新训练行为）方面的不足。引入新的TV距离度量也为评估遗忘效果提供了更严格的标准。其重要性体现在为实现“被遗忘权”提供了高效且鲁棒的解决方案，对负责任的AI发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了执行用户删除权和减轻有害或有偏见的预测，从训练好的模型中遗忘特定类别至关重要。完全重新训练成本高昂，而现有遗忘方法在预测来自被遗忘类别的样本时无法复制重新训练模型的行为，并且容易受到一种新的成员推断攻击（MIA-NN）的揭露。

**Method:** 本文提出了一种输出重加权遗忘方法RWFT，它是一种轻量级技术，无需完全重新训练即可从训练好的分类器中擦除整个类别。该方法通过简单地重新分配被遗忘类别样本的预测概率质量来抵御MIA-NN攻击。此外，还引入了一种基于总变异（TV）距离的新度量来量化残余泄漏。

**Result:** 通过与最先进的机器学习遗忘基线进行广泛实验，RWFT在先前用于评估的指标和本文提出的新指标上都与完全重新训练的结果相匹配。与最先进的方法相比，RWFT在先前使用的指标上提高了2.79%，在我们新的基于TV的指标上比现有最佳方法提高了111.45%。

**Conclusion:** 本文证明了输出分布重新加权对于有效类别遗忘的必要性，因为它可以抵御成员推断攻击并达到与完全重新训练相当的性能。

> **ai_Abstract:** 本文提出了一种名为RWFT的轻量级输出重加权遗忘方法，旨在有效从训练好的分类器中移除特定类别，以应对用户数据删除权和模型偏见问题。针对现有遗忘方法无法完全消除被遗忘类别信息，且易受新型成员推断攻击（MIA-NN）的挑战，RWFT通过重新分配被遗忘类别的预测概率质量来增强鲁棒性。同时，引入了一种基于总变异距离的新度量来量化遗忘效果。实验结果表明，RWFT在性能上与完全重新训练相当，并在多个指标上显著优于现有最先进的遗忘方法。

> **摘要翻译:** 在这项工作中，我们引入了一种输出重加权遗忘方法RWFT，这是一种轻量级技术，可以在不进行完全重新训练的情况下从训练好的分类器中擦除整个类别。从训练好的模型中遗忘特定类别对于执行用户删除权和减轻有害或有偏见的预测至关重要。完全重新训练成本高昂，而现有遗忘方法在预测来自被遗忘类别的样本时无法复制重新训练模型的行为。我们通过设计一种成员推断攻击的变体MIA-NN来证明这种失败，该攻击能够成功揭示任何这些方法的被遗忘类别。我们提出了一种简单的概率质量重新分配方案，用于被遗忘类别样本的预测，该方案对MIA-NN具有鲁棒性。我们还引入了一种基于总变异（TV）距离的预测概率新度量，以量化残余泄漏，从而防止未来的方法易受新攻击的影响。通过与最先进的机器学习遗忘基线进行广泛实验，我们表明我们的方法在先前工作用于评估的指标和我们在这项工作中提出的新指标上都与完全重新训练的结果相匹配。与最先进的方法相比，我们在先前使用的指标上获得了2.79%的提升，在我们新的基于TV的指标上比现有最佳方法获得了111.45%的提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [290] [Graph-Structured Feedback Multimodel Ensemble Online Conformal Prediction](https://arxiv.org/abs/2506.20898)
> *图结构反馈多模型集成在线共形预测*

*Erfan Hajihashemi, Yanning Shen* | **Category: cs.LG**

**Keywords:** 在线共形预测, 多模型集成, 图结构反馈, 预测集, 模型选择

**Comment:** 

> **TL;DR:** 提出了一种基于图结构反馈的新型多模型在线共形预测算法，能动态选择有效模型子集，以降低计算复杂度和生成更小的预测集，同时保持覆盖率。

**AI_Comments:** 这篇论文通过引入图结构反馈机制，创新性地解决了多模型在线共形预测中模型选择和效率的痛点。将预测集大小作为反馈信号，是提高算法效率的一个重要且实用的贡献。这种动态模型选择方法有望在实际应用中显著提升在线预测的性能和资源利用率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模型在线共形预测在处理分布偏移时，其预选模型集的选择面临挑战：模型数量过多会导致计算复杂性增加，而包含不相关模型则会负面影响性能并导致预测集过大。

**Method:** 提出了一种新颖的多模型在线共形预测算法。该算法通过从二分图中收集反馈来识别每个时间步的有效模型子集，该图会随着新数据的接收而细化。然后从该子集中选择一个模型来构建预测集。此外，除了模型损失外，还将预测集大小作为反馈来显著提高效率。

**Result:** 提出的算法能够构建更小的预测集，并被证明能确保有效的覆盖率并实现次线性遗憾。在真实和合成数据集上的实验验证了所提方法优于现有的多模型在线共形预测方法。

**Conclusion:** 本文提出了一种创新的图结构反馈多模型在线共形预测算法，有效解决了现有方法在计算复杂性和预测集大小方面的挑战，同时保证了预测的有效性和效率。

> **ai_Abstract:** 本文提出了一种新型的多模型在线共形预测算法，旨在解决现有方法中因模型集过大或包含不相关模型而导致的计算复杂性高和预测集过大的问题。该算法利用图结构反馈动态识别有效模型子集，并选择其中一个模型来构建预测集。通过将预测集大小作为额外反馈，进一步提高了效率。实验证明，该方法在保持有效覆盖率和次线性遗憾的同时，能生成更小的预测集，并优于现有方法。

> **摘要翻译:** 在线共形预测已证明其能够为每个传入数据点构建一个预测集，该预测集以预定概率覆盖真实标签。为了应对潜在的分布偏移，引入了多模型在线共形预测，用于从预选的候选集中选择和利用不同的模型。在提高灵活性的同时，预选集的选择也带来了挑战。包含大量模型的候选集可能会增加计算复杂性。此外，包含性能不佳的不相关模型可能会对性能产生负面影响，并导致不必要的过大预测集。为了解决这些挑战，我们提出了一种新颖的多模型在线共形预测算法，该算法通过从二分图中收集反馈来识别每个时间步的有效模型子集，该图在接收新数据时会进行细化。然后从该子集中选择一个模型来构建预测集，从而降低了计算复杂性并减小了预测集。此外，我们证明了将预测集大小作为反馈，以及模型损失，可以通过构建更小的预测集来显著提高效率，同时仍满足所需的覆盖保证。所提出的算法被证明能够确保有效的覆盖率并实现次线性遗憾。在真实和合成数据集上的实验验证了所提出的方法构建了更小的预测集，并且优于现有的多模型在线共形预测方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [296] [Explainable AI for Radar Resource Management: Modified LIME in Deep Reinforcement Learning](https://arxiv.org/abs/2506.20916)
> *雷达资源管理的可解释人工智能：深度强化学习中的改进LIME*

*Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney* | **Category: cs.LG**

**Keywords:** 深度强化学习, 可解释人工智能, LIME, 雷达资源管理, DL-LIME

**Comment:** 

> **TL;DR:** 本文提出了一种名为DL-LIME的改进LIME方法，通过将深度学习集成到采样过程中，提高了雷达资源管理中深度强化学习的可解释性、保真度和任务性能。

**AI_Comments:** 本文的创新点在于提出了DL-LIME，通过将深度学习引入LIME的采样过程，解决了传统LIME在处理特征相关性方面的不足。这对于提高深度强化学习在实际应用中（如雷达资源管理）的透明度和可信度具有重要意义。该方法不仅提升了解释的准确性，还改善了模型的任务性能，为“黑箱”模型的解释提供了一个有效且实用的途径。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习在雷达资源管理等决策过程中表现出色，但其“黑箱”性质限制了对其决策原理的理解。现有的可解释人工智能（XAI）方法LIME在采样过程中忽略了特征之间的相关性。

**Method:** 本文提出了一种名为DL-LIME的改进LIME方法，该方法将深度学习（DL）集成到LIME的采样过程中。研究人员将DL-LIME应用于深度强化学习的雷达资源管理任务中。

**Result:** 数值结果表明，DL-LIME在保真度和任务性能方面均优于传统的LIME方法。DL-LIME还能揭示雷达资源管理决策中哪些因素更为重要。

**Conclusion:** DL-LIME通过改进LIME的采样过程，成功提高了深度强化学习在雷达资源管理中决策的可解释性和性能，为理解“黑箱”模型提供了有效工具。

> **ai_Abstract:** 本文针对深度强化学习在雷达资源管理中“黑箱”决策的局限性，提出了一种改进的LIME方法——DL-LIME。DL-LIME通过将深度学习融入LIME的采样过程，有效解决了传统LIME忽略特征相关性的问题。实验结果表明，DL-LIME在提高解释的保真度和任务性能方面均优于传统LIME，并能揭示雷达资源管理决策中的关键影响因素，从而增强了深度强化学习的可解释性。

> **摘要翻译:** 深度强化学习在决策过程中得到了广泛研究，并在包括雷达资源管理（RRM）在内的各个领域中表现出优于传统方法的性能。然而，神经网络的一个显著局限性是其“黑箱”性质，最近的研究工作越来越关注可解释人工智能（XAI）技术，以描述神经网络决策背后的原理。一种有前景的XAI方法是局部可解释模型无关解释（LIME）。然而，LIME中的采样过程忽略了特征之间的相关性。在本文中，我们提出了一种改进的LIME方法，将深度学习（DL）集成到采样过程中，我们称之为DL-LIME。我们将DL-LIME应用于深度强化学习的雷达资源管理中。数值结果表明，DL-LIME在保真度和任务性能方面均优于传统的LIME，在两项指标上都表现出卓越的性能。DL-LIME还提供了关于哪些因素在雷达资源管理决策中更重要的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [301] [Interpretable Representation Learning for Additive Rule Ensembles](https://arxiv.org/abs/2506.20927)
> *可解释的加性规则集成表示学习*

*Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley* | **Category: cs.LG, cs.AI**

**Keywords:** 可解释性, 规则集成, 稀疏线性变换, 模型复杂度, 梯度提升

**Comment:** 

> **TL;DR:** 本文通过引入可学习的稀疏线性变换，扩展了传统规则集成，使其能处理倾斜决策区域，从而在保持相同预测风险的同时显著降低模型复杂度。

**AI_Comments:** 这篇论文通过引入可学习的稀疏线性变换，创新性地解决了传统规则集成模型在特征不足时可解释性下降的问题。其核心贡献在于将轴平行决策边界扩展为倾斜边界，从而在不牺牲准确性的前提下显著简化了模型。这种方法对于需要高度可解释性但数据特征不尽理想的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的加性规则集成模型虽然可解释，但其基于单变量阈值的方法（轴平行多面体）依赖于高质量的输入特征。如果缺乏此类特征，为达到足够的准确性就需要增加规则的数量和复杂性，从而损害模型的可解释性。

**Method:** 提出了一种扩展经典规则集成的方法，引入了带有可学习稀疏线性变换的逻辑命题，即形式为 $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$ 的命题，从而实现具有倾斜面的更通用多面体决策区域。学习方法采用基于迭代重加权逻辑回归的序列贪婪优化。

**Result:** 实验结果表明，所提出的方法能够高效地构建规则集成，在十个基准数据集上达到与最新技术方法相同的测试风险，同时显著降低了模型复杂性。

**Conclusion:** 通过引入可学习的稀疏线性变换，本方法能够构建出在保持预测性能的同时，模型复杂度显著降低的可解释规则集成。

> **ai_Abstract:** 本文针对传统加性规则集成在缺乏高质量特征时可解释性下降的问题，提出了一种新的方法。该方法通过引入带有可学习稀疏线性变换的逻辑命题，使得决策区域能够形成具有倾斜面的通用多面体。采用基于迭代重加权逻辑回归的序列贪婪优化进行学习。实验证明，该方法在保持与现有技术相当的预测性能的同时，显著降低了模型复杂度，提升了模型的可解释性。

> **摘要翻译:** 加性符号规则的小型集成提供了可解释的预测模型。传统上，这些集成使用基于单个输入变量 $x$ 和阈值 $t$ 的简单阈值命题 $x \geq t$ 的合取规则条件，几何上导致决策区域为轴平行多面体。虽然这种形式确保了单个规则的高度可解释性，并且可以使用梯度提升方法高效学习，但它依赖于访问一组经过精心策划的、表达能力强且理想情况下独立的输入特征，以便少量轴平行区域的集成能够很好地描述目标变量。在缺乏此类特征的情况下，达到足够的准确性需要增加单个规则的数量和复杂性，这会降低模型的可解释性。
本文通过引入带有可学习稀疏线性变换的输入变量的逻辑命题，即形式为 $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$ 的命题，扩展了经典规则集成，其中 $\mathbf{w}$ 是一个可学习的稀疏权重向量，从而使决策区域成为具有倾斜面的通用多面体。我们提出了一种基于迭代重加权逻辑回归的序列贪婪优化学习方法。实验结果表明，所提出的方法能够高效地构建规则集成，在十个基准数据集上达到与最新技术方法相同的测试风险，同时显著降低了模型复杂性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [303] [Model State Arithmetic for Machine Unlearning](https://arxiv.org/abs/2506.20941)
> *模型状态算术用于机器遗忘*

*Keivan Rezaei, Mehrdad Saberi, Abhilasha Ravichander, Soheil Feizi* | **Category: cs.LG**

**Keywords:** 机器遗忘, 大型语言模型, 模型检查点, 数据擦除, MSA

**Comment:** Preprint. Work in progress

> **TL;DR:** 本文提出了一种名为MSA的新算法，通过利用模型检查点来估计和消除数据点的影响，从而实现高效的机器遗忘，并优于现有算法。

**AI_Comments:** 这项工作在机器遗忘领域具有重要意义，特别是在大型语言模型背景下。其创新点在于利用模型检查点来解决传统重新训练成本高昂的问题，提供了一种更高效、更具可扩展性的数据擦除方法。MSA的提出有望促进更符合隐私、版权和数据质量要求的大模型的开发。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在大量网络数据上训练，可能包含隐私、版权、不准确或降低性能的数据。通过完全重新训练来消除这些问题数据点的影响计算成本过高，因此需要低成本的遗忘算法。

**Method:** 本文提出了一种新的算法MSA（Model State Arithmetic），通过利用模型检查点（即捕获预训练不同阶段模型状态的工件）来估计和消除数据点的影响。

**Result:** 实验结果表明，MSA在多个基准、模型和评估指标上始终优于现有的机器遗忘算法。

**Conclusion:** MSA可以成为一种有效的方法，实现更灵活、能够进行数据擦除的大型语言模型。

> **ai_Abstract:** 本文针对大型语言模型中移除问题数据的挑战，提出了一种名为MSA的新型机器遗忘算法。该算法通过利用模型预训练过程中的检查点来高效地估计并消除特定数据点的影响。实验证明，MSA在多个场景下均优于现有遗忘算法，为实现可数据擦除的灵活大模型提供了有效途径。

> **摘要翻译:** 大型语言模型在海量网络数据语料库上进行训练，其中可能包含私人数据、受版权保护的材料、事实不准确的数据或降低模型性能的数据。通过完全重新训练（即在排除这些特定实例的数据集上重复预训练模型）来消除此类问题数据点的影响，计算成本过高。因此，出现了旨在消除特定数据点影响，同时以低计算成本保留模型的遗忘算法。然而，精确估计和消除单个数据点的影响已被证明具有挑战性。在这项工作中，我们提出了一种新的算法MSA，通过利用模型检查点（即捕获预训练不同阶段模型状态的工件）来估计和消除数据点的影响。我们的实验结果表明，MSA在多个基准、模型和评估指标上始终优于现有的机器遗忘算法，这表明MSA可能是一种有效的方法，有助于实现更灵活、能够进行数据擦除的大型语言模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [306] [Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding](https://arxiv.org/abs/2506.20957)
> *抗体设计与优化：基于多尺度等变图扩散模型实现精准复杂抗原结合*

*Jiameng Chen, Xiantao Cai, Jia Wu, Wenbin Hu* | **Category: cs.LG, cs.AI, I.2.6; I.2.1; J.3**

**Keywords:** 抗体设计, 等变图扩散, 多尺度, 序列-结构协同设计, 抗原结合

**Comment:** 9 pages, 4 figures, accepted at IJCAI 2025

> **TL;DR:** AbMEGD是一种基于多尺度等变图扩散的抗体设计新模型，显著提高了复杂抗原结合的准确性和功能性，优于现有方法。

**AI_Comments:** AbMEGD的创新在于其多尺度等变图扩散方法，结合了原子级和残基级信息，并引入了E(3)-等变性，这对于确保几何精度和泛化能力至关重要，特别是在复杂抗原结合方面。相对于领先模型的定量改进突显了其在治疗和诊断开发中的实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的计算抗体设计方法在捕获几何特征、保持对称性以及泛化到新型抗原界面方面存在局限性，导致难以准确捕获分子相互作用并维持结构完整性。

**Method:** 本文提出了AbMEGD，一个端到端的框架，整合了多尺度等变图扩散（Multi-scale Equivariant Graph Diffusion）用于抗体序列和结构协同设计。它结合了原子级几何特征和残基级嵌入，并采用E(3)-等变扩散方法，以确保几何精度、计算效率和鲁棒的泛化能力。

**Result:** 与领先的抗体设计模型DiffAb相比，AbMEGD在SAbDab数据库上的实验表明，氨基酸恢复率提高了10.13%，改进百分比提高了3.32%，关键CDR-H3区域的均方根偏差降低了0.062 Å。

**Conclusion:** AbMEGD成功平衡了结构完整性与功能性提升，为抗体序列-结构协同设计和亲和力优化建立了新的基准。

> **ai_Abstract:** 本文介绍了AbMEGD，一个利用多尺度等变图扩散的端到端新框架，用于抗体序列和结构协同设计。它通过结合原子级几何特征与残基级嵌入，并采用E(3)-等变扩散方法，解决了现有方法的局限性。AbMEGD表现出优于现有模型（如DiffAb）的性能，在氨基酸恢复率、改进百分比和RMSD方面取得了显著提升，从而为抗体设计和亲和力优化设定了新标准。

> **摘要翻译:** 抗体设计仍然是治疗和诊断开发中的一个关键挑战，特别是对于具有多样结合界面的复杂抗原。当前的计算方法面临两个主要限制：(1) 在保留对称性的同时捕获几何特征，以及 (2) 泛化到新的抗原界面。尽管最近取得了进展，但这些方法往往无法准确捕获分子相互作用并保持结构完整性。为了解决这些挑战，我们提出了 AbMEGD，这是一个端到端框架，整合了Multi-scale Equivariant Graph Diffusion（多尺度等变图扩散）用于抗体序列和结构协同设计。AbMEGD 利用先进的几何深度学习，将原子级几何特征与残基级嵌入相结合，捕获局部原子细节和全局序列-结构相互作用。其 E(3)-等变扩散方法确保了几何精度、计算效率以及对复杂抗原的鲁棒泛化能力。此外，使用 SAbDab 数据库进行的实验表明，与领先的抗体设计模型 DiffAb 相比，AbMEGD 在关键的 CDR-H3 区域内氨基酸恢复率提高了 10.13%，改进百分比提高了 3.32%，均方根偏差降低了 0.062 Å。这些结果突显了 AbMEGD 在平衡结构完整性与提高功能性方面的能力，为序列-结构协同设计和亲和力优化建立了新的基准。代码可在以下网址获取：https://github.com/Patrick221215/AbMEGD。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [310] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
> *SharpZO：通过仅前向传播实现的混合锐度感知视觉语言模型提示微调*

*Yifan Yang, Zhen Zhang, Rupak Vignesh Swaminathan, Jing Liu, Nathan Susanj, Zheng Zhang* | **Category: cs.LG, cs.CL, cs.CV**

**Keywords:** 视觉语言模型, 零阶优化, 提示微调, 锐度感知, 仅前向传播

**Comment:** 

> **TL;DR:** SharpZO提出了一种混合锐度感知零阶优化方法，用于视觉语言模型提示微调，仅依靠前向传播，显著提高了精度和收敛速度，优于现有仅前向传播方法。

**AI_Comments:** SharpZO的创新之处在于其结合了锐度感知、演化策略和零阶优化，并实现了仅前向传播的微调，这对于边缘设备的应用具有重要意义。其两阶段优化策略能够有效平衡全局探索和局部优化，从而在无需梯度的前提下达到高性能。论文解决了VLM在资源受限环境下部署的关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型（VLM）微调方法需要通过反向传播（BP）获取模型梯度，这不适用于内存受限的推理专用边缘设备。虽然有无需BP的微调方法，但它们通常依赖于高方差的演化策略（ES）或零阶（ZO）优化，并且性能不尽如人意。

**Method:** 本文提出了一种混合锐度感知零阶优化（SharpZO）方法。它通过锐度感知热身训练来增强ZO VLM微调的性能。SharpZO包含两阶段优化过程：首先是锐度感知ES阶段，用于全局探索和平滑损失景观以构建强大的初始化；其次是通过稀疏ZO优化进行细粒度局部搜索。整个优化过程仅依赖于前向传播。

**Result:** SharpZO显著提高了精度和收敛速度，在CLIP模型上实现了比最先进的仅前向传播方法平均高达7%的增益。

**Conclusion:** SharpZO通过结合锐度感知演化策略和稀疏零阶优化，为内存受限的边缘设备提供了高效且高性能的视觉语言模型提示微调解决方案，仅依赖于前向传播。

> **ai_Abstract:** 本文提出了一种名为SharpZO的混合锐度感知零阶优化方法，旨在解决视觉语言模型在内存受限设备上微调时对反向传播的依赖问题。SharpZO通过一个锐度感知演化策略进行全局探索和初始化，随后进行稀疏零阶优化进行局部搜索，整个过程仅依赖于前向传播。实验证明，SharpZO显著提升了VLM微调的精度和收敛速度，相较于现有仅前向传播方法有显著性能提升。

> **摘要翻译:** 视觉语言模型（VLM）的微调在各种下游任务中取得了显著的性能；然而，它需要通过反向传播（BP）访问模型梯度，这使得它们不适用于内存受限、仅推理的边缘设备。为了解决这一限制，以前的工作探索了各种无需BP的微调方法。然而，这些方法通常依赖于高方差的演化策略（ES）或零阶（ZO）优化，并且往往无法达到令人满意的性能。在本文中，我们提出了一种混合锐度感知零阶优化（SharpZO）方法，专门设计用于通过锐度感知热身训练来提高ZO VLM微调的性能。SharpZO具有两阶段优化过程：一个锐度感知ES阶段，用于全局探索和平滑损失景观以构建强大的初始化，然后是通过稀疏ZO优化进行细粒度局部搜索。整个优化过程仅依赖于前向传播。详细的理论分析和对CLIP模型的广泛实验表明，SharpZO显著提高了精度和收敛速度，比最先进的仅前向传播方法平均提高了高达7%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [313] [Distilling Normalizing Flows](https://arxiv.org/abs/2506.21003)
> *蒸馏归一化流*

*Steven Walton, Valeriy Klyukin, Maksim Artemev, Denis Derkach, Nikita Orlov, Humphrey Shi* | **Category: cs.LG**

**Keywords:** 归一化流, 知识蒸馏, 生成模型, 密度估计, 模型压缩

**Comment:** Published in eLVM @ CVPR
  (https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Walton_Distilling_Normalizing_Flows_CVPRW_2025_paper)

> **TL;DR:** 本文提出了一种新的知识蒸馏技术，用于提高小型归一化流的采样质量和密度估计，发现蒸馏可以显著减小模型尺寸并提升性能和吞吐量。

**AI_Comments:** 这项工作通过引入知识蒸馏来解决归一化流的实际应用挑战，即模型复杂度和采样效率。其创新之处在于利用了归一化流的独特架构特性，允许在中间层进行知识转移，这为模型压缩和性能提升提供了一条新颖且有效的路径。

<details>
  <summary>Details</summary>

**Motivation:** 显式密度学习器（如归一化流）因其更好地建模概率分布的能力，在生成模型中越来越受欢迎，但它们通常难以训练且采样质量较低。本研究旨在通过知识蒸馏解决这些问题，以提高小型归一化流的性能。

**Method:** 提出了新颖的知识蒸馏技术，并将其应用于组合归一化流（Compositional Normalizing Flows），探索了归一化流的独特属性，允许在中间层进行知识转移。

**Result:** 通过知识蒸馏，学生模型可以显著减小尺寸，同时在性能上相比未蒸馏的学生模型有实质性提升。较小的模型由于网络中双射器（bijectors）和参数数量的减少，吞吐量也相应增加。

**Conclusion:** 知识蒸馏是一种有效的方法，可以使归一化流模型更小、更快，同时保持甚至提高其采样质量和密度估计能力，证明了其在归一化流架构中的潜力。

> **ai_Abstract:** 本文提出了一种针对归一化流的新型知识蒸馏方法，旨在解决其训练困难和采样质量低的缺点。研究发现，通过将知识从大型归一化流转移到小型学生模型，可以显著减小模型尺寸，同时大幅提高其采样质量和密度估计性能，并带来更高的吞吐量。这表明知识蒸馏是优化归一化流模型效率和性能的有效途径。

> **摘要翻译:** 显式密度学习器因其更好地建模概率分布的能力，正成为生成模型中越来越流行的技术。它们相对于生成对抗网络具有优势，因为它们能够执行密度估计并具有精确的潜在变量推断。这带来了许多优点，包括：能够简单地插值、计算样本似然和分析概率分布。这些模型的缺点是它们通常更难训练且采样质量较低。
归一化流是显式密度模型，它们使用可组合的双射函数将难以处理的概率函数转换为可处理的函数。在这项工作中，我们提出了新颖的知识蒸馏技术，以提高小型学生归一化流的采样质量和密度估计。我们旨在研究知识蒸馏在组合归一化流中的能力，以了解这些架构提供的优点和缺点。归一化流具有独特的特性，允许非传统的知识转移形式，我们可以在中间层转移知识。我们发现，通过这种蒸馏，我们可以使学生模型显著变小，同时相对于未蒸馏的学生模型取得实质性的性能提升。随着模型变小，吞吐量也成比例增加，因为这取决于网络中双射器（bijectors）的数量，从而取决于参数的数量。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [315] [Flow-Based Single-Step Completion for Efficient and Expressive Policy Learning](https://arxiv.org/abs/2506.21427)
> *基于流的单步完成，实现高效和富有表现力的策略学习*

*Prajwal Koirala, Cody Fleming* | **Category: cs.LG, cs.RO**

**Keywords:** 强化学习, 生成模型, 流匹配, 单步完成策略, 离线RL

**Comment:** 

> **TL;DR:** 提出SSCP，一种基于流匹配的生成策略，通过单步动作生成解决现有生成RL模型效率和稳定性问题，并在多种RL设置中表现出色。

**AI_Comments:** SSCP的创新点在于通过“单步完成”机制，巧妙地解决了生成模型在强化学习中迭代采样带来的效率和稳定性痛点。它在保持生成模型表达能力的同时，显著提升了推理速度和训练稳定性，这对于实际部署和应用具有重要意义。其在多种RL设置下的有效性和对目标条件RL的扩展，进一步展现了其通用性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型和流匹配等生成模型在离线强化学习中虽然能捕捉丰富、多模态的动作分布，但其迭代采样导致推理成本高昂，且由于跨采样步骤的梯度传播导致训练不稳定。

**Method:** 提出单步完成策略（SSCP），这是一种生成式策略，通过增强的流匹配目标进行训练，以从中间流样本预测直接完成向量，从而实现准确的单步动作生成。SSCP在离策略actor-critic框架中运行，结合了生成模型的表达能力与单模态策略的训练和推理效率，无需冗长的反向传播链。该方法还扩展到目标条件RL，使扁平策略能够利用子目标结构而无需显式分层推理。

**Result:** SSCP在速度和适应性方面比基于扩散的基线有显著提升，能有效扩展到离线、离线到在线以及在线RL设置。在标准离线RL和行为克隆基准测试中取得了优异的结果。

**Conclusion:** SSCP是一个多功能、富有表现力且高效的深度强化学习和序列决策框架。

> **ai_Abstract:** 本文提出单步完成策略（SSCP），旨在解决现有生成模型在离线强化学习中面临的推理效率低下和训练不稳定性问题。SSCP通过增强的流匹配目标进行训练，能够实现一次性、准确的动作生成。该策略在离策略actor-critic框架下运行，有效结合了生成模型的表达能力和单模态策略的效率。实验证明，SSCP在速度和适应性上优于扩散模型，并能有效应用于离线、离线到在线以及在线RL场景，甚至扩展到目标条件RL，在多个标准基准测试中表现出色，是一个多功能、高效的强化学习框架。

> **摘要翻译:** 扩散和流匹配等生成模型通过捕捉丰富、多模态的动作分布，为离线强化学习（RL）提供了富有表现力的策略，但其迭代采样引入了高昂的推理成本，并且由于跨采样步骤的梯度传播导致训练不稳定。我们提出了“单步完成策略”（SSCP），这是一种生成式策略，通过增强的流匹配目标进行训练，以从中间流样本预测直接完成向量，从而实现准确的单步动作生成。在离策略actor-critic框架中，SSCP结合了生成模型的表达能力与单模态策略的训练和推理效率，而无需冗长的反向传播链。我们的方法能有效扩展到离线、离线到在线以及在线RL设置，在速度和适应性方面比基于扩散的基线有显著提升。我们进一步将SSCP扩展到目标条件RL，使扁平策略能够利用子目标结构而无需显式分层推理。SSCP在标准离线RL和行为克隆基准测试中取得了优异的结果，使其成为深度RL和序列决策的多功能、富有表现力且高效的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [317] [TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence](https://arxiv.org/abs/2506.21028)
> *TRIDENT：结合分类学注释和局部对应关系的三模态分子表示学习*

*Feng Jiang, Mangal Prakash, Hehuan Ma, Jianyuan Deng, Yuzhi Guo, Amina Mollaysa, Tommaso Mansi, Rui Liao, Junzhou Huang* | **Category: cs.LG**

**Keywords:** 分子表示学习, 多模态学习, 分子性质预测, 分类学注释, 局部对应

**Comment:** 

> **TL;DR:** TRIDENT是一个新颖的框架，通过整合SMILES、文本描述和分类学功能注释，学习丰富的三模态分子表示，并在分子性质预测任务上实现了最先进的性能。

**AI_Comments:** TRIDENT的创新之处在于其三模态整合（SMILES、文本、分类学注释），以及提出的基于体积的全局对齐和局部对齐目标，超越了传统的对比学习，实现了更精细和全面的分子表示学习。其在多个下游任务上取得的SOTA性能证明了这种多源信息融合策略的有效性，为未来的分子表示学习提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的分子表示学习方法在多模态学习中忽视了分子的文本和分类学信息，限制了学习到的分子表示的丰富性。

**Method:** 论文提出了TRIDENT框架，整合分子SMILES、文本描述和分类学功能注释来学习分子表示。为此，作者收集了一个包含分子-文本对和结构化、多级功能注释的综合数据集。TRIDENT采用基于体积的全局对齐目标，实现跨模态的软、几何感知对齐，并引入了新颖的局部对齐目标来捕捉分子子结构及其对应子文本描述之间的关系。通过基于动量的机制动态平衡全局和局部对齐。

**Result:** TRIDENT在11个下游任务上取得了最先进的性能。

**Conclusion:** 结合SMILES、文本和分类学功能注释对于分子性质预测具有重要价值。

> **ai_Abstract:** 本文提出TRIDENT，一个用于分子表示学习的三模态框架，它创新性地整合了分子SMILES、文本描述和分类学功能注释。TRIDENT通过构建综合数据集，并采用独特的基于体积的全局对齐和局部对齐目标来捕捉不同粒度的跨模态关系。实验结果表明，TRIDENT在多项分子性质预测任务上达到了最先进的性能，突显了结合多源信息在分子表示学习中的重要性。

> **摘要翻译:** 分子性质预测旨在学习将化学结构映射到功能性质的表示。尽管多模态学习已成为学习分子表示的强大范式，但以往的工作在很大程度上忽视了分子的文本和分类学信息用于表示学习。我们引入了TRIDENT，一个新颖的框架，它整合了分子SMILES、文本描述和分类学功能注释来学习丰富的分子表示。为了实现这一点，我们整理了一个包含结构化、多级功能注释的分子-文本对的综合数据集。TRIDENT没有依赖传统的对比损失，而是采用基于体积的对齐目标，在全局层面联合对齐三模态特征，从而实现跨模态的软、几何感知对齐。此外，TRIDENT引入了一种新颖的局部对齐目标，捕捉分子子结构及其相应子文本描述之间的详细关系。基于动量的机制动态平衡全局和局部对齐，使模型能够学习广泛的功能语义和细粒度的结构-功能映射。TRIDENT在11个下游任务上取得了最先进的性能，证明了结合SMILES、文本和分类学功能注释对于分子性质预测的价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [320] [Little By Little: Continual Learning via Self-Activated Sparse Mixture-of-Rank Adaptive Learning](https://arxiv.org/abs/2506.21035)
> *循序渐进：通过自激活稀疏秩自适应学习的持续学习*

*Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong* | **Category: cs.LG**

**Keywords:** 持续学习, 专家混合, 低秩适应, 灾难性遗忘, 大型语言模型

**Comment:** Preprint

> **TL;DR:** 大型预训练模型的持续学习面临灾难性遗忘和任务干扰。现有方法存在干扰、冗余和路由模糊问题。本文提出MoRA，一种自激活稀疏秩自适应学习方法，将每个秩-r更新分解为r个秩-1组件作为独立专家，实现细粒度选择，并通过自推断相关性和剪枝预算来缓解干扰、冗余和路由模糊，有效提升持续学习性能。

**AI_Comments:** 本文的创新点在于提出了MoRA，一种细粒度的秩自适应学习方法，通过将高秩更新分解为多个独立的秩-1专家，并允许这些专家自适应地选择性激活。这解决了现有LoRA-based MoE方法在持续学习中面临的干扰、冗余和路由模糊等核心挑战。其重要性在于，通过更精细的知识表示和选择机制，有效提升了大型预训练模型在面对新任务时的泛化能力，并显著减轻了灾难性遗忘，为持续学习领域提供了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型预训练模型的持续学习（CL）面临灾难性遗忘和任务干扰的挑战。现有的基于LoRA的专家混合（MoE）方法通过分配和冻结任务特定适配器来缓解遗忘，但由于粗粒度的适配器级别选择，它们仍面临干扰、冗余和模糊路由的问题。具体而言，对每个输入激活完整的LoRA专家会导致子空间干扰，阻碍跨任务有用组件的选择性重用，并导致新添加的专家由于不必要的无关秩激活和相关秩的不足重用而重复或矛盾现有知识。此外，任务间重叠的特征会混淆路由器，导致专家分配不稳定，随着专家数量的积累，早期任务路由性能下降，加速遗忘。

**Method:** 本文提出MoRA，一种用于持续学习的自激活稀疏秩自适应学习方法。与混合多个低秩矩阵不同，MoRA将每个秩-r更新分解为r个秩-1组件，每个组件被视为一个独立的专家，从而实现秩-1专家的细粒度混合利用，同时缓解干扰和冗余。为了避免模糊路由，我们提出每个秩-1专家可以通过中间激活来推断其自身的相关性。结合我们提出的秩剪枝和激活预算，MoRA能够为每个输入自适应地选择稀疏的秩混合。

**Result:** MoRA在CLIP和大型语言模型（LLM）的持续学习任务中得到了验证，分析了微调过程中的域内学习和域外遗忘/泛化。MoRA在增强预训练模型的持续学习能力、提高泛化能力和减轻遗忘方面显示出显著的有效性。

**Conclusion:** MoRA通过引入一种细粒度、自激活和稀疏的秩自适应学习方法，有效地解决了大型预训练模型在持续学习中面临的挑战，从而改善了泛化能力并减少了遗忘。

> **ai_Abstract:** 本文提出MoRA，一种用于大型预训练模型持续学习的新方法，旨在解决现有LoRA-based MoE方法中的灾难性遗忘、任务干扰、冗余和路由模糊问题。MoRA将秩-r更新分解为独立的秩-1专家，实现细粒度的专家利用，并通过自激活和稀疏秩选择来缓解干扰和冗余。通过让每个秩-1专家推断自身相关性并结合秩剪枝和激活预算，MoRA有效地提高了持续学习的泛化能力并减轻了遗忘，在CLIP和大型语言模型上得到了验证。

> **摘要翻译:** 大型预训练模型（PTMs）的持续学习（CL）面临灾难性遗忘和任务干扰的挑战。现有的基于LoRA的专家混合（MoE）方法通过分配和冻结任务特定适配器来缓解遗忘，但由于粗粒度的适配器级别选择，它们仍面临干扰、冗余和模糊路由的问题。然而，这种设计引入了三个关键挑战：1）干扰：每个输入激活完整的LoRA专家会导致子空间干扰，并阻止跨任务有用组件的选择性重用。2）冗余：由于不必要的无关秩激活和相关秩的不足重用，新添加的专家通常会复制或矛盾现有知识。3）模糊性：任务间重叠的特征会混淆路由器，导致专家分配不稳定。随着更多专家的积累，早期任务路由性能下降，加速遗忘。我们提出了MoRA，一种具有自激活和稀疏秩激活的秩自适应学习方法，用于持续学习。与混合多个低秩矩阵不同，MoRA将每个秩-r更新分解为r个秩-1组件，每个组件被视为一个独立的专家，从而实现秩-1专家利用的细粒度混合，同时缓解干扰和冗余。为了避免模糊路由，我们提出每个秩-1专家可以通过中间激活来推断其自身的相关性。结合我们提出的秩剪枝和激活预算，MoRA能够为每个输入自适应地选择稀疏的秩混合。我们在使用CLIP和大型语言模型（LLMs）的持续学习任务上验证了MoRA，分析了微调过程中的域内学习和域外遗忘/泛化。MoRA在增强预训练模型的持续学习能力、提高泛化能力和减轻遗忘方面显示出显著的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [325] [RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment](https://arxiv.org/abs/2506.21037)
> *RL-Selector：基于强化学习和冗余评估的数据选择方法*

*Suorong Yang, Peijia Li, Furao Shen, Jian Zhao* | **Category: cs.LG, cs.CV**

**Keywords:** 强化学习, 数据选择, 冗余评估, epsilon-sample cover, 训练效率

**Comment:** ICCV 2025

> **TL;DR:** RL-Selector是一种通过强化学习和epsilon-sample cover进行数据选择的新方法，旨在减少大型数据集的冗余，提高训练效率和泛化性能，并优于现有基线。

**AI_Comments:** 本文的创新点在于引入了epsilon-sample cover来量化样本冗余，并将数据选择问题巧妙地转化为强化学习任务。这种动态的、基于训练过程演变的样本选择方式，克服了传统静态方法的局限性，有效提升了训练效率和模型性能，为大规模深度学习的数据处理提供了有前景的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现代深度学习模型依赖大规模数据集，但训练成本高昂且数据存在大量冗余。现有数据选择方法通常依赖静态指标或预训练模型，未能考虑样本组合效应及训练过程中的动态变化，因此需要更数据高效的训练范式。

**Method:** 本文提出了epsilon-sample cover概念来量化样本冗余，并基于此将数据选择重构为强化学习过程。RL-Selector通过一个轻量级强化学习代理，利用从动态数据集分布中导出的epsilon-sample cover作为奖励信号来优化数据选择策略。

**Result:** 在多个基准数据集和不同架构上的大量实验表明，该方法持续优于现有最先进的基线。使用RL-Selector选择的数据集训练的模型显示出更强的泛化性能和更高的训练效率。

**Conclusion:** RL-Selector通过引入epsilon-sample cover和强化学习框架，有效解决了大规模数据集的冗余问题，显著提高了模型训练效率和泛化性能。

> **ai_Abstract:** RL-Selector是一种新颖的数据选择方法，旨在解决大规模数据集训练中的冗余和高成本问题。它引入了epsilon-sample cover来量化样本冗余，并将数据选择建模为一个强化学习过程。通过一个轻量级RL代理，利用动态数据集分布中的epsilon-sample cover作为奖励信号来优化数据选择策略。实验证明，RL-Selector在多个基准数据集上优于现有方法，能有效提高模型泛化能力和训练效率。

> **摘要翻译:** 现代深度架构通常依赖大规模数据集，但在此类数据集上进行训练会产生高昂的计算和存储开销。真实世界的数据集通常包含大量冗余，这促使人们需要更数据高效的训练范式。数据选择已显示出通过识别最具代表性的样本来减轻冗余的潜力，从而在不损害性能的情况下降低训练成本。现有方法通常依赖静态评分指标或预训练模型，忽视了所选样本的组合效应及其在训练期间的演变动态。我们引入了epsilon-sample cover的概念，它基于样本间关系量化样本冗余，捕获数据集的内在结构。在此基础上，我们将数据选择重构为强化学习（RL）过程，并提出了RL-Selector，其中一个轻量级RL代理通过利用从演变的数据集分布中导出的epsilon-sample cover作为奖励信号来优化选择策略。在基准数据集和不同架构上的大量实验表明，我们的方法持续优于现有最先进的基线。使用我们选择的数据集训练的模型显示出增强的泛化性能和改进的训练效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.21039)
> *严格子目标执行：分层强化学习中可靠的长周期规划*

*Jaebak Hwang, Sanghyeon Lee, Jeongmo Kim, Seungyul Han* | **Category: cs.LG, cs.AI**

**Keywords:** 分层强化学习, 子目标执行, 长周期规划, 目标条件RL, 稀疏奖励

**Comment:** 9 technical page followed by references and appendix

> **TL;DR:** 严格子目标执行（SSE）是一种新的分层强化学习框架，通过结构化约束高层决策、解耦探索策略和故障感知路径优化，解决了长周期目标条件任务中子目标不可行和规划效率低下的问题，并在多个基准测试中表现出卓越的效率和成功率。

**AI_Comments:** SSE的创新之处在于其“严格子目标执行”的概念，通过结构化约束高层决策来强制可达性，以及结合解耦探索和故障感知路径优化，共同解决了分层RL中的关键挑战。这对于处理复杂、稀疏奖励的长周期任务具有重要意义，有望提升实际应用中的机器人规划和控制能力。

<details>
  <summary>Details</summary>

**Motivation:** 长周期目标条件任务对强化学习（RL）提出了根本性挑战，特别是当目标遥远且奖励稀疏时。现有的分层和基于图的方法虽然提供部分解决方案，但往往面临子目标不可行和规划效率低下的问题。

**Method:** 本研究引入了严格子目标执行（SSE），一个基于图的分层RL框架。它通过结构化约束高层决策来强制实现单步子目标可达性。为了增强探索，SSE采用解耦探索策略，系统地遍历目标空间中探索不足的区域。此外，它还引入了故障感知路径优化，通过根据观察到的低层成功率动态调整边缘成本来改进基于图的规划，从而提高子目标的可靠性。

**Result:** 实验结果表明，在各种长周期基准测试中，SSE在效率和成功率方面始终优于现有的目标条件RL和分层RL方法。

**Conclusion:** 严格子目标执行（SSE）框架通过其创新的设计，有效解决了长周期目标条件任务中的关键挑战，显著提高了分层强化学习的性能和可靠性。

> **ai_Abstract:** 严格子目标执行（SSE）是一个针对长周期目标条件任务的分层强化学习框架，旨在解决现有方法中子目标不可行和规划效率低下的问题。SSE通过结构化约束高层决策确保单步子目标可达性，采用解耦探索策略促进目标空间探索，并通过故障感知路径优化动态调整规划以提高子目标可靠性。实验证明，SSE在效率和成功率上均超越了现有方法。

> **摘要翻译:** 长周期目标条件任务对强化学习（RL）提出了根本性挑战，特别是当目标遥远且奖励稀疏时。虽然分层和基于图的方法提供部分解决方案，但它们常常面临子目标不可行和规划效率低下的问题。我们引入了严格子目标执行（SSE），一个基于图的分层RL框架，它通过结构化约束高层决策来强制实现单步子目标可达性。为了增强探索，SSE采用解耦探索策略，系统地遍历目标空间中探索不足的区域。此外，故障感知路径优化通过根据观察到的低层成功率动态调整边缘成本来改进基于图的规划，从而提高子目标的可靠性。在各种长周期基准测试中的实验结果表明，SSE在效率和成功率方面始终优于现有的目标条件RL和分层RL方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [331] [Efficient Skill Discovery via Regret-Aware Optimization](https://arxiv.org/abs/2506.21044)
> *通过后悔感知优化实现高效技能发现*

*He Zhang, Ming Zhou, Shaopeng Zhai, Ying Sun, Hui Xiong* | **Category: cs.LG, cs.AI**

**Keywords:** 技能发现, 强化学习, 后悔感知, 高效性, 多样性

**Comment:** 

> **TL;DR:** 现有无监督技能发现方法在效率上受限，尤其在高维环境中。本文提出一种后悔感知方法，将技能发现建模为最小-最大博弈，通过后悔来指导技能探索，提高了高维环境下的效率和多样性。

**AI_Comments:** 这项工作通过引入“后悔感知”机制，将技能发现与策略学习的对抗性视角相结合，提供了一种新颖且高效的技能探索策略。其创新点在于利用后悔来量化策略强度收敛，从而智能地分配探索资源，有效解决了高维环境下的效率问题。15%的零样本改进是一个显著的成果，表明该方法具有较强的泛化能力和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有无监督技能发现方法（如纯探索、互信息优化、时间表征学习）虽然在探索方面表现良好，但在效率方面存在局限性，特别是在高维环境下。

**Method:** 将技能发现构建为技能生成和策略学习的最小-最大博弈。提出一种基于时间表征学习的后悔感知方法，沿着可升级策略强度的方向扩展发现的技能空间。核心思想是技能发现与策略学习是对抗的，即对强度弱的技能进行更多探索，对强度收敛的技能减少探索。具体实现通过后悔度量强度收敛程度，并使用可学习的技能生成器引导技能发现，同时通过可升级的技能生成器群体避免退化。

**Result:** 实验结果表明，该方法在效率和多样性方面均优于基线方法。此外，在高维环境中，该方法比现有方法实现了15%的零样本改进。

**Conclusion:** 本文提出的通过后悔感知优化实现高效技能发现的方法，有效解决了现有方法在效率上的局限性，并在高维环境中展现出显著的性能提升。

> **ai_Abstract:** 本文提出一种名为“后悔感知优化”的高效无监督技能发现方法，旨在解决现有方法在高维环境中的效率瓶颈。该方法将技能发现建模为技能生成与策略学习的最小-最大博弈，并利用“后悔”机制来指导技能探索，即对策略强度较弱的技能进行更多探索。实验证明，该方法在效率和多样性上均优于现有基线，尤其在高维环境中实现了显著的零样本性能提升。

> **摘要翻译:** 无监督技能发现旨在在开放式强化学习中学习多样化和可区分的行为。现有方法侧重于通过纯粹探索、互信息优化和学习时间表征来提高多样性。尽管它们在探索方面表现良好，但在效率方面仍然有限，特别是对于高维情况。在这项工作中，我们将技能发现构建为技能生成和策略学习的最小-最大博弈，提出了一种基于时间表征学习的后悔感知方法，该方法沿着可升级策略强度的方向扩展发现的技能空间。该方法背后的关键见解是技能发现与策略学习是对抗的，即应进一步探索强度较弱的技能，而对强度已收敛的技能则减少探索。作为一种实现方式，我们用后悔来评估强度收敛的程度，并用可学习的技能生成器指导技能发现。为了避免退化，技能生成来自一个可升级的技能生成器群体。我们在不同复杂度和维度大小的环境中进行了实验。实证结果表明，我们的方法在效率和多样性方面均优于基线。此外，与现有方法相比，我们的方法在高维环境中实现了15%的零样本改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [333] [FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning](https://arxiv.org/abs/2506.21054)
> *联邦学习中概念漂移适应的动态客户端聚类：FedDAA*

*Fu Peng, Ming Tang* | **Category: cs.LG**

**Keywords:** 联邦学习, 概念漂移, 动态聚类, 数据异质性, 灾难性遗忘

**Comment:** 

> **TL;DR:** FedDAA是一种动态聚类联邦学习框架，通过区分真实漂移、虚拟漂移和标签漂移来适应多源概念漂移，并有效保留历史知识，显著提高了准确性。

**AI_Comments:** FedDAA的创新点在于其能够区分并针对联邦学习中的多源概念漂移（真实漂移、虚拟漂移、标签漂移）采取不同的适应策略，特别是其保留历史知识的能力，有效解决了现有方法在虚拟或标签漂移下易发生灾难性遗忘的问题。这对于提升联邦学习在动态非IID环境下的鲁棒性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中客户端数据分布随时间变化导致概念漂移（包括真实漂移、虚拟漂移和标签漂移）。现有方法主要关注真实漂移，在面对虚拟或标签漂移时未能有效保留历史知识，导致灾难性遗忘。区分不同漂移源并采用不同适应策略是关键挑战。

**Method:** 提出FedDAA，一个动态聚类联邦学习框架。它包含三个模块：1) 聚类数量确定模块，用于找到最优聚类数；2) 真实漂移检测模块，用于区分真实漂移与虚拟/标签漂移；3) 概念漂移适应模块，用于适应新数据同时保留有用历史信息。该方法提供理论收敛保证。

**Result:** 实验表明，FedDAA在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上比现有最先进方法实现了7.84%到8.52%的准确率提升。

**Conclusion:** FedDAA通过动态客户端聚类和多源概念漂移适应策略，有效解决了联邦学习中的概念漂移问题，特别是在处理虚拟和标签漂移时能更好地保留历史知识，从而提高了模型性能。

> **ai_Abstract:** 本文提出了FedDAA，一个针对联邦学习中多源概念漂移（包括真实漂移、虚拟漂移和标签漂移）的动态聚类框架。FedDAA通过区分不同漂移源，并设计了聚类数确定、真实漂移检测和概念漂移适应三个模块，以在适应新数据的同时有效保留历史知识，避免灾难性遗忘。理论分析和实验结果均验证了FedDAA的有效性，其在多个数据集上显著优于现有SOTA方法。

> **摘要翻译:** 在联邦学习（FL）中，每个客户端的数据分布可能随时间变化，引入时间性和空间性数据异质性，即概念漂移。数据异质性源于三种漂移源：真实漂移（条件分布 P(y|x) 的变化）、虚拟漂移（输入分布 P(x) 的变化）和标签漂移（标签分布 P(y) 的变化）。然而，大多数现有解决概念漂移的联邦学习方法主要关注真实漂移。当客户端经历虚拟漂移或标签漂移时，这些方法往往无法选择性地保留有用的历史知识，导致灾难性遗忘。一个关键挑战在于区分不同来源的漂移，因为它们需要不同的适应策略：真实漂移需要丢弃过时数据，而虚拟漂移或标签漂移则受益于保留历史数据。如果没有明确识别漂移源，一般的适应策略是次优的，并可能损害泛化能力。为了解决这一挑战，我们提出了 FedDAA，一个动态聚类联邦学习框架，旨在适应多源概念漂移，同时保留有价值的历史知识。具体而言，FedDAA 集成了三个模块：一个聚类数量确定模块，用于找到最优聚类数量；一个真实漂移检测模块，用于区分真实漂移与虚拟/标签漂移；以及一个概念漂移适应模块，用于适应新数据同时保留有用的历史信息。我们提供了理论收敛保证，实验表明 FedDAA 在 Fashion-MNIST、CIFAR-10 和 CIFAR-100 上比现有最先进方法实现了 7.84% 到 8.52% 的准确率提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [336] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
> *利用知识图谱的高质量指令数据增强大型语言模型工具使用*

*Jingwei Wang, Zai Zhang, Hao Qian, Chunjing Gan, Binbin Hu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Bin Shi, Bo Dong* | **Category: cs.LG, cs.CL**

**Keywords:** 大型语言模型, 工具使用, 知识图谱, 指令数据, 微调

**Comment:** 20 pages, 12 figures

> **TL;DR:** 提出利用知识图谱生成高质量指令数据，以显著提升大型语言模型的工具使用能力。

**AI_Comments:** 该论文的创新之处在于利用知识图谱结构化和语义丰富的特性来生成高质量的指令数据，克服了以往依赖LLM生成数据质量不足的局限性。这为提升LLM的实际问题解决能力提供了一个更可靠的途径，具有重要的意义。

<details>
  <summary>Details</summary>

**Motivation:** 教会大型语言模型（LLMs）使用工具对于提升其解决问题能力和扩展应用至关重要，但由于需要深入理解工具功能和用户意图，有效使用工具具有挑战性。以往依赖LLM生成指令数据的方法质量通常不足。

**Method:** 提出一种新方法，利用知识图谱生成高质量指令数据。具体步骤包括：从知识图谱中提取查询路径并转化为用户查询；将实体之间的关系转化为可操作的工具；将每个查询的路径解析为详细的解决方案步骤，从而创建高质量指令数据。

**Result:** 实验表明，仅使用少量这种合成数据进行微调，即可显著提高LLM的工具利用率和整体能力。

**Conclusion:** 利用知识图谱生成高质量指令数据是一种有效增强大型语言模型工具使用和整体能力的方法。

> **ai_Abstract:** 本论文提出了一种利用知识图谱生成高质量指令数据的新方法，旨在解决大型语言模型（LLMs）在工具使用方面面临的挑战。通过从知识图谱中提取并转化查询路径为用户查询，将实体关系转化为工具，并解析详细解决方案步骤，该方法能够创建优质的训练数据。实验结果表明，仅使用少量这种合成数据进行微调，即可显著提升LLMs的工具使用能力和整体性能。

> **摘要翻译:** 教大型语言模型（LLMs）使用工具对于提升其解决问题能力和扩展应用至关重要。然而，有效使用工具具有挑战性，因为它需要对工具功能和用户意图有深入的理解。以往的方法主要依赖LLM生成指令数据，但这些数据的质量往往不足。在本文中，我们提出了一种新方法，利用知识图谱生成LLM所需的高质量指令数据。知识图谱是人工策划的、富含语义信息的。我们首先从给定的知识图谱中提取各种查询路径，这些路径被转化为广泛的用户查询。然后，我们将实体之间的关系转化为可操作的工具，并将每个查询的路径解析为详细的解决方案步骤，从而创建高质量的指令数据。我们的实验表明，仅使用少量这种合成数据进行微调，即可显著提高LLM的工具利用率和整体能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [340] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
> *FeDa4Fair：用于公平性评估的客户端级联邦数据集*

*Xenia Heilmann, Luca Corbucci, Mattia Cerrato, Anna Monreale* | **Category: cs.LG, cs.AI**

**Keywords:** 联邦学习, 公平性, 数据集, 偏差, 基准测试

**Comment:** 

> **TL;DR:** 本文介绍了FeDa4Fair，一个用于生成和评估联邦学习中具有客户端异构偏差的公平性数据集的库，旨在促进更稳健和可复现的公平性研究。

**AI_Comments:** 这项工作通过提供专门的数据集和评估工具，解决了联邦学习中公平性研究的一个关键痛点。其创新之处在于关注客户端层面的异构偏差，并提供了一个可复用、标准化的基准测试框架，这对于推动联邦学习领域公平性研究的进展至关重要。这有助于研究人员在更真实和受控的环境中比较和开发公平性缓解方法。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中存在公平性问题，因为客户端本地数据集的偏差和数据分布的异构性可能导致模型对不同客户端的公平性表现不一。现有的公平性增强方案通常只关注单个敏感属性，忽略了不同客户端多样化且有时相互冲突的公平性需求。为了支持更稳健和可复现的联邦学习公平性研究，并实现全局和客户端级别公平性感知联邦学习方法的一致基准测试。

**Method:** 本文贡献了三点：1) 引入了FeDa4Fair，一个用于生成表格数据集的库，专门用于评估异构客户端偏差下的公平联邦学习方法；2) 发布了四个具有偏差异构性的数据集以及相应的基准，以便在受控环境中比较公平性缓解方法；3) 提供了用于评估这些数据集公平性结果的即用型函数。

**Result:** 本文引入了FeDa4Fair库，能够生成用于评估公平联邦学习方法在异构客户端偏差下表现的表格数据集。同时，发布了四个具有偏差异构性的数据集及其基准，为受控环境下比较公平性缓解方法提供了资源。此外，还提供了评估这些数据集公平性结果的即用型函数。

**Conclusion:** 本文通过引入FeDa4Fair库、发布偏差异构数据集和基准，以及提供评估函数，为联邦学习中公平性研究的基准测试和评估提供了重要工具，有助于推动该领域更稳健和可复现的研究。

> **ai_Abstract:** 本文介绍了FeDa4Fair，一个专门为联邦学习（FL）中公平性评估设计的库。鉴于FL中客户端数据异构性和偏差导致的公平性挑战以及现有解决方案的局限性，FeDa4Fair旨在通过生成具有异构客户端偏差的表格数据集来支持更稳健和可复现的公平性研究。该工作还发布了四个此类数据集及其基准，并提供了评估公平性结果的实用函数，为全局和客户端级别的公平性感知FL方法提供了一致的基准测试环境。

> **摘要翻译:** 联邦学习（FL）实现了跨多个客户端的协作模型训练，而无需共享客户端的私有数据。然而，公平性仍然是一个关键问题，因为本地客户端数据集中存在的偏差可能会影响整个联邦系统。客户端之间异构的数据分布可能导致模型对某些客户端比对其他客户端更公平。尽管现有文献中存在一些增强公平性的解决方案，但大多数都集中于缓解单个敏感属性（通常是二进制）的偏差，而忽略了不同客户端多样化且有时相互冲突的公平性需求。这种有限的视角可能会限制公平性干预对不同客户端的有效性。为了支持联邦学习中更稳健和可复现的公平性研究，我们的目标是实现全局和客户端级别公平性感知联邦学习方法的一致基准测试。在本文中，我们通过三种方式做出了贡献：(1) 我们引入了FeDa4Fair，一个用于生成表格数据集的库，专门用于评估异构客户端偏差下的公平联邦学习方法；(2) 我们发布了四个具有偏差异构性的数据集和相应的基准，以便在受控环境中比较公平性缓解方法；(3) 我们提供了用于评估这些数据集公平性结果的即用型函数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [342] [Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning](https://arxiv.org/abs/2506.21102)
> *通过注意力引导图学习实现可解释的层次概念推理*

*David Debot, Pietro Barbiero, Gabriele Dominici, Giuseppe Marra* | **Category: cs.LG, cs.AI**

**Keywords:** 概念基模型, 可解释性, 层次推理, 图学习, 注意力机制

**Comment:** 

> **TL;DR:** 本文提出了一种名为H-CMR的新型概念基模型，它通过学习有向无环图和神经注意力机制，为概念预测和任务预测都提供了可解释性，并达到了与现有技术相当的性能，同时支持强人机交互。

**AI_Comments:** 本文的创新之处在于提出了一种能够同时为概念和最终任务预测提供可解释性的CBM，这解决了现有CBMs的“黑盒”问题。通过引入注意力引导的图学习来建模概念间的层次关系，H-CMR不仅提高了模型的可解释性，还通过人机交互展示了实际应用潜力，例如提高推理准确性和数据效率。这对于可信AI的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有概念基模型（CBMs）仅为最终任务预测提供可解释性，而概念预测本身通常通过黑盒神经网络进行，缺乏透明度。本文旨在解决这一局限性，为概念和任务预测都提供可解释性。

**Method:** 本文提出了一种名为层次概念记忆推理器（H-CMR）的新型概念基模型。H-CMR通过学习一个有向无环图来建模概念之间的关系，其中边代表定义概念的逻辑规则。在推理过程中，H-CMR利用神经注意力机制选择这些规则的一个子集，然后分层应用这些规则来预测所有概念和最终任务。

**Result:** 实验结果表明，H-CMR在性能上与最先进的模型相当，同时通过概念和模型干预实现了强大的人机交互。概念干预可以在推理时显著提高准确性，而模型干预可以在有背景知识时提高训练期间的数据效率。

**Conclusion:** H-CMR通过为概念和任务预测提供可解释性，并支持有效的人机交互，克服了现有概念基模型的局限性，同时保持了最先进的性能。

> **ai_Abstract:** 本文提出了一种名为层次概念记忆推理器（H-CMR）的新型概念基模型，旨在解决现有概念基模型在概念预测层面缺乏可解释性的问题。H-CMR通过构建一个学习到的有向无环图来表示概念间的逻辑关系，并结合注意力机制分层应用这些规则进行概念和任务预测，从而实现了对两者的可解释性。实验证明，H-CMR在保持与现有技术相当性能的同时，显著增强了人机交互能力，通过概念和模型干预分别提升了推理准确性和训练数据效率。

> **摘要翻译:** 概念基模型（CBMs）是一类深度学习模型，通过高级概念解释预测来提供可解释性。这些模型首先预测概念，然后利用它们执行下游任务。然而，当前的CBMs仅为最终任务预测提供可解释性，而概念预测本身通常通过黑盒神经网络进行。为了解决这一局限性，我们提出了层次概念记忆推理器（H-CMR），这是一种新型CBM，为概念和任务预测都提供了可解释性。H-CMR使用学习到的有向无环图来建模概念之间的关系，其中边表示定义其他概念的逻辑规则。在推理过程中，H-CMR采用神经注意力机制选择这些规则的一个子集，然后分层应用这些规则来预测所有概念和最终任务。实验结果表明，H-CMR在性能上与最先进的技术相当，同时通过概念和模型干预实现了强大的人机交互。前者可以在推理时显著提高准确性，而后者可以在有背景知识时提高训练期间的数据效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [344] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
> *学习跳过Transformer的中间层*

*Tim Lawson, Laurence Aitchison* | **Category: cs.LG, cs.CL**

**Keywords:** Transformer, 条件计算, 层跳过, 模型效率, 门控机制

**Comment:** 11 pages, 2 figures

> **TL;DR:** 本文提出了一种动态跳过Transformer中间层的新架构，旨在提高效率，但实验结果显示与更少层的密集基线相比，在验证交叉熵和FLOPs的权衡上没有改进。

**AI_Comments:** 该论文的创新点在于其提出了一种新颖的动态跳过Transformer中间层的方法，这是基于对Transformer中间层冗余性的深入理解。它引入了门控机制和残差范数控制等技术来管理跳层行为。然而，其主要局限性在于，在所研究的规模下，该方法并未能实现预期的计算效率提升，这表明在实际应用中可能需要进一步的优化或在更大规模上进行验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有条件计算方法常针对独立模块或独立跳过层，但解释性研究表明Transformer中间层冗余度更高，早期层聚合信息。受此启发，本文旨在通过跳过中间层来提高Transformer的效率，并减少“更简单”token的计算需求，期望形成多级表示层次。

**Method:** 提出了一种新的架构，该架构根据输入动态跳过数量可变的中间层。一个学习到的门控机制决定是否绕过对称的中心块跨度，一个门控注意力机制阻止后续token关注被跳过的token位置。残差范数通过“sandwich”或“perilayernorm”方案控制，门控稀疏性通过自适应正则化损失控制。

**Result:** 在所研究的规模下，与层数更少的密集基线相比，该方法在验证交叉熵和估计FLOPs之间的权衡方面未能实现改进。

**Conclusion:** 尽管提出了一种新颖的动态跳过Transformer中间层的架构，但在所测试的规模下，该方法未能达到预期的计算效率提升。

> **ai_Abstract:** 本文提出了一种基于Transformer中间层冗余性观察的新型条件计算架构。该架构通过学习到的门控机制动态跳过对称的中间层，并结合门控注意力机制和残差范数控制策略，旨在提高效率并减少简单token的计算量。然而，实验结果显示，在测试规模下，该方法在计算效率与模型性能的权衡上未能超越传统的密集Transformer基线。

> **摘要翻译:** 条件计算是提高Transformer效率的常用策略。现有方法通常针对单个模块（例如，专家混合层）或独立跳过层。然而，可解释性研究表明，Transformer的中间层表现出更大的冗余性，并且早期层将信息聚合到token位置。受这些见解的启发，我们提出了一种新颖的架构，可以动态地从中间向外跳过可变数量的层。特别是，一个学习到的门控机制根据输入决定是否绕过对称的中心块跨度，一个门控注意力机制阻止后续token关注被跳过的token位置。残差范数通过“sandwich”或“perilayernorm”方案控制，门控稀疏性通过自适应正则化损失控制。我们旨在减少“更简单”token的计算需求，并可能促进一种新兴的多级表示层次结构，但在所研究的规模下，与层数更少的密集基线相比，我们的方法在验证交叉熵和估计FLOPs之间的权衡方面未能实现改进。我们已在https://github.com/tim-lawson/skip-middle 发布了我们的代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [346] [Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual Conditional Diffusion Implicit Bridges](https://arxiv.org/abs/2506.21107)
> *Unlasting: 通过双条件扩散隐式桥接进行非配对单细胞多扰动估计*

*Changxi Chi, Jun Xia, Yufei Huang, Jingbo Zhou, Siyuan Li, Yunfan Liu, Chang Yu, Stan Z. Li* | **Category: cs.LG, q-bio.MN**

**Keywords:** 单细胞扰动, 非配对数据, 扩散模型, 基因调控网络, 数据增强

**Comment:** 

> **TL;DR:** Unlasting使用双条件扩散模型解决单细胞多扰动数据非配对问题，并通过整合基因调控网络和掩码机制提高估计质量和异质性捕捉能力。

**AI_Comments:** Unlasting的创新点在于利用双条件扩散模型有效处理单细胞扰动数据固有的非配对问题，这在现有方法中是一个重大挑战。通过整合基因调控网络和引入掩码机制，它不仅提高了估计的生物学合理性，也提升了生成数据的质量。引入新的评估指标以捕捉细胞间异质性，也显示了对生物学复杂性的深入理解。该框架有望提高单细胞药物筛选和关键基因识别的效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 估计单细胞对各种扰动的反应对于识别关键基因和药物筛选至关重要，能显著提高实验效率。然而，单细胞测序的破坏性导致无法捕获同一细胞扰动前后表型，使得数据天生非配对。现有方法要么强制配对，要么忽略细胞间的内在关系。

**Method:** 本文提出了一个基于双扩散隐式桥接（DDIB）的框架Unlasting，用于学习不同数据分布间的映射，以解决非配对数据问题。该框架被解释为一种数据增强形式。它整合了基因调控网络（GRN）信息以生物学上有意义的方式传播扰动信号，并引入掩码机制来预测沉默基因。此外，为了捕捉单细胞响应的内在异质性，还引入了一个更合适的评估指标。

**Result:** Unlasting成功克服了非配对单细胞扰动数据的问题，并在基因调控网络的指导下增强了模型对扰动的洞察力。通过专门设计的掩码模型预测沉默基因，提高了生成谱的质量。引入的生物学评估指标能更好地反映单细胞响应中固有的异质性。

**Conclusion:** Unlasting通过其双条件扩散模型、基因调控网络整合、掩码机制和新的评估指标，有效地解决了单细胞多扰动数据非配对的挑战，并提高了扰动响应估计的准确性和生物学相关性。

> **ai_Abstract:** 本文提出了Unlasting，一个基于双条件扩散隐式桥接（DDIB）的框架，旨在解决单细胞多扰动数据中固有的非配对问题。Unlasting通过学习不同数据分布之间的映射来估计单细胞对各种扰动的反应。该方法整合了基因调控网络（GRN）信息以生物学方式传播扰动信号，并引入掩码机制预测沉默基因，从而提高生成数据的质量。此外，为了更好地捕捉单细胞响应的内在异质性，Unlasting还引入了一个新的、更合适的评估指标。

> **摘要翻译:** 估计单细胞对各种扰动的反应有助于识别关键基因和加强药物筛选，显著提高实验效率。然而，单细胞测序是一个破坏性过程，使得在扰动前后捕获同一细胞的表型变得不可能。因此，在扰动和未扰动条件下收集的数据本质上是未配对的。现有方法要么尝试使用随机抽样强制配对未配对数据，要么在建模过程中忽略未扰动和扰动细胞之间的内在关系。在这项工作中，我们提出了一个基于双扩散隐式桥接（DDIB）的框架，以学习不同数据分布之间的映射，有效解决未配对数据的挑战。我们进一步将此框架解释为一种数据增强形式。我们整合了基因调控网络（GRN）信息，以生物学上有意义的方式传播扰动信号，并进一步结合掩码机制来预测沉默基因，从而提高生成谱的质量。此外，在相同扰动下，基因表达在不同细胞间往往差异显著，经常表现出反映内在异质性的双峰分布。为了捕捉这一点，我们引入了一个更合适的评估指标。我们提出了Unlasting，这是一种双条件扩散模型，它克服了单细胞扰动数据未配对的问题，并在GRN的指导下加强了模型对扰动的洞察力，同时设计了一个专门的掩码模型，通过预测沉默基因来提高生成质量。此外，我们引入了一个基于生物学原理的评估指标，可以更好地反映单细胞响应中固有的异质性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [347] [Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments](https://arxiv.org/abs/2506.21127)
> *应对对抗性环境中无人机冲突消除的抗脆弱强化学习的鲁棒策略切换*

*Deepak Kumar Panda, Weisi Guo* | **Category: cs.LG, cs.AI**

**Keywords:** 抗脆弱强化学习, 策略切换, 无人机冲突消除, 对抗性环境, 折扣汤普森采样

**Comment:** 

> **TL;DR:** 提出了一种基于折扣汤普森采样的鲁棒策略切换机制，用于在对抗性环境中增强无人机导航的抗脆弱强化学习，以适应更广泛的分布变化。

**AI_Comments:** 这篇论文的创新点在于将抗脆弱性概念引入强化学习，并通过动态策略切换机制来应对对抗性环境中的未知和变化的扰动。它将策略选择问题转化为多臂老虎机问题，并利用折扣汤普森采样进行优化，这提供了一个新颖的适应性框架。这项工作对于提高无人机在复杂、不确定环境中的自主性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的鲁棒强化学习方法在应对固定扰动时有效，但对最佳价值分布之外的分布变化泛化能力有限，无法有效处理传感器操纵等对抗性攻击导致的漏洞。

**Method:** 本文引入了一个抗脆弱强化学习框架，通过结合基于折扣汤普森采样（DTS）的切换机制来增强对更广泛分布变化的适应性。该机制动态选择多个鲁棒策略以最小化对抗性引起的状态-动作-价值分布变化。首先，通过考虑策略空间中的一系列扰动，推导出一组多样化的动作鲁棒策略。然后，将这些策略建模为多臂老虎机（MAB）问题，其中DTS根据非平稳伯努利奖励最优地选择策略，从而有效地适应不断演变的对抗性策略。还提供了理论框架，通过优化DTS以最小化由于分布变化引起的总遗憾，从而实现对未知对抗性攻击的有效适应。

**Result:** 广泛的数值模拟验证了所提出的框架在具有多个动态三维障碍物和更强的PGD（投影梯度下降）和欺骗攻击的复杂导航环境中的有效性。与传统的鲁棒、非自适应强化学习方法相比，抗脆弱方法表现出卓越的性能，导航路径长度更短，无冲突导航轨迹率更高。

**Conclusion:** 论文提出的抗脆弱强化学习框架，通过动态策略切换机制，能够有效应对复杂对抗环境中的分布变化和未知攻击，显著提升了无人机导航的鲁棒性和安全性。

> **ai_Abstract:** 本文提出了一种针对无人机在对抗性环境中导航的抗脆弱强化学习框架。该框架通过引入基于折扣汤普森采样的动态策略切换机制，克服了传统鲁棒RL方法在处理分布外偏移时的局限性。它通过将多样化的鲁棒策略建模为多臂老虎机问题，并利用DTS进行最优选择，从而有效地适应不断演变的对抗性策略和未知攻击。实验结果表明，该方法在复杂导航环境中表现出优于现有方法的性能，实现了更短的导航路径和更高的无冲突率。

> **摘要翻译:** 无人机（UAV）导航自动化程度的提高，使其暴露于利用传感器操纵来利用强化学习（RL）漏洞的对抗性攻击。尽管现有的鲁棒RL方法旨在缓解此类威胁，但它们的有效性对来自最优价值分布的分布外偏移的泛化能力有限，因为它们主要设计用于处理固定扰动。为了解决这一限制，本文引入了一个抗脆弱RL框架，通过结合基于折扣汤普森采样（DTS）的切换机制来增强对更广泛分布变化的适应性。该机制动态选择多个鲁棒策略，以最小化对抗性引起的状态-动作-价值分布偏移。所提出的方法首先通过考虑策略空间中的一系列扰动，推导出一组多样化的动作鲁棒策略。然后，将这些策略建模为多臂老虎机（MAB）问题，其中DTS根据非平稳伯努利奖励最优地选择策略，有效地适应不断演变的对抗性策略。还提供了理论框架，通过优化DTS以最小化由于分布偏移引起的总遗憾，从而实现对未知对抗性攻击的有效适应，从而产生抗脆弱性。广泛的数值模拟验证了所提出的框架在具有多个动态三维障碍物和更强的投影梯度下降（PGD）和欺骗攻击的复杂导航环境中的有效性。与传统的鲁棒、非自适应RL方法相比，抗脆弱方法实现了卓越的性能，与现有鲁棒RL技术相比，展示了更短的导航路径长度和更高的无冲突导航轨迹率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [349] [Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks](https://arxiv.org/abs/2506.21129)
> *课程引导的反脆弱强化学习，用于观测空间攻击下的安全无人机冲突解除*

*Deepak Kumar Panda, Adolfo Perrusquia, Weisi Guo* | **Category: cs.LG, cs.AI**

**Keywords:** 反脆弱强化学习, 对抗性攻击, 无人机冲突解除, 观测空间攻击, 课程学习

**Comment:** 

> **TL;DR:** 该研究提出了一种反脆弱强化学习框架，通过模拟攻击者逐步增强观测空间扰动，使RL策略能够适应并泛化，从而在对抗性攻击下实现安全的无人机冲突解除。

**AI_Comments:** 该论文的创新点在于提出了“反脆弱”强化学习的概念，并将其应用于安全关键系统，特别是无人机导航中的对抗性攻击防御。通过引入“课程引导”的模拟攻击者，逐步增加扰动强度，使得RL智能体能够主动适应并泛化，而不仅仅是被动抵抗。这种方法不仅解决了传统RL策略在面对OOD攻击时的脆弱性，还通过理论表征和实验验证了其有效性，具有重要的实践意义和理论贡献。特别是在价值函数分布的灾难性遗忘和反脆弱性定义上，提供了坚实的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）策略部署在无人机导航等安全关键系统中时，容易受到观测空间中分布外（OOD）对抗性攻击的影响。这些攻击会导致分布偏移，显著降低价值估计，从而导致不安全或次优的决策，使现有策略脆弱。

**Method:** 该研究提出了一种反脆弱RL框架，旨在适应递增的对抗性扰动课程。该框架引入了一个模拟攻击者，该攻击者逐步增加观测空间扰动的强度，使RL智能体能够适应并泛化更广泛的OOD观测，并预测以前未见的攻击。理论上，将脆弱性定义为价值函数分布随扰动强度增加而单调发散的灾难性遗忘；将反脆弱性定义为这种价值偏移的有界性，并推导了稳定遗忘的适应条件。该方法通过使用Wasserstein距离最小化，在逐步扰动的观测中，通过迭代专家引导的批评者对齐来强制执行这些边界。

**Result:** 在涉及动态3D障碍物的无人机冲突解除场景中，反脆弱策略在面对PGD和GPS欺骗攻击时，始终优于标准和鲁棒RL基线，累积奖励提高了15%，冲突事件减少了30%以上。

**Conclusion:** 这些发现证明了反脆弱强化学习在具有演变威胁情景的环境中实现安全和弹性决策的实践和理论可行性。

> **ai_Abstract:** 本研究提出了一种名为“课程引导的反脆弱强化学习”的新框架，旨在解决强化学习（RL）策略在安全关键系统中（如无人机导航）面临的观测空间对抗性攻击导致的脆弱性问题。该框架通过引入一个模拟攻击者，逐步增加扰动强度，使RL智能体能够适应并泛化到广泛的分布外观测，从而预测并抵御未知攻击。研究首先从理论上定义了脆弱性（灾难性遗忘）和反脆弱性（价值偏移的有界性），并提出了在递增扰动下稳定遗忘的适应条件。通过迭代专家引导的批评者对齐和Wasserstein距离最小化，该方法在无人机冲突解除场景中进行了验证。实验结果表明，与现有基线相比，所提出的反脆弱策略在面对PGD和GPS欺骗攻击时表现出显著优越的性能，实现了更高的累积奖励和更少的冲突事件，证明了其在复杂威胁环境下实现安全和弹性决策的有效性。

> **摘要翻译:** 强化学习（RL）策略部署在安全关键系统（如动态空域中的无人机（UAV）导航）中，容易受到观测空间中分布外（OOD）对抗性攻击的影响。这些攻击会导致分布偏移，显著降低价值估计，从而导致不安全或次优的决策，使现有策略脆弱。为了解决这种脆弱性，我们提出了一种反脆弱RL框架，旨在适应递增的对抗性扰动课程。该框架引入了一个模拟攻击者，该攻击者逐步增加观测空间扰动的强度，使RL智能体能够适应并泛化更广泛的OOD观测，并预测以前未见的攻击。我们首先对脆弱性进行了理论表征，将灾难性遗忘正式定义为价值函数分布随扰动强度增加而单调发散。在此基础上，我们将反脆弱性定义为这种价值偏移的有界性，并推导了稳定遗忘的适应条件。我们的方法通过使用Wasserstein距离最小化，在逐步扰动的观测中，通过迭代专家引导的批评者对齐来强制执行这些边界。我们在涉及动态3D障碍物的无人机冲突解除场景中对该方法进行了实证评估。结果表明，当受到投影梯度下降（PGD）和GPS欺骗攻击时，反脆弱策略始终优于标准和鲁棒RL基线，累积奖励提高了15%，冲突事件减少了30%以上。这些发现证明了反脆弱强化学习在具有演变威胁情景的环境中实现安全和弹性决策的实践和理论可行性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [351] [NaLaFormer: Norm-Aware Linear Attention for Transformer Models](https://arxiv.org/abs/2506.21137)
> *NaLaFormer：面向Transformer模型的范数感知线性注意力机制*

*Weikang Meng, Yadan Luo, Liangyu Huo, Yaowei Wang, Xin Li, Zheng Zhang* | **Category: cs.LG**

**Keywords:** 线性注意力, Transformer, 范数感知, NaLaFormer, 熵减

**Comment:** 

> **TL;DR:** NaLaFormer提出了一种范数感知线性注意力机制，通过解耦查询和键矩阵以及范数保持映射来解决现有线性注意力中范数被忽略和负值抑制导致的问题，提升了Transformer在视觉和语言任务上的性能和效率。

**AI_Comments:** NaLaFormer的创新点在于其范数感知设计，通过解耦范数和方向以及引入范数保持映射，解决了线性注意力中长期存在的范数丢失和负值抑制问题。这不仅提升了模型的表达能力和效率，也为线性注意力机制的理论完善提供了新的思路。其对熵减程度与查询范数关系的数学揭示也具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有线性注意力机制在L1归一化过程中忽略了查询范数，导致熵间隙；同时，对查询和键向量的负值抑制导致内积交互缺失。这些问题影响了线性注意力的非负性和熵减性质。

**Method:** 提出了一种新颖的范数感知线性注意力（NaLaFormer）机制。具体方法包括：1. 将查询和键矩阵解耦为范数和方向两部分，以实现范数感知的尖峰控制和范数一致性。2. 引入查询范数感知的核函数，以动态控制熵减程度。3. 采用范数保持映射将角度矩阵的所有元素投影为正值，并利用余弦相似度抑制方向相反的维度，以确保范数一致性并强制执行非负性约束。

**Result:** NaLaFormer在视觉和语言任务上提高了性能，表达能力和效率提升高达4.2%。

**Conclusion:** NaLaFormer通过解决现有线性注意力中范数被忽略和负值抑制的问题，成功恢复了范数引导的动态尖峰性和核扰动范数分布，显著提升了Transformer模型的性能和效率。

> **ai_Abstract:** 本文提出了NaLaFormer，一种范数感知线性注意力机制，旨在解决现有线性注意力中范数被忽略导致的熵间隙和负值抑制导致的内积交互缺失问题。NaLaFormer通过将查询和键矩阵解耦为范数和方向，并采用范数保持映射来恢复范数引导的动态尖峰性和核扰动范数分布。实验证明，NaLaFormer在视觉和语言任务上显著提升了Transformer模型的性能、表达能力和效率，最高可达4.2%。

> **摘要翻译:** 线性注意力作为softmax注意力的可行替代方案，已将复杂性从序列长度的二次方降低到线性。为了保持softmax的两个基本属性——非负性和熵减，当前工作采用各种线性可分离的核函数进行L1归一化，而非softmax操作符。然而，线性注意力中的归一化操作忽略了查询范数，这种退化严重导致了熵间隙。同时，现有工作抑制了查询和键向量的负值，导致映射后缺少内积交互。为了解决这些双重挑战，我们提出了一种新颖的范数感知线性注意力机制，旨在恢复范数引导的动态尖峰性并恢复核扰动的范数分布。具体来说，我们首先将查询和键矩阵解耦为两个分量：范数和方向，分别实现范数感知的尖峰控制和范数一致性。我们通过数学揭示，softmax归一化中熵减的程度随查询范数而变化，这促使我们提出一个查询范数感知的核函数，用于动态控制熵减。此外，为了确保范数一致性并强制执行非负性约束，我们采用范数保持映射将角度矩阵的所有元素投影为正值，利用余弦相似度抑制方向相反的维度。我们进行了广泛的实验，证明NaLaFormer在视觉和语言任务上提高了性能，表达能力和效率提升高达4.2%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [353] [DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding](https://arxiv.org/abs/2506.21140)
> *DBConformer：用于脑电图解码的双分支卷积Transformer*

*Ziwei Wang, Hongbin Wang, Tianwang Jia, Xingyi He, Siyang Li, Dongrui Wu* | **Category: cs.LG, cs.AI**

**Keywords:** EEG解码, 脑机接口, 卷积Transformer, 双分支网络, 通道注意力

**Comment:** 12 pages, 6 figures

> **TL;DR:** 提出DBConformer，一个双分支卷积Transformer网络，通过独立建模时序和空间特征，并结合通道注意力机制，在EEG解码任务上实现了卓越的性能和可解释性，同时参数量显著减少。

**AI_Comments:** DBConformer的创新点在于其双分支结构，分别处理EEG信号的时序和空间特征，这种解耦设计比传统串行Conformer更能有效整合局部和全局信息。此外，引入轻量级通道注意力模块进一步提升了空间表示的精细度。该模型在参数效率和可解释性方面的优势，使其在实际BCI应用中具有重要潜力，有助于推动EEG解码技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的用于EEG解码的CNN模型难以捕获长程时间依赖性和全局通道间关系，而串行设计的CNN-Transformer混合模型（Conformers）未能充分整合局部和全局特征，并且忽视了显式的通道建模。

**Method:** 提出DBConformer，一个双分支卷积Transformer网络。它包含一个时间Conformer用于建模长程时间依赖，以及一个空间Conformer用于提取通道间交互。此外，一个轻量级通道注意力模块通过数据驱动的方式为EEG通道分配重要性，进一步优化空间表示。

**Result:** DBConformer在5个运动想象数据集和2个癫痫检测数据集上，在3种评估设置下，始终优于10个基线模型。其参数量比高容量的EEG Conformer基线少8倍以上。可视化结果证实DBConformer提取的特征具有生理学可解释性，并与运动想象中的感觉运动先验知识一致。

**Conclusion:** DBConformer卓越的性能和可解释性使其在稳健和可解释的EEG解码中表现可靠。

> **ai_Abstract:** 本文提出了DBConformer，一种新颖的双分支卷积Transformer网络，用于解决传统CNN在EEG解码中难以捕获长程依赖和通道间关系的问题，以及现有Conformer模型集成局部与全局特征不佳的局限性。DBConformer通过分离的时间和空间Conformer分支来独立处理时间动态和空间模式，并辅以通道注意力机制。实验证明，DBConformer在多个EEG数据集上性能显著优于现有模型，且参数量更少，同时提取的特征具有良好的生理学可解释性，为稳健和可解释的EEG解码提供了可靠方案。

> **摘要翻译:** 基于脑电图（EEG）的脑机接口（BCIs）将自发/诱发的神经活动转化为外部通信的控制命令。尽管卷积神经网络（CNNs）仍然是EEG解码的主流骨干网络，但其固有的短感受野使其难以捕获长程时间依赖性和全局通道间关系。最近的CNN-Transformer混合模型（Conformers）部分解决了这个问题，但大多数采用串行设计，导致局部和全局特征的整合次优，并且经常忽视显式的通道建模。为了解决这些局限性，我们提出了DBConformer，一个专为EEG解码设计的双分支卷积Transformer网络。它整合了一个时间Conformer来建模长程时间依赖，以及一个空间Conformer来提取通道间交互，从而捕获EEG信号中的时间动态和空间模式。一个轻量级通道注意力模块通过为EEG通道分配数据驱动的重要性，进一步细化空间表示。在五个运动想象（MI）数据集和两个癫痫检测数据集上，在三种评估设置下进行的广泛实验表明，DBConformer始终优于10个有竞争力的基线模型，且其参数量比高容量的EEG Conformer基线少八倍以上。此外，可视化结果证实DBConformer提取的特征具有生理学可解释性，并与运动想象中的感觉运动先验知识一致。DBConformer卓越的性能和可解释性使其在稳健和可解释的EEG解码中表现可靠。代码已在https://github.com/wzwvv/DBConformer公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [354] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
> *复杂度感知微调*

*Andrey Goncharov, Daniil Vyazhev, Petr Sychev, Edvard Khalafyan, Alexey Zaytsev* | **Category: cs.LG, cs.CL**

**Keywords:** 大型语言模型, 微调, 复杂度感知, 蒸馏, 熵

**Comment:** 

> **TL;DR:** 提出一种基于熵的复杂度感知微调方法，能以更少数据实现与蒸馏相当的性能，并优于标准SFT。

**AI_Comments:** 这篇论文的创新点在于引入了“复杂度感知”的概念，通过数据复杂度分类来优化LLM的微调过程。这种方法有效地结合了SFT的效率和蒸馏的性能优势，同时显著降低了数据和计算成本，为高效LLM微调提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 通用大型语言模型（LLMs）通过监督微调（SFT）提升性能，但其效果有限。虽然通过蒸馏大型模型的思维链可以获得更好的结果，但这需要大量昂贵的计算和更多的数据，效率低下。

**Method:** 提出一种高效的微调方案，仅对通过熵识别的复杂数据使用推理。具体来说，通过单令牌答案熵（ROC AUC 0.73）将训练数据分为不同复杂度类别，然后对小型开放模型（约3B）通过SFT和蒸馏进行微调。

**Result:** 该方法显著优于标准SFT方法（平均准确率0.55 vs 0.43），并且在使用62%更少数据的情况下，实现了与蒸馏相当的性能（两者平均准确率均为0.55）。

**Conclusion:** 复杂度感知微调是一种有效且数据高效的LLM微调方法，它在性能上优于标准SFT并与蒸馏相当，同时显著减少了数据需求。

> **ai_Abstract:** 本文提出了一种新颖的“复杂度感知微调”方法，旨在提高大型语言模型（LLMs）微调的效率。该方法利用熵来识别训练数据中的复杂样本，并仅对这些复杂样本应用更耗资源的推理（蒸馏），而对简单样本使用标准监督微调（SFT）。实验结果表明，该方法在小型模型上显著优于传统的SFT方法，并在使用更少数据（减少62%）的情况下，达到了与昂贵的全量蒸馏相媲美的性能。

> **摘要翻译:** 通用大型语言模型（LLMs）经常通过监督微调（SFT）进行微调，以提高在特定领域的性能。通过蒸馏更大模型的思维链可以获得更好的结果，但这需要大量昂贵的调用和更多的数据。我们提出了一种新颖高效的微调蓝图，该蓝图仅对通过熵识别的复杂数据使用推理。具体来说，我们对两个小型开放模型（约3B）将训练数据通过单令牌答案熵（ROC AUC 0.73）分为复杂度类别，通过SFT和蒸馏微调大型语言模型（LLMs），并表明我们的流程显著优于标准SFT方法（平均准确率0.55 vs 0.43），并且在使用62%更少数据的情况下，提供了与蒸馏相当的性能（两者平均准确率均为0.55）。我们发布了代码和数据，以促进该方向的进一步研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [356] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
> *无人机网络攻击的生成对抗规避与分布外检测*

*Deepak Kumar Panda, Weisi Guo* | **Category: cs.LG**

**Keywords:** 无人机网络安全, 入侵检测系统, 生成对抗网络, 分布外检测, 条件变分自编码器

**Comment:** 

> **TL;DR:** 该研究提出一个基于cGAN的框架来生成隐蔽的对抗性攻击以规避无人机入侵检测系统（IDS），并使用CVAE来有效检测这些隐蔽攻击。

**AI_Comments:** 该论文的创新点在于同时利用生成对抗网络（cGAN）来创建高度隐蔽的对抗性攻击，并引入条件变分自编码器（CVAE）来有效检测这些由生成模型产生的复杂威胁。这种攻防兼备的视角对于提升无人机网络安全防御的鲁棒性具有重要意义，尤其是在面对日益智能化的网络攻击时。研究强调了高级概率建模在区分真实OOD事件和隐蔽攻击方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的入侵检测系统（IDS）难以识别新型威胁，且常规的分布外（OOD）检测器难以区分隐蔽的对抗性攻击和真正的OOD事件，这使得无人机系统在缓解措施不足时容易受到攻击。

**Method:** 本文引入了一个基于条件生成对抗网络（cGAN）的框架来生成隐蔽的对抗性攻击，以规避IDS机制。首先，设计了一个鲁棒的多类别IDS分类器，该分类器在良性无人机遥测数据和已知网络攻击（包括DoS、FDI、MiTM和重放攻击）上进行训练。利用此分类器，cGAN扰动已知攻击以生成对抗性样本，这些样本被错误分类为良性，同时保留与OOD分布的统计相似性。这些对抗性样本被迭代优化以实现高隐蔽性和成功率。为了检测此类扰动，本文实现了一个条件变分自编码器（CVAE），利用负对数似然来将对抗性输入与真实的OOD样本分离。

**Result:** 比较评估表明，基于CVAE的遗憾分数在识别隐蔽对抗性威胁方面显著优于传统的基于马哈拉诺比斯距离的检测器。

**Conclusion:** 研究结果强调了先进概率建模对于加强IDS防御自适应、基于生成模型的网络入侵的重要性。

> **ai_Abstract:** 本文针对无人机网络攻击中传统入侵检测系统（IDS）和分布外（OOD）检测器在识别新型和隐蔽对抗性威胁方面的不足，提出了一种创新框架。该框架利用条件生成对抗网络（cGAN）生成能规避IDS且统计上类似OOD的隐蔽对抗性攻击，并使用条件变分自编码器（CVAE）通过负对数似然有效检测这些攻击。实验结果表明，基于CVAE的检测方法在识别隐蔽对抗性威胁方面显著优于传统方法，强调了先进概率建模在增强无人机IDS防御能力方面的重要性。

> **摘要翻译:** 无人机日益融入民用空域，凸显了对弹性智能入侵检测系统（IDS）的需求，因为传统的异常检测方法往往无法识别新型威胁。一种常见的方法是将不熟悉的攻击视为分布外（OOD）样本；然而，当缓解措施不足时，这会使系统容易受到攻击。此外，传统的OOD检测器难以区分隐蔽的对抗性攻击与真正的OOD事件。本文引入了一个基于条件生成对抗网络（cGAN）的框架，用于制作规避IDS机制的隐蔽对抗性攻击。我们首先设计了一个鲁棒的多类别IDS分类器，该分类器在良性无人机遥测数据和已知网络攻击（包括拒绝服务（DoS）、虚假数据注入（FDI）、中间人（MiTM）和重放攻击）上进行训练。利用此分类器，我们的cGAN扰动已知攻击以生成对抗性样本，这些样本被错误分类为良性，同时保留与OOD分布的统计相似性。这些对抗性样本被迭代优化以实现高隐蔽性和成功率。为了检测此类扰动，我们实现了一个条件变分自编码器（CVAE），利用负对数似然来分离对抗性输入与真实的OOD样本。比较评估表明，基于CVAE的遗憾分数在识别隐蔽对抗性威胁方面显著优于传统的基于马哈拉诺比斯距离的检测器。我们的发现强调了先进概率建模对于加强IDS防御自适应、基于生成模型的网络入侵的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [357] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
> *DiLoCoX：一种用于去中心化集群的低通信大规模训练框架*

*Ji Qi, WenPeng Zhu, Li Li, Ming Wu, YingJun Wu, Wu He, Xun Gao, Jason Zeng, Michael Heinrich* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 去中心化训练, 低通信, 大规模模型, 流水线并行, 梯度压缩

**Comment:** 

> **TL;DR:** DiLoCoX是一种低通信量的大规模去中心化集群训练框架，可以在慢速网络上训练千亿级参数模型，显著提高训练速度。

**AI_Comments:** DiLoCoX的创新之处在于其结合多种策略有效降低了大规模模型在去中心化、低带宽网络环境下的通信开销，特别是其一步延迟重叠和自适应梯度压缩机制。这对于推动LLM等基础模型在更广泛、更具挑战性的网络条件下进行训练具有重要意义，打破了对昂贵中心化集群的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 分布式训练基础模型（特别是LLM）需要高通信量，因此高度依赖于具有快速可靠互连的中心化集群。当前挑战是在慢速网络上训练超过千亿参数的模型，并释放去中心化集群的潜力。

**Method:** DiLoCoX框架结合了流水线并行（Pipeline Parallelism）、双优化器策略（Dual Optimizer Policy）、通信与本地训练的一步延迟重叠（One-Step-Delay Overlap of Communication and Local Training）以及自适应梯度压缩方案（Adaptive Gradient Compression Scheme）。并通过收敛性理论分析证明了一步延迟重叠和自适应梯度压缩方案的益处。

**Result:** DiLoCoX能够在1Gbps网络上预训练107B的基础模型。与传统的AllReduce相比，DiLoCoX在分布式训练中实现了357倍的速度提升，同时模型收敛性退化可忽略不计。

**Conclusion:** DiLoCoX是第一个成功应用于千亿级参数模型的去中心化训练框架，能够有效解决慢速网络下大规模模型训练的通信瓶颈。

> **ai_Abstract:** DiLoCoX是一个针对大型模型在去中心化集群中进行低通信量训练的框架。它通过整合流水线并行、双优化器策略、一步延迟通信重叠和自适应梯度压缩，显著提升了参数规模和预训练速度。实验证明，DiLoCoX能在慢速网络上高效训练千亿级模型，相较于AllReduce实现了显著加速，且不影响收敛性。

> **摘要翻译:** 基础模型，特别是大型语言模型（LLM）的分布式训练，需要高水平的通信。因此，它高度依赖于具有快速可靠互连的中心化集群。我们能否在慢速网络上进行训练，从而在处理超过1000亿参数的模型时释放去中心化集群的潜力？在本文中，我们提出了DiLoCoX，一种低通信的大规模去中心化集群训练框架。它结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案。这种组合显著提高了参数规模和模型预训练的速度。我们通过收敛性理论分析证明了通信与本地训练的一步延迟重叠以及自适应梯度压缩方案的益处。通过实验，我们证明DiLoCoX能够在1Gbps网络上预训练一个107B的基础模型。与传统的AllReduce相比，DiLoCoX在分布式训练中可以实现357倍的速度提升，同时保持模型收敛性的可忽略不计的退化。据我们所知，这是第一个成功应用于超过1000亿参数模型的去中心化训练框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [359] [Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion](https://arxiv.org/abs/2506.21144)
> *通过双提示优化和交叉融合的个性化联邦学习*

*Yuguang Zhang, Kuangpu Guo, Zhihe Lu, Yunbo Wang, Jian Liang* | **Category: cs.LG, cs.CV**

**Keywords:** 联邦学习, 个性化联邦学习, 提示学习, 视觉-语言模型, 异质性

**Comment:** 

> **TL;DR:** 本文提出了一种名为pFedDC的个性化联邦学习（FL）框架，通过双提示优化和交叉融合来解决FL中的异质性问题，并在视觉-语言模型（VLM）中实现更优的性能。

**AI_Comments:** 本文的创新点在于将双提示学习（全局和局部提示）和交叉融合机制引入联邦学习，特别是在视觉-语言模型背景下，以有效应对数据异质性并实现模型个性化，超越了传统仅依赖文本提示的方法。这为构建更鲁棒和个性化的联邦学习系统迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）在去中心化客户端协作训练模型时面临数据、计算和通信异质性挑战。尽管预训练的视觉-语言模型（VLM）通过提示词微调具有良好的泛化能力，但现有联邦提示学习方法仅依赖文本提示，忽略了联合标签-域分布偏移问题。

**Method:** 本文提出了一个名为pFedDC的个性化联邦学习框架，它基于双提示学习和交叉融合。具体而言，每个客户端在视觉和语言模态中维护全局和局部提示：全局提示捕获联邦共享的通用知识，而局部提示编码客户端特定的语义和领域特征。同时，设计了一个交叉融合模块，以自适应地整合不同级别的提示，使模型能够生成与每个客户端独特数据分布对齐的个性化表示。

**Result:** 在九个具有各种异质性类型的数据集上进行的广泛实验表明，pFedDC始终优于最先进的方法。

**Conclusion:** pFedDC框架通过双提示优化和交叉融合，有效解决了联邦学习中的异质性挑战，并在个性化联邦学习方面实现了优于现有方法的性能。

> **ai_Abstract:** 本文提出了一个名为pFedDC的个性化联邦学习（FL）框架，旨在解决FL中的数据异质性问题。该框架利用视觉-语言模型（VLM）的双提示学习机制，为每个客户端维护全局和局部提示，分别捕获通用知识和客户端特定特征。此外，一个交叉融合模块被设计用于自适应地整合这些提示，从而生成与客户端数据分布对齐的个性化表示。实验结果表明，pFedDC在多个数据集上均优于现有先进方法。

> **摘要翻译:** 联邦学习（FL）使得去中心化客户端无需共享本地数据即可进行协作模型训练，但面临数据、计算和通信异质性的挑战。预训练的视觉-语言模型（VLM）凭借其强大的泛化能力和轻量级提示词微调，提供了一个有前景的解决方案。然而，现有的联邦提示学习方法仅依赖于文本提示，并且忽略了联合标签-域分布偏移。在本文中，我们提出了一个基于双提示学习和交叉融合的个性化FL框架，命名为pFedDC。具体来说，每个客户端在视觉和语言模态中维护全局和局部提示：全局提示捕获联邦共享的通用知识，而局部提示编码客户端特定的语义和领域特征。同时，设计了一个交叉融合模块，以自适应地整合来自不同级别的提示，使模型能够生成与每个客户端独特数据分布对齐的个性化表示。在九个具有各种异质性类型的数据集上进行的广泛实验表明，pFedDC始终优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [362] [Linearity-based neural network compression](https://arxiv.org/abs/2506.21146)
> *基于线性的神经网络压缩*

*Silas Dobler, Florian Lemmerich* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 神经网络压缩, 线性, ReLU, 模型大小, 无损压缩

**Comment:** 

> **TL;DR:** 本文提出了一种基于线性的新型神经网络压缩方法，通过利用ReLU激活函数下近似线性行为的神经元来合并层，实现了在大多数模型中高达1/4的无损压缩，并可与其他压缩技术结合使用。

**AI_Comments:** 这项工作引入了一种新颖的神经网络压缩视角，即利用神经元的线性行为而非传统的参数重要性或冗余度量。其创新点在于将线性行为与层合并结合起来，实现了显著的无损压缩。该方法与现有技术的兼容性也增加了其实用价值，为神经网络的部署和效率提升提供了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强现有的高度优化的神经网络压缩解决方案，并进一步减少神经网络中的冗余参数，因为大多数当前方法主要通过测量重要性和冗余来减少参数。

**Method:** 提出了一种基于线性的神经网络压缩方法。其核心思想是，对于ReLU类激活函数，几乎总是激活的神经元表现出线性行为，这允许合并后续层。该方法包括理论介绍和实验评估。

**Result:** 在大多数测试模型中，实现了高达1/4原始模型大小的无损压缩。将该方法应用于已进行基于重要性剪枝的模型时，显示出不同类型压缩之间干扰极小，证明了技术成功组合的可能性。

**Conclusion:** 本文为一种新型的神经网络压缩方法奠定了基础，该方法能够实现更小、最终更高效的神经网络模型。

> **ai_Abstract:** 本文提出了一种新颖的基于线性的神经网络压缩方法，旨在通过利用ReLU类激活函数下近似线性行为的神经元来合并后续层，从而有效减少模型大小。该方法在理论上得到阐述并经过实验验证，在大多数测试模型中实现了高达1/4的无损压缩。此外，它能与现有的基于重要性的剪枝方法良好结合，为构建更小、更高效的神经网络模型提供了新途径。

> **摘要翻译:** 在神经网络压缩领域，大多数现有方法通过衡量重要性和冗余来减少不必要的参数。为了增强现有高度优化的解决方案，我们提出了一种基于线性的压缩方法，作为减少神经网络权重的创新方式。它基于这样一种直觉：对于ReLU类激活函数，几乎总是激活的神经元表现出线性行为，从而允许合并后续层。我们介绍了这种压缩方法的基础理论，并对我们的方法进行了实验评估。我们的新方法在大多数测试模型中实现了高达原始模型大小1/4的无损压缩。将我们的方法应用于已经基于重要性修剪的模型，显示出不同类型压缩之间干扰极小，证明了成功组合技术的可能性。总的来说，我们的工作为一种新型的压缩方法奠定了基础，该方法能够实现更小、最终更高效的神经网络模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [364] [Diverse Mini-Batch Selection in Reinforcement Learning for Efficient Chemical Exploration in de novo Drug Design](https://arxiv.org/abs/2506.21158)
> *强化学习中多样化小批量选择用于从头药物设计中的高效化学探索*

*Hampus Gummesson Svensson, Ola Engkvist, Jon Paul Janet, Christian Tyrchan, Morteza Haghir Chehreghani* | **Category: cs.LG**

**Keywords:** 强化学习, 多样化小批量选择, 行列式点过程, 从头药物设计, 化学探索

**Comment:** 

> **TL;DR:** 本论文提出了一种基于行列式点过程的强化学习多样化小批量选择框架，用于从头药物设计中的高效化学探索，实验证明该方法在保持高质量的同时显著提高了解决方案的多样性。

**AI_Comments:** 该论文通过引入行列式点过程进行强化学习中的多样化小批量选择，为解决高成本评估和模式崩溃问题提供了一个新颖的视角。将其应用于从头药物设计这一实际且重要的领域，突出了其潜在的应用价值。通过平衡多样性和质量，该方法有望提升药物发现的效率。

<details>
  <summary>Details</summary>

**Motivation:** 在许多实际应用中，评估实例的优劣成本高昂且耗时，尤其是在强化学习中，新的环境交互需要评估以提供奖励信号。为了进行充分探索并避免模式崩溃，从多样化的小批量中学习至关重要。

**Method:** 本文引入了强化学习中的多样化小批量选择方法，并提出使用行列式点过程（Determinantal Point Processes）来完成此任务。该框架应用于从头药物设计中的化学探索。

**Result:** 实验结果表明，所提出的多样化小批量选择框架能够显著提高解决方案的多样性，同时仍能获得高质量的解决方案。

**Conclusion:** 多样化小批量选择框架能有效提升从头药物设计中化学探索的效率和多样性，有助于更快满足未满足的药物需求。

> **ai_Abstract:** 本研究提出了一种在强化学习中进行多样化小批量选择的新框架，利用行列式点过程来解决实例评估成本高昂的问题，尤其是在从头药物设计领域。该方法旨在促进高效的化学探索，通过确保学习批次的多样性来避免模式崩溃。实验证明，该框架在保持高解决方案质量的同时，显著提高了生成分子的多样性，有望加速新药的发现。

> **摘要翻译:** 在许多实际应用中，评估实例的优劣往往是成本高昂且耗时的，例如人工反馈和物理模拟，这与提出新实例形成对比。特别是，这在强化学习中更为关键，因为需要评估与环境的新交互（即新实例）以提供学习所需的奖励信号。由于充分探索至关重要，从多样化的小批量中学习可以产生巨大影响并有助于缓解模式崩溃。在本文中，我们引入了强化学习中的多样化小批量选择，并提出使用行列式点过程来完成此任务。我们在一个实际问题，即药物发现的背景下研究了该框架。我们通过实验研究了我们提出的框架如何提高从头药物设计中化学探索的有效性，其中找到多样化和高质量的解决方案至关重要。我们使用三个成熟的分子生成预言机进行了多次生成步骤的全面评估。我们的实验得出结论，我们的多样化小批量选择框架可以显著提高解决方案的多样性，同时仍能获得高质量的解决方案。在药物发现中，这样的结果可能潜在地导致更快地满足未满足的药物需求。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [365] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
> *潜在原型路由：实现专家混合模型中近乎完美的负载均衡*

*Jiajie Yang* | **Category: cs.LG, cs.CL**

**Keywords:** 专家混合, 负载均衡, 潜在原型路由, 大型语言模型, 路由

**Comment:** 15 pages,4 figures

> **TL;DR:** 提出潜在原型路由（LPR）框架，显著改善专家混合（MoE）模型中的专家负载不平衡问题，实现近乎完美的负载均衡。

**AI_Comments:** 这篇论文的创新点在于从聚类视角重新审视专家路由，并提出了LPR框架，有效解决了MoE模型中长期存在的负载不平衡问题。其重要性在于通过提高专家利用率，能够更高效地利用LLM的计算资源和模型容量，对于MoE架构的实际部署和扩展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的专家混合（MoE）系统存在严重的负载不平衡问题，即在训练和推理过程中只有一小部分专家被持续激活，导致模型容量和计算资源严重未被充分利用。

**Method:** 通过聚类视角重新审视专家路由，并提出了潜在原型路由（LPR），这是一个新颖的路由框架，它推广了现有方法，并在不损害下游性能的情况下促进平衡的专家利用。

**Result:** 在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上，LPR将专家负载的基尼系数平均从0.70降低到0.035，并将最小-最大专家负载比从1e-6提高到0.70，实现了近乎完美的负载均衡。

**Conclusion:** 潜在原型路由（LPR）能够显著解决MoE模型中的负载不平衡问题，实现近乎完美的负载均衡，同时不影响模型性能，有效提升资源利用率。

> **ai_Abstract:** 这篇论文提出了一种名为“潜在原型路由”（LPR）的新型专家路由框架，旨在解决大型语言模型中专家混合（MoE）架构普遍存在的负载不平衡问题。LPR通过聚类视角优化专家分配，确保专家得到更平衡的利用，同时不影响模型性能。实验证明，LPR能显著降低专家负载的基尼系数并提高最小-最大负载比，从而在多种MoE模型中实现近乎完美的负载均衡，有效提升资源利用率。

> **摘要翻译:** 专家混合（MoE）架构已成为有效扩展大型语言模型（LLM）的关键策略。然而，当前的MoE系统存在严重的负载不平衡问题，在训练和推理过程中只有一小部分专家被持续激活，导致模型容量和计算资源严重未被充分利用。在这项工作中，我们通过聚类视角重新审视专家路由，并提出了潜在原型路由（LPR），这是一个新颖的路由框架，它推广了现有方法，同时在不损害下游性能的情况下促进平衡的专家利用。在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上进行的大量实验表明，LPR将专家负载的基尼系数平均从0.70降低到0.035，将最小-最大专家负载比从1e-6提高到0.70，实现了近乎完美的负载均衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [368] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
> *通过随机变分子空间推断实现大型语言模型的可扩展贝叶斯低秩适应*

*Colin Samplawski, Adam D. Cobb, Manoj Acharya, Ramneet Kaur, Susmit Jha* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 贝叶斯深度学习, 大型语言模型, 低秩适应, 不确定性量化, 随机变分推断

**Comment:** Accepted at UAI 2025

> **TL;DR:** 本文提出了ScalaBL，一种新的贝叶斯低秩适应方法，通过在低维子空间中进行推断，显著减少了额外参数需求，并能扩展到更大的LLM，同时保持与现有技术相当的性能，解决了贝叶斯LLM的可扩展性问题。

**AI_Comments:** 本文的创新点在于提出了ScalaBL，通过利用低维子空间推断和重新利用LoRA参数作为投影矩阵，显著降低了贝叶斯LLM的额外参数需求，并提高了其可扩展性。这对于在资源受限的环境下实现LLM的不确定性量化具有重要意义，尤其是在高风险应用领域。其能够扩展到更大模型的能力是该研究的一个重要突破。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）广泛使用，但它们存在幻觉错误信息和校准不佳的问题，这使得LLM的不确定性量化至关重要，尤其是在自动驾驶和医疗保健等高风险领域。现有基于贝叶斯深度学习的方法通过对微调模型的低秩适应（LoRA）参数进行推断，虽然有效，但由于需要额外的参数，难以扩展到更大的LLM。

**Method:** 本文提出了可扩展贝叶斯低秩适应（ScalaBL），通过随机变分子空间推断实现。该方法在LoRA秩r的r维子空间中进行贝叶斯推断。通过将LoRA参数重新用作投影矩阵，能够将来自子空间的样本映射到LLM的完整权重空间。所有参数都使用随机变分推断进行学习。

**Result:** ScalaBL在仅需要约1000个额外参数的情况下，能够与最先进的方法达到竞争性性能。此外，它能够扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

**Conclusion:** 本文提出的ScalaBL方法通过在低维子空间中进行贝叶斯推断，成功解决了大型语言模型贝叶斯不确定性量化的可扩展性问题，并在参数效率和模型规模方面取得了显著的改进，同时保持了高性能。

> **ai_Abstract:** 本文提出了一种名为ScalaBL的可扩展贝叶斯低秩适应方法，旨在解决大型语言模型的不确定性量化问题及其现有贝叶斯方法的可扩展性挑战。ScalaBL通过在低维子空间中进行贝叶斯推断，并将LoRA参数用作投影矩阵，实现了将子空间样本映射到LLM的全权重空间。该方法仅需约1000个额外参数，即可达到与现有技术相当的性能，并成功扩展到比以往更大的贝叶斯LLM。

> **摘要翻译:** 尽管大型语言模型（LLMs）广泛使用，但它们存在幻觉错误信息和校准不佳的问题。这使得这些模型的不确定性量化至关重要，尤其是在自动驾驶和医疗保健等高风险领域。先前的工作通过对微调模型的低秩适应（LoRA）参数进行推断，使得基于贝叶斯深度学习的方法解决了这个问题，变得更易处理。然而，这些方法由于需要比LoRA更多的额外参数，难以扩展到更大的LLM。在这项工作中，我们提出了通过随机变分子空间推断实现的可扩展贝叶斯低秩适应（ScalaBL）。我们对LoRA秩r的r维子空间进行贝叶斯推断。通过将LoRA参数重新用作投影矩阵，我们能够将来自此子空间的样本映射到LLM的完整权重空间。这使我们能够使用随机变分推断学习我们方法的所有参数。尽管我们的子空间维度较低，但我们能够以仅需要约1000个额外参数的代价，实现与最先进方法相当的性能。此外，它使我们能够扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [369] [Zero-Shot Learning for Obsolescence Risk Forecasting](https://arxiv.org/abs/2506.21240)
> *零样本学习在报废风险预测中的应用*

*Elie Saad, Aya Mrabah, Mariem Besbes, Marc Zolghadri, Victor Czmil, Claude Baron, Vincent Bourgeois* | **Category: cs.LG**

**Keywords:** 零样本学习, 报废风险预测, 大型语言模型, 数据稀缺, 电子元件

**Comment:** 

> **TL;DR:** 本文提出了一种利用零样本学习（ZSL）和大型语言模型（LLMs）来预测电子元件报废风险的新方法，以应对数据稀缺问题，并在实际数据集中展现了有效性。

**AI_Comments:** 该论文的创新点在于将零样本学习和大型语言模型应用于传统上数据稀缺的报废风险预测领域，为解决数据限制问题提供了一种新颖的思路。其重要性在于能够帮助行业提高预测准确性，减少成本和系统中断。论文还通过比较评估不同LLM，为实际应用提供了选型指导。

<details>
  <summary>Details</summary>

**Motivation:** 电子元件报废给相关行业带来了巨大的挑战，导致成本增加和系统安全与可用性中断。准确的报废风险预测至关重要，但受限于可靠数据的缺乏。

**Method:** 本文提出了一种新颖的方法，利用零样本学习（ZSL）结合大型语言模型（LLMs）来预测报废风险，通过利用表格数据集中的领域特定知识来解决数据限制。该方法应用于两个真实世界数据集。

**Result:** 该方法在两个真实世界数据集中展示了有效的风险预测能力。对四种LLM的比较评估强调了为特定预测任务选择合适模型的重要性。

**Conclusion:** 利用零样本学习和大型语言模型可以有效预测报废风险，且选择合适的LLM对于特定的预测任务至关重要。

> **ai_Abstract:** 本文针对电子元件报废风险预测中数据匮乏的挑战，提出了一种创新性的零样本学习（ZSL）方法，结合大型语言模型（LLMs）和领域特定表格数据进行风险预测。该方法在实际数据集中表现出有效性，并且研究强调了为特定预测任务选择合适LLM的重要性。

> **摘要翻译:** 电子元件报废给依赖电子元件的行业带来了巨大的挑战，导致成本增加以及系统安全性和可用性的中断。准确的报废风险预测至关重要，但受到可靠数据缺乏的阻碍。本文提出了一种利用零样本学习（ZSL）与大型语言模型（LLMs）相结合来预测报废风险的新方法，通过利用表格数据集中的领域特定知识来解决数据限制。该方法应用于两个真实世界数据集，展示了有效的风险预测能力。对四种LLM的比较评估强调了为特定预测任务选择合适模型的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [373] [Improved seeding strategies for k-means and k-GMM](https://arxiv.org/abs/2506.21291)
> *改进的k-means和k-GMM播种策略*

*Guillaume Carrière, Frédéric Cazals* | **Category: cs.LG, F.2; G.3**

**Keywords:** k-means, k-GMM, 播种策略, 初始化, 聚类

**Comment:** 13 pages

> **TL;DR:** 本文重新审视并改进了k-means和k-GMM的随机播种技术，通过引入前瞻性原则和多通道策略，实现了在最终评估指标上的显著性能提升，并揭示了k-means的一些细微特性。

**AI_Comments:** 本文的创新之处在于对k-means和k-GMM随机播种技术的深入形式化，并由此提出了结合“前瞻性原则”和“多通道策略”的新型初始化方法。其重要性体现在两方面：实践上，它提供了在性能上超越现有顶级方法的播种策略，有望成为新的工业标准；理论上，这种形式化为播种算法的分析打开了新的研究路径。此外，实验分析还揭示了k-means的一些常被忽视的特性，增加了对算法行为的理解。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在改进k-means聚类和k-GMM（高斯混合模型拟合）的随机播种技术，通过形式化其关键组成部分，以期在性能上超越现有方法，特别是最近设计的multi-swap策略和贪婪的k-means++播种方法。

**Method:** 作者重新审视了k-means和k-GMM的随机播种技术，并形式化了其三个关键要素：用于种子采样的度量、候选种子的数量以及用于种子选择的度量。在此基础上，提出了利用“前瞻性原则”（根据最终评估算法的度量标准增强种子选择的一致性）和“多通道策略”（以驯服随机化效应）的新型初始化方法家族。

**Result:** 实验结果表明，与经典竞争者相比，所提出的方法在最终度量（k-means的SSE，k-GMM的对数似然）方面实现了持续的常数因子改进，且开销适中。特别是对于k-means，这些方法改进了最近设计的multi-swap策略，后者是第一个超越贪婪k-means++播种的方法。实验分析还揭示了k-means的一些常被忽视的微妙特性，包括播种时的SSE与最终SSE之间（缺乏）相关性、迭代播种方法中观察到的方差减少现象，以及最终SSE对贪婪方法池大小的敏感性。

**Conclusion:** 本文提出的最有效的播种方法有望成为标准技术之一。从理论角度看，播种的形式化为新的分析方法打开了大门。

> **ai_Abstract:** 本文重新审视了k-means和k-GMM的随机播种技术，并对其关键组成部分进行了形式化。在此基础上，提出了基于前瞻性原则和多通道策略的新型初始化方法。实验证明，这些方法在最终评估指标上取得了显著且持续的改进，性能超越了现有的先进播种策略，并揭示了k-means的一些深层特性。这些新方法有望成为业界标准，并为播种理论研究开辟了新方向。

> **摘要翻译:** 我们重新审视了k-means聚类和k-GMM（通过期望最大化进行高斯混合模型拟合）的随机播种技术，并形式化了其三个关键组成部分：用于种子采样的度量、候选种子的数量以及用于种子选择的度量。这项分析产生了利用前瞻性原则（根据用于评估算法的最终度量增强种子选择的一致性）和多通道策略（以驯服随机化效应）的新型初始化方法家族。
实验表明，在最终度量（k-means的SSE，k-GMM的对数似然）方面，与经典竞争者相比，在适度的开销下，实现了持续的常数因子改进。特别是对于k-means，我们的方法改进了最近设计的multi-swap策略，这是第一个超越贪婪k-means++播种的方法。
我们的实验分析还揭示了k-means的一些常被忽视的细微特性，包括播种时的SSE与最终SSE之间（缺乏）相关性、迭代播种方法中观察到的方差减少现象，以及最终SSE对贪婪方法池大小的敏感性。
实际上，我们最有效的播种方法是成为标准技术之一（如果不是唯一）的有力候选者。从理论角度看，我们对播种的形式化为新的分析方法打开了大门。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [378] [DynamicBench: Evaluating Real-Time Report Generation in Large Language Models](https://arxiv.org/abs/2506.21343)
> *DynamicBench：评估大型语言模型中的实时报告生成*

*Jingyao Li, Hao Sun, Zile Qiao, Yong Jiang, Pengjun Xie, Fei Huang, Hong Xu, Jiaya Jia* | **Category: cs.LG**

**Keywords:** 大型语言模型, 实时报告生成, 基准测试, 动态评估, DynamicBench

**Comment:** 

> **TL;DR:** DynamicBench是一个新的基准测试，用于评估LLM处理和生成实时报告的能力，它采用双路径检索，并在无文档和有文档场景下表现优于GPT4o。

**AI_Comments:** 该论文的创新之处在于提出了一个针对LLM实时信息处理能力的动态评估基准DynamicBench，弥补了传统静态评估的不足。其采用的双路径检索管道（网络搜索与本地数据库结合）以及在不同文档提供情况下的评估方式，能够更全面地衡量LLM处理动态信息和利用上下文的能力。此外，超越GPT4o的性能表明了其方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的LLM基准测试未能捕捉到当代应用中实时信息处理的动态需求，因此需要一个新的基准来评估LLM处理最新数据的能力。

**Method:** 本文提出了DynamicBench，一个旨在评估LLM存储和处理实时数据能力的基准。它采用双路径检索管道，整合了网络搜索和本地报告数据库，并要求领域特定知识。DynamicBench通过在提供或不提供外部文档的场景中评估模型，来衡量其独立处理最新信息或利用上下文增强的能力。此外，还引入了一个先进的报告生成系统来管理动态信息合成。

**Result:** 实验结果证实了该方法的有效性，其方法实现了最先进的性能，在无文档和文档辅助场景中分别超越GPT4o 7.0%和5.8%。

**Conclusion:** DynamicBench是一个有效且性能卓越的基准测试和报告生成系统，能够评估并提升大型语言模型在实时动态信息处理方面的能力，并在多项任务中超越现有最先进模型。

> **ai_Abstract:** 本文介绍了DynamicBench，一个旨在评估大型语言模型（LLM）实时报告生成能力的基准测试。针对传统静态评估的局限性，DynamicBench采用双路径检索管道，结合网络搜索和本地数据库，并在有无外部文档的场景下测试LLM处理最新信息的能力。研究还提出了一个先进的报告生成系统。实验结果表明，DynamicBench方法在性能上超越了GPT4o，验证了其在动态信息处理方面的有效性。

> **摘要翻译:** 大型语言模型（LLM）的传统基准测试通常依赖于通过讲故事或表达意见进行的静态评估，这未能捕捉到当代应用中实时信息处理的动态需求。为了解决这一限制，我们提出了DynamicBench，一个旨在评估LLM存储和处理最新数据能力的基准。DynamicBench利用双路径检索管道，整合了网络搜索和本地报告数据库。它需要领域特定知识，以确保在专业领域内生成准确的报告。通过在提供或不提供外部文档的场景中评估模型，DynamicBench有效地衡量了它们独立处理最新信息或利用上下文增强的能力。此外，我们引入了一个先进的报告生成系统，擅长管理动态信息合成。我们的实验结果证实了我们方法的有效性，我们的方法实现了最先进的性能，在无文档和文档辅助场景中分别超越GPT4o 7.0%和5.8%。代码和数据将公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [381] [SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning](https://arxiv.org/abs/2506.21355)
> *SMMILE：一个专家驱动的多模态医学情境学习基准*

*Melanie Rieff, Maya Varma, Ossian Rabow, Subathra Adithan, Julie Kim, Ken Chang, Hannah Lee, Nidhi Rohatgi, Christian Bluethgen, Mohamed S. Muneer, Jean-Benoit Delbrouck, Michael Moor* | **Category: cs.LG**

**Keywords:** 多模态情0境学习, 医学AI, 基准测试, MLLMs, SMMILE

**Comment:** 

> **TL;DR:** SMMILE引入了首个专家驱动的多模态医学情境学习基准，评估了MLLM在此类任务上的表现，发现现有模型表现不佳，且对不相关示例和示例顺序敏感。

**AI_Comments:** 该论文的创新之处在于构建了首个专家驱动的多模态医学ICL基准SMMILE及其增强版SMMILE++，填补了该领域基准测试的空白。其重要性在于揭示了当前MLLMs在医学多模态情境学习方面的不足和存在的偏见，为未来的模型改进提供了明确的方向。特别是对不相关示例敏感性和近因偏见的发现，对设计更鲁棒和有效的ICL策略具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态情境学习（ICL）在医学等领域具有巨大潜力，但其探索不足。临床医生常遇到需要从有限示例中学习的专业任务。虽然多模态大型语言模型（MLLMs）在医学视觉问答（VQA）方面取得进展，但其从情境中学习多模态任务的能力尚不清楚。

**Method:** 引入了SMMILE，首个专家驱动的多模态医学任务ICL基准。11位医学专家策划了111个问题（517个问答-图像三元组），涵盖6个医学专业和13种成像模式。进一步引入了SMMILE++，一个包含1038个排列问题的增强变体。对15个MLLM进行了全面评估。

**Result:** 大多数模型在医学任务中的多模态ICL能力表现为中等到差。在开放式评估中，ICL在SMMILE上仅比零样本平均提高8%，在SMMILE++上提高9.4%。发现模型容易受到不相关情境示例的影响：即使单个噪声或不相关示例也能使性能下降高达9.5%。此外，示例顺序表现出近因偏见，即把最相关的示例放在最后可以带来高达71%的显著性能提升。

**Conclusion:** 研究结果强调了当前MLLM在从情境中学习多模态医学任务时存在的关键局限性和偏见。

> **ai_Abstract:** 本研究介绍了SMMILE，一个由11位医学专家构建的、首个专家驱动的多模态医学情境学习（ICL）基准，包含111个问题和517个问答-图像三元组，涵盖6个医学专业和13种成像模式。同时提出了增强版SMMILE++。通过对15个多模态大型语言模型（MLLMs）的评估发现，现有模型在医学多模态ICL任务中表现普遍不佳，ICL相对于零样本的提升有限。研究还揭示了MLLMs对不相关情境示例的敏感性以及示例顺序的近因偏见，凸显了当前MLLMs在医学情境学习中的局限性。

> **摘要翻译:** 多模态情境学习（ICL）尽管在医学等领域具有巨大潜力，但仍未得到充分探索。临床医生经常遇到需要从有限示例中适应的各种专业任务，例如从少量相关先例中获取见解或考虑一组受限的鉴别诊断。尽管多模态大型语言模型（MLLMs）在医学视觉问答（VQA）方面取得了进展，但它们从情境中学习多模态任务的能力在很大程度上是未知的。我们引入了SMMILE，这是第一个专家驱动的医学任务多模态ICL基准。十一位医学专家策划了问题，每个问题都包含一个多模态查询和多模态情境示例作为任务演示。SMMILE包含111个问题（517个问答-图像三元组），涵盖6个医学专业和13种成像模式。我们进一步引入了SMMILE++，一个包含1038个排列问题的增强变体。对15个MLLM的全面评估表明，大多数模型在医学任务中表现出中等到差的多模态ICL能力。在开放式评估中，ICL在SMMILE上仅比零样本平均提高8%，在SMMILE++上提高9.4%。我们观察到模型对不相关情境示例的敏感性：即使单个噪声或不相关示例也能使性能下降高达9.5%。此外，示例排序表现出近因偏见，即把最相关的示例放在最后可以带来高达71%的显著性能提升。我们的研究结果强调了当前MLLM在从情境中学习多模态医学任务时存在的关键局限性和偏见。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [382] [rQdia: Regularizing Q-Value Distributions With Image Augmentation](https://arxiv.org/abs/2506.21367)
> *rQdia：使用图像增强正则化Q值分布*

*Sam Lerman, Jing Bi* | **Category: cs.LG, cs.AI**

**Keywords:** Q值分布正则化, 图像增强, 深度强化学习, 无模型控制, 像素级控制

**Comment:** 

> **TL;DR:** rQdia通过图像增强和简单的辅助损失正则化Q值分布，显著提升了像素级深度强化学习（如DrQ、SAC、Rainbow）的性能，并使无模型连续控制超越了状态编码基线。

**AI_Comments:** rQdia的创新在于将图像增强与Q值分布正则化结合，通过一个简单的辅助损失实现了显著的性能提升。其重要性体现在它不仅提升了现有算法的效率和长期表现，还使像素级的无模型连续控制达到了超越状态编码基线的里程碑，这对于实际应用中从原始像素输入进行控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过正则化Q值分布来提升像素级深度强化学习的性能。

**Method:** rQdia通过图像增强来正则化像素级深度强化学习中的Q值分布。它使用一个简单的辅助损失函数，通过均方误差（MSE）来均衡这些分布。

**Result:** rQdia在MuJoCo连续控制套件中，分别提升了DrQ在9/12任务和SAC在10/12任务上的表现，并在26个Atari街机环境中的18个提升了Data-Efficient Rainbow的性能。性能提升体现在样本效率和长期训练。此外，rQdia的加入使得像素级的无模型连续控制超越了状态编码基线。

**Conclusion:** rQdia通过正则化Q值分布，显著提升了现有像素级深度强化学习算法的性能，并使无模型连续控制从像素输入超越了状态编码基线。

> **ai_Abstract:** rQdia是一种在像素级深度强化学习中，通过图像增强和基于MSE的辅助损失来正则化Q值分布的方法。该方法显著提升了DrQ、SAC和Data-Efficient Rainbow在多个基准测试（MuJoCo和Atari）上的性能，并在样本效率和长期训练方面均有增益。值得注意的是，rQdia使无模型连续控制从像素输入超越了状态编码基线。

> **摘要翻译:** rQdia通过增强图像来正则化基于像素的深度强化学习中的Q值分布。通过一个简单的辅助损失函数，该函数通过均方误差（MSE）来均衡这些分布，rQdia在MuJoCo连续控制套件中分别提升了DrQ在12个任务中的9个和SAC在12个任务中的10个的表现，并提升了Data-Efficient Rainbow在26个Atari街机环境中的18个。性能提升体现在样本效率和长期训练。此外，rQdia的加入最终使基于像素的无模型连续控制超越了状态编码基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN Hardware Accelerators](https://arxiv.org/abs/2506.21371)
> *MAx-DNN：用于节能型DNN硬件加速器的多级算术近似*

*Vasileios Leon, Georgios Makris, Sotirios Xydis, Kiamal Pekmestzi, Dimitrios Soudris* | **Category: cs.LG, cs.AR**

**Keywords:** DNN, 硬件加速器, 算术近似, 能效, 多级近似

**Comment:** Presented at the 13th IEEE LASCAS Conference

> **TL;DR:** MAx-DNN通过在层、滤波器和核级别应用细粒度近似乘法器，显著提高了DNN硬件加速器的能效，同时将精度损失控制在可接受范围内。

**AI_Comments:** 该论文的创新点在于提出了多级（层、滤波器、核）的细粒度算术近似方法，并系统地探索了近似乘法器在DNN中的分布。其重要性体现在显著提高了DNN硬件加速器的能效，同时将精度损失控制在可接受的范围内，甚至优于现有技术，这对于边缘计算和低功耗AI设备具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）架构的快速增长使其成为提供高级机器学习任务的事实标准，但其计算需求高。本研究旨在通过硬件近似技术实现低功耗DNN计算，以提高能效。

**Method:** 本研究利用最先进的ROUP近似乘法器，系统地探索了其在网络中细粒度的分布，并提出了层级、滤波器级和核级的方法。通过检查DNN工作负载的细粒度错误弹性与硬件近似技术之间的相互作用，以实现更高的能效。使用ResNet-8模型在CIFAR-10数据集上进行评估。

**Result:** 与基线量化模型相比，所提出的解决方案实现了高达54%的能耗增益，而精度损失最高为4%。与最先进的DNN近似方法相比，它提供了2倍的能耗增益，同时保持了更好的精度。

**Conclusion:** MAx-DNN通过在DNN硬件加速器中引入多级算术近似，显著提高了能效，同时将精度损失控制在可接受的范围内，甚至优于现有最先进的近似方法。

> **ai_Abstract:** 本文提出MAx-DNN，一种用于节能型DNN硬件加速器的多级算术近似方法。该方法利用ROUP近似乘法器，在层、滤波器和核级别上系统地探索其细粒度分布，以利用DNN工作负载的错误弹性。在ResNet-8模型和CIFAR-10数据集上的评估显示，与基线量化模型相比，MAx-DNN可实现高达54%的能耗增益，精度损失最大为4%；与现有最先进的DNN近似方法相比，可实现2倍能耗增益且精度更优。

> **摘要翻译:** 如今，深度神经网络（DNN）架构的快速发展已使其成为提供具有出色准确性的高级机器学习任务的事实方法。针对低功耗DNN计算，本文研究了DNN工作负载的细粒度错误弹性与硬件近似技术之间的相互作用，以实现更高水平的能效。我们利用最先进的ROUP近似乘法器，系统地探索了它们在网络中根据我们的层级、滤波器级和核级方法的细粒度分布，并检查了它们对准确性和能耗的影响。我们使用CIFAR-10数据集上的ResNet-8模型来评估我们的近似。与基线量化模型相比，所提出的解决方案实现了高达54%的能耗增益，而精度损失最高为4%，同时与最先进的DNN近似方法相比，它提供了2倍的能耗增益，并具有更好的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [386] [Pay Attention to Small Weights](https://arxiv.org/abs/2506.21374)
> *关注小权重*

*Chao Zhou, Tom Jacobs, Advait Gadhikar, Rebekka Burkholz* | **Category: cs.LG, cs.AI**

**Keywords:** 微调, 预训练模型, NANOADAM, 资源效率, 泛化性能

**Comment:** 

> **TL;DR:** 论文提出NANOADAM，一种动态更新预训练模型中小型权重的方法，以减少微调时的资源消耗，同时提高泛化性能并减少灾难性遗忘。

**AI_Comments:** 这篇论文通过深入分析梯度与权重的关系，提出了一种新颖且高效的微调策略。其创新点在于利用小权重与大梯度的关联性，设计出一种无梯度、能有效减少灾难性遗忘并提升泛化性能的方法。NANOADAM的提出对于资源受限的深度学习应用具有重要意义，提供了一种更经济且高效的模型微调范式。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型预训练神经网络资源消耗大（内存和计算成本高）。现有方法是限制训练参数子集。作者通过分析发现微调时大梯度常与小权重相关，受此启发提出新方法。

**Method:** 提出NANOADAM方法，在微调过程中动态地只更新小幅度的权重。该方法无需梯度计算即可确定参数子集，能保留大权重以减少灾难性遗忘，并允许使用更大的学习率。

**Result:** NANOADAM在实验中持续带来更好的泛化性能，并在NLP和视觉任务中得到验证。

**Conclusion:** 通过只更新小权重，NANOADAM有效降低了微调的资源消耗，同时提升了模型性能，并减少了灾难性遗忘。

> **ai_Abstract:** 本文针对大型预训练模型微调时资源消耗大的问题，提出了一种名为NANOADAM的新方法。该方法基于一个观察，即微调时大梯度常与小幅度权重相关。NANOADAM动态地只更新模型中的小幅度权重，从而实现无梯度确定更新参数、保留关键特征以减少灾难性遗忘、并允许使用更大学习率，最终在NLP和视觉任务中展现出更好的泛化性能。

> **摘要翻译:** 微调大型预训练神经网络在内存和计算成本方面都已知是资源密集型的。为了缓解这一问题，一种常见的方法是将训练限制在模型参数的一个子集上。通过分析微调过程中梯度与权重之间的关系，我们观察到一个显著的模式：大梯度通常与小幅度的权重相关。这种相关性在微调设置中比从头开始训练时更为明显。受此观察的启发，我们提出了NANOADAM，它在微调过程中动态地只更新小幅度的权重，并提供了几个实际优势：首先，这个标准是无梯度的——参数子集可以在不计算梯度的情况下确定；其次，它保留了大幅度的权重，这些权重可能编码了预训练期间学到的关键特征，从而降低了灾难性遗忘的风险；第三，它允许使用更大的学习率，并在实验中持续带来更好的泛化性能。我们在自然语言处理（NLP）和视觉任务中都证明了这一点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [387] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
> *用于加密货币交易欺诈检测的时间感知图注意力网络*

*Zhi Zheng, Bochuan Zhou, Yuping Song* | **Category: cs.LG, cs.AI**

**Keywords:** 加密货币欺诈检测, 图注意力网络, 时间感知, 类别不平衡, 三重注意力

**Comment:** 

> **TL;DR:** 本文提出了一种名为ATGAT的增强型时间感知图注意力网络，通过融合时间特征、构建三重注意力机制和使用加权BCE损失来解决加密货币交易欺诈检测中复杂的交易模式和类别不平衡问题，并在Elliptic++数据集上取得了显著的性能提升。

**AI_Comments:** 该论文的创新点在于提出了增强型时间感知图注意力网络（ATGAT），特别是在时间特征融合（多尺度时间差与周期位置编码）和三重注意力机制（结构、时间、全局上下文）方面，有效解决了加密货币交易欺诈中时间依赖性和复杂模式捕捉的难题。其性能提升显著，且方法具有一定的通用性，可应用于其他时间图异常检测任务，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 加密货币交易欺诈检测面临交易模式日益复杂和类别严重不平衡的双重挑战。传统方法依赖手动特征工程，难以捕捉交易网络中的时间依赖性和结构依赖性。

**Method:** 本文提出了一种增强型时间感知图注意力网络（ATGAT），通过以下三个模块提升检测性能：1) 设计先进的时间嵌入模块，融合多尺度时间差特征与周期位置编码；2) 构建时间感知三重注意力机制，共同优化结构、时间及全局上下文注意力；3) 采用加权BCE损失以解决类别不平衡问题。

**Result:** 在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比最佳传统方法XGBoost提高了9.2%，比GCN提高了12.0%，比标准GAT提高了10.0%。

**Conclusion:** 该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广到其他时间图异常检测任务。

> **ai_Abstract:** 本文提出了一种增强型时间感知图注意力网络（ATGAT），旨在解决加密货币交易欺诈检测中复杂的交易模式和严重的类别不平衡问题。ATGAT通过融合多尺度时间差特征和周期位置编码的时间嵌入模块、共同优化结构、时间及全局上下文注意力的时间感知三重注意力机制，以及采用加权BCE损失来提升性能。实验证明，ATGAT在Elliptic++数据集上取得了显著优于传统方法和现有图神经网络的欺诈检测效果，验证了其创新机制的有效性，并为金融机构提供了更可靠的工具。

> **摘要翻译:** 加密货币交易欺诈检测面临日益复杂的交易模式和严重的类别不平衡的双重挑战。传统方法依赖于手动特征工程，难以捕捉交易网络中的时间和结构依赖性。本文提出了一种增强型时间感知图注意力网络（ATGAT），通过三个模块提高检测性能：(1) 设计一个先进的时间嵌入模块，融合多尺度时间差特征与周期位置编码；(2) 构建一个时间感知三重注意力机制，共同优化结构、时间及全局上下文注意力；(3) 采用加权BCE损失以解决类别不平衡。在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比最佳传统方法XGBoost提高了9.2%，比GCN提高了12.0%，比标准GAT提高了10.0%。该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广到其他时间图异常检测任务。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [Early Stopping Tabular In-Context Learning](https://arxiv.org/abs/2506.21387)
> *表格上下文学习的提前停止*

*Jaris Küken, Lennart Purucker, Frank Hutter* | **Category: cs.LG**

**Keywords:** 表格上下文学习, 提前停止, 推理加速, Transformer编码器

**Comment:** ICML Workshop Paper

> **TL;DR:** 本文提出了一种提前停止策略，通过在每个Transformer编码器层后动态评估是否停止上下文学习，从而显著加速表格上下文学习的推理过程，同时保持预测性能。

**AI_Comments:** 该论文提出了一种创新的方法来解决表格上下文学习中推理时间成本高的问题，即采用提前停止策略。这种方法通过动态评估停止点，有效平衡了计算效率和模型性能，对于实际应用具有重要意义。其创新性在于将早期退出机制应用于表格领域的上下文学习，为未来基础模型在资源受限环境下的部署提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 表格基础模型通过上下文学习在各种表格学习任务中表现出色，但其推理时间成本很高，特别是对于大型数据集。

**Method:** 我们提出了提前停止上下文学习过程。通过在每个Transformer编码器层之后动态评估是否停止上下文学习来实现。一旦停止，我们使用预训练的逐层解码器解码嵌入。

**Result:** 在34个小型分类任务上的实验表明，提前停止上下文学习可将推理速度提高达1.3倍，同时预测性能下降可忽略不计。在5个大型分类任务上进一步评估，速度提升高达2.2倍。

**Conclusion:** 我们的结果表明，提前退出是提高表格上下文学习效率的一种有效且实用的策略。

> **ai_Abstract:** 本文针对表格基础模型在上下文学习中推理成本高的问题，提出了一种提前停止上下文学习的策略。该方法通过在Transformer编码器层后动态评估停止点，并使用预训练解码器解码嵌入。实验结果显示，在小型分类任务上可加速1.3倍且性能无显著下降，在大型任务上可加速高达2.2倍，证明了提前退出在提高表格上下文学习效率方面的潜力。

> **摘要翻译:** 表格基础模型通过上下文学习在各种表格学习任务中表现出强大的性能，无需任何下游微调即可提供强大的泛化能力。然而，它们的推理时间成本仍然很高，特别是对于大型数据集。为了解决这个问题，我们提出了提前停止上下文学习过程。我们通过在每个Transformer编码器层之后动态评估是否停止上下文学习来实现这一点。一旦停止，我们使用预训练的逐层解码器解码嵌入。在34个小型分类任务上的实验表明，提前停止上下文学习可将推理速度提高达1.3倍，同时预测性能下降可忽略不计。为了评估可扩展性，我们进一步在五个大型分类任务上评估了我们的方法，实现了高达2.2倍的速度提升。我们的结果表明，提前退出是提高表格上下文学习效率的一种有效且实用的策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [391] [Distributed Cross-Channel Hierarchical Aggregation for Foundation Models](https://arxiv.org/abs/2506.21411)
> *分布式跨通道分层聚合基础模型*

*Aristeidis Tsaris, Isaac Lyngaas, John Lagregren, Mohamed Wahib, Larry York, Prasanna Balaprakash, Dan Lu, Feiyi Wang, Xiao Wang* | **Category: cs.LG**

**Keywords:** 分布式聚合, 基础模型, 视觉Transformer, 计算效率, 高光谱成像

**Comment:** 

> **TL;DR:** 本文提出了分布式跨通道分层聚合（D-CHAG）方法，用于视觉科学基础模型，显著提高了多通道图像数据的计算效率并减少了内存使用。

**AI_Comments:** 该论文为训练大型视觉基础模型（特别是处理高维数据如高光谱图像的模型）引入了一项重要的优化。D-CHAG方法与现有并行策略的兼容性以及在超级计算机上实现的显著性能提升（内存减少、吞吐量增加）突显了其实用价值和加速科学发现的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前分布式方法未能充分解决视觉科学基础模型在对图像进行标记和聚合时计算密集的问题，特别是对于具有大量通道的数据集。

**Method:** 本文引入了分布式跨通道分层聚合（D-CHAG）方法，专为具有大量图像模态通道的数据集设计。该方法兼容任何模型并行策略和任何类型的视觉Transformer架构。通过与张量并行和模型分片集成，在超光谱成像和天气预报任务上进行了评估。

**Result:** 当与张量并行和模型分片集成时，D-CHAG在多达1,024个AMD GPU上实现了高达75%的内存使用量减少，并在Frontier超级计算机上将持续吞吐量提高了一倍以上。

**Conclusion:** D-CHAG显著提高了视觉基础模型处理大型多通道数据集的计算效率和内存利用率，并在超级计算机上展示了强大的可扩展性。

> **ai_Abstract:** 本文提出了一种名为分布式跨通道分层聚合（D-CHAG）的新方法，旨在解决基于视觉的科学基础模型在处理多通道图像数据时面临的计算挑战。D-CHAG兼容多种模型并行策略和视觉Transformer架构，能够显著提高计算效率并减少内存使用。在超光谱成像和天气预报任务上的评估表明，该方法在大型GPU集群上实现了显著的性能提升。

> **摘要翻译:** 基于视觉的科学基础模型在推进科学发现和创新方面具有巨大潜力。这种潜力源于它们能够聚合来自不同来源（例如不同的物理基础或数据采集系统）的图像，并使用Transformer架构学习时空相关性。然而，对图像进行标记化和聚合可能计算密集，这是一个当前分布式方法尚未完全解决的挑战。在这项工作中，我们引入了分布式跨通道分层聚合（D-CHAG）方法，专为具有大量图像模态通道的数据集设计。我们的方法兼容任何模型并行策略和任何类型的视觉Transformer架构，显著提高了计算效率。我们在超光谱成像和天气预报任务上评估了D-CHAG。当与张量并行和模型分片集成时，我们的方法在Frontier超级计算机上使用多达1,024个AMD GPU时，实现了高达75%的内存使用量减少，并将持续吞吐量提高了一倍以上。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [394] [Deception Detection in Dyadic Exchanges Using Multimodal Machine Learning: A Study on a Swedish Cohort](https://arxiv.org/abs/2506.21429)
> *使用多模态机器学习在两人对话中进行欺骗检测：一项针对瑞典人群的研究*

*Franco Rugolon, Thomas Jack Samuels, Stephan Hau, Lennart Högman* | **Category: cs.LG**

**Keywords:** 欺骗检测, 多模态机器学习, 两人互动, 晚期融合, 瑞典人群

**Comment:** 40 pages, 2 figures, 2 tables. To be submitted in Behavior Research
  Methods

> **TL;DR:** 本研究使用多模态机器学习（音频和视频）在瑞典人群中检测两人对话中的欺骗行为。结果显示，结合说话者和被欺骗者的多模态数据（特别是晚期融合）能显著提高欺骗检测准确率，达到71%。

**AI_Comments:** 这项研究的创新之处在于首次在斯堪的纳维亚人群中进行双人互动中的欺骗检测，并强调了结合欺骗者和被欺骗者双方多模态数据（音频和视频）的重要性。其发现对于理解欺骗行为的心理学机制具有价值，并为未来在心理治疗等实际应用中的欺骗检测研究提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索使用多模态机器学习技术提高两人互动中欺骗检测的有效性，并关注整合欺骗者和被欺骗者双方数据的重要性。

**Method:** 研究采用多模态机器学习方法，整合音频和视频数据（特别是动作单元和凝视信息），比较了早期融合和晚期融合策略。数据集是新收集的瑞典母语者在情感相关主题的真实或谎言情景中的数据。分析涵盖了所有可能的模态和参与者组合。

**Result:** 结果表明，结合语音和面部信息的多模态方法优于单一模态方法。此外，纳入双方参与者的数据显著提高了欺骗检测的准确性。最佳性能（71%）是通过对所有模态和参与者应用晚期融合策略实现的。

**Conclusion:** 研究结果与心理学理论一致，表明在初始互动中面部和声音表情的差异化控制。作为首个针对斯堪的纳维亚人群的同类研究，它为未来在两人互动（特别是心理治疗环境）中的研究奠定了基础。

> **ai_Abstract:** 本研究探讨了在两人互动中使用多模态机器学习检测欺骗的有效性，并首次在瑞典人群中进行。研究比较了早期和晚期融合策略，利用欺骗者和被欺骗者的音频（语音）和视频（动作单元、凝视）数据。结果显示，结合语音和面部信息的多模态方法以及纳入双方参与者的数据显著提高了欺骗检测的准确性，最佳准确率为71%（采用晚期融合策略）。这些发现支持了心理学理论，并为未来在心理治疗等情境下的两人互动研究奠定了基础。

> **摘要翻译:** 本研究旨在探讨使用多模态机器学习技术在两人互动中检测欺骗的有效性，重点关注整合欺骗者和被欺骗者双方的数据。我们比较了早期和晚期融合方法，利用音频和视频数据——特别是动作单元和凝视信息——跨所有可能的模态和参与者组合。我们的数据集是新收集的瑞典母语者在情感相关主题的真实或谎言情景中的数据，作为我们分析的基础。结果表明，结合语音和面部信息比单一模态方法表现更优越。此外，纳入双方参与者的数据显著提高了欺骗检测的准确性，最佳性能（71%）是通过对所有模态和参与者应用晚期融合策略实现的。这些发现与心理学理论一致，表明在初始互动中面部和声音表情的差异化控制。作为首个针对斯堪的纳维亚人群的同类研究，这项研究为未来对两人互动，特别是在心理治疗环境中的调查奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [397] [A Keyword-Based Technique to Evaluate Broad Question Answer Script](https://arxiv.org/abs/2506.21461)
> *一种基于关键词的宽泛问题答案脚本评估技术*

*Tamim Al Mahmud, Md Gulzar Hussain, Sumaiya Kabir, Hasnain Ahmad, Mahmudus Sobhan* | **Category: cs.LG**

**Keywords:** 关键词评估, 答案脚本评估, 电子评估, 主观测试, 准确率

**Comment:** ACM Conference Proceedings (9 Pages)

> **TL;DR:** 本文提出了一种基于关键词的集成系统，用于电子评估主观答案脚本，该系统通过比对关键词、检查语法和拼写错误，并在100份学生答案脚本上实现了0.91的准确率。

**AI_Comments:** 本文提出了一种实用且高效的方法，旨在自动化主观答案脚本的评估，这是教育评估中一项具有挑战性的任务。其创新之处在于将关键词匹配与语法和拼写检查相结合的集成系统。0.91的准确率表明其在实际应用中的潜力，有望显著改进手动评估过程。然而，摘要中没有详细说明关键词提取的方法或用于比较和错误检查的具体算法，这可能是理解其完整技术深度的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 为了提供一种高效的电子评估主观答案脚本的解决方案，以改进教育系统中的评估方法。

**Method:** 本文提出并实现了一个集成系统，该系统从答案脚本中查找关键词，然后将其与从开放域和封闭域解析的关键词进行比较，并检查答案脚本中的语法和拼写错误。

**Result:** 该系统用100名学生的答案脚本进行了测试，并获得了0.91的准确率分数。

**Conclusion:** 本文提出了一种高效的、基于关键词的集成系统，用于电子评估主观答案脚本，并取得了令人满意的准确率。

> **ai_Abstract:** 本文介绍了一种基于关键词的集成系统，用于电子评估主观答案脚本。该系统识别答案中的关键词，将其与特定领域关键词进行比较，并纠正语法和拼写错误。该系统在100份学生答案脚本上进行了测试，取得了0.91的准确率，为自动化评估提供了一种高效的解决方案。

> **摘要翻译:** 评估是通过各种技术（例如口头或口试、主观或客观书面测试）评估和确定教育系统的方法。本文提出了一种有效的方法，可以电子方式评估主观答案脚本。在本文中，我们提出并实现了一个检查和评估书面答案脚本的集成系统。本文重点从答案脚本中查找关键词，然后将其与从开放域和封闭域解析的关键词进行比较。该系统还检查答案脚本中的语法和拼写错误。我们提出的系统用100名学生的答案脚本进行了测试，并给出了0.91的准确率分数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [399] [Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage](https://arxiv.org/abs/2506.21465)
> *优化四阶龙格-库塔方法：一种提高效率和降低存储的动态启发式方法*

*Gavin Lee Goodship, Luis Miralles-Pechuan, Stephen O'Sullivan* | **Category: cs.LG, cs.AI**

**Keywords:** 龙格-库塔方法, 遗传算法, 强化学习, 启发式优化, 计算效率

**Comment:** 

> **TL;DR:** 本研究提出了一种混合遗传算法（GA）和强化学习（RL）的动态启发式方法，用于优化低存储扩展稳定性龙格-库塔（ESRK）方法，显著提高了计算效率并保持了数值稳定性。

**AI_Comments:** 这篇论文的创新点在于将遗传算法（GA）和强化学习（RL）这两种强大的优化技术结合起来，用于自动化地发现和优化数值方法中的启发式策略，特别是针对低存储的四阶Runge-Kutta方法。这种动态启发式方法避免了手动设计启发式的局限性，并实现了显著的计算效率提升。它为数值方法的优化提供了一个新的范式，并预示了深度强化学习和AutoML在该领域应用的巨大潜力，对于计算流体力学、物理模拟等计算密集型领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩展稳定性龙格-库塔（ESRK）方法在解决大规模计算问题中至关重要，但平衡精度、稳定性和计算效率，特别是对于高阶、低存储方案，仍然具有挑战性。

**Method:** 本研究引入了一种混合遗传算法（GA）和强化学习（RL）方法，用于自动化启发式发现，以优化低存储ESRK方法。该方法利用GA驱动的变异进行搜索空间探索，并采用受RL启发的态转移机制动态地完善启发式选择，从而系统地减少参数并保持四阶精度。

**Result:** 所提出的GA-RL启发式优化框架在基准问题（包括一维和二维Brusselator系统以及稳态Navier-Stokes方程）上进行了严格测试。性能最佳的启发式方法与传统ESRK优化过程相比，将IPOPT运行时减少了25%，同时保持了数值稳定性和精度。

**Conclusion:** 本研究表明自适应启发式发现有潜力提高高保真模拟中的资源效率，并拓宽低存储龙格-库塔方法在实际计算流体力学、物理模拟和其他要求苛刻领域中的适用性。这项工作为数值方法的启发式优化建立了新范式。

> **ai_Abstract:** 本研究提出了一种创新的混合遗传算法（GA）和强化学习（RL）框架，用于自动化优化低存储扩展稳定性龙格-库塔（ESRK）方法。该方法通过GA进行搜索空间探索，并利用RL动态优化启发式选择，旨在克服传统方法在平衡精度、稳定性和计算效率方面的挑战。实验结果表明，与传统方法相比，该框架能将IPOPT运行时减少25%，同时保持数值稳定性和精度，为高保真模拟中的资源效率提升和Runge-Kutta方法在实际应用中的推广提供了新范式。

> **摘要翻译:** 扩展稳定性龙格-库塔（ESRK）方法对于解决科学和工程中的大规模计算问题至关重要，包括天气预报、空气动力学分析和复杂的生物建模。然而，平衡精度、稳定性和计算效率仍然具有挑战性，特别是对于高阶、低存储方案。本研究引入了一种混合遗传算法（GA）和强化学习（RL）方法，用于自动化启发式发现，以优化低存储ESRK方法。与依赖手动设计启发式或穷举数值搜索的传统方法不同，我们的方法利用GA驱动的变异进行搜索空间探索，并采用受RL启发的态转移机制动态地完善启发式选择。这使得系统地减少参数成为可能，同时保持四阶精度并显著提高计算效率。所提出的GA-RL启发式优化框架通过对基准问题（包括一维和二维Brusselator系统以及稳态Navier-Stokes方程）的严格测试进行了验证。性能最佳的启发式方法与传统ESRK优化过程相比，将IPOPT运行时减少了25%，同时保持了数值稳定性和精度。这些发现表明自适应启发式发现有潜力提高高保真模拟中的资源效率，并拓宽低存储龙格-库塔方法在实际计算流体力学、物理模拟和其他要求苛刻领域中的适用性。这项工作为数值方法的启发式优化建立了新范式，为使用深度强化学习和基于AutoML的启发式搜索进一步探索开辟了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [401] [Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems](https://arxiv.org/abs/2506.21502)
> *流程挖掘驱动的建模与仿真以增强信息物理系统中的故障诊断*

*Francesco Vitale, Nicola Dall'Ora, Sebastiano Gaiardelli, Enrico Fraccaroli, Nicola Mazzocca, Franco Fummi* | **Category: cs.LG, cs.AI**

**Keywords:** 故障诊断, 信息物理系统, 流程挖掘, 随机仿真, 异常检测

**Comment:** 

> **TL;DR:** 本文提出了一种结合多变量时间序列异常检测、流程挖掘和随机仿真的无监督故障诊断方法，旨在解决信息物理系统（CPS）中手动建模故障行为的复杂性和错误问题，并在机械臂数据集上验证了其有效性。

**AI_Comments:** 该论文提出了一种结合多源技术的创新故障诊断方法，特别是在将流程挖掘应用于异常事件日志以构建可解释模型方面具有新颖性。它有效地解决了手动故障建模的复杂性和错误问题，并通过随机仿真增强了诊断能力。该方法对于提升信息物理系统的可靠性，特别是支持预测性维护和数字孪生技术的发展，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 信息物理系统（CPS）中的故障诊断对于确保系统可靠性和运行效率至关重要。然而，手动建模故障行为通常需要广泛的领域专业知识，并且生成的模型复杂、易错且难以解释。

**Method:** 本文提出了一种新颖的无监督故障诊断方法，该方法集成了多变量时间序列中的集体异常检测、流程挖掘和随机仿真。首先，利用多变量时间序列分析从低级传感器数据中检测集体异常。然后，将这些异常转换为结构化事件日志，通过流程挖掘发现可解释的流程模型。通过将时间分布纳入提取的Petri网中，该方法支持故障行为的随机仿真，从而增强了根本原因分析和行为理解。

**Result:** 该方法在智能制造领域广泛认可的机械臂数据集（RoAD）上进行了验证。实验结果表明，该方法在信息物理系统（CPS）中建模、仿真和分类故障行为方面是有效的。

**Conclusion:** 这项研究能够创建全面的故障字典，支持预测性维护和工业环境中数字孪生的开发。

> **ai_Abstract:** 本文提出了一种创新的无监督故障诊断方法，旨在克服信息物理系统（CPS）中手动建模故障行为的挑战。该方法通过整合多变量时间序列异常检测、流程挖掘和随机仿真，从低级传感器数据中识别并分析故障。首先检测集体异常并将其转换为事件日志，然后利用流程挖掘构建可解释的Petri网模型，并通过随机仿真增强根本原因分析。在机械臂数据集上的验证表明，该方法能有效地建模、仿真和分类CPS中的故障行为，从而支持预测性维护和数字孪生。

> **摘要翻译:** 信息物理系统（CPS）中的故障诊断对于通过准确检测异常并识别其根本原因来确保系统可靠性和运行效率至关重要。然而，手动建模故障行为通常需要广泛的领域专业知识，并且生成的模型复杂、易错且难以解释。为了解决这一挑战，我们提出了一种新颖的无监督故障诊断方法，该方法集成了多变量时间序列中的集体异常检测、流程挖掘和随机仿真。最初，利用多变量时间序列分析从低级传感器数据中检测集体异常。然后，将这些异常转换为结构化事件日志，通过流程挖掘发现可解释的流程模型。通过将时间分布纳入提取的Petri网中，该方法支持故障行为的随机仿真，从而增强了根本原因分析和行为理解。该方法在智能制造领域广泛认可的机械臂数据集（RoAD）上进行了验证。实验结果表明，该方法在信息物理系统（CPS）中建模、仿真和分类故障行为方面是有效的。这使得能够创建全面的故障字典，支持预测性维护和工业环境中数字孪生的开发。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale](https://arxiv.org/abs/2506.21550)
> *mTSBench：大规模多元时间序列异常检测与模型选择基准测试*

*Xiaona Zhou, Constantin Brif, Ismini Lourentzou* | **Category: cs.LG, cs.AI**

**Keywords:** 多元时间序列异常检测, 模型选择, 基准测试, 无监督学习, 大型语言模型

**Comment:** 

> **TL;DR:** mTSBench是一个大型基准平台，用于评估多元时间序列异常检测和无监督模型选择方法，发现没有单一最佳检测器，且现有模型选择方法仍有很大提升空间。

**AI_Comments:** 这篇论文通过引入mTSBench，解决了多元时间序列异常检测领域缺乏大规模、标准化基准测试平台的问题。其创新点在于集合了大量数据集和检测方法，并首次将LLM-based检测器纳入考量。论文强调了模型选择的重要性，并指出现有选择方法的不足，为未来的研究指明了方向。mTSBench的建立对于促进MTS-AD领域的严格比较和可复现性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多元时间序列异常检测(MTS-AD)在医疗、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖、时间动态性和稀疏的异常标签，仍然具有挑战性。此外，缺乏一个大规模、统一的基准来评估和比较MTS-AD方法和无监督模型选择技术。

**Method:** 引入了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准平台。它涵盖了19个数据集、12个不同应用领域的344个带标签时间序列，并评估了24种异常检测方法（包括基于大型语言模型的方法）。mTSBench还在标准化条件下系统地测试了无监督模型选择技术。

**Result:** 研究结果证实，没有单一的检测器能在所有数据集上表现出色，这强调了模型选择的重要性。然而，即使是最先进的模型选择方法也远非最优，这揭示了关键的差距。

**Conclusion:** mTSBench提供了一个统一的评估套件，以实现严格、可复现的比较，并促进自适应异常检测和鲁棒模型选择领域的未来进展。

> **ai_Abstract:** mTSBench是一个全新的大规模基准平台，专为多元时间序列异常检测（MTS-AD）及无监督模型选择而设计。该平台整合了19个数据集、344个时间序列，并评估了24种不同的异常检测方法（包括LLM-based）。研究发现，没有单一的异常检测器能普适最优，且当前的模型选择技术仍有显著提升空间。mTSBench旨在提供一个标准化的评估环境，以推动MTS-AD领域的未来研究。

> **摘要翻译:** 多元时间序列异常检测（MTS-AD）在医疗保健、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖、时间动态性和稀疏的异常标签，仍然具有挑战性。我们引入了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准平台，涵盖了19个数据集和12个不同应用领域的344个带标签时间序列。mTSBench评估了24种异常检测方法，包括用于多元时间序列的基于大型语言模型（LLM）的检测器，并在标准化条件下系统地测试了无监督模型选择技术。与先前的研究结果一致，我们的结果证实没有单一的检测器能在所有数据集上表现出色，这强调了模型选择的重要性。然而，即使是最先进的选择方法也远非最优，这揭示了关键的差距。mTSBench提供了一个统一的评估套件，以实现严格、可复现的比较，并促进自适应异常检测和鲁棒模型选择领域的未来进展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [406] [Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test](https://arxiv.org/abs/2506.21551)
> *在LLM预训练中何处寻找Grokking？无需测试即可监控记忆到泛化*

*Ziyue Li, Chenrui Fan, Tianyi Zhou* | **Category: cs.LG**

**Keywords:** Grokking, LLM预训练, 泛化, 记忆, 路径分析

**Comment:** 

> **TL;DR:** 本研究首次在大型语言模型预训练中发现了“Grokking”现象，并通过分析模型内部动态（即训练样本路径的演变）揭示了其从记忆到泛化的机制。研究还提出了两种新的度量标准，可以在不进行微调和测试的情况下预测泛化性能。

**AI_Comments:** 这项研究的创新之处在于它是首次在大规模LLM预训练中探索Grokking现象，并提供了其从记忆到泛化的内部机制解释，即通过训练样本路径的演变。其提出的两种新度量标准具有重要的实践价值，可以在不依赖下游任务测试的情况下，高效地监控模型泛化能力，这对于LLM的预训练优化具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** Grokking现象（即训练损失收敛后测试性能仍持续提升）的发现使得泛化机制和推理等新兴能力变得神秘。先前的研究大多在小型模型和特定任务上进行，本研究旨在首次在大型语言模型（LLM）的预训练过程中探索Grokking现象。

**Method:** 研究在一个7B大型语言模型（OLMoE）的一次性预训练过程中，对检查点进行Grokking研究。计算训练损失并在包括数学推理、代码生成、常识/领域特定知识检索等多样化基准任务上评估泛化能力。通过调查LLM内部动态，特别是训练样本的路径（即跨层的专家选择）来揭示Grokking的“泛化涌现”。开发了两种新颖的度量标准来量化路径距离和单个路径的复杂性。

**Result:** 研究首次证实Grokking现象在大规模基础模型预训练中仍然存在，尽管不同数据可能异步进入Grokking阶段。发现训练样本的路径从随机、实例特定演变为更结构化且样本间可共享，并且样本路径的复杂性在损失收敛后有所降低。这表明发生了从记忆到泛化的转换，为延迟泛化提供了机制解释。开发的两种新度量标准能够预测各种下游任务上的泛化改进。

**Conclusion:** Grokking现象确实发生在大规模LLM预训练中，其背后机制是训练样本路径从随机到结构化、可共享的演变，体现了从记忆到泛化的转变。新提出的路径度量标准能有效且高效地在不进行微调和测试的情况下监控泛化性能。理论上，更结构化的路径可以降低模型复杂性并提高泛化界限。

> **ai_Abstract:** 本研究首次在7B大型语言模型（OLMoE）的预训练过程中，对“Grokking”现象进行了深入探究。研究发现，Grokking现象在大规模基础模型预训练中确实存在，并通过分析训练样本在模型内部的路径演变，揭示了其从记忆到泛化的机制。具体而言，样本路径从随机变得更结构化和可共享，复杂性降低。此外，研究提出了两种新颖的度量标准，能够高效且准确地在不进行微调和测试的情况下预测模型的泛化性能，为LLM的预训练监控提供了实用工具。

> **摘要翻译:** Grokking，即训练损失收敛后测试性能仍持续提升的现象，最近在神经网络训练中被观察到，这使得泛化机制以及推理等新兴能力变得神秘。虽然之前的研究通常在少量玩具或高度特定的任务上训练小型模型数千个epoch，但我们首次对7B大型语言模型（LLM），即OLMoE的一次性预训练过程中的检查点进行Grokking研究。我们计算了训练损失，并在包括数学推理、代码生成以及常识/领域特定知识检索任务在内的多样化基准任务上评估了泛化能力。
我们的研究首次验证了Grokking现象在大规模基础模型预训练中仍然发生，尽管不同数据可能异步进入Grokking阶段。我们通过调查LLM的内部动态，进一步揭示了Grokking的“泛化涌现”机制。具体来说，我们发现训练样本的路径（即跨层的专家选择）在Grokking过程中从随机、实例特定演变为更结构化且样本间可共享。此外，尽管损失已收敛，但样本路径的复杂性却降低了。这些表明发生了从记忆到泛化的转换，为延迟泛化提供了机制解释。在本研究中，我们开发了两种新颖的度量标准来量化路径距离和单个路径的复杂性。我们展示了它们预测各种下游任务泛化改进的能力。它们高效、计算简单，并且仅依赖于训练数据。因此，它们对预训练具有实用价值，使我们能够在不进行微调和测试的情况下监控泛化性能。理论上，我们表明更结构化的路径降低了模型复杂性并提高了泛化界限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [9] [IMA-Catcher: An IMpact-Aware Nonprehensile Catching Framework based on Combined Optimization and Learning](https://arxiv.org/abs/2506.20801)
> *IMA-Catcher：一个基于组合优化和学习的冲击感知非抓取捕获框架*

*Francesco Tassi, Jianzhuang Zhao, Gustavo J. G. Lahr, Luna Gava, Marco Monforte, Arren Glover, Chiara Bartolozzi, Arash Ajoudani* | **Category: cs.RO**

**Keywords:** 机器人捕获, 冲击感知, 优化, 学习, 非抓取

**Comment:** 25 pages, 17 figures, accepted by International Journal of Robotics
  Research (IJRR)

> **TL;DR:** 提出IMA-Catcher框架，通过在捕获前优化轨迹以减小冲击力，并在捕获后通过学习和控制来消散能量、减少弹跳，解决机器人捕获高速物体时的高冲击力问题。

**AI_Comments:** 这篇论文通过结合优化和学习，为机器人非抓取捕获任务中高冲击力问题提供了一个创新性解决方案。其亮点在于将捕获过程分解为冲击前的速度匹配优化和冲击后的能量耗散与约束满足，并通过人类演示引入学习，增强了系统的适应性。将反射质量最小化作为次要目标，进一步提升了控制的精细度。实验结果也清晰地展示了其有效性和鲁棒性，特别是对多轴泛化的验证，预示了其在复杂实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 机器人捕获飞行物体时会产生高冲击力，这可能导致任务失败和潜在的硬件损坏，尤其当物体质量与机器人有效载荷比增加时，问题会更加突出。

**Method:** 本文提出了一个隐式冲击感知框架，分为两个阶段：在捕获前阶段，实时优化规划器生成末端执行器轨迹以最小化机器人与物体间的速度差，从而减少冲击力；在捕获后阶段，基于人类演示生成机器人的位置、速度和刚度轨迹，以平滑耗散能量并最小化弹跳。此外，使用分层二次规划控制器来强制执行机器人约束（如关节和扭矩限制），并将末端执行器反射质量最小化作为次要目标。

**Result:** 初步实验证明，如果没有速度匹配，相同任务会因冲击导致的关节扭矩过大而不可行。研究了反射质量最小化的添加效果，并增加了捕获高度以评估方法的鲁棒性。最后，将设置扩展到沿多个笛卡尔轴的捕获，证明了其在空间上的泛化能力。

**Conclusion:** 该框架通过结合优化和学习，有效解决了机器人捕获高速物体时的高冲击力问题，提高了捕获任务的成功率和鲁棒性，并展现了其在多轴捕获中的泛化能力。

> **ai_Abstract:** 本文提出了IMA-Catcher，一个隐式冲击感知的非抓取捕获框架，旨在解决机器人捕获高速飞行物体时产生的高冲击力问题。该框架在捕获前通过优化机器人末端执行器与物体间的速度匹配来减小冲击力，在捕获后则通过基于人类演示学习的轨迹规划和分层二次规划控制器来平滑耗散能量、最小化弹跳，并满足机器人约束。实验证明该方法能有效降低冲击、提高捕获成功率和鲁棒性，并具有多轴泛化能力。

> **摘要翻译:** 机器人捕获飞行物体通常会产生高冲击力，这可能导致任务失败和潜在的硬件损坏。当物体质量与机器人有效载荷之比增加时，考虑到表征此任务的强惯性分量，这种情况会更加突出。本文旨在通过提出一个隐式冲击感知框架来解决这个问题，该框架在捕获前和捕获后阶段都能完成捕获任务。在第一阶段，运动规划器生成最小化捕获力的最佳轨迹，而在第二阶段，物体的能量被平滑地耗散，从而最大程度地减少弹跳。特别是，在捕获前阶段，实时优化规划器负责生成末端执行器的轨迹，以最小化机器人与物体之间的速度差，从而减少捕获时的冲击力。在捕获后阶段，机器人的位置、速度和刚度轨迹是根据人类演示生成的，这些演示涉及捕获一系列未知质量的自由落体物体。使用分层二次规划控制器来强制执行机器人的约束（即关节和扭矩限制），并创建一堆任务，将末端执行器的反射质量最小化作为次要目标。初步实验在一维上隔离了问题，以准确研究每个贡献对所提出指标的影响。我们展示了如果没有速度匹配，由于冲击导致关节扭矩过大，相同的任务将不可行。然后研究了反射质量最小化的添加，并增加了捕获高度以评估该方法的鲁棒性。最后，将设置扩展到沿多个笛卡尔轴的捕获，以证明其在空间上的泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [25] [Online Planning for Cooperative Air-Ground Robot Systems with Unknown Fuel Requirements](https://arxiv.org/abs/2506.20804)
> *未知燃料需求下空地机器人协同系统的在线规划*

*Ritvik Agarwal, Behnoushsadat Hatami, Alvika Gautam, Parikshit Maini* | **Category: cs.RO**

**Keywords:** 空地机器人系统, 在线规划, 燃料受限路径规划, 无人机, 无人车

**Comment:** Submitted to RSS (MRS Workshop)

> **TL;DR:** 针对燃料受限无人机与移动加油站的在线路径规划问题，当目标燃料成本未知时，论文提出一种两阶段解决方案：离线启发式规划初始路径，在线算法动态调整会合点。Gazebo仿真验证了其可行性。

**AI_Comments:** 该论文提出了一种创新的两阶段在线规划方法，有效应对了空地机器人协同系统中未知燃料需求这一复杂挑战。其在线动态调整机制是关键创新点，提高了系统在不确定环境下的适应性。初步仿真结果令人鼓舞，但未来可能需要更复杂的场景和实际部署来进一步验证其鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 解决带有地面移动加油站（FCURP-MRS）的燃料受限无人机路径规划问题的在线变体，特别是当目标会产生未知燃料成本时。

**Method:** 开发了一个两阶段解决方案：一个离线启发式规划器计算初始无人机和无人车路径，以及一个新颖的在线规划算法，根据目标处理期间的实时燃料消耗动态调整会合点。

**Result:** 初步的Gazebo仿真证明了该方法在保持无人机-无人车路径有效性、确保任务完成方面的可行性。

**Conclusion:** 该方法对于解决带有未知燃料需求的空地机器人协同系统的在线规划问题是可行的，能够有效保持路径有效性并确保任务完成。

> **ai_Abstract:** 该研究提出了一种针对燃料受限无人机与地面移动加油站协同系统（FCURP-MRS）的在线规划解决方案，旨在解决目标燃料成本未知的问题。该方案包含一个离线启发式路径规划阶段和一个在线动态调整会合点的算法。初步的Gazebo仿真验证了该方法在维持路径有效性和确保任务完成方面的可行性。

> **摘要翻译:** 我们考虑了带有地面移动加油站（FCURP-MRS）的燃料受限无人机路径规划问题的在线变体，其中目标会产生未知的燃料成本。我们开发了一个两阶段解决方案：一个离线启发式规划器计算初始无人机和无人车路径，以及一个新颖的在线规划算法，根据目标处理期间的实时燃料消耗动态调整会合点。初步的Gazebo仿真证明了我们方法在保持无人机-无人车路径有效性、确保任务完成方面的可行性。视频链接：https://youtu.be/EmpVj-fjqNY

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [49] [Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection](https://arxiv.org/abs/2506.20812)
> *架空电力线基于模型的实时姿态和垂度LiDAR无人机检查估计*

*Alexandre Girard, Steven A. Parkison, Philippe Hamelin* | **Category: cs.RO, cs.CV**

**Keywords:** 无人机检查, LiDAR, 电力线, 姿态估计, 垂度估计, 模型化估计

**Comment:** Submitted to IEEE case 2025

> **TL;DR:** 提出了一种基于LiDAR的电力线模型化估计方法，用于无人机检查中的姿态和垂度估计，解决了现有技术在数据稀疏、检测不一致和点云区分上的挑战，实现了快速准确的跟踪。

**AI_Comments:** 该研究通过引入一种整体几何模型来解决LiDAR数据稀疏和噪声干扰下的电力线跟踪问题，具有创新性。其高效的实时性能和对异常点的鲁棒性，对于提升无人机电力线检查的自动化和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有无人机LiDAR检查架空电力线面临挑战：导体表面小导致LiDAR点少；并非所有导体都能持续检测；难以区分导体点与其他物体（如树木、电线杆）。

**Method:** 提出一种估计方法，通过最小化LiDAR测量值与代表整个导体阵列的单一几何模型之间的误差，而不是单独跟踪每个导体。

**Result:** 实验结果表明该方法实现了精确跟踪，求解器每帧收敛时间少于50毫秒，即使在部分观测、噪声和异常值存在的情况下也能表现良好。敏感性分析显示，该估计方法能容忍高达两倍于有效导体测量值的异常点。

**Conclusion:** 该模型化估计方法为无人机LiDAR检查架空电力线提供了一种鲁棒且高效的解决方案，克服了传统方法在数据稀疏性和噪声下的局限性。

> **ai_Abstract:** 本文提出一种基于LiDAR的架空电力线模型化估计方法，旨在解决无人机检查中导体LiDAR数据稀疏、检测不一致及点云区分困难等挑战。该方法通过最小化LiDAR测量与整体导体几何模型间的误差进行估计，而非独立跟踪每根导体。实验证明，该方法能实现精确跟踪，求解器每帧收敛时间小于50毫秒，并对部分观测、噪声和异常值具有高鲁棒性。

> **摘要翻译:** 无人机可以在带电状态下检查架空电力线，这大大简化了检查过程。然而，使用机载LiDAR传感器定位无人机相对于所有导体存在几个挑战：(1) 导体为LiDAR光束提供的表面极小，限制了每次扫描中导体点的数量，(2) 并非所有导体都能持续检测到，以及 (3) 区分对应于导体的LiDAR点与其他物体（如树木和电线杆）的点很困难。本文提出了一种估计方法，该方法通过最小化LiDAR测量值与代表整个导体阵列的单一几何模型之间的误差，而不是单独跟踪每个导体。使用电力线无人机检查数据进行的实验结果表明，该方法实现了精确跟踪，即使在部分观测、噪声和异常值存在的情况下，求解器也能在每帧50毫秒内收敛。敏感性分析表明，该估计方法可以容忍多达两倍于有效导体测量值的异常点。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [73] [Cooperative Circumnavigation for Multi-Quadrotor Systems via Onboard Sensing](https://arxiv.org/abs/2506.20954)
> *多旋翼系统基于机载传感的协同环绕飞行*

*Xueming Liu, Lin Li, Xiang Zhou, Qingrui Zhang, Tianjiang Hu* | **Category: cs.RO**

**Keywords:** 多旋翼系统, 协同环绕, 机载传感, 卡尔曼滤波, 目标跟踪, 容错性

**Comment:** 8 Pages, 7 figures. Accepted by RA-L

> **TL;DR:** 提出了一种多旋翼无人机协同环绕框架，利用机载传感和改进卡尔曼滤波实现无外部定位系统下的目标跟踪，并在遮挡和故障条件下验证了其鲁棒性。

**AI_Comments:** 这篇论文的创新点在于提出了一个完全依赖机载传感器的多旋翼协同环绕框架，克服了对外部定位系统的依赖，这对于野外或GPS受限环境下的应用至关重要。其结合多种卡尔曼滤波变体处理不同层面的估计问题（旋翼间相对定位和目标状态估计）显得精巧。尤其是在遮挡和故障情况下的验证，极大地增强了其在实际复杂场景中部署的可信度，特别是其在搜救任务中的潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为多旋翼系统提供一个无需外部定位系统即可包围和跟踪移动目标的协同环绕框架。

**Method:** 采用异构感知策略和状态估计算法评估旋翼-旋翼及旋翼-目标交互关系；开发了改进的卡尔曼滤波器融合视觉-惯性里程计与测距信息以提高旋翼间相对定位精度；设计了事件触发分布式卡尔曼滤波器，通过结合邻居测量和估计的旋翼间相对位置，在视觉遮挡下实现鲁棒的目标状态估计；并利用振荡器基的自主编队飞行策略构建了协同环绕控制器。

**Result:** 通过广泛的室内外实验验证了所提出环绕框架在遮挡环境下的效率。此外，四旋翼故障实验突出了该框架固有的容错特性。

**Conclusion:** 所提出的协同环绕框架无需外部定位系统即可有效跟踪移动目标，并在遮挡环境下表现出高效性与鲁棒性，具备固有的容错能力，有望应用于搜救行动。

> **ai_Abstract:** 本文提出了一种创新的多旋翼协同环绕框架，使其能够在没有外部定位系统的情况下，仅依靠机载传感来包围和跟踪移动目标。该框架融合了异构感知、改进卡尔曼滤波进行旋翼间高精度相对定位，以及事件触发分布式卡尔曼滤波以在视觉遮挡下鲁棒估计目标状态。通过基于振荡器的编队飞行策略构建控制器。实验证明了该框架在遮挡环境下的高效性及在故障条件下的容错能力，展现了其在搜救等实际应用中的巨大潜力。

> **摘要翻译:** 针对多旋翼系统，提出了一种协同环绕框架，用于在不依赖外部定位系统的情况下包围和跟踪移动目标。使用异构感知策略和相应的状态估计算法，评估了旋翼-旋翼和旋翼-目标交互之间的独特关系。开发了一种改进的卡尔曼滤波器，将视觉-惯性里程计与测距数据融合，以提高旋翼间相对定位的精度。设计了一种事件触发分布式卡尔曼滤波器，通过结合邻居测量和估计的旋翼间相对位置，在视觉遮挡下实现鲁棒的目标状态估计。利用估计结果，构建了一个协同环绕控制器，利用基于振荡器的自主编队飞行策略。我们进行了广泛的室内外实验，以验证所提出的环绕框架在遮挡环境中的效率。此外，一项旋翼故障实验突出了所提出框架固有的容错特性，强调了其在搜救行动中部署的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [97] [Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends](https://arxiv.org/abs/2506.20966)
> *VLA模型后训练与人类运动学习的并行性：进展、挑战与趋势*

*Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duan, Fu-Chao Xie, Wen-Kai Wang, Si-Cheng Wang, Ling-Yun Li, Tian Tu, Zeng-Guang Hou* | **Category: cs.RO, cs.AI**

**Keywords:** VLA模型, 后训练, 人类运动学习, 机器人操作, 综述

**Comment:** 

> **TL;DR:** 本文从人类运动学习的角度回顾了VLA模型的后训练策略，并提出了一个结构化分类法，以应对VLA模型在机器人操作中精度和准确性方面的挑战。

**AI_Comments:** 该论文的创新之处在于其独特的视角，将VLA模型的后训练与人类运动学习过程进行类比，这为理解和改进机器人学习提供了一个新颖且直观的框架。通过借鉴人类学习机制，论文不仅对现有方法进行了系统分类，还为未来的研究指明了方向，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** VLA模型在机器人操作中展现出良好的泛化能力，但在需要高精度和准确性的应用中存在性能差距。后训练对于弥合基础模型与下游应用之间的差距至关重要，因此需要深入研究VLA模型的后训练方法。

**Method:** 本文从人类运动学习的角度，通过环境、具身和任务三个维度，回顾了VLA模型的后训练策略。引入了一个与人类学习机制对齐的结构化分类法，包括：(1) 增强环境感知，(2) 提高具身意识，(3) 加深任务理解，以及 (4) 多组件集成。

**Result:** 本文识别了VLA模型后训练中的关键挑战和趋势，并建立了一个概念框架来指导未来的研究。

**Conclusion:** 本文从人类运动学习的角度全面概述了当前的VLA模型后训练方法，并为VLA模型开发提供了实用的见解。

> **ai_Abstract:** 本文从人类运动学习的角度，对视觉-语言-动作（VLA）模型的后训练策略进行了全面综述。针对VLA模型在机器人操作中高精度和准确性应用中存在的性能差距，文章强调了后训练的重要性。作者提出了一个结构化的分类法，将VLA模型的后训练方法分为增强环境感知、提高具身意识、加深任务理解和多组件集成四个方面，并探讨了该领域的挑战和未来趋势，旨在为VLA模型的发展提供指导和实用见解。

> **摘要翻译:** 视觉-语言-动作（VLA）模型通过集成动作生成模块，将视觉-语言模型（VLM）扩展到机器人操作领域。VLA模型利用VLM在视觉感知和指令理解方面的优势，在各种操作任务中展现出良好的泛化能力。然而，需要高精度和准确性的应用揭示了在不进行进一步适应的情况下存在的性能差距。来自多个领域的证据强调了后训练在使基础模型与下游应用对齐方面的关键作用，从而激发了对VLA模型后训练的广泛研究。VLA模型后训练旨在解决提高具身与环境交互能力以完成给定任务的挑战，这类似于人类运动技能习得的过程。因此，本文从人类运动学习的角度回顾了VLA模型的后训练策略，重点关注三个维度：环境、具身和任务。引入了一个与人类学习机制对齐的结构化分类法：(1) 增强环境感知，(2) 提高具身意识，(3) 加深任务理解，以及 (4) 多组件集成。最后，识别了VLA模型后训练中的关键挑战和趋势，建立了一个概念框架来指导未来的研究。这项工作提供了从人类运动学习角度对当前VLA模型后训练方法的全面概述，以及对VLA模型开发的实用见解。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [119] [ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation](https://arxiv.org/abs/2506.20969)
> *ThermalDiffusion：用于自主导航的视觉到热像图像到图像转换*

*Shruti Bansal, Wenshan Wang, Yifei Liu, Parv Maheshwari* | **Category: cs.RO, cs.CV**

**Keywords:** 热像仪, 图像转换, 自主导航, 条件扩散模型, 数据增强

**Comment:** Accepted at Thermal Infrared in Robotics (TIRO) Workshop, ICRA 2025

> **TL;DR:** 本文提出了一种使用条件扩散模型将现有RGB图像转换为热像图像的方法，以解决自主导航中热像数据缺乏的问题。

**AI_Comments:** 该论文的关键创新在于提出了一个通过条件扩散模型生成合成热像数据的方法，有效解决了热像数据稀缺的痛点。这对于在恶劣环境下提升自主系统的感知能力具有重要意义，有助于推动热像仪在机器人和自动化领域的普及和应用。

<details>
  <summary>Details</summary>

**Motivation:** 自主系统依赖传感器感知环境，但相机、激光雷达和雷达在夜间或恶劣环境下有局限性。热像仪能提供有价值的信息，但机器人和自动化领域面临热像数据缺乏的巨大障碍，现有多模态数据集缺乏热像数据。

**Method:** 提出了一种解决方案，通过合成热像数据来扩充数据集。具体利用条件扩散模型，通过自注意力学习真实物体的热特性，将现有RGB图像转换为热像图像。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文提出ThermalDiffusion，一种利用条件扩散模型将RGB图像转换为热像图像的方法，旨在解决自主导航领域热像数据稀缺的问题。通过合成热像数据来扩充现有数据集，从而促进热像仪在机器人和自动化系统中的广泛应用。

> **摘要翻译:** 自主系统依赖传感器来估计周围环境。然而，相机、激光雷达和雷达都有其自身的局限性。在夜间或雾、霾或灰尘等恶劣环境中，热像仪由于物体的热特征，可以提供有关感兴趣物体存在的重要信息。它们使得识别通常比周围环境温度更高的人和车辆变得容易。在本文中，我们专注于热像仪在机器人和自动化领域的应用，其中最大的障碍是数据的缺乏。有几个多模态数据集可用于驾驶机器人研究，涉及场景分割、目标检测和深度估计等任务，这些是自主系统的基石。然而，这些数据集被发现缺乏热像数据。我们的论文提出了一种解决方案，通过合成热像数据来扩充这些数据集，以实现热像仪的广泛和快速适应。我们探索使用条件扩散模型，通过自注意力学习真实物体的热特性，将现有RGB图像转换为热像图像。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [139] [Fault-Tolerant Spacecraft Attitude Determination using State Estimation Techniques](https://arxiv.org/abs/2506.21016)
> *基于状态估计算技术的容错航天器姿态确定*

*B. Chidambaram, A. Hilbert, M. Silva* | **Category: cs.RO, cs.SY, eess.SY**

**Keywords:** 容错, 姿态确定, 卡尔曼滤波器, 粒子滤波器, 状态估计

**Comment:** 8 pages, 19 figures

> **TL;DR:** 本文评估了扩展卡尔曼滤波器、无迹卡尔曼滤波器和粒子滤波器在航天器容错姿态估计中的性能，并分析了基于这些滤波器的故障检测、隔离和恢复技术。

**AI_Comments:** 该论文关注航天器自主性和可靠性的一个关键方面：容错姿态确定。使用已建立的状态估计技术（卡尔曼滤波器变体、粒子滤波器）结合故障检测、隔离和恢复（FDIR）策略是一种实用的方法。其创新之处在于对这些滤波器在各种故障模式下的比较分析，这对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨扩展卡尔曼滤波器、无迹卡尔曼滤波器和粒子滤波器在航天器容错姿态估计中的性能，特别是针对故障检测、隔离和从错误传感器测量中恢复的能力。

**Method:** 本文采用扩展卡尔曼滤波器（EKF）、无迹卡尔曼滤波器（UKF）和粒子滤波器（PF）作为容错姿态估计的鲁棒框架。研究分析了基于这些滤波器构建的各种故障检测、隔离和恢复（FDIR）技术，以应对错误的传感器测量。分析对象为低地球轨道上的一颗大型卫星。

**Result:** 分析的主要结果包括各种故障模式下滤波器的性能表现。

**Conclusion:** 扩展卡尔曼滤波器、无迹卡尔曼滤波器和粒子滤波器为航天器容错姿态估计提供了鲁棒框架，它们的性能在不同故障模式下有所差异，并且在故障检测、隔离和恢复方面得到了应用分析。

> **ai_Abstract:** 本文研究了扩展卡尔曼滤波器、无迹卡尔曼滤波器和粒子滤波器在航天器容错姿态确定中的应用和性能。它专门分析了这些状态估计算技术，以及集成的故障检测、隔离和恢复方法，在处理低地球轨道大型卫星上错误的传感器测量时的表现，并强调了它们在不同故障模式下的性能。

> **摘要翻译:** 扩展卡尔曼滤波器、无迹卡尔曼滤波器和粒子滤波器为航天器容错姿态估计提供了一个鲁棒的框架。本文探讨了每种滤波器在低地球轨道大型卫星上的性能。此外，还分析了基于这些滤波器构建的各种技术，用于故障检测、隔离和从错误传感器测量中恢复。这项分析的主要结果包括各种故障模式下的滤波器性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [155] [STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner](https://arxiv.org/abs/2506.21030)
> *STEP规划器：构建跨层级子目标树作为具身长周期任务规划器*

*Zhou Tianxing, Wang Zhirui, Ao Haojia, Chen Guangyan, Xing Boyang, Cheng Jingwen, Yang Yi, Yue Yufeng* | **Category: cs.RO**

**Keywords:** 长周期任务规划, 具身机器人, 子目标树, 大型语言模型, 闭环模型

**Comment:** 

> **TL;DR:** STEP规划器通过构建跨层级子目标树和使用闭环模型（子目标分解与叶节点终止），显著提高了机器人执行长周期具身任务的成功率，优于现有方法。

**AI_Comments:** STEP规划器通过引入跨层级的子目标树和一对闭环模型，为长周期具身任务规划提供了一个新颖且有效的解决方案。其创新点在于结合了LLM的分解能力和实时环境反馈，克服了LLM在处理复杂、长周期任务时的局限性。这种方法提高了机器人任务规划的可靠性和成功率，对于机器人实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 部署机器人在现实环境中需要可靠的长周期任务规划能力。然而，直接使用大型语言模型（LLMs）生成动作序列在长周期具身任务中成功率低，因为LLMs的推理能力有限。

**Method:** STEP框架通过一对闭环模型构建一个子目标树：一个子目标分解模型和一个叶节点终止模型。该框架开发了一个从粗到细的分层树结构。子目标分解模型利用基础LLM将复杂目标分解为可管理的子目标，从而扩展子目标树。叶节点终止模型根据环境状态提供实时反馈，确定何时终止树的扩展，并确保每个叶节点都可以直接转换为原始动作。

**Result:** 在VirtualHome WAH-NL基准和真实机器人上的实验表明，STEP在长周期具身任务完成方面取得了高达34%（WAH-NL）和25%（真实机器人）的成功率，优于现有SOTA方法。

**Conclusion:** STEP规划器通过其独特的跨层级子目标树结构和闭环模型，有效解决了机器人长周期具身任务规划中LLM推理能力不足的问题，显著提高了任务完成的成功率。

> **ai_Abstract:** 本文提出了STEP规划器，旨在解决大型语言模型在长周期具身任务规划中推理能力不足导致成功率低的问题。STEP框架通过一对闭环模型（子目标分解模型和叶节点终止模型）构建了一个从粗到细的跨层级子目标树。子目标分解模型利用基础LLM分解复杂目标，而叶节点终止模型则提供实时反馈以确保叶节点可直接转换为原始动作。实验结果表明，STEP在虚拟和真实机器人环境中均显著提高了长周期具身任务的成功率，并优于现有最先进方法。

> **摘要翻译:** 能够执行可靠的长周期任务规划对于在现实世界环境中部署机器人至关重要。然而，直接使用大型语言模型（LLMs）作为动作序列生成器通常会导致成功率较低，因为它们对长周期具身任务的推理能力有限。在STEP框架中，我们通过一对闭环模型构建了一个子目标树：一个子目标分解模型和一个叶节点终止模型。在此框架内，我们开发了一个从粗到细的分层树结构。子目标分解模型利用基础LLM将复杂目标分解为可管理的子目标，从而扩展子目标树。叶节点终止模型根据环境状态提供实时反馈，确定何时终止树的扩展，并确保每个叶节点都可以直接转换为原始动作。在VirtualHome WAH-NL基准和真实机器人上进行的实验表明，STEP在长周期具身任务完成方面取得了高达34%（WAH-NL）和25%（真实机器人）的成功率，优于现有SOTA方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [175] [V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](https://arxiv.org/abs/2506.21041)
> *V2X-REALM：基于视觉语言模型的鲁棒端到端协同自动驾驶与自适应长尾建模*

*Junwei You, Pei Li, Zhuoyu Jiang, Zilin Huang, Rui Gan, Haotian Shi, Bin Ran* | **Category: cs.RO, cs.AI, cs.CV**

**Keywords:** 自动驾驶, 视觉语言模型, 长尾场景, 协同驾驶, 鲁棒性

**Comment:** 

> **TL;DR:** V2X-REALM提出了一种基于视觉语言模型的框架，通过生成长尾场景、自适应注意力模块和对比学习，显著提升了协同自动驾驶在复杂长尾场景下的鲁棒性和性能。

**AI_Comments:** V2X-REALM的创新之处在于其结合视觉语言模型，并针对自动驾驶的长尾问题提出了系统性的解决方案，包括数据增强、特征校准和多模态对齐。特别是利用基础模型生成长尾场景，为解决数据稀缺性提供了高效途径，对提升自动驾驶在复杂现实世界中的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在城市环境中，自动驾驶在罕见、多样化和视觉退化的长尾场景下，确保鲁棒的规划和决策仍然是一个基本挑战。在车辆和基础设施共同感知和推理的协同设置中，这个问题变得更加关键。

**Method:** 本文提出了V2X-REALM，一个基于视觉语言模型（VLM）的框架，采用自适应多模态学习，用于在长尾场景下实现鲁棒的协同自动驾驶。V2X-REALM引入了三项核心创新：(i) 一个提示驱动的长尾场景生成和评估管道，利用基础模型合成跨车辆和基础设施视角的真实长尾条件（如雪和雾），有效丰富训练多样性；(ii) 一个门控多场景自适应注意力模块，利用场景先验来调节视觉流，以重新校准模糊或损坏的特征；(iii) 一个多任务场景感知对比学习目标，以改善多模态对齐并促进跨场景特征的可分离性。

**Result:** 大量实验表明，V2X-REALM在复杂、具有挑战性的驾驶条件下，在鲁棒性、语义推理、安全性以及规划精度方面显著优于现有基线。

**Conclusion:** V2X-REALM显著提升了在复杂长尾场景下协同自动驾驶的性能，并推动了端到端协同自动驾驶的可扩展性。

> **ai_Abstract:** V2X-REALM是一个基于视觉语言模型的协同自动驾驶框架，旨在解决长尾场景下的鲁棒性问题。它通过引入提示驱动的长尾场景生成、门控多场景自适应注意力模块和多任务场景感知对比学习目标三项核心创新，有效提升了模型在恶劣条件下的性能。实验证明，V2X-REALM在鲁棒性、语义推理、安全性和规划精度方面均显著超越现有基线，从而提高了端到端协同自动驾驶的实用性和可扩展性。

> **摘要翻译:** 确保在罕见、多样化和视觉退化的长尾场景下进行鲁棒的规划和决策，仍然是城市环境中自动驾驶面临的一个基本挑战。在车辆和基础设施共同感知和推理的协同设置中，这个问题变得更加关键。为了解决这一挑战，我们提出了V2X-REALM，一个基于视觉语言模型（VLM）的框架，采用自适应多模态学习，用于在长尾场景下实现鲁棒的协同自动驾驶。V2X-REALM引入了三项核心创新：(i) 一个提示驱动的长尾场景生成和评估管道，利用基础模型合成跨车辆和基础设施视角的真实长尾条件（如雪和雾），有效丰富训练多样性；(ii) 一个门控多场景自适应注意力模块，利用场景先验来调节视觉流，以重新校准模糊或损坏的特征；(iii) 一个多任务场景感知对比学习目标，以改善多模态对齐并促进跨场景特征的可分离性。大量实验表明，V2X-REALM在复杂、具有挑战性的驾驶条件下，在鲁棒性、语义推理、安全性以及规划精度方面显著优于现有基线，推动了端到端协同自动驾驶的可扩展性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [190] [Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions](https://arxiv.org/abs/2506.21057)
> *知识驱动的模仿学习：实现跨多样化条件的泛化*

*Zhuochen Miao, Jun Lv, Hongjie Fang, Yang Jin, Cewu Lu* | **Category: cs.RO**

**Keywords:** 模仿学习, 知识驱动, 机器人操作, 泛化, 数据效率

**Comment:** IROS 2025

> **TL;DR:** 本文提出了一种知识驱动的模仿学习框架，通过利用外部结构语义知识来抽象对象表示，从而显著提高机器人操作中模仿学习的泛化能力和数据效率。

**AI_Comments:** 该论文的创新之处在于将外部结构语义知识融入模仿学习，有效解决了传统方法泛化能力差和数据效率低的问题。通过引入语义关键点图和模板匹配算法，实现了对对象表示的抽象，使其能够更好地适应多样化的条件。这项工作为机器人学习在真实世界环境中的应用开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 模仿学习在机器人操作中表现出色，但其泛化能力受限于有限专家演示中的特定对象依赖性。

**Method:** 本文提出了知识驱动的模仿学习框架，利用外部结构语义知识抽象同类别内的对象表示。引入了一种新颖的语义关键点图作为知识模板，并开发了一种粗到细的模板匹配算法，优化结构一致性和语义相似性。

**Result:** 在三个真实世界机器人操作任务中，该方法表现优越，仅用四分之一的专家演示就超越了基于图像的扩散策略。实验进一步证明了其在新型对象、背景和光照条件下的鲁棒性。

**Conclusion:** 这项工作开创了一种知识驱动的方法，用于在真实世界环境中进行数据高效的机器人学习。

> **ai_Abstract:** 本文提出了一种知识驱动的模仿学习框架，旨在解决传统模仿学习在机器人操作中泛化能力受限的问题。通过引入语义关键点图作为知识模板并开发粗到细的模板匹配算法，该方法能够利用外部结构语义知识抽象对象表示。实验结果表明，该方法在真实世界任务中表现优越，显著提高了数据效率和对新型环境的鲁棒性。

> **摘要翻译:** 模仿学习已成为机器人操作中一种强大的范式，但其泛化能力仍受限于有限专家演示中特定于对象的依赖性。为了解决这一挑战，我们提出了知识驱动的模仿学习，一个利用外部结构语义知识来抽象同一类别内对象表示的框架。我们引入了一种新颖的语义关键点图作为知识模板，并开发了一种粗到细的模板匹配算法，该算法优化了结构一致性和语义相似性。在三个真实世界机器人操作任务上进行评估，我们的方法取得了卓越的性能，仅用四分之一的专家演示就超越了基于图像的扩散策略。广泛的实验进一步证明了其在新型对象、背景和光照条件下的鲁棒性。这项工作开创了一种知识驱动的方法，用于在真实世界环境中进行数据高效的机器人学习。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [203] [Control of Marine Robots in the Era of Data-Driven Intelligence](https://arxiv.org/abs/2506.21063)
> *数据驱动智能时代下海洋机器人的控制*

*Lin Hong, Lu Liu, Zhouhua Peng, Fumin Zhang* | **Category: cs.RO**

**Keywords:** 海洋机器人控制, 数据驱动, 机器学习, 综述, 自主性

**Comment:** 

> **TL;DR:** 本文综述了数据驱动智能在海洋机器人控制中的最新进展，涵盖个体和协作系统，并展望了未来研究方向。

**AI_Comments:** 本文作为一篇综述性文章，全面梳理了数据驱动智能在海洋机器人控制领域的应用，指出了传统方法的局限性，并展望了未来发展方向，具有重要的指导意义。其价值在于为研究人员提供了一个清晰的路线图，加速了该领域向高水平自主性迈进。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于模型的海洋机器人控制方法在处理非线性和不确定性方面存在局限性，而机器学习的快速发展为数据驱动智能控制提供了新机遇，推动了海洋机器人控制范式的转变。

**Method:** 本文通过新兴的数据驱动智能范式，综述了海洋机器人控制的最新进展，涵盖个体和协作系统，并总结了支持开发和验证先进控制方法的开源资源。

**Result:** 文章强调了数据驱动控制在海洋机器人领域的显著成就，并总结了相关开源资源。它还提出了未来研究方向，以实现海洋机器人在实际应用中的高级自主性。

**Conclusion:** 本文旨在为数据驱动智能时代下海洋机器人下一代控制框架的研究提供路线图。

> **ai_Abstract:** 本文综述了数据驱动智能在海洋机器人控制领域的最新进展，旨在应对传统模型方法的局限性。文章涵盖了数据驱动控制在个体和协作海洋机器人系统中的应用，突出了显著成就，并列举了开源资源。最后，提出了未来的研究方向，以期推动海洋机器人在实际应用中实现更高水平的自主性，为下一代控制框架提供路线图。

> **摘要翻译:** 长期以来，海洋机器人的控制一直依赖于基于经典和现代控制理论的模型方法。然而，机器人动力学固有的非线性和不确定性，加上海洋环境的复杂性，揭示了传统控制方法的局限性。机器学习的快速发展为将数据驱动智能融入控制策略开辟了新途径，促使海洋机器人控制发生范式转变。本文从这一新兴范式的角度，综述了海洋机器人控制的最新进展。综述涵盖了单个和协作海洋机器人系统，重点介绍了数据驱动海洋机器人控制方面的显著成就，并总结了支持先进控制方法开发和验证的开源资源。最后，概述了几个未来展望，以指导研究实现海洋机器人在实际应用中的高级自主性。本文旨在作为数据驱动智能时代下海洋机器人下一代控制框架的路线图。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [218] [CURL-SLAM: Continuous and Compact LiDAR Mapping](https://arxiv.org/abs/2506.21077)
> *CURL-SLAM：连续紧凑的激光雷达建图*

*Kaicheng Zhang, Shida Xu, Yining Ding, Xianwen Kong, Sen Wang* | **Category: cs.RO**

**Keywords:** 激光雷达SLAM, 紧凑地图, CURL, 球谐函数, 实时性能

**Comment:** 

> **TL;DR:** CURL-SLAM提出了一种基于CURL的激光雷达SLAM新范式，实现了连续、紧凑且一致的3D地图，并具有高精度和实时性能。

**AI_Comments:** CURL-SLAM的创新之处在于引入了CURL作为激光雷达地图表示，这显著提高了地图的紧凑性和连续性。通过将位姿估计公式化为针对CURL的优化问题，并结合局部BA，实现了更精确的位姿和地图修正。该方法在保证高精度的同时，实现了CPU上的实时性能，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的激光雷达同步定位与建图（SLAM）系统通常依赖于3D点云地图，这需要大量的存储空间来保留大规模环境中的结构细节。

**Method:** 本文提出了一种新的激光雷达SLAM范式，利用了[1]中引入的激光雷达连续超紧凑表示（CURL）。所提出的CURL-SLAM方法通过CURL的球谐函数隐式编码生成紧凑的3D地图，能够以可变密度进行连续重建，并在闭环后实现全局地图一致性。与流行的基于迭代最近点（ICP）的激光雷达里程计技术不同，CURL-SLAM将激光雷达位姿估计公式化为一个针对CURL量身定制的独特优化问题，并将其扩展到局部捆集调整（BA），从而实现同时的位姿细化和地图校正。

**Result:** CURL-SLAM在CPU上实现了最先进的3D建图质量和具有竞争力的激光雷达轨迹精度，并提供了传感器速率的实时性能（10 Hz）。

**Conclusion:** CURL-SLAM通过引入基于CURL的新型激光雷达SLAM范式，成功解决了传统点云地图存储量大、连续性不足的问题，实现了高效、高质量且实时运行的3D激光雷达建图。

> **ai_Abstract:** CURL-SLAM提出了一种创新的激光雷达SLAM方法，旨在解决传统点云地图存储需求大的问题。该方法利用激光雷达连续超紧凑表示（CURL）来生成紧凑、可变密度且一致的3D地图。CURL-SLAM将位姿估计重新定义为针对CURL的优化问题，并结合局部捆集调整，实现了位姿和地图的同步优化。实验证明，CURL-SLAM在3D建图质量和轨迹精度上达到了先进水平，并能在CPU上实现实时性能。

> **摘要翻译:** 本文研究了3D激光雷达建图，重点是开发一种可更新和可定位的地图表示，以实现3D地图的连续性、紧凑性和一致性。传统的激光雷达同步定位与建图（SLAM）系统通常依赖于3D点云地图，这通常需要大量的存储空间来保留大规模环境中的结构细节。在本文中，我们通过利用[1]中引入的激光雷达连续超紧凑表示（CURL），提出了一种新的激光雷达SLAM范式。我们提出的激光雷达建图方法CURL-SLAM，使用CURL的球谐函数隐式编码，生成能够以可变密度进行连续重建的紧凑3D地图，并在闭环后实现全局地图一致性。与流行的基于迭代最近点（ICP）的激光雷达里程计技术不同，CURL-SLAM将激光雷达位姿估计公式化为一个针对CURL量身定制的独特优化问题，并将其扩展到局部捆集调整（BA），从而实现同时的位姿细化和地图校正。实验结果表明，CURL-SLAM在CPU上实现了最先进的3D建图质量和具有竞争力的激光雷达轨迹精度，并提供了传感器速率的实时性能（10 Hz）。我们将向社区发布CURL-SLAM的实现。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [230] [UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research](https://arxiv.org/abs/2506.21178)
> *UAIbot：适用于交互式机器人学习和研究的初学者友好型网络模拟器*

*Johnata Brayan, Armando Alves Neto, Pavel Petrovič, Gustavo M Freitas, Vinicius Mariano Gonçalves* | **Category: cs.RO, 68T40, I.2.9; I.6.3**

**Keywords:** 机器人模拟器, 网络平台, 交互式学习, 开源, 机器人教育

**Comment:** 12 pages, 8 figures, submitted to Springer proceedings

> **TL;DR:** UAIbot是一个免费开源的网络机器人模拟器，旨在简化机器人学习和研究，提供无需安装的交互式体验。

**AI_Comments:** UAIbot的创新在于其网络化、开源和无需安装的特性，极大地降低了机器人学习和研究的门槛。这对于普及机器人教育和加速研究进展具有重要意义，尤其适合初学者和资源受限的环境。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统模拟平台在教育和研究中面临的挑战，提供无障碍的动手学习体验，避免繁琐的安装。

**Method:** UAIbot是一个免费、开源的网络机器人模拟器，具有Python和JavaScript接口，允许用户交互式探索从机械臂运动学到行人流动力学等基本数学和物理原理。

**Result:** 促进学生理解，加速实验进程，并增强研究成果的传播。

**Conclusion:** UAIbot是一个有效的工具，可以深化学生理解，促进快速实验，并增强研究传播。

> **ai_Abstract:** 本文推出了UAIbot，一个免费开源的网络机器人模拟器，旨在克服传统模拟平台的教育和研究障碍。它提供Python和JavaScript接口，无需安装即可进行交互式学习和实验，帮助用户深入理解机器人学原理，加速研究进程。

> **摘要翻译:** 本文介绍了UAIbot，一个免费开源的基于网络的机器人模拟器，旨在解决传统模拟平台普遍面临的教育和研究挑战。UAIbot的Python和JavaScript接口使得无需繁琐安装即可获得可访问的动手学习体验。通过允许用户交互式探索从机械臂运动学到行人流动力学等基本数学和物理原理，UAIbot为加深学生理解、促进快速实验和增强研究传播提供了有效工具。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [241] [Dynamic Risk-Aware MPPI for Mobile Robots in Crowds via Efficient Monte Carlo Approximations](https://arxiv.org/abs/2506.21205)
> *动态风险感知MPPI在人群中移动机器人中的应用：通过高效蒙特卡洛近似*

*Elia Trevisan, Khaled A. Mustafa, Godert Notten, Xinwei Wang, Javier Alonso-Mora* | **Category: cs.RO**

**Keywords:** 移动机器人, 风险感知, MPPI, 蒙特卡洛近似, 碰撞概率

**Comment:** Accepted for presentation at IROS 2025. Submitted Version

> **TL;DR:** 本文提出了一种名为DRA-MPPI的运动规划器，通过高效的蒙特卡洛近似计算碰撞概率，使移动机器人在人群中安全导航，并解决了“机器人冻结”问题。

**AI_Comments:** 这篇论文的创新点在于将蒙特卡洛近似方法高效地融入到MPPI框架中，以处理复杂且不确定的动态障碍物预测，特别是非高斯预测。这种方法有效地解决了传统运动规划器在密集人群中可能出现的“机器人冻结”问题，显著提升了移动机器人的安全性和实用性。其在实时性方面的突破也使其在实际部署中具有很高的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在人群中安全部署移动机器人，需要运动规划器考虑其他代理预测轨迹中的不确定性，这在传统方法中，尤其是在任意形状的预测和实时约束下，仍然具有挑战性。

**Method:** 提出了一种动态风险感知模型预测路径积分控制（DRA-MPPI）。该方法利用MPPI的无梯度特性，通过蒙特卡洛（MC）方法实时高效地近似多个动态障碍物之间的联合碰撞概率（CP），从而能够拒绝超过预定义CP阈值的样本或将CP作为加权目标整合到导航成本函数中。

**Result:** DRA-MPPI缓解了“机器人冻结”问题，同时增强了安全性。在有多个动态障碍物的真实世界和模拟实验中，DRA-MPPI与现有最先进的方法（包括基于场景的模型预测控制（S-MPC）、Frenet规划器和香草MPPI）相比，表现出卓越的性能。

**Conclusion:** DRA-MPPI通过高效的蒙特卡洛近似处理不确定性预测和实时约束，为移动机器人在人群中的安全导航提供了一种优越的解决方案，有效提高了安全性和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为动态风险感知模型预测路径积分控制（DRA-MPPI）的运动规划器，旨在解决移动机器人在人群中安全导航时处理不确定性预测和实时约束的挑战。DRA-MPPI利用蒙特卡洛近似实时计算多障碍物联合碰撞概率，并将其用于样本筛选或成本函数加权，从而有效避免了“机器人冻结”问题并提升了安全性。实验结果表明，DRA-MPPI在复杂动态环境中优于现有先进方法。

> **摘要翻译:** 在人群中安全部署移动机器人，要求运动规划器考虑其他代理预测轨迹中的不确定性。这在传统方法中仍然具有挑战性，尤其是在任意形状的预测和实时约束下。为了解决这些挑战，我们提出了一种动态风险感知模型预测路径积分控制（DRA-MPPI），这是一种运动规划器，它结合了可能具有非高斯随机预测模型的不确定未来运动。通过利用MPPI的无梯度特性，我们提出了一种方法，通过蒙特卡洛（MC）方法实时高效地近似多个动态障碍物在数百条采样轨迹中的联合碰撞概率（CP）。这使得可以拒绝超过预定义CP阈值的样本，或者将CP作为加权目标整合到导航成本函数中。因此，DRA-MPPI缓解了机器人冻结问题，同时增强了安全性。在有多个动态障碍物的真实世界和模拟实验中，DRA-MPPI与现有最先进的方法（包括基于场景的模型预测控制（S-MPC）、Frenet规划器和香草MPPI）相比，表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [246] [Active Disturbance Rejection Control for Trajectory Tracking of a Seagoing USV: Design, Simulation, and Field Experiments](https://arxiv.org/abs/2506.21265)
> *自抗扰控制在远洋无人水面艇轨迹跟踪中的应用：设计、仿真与实地实验*

*Jelmer van der Saag, Elia Trevisan, Wouter Falkena, Javier Alonso-Mora* | **Category: cs.RO, cs.SY, eess.SY**

**Keywords:** 自抗扰控制, 无人水面艇, 轨迹跟踪, 环境扰动, 实地实验

**Comment:** Accepted for presentation at IROS 2025. Submitted version

> **TL;DR:** 本文提出了一种基于自抗扰控制（ADRC）的无人水面艇（USV）轨迹跟踪控制器，通过仿真和实地实验验证了其在减少横向跟踪误差方面的有效性，但代价是控制工作量和能耗增加。

**AI_Comments:** 该论文的创新点在于将自抗扰控制（ADRC）应用于受环境扰动影响的无人水面艇轨迹跟踪，并通过仿真和实地实验进行了全面验证。其重要性在于证明了ADRC在复杂海洋环境下的有效性，为USV控制提供了新的思路。主要局限性在于ADRC虽然提高了控制精度，但能耗显著增加，这在实际应用中需要权衡。

<details>
  <summary>Details</summary>

**Motivation:** 无人水面艇（USV）在面对波浪和水流等不确定环境扰动时，面临着严峻的控制挑战。

**Method:** 本文提出了一种基于自抗扰控制（ADRC）的轨迹跟踪控制器，并将其应用于DUS V2500无人水面艇。开发了包含真实波浪和水流扰动的定制仿真平台以验证控制器性能，并通过在荷兰斯赫弗宁根港口和海上进行的实地测试进一步验证。

**Result:** 仿真结果表明，与基线PID控制器相比，ADRC在所有测试条件下显著减少了横向跟踪误差，但增加了控制工作量和能耗。实地试验证实了这些发现，并揭示了海上试验中能耗相比基线进一步增加。

**Conclusion:** 自抗扰控制（ADRC）能有效降低无人水面艇在环境扰动下的轨迹跟踪误差，尽管会增加控制工作量和能耗。

> **ai_Abstract:** 本文针对无人水面艇（USV）在环境扰动下的轨迹跟踪难题，提出并验证了一种基于自抗扰控制（ADRC）的控制器。通过定制仿真和实地实验（包括港口和海上测试），研究发现ADRC能有效降低横向跟踪误差，性能优于传统PID控制器。然而，其代价是控制工作量和能源消耗的显著增加。

> **摘要翻译:** 无人水面艇（USVs）由于波浪和水流等不确定环境扰动而面临严峻的控制挑战。本文提出了一种基于自抗扰控制（ADRC）的轨迹跟踪控制器，并将其应用于DUS V2500。开发了一种包含真实波浪和水流扰动的定制仿真模型，以验证控制器的性能，并通过在荷兰斯赫弗宁根港口和海上进行的实地测试进一步验证。仿真结果表明，与基线PID控制器相比，ADRC在所有测试条件下显著减少了横向跟踪误差，但增加了控制工作量和能耗。实地试验证实了这些发现，同时揭示了海上试验中能耗相比基线进一步增加。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [253] [ACTLLM: Action Consistency Tuned Large Language Model](https://arxiv.org/abs/2506.21250)
> *ACTLLM：动作一致性调整的大语言模型*

*Jing Bi, Lianggong Bruce Wen, Zhang Liu, Chenliang Xu* | **Category: cs.RO**

**Keywords:** ACTLLM, 机器人操作, 大语言模型, 动作一致性, 视觉对话

**Comment:** 

> **TL;DR:** ACTLLM是一个为动态环境中机器人操作设计的新型大语言模型，它利用语言生成结构化场景描述，引入动作一致性约束，并将MDP重构为多轮视觉对话，以提高视觉感知和任务执行的有效性。

**AI_Comments:** ACTLLM的创新之处在于其结合大语言模型、动作一致性约束和多轮视觉对话框架来解决机器人操作中视觉表示学习和环境适应性的挑战。通过语言作为统一接口，它有效地桥接了高级推理和低级动作执行，这对于提升机器人在复杂动态环境中的自主性具有重要意义。该方法有望推动机器人领域在真实世界部署中的进步。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于视觉的系统在学习既擅长任务执行又擅长空间推理的视觉表示方面存在困难，从而限制了它们在动态环境中的适应性。

**Method:** ACTLLM通过利用语言来创建结构化场景描述，为空间理解和任务性能提供统一接口。此外，它引入了一种新颖的动作一致性约束，以对齐视觉感知与相应动作，从而增强可操作视觉表示的学习。该方法还将操作任务的马尔可夫决策过程重新构建为多轮视觉对话框架，以建模长期任务执行，并从任务执行历史中获得增强的上下文相关性。

**Result:** ACTLLM在各种场景中表现出色，证明了其在具有挑战性的基于视觉的机器人操作任务上的有效性。

**Conclusion:** 该论文引入的ACTLLM通过语言驱动的场景描述、动作一致性约束和多轮视觉对话框架，显著提升了机器人在动态环境下的操作能力和视觉表示学习效果。

> **ai_Abstract:** ACTLLM是一种用于动态环境中机器人操作的新型大语言模型。它通过语言创建结构化场景描述来解决传统视觉系统在任务执行和空间推理上的不足。该模型引入了动作一致性约束来优化视觉感知与动作的对齐，并将马尔可夫决策过程重构为多轮视觉对话，以增强长期任务的上下文理解。实验证明ACTLLM在复杂的视觉机器人操作任务中表现优异。

> **摘要翻译:** 本文介绍了ACTLLM（动作一致性调整的大语言模型），一种在动态环境中进行机器人操作的新颖方法。传统的基于视觉的系统通常难以学习在任务执行和空间推理方面都表现出色的视觉表示，从而限制了它们在动态环境中的适应性。ACTLLM通过利用语言来制作结构化场景描述来解决这些挑战，为通过灵活的语言指令进行空间理解和任务性能提供统一的界面。此外，我们引入了一种新颖的动作一致性约束，它将视觉感知与相应的动作对齐，从而增强了可操作视觉表示的学习。此外，我们还将操作任务的马尔可夫决策过程重新构建为多轮视觉对话框架。这种方法能够通过从任务执行历史中获得的增强上下文相关性来建模长期任务执行。在我们的评估中，ACTLLM在各种场景中表现出色，证明了其在具有挑战性的基于视觉的机器人操作任务上的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [267] [Real-time Terrain Analysis for Off-road Autonomous Vehicles](https://arxiv.org/abs/2506.21347)
> *越野自动驾驶汽车的实时地形分析*

*Edwina Lewis, Aditya Parameshwaran, Laura Redmond, Yue Wang* | **Category: cs.RO**

**Keywords:** 实时地形分析, 自动驾驶汽车, 路面粗糙度估计, 贝叶斯校准, Simplex控制器

**Comment:** 

> **TL;DR:** 本研究提出了一种新颖的实时路面粗糙度估计系统，该系统采用贝叶斯校准方法，通过处理车轴加速度来预测地形粗糙度，并量化置信度，以增强越野自动驾驶汽车的运行安全性和效率。

**AI_Comments:** 该论文提出了一种创新的贝叶斯框架，用于实时路面粗糙度估计，其核心在于将贝叶斯校准与高斯过程替代模型相结合，并量化了预测不确定性，这对于自适应风险管理至关重要。将该系统与Simplex控制器集成，实现了对车辆速度的动态调整，显著提升了自动驾驶车辆在复杂地形下的安全性和效率。其创新性在于为解决越野环境中的路面粗糙度挑战提供了一个全面的、数据驱动的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决自动驾驶汽车因路面粗糙度变化而导致的控制挑战，这些变化可能在转向操作期间引起路线偏差并可能导致与路面失去接触。

**Method:** 提出了一种新颖的实时路面粗糙度估计系统，采用贝叶斯校准方法处理车轴加速度。该系统集成了高斯过程替代模型与模拟半车辆模型，系统地处理车辆速度和路面粗糙度参数以生成相应的车轴加速度响应。贝叶斯校准程序从观测到的加速度和速度中逆向估计路面粗糙度，产生量化预测不确定性的后验分布。训练数据通过拉丁超立方体采样生成，校准后的模型与Simplex控制器架构无缝集成，根据实时粗糙度预测动态调整速度限制。

**Result:** 在具有不同粗糙度区域的随机生成表面上的实验验证表明，该系统具有强大的实时表征能力。集成的Simplex控制策略通过主动响应路面状况，有效增强了自动驾驶汽车的运行安全性。

**Conclusion:** 这种创新的贝叶斯框架为减轻与粗糙度相关的操作风险奠定了全面的基础，同时提高了自动驾驶系统的效率和安全裕度。

> **ai_Abstract:** 本研究提出了一种用于越野自动驾驶汽车的实时路面粗糙度估计系统。该系统利用贝叶斯校准方法和高斯过程替代模型，通过分析车轴加速度和车辆速度来预测地形粗糙度及其不确定性。通过与Simplex控制器集成，该系统能动态调整速度限制以应对路面状况，从而提高自动驾驶汽车在复杂地形中的运行安全性和效率。实验验证表明其在实时表征和风险缓解方面的有效性。

> **摘要翻译:** 这项研究解决了由路面粗糙度变化引起的自动驾驶汽车关键控制挑战，这些变化在转向操作期间会导致路线偏差和潜在的路面接触损失。我们提出了一种新颖的实时路面粗糙度估计系统，该系统采用贝叶斯校准方法，通过处理车轴加速度来预测地形粗糙度，并量化置信度。该技术框架将高斯过程替代模型与模拟半车辆模型相结合，系统地处理车辆速度和路面粗糙度参数以生成相应的车轴加速度响应。贝叶斯校准程序从观测到的加速度和速度中逆向估计路面粗糙度，产生量化预测不确定性的后验分布，以实现自适应风险管理。训练数据生成利用拉丁超立方体采样在全面的速度和粗糙度参数空间中进行，而校准后的模型与Simplex控制器架构无缝集成，根据实时粗糙度预测动态调整速度限制。在具有不同粗糙度区域的随机生成表面上的实验验证表明，该系统具有强大的实时表征能力，集成的Simplex控制策略通过主动响应路面状况，有效增强了自动驾驶汽车的运行安全性。这种创新的贝叶斯框架为减轻与粗糙度相关的操作风险奠定了全面的基础，同时提高了自动驾驶系统中的效率和安全裕度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [273] [WorldVLA: Towards Autoregressive Action World Model](https://arxiv.org/abs/2506.21539)
> *WorldVLA：迈向自回归动作世界模型*

*Jun Cen, Chaohui Yu, Hangjie Yuan, Yuming Jiang, Siteng Huang, Jiayan Guo, Xin Li, Yibing Song, Hao Luo, Fan Wang, Deli Zhao, Hao Chen* | **Category: cs.RO, cs.AI**

**Keywords:** WorldVLA, 自回归模型, 动作世界模型, 视觉-语言-动作, 注意力掩码

**Comment:** Code: https://github.com/alibaba-damo-academy/WorldVLA

> **TL;DR:** WorldVLA是一种新的自回归动作世界模型，它将VLA模型和世界模型集成在一个框架中，实现动作和图像的理解与生成。它展示了动作模型和世界模型之间的相互增强作用，并提出了一种注意力掩码策略来解决自回归动作生成中的性能下降问题。

**AI_Comments:** 这篇论文通过结合VLA和世界模型，提出了一种有趣且创新的集成方法，实现了动作和图像理解与生成的统一。动作模型和世界模型之间相互增强的概念具有重要意义。此外，识别并解决了自回归动作生成问题，并提出了注意力掩码策略，这展示了实用的问题解决能力。这项工作有助于实现更鲁棒和泛化能力更强的智能体学习。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过将视觉-语言-动作（VLA）模型和世界模型整合到一个单一框架中，实现动作和图像理解与生成的统一。其目的是让世界模型通过学习环境的底层物理来改进动作生成，同时让动作模型通过基于图像观察生成动作来辅助视觉理解和生成。

**Method:** WorldVLA将视觉-语言-动作（VLA）模型和世界模型整合到一个单一的自回归框架中。世界模型通过利用动作和图像理解来预测未来图像，以学习环境物理。动作模型则根据图像观察生成后续动作。为了解决自回归动作生成中性能下降的问题，本文提出了一种注意力掩码策略，即在生成当前动作时选择性地掩盖先前的动作。

**Result:** WorldVLA的性能优于独立的动作模型和世界模型，突出了两者之间的相互增强作用。研究发现，动作模型在自回归生成动作序列时性能会下降，这归因于其动作预测泛化能力有限和错误传播。所提出的注意力掩码策略在动作块生成任务中显著提升了性能。

**Conclusion:** 本文提出了WorldVLA，一个有效的集成模型，用于统一动作和图像的理解与生成。它强调了结合动作模型和世界模型的优势，并通过新颖的注意力掩码策略解决了自回归动作生成中的挑战。

> **ai_Abstract:** WorldVLA是一种新颖的自回归动作世界模型，它在一个统一的框架中整合了视觉-语言-动作（VLA）模型和世界模型，以实现动作和图像的理解与生成。该模型通过世界模型预测未来图像来学习环境物理，并由动作模型生成基于图像观察的动作。研究表明WorldVLA优于独立的动作和世界模型，突出了两者的相互促进作用。针对自回归动作生成中存在的性能下降问题，作者提出了一种注意力掩码策略，通过选择性地掩盖先前的动作来有效提升动作块生成任务的性能。

> **摘要翻译:** 我们提出了WorldVLA，一个自回归动作世界模型，它统一了动作和图像的理解与生成。我们的WorldVLA将视觉-语言-动作（VLA）模型和世界模型整合到一个单一框架中。世界模型通过利用动作和图像理解来预测未来的图像，目的是学习环境的底层物理以改进动作生成。同时，动作模型根据图像观察生成后续动作，辅助视觉理解，进而帮助世界模型的视觉生成。我们证明了WorldVLA优于独立的动作和世界模型，突出了世界模型和动作模型之间的相互增强。此外，我们发现动作模型在自回归生成动作序列时性能会下降。这种现象可以归因于模型动作预测的泛化能力有限，导致错误从早期动作传播到后续动作。为了解决这个问题，我们提出了一种注意力掩码策略，在生成当前动作时选择性地掩盖先前的动作，这在动作块生成任务中显示出显著的性能改进。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [17] [OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport](https://arxiv.org/abs/2506.20741)
> *OTSurv：一种用于生存预测的异质性感知最优传输多示例学习框架*

*Qin Ren, Yifan Wang, Ruogu Fang, Haibin Ling, Chenyu You* | **Category: cs.CV**

**Keywords:** 多示例学习, 生存预测, 最优传输, 病理异质性, 全玻片图像

**Comment:** 

> **TL;DR:** OTSurv是一种新的MIL框架，它通过异质性感知最优传输来提高生存预测的准确性，解决了现有方法未能捕捉病理异质性的问题，并在六个基准测试中取得了SOTA结果。

**AI_Comments:** OTSurv的创新之处在于将最优传输理论引入到多示例学习框架中，以显式地处理全玻片图像中的病理异质性，这对于提高生存预测的准确性和模型鲁棒性至关重要。其通过全局长尾和局部不确定性感知约束来优化传输过程，有效解决了模式崩溃和噪声问题，并实现了显著的性能提升。该方法为数字病理学中的WSI分析提供了一个强大且可解释的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多示例学习（MIL）方法在利用全玻片图像（WSI）进行生存预测时，未能明确捕捉WSI内的病理异质性，包括全局的长尾形态分布和局部的切片级预测不确定性。

**Method:** 本文提出OTSurv，一个基于最优传输（OT）的新型多示例学习（MIL）框架。它将生存预测公式化为一个异质性感知的OT问题，并带有两个约束：1）全局长尾约束，通过调节传输质量分配来建模先验形态分布，从而避免模式崩溃和过度均匀性；2）局部不确定性感知约束，通过逐步增加总传输质量来优先处理高置信度补丁并抑制噪声。该问题被重铸为非平衡OT公式，并通过高效、硬件友好的矩阵缩放算法求解。

**Result:** OTSurv在六个流行的基准测试中取得了新的最先进结果，平均C-index绝对提高了3.6%。此外，OTSurv在对数秩检验中达到了统计显著性，并提供了高可解释性。

**Conclusion:** OTSurv是一个强大的数字病理学生存预测工具，它通过有效捕捉病理异质性，提高了预测准确性和可解释性。

> **ai_Abstract:** 本文提出OTSurv，一个基于最优传输（OT）的新型多示例学习（MIL）框架，用于通过全玻片图像（WSI）进行生存预测。针对现有MIL方法未能有效捕捉WSI内病理异质性的问题，OTSurv引入了全局长尾约束和局部不确定性感知约束，将生存预测建模为异质性感知的OT问题。该方法通过高效算法求解，并在六个基准测试中实现了SOTA性能，平均C-index提升3.6%，同时具有高可解释性。

> **摘要翻译:** 使用全玻片图像（WSI）进行生存预测可以被视为一个多示例学习（MIL）问题。然而，现有的MIL方法往往未能明确捕捉WSI内部的病理异质性，无论是全局的——通过长尾形态分布，还是局部的——通过切片级预测不确定性。最优传输（OT）通过整合边际分布约束，提供了一种建模这种异质性的原则性方法。基于这一见解，我们提出了OTSurv，一个从最优传输角度出发的新型MIL框架。具体来说，OTSurv将生存预测公式化为一个异质性感知的OT问题，并带有两个约束：（1）全局长尾约束，通过调节传输质量分配来建模先验形态分布，从而避免模式崩溃和过度均匀性，以及（2）局部不确定性感知约束，通过逐步增加总传输质量来优先处理高置信度补丁并抑制噪声。然后，我们将最初的OT问题（通过这些约束增强）重铸为非平衡OT公式，该公式可以通过高效、硬件友好的矩阵缩放算法求解。经验上，OTSurv在六个流行的基准测试中取得了新的最先进结果，平均C-index绝对提高了3.6%。此外，OTSurv在对数秩检验中达到了统计显著性，并提供了高可解释性，使其成为数字病理学中生存预测的强大工具。我们的代码可在 https://github.com/Y-Research-SBU/OTSurv 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [32] [StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation](https://arxiv.org/abs/2506.20756)
> *StereoDiff：视频深度估计中的立体-扩散协同*

*Haodong Li, Chen Wang, Jiahui Lei, Kostas Daniilidis, Lingjie Liu* | **Category: cs.CV**

**Keywords:** 视频深度估计, 立体匹配, 扩散模型, 时间一致性, 频域分析

**Comment:** Work done in Nov. 2024. Project page: https://stereodiff.github.io/

> **TL;DR:** StereoDiff通过结合立体匹配处理静态区域和视频深度扩散处理动态区域，显著提升了视频深度估计的性能和一致性。

**AI_Comments:** 这篇论文的创新点在于认识到视频中动态和静态区域对深度一致性的不同需求，并提出了一种巧妙的两阶段协同方法。通过结合立体匹配的全局3D信息和视频深度扩散的动态平滑过渡能力，StereoDiff有效解决了视频深度估计的挑战。数学上的频域分析进一步增强了其理论基础。其在零样本真实世界场景下的SoTA表现，证明了该方法的实用性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频深度估计方法将视频深度估计视为图像深度估计的简单扩展，但作者认为视频中动态和静态区域的时间一致性要求不同，静态区域更适合立体匹配以获取全局3D线索，而动态区域需要从大规模数据中学习以确保平滑过渡。

**Method:** 本文提出了StereoDiff，一个两阶段视频深度估计器。它将立体匹配（主要用于静态区域以实现一致深度）与视频深度扩散（用于保持动态区域的深度平滑过渡）相结合。通过频域分析，数学地证明了立体匹配和视频深度扩散如何提供互补优势。

**Result:** 在零样本、真实世界、动态视频深度基准（包括室内和室外）上的实验结果表明，StereoDiff达到了最先进的性能，展示了其在视频深度估计中卓越的一致性和准确性。

**Conclusion:** StereoDiff通过结合立体匹配和视频深度扩散，有效地解决了视频深度估计中动态和静态区域的不同一致性要求，实现了最先进的性能，并提供了卓越的一致性和准确性。

> **ai_Abstract:** StereoDiff是一种新颖的两阶段视频深度估计方法，它克服了现有方法将视频深度视为图像深度简单扩展的局限性。该方法创新性地结合了立体匹配（用于静态区域的全局3D一致性）和视频深度扩散（用于动态区域的平滑过渡），并通过频域分析证明了其互补性。实验结果表明，StereoDiff在零样本、真实世界动态视频深度估计任务上取得了最先进的性能，显著提升了视频深度估计的一致性和准确性。

> **摘要翻译:** 最近的视频深度估计方法通过遵循图像深度估计的范式，即通常使用海量数据微调预训练的视频扩散模型，取得了优异的性能。然而，我们认为视频深度估计并非图像深度估计的简单扩展。视频中动态和静态区域的时间一致性要求根本不同。静态区域（通常是背景）中一致的视频深度可以通过跨所有帧的立体匹配更有效地实现，这提供了更强的全局3D线索。而动态区域的一致性，由于三角测量约束的违反，仍应从大规模视频深度数据中学习以确保平滑过渡。基于这些见解，我们引入了StereoDiff，一个两阶段视频深度估计器，它将主要用于静态区域的立体匹配与用于保持动态区域深度平滑过渡的视频深度扩散相结合。我们通过频域分析数学地证明了立体匹配和视频深度扩散如何提供互补优势，突出了它们协同作用在捕捉两者优点方面的有效性。在零样本、真实世界、动态视频深度基准（包括室内和室外）上的实验结果表明，StereoDiff达到了最先进的性能，展示了其在视频深度估计中卓越的一致性和准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [56] [ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations](https://arxiv.org/abs/2506.20757)
> *ConViTac: 对齐视觉-触觉融合与对比表示*

*Zhiyuan Wu, Yongqiang Zhao, Shan Luo* | **Category: cs.CV, cs.RO**

**Keywords:** 视觉-触觉融合, 对比学习, 机器人感知, 特征对齐, 多模态学习

**Comment:** 

> **TL;DR:** ConViTac通过引入对比表示和对比嵌入条件（CEC）机制，有效解决了视觉-触觉融合中特征对齐不佳的问题，显著提升了机器人感知任务的性能。

**AI_Comments:** ConViTac的创新点在于将对比学习引入视觉-触觉融合领域，通过其独特的对比嵌入条件（CEC）机制，有效地解决了多模态特征对齐这一关键挑战。这种方法为机器人感知和操作任务提供了更鲁棒和高性能的解决方案，对于未来多模态机器人学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人视觉和触觉是互补的感知模态，但现有联合学习视觉-触觉表示的方法常依赖直接组合（如特征相加和拼接），导致模态融合时特征整合效果不佳。

**Method:** 本文提出了ConViTac，一个视觉-触觉表示学习网络。其核心是对比嵌入条件（CEC）机制，该机制利用通过自监督对比学习预训练的对比编码器，将视觉和触觉输入投射到统一的潜在嵌入中。这些嵌入通过跨模态注意力来耦合视觉-触觉特征融合，以实现统一表示的对齐并提升下游任务性能。

**Result:** ConViTac在真实世界实验中表现出优于当前最先进方法的性能。所提出的CEC机制有效性得到证实，在材料分类和抓取预测任务中，准确率提高了高达12.0%。

**Conclusion:** ConViTac通过创新的对比表示和对比嵌入条件（CEC）机制，成功解决了视觉-触觉融合中的特征对齐挑战，从而显著提升了机器人感知和操作任务的准确性和鲁棒性。

> **ai_Abstract:** 本文提出了ConViTac，一个旨在通过对比表示改进视觉-触觉融合的表示学习网络。为了解决现有融合方法中特征整合不佳的问题，ConViTac引入了对比嵌入条件（CEC）机制，利用自监督对比学习预训练的编码器将多模态输入映射到统一的潜在嵌入，并通过跨模态注意力实现特征的有效对齐。实验结果表明，ConViTac在真实世界的材料分类和抓取预测任务中显著优于现有技术，准确率提升高达12.0%。

> **摘要翻译:** 视觉和触觉是机器人两种基本的感觉模态，提供互补信息，增强感知和操作任务。先前的研究试图联合学习视觉-触觉表示以提取更有意义的信息。然而，这些方法通常依赖于直接组合，例如特征相加和拼接，进行模态融合，这往往导致特征整合不佳。在本文中，我们提出了ConViTac，一个视觉-触觉表示学习网络，旨在通过对比表示增强融合过程中的特征对齐。我们的主要贡献是对比嵌入条件（CEC）机制，该机制利用通过自监督对比学习预训练的对比编码器将视觉和触觉输入投射到统一的潜在嵌入中。这些嵌入用于通过跨模态注意力耦合视觉-触觉特征融合，旨在对齐统一表示并增强下游任务的性能。我们进行了广泛的实验，证明了ConViTac在真实世界中优于当前最先进的方法，以及我们提出的CEC机制的有效性，该机制在材料分类和抓取预测任务中将准确率提高了高达12.0%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [79] [AI-Driven MRI-based Brain Tumour Segmentation Benchmarking](https://arxiv.org/abs/2506.20786)
> *AI驱动的MRI脑肿瘤分割基准测试*

*Connor Ludwig, Khashayar Namdar, Farzad Khalvati* | **Category: cs.CV**

**Keywords:** 脑肿瘤分割, SAM, nnU-Net, 零样本推理, 医学图像分割

**Comment:** 

> **TL;DR:** 本研究评估了多种基于SAM的模型（SAM, SAM 2, MedSAM, SAM-Med-3D）和nnU-Net在BraTS 2023数据集上的零样本脑肿瘤分割性能，发现虽然SAM系列模型在精确边界框提示下表现出色，但nnU-Net在实际应用中仍占主导地位，微调后点提示性能有所提升但仍不及边界框或nnU-Net。

**AI_Comments:** 这项研究通过系统地评估多种基于SAM的通用可提示模型在医学图像分割领域的零样本和微调性能，填补了当前医学图像分割领域对这类模型缺乏统一评估的空白。其创新之处在于对比了不同提示质量（点和边界框）对模型性能的影响，并指出了通用大模型在医学应用中面临的实际挑战（即难以获得高精度提示）。尽管SAM模型在理想条件下表现出色，但研究强调了nnU-Net在实际场景中的鲁棒性和实用性，这为医学图像分割领域未来的研究方向提供了重要参考。

<details>
  <summary>Details</summary>

**Motivation:** 当前缺乏对各种通用提示模型及其医学变体在通用医学数据集上，针对不同提示质量进行评估和比较。

**Method:** 使用Segment Anything Model (SAM)、Segment Anything Model 2 (SAM 2)、MedSAM、SAM-Med-3D和nnU-Net在BraTS 2023成人胶质瘤和儿科数据集上进行零样本推理，评估点和边界框两种提示质量。此外，还在儿科数据集上对SAM、SAM 2、MedSAM和SAM-Med-3D进行了微调，并评估了性能改进。

**Result:** 在极度精确的边界框提示下，SAM和SAM 2的Dice分数分别高达0.894和0.893，超过了nnU-Net的分割性能。然而，由于提供高精度提示的不切实际性，nnU-Net仍然是主要的医学图像分割网络。微调后，点提示性能有显著提升，但仍未能达到边界框或nnU-Net的分割效果。

**Conclusion:** 尽管基于SAM的模型在特定理想条件下表现优异，但考虑到实际应用中获取高精度提示的挑战，nnU-Net在医学图像分割领域仍保持其主导地位。微调可以显著提升点提示的性能，但仍有待进一步研究以超越现有最佳方案。

> **ai_Abstract:** 本文评估了SAM系列模型（SAM、SAM 2、MedSAM、SAM-Med-3D）和nnU-Net在BraTS 2023数据集上进行脑肿瘤分割的性能。研究发现，在提供极精确边界框提示时，SAM和SAM 2的表现优于nnU-Net。然而，考虑到实际应用中高精度提示的获取难度，nnU-Net仍是主流选择。文章还探讨了模型微调对点提示性能的改善，尽管有显著提升，但仍未能超越边界框提示或nnU-Net。

> **摘要翻译:** 医学图像分割极大地辅助了医学诊断，其中基于U-Net的架构和nnU-Net提供了最先进的性能。近年来，已经引入了许多通用可提示模型和医学变体，但目前缺乏在通用医学数据集上，针对各种提示质量对这些模型进行评估和比较。本研究使用Segment Anything Model (SAM)、Segment Anything Model 2 (SAM 2)、MedSAM、SAM-Med-3D和nnU-Net在BraTS 2023成人胶质瘤和儿科数据集上进行零样本推理，针对点和边界框两种提示质量进行评估。其中几个模型表现出有希望的Dice分数，特别是SAM和SAM 2在给定极其精确的边界框提示时，分别达到了0.894和0.893的分数，这超过了nnU-Net的分割性能。然而，由于向模型提供高度精确提示的不切实际性，nnU-Net仍然是主要的医学图像分割网络。模型和提示评估以及比较通过在儿科数据集上微调SAM、SAM 2、MedSAM和SAM-Med-3D而得到扩展。微调后点提示性能的提升是显著的，并显示出未来研究的潜力，但仍未能实现比边界框或nnU-Net更好的分割效果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [102] [How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?](https://arxiv.org/abs/2506.20795)
> *基础模型与基于骨架的方法在人机交互手势识别中的比较如何？*

*Stephanie Käs, Anton Burenko, Louis Markert, Onur Alp Culha, Dennis Mack, Timm Linder, Bastian Leibe* | **Category: cs.CV, cs.HC, cs.RO, I.2.10; I.2.9; I.5.4; I.4.8; I.4.9; H.1.2**

**Keywords:** 手势识别, 基础模型, 人机交互, 基于骨架的方法, NUGGET数据集

**Comment:** 

> **TL;DR:** 本研究比较了基础模型（V-JEPA, Gemini Flash 2.0）与基于骨架的方法（HD-GCN）在人机交互手势识别中的表现，并引入了新数据集NUGGET。结果显示HD-GCN性能最佳，但V-JEPA也表现出色，表明其在简化系统方面的潜力。Gemini在零样本设置下表现不佳。

**AI_Comments:** 该论文解决了人机交互中的一个重要问题。其创新之处在于评估了基础模型与传统方法在手势识别中的表现，并引入了一个新的数据集。V-JEPA在仅使用简单头部的情况下能够与专门的HD-GCN相媲美的发现，对于降低系统复杂性具有重要意义。同时，指出了Gemini在零样本设置下的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统手势识别方法依赖于复杂的任务特定架构，而视觉基础模型（VFMs）和视觉语言模型（VLMs）具有强大的泛化能力，有望通过取代专用模块来降低系统复杂性。本研究旨在探索这些模型在动态全身手势识别中的应用潜力。

**Method:** 本研究比较了V-JEPA（一种最先进的视觉基础模型）、Gemini Flash 2.0（一种多模态视觉语言模型）以及HD-GCN（一种性能卓越的基于骨架的方法）在动态全身手势识别方面的性能。研究引入了一个名为NUGGET的新数据集，该数据集专为内部物流环境中的人机交流而设计，用于评估不同的手势识别方法。

**Result:** 在实验中，HD-GCN取得了最佳性能。V-JEPA仅使用一个简单的任务特定分类头就取得了接近HD-GCN的性能。相比之下，Gemini Flash 2.0在零样本设置下仅凭文本描述难以区分手势。

**Conclusion:** 尽管HD-GCN表现最佳，但V-JEPA接近的性能，以及其作为共享多任务模型的潜力，为降低系统复杂性提供了一条可能的途径。对于Gemini这类模型，需要进一步研究适合手势的输入表示，尤其是在零样本设置下。

> **ai_Abstract:** 本论文评估了基础模型（V-JEPA、Gemini Flash 2.0）与基于骨架的方法（HD-GCN）在人机交互中动态全身手势识别方面的表现，并为此目的引入了新的NUGGET数据集。结果表明，HD-GCN性能最优，但V-JEPA在仅使用简单分类头的情况下也表现接近，这表明其作为多任务模型在简化人机交互系统方面的潜力。Gemini在零样本设置下表现不佳，这强调了对更优手势输入表示的需求。

> **摘要翻译:** 手势实现了非语言的人机交流，尤其是在敏捷生产等嘈杂环境中。传统的基于深度学习的手势识别依赖于使用图像、视频或骨骼姿态估计作为输入的任务特定架构。与此同时，视觉基础模型（VFMs）和视觉语言模型（VLMs）凭借其强大的泛化能力，通过取代专用任务特定模块，有望降低系统复杂性。本研究调查了如何调整这些模型进行动态全身手势识别，并比较了V-JEPA（最先进的VFM）、Gemini Flash 2.0（多模态VLM）和HD-GCN（表现最佳的基于骨架的方法）。我们引入了NUGGET，一个专为内部物流环境中人机交流量身定制的数据集，以评估不同的手势识别方法。在我们的实验中，HD-GCN取得了最佳性能，但V-JEPA在仅使用一个简单的任务特定分类头的情况下也表现接近——这为通过将其用作共享多任务模型来降低系统复杂性铺平了可能的道路。相比之下，Gemini在零样本设置下仅凭文本描述难以区分手势，这突出表明需要进一步研究适合手势的输入表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [123] [Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models](https://arxiv.org/abs/2506.20832)
> *利用视觉-语言模型选择扩散模型生成的可靠超分辨率样本*

*Cansu Korkmaz, Ahmet Murat Tekalp, Zafer Dogan* | **Category: cs.CV, cs.AI**

**Keywords:** 超分辨率, 扩散模型, 视觉-语言模型, 可信度分数, 图像质量评估

**Comment:** 14 pages, 9 figures, 5 tables, accepted to IEEE Transactions on
  Circuits and Systems for Video Technology

> **TL;DR:** 本文提出一个利用视觉-语言模型（VLM）从扩散模型生成的超分辨率图像中选择最可靠样本的自动化框架，并通过结合语义、结构和伪影敏感性的新型可信度分数（TWS）进行验证。

**AI_Comments:** 这项工作创新性地将视觉-语言模型引入超分辨率领域，解决了扩散模型生成多样性样本后难以选择“最可靠”输出的关键问题。通过引入可信度分数TWS，为评估生成式SR的质量提供了一个更全面、更贴近人类感知的量化标准，克服了传统指标的局限性。其通用性和可扩展性使其在信息敏感型应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 回归型超分辨率（SR）模型在保真度和感知质量之间存在权衡，可能引入伪影，在信息关键应用中造成歧义。扩散模型虽然能生成多样化的SR图像，但从其生成的集合中选择最可靠的解决方案仍然是一个挑战。

**Method:** 本文引入一个鲁棒的自动化框架，通过利用视觉-语言模型（VLM，如BLIP-2、GPT-4o及其变体）的语义推理能力，评估扩散模型生成的SR样本的语义正确性、视觉质量和伪影存在。排名靠前的SR候选样本随后被集成以产生单一的可靠输出。为评估VLM选择的有效性，提出了一种新颖的可信度分数（TWS），该分数结合了CLIP嵌入的语义相似性、边缘图SSIM的结构完整性以及多级小波分解的伪影敏感性。

**Result:** 经验证明，TWS在模糊图像和自然图像中都与人类偏好高度相关。VLM引导的选择始终产生高TWS值。与未能反映信息保真度的传统指标（如PSNR、LPIPS）相比，该方法提供了一种原则性、可扩展且可推广的解决方案，用于解决扩散SR空间的不确定性。

**Conclusion:** 本研究通过使生成式超分辨率的输出与人类期望和语义正确性对齐，为其可信度设定了新的基准。

> **ai_Abstract:** 本文提出一个利用视觉-语言模型（VLM）从扩散模型生成的超分辨率（SR）图像中选择最可靠样本的自动化框架。针对回归型SR模型在保真度和感知质量间的权衡以及扩散模型选择可靠样本的挑战，研究者利用BLIP-2、GPT-4o等VLM评估SR样本的语义正确性、视觉质量和伪影，并集成优秀候选。为验证VLM选择的有效性，引入了结合语义相似性、结构完整性和伪影敏感性的新型可信度分数（TWS）。实验证明TWS与人类偏好高度相关，且VLM选择的样本具有高TWS值，优于传统指标，为生成式SR的可信度提供了可扩展的解决方案。

> **摘要翻译:** 超分辨率（SR）是一个不适定逆问题，对于给定的低分辨率图像，存在许多可行的解决方案。一方面，回归型SR模型旨在平衡保真度和感知质量以产生单一解决方案，但这种权衡常常引入伪影，在识别数字或字母等信息关键应用中造成歧义。另一方面，扩散模型生成多样化的SR图像，但从该集合中选择最可靠的解决方案仍然是一个挑战。本文引入了一个鲁棒的自动化框架，通过利用视觉-语言模型（VLM）的语义推理能力，从扩散模型生成的集合中识别最可靠的SR样本。具体来说，BLIP-2、GPT-4o及其变体等VLM被用于结构化查询，以评估语义正确性、视觉质量和伪影存在。然后，将排名靠前的SR候选样本进行集成，以经济高效的方式产生单一的可靠输出。为了严格评估VLM选择样本的有效性，我们提出了一种新颖的可信度分数（TWS）——一种混合度量，通过三个互补的组成部分量化SR可靠性：通过CLIP嵌入的语义相似性、使用边缘图SSIM的结构完整性以及通过多级小波分解的伪影敏感性。我们通过经验证明，TWS在模糊图像和自然图像中都与人类偏好高度相关，并且VLM引导的选择始终产生高TWS值。与PSNR、LPIPS等未能反映信息保真度的传统指标相比，我们的方法为解决扩散SR空间的不确定性提供了一种原则性、可扩展且可推广的解决方案。通过使输出与人类期望和语义正确性对齐，这项工作为生成式SR的可信度设定了新的基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [142] [FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization](https://arxiv.org/abs/2506.20841)
> *FixCLR：半监督域泛化的负类对比学习*

*Ha Min Son, Shahbaz Rezaei, Xin Liu* | **Category: cs.CV, cs.AI**

**Keywords:** 半监督域泛化, 对比学习, 域不变性, 伪标签, FixCLR

**Comment:** 

> **TL;DR:** FixCLR是一种新的半监督域泛化方法，通过修改对比学习来显式学习域不变表示，尤其与现有方法结合时效果显著。

**AI_Comments:** FixCLR的创新之处在于其通过修改对比学习来显式地解决SSDG中域不变性学习的关键挑战，特别是利用伪标签和仅使用排斥项的设计。其作为插件可与现有方法结合的特性也增加了其实用性和影响力。该研究还进行了更全面的实验评估，进一步验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 半监督域泛化（SSDG）在标签稀缺时，现有方法未能显式地正则化以学习跨所有域的域不变表示，而这正是域泛化的关键目标。

**Method:** 本文引入了FixCLR，受自监督学习启发，通过改变对比学习的两个关键组件来实现显式域不变性正则化：利用伪标签的类信息和仅使用排斥项。FixCLR还可以作为插件与大多数现有SSDG和半监督方法结合使用。

**Result:** 进行了SSDG研究中未曾探索的广泛实验，包括对半监督方法不同改进的基准测试、评估预训练与非预训练模型的性能，以及在多域数据集上的测试。

**Conclusion:** FixCLR被证明是一种有效的SSDG方法，特别是与其它半监督方法结合时。

> **ai_Abstract:** 本文针对半监督域泛化（SSDG）中标签稀缺导致现有方法难以学习域不变表示的问题，提出了FixCLR。该方法受自监督学习启发，通过利用伪标签的类信息和仅使用排斥项来改进对比学习，从而实现显式的域不变性正则化。广泛的实验表明，FixCLR是一种有效的SSDG方法，尤其是在与现有半监督方法结合使用时，能带来互补的性能提升。

> **摘要翻译:** 半监督域泛化（SSDG）旨在解决当只有少量标签可用时，泛化到分布外数据的问题。由于标签稀缺，应用域泛化方法通常表现不佳。因此，现有的SSDG方法将半监督学习方法与各种正则化项结合起来。然而，这些方法没有明确地正则化以学习跨所有域的域不变表示，这是域泛化的一个关键目标。为了解决这个问题，我们引入了FixCLR。受自监督学习成功的启发，我们改变了两个关键组件，以使对比学习适应显式域不变性正则化：利用伪标签的类信息和仅使用排斥项。FixCLR还可以添加到大多数现有SSDG和半监督方法之上，以实现互补的性能改进。我们的研究包括以前在SSDG研究中未曾探索的广泛实验。这些实验包括对半监督方法不同改进的基准测试、评估预训练与非预训练模型的性能，以及在多域数据集上的测试。总的来说，FixCLR被证明是一种有效的SSDG方法，特别是与其它半监督方法结合时。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [160] [Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision](https://arxiv.org/abs/2506.20850)
> *向量对比学习在医学视觉像素级预训练中的应用*

*Yuting He, Shuo Li* | **Category: cs.CV**

**Keywords:** 向量对比学习, 像素级预训练, 医学视觉, 自监督学习, 特征相关性

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 提出向量对比学习（Vector CL）和COVER框架，通过将对比学习重构为向量回归问题，解决了标准对比学习在像素级预训练中的过度分散问题，显著提升了医学视觉基础模型的泛化能力。

**AI_Comments:** 这篇论文通过将对比学习从传统的二元优化问题重新定义为向量回归问题，提出了一个新颖的像素级预训练范式，解决了医学图像领域中像素级特征相关性被破坏的关键挑战。COVER框架的设计，特别是其向量金字塔架构，对于保持粒度适应性和特征相关性至关重要。其创新点在于对对比学习原理的深刻理解和在像素级应用的突破，对于推动医学视觉基础模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准对比学习（CL）在像素级表示方面存在过度分散问题，这会破坏像素级特征相关性并扰乱类内分布，而像素级表示对医学视觉至关重要，因此需要一种新的方法来解决这一挑战。

**Method:** 提出向量对比学习（vector CL），将CL重构为向量回归问题，通过建模回归位移向量中的特征距离来实现像素级预训练中的分散量化。为实现这一范式，提出COntrast in VEctor Regression (COVER) 框架，该框架建立了可扩展的基于向量的自学习，强制执行从向量回归到距离建模的一致优化流，并利用向量金字塔架构进行粒度适应，从而在自监督预训练（SSP）中保留像素级特征相关性。

**Result:** 在跨越2个维度和4种模态的8项任务中进行的广泛实验表明，COVER显著改进了像素级自监督预训练（SSP），推动了可泛化的医学视觉基础模型的发展。

**Conclusion:** 向量对比学习及其实现的COVER框架有效解决了标准对比学习在医学视觉像素级预训练中的挑战，显著提升了模型性能和泛化能力，为医学视觉基础模型的发展提供了新途径。

> **ai_Abstract:** 本文提出向量对比学习（vector CL）范式和COntrast in VEctor Regression (COVER) 框架，旨在解决标准对比学习在医学视觉像素级预训练中过度分散、破坏特征相关性的问题。通过将对比学习重构为向量回归问题，COVER框架能够量化特征分散并保留像素级特征相关性。实验证明，COVER显著提升了像素级自监督预训练的效果，促进了可泛化医学视觉基础模型的发展。

> **摘要翻译:** 对比学习（CL）已成为基础模型中自监督预训练（SSP）的基石，然而，将CL扩展到像素级表示（这对医学视觉至关重要）仍然是一个悬而未决的问题。标准CL将SSP表述为一个二元优化问题（二元CL），其中过度追求特征分散导致过度分散问题，破坏了像素级特征相关性，从而扰乱了类内分布。我们的向量CL将CL重构为一个向量回归问题，通过建模回归位移向量中的特征距离，实现了像素级预训练中的分散量化。为了实现这一新颖的范式，我们提出了向量回归中的对比（COVER）框架。COVER建立了一个可扩展的基于向量的自学习，强制执行从向量回归到距离建模的一致优化流，并利用向量金字塔架构进行粒度适应，从而在SSP中保留像素级特征相关性。在跨越2个维度和4种模态的8项任务中进行的广泛实验表明，COVER显著改进了像素级SSP，推动了可泛化的医学视觉基础模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [166] [Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance](https://arxiv.org/abs/2506.20995)
> *基于负面音频引导的逐步视频到音频合成*

*Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji* | **Category: cs.CV, cs.LG, cs.SD, eess.AS**

**Keywords:** 视频到音频合成, 逐步生成, 负面音频引导, 拟音工作流, 音频生成

**Comment:** 

> **TL;DR:** 提出了一种新颖的逐步视频到音频生成方法，通过负面音频引导顺序生成独立的音轨，从而实现高质量的复合音频合成。

**AI_Comments:** 该论文的创新点在于其“逐步”和“负面音频引导”的生成范式，模仿了传统的拟音工作流程，这在视频到音频合成领域是一个新颖的视角。此外，它解决了专用配对数据集的需求问题，通过利用预训练模型和更易获取的数据进行训练，大大降低了数据门槛。其能够生成语义上不同的独立音轨，并最终合成高质量复合音频的能力，显示了其在多音源视频生成方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法可能无法全面捕捉视频中所有声事件，或需要专门的配对数据集。本文旨在提出一种能够全面捕捉视频中所有声事件、且无需专门配对数据集的视频到音频生成方法。

**Method:** 提出了一种逐步视频到音频生成方法，该方法模仿传统的拟音工作流程。每个生成步骤都被表述为一个引导式视频到音频合成任务，以目标文本提示和先前生成的音轨为条件。引入了一个训练框架，利用预训练的视频到音频模型，并消除了对专门配对数据集的需求，允许在更易获取的数据上进行训练。

**Result:** 实验结果表明，该方法能够为单个输入视频生成多个语义上不同的音轨，并且比现有基线方法产生更高质量的复合音频合成。

**Conclusion:** 本文提出的基于负面音频引导的逐步视频到音频合成方法，能够有效地生成高质量的复合音频，并且在数据需求方面具有优势。

> **ai_Abstract:** 本文提出了一种名为“逐步视频到音频合成”的新方法，该方法通过模仿拟音工作流，顺序生成视频中各声事件对应的独立音轨。每个生成步骤都受到目标文本提示和已生成音轨的引导，并借鉴了概念否定的思想。该方法利用预训练模型，无需特定配对数据集，可在更易获取的数据上训练。实验证明，该方法能为单个视频生成多个语义独立的音轨，合成的复合音频质量优于现有基线。

> **摘要翻译:** 我们提出了一种新颖的逐步视频到音频生成方法，该方法顺序生成独立的音轨，每个音轨对应视频中特定的声音事件。我们的方法模仿传统的拟音工作流程，旨在全面捕捉给定视频中所有由视频引发的声音事件。每个生成步骤都被表述为一个引导式视频到音频合成任务，以目标文本提示和先前生成的音轨为条件。这种设计灵感来源于先前组合生成框架中的概念否定思想。为了实现这种引导式生成，我们引入了一个训练框架，该框架利用预训练的视频到音频模型，并消除了对专门配对数据集的需求，允许在更易获取的数据上进行训练。实验结果表明，我们的方法能够为单个输入视频生成多个语义上不同的音轨，从而产生比现有基线方法更高质量的复合音频合成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [178] [Enhancing Ambiguous Dynamic Facial Expression Recognition with Soft Label-based Data Augmentation](https://arxiv.org/abs/2506.20867)
> *基于软标签数据增强的模糊动态面部表情识别增强*

*Ryosuke Kawamura, Hideaki Hayashi, Shunsuke Otake, Noriko Takemura, Hajime Nagahara* | **Category: cs.CV**

**Keywords:** 动态面部表情识别, 数据增强, 软标签, 模糊表情识别, mixup

**Comment:** 

> **TL;DR:** 本文提出MIDAS，一种基于软标签的数据增强方法，旨在提高模糊动态面部表情识别的性能，并通过实验证明其优于现有SOTA方法。

**AI_Comments:** 本文的创新点在于将mixup数据增强策略与软标签结合，应用于动态面部表情识别中模糊表情的处理，并引入了一个新的软标签数据集。这种方法简单高效，为解决实际场景中模糊表情识别的挑战提供了一条有前景的途径。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，尤其是在野外数据中，准确识别模糊面部表情对于动态面部表情识别（DFER）至关重要。

**Method:** 本文提出MIDAS，一种数据增强方法，通过凸组合视频帧对及其对应的软标签（表示多个情感类别的概率）来扩充训练数据。该方法将mixup扩展到软标签视频数据，以处理DFER中的模糊性。

**Result:** 在DFEW数据集和新构建的FERV39k-Plus数据集上进行的实验表明，使用MIDAS增强数据训练的模型与在原始数据集上训练的最新方法相比，取得了卓越的性能。

**Conclusion:** MIDAS是一种简单而高效的方法，能够有效处理动态面部表情识别中的模糊性，并显著提升识别性能。

> **ai_Abstract:** 本文提出MIDAS，一种基于软标签的数据增强方法，旨在提高动态面部表情识别（DFER）对模糊表情的识别能力。MIDAS通过凸组合视频帧及其对应的软标签来扩充训练数据，将mixup的思想扩展到软标签视频数据。实验结果表明，MIDAS增强的数据训练的模型在DFEW和FERV39k-Plus数据集上均优于现有SOTA方法，证明了其在处理模糊动态面部表情方面的有效性。

> **摘要翻译:** 动态面部表情识别（DFER）是一项从面部表情视频序列中估计情绪的任务。对于实际应用而言，准确识别模糊的面部表情——这在野外数据中经常遇到——至关重要。在本研究中，我们提出了MIDAS，一种数据增强方法，旨在利用表示多个情绪类别概率的软标签，提升模糊面部表情数据的DFER性能。MIDAS通过凸组合视频帧对及其对应的表情类别标签来扩充训练数据。这种方法将mixup扩展到软标签视频数据，为处理DFER中的模糊性提供了一种简单而高效的方法。为了评估MIDAS，我们在DFEW数据集和FERV39k-Plus（一个新构建的、为现有DFER数据集分配软标签的数据集）上进行了实验。结果表明，使用MIDAS增强数据训练的模型与在原始数据集上训练的最新方法相比，取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [194] [THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion](https://arxiv.org/abs/2506.20877)
> *THIRDEYE：脑启发式多阶段融合的线索感知单目深度估计*

*Calin Teodor Ioan* | **Category: cs.CV, cs.AI, I.4.8; I.2.10**

**Keywords:** 单目深度估计, 线索感知, 脑启发, 多阶段融合, THIRDEYE

**Comment:** 

> **TL;DR:** ThirdEye 提出了一种脑启发式的多阶段融合框架，通过显式集成单目线索来改进单目深度估计，解决了传统方法忽视人类视觉系统依赖的显式线索的问题。

**AI_Comments:** 该论文的创新点在于其明确地将人类视觉系统所依赖的单目线索集成到深度估计流程中，并采用了脑启发式的多阶段融合架构。这种方法有望通过超越传统的隐式学习来提高深度估计的准确性。然而，本版本尚未提供定量结果，这是其当前的一个局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单目深度估计方法通过深度模型从RGB像素中隐式推断深度，但这常常忽略了人类视觉系统所依赖的显式单目线索，如遮挡边界、阴影和透视。本文旨在通过明确提供这些线索来解决这个问题。

**Method:** 本文提出了ThirdEye，一个线索感知的管道，通过专门的、预训练和冻结的网络刻意提供每种线索。这些线索在一个三阶段的皮层层级（V1->V2->V3）中融合，该层级配备了键值工作记忆模块，根据可靠性对线索进行加权。然后，一个自适应箱变压器头部生成高分辨率的视差图。由于线索专家网络是冻结的，ThirdEye继承了大量的外部监督，同时只需要适度的微调。

**Result:** 定量结果将在未来的修订中出现。

**Conclusion:** ThirdEye提出了一种通过脑启发式多阶段融合来显式整合单目线索的单目深度估计方法，该方法通过利用预训练和冻结的专家网络，能够继承大量外部监督并仅需适度微调。

> **ai_Abstract:** ThirdEye提出了一种新颖的单目深度估计方法，该方法通过明确整合人类视觉系统所依赖的显式单目线索（如遮挡边界、阴影和透视）来克服传统方法的局限性。该方法利用预训练并冻结的专家网络提供这些线索，并通过一个脑启发式的三阶段皮层层级结构进行融合，其中包含一个基于可靠性加权的键值工作记忆模块。最终，一个自适应箱变压器头部生成高分辨率视差图。ThirdEye的创新之处在于其能够继承大量外部监督，同时仅需少量微调。

> **摘要翻译:** 单目深度估计方法传统上训练深度模型直接从RGB像素推断深度。这种隐式学习常常忽视人类视觉系统所依赖的显式单目线索，例如遮挡边界、阴影和透视。我们没有期望网络在没有帮助的情况下发现这些线索，而是提出了ThirdEye，一个线索感知的管道，通过专门的、预训练和冻结的网络刻意提供每种线索。这些线索在一个三阶段的皮层层级（V1->V2->V3）中融合，该层级配备了键值工作记忆模块，根据可靠性对线索进行加权。然后，一个自适应箱变压器头部生成高分辨率的视差图。由于线索专家网络是冻结的，ThirdEye继承了大量的外部监督，同时只需要适度的微调。这个扩展版本提供了额外的架构细节、神经科学动机和扩展的实验协议；定量结果将在未来的修订中出现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [206] [MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans](https://arxiv.org/abs/2506.20879)
> *MultiHuman-Testbench：多人物图像生成基准测试*

*Shubhankar Borse, Seokeon Choi, Sunghyun Park, Jeongho Kim, Shreya Kadambi, Risheek Garrepalli, Sungrack Yun, Munawar Hayat, Fatih Porikli* | **Category: cs.CV**

**Keywords:** 多人物图像生成, 基准测试, 面部身份, 姿态条件, 图像评估

**Comment:** 

> **TL;DR:** 本文提出了MultiHuman-Testbench，一个用于评估多人物图像生成模型的新基准，解决了现有模型在生成多人物图像时面临的挑战，并提高了身份相似性。

**AI_Comments:** 该论文的创新之处在于提出了首个专门针对多人物图像生成问题的综合基准MultiHuman-Testbench，填补了该领域基准测试的空白。其重要性体现在为未来的研究提供了一个标准化的评估工具，并提出了有效提高生成图像中人物身份相似性的新方法，对提升多人物图像生成质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成包含多个执行复杂动作且保留面部身份的图像是一项重大挑战，主要原因是缺乏专门的基准测试。

**Method:** 本文引入了MultiHuman-Testbench，一个包含1800个样本（包括文本提示和5550个多样化的人脸图像）以及人工选择的姿态条件图像的新型基准。提出了一个多方面的评估套件，采用面部计数、ID相似性、提示对齐和动作检测四项关键指标。此外，还提出了利用人体分割和匈牙利匹配来整合图像和区域隔离的新技术。

**Result:** 对包括零样本和基于训练的方法在内的多种模型进行了全面评估，并展示了所提出的新技术显著提高了ID相似性。

**Conclusion:** 所提出的基准和主要发现为推进多人物图像生成研究提供了宝贵的见解和标准化工具。

> **ai_Abstract:** 本文介绍了MultiHuman-Testbench，一个用于评估多人物图像生成模型的新型基准。该基准包含1800个样本，包括多样化的文本提示、人脸图像和人工选择的姿态条件图像。研究者提出了一个包含面部计数、ID相似性、提示对齐和动作检测的四项关键指标的评估套件，并引入了结合人体分割和匈牙利匹配以提高ID相似性的新技术。该基准和相关发现旨在推动多人物图像生成领域的研究。

> **摘要翻译:** 生成包含多个人物、执行复杂动作同时保留其面部身份的图像是一个重大挑战。导致这一问题的一个主要因素是缺乏专门的基准。为了解决这个问题，我们引入了MultiHuman-Testbench，这是一个用于严格评估多人物生成模型的生成模型的新型基准。该基准包含1800个样本，其中包括精心策划的文本提示，描述了从简单到复杂的一系列人类动作。这些提示与总共5550个独特的人脸图像匹配，这些图像均匀采样以确保年龄、种族背景和性别多样性。除了标题，我们还提供了人工选择的姿态条件图像，这些图像与提示准确匹配。我们提出了一个多方面的评估套件，采用四个关键指标来量化面部计数、ID相似性、提示对齐和动作检测。我们对包括零样本方法和基于训练的方法（有无区域先验）在内的多种模型进行了彻底评估。我们还提出了结合人体分割和匈牙利匹配来整合图像和区域隔离的新技术，显著提高了ID相似性。我们提出的基准和关键发现为推进多人物图像生成研究提供了宝贵的见解和标准化工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [221] [The Role of Cyclopean-Eye in Stereo Vision](https://arxiv.org/abs/2506.20900)
> *独眼视觉在立体视觉中的作用*

*Sherlon Almeida da Silva, Davi Geiger, Luiz Velho, Moacir Antonelli Ponti* | **Category: cs.CV**

**Keywords:** 立体视觉, 独眼视觉, 深度重建, 几何先验, 深度学习

**Comment:** arXiv admin note: text overlap with arXiv:2502.21280

> **TL;DR:** 本文探讨了独眼视觉模型在现代立体视觉中的几何基础，并结合深度学习和注意力机制，通过理论和实证研究证明了几何先验与学习特征结合的重要性。

**AI_Comments:** 这篇论文通过重新审视经典的独眼视觉模型并将其与现代深度学习技术相结合，提出了一种新颖的方法来处理立体视觉中的深度重建问题。其创新点在于将几何先验知识与学习到的特征相结合，这对于提升遮挡和深度不连续性区域的重建精度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代立体视觉系统如何利用3D结构和受人类启发感知来准确重建深度。

**Method:** 重新审视独眼视觉模型，提出新的几何约束以处理遮挡和深度不连续性；评估深度学习模型衍生的立体特征匹配质量；分析注意力机制在恢复有意义3D表面中的作用。通过理论分析和真实数据集的实证研究。

**Result:** 结合强大的几何先验与学习特征，为理解立体视觉系统提供了内部抽象。

**Conclusion:** 结合几何先验与学习特征能够有效提升立体视觉系统的理解和深度重建能力。

> **ai_Abstract:** 本文探讨了独眼视觉模型在现代立体视觉系统中的几何基础，旨在提高深度重建的准确性。研究提出了新的几何约束以处理遮挡和深度不连续，并评估了深度学习特征匹配质量和注意力机制的作用。通过理论和实证研究，论文证明了结合几何先验与学习特征对于理解立体视觉系统的重要性。

> **摘要翻译:** 本文研究了现代立体视觉系统的几何基础，重点关注3D结构和受人类启发感知如何有助于准确的深度重建。我们重新审视了独眼视觉模型，并提出了新的几何约束，以解决遮挡和深度不连续性。我们的分析包括评估源自深度学习模型的立体特征匹配质量，以及注意力机制在恢复有意义的3D表面中的作用。通过理论洞察和对真实数据集的实证研究，我们证明了将强大的几何先验与学习特征相结合，为理解立体视觉系统提供了内部抽象。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [225] [Out-of-Distribution Semantic Occupancy Prediction](https://arxiv.org/abs/2506.21185)
> *域外语义占据预测*

*Yuheng Zhang, Mengfei Duan, Kunyu Peng, Yuhang Wang, Ruiping Liu, Fei Teng, Kai Luo, Zhiyong Li, Kailun Yang* | **Category: cs.CV, cs.RO, eess.IV**

**Keywords:** 语义占据预测, 域外检测, 自动驾驶, 合成数据, OccOoD

**Comment:** The established datasets and source code will be made publicly
  available at https://github.com/7uHeng/OccOoD

> **TL;DR:** 本文提出了一种新的框架OccOoD，用于在3D体素空间中进行域外（OoD）语义占据预测。通过引入合成异常数据生成流程和Voxel-BEV渐进式融合（VBPF）模块，OccOoD在OoD检测方面达到了最先进水平，同时保持了良好的占据预测性能，对于提升自动驾驶的安全性至关重要。

**AI_Comments:** 这篇论文通过引入OoD检测的概念，解决了自动驾驶中3D语义占据预测对未知或异常物体识别不足的关键安全问题。其创新点在于提出了合成异常数据生成流程来弥补真实世界数据稀缺的挑战，以及设计了集成了OoD检测的OccOoD框架，特别是VBPF模块利用几何-语义融合提升检测精度。这对于提升自动驾驶系统的鲁棒性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D语义占据预测方法主要关注域内场景，对域外（OoD）对象和长尾分布敏感，这增加了未检测到异常和误解的风险，从而构成安全隐患。

**Method:** 1. 提出“合成异常整合流程”（Synthetic Anomaly Integration Pipeline），通过注入合成异常来创建数据集VAA-KITTI和VAA-KITTI-360，以弥补数据集中的空白。2. 引入OccOoD框架，将OoD检测集成到3D语义占据预测中，其中包含Voxel-BEV渐进式融合（VBPF）模块，该模块利用基于RWKV的分支通过几何-语义融合增强OoD检测。

**Result:** OccOoD在1.2米区域内实现了最先进的OoD检测性能，AuROC为67.34%，AuPRCr为29.21%，同时保持了有竞争力的占据预测性能。

**Conclusion:** 该研究成功解决了3D语义占据预测中域外对象的检测挑战，通过新颖的OccOoD框架和合成数据生成方法，显著提升了自动驾驶环境感知的安全性，并为未来的研究提供了公开的数据集和源代码。

> **ai_Abstract:** 本文针对自动驾驶中3D语义占据预测现有方法对域外（OoD）对象识别不足的问题，提出了“域外语义占据预测”的概念。研究引入了“合成异常整合流程”以创建包含合成异常的数据集VAA-KITTI和VAA-KITTI-360，并提出了OccOoD框架，该框架将OoD检测融入3D语义占据预测，通过Voxel-BEV渐进式融合（VBPF）模块利用几何-语义融合增强OoD检测能力。实验证明，OccOoD在OoD检测方面达到了最先进水平，同时保持了良好的占据预测性能，为自动驾驶系统的安全性提供了重要保障。

> **摘要翻译:** 3D语义占据预测对于自动驾驶至关重要，它提供了一种密集、语义丰富的环境表示。然而，现有方法主要关注域内场景，使其容易受到域外（OoD）对象和长尾分布的影响，这增加了未检测到异常和误解的风险，从而构成安全隐患。为了解决这些挑战，我们引入了域外语义占据预测，旨在3D体素空间中进行OoD检测。为了弥补数据集的不足，我们提出了一个合成异常整合流程，该流程注入合成异常，同时保留真实的G空间和遮挡模式，从而能够创建两个数据集：VAA-KITTI和VAA-KITTI-360。我们引入了OccOoD，一个将OoD检测集成到3D语义占据预测中的新型框架，其中Voxel-BEV渐进式融合（VBPF）模块利用基于RWKV的分支，通过几何-语义融合增强OoD检测。实验结果表明，OccOoD在1.2米区域内实现了最先进的OoD检测，AuROC为67.34%，AuPRCr为29.21%，同时保持了有竞争力的占据预测性能。所建立的数据集和源代码将在https://github.com/7uHeng/OccOoD公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [233] [FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing](https://arxiv.org/abs/2506.20911)
> *FaSTA$^*$: 用于高效多轮图像编辑的快慢工具路径代理与子程序挖掘*

*Advait Gupta, Rishie Raj, Dang Nguyen, Tianyi Zhou* | **Category: cs.CV**

**Keywords:** 多轮图像编辑, 神经符号代理, 工具路径规划, 子程序挖掘, LLM, A$^*$搜索

**Comment:** 

> **TL;DR:** FaSTA$^*$是一种结合LLM规划和A$^*$搜索的神经符号代理，通过挖掘和重用子程序，实现多轮图像编辑的成本效益和高效率。

**AI_Comments:** FaSTA$^*$的创新之处在于其“快慢”混合规划策略，以及通过LLM进行子程序挖掘和重用来优化昂贵的A$^*$搜索。这种结合了符号推理和神经模型的混合方法，提高了复杂多轮任务的效率，并展现了在AI代理中学习和重用经验的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决复杂的多轮图像编辑任务，这些任务需要识别、修改多个对象，并找到成本效益高的工具路径。现有方法可能效率不高。

**Method:** FaSTA$^*$结合了LLM进行快速、高层次的子任务规划，以及A$^*$搜索进行慢速、准确的工具使用和局部搜索。为了降低A$^*$的成本，系统通过LLM对成功的工具路径进行归纳推理，持续提取和优化常用子程序，并将其作为新工具重用。这形成了一种自适应的快慢规划：优先探索高层子程序，失败时才激活低层A$^*$搜索。

**Result:** FaSTA$^*$在计算效率上显著优于现有图像编辑方法，同时在成功率方面与最先进的基线保持竞争力。

**Conclusion:** FaSTA$^*$通过结合LLM的快速规划和A$^*$的慢速搜索，并通过子程序挖掘和重用，有效地解决了多轮图像编辑任务，实现了高效率和竞争性的成功率。

> **ai_Abstract:** FaSTA$^*$是一个神经符号代理，专为高效多轮图像编辑而设计。它结合了LLM的高级规划和A$^*$的低级搜索，并通过挖掘和重用常用的工具路径子程序来显著提高效率。该方法通过优先使用预定义的子程序，仅在必要时才进行昂贵的A$^*$搜索，从而在保持高成功率的同时大幅降低了计算成本。

> **摘要翻译:** 我们开发了一种成本高效的神经符号代理，以解决具有挑战性的多轮图像编辑任务，例如“检测图像中的长凳并将其重新着色为粉红色。此外，为了更清晰的视图移除猫并将墙壁重新着色为黄色。”它结合了大型语言模型（LLM）的快速、高层次子任务规划与每个子任务的慢速、准确、工具使用和局部A$^*$搜索，以找到成本高效的工具路径——一系列对AI工具的调用。为了节省A$^*$在类似子任务上的成本，我们通过LLM对先前成功的工具路径进行归纳推理，持续提取/细化常用子程序，并将其作为新工具在自适应的快慢规划中用于未来的任务，其中首先探索更高级别的子程序，只有当它们失败时，才激活低级别的A$^*$搜索。可重用的符号子程序显著节省了应用于类似图像的相同类型子任务的探索成本，产生了一种类似人类的快慢工具路径代理“FaSTA$^*$”：首先由LLM尝试快速子任务规划，然后是每个子任务的基于规则的子程序选择，预计这可以覆盖大多数任务，而慢速A$^*$搜索仅在新颖和具有挑战性的子任务中触发。通过与最近的图像编辑方法进行比较，我们证明FaSTA$^*$在计算效率上显著更高，同时在成功率方面与最先进的基线保持竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [237] [Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation](https://arxiv.org/abs/2506.21198)
> *解锁约束：无源遮挡感知无缝分割*

*Yihong Cao, Jiaming Zhang, Xu Zheng, Hao Shi, Kunyu Peng, Hang Liu, Kailun Yang, Hui Zhang* | **Category: cs.CV, cs.RO, eess.IV**

**Keywords:** 无源域适应, 全景分割, 遮挡感知, 无缝分割, UNLOCK

**Comment:** Accepted to ICCV 2025. All data and code will be made publicly
  available at https://github.com/yihong-97/UNLOCK

> **TL;DR:** 本文提出了一种名为SFOASS的新型无源、遮挡感知无缝分割任务，并提供了首个解决方案UNLOCK，该方法在不依赖源数据或目标标签的情况下实现了与有源方法相当的性能。

**AI_Comments:** 该论文的创新点在于提出了一个更具实用性的“无源”域适应任务，即SFOASS，这解决了传统域适应方法对源数据依赖的限制。UNLOCK框架的设计，特别是其无源适应能力和对遮挡感知的关注，对于实际的全景图像处理和全方位感知具有重要意义。性能与有源方法相当甚至超越，证明了其方法的有效性和先进性。

<details>
  <summary>Details</summary>

**Motivation:** 全景图像处理对于全方位感知至关重要，但面临失真、透视遮挡和注释有限等挑战。现有的无监督域适应方法需要访问源针孔数据，这在实际应用中存在限制。

**Method:** 本文提出了“无源遮挡感知无缝分割 (SFOASS)”任务及其首个解决方案“无约束学习全方位知识 (UNLOCK)”。UNLOCK包含两个关键模块：全方位伪标签学习和非模态驱动上下文学习。该框架在不依赖源数据或目标标签的情况下，使模型能够实现360度视角的分割和遮挡感知推理。

**Result:** 实验结果表明，该无源方法实现了与有源方法相当的性能，在mAAP上达到10.9、mAP上达到11.6的最新分数，并且在mAPQ上相对于仅源方法有+4.3的绝对提升。

**Conclusion:** 本文成功引入并解决了无源遮挡感知无缝分割这一新任务，提出的UNLOCK框架在不依赖源数据或目标标签的情况下，在全景图像分割方面取得了与有源方法相当甚至超越的先进性能，显著提升了全方位感知能力。

> **ai_Abstract:** 本文针对全景图像处理中存在的失真、遮挡和标注限制，以及现有域适应方法对源数据的依赖问题，提出了一种新的“无源遮挡感知无缝分割 (SFOASS)”任务。研究者设计了首个解决方案UNLOCK框架，该框架通过“全方位伪标签学习”和“非模态驱动上下文学习”两个模块，实现了在无源数据和无目标标签的情况下，对全景图像进行360度视角覆盖和遮挡感知的分割。实验证明，UNLOCK在性能上与依赖源数据的方法相当，甚至在某些指标上有所超越，达到了最先进水平。

> **摘要翻译:** 全景图像处理对于全方位感知至关重要，但面临失真、透视遮挡和注释有限等约束。以前的无监督域适应方法将知识从带标签的针孔数据转移到无标签的全景图像，但它们需要访问源针孔数据。为了解决这些问题，我们引入了一个更实用的任务，即无源遮挡感知无缝分割（SFOASS），并提出了其首个解决方案，名为无约束学习全方位知识（UNLOCK）。具体来说，UNLOCK包括两个关键模块：全方位伪标签学习和非模态驱动上下文学习。在不依赖源数据或目标标签进行适应的同时，该框架增强了模型，以实现360度视角的分割和遮挡感知推理。此外，我们通过真实到真实和合成到真实两种适应设置对所提出的SFOASS任务进行了基准测试。实验结果表明，我们的无源方法实现了与有源方法相当的性能，在mAAP上获得10.9、mAP上获得11.6的最新分数，并且在mAPQ上相对于仅源方法有+4.3的绝对提升。所有数据和代码将在https://github.com/yihong-97/UNLOCK 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [244] [M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization](https://arxiv.org/abs/2506.20922)
> *M2SFormer: 结合边缘感知难度引导的多光谱多尺度注意力图像伪造定位*

*Ju-Hyeon Nam, Dong-Hyun Moon, Sang-Chul Lee* | **Category: cs.CV**

**Keywords:** 图像伪造定位, Transformer, 多尺度注意力, 多频率注意力, 难度引导注意力

**Comment:** Accepted in International Conference on Computer Vision (ICCV) 2025

> **TL;DR:** M2SFormer是一个新的Transformer框架，通过统一多频率和多尺度注意力并利用难度引导注意力模块，解决了现有图像伪造定位方法计算开销大和表示能力有限的问题，并在多个基准数据集上取得了SOTA性能。

**AI_Comments:** M2SFormer的创新之处在于其对多频率和多尺度注意力的统一处理，以及引入边缘感知难度引导机制，这有效地提升了模型对复杂和细微伪造的定位能力。其在Transformer框架下的应用，也体现了将先进的注意力机制应用于图像取证领域的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习图像伪造定位方法在像素级定位方面取得了高精度，但常面临计算开销大和表示能力有限的问题，尤其对于细微或复杂的篡改效果不佳。

**Method:** 本文提出了M2SFormer，一个基于Transformer编码器的新框架。它在跳跃连接中统一了多频率和多尺度注意力，利用全局上下文捕获多样化的伪造痕迹。此外，M2SFormer利用一个全局先验图（曲率度量，指示伪造定位难度）来指导一个难度引导注意力模块，以更有效地保留细微的操作，解决上采样过程中精细细节丢失的问题。

**Result:** 在多个基准数据集上进行的广泛实验表明，M2SFormer优于现有最先进的模型，在检测和定位未知领域伪造方面表现出卓越的泛化能力。

**Conclusion:** M2SFormer通过其独特的多光谱多尺度注意力机制和边缘感知难度引导模块，有效克服了现有图像伪造定位方法的局限性，并在泛化能力和性能上超越了SOTA模型。

> **ai_Abstract:** M2SFormer是一个针对图像伪造定位的新型Transformer框架，旨在解决现有方法计算开销大和表示能力有限的问题。它通过在跳跃连接中统一多频率和多尺度注意力来捕获多样化的伪造痕迹，并利用一个难度引导注意力模块（基于全局先验图）来保留细微细节。实验证明M2SFormer在多个基准数据集上优于现有SOTA模型，并具有更强的泛化能力。

> **摘要翻译:** 图像编辑技术发展迅速，既促进了创新的应用，也导致了数字图像的恶意篡改。基于深度学习的方法最近在像素级伪造定位方面取得了高精度，但它们经常面临计算开销大和表示能力有限的问题，特别是对于细微或复杂的篡改。在本文中，我们提出了M2SFormer，一个新颖的基于Transformer编码器的框架，旨在克服这些挑战。与单独处理空间和频率线索的方法不同，M2SFormer在跳跃连接中统一了多频率和多尺度注意力，利用全局上下文更好地捕获多样化的伪造痕迹。此外，我们的框架通过利用全局先验图（一个指示伪造定位难度的曲率度量）来解决上采样过程中精细细节的丢失问题，然后该先验图指导一个难度引导注意力模块，以更有效地保留细微的操作。在多个基准数据集上进行的广泛实验表明，M2SFormer优于现有最先进的模型，在检测和定位未知领域伪造方面表现出卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [247] [Generalizable Neural Electromagnetic Inverse Scattering](https://arxiv.org/abs/2506.21349)
> *可泛化的神经电磁逆散射*

*Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang* | **Category: cs.CV, eess.IV**

**Keywords:** 电磁逆散射, 泛化, 物理信息, 感应电流, 神经网络

**Comment:** 

> **TL;DR:** 本文提出了一种可泛化的物理驱动框架，用于解决电磁逆散射问题（EISP），通过将问题重新表述为两阶段过程并引入感应电流作为中间表示，显著提高了重建精度、泛化能力和对稀疏发射器设置的鲁棒性。

**AI_Comments:** 这项工作通过引入感应电流作为可泛化的中间表示，并构建两阶段的物理驱动框架，为解决电磁逆散射问题提供了根本性的新视角。其创新点在于将复杂的非线性逆问题有效解耦，显著提升了模型对未见数据的泛化能力和在稀疏测量条件下的鲁棒性，克服了现有数据驱动方法的关键局限性。这对于推动电磁成像在实际应用中的成本效益和可行性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 电磁逆散射问题（EISP）在医学成像等应用中至关重要，但由于其固有的病态性和高度非线性而极具挑战性。现有的机器学习方法（如Img-Interiors）虽然有前景，但存在需要针对特定案例优化、缺乏对未见数据的泛化能力以及在稀疏发射器设置下失效等局限性。

**Method:** 本文从物理信息角度重新审视EISP，将其重新表述为两阶段的逆透射-散射过程，并发现感应电流是可泛化的中间表示，有效解耦了非线性散射过程和病态逆问题。在此基础上，提出了第一个可泛化的物理驱动EISP框架，包含一个电流估计器和一个介电常数求解器。电流估计器明确学习感应电流作为入射场和散射场之间的物理桥梁，而介电常数求解器直接从估计的感应电流计算相对介电常数。

**Result:** 广泛的实验表明，该方法在重建精度、泛化能力和鲁棒性方面优于现有最先进的方法。

**Conclusion:** 这项工作为电磁逆散射提供了一个全新的视角，代表着向经济高效的电磁成像实用解决方案迈出了重要一步。

> **ai_Abstract:** 本文针对电磁逆散射问题（EISP）中现有机器学习方法泛化能力差和稀疏发射器下失效的问题，提出了一个可泛化的物理驱动框架。通过将EISP重新表述为两阶段的逆透射-散射过程，并引入感应电流作为中间表示，该框架有效解耦了非线性散射与病态逆问题。所提出的方法包含一个电流估计器和一个介电常数求解器，实现了对未见数据的泛化预测和对稀疏发射器设置的鲁棒性。实验证明，该方法在重建精度、泛化性和鲁棒性上均优于现有技术，为电磁成像提供了新的解决方案。

> **摘要翻译:** 解决电磁逆散射问题（EISP）在医学成像等应用中至关重要，其目标是从散射电磁场中重建相对介电常数。这种逆过程本质上是病态且高度非线性的，使其极具挑战性。最近一种基于机器学习的方法Img-Interiors通过利用连续隐式函数显示出有前景的结果。然而，它需要针对特定案例进行优化，缺乏对未见数据的泛化能力，并且在稀疏发射器设置下（例如，只有一个发射器）会失效。为了解决这些局限性，我们从物理信息角度重新审视EISP，将其重新表述为两阶段的逆透射-散射过程。这种表述揭示了感应电流是一种可泛化的中间表示，有效地将非线性散射过程与病态逆问题解耦。基于这一见解，我们提出了第一个可泛化的物理驱动EISP框架，包括一个电流估计器和一个介电常数求解器，以端到端的方式工作。电流估计器明确地将感应电流学习为入射场和散射场之间的物理桥梁，而介电常数求解器直接从估计的感应电流计算相对介电常数。这种设计使得在未见数据上进行数据驱动训练和可泛化的前向预测相对介电常数成为可能，同时对发射器稀疏性保持强大的鲁棒性。广泛的实验表明，我们的方法在重建精度、泛化能力和鲁棒性方面优于现有最先进的方法。这项工作为电磁逆散射提供了根本性的新视角，代表着向经济高效的电磁成像实用解决方案迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [251] [Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features](https://arxiv.org/abs/2506.21046)
> *自监督视觉Transformer特征增强生成对抗性迁移能力*

*Shangbo Wu, Yu-an Tan, Ruinan Ma, Wencong Ma, Dehua Zhu, Yuanzhang Li* | **Category: cs.CV, cs.CR**

**Keywords:** 对抗样本, 黑盒迁移, 自监督学习, 视觉Transformer, 特征攻击

**Comment:** 14 pages, 9 figures, to appear in ICCV 2025

> **TL;DR:** 本文提出dSVA方法，利用自监督Vision Transformer（ViT）的特征（包括对比学习的全局结构特征和掩蔽图像建模的局部纹理特征），生成具有高黑盒迁移能力的对抗样本，并超越了现有先进方法。

**AI_Comments:** 创新点在于首次将自监督ViT特征（特别是CL和MIM的双重特征）应用于生成对抗样本以提升黑盒迁移性。此方法通过利用模型深层特征而非标签，为提高对抗样本的泛化能力提供了新思路，对提升AI模型的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有对抗样本生成方法多依赖监督学习特征，而自监督学习和Transformer架构的协同作用启发研究者探索自监督Vision Transformer（ViT）表示是否能提升对抗性迁移能力，旨在提高黑盒对抗样本的泛化能力。

**Method:** 提出了dSVA——一种生成式双自监督ViT特征攻击，利用对比学习（CL）的全局结构特征和掩蔽图像建模（MIM）的局部纹理特征。设计了一个新的生成式训练框架，包含一个生成器来创建黑盒对抗样本，并通过利用自监督ViT的联合特征和注意力机制来训练生成器。

**Result:** 研究发现，CL和MIM使ViT能够关注不同的特征倾向，当它们协同利用时，能带来出色的对抗泛化能力。通过扰乱自监督ViT提取的双重深度特征，实现了对各种架构模型的显著黑盒迁移能力，并超越了现有最先进的方法。

**Conclusion:** 利用自监督ViT（CL和MIM）的双重特征可以有效提升生成对抗样本的黑盒迁移能力，超越现有技术。

> **ai_Abstract:** 本文提出dSVA方法，通过利用自监督视觉Transformer（ViT）的特征（包括对比学习的全局特征和掩蔽图像建模的局部特征），生成具有高黑盒迁移能力的对抗样本。研究发现，结合这两种自监督特征能显著提升对抗样本的泛化能力，并在各种模型架构上实现了超越现有先进技术的黑盒迁移效果。

> **摘要翻译:** 深度神经网络（DNN）的能力来源于从提供的数据中提取和解释特征。通过利用DNN中的中间特征而不是依赖硬标签，我们能够制作出更有效泛化的对抗性扰动，从而提升黑盒迁移能力。在以往的工作中，这些特征普遍来源于监督学习。受自监督学习和Transformer架构之间卓越协同作用的启发，本文探讨了利用自监督视觉Transformer（ViT）表示是否能提高对抗性迁移能力。我们提出了dSVA——一种生成式双自监督ViT特征攻击，它利用了来自对比学习（CL）的全局结构特征和来自掩蔽图像建模（MIM）的局部纹理特征，这是ViT的自监督学习范式双核。我们设计了一种新颖的生成式训练框架，该框架包含一个生成器来创建黑盒对抗样本，以及通过利用自监督ViT的联合特征和注意力机制来训练生成器的策略。我们的研究结果表明，CL和MIM使ViT能够关注不同的特征倾向，当它们协同利用时，能带来极大的对抗泛化能力。通过扰乱自监督ViT提取的双重深度特征，我们获得了对各种架构模型显著的黑盒迁移能力，其性能优于现有最先进的方法。代码可在https://github.com/spencerwooo/dSVA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling](https://arxiv.org/abs/2506.20936)
> *PhysRig：一种用于逼真关节对象建模的可微分基于物理的蒙皮与骨骼绑定框架*

*Hao Zhang, Haolan Xu, Chun Feng, Varun Jampani, Narendra Ahuja* | **Category: cs.CV**

**Keywords:** 蒙皮, 骨骼绑定, 物理模拟, 可微分, 软体变形

**Comment:** Accepted by ICCV 2025

> **TL;DR:** PhysRig是一个可微分的基于物理的蒙皮和骨骼绑定框架，通过将骨骼嵌入可变形软体结构中来克服传统LBS的体积损失和不自然变形问题，生成更逼真、物理上更合理的结果。

**AI_Comments:** 这项工作通过引入物理模拟来改进蒙皮和骨骼绑定，解决了传统LBS的固有缺陷，特别是其在处理体积损失和弹性材料方面的局限性。其创新点在于将骨骼嵌入到可变形软体结构中并利用连续介质力学，同时保持了可微分性，这对于优化和学习至关重要。引入材料原型是另一个巧妙之处，有助于在保持表达性的同时减少计算复杂度。该框架在生成物理上更合理和逼真的动画方面具有重要意义，尤其适用于复杂生物体和弹性对象的建模。

<details>
  <summary>Details</summary>

**Motivation:** 现有的蒙皮和骨骼绑定方法主要依赖线性混合蒙皮（LBS），但LBS会导致体积损失和不自然的变形，并且无法有效模拟弹性材料，如软组织、毛发和柔性附件。

**Method:** 论文提出了PhysRig，一个可微分的基于物理的蒙皮和骨骼绑定框架。该方法将刚性骨骼嵌入到体积表示（例如四面体网格）中，并将其模拟为由动画骨骼驱动的可变形软体结构。它利用连续介质力学，将对象离散化为嵌入欧拉背景网格中的粒子，以确保对材料属性和骨骼运动的可微分性。此外，引入了材料原型以减少学习空间并保持高表达性。

**Result:** PhysRig在综合合成数据集上进行了评估，结果表明该方法始终优于传统的基于LBS的方法，生成了更逼真和物理上更合理的结果。它还展示了在姿态迁移任务中的适用性，突出了其在关节对象建模方面的多功能性。

**Conclusion:** PhysRig框架通过引入物理模拟克服了传统LBS的局限性，能够生成更逼真、物理上更合理的变形，并具有广泛的应用潜力，尤其是在姿态迁移等关节对象建模任务中。

> **ai_Abstract:** PhysRig是一种新颖的可微分物理蒙皮和骨骼绑定框架，旨在解决传统线性混合蒙皮（LBS）在处理体积损失、不自然变形和弹性材料方面的不足。通过将刚性骨骼嵌入到可变形的软体体积表示中并进行物理模拟，该框架利用连续介质力学和欧拉网格粒子离散化来实现对材料属性和骨骼运动的可微分性。此外，引入的材料原型优化了学习效率。实验证明，PhysRig在生成更逼真、物理上合理的变形方面优于LBS，并在姿态迁移等关节对象建模任务中展现出强大的多功能性。

> **摘要翻译:** 蒙皮和骨骼绑定是动画、关节对象重建、动作迁移和4D生成中的基本组成部分。现有方法主要依赖线性混合蒙皮（LBS），因为它简单且可微分。然而，LBS会引入体积损失和不自然变形等伪影，并且无法模拟软组织、毛发和柔性附件（例如，象鼻、耳朵和脂肪组织）等弹性材料。在这项工作中，我们提出了PhysRig：一个可微分的基于物理的蒙皮和骨骼绑定框架，通过将刚性骨骼嵌入到体积表示（例如四面体网格）中来克服这些限制，该网格被模拟为由动画骨骼驱动的可变形软体结构。我们的方法利用连续介质力学，并将对象离散化为嵌入欧拉背景网格中的粒子，以确保对材料属性和骨骼运动的可微分性。此外，我们引入了材料原型，显著减少了学习空间，同时保持了高表达性。为了评估我们的框架，我们使用来自Objaverse、The Amazing Animals Zoo和MixaMo的网格构建了一个全面的合成数据集，涵盖了不同的对象类别和运动模式。我们的方法始终优于传统的基于LBS的方法，生成了更逼真和物理上更合理的结果。此外，我们展示了我们框架在姿态迁移任务中的适用性，突出了其在关节对象建模方面的多功能性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [261] [AIR-VIEW: The Aviation Image Repository for Visibility Estimation of Weather, A Dataset and Benchmark](https://arxiv.org/abs/2506.20939)
> *AIR-VIEW：用于天气能见度估计的航空图像存储库，一个数据集和基准*

*Chad Mourning, Zhewei Wang, Justin Murray* | **Category: cs.CV**

**Keywords:** 航空气象, 能见度估计, 图像数据集, 机器学习, 基准测试

**Comment:** 5 pages, meant as citation for dataset

> **TL;DR:** 本文介绍了AIR-VIEW，一个用于航空天气能见度估计的新数据集和基准，以解决现有公开数据集的不足。

**AI_Comments:** 该论文通过创建AIR-VIEW数据集，解决了航空气象能见度估计领域一个关键的资源短缺问题，即缺乏适合机器学习的带标签图像数据。其创新性在于提供了一个大规模、多样化且与航空相关的图像数据集，并建立了评估模型性能的基准，这对于推动该领域低成本气象解决方案的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的公开数据集在航空相关距离、多样化地点和足够大的规模方面不足，无法用于监督学习进行大气能见度估计，而传统气象传感器成本高昂。

**Method:** 本文介绍了AIR-VIEW数据集，它是通过FAA气象相机网络一年多的数据收集活动形成的。同时，本文还提出了一个基准测试，将三种常用方法和一个通用基线模型在AIR-VIEW数据集和其他三个公开数据集上进行训练和测试，并与最近批准的ASTM标准进行比较。

**Result:** 本文提供了AIR-VIEW数据集，并建立了一个基准测试，展示了三种常用方法和一个通用基线模型在该数据集上的表现，并与ASTM标准进行了对比。具体性能结果未在摘要中提及。

**Conclusion:** AIR-VIEW数据集及其伴随的基准测试为航空气象能见度估计领域的机器学习研究提供了急需的资源，解决了现有数据集的不足，并为未来研究提供了评估标准。

> **ai_Abstract:** 本文推出了AIR-VIEW数据集，这是一个专为航空气象能见度估计设计的图像存储库，旨在解决当前缺乏高质量公开数据集的问题。该数据集汇集了FAA气象相机网络一年的数据。此外，论文还提出了一个基准测试，评估了三种常用方法和一个通用基线模型在AIR-VIEW及其他公开数据集上的性能，并与最新的ASTM标准进行了比较，为该领域的研究提供了重要的资源和评估框架。

> **摘要翻译:** 机器学习在航空气象领域是一个不断发展的研究方向，旨在为传统昂贵的气象传感器提供低成本替代方案；然而，在大气能见度估计领域，缺乏适用于航空相关距离、地点多样、规模足够大以用于监督学习的公开可用且带有能见度估计标签的数据集。本文介绍了一个新的数据集，它代表了美国联邦航空管理局（FAA）气象相机网络一年期数据收集活动的成果，非常适合此目的。我们还在应用三种常用方法和一个通用基线模型时，提供了一个基准测试，这些模型除了在我们的数据集上进行训练和测试外，还在三个公开可用数据集上进行训练和测试，并与最近批准的ASTM标准进行了比较。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [268] [Hierarchical Sub-action Tree for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.20947)
> *用于连续手语识别的分层子动作树*

*Dejie Yang, Zhu Xu, Xinjie Gao, Yang Liu* | **Category: cs.CV, cs.MM**

**Keywords:** 连续手语识别, 分层子动作树, 跨模态对齐, 词汇知识, 大型语言模型

**Comment:** 

> **TL;DR:** 本文提出了一种名为分层子动作树（HST）的新方法，通过结合大型语言模型的词汇知识来提高连续手语识别（CSLR）的性能，并有效对齐视觉和文本模态。

**AI_Comments:** 该论文的创新点在于提出了分层子动作树（HST）结构，并结合大型语言模型来更有效地利用词汇知识，解决CSLR中长期存在的训练数据不足和模态对齐问题。通过树结构降低计算复杂度的设计也具有实用价值。该方法为CSLR领域提供了一个新的、高效的跨模态学习范式。

<details>
  <summary>Details</summary>

**Motivation:** 连续手语识别（CSLR）面临数据集不足和标注不精确的问题，导致训练数据不足。现有跨模态解决方案未能充分利用词汇知识。

**Method:** 本文提出了分层子动作树（HST），称为HST-CSLR，以有效地将词汇知识与视觉表示学习相结合。通过从大型语言模型中引入词汇特定知识，构建HST进行文本信息表示，逐步对齐视觉和文本模态，并利用树结构降低计算复杂度。此外，还引入对比对齐增强以弥合两种模态之间的差距。

**Result:** 在PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture四个数据集上的实验证明了HST-CSLR的有效性。

**Conclusion:** 本文提出的HST-CSLR方法通过有效利用词汇知识和分层对齐策略，显著提升了连续手语识别的性能。

> **ai_Abstract:** 本文针对连续手语识别（CSLR）中数据不足和词汇知识利用不足的问题，提出了一种名为分层子动作树（HST）的新方法，即HST-CSLR。该方法通过整合大型语言模型的词汇知识，并构建HST来表示文本信息，实现视觉与文本模态的逐步对齐，并利用树结构降低计算复杂度。同时，引入对比对齐增强以弥合模态间差距。实验结果表明，HST-CSLR在多个数据集上表现出有效性。

> **摘要翻译:** 连续手语识别（CSLR）旨在将未剪辑的视频转录为通常为文本词汇的词汇。最近的研究表明，由于训练数据不足，大型数据集和精确标注的缺乏已成为CSLR的瓶颈。为解决此问题，一些工作开发了跨模态解决方案以对齐视觉和文本模态。然而，它们通常从词汇中提取文本特征，而未充分利用其知识。在本文中，我们提出了分层子动作树（Hierarchical Sub-action Tree，简称HST），称为HST-CSLR，以有效地将词汇知识与视觉表示学习相结合。通过整合来自大型语言模型的词汇特定知识，我们的方法更有效地利用了文本信息。具体来说，我们构建了一个用于文本信息表示的HST，逐步对齐视觉和文本模态，并受益于树结构以降低计算复杂度。此外，我们施加了对比对齐增强以弥合两种模态之间的差距。在四个数据集（PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture）上的实验证明了我们的HST-CSLR的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [274] [OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs](https://arxiv.org/abs/2506.20960)
> *OmniEval: 一个用于评估视觉、听觉和文本输入的万模态模型的基准*

*Yiman Zhang, Ziheng Luo, Qiangyu Yan, Wei He, Borui Jiang, Xinghao Chen, Kai Han* | **Category: cs.CV, cs.AI**

**Keywords:** 万模态模型, 评估基准, 视觉, 听觉, 文本

**Comment:** 

> **TL;DR:** OmniEval是一个新的基准测试，用于评估能处理视觉、听觉和文本输入的万模态模型，通过设计强调全模态协作、视频多样性和任务多样性与细粒度的评估任务。

**AI_Comments:** OmniEval的创新之处在于其强调“全模态协作”，这对于评估真正意义上的万模态模型至关重要，因为它迫使模型理解不同模态间的深层关联而非简单堆叠。同时，其任务的多样性和细粒度，特别是引入更精细的视频定位任务，提升了评估的全面性和深度。该基准有望推动万模态模型在复杂真实世界感知任务中的发展。

<details>
  <summary>Details</summary>

**Motivation:** 为了有效评估MiniCPM-O 2.6等万模态模型处理视觉、听觉和文本输入的能力，并弥补现有基准的不足。

**Method:** 本文介绍了OmniEval，一个用于评估万模态模型的基准。其特点包括：(i) 全模态协作：设计强调音频和视频强耦合的任务，要求模型有效利用所有模态的协同感知；(ii) 视频多样性：包含810个音视频同步视频（285个中文，525个英文）；(iii) 任务多样性和细粒度：包含2617个问答对（1412个开放式，1205个多项选择），分为3种主要任务类型和12种子任务类型，并引入了更细粒度的视频定位任务“Grounding”。随后，使用OmniEval对多个万模态模型进行了实验。

**Result:** 本文成功构建并推出了OmniEval基准，该基准具有全模态协作、视频多样性和任务多样性与细粒度等独特特征，并已用于对多种万模态模型进行实验评估。

**Conclusion:** OmniEval旨在为评估模型从所有模态上下文中构建和理解连贯性的能力提供一个平台。

> **ai_Abstract:** 本文提出了OmniEval，一个针对万模态模型（如MiniCPM-O 2.6）设计的综合评估基准，该基准支持视觉、听觉和文本输入。与现有基准不同，OmniEval强调全模态协作，包含多样化的音视频数据（810个视频，中英文皆有），并提供了细粒度的任务类型（2617个问答对，涵盖12种子任务，包括新的Grounding任务）。该基准旨在为评估模型理解和构建多模态上下文连贯性的能力提供平台。

> **摘要翻译:** 在本文中，我们介绍了OmniEval，一个用于评估MiniCPM-O 2.6等万模态模型的基准，该基准包含视觉、听觉和文本输入。与现有基准相比，我们的OmniEval具有几个显著特点：(i) 全模态协作：我们设计的评估任务强调音频和视频之间的强耦合，要求模型有效利用所有模态的协同感知；(ii) 视频多样性：OmniEval包含810个音视频同步视频，其中285个中文视频和525个英文视频；(iii) 任务的多样性和细粒度：OmniEval包含2617个问答对，包括1412个开放式问题和1205个多项选择问题。这些问题分为3种主要任务类型和12种子任务类型，以实现全面评估。其中，我们引入了一个更细粒度的视频定位任务，名为Grounding。然后，我们使用OmniEval对几个万模态模型进行了实验。我们希望OmniEval能够为评估从所有模态上下文中构建和理解连贯性的能力提供一个平台。代码和数据可在https://omnieval.github.io/找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [276] [Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval](https://arxiv.org/abs/2506.21538)
> *最大匹配的重要性：防止表示坍塌以实现鲁棒的跨模态检索*

*Hani Alomari, Anushka Sivakumar, Andrew Zhang, Chris Thomas* | **Category: cs.CV, cs.IR, cs.LG**

**Keywords:** 跨模态检索, 表示坍塌, 基于集合的嵌入, 最大匹配, 损失函数

**Comment:** Accepted at the 63rd Annual Meeting of the Association for
  Computational Linguistics (ACL 2025 Main)

> **TL;DR:** 本文提出了一种利用最大对分配相似度及两种新颖损失函数的新方法，以防止基于集合的跨模态检索中的表示坍塌，并取得了最先进的性能。

**AI_Comments:** 该论文的创新之处在于解决了基于集合的跨模态检索中“集合坍塌”和“稀疏监督”的具体问题，这些问题对于捕捉细微关系至关重要。最大对分配相似度和两种新颖损失函数（全局判别损失和集合内散度损失）的引入直接解决了这些问题，从而产生了鲁棒且多样化的表示。无需外部数据即可达到最先进的性能，这突显了其有效性和实际适用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单向量嵌入难以捕捉跨模态的细微和多样化关系。尽管基于集合的方法有潜力，但它们面临稀疏监督和集合坍塌的问题，限制了其有效性。

**Method:** 本文提出了最大对分配相似度（Maximal Pair Assignment Similarity）来优化嵌入集合之间的一对一匹配，以保留语义多样性。此外，还引入了全局判别损失（Global Discriminative Loss）来增强嵌入之间的区分度，以及集合内散度损失（Intra-Set Divergence Loss）来防止每个集合内部的坍塌。

**Result:** 该方法在MS-COCO和Flickr30k数据集上无需依赖外部数据就达到了最先进的性能。

**Conclusion:** 所提出的最大对分配相似度以及两种新的损失函数有效解决了基于集合的跨模态检索中的表示坍塌和稀疏监督问题，从而提高了性能。

> **ai_Abstract:** 本文旨在解决跨模态图像-文本检索中基于集合表示的局限性，特别是稀疏监督和表示坍塌问题。为此，它引入了最大对分配相似度，用于嵌入集合之间的一对一匹配，并提出了全局判别损失和集合内散度损失，以保持语义多样性并防止坍塌。该方法在标准基准测试中取得了最先进的性能。

> **摘要翻译:** 跨模态图像-文本检索具有挑战性，因为不同模态内容之间可能存在多种关联。传统方法学习单一向量嵌入来表示每个样本的语义，但难以捕捉跨模态存在的细微和多样化关系。基于集合的方法，即用多个嵌入表示每个样本，提供了一种有前景的替代方案，因为它们可以捕获更丰富和更多样化的关系。在本文中，我们表明，尽管基于集合的表示很有前景，但它们仍然面临稀疏监督和集合坍塌等问题，这限制了它们的有效性。为了解决这些挑战，我们提出了最大对分配相似度（Maximal Pair Assignment Similarity）来优化嵌入集合之间的一对一匹配，从而保留集合内的语义多样性。我们还引入了两个损失函数以进一步增强表示：全局判别损失（Global Discriminative Loss）以增强嵌入之间的区分度，以及集合内散度损失（Intra-Set Divergence Loss）以防止每个集合内部的坍塌。我们的方法在MS-COCO和Flickr30k数据集上无需依赖外部数据就达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [279] [Evidence-based diagnostic reasoning with multi-agent copilot for human pathology](https://arxiv.org/abs/2506.20964)
> *人类病理学中基于证据的诊断推理与多智能体副驾驶*

*Chengkuan Chen, Luca L. Weishaupt, Drew F. K. Williamson, Richard J. Chen, Tong Ding, Bowen Chen, Anurag Vaidya, Long Phi Le, Guillaume Jaume, Ming Y. Lu, Faisal Mahmood* | **Category: cs.CV, cs.AI**

**Keywords:** 病理学, 多模态大语言模型, 诊断推理, 全玻片图像, 人工智能

**Comment:** 

> **TL;DR:** 论文介绍了PathChat+，一个专门为病理学设计的新型多模态大语言模型（MLLM），以及SlideSeek，一个利用PathChat+进行自主诊断推理的多智能体AI系统，显著提升了病理诊断的准确性和可解释性。

**AI_Comments:** 本文的创新之处在于结合了大型语言模型和多智能体系统，解决了传统计算病理学模型在语言理解和自主推理方面的局限。PathChat+的大规模病理学特定数据训练是其性能优越的关键。SlideSeek的多智能体、迭代推理机制是其实现高精度诊断和可解释报告的核心。这对于提升数字病理诊断的自动化和辅助医生决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的计算病理模型主要侧重图像分析，缺乏自然语言指令和文本上下文整合。现有的多模态大语言模型（MLLMs）在计算病理学中存在训练数据不足、对多图像理解支持和评估不足以及缺乏自主诊断推理能力等局限性。

**Method:** 引入PathChat+，一个专门为人类病理学设计的新型多模态大语言模型（MLLM），该模型在超过100万个多样化的病理学特定指令样本和近550万个问答回合上进行训练。此外，提出了SlideSeek，一个利用PathChat+的、支持推理的多智能体AI系统，通过迭代、分层的诊断推理自主评估千兆像素的全玻片图像（WSIs）。

**Result:** PathChat+在各种病理学基准测试中，显著优于先前的PathChat副驾驶以及最先进的通用模型和其他病理学专用模型。SlideSeek在具有挑战性的开放式鉴别诊断基准DDxBench上达到了高准确率，并能够生成视觉上接地、人类可解释的摘要报告。

**Conclusion:** 论文成功开发了PathChat+和SlideSeek，显著克服了当前计算病理学中多模态模型的局限性，实现了基于证据的自主诊断推理，提升了病理诊断的准确性和可解释性，推动了数字病理学的发展。

> **ai_Abstract:** 本文针对计算病理学中传统模型和现有多模态大语言模型在语言整合、多图像理解及自主推理方面的不足，提出了PathChat+和SlideSeek。PathChat+是一个新型病理学专用MLLM，通过海量数据训练，在多个基准测试中表现优异。在此基础上，SlideSeek作为多智能体AI系统，能够对全玻片图像进行迭代、分层的自主诊断推理，并在鉴别诊断任务上取得高准确率，同时生成可解释的报告，显著推动了数字病理诊断的智能化和可靠性。

> **摘要翻译:** 病理学正在经历由全玻片成像和人工智能（AI）驱动的快速数字化转型。虽然基于深度学习的计算病理学取得了显著成功，但传统模型主要侧重于图像分析，而没有整合自然语言指令或丰富的文本上下文。当前计算病理学中的多模态大语言模型（MLLMs）面临局限性，包括训练数据不足、对多图像理解的支持和评估不足，以及缺乏自主诊断推理能力。为了解决这些局限性，我们引入了PathChat+，一个专门为人类病理学设计的新型MLLM，它在超过100万个多样化的病理学特定指令样本和近550万个问答回合上进行训练。在各种病理学基准测试中的广泛评估表明，PathChat+显著优于先前的PathChat副驾驶以及最先进的（SOTA）通用模型和其他病理学专用模型。此外，我们提出了SlideSeek，一个支持推理的多智能体AI系统，它利用PathChat+通过迭代、分层的诊断推理自主评估千兆像素的全玻片图像（WSIs），在具有挑战性的开放式鉴别诊断基准DDxBench上达到了高准确率，同时也能生成视觉上接地、人类可解释的摘要报告。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [282] [DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing](https://arxiv.org/abs/2506.20967)
> *DFVEdit：零样本视频编辑的条件增量流向量*

*Lingling Cai, Kang Zhao, Hangjie Yuan, Xiang Wang, Yingya Zhang, Kejie Huang* | **Category: cs.CV, cs.AI**

**Keywords:** 视频编辑, 视频扩散Transformer, 零样本, 流向量, 计算效率

**Comment:** Zero-shot video editing

> **TL;DR:** DFVEdit是一种针对视频扩散Transformer（Video DiTs）的高效零样本视频编辑方法，通过流变换直接在潜在空间操作，避免了注意力修改和微调，显著提升了推理速度和内存效率。

**AI_Comments:** DFVEdit的创新点在于其通过流变换直接在潜在空间进行操作，巧妙地避开了Video DiTs中计算量大的注意力修改和微调，从而实现了显著的效率提升。这种基于“流”的统一编辑和采样视角，以及CDFV、ICA和ER的结合，为零样本视频编辑提供了一个高效且高质量的新范式。其在速度和内存上的优势使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 将现有视频编辑方法直接应用于视频扩散Transformer（Video DiTs）会导致巨大的计算开销，原因在于其资源密集型的注意力修改或微调需求。

**Method:** 本文提出了DFVEdit，一种高效的零样本视频编辑方法，专为Video DiTs设计。DFVEdit通过流变换直接在干净的潜在空间上操作，从而无需进行注意力修改和微调。该方法将编辑和采样统一在连续流的视角下，并提出了条件增量流向量（CDFV）——一种理论上无偏的DFV估计。此外，DFVEdit还集成了隐式交叉注意力（ICA）引导和嵌入增强（ER）以进一步提升编辑质量。

**Result:** DFVEdit在实际效率方面表现出色，与基于注意力工程的编辑方法相比，在Video DiTs上实现了至少20倍的推理速度提升和85%的内存减少。广泛的定量和定性实验表明，DFVEdit可以无缝应用于流行的Video DiTs（如CogVideoX和Wan2.1），并在结构保真度、时空一致性和编辑质量方面达到了最先进的性能。

**Conclusion:** DFVEdit为视频扩散Transformer提供了一种高效、高质量的零样本视频编辑解决方案，显著提升了计算效率并保持了出色的编辑效果。

> **ai_Abstract:** DFVEdit是一种针对视频扩散Transformer（Video DiTs）的高效零样本视频编辑方法。它通过将编辑和采样统一在连续流视角下，并引入条件增量流向量（CDFV）以及隐式交叉注意力（ICA）和嵌入增强（ER），来避免传统方法中昂贵的注意力修改和微调。实验证明，DFVEdit在推理速度和内存使用上相比现有方法有显著提升（20倍加速，85%内存减少），并在多种Video DiTs上实现了卓越的编辑质量和一致性。

> **摘要翻译:** 视频扩散Transformer（Video DiTs）的出现标志着视频生成领域的一个里程碑。然而，由于资源密集型的注意力修改或微调，将现有视频编辑方法直接应用于Video DiTs通常会产生大量的计算开销。为了缓解这个问题，我们提出了DFVEdit，一种专为Video DiTs量身定制的高效零样本视频编辑方法。DFVEdit通过流变换直接在干净的潜在空间上操作，从而消除了对注意力修改和微调的需求。更具体地说，我们观察到编辑和采样可以在连续流的视角下统一。在此基础上，我们提出了条件增量流向量（CDFV）——一种理论上无偏的DFV估计——并集成了隐式交叉注意力（ICA）引导以及嵌入增强（ER）以进一步提高编辑质量。DFVEdit在实际效率方面表现出色，与基于注意力工程的编辑方法相比，在Video DiTs上提供了至少20倍的推理速度提升和85%的内存减少。广泛的定量和定性实验表明，DFVEdit可以无缝应用于流行的Video DiTs（例如CogVideoX和Wan2.1），在结构保真度、时空一致性和编辑质量方面达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [285] [From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging](https://arxiv.org/abs/2506.20977)
> *从摇篮到拐杖：一种高保真寿命人脸老化两阶段框架*

*Tao Liu, Dafeng Zhang, Gengchen Li, Shizhuo Liu, Yongqi Song, Senmao Li, Shiqi Yang, Boqian Li, Kai Wang, Yaxing Wang* | **Category: cs.CV, cs.AI**

**Keywords:** 人脸老化, 两阶段框架, 扩散模型, 身份保持, 年龄准确性

**Comment:** 30 pages, 12 figures

> **TL;DR:** 本文提出了一种名为Cradle2Cane的两阶段人脸老化框架，利用文本到图像扩散模型，通过平衡年龄准确性和身份保持，实现逼真且跨越整个生命周期的人脸老化。

**AI_Comments:** 这项工作通过创新的两阶段框架解决了人脸老化领域的一个核心挑战——年龄准确性与身份保持的权衡。利用扩散模型并引入自适应噪声注入和身份感知嵌入，展示了在复杂生成任务中精细控制不同属性的能力。其端到端训练和在极端情况下的表现潜力，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人脸老化方法在实现逼真、无缝的跨生命周期转换方面存在困难，尤其是在处理大年龄差距或极端头部姿势时。核心挑战在于平衡年龄准确性和身份保持，即“年龄-身份权衡”，大多数现有方法都牺牲其中一个来优先另一个。

**Method:** 本文提出了一种名为Cradle2Cane的两阶段人脸老化框架，该框架基于少量步骤的文本到图像（T2I）扩散模型。第一阶段通过引入自适应噪声注入（AdaNI）机制解决年龄准确性问题，该机制由年龄和性别提示作为文本条件引导，并通过调整噪声水平控制老化强度。第二阶段通过以两个身份感知嵌入（SVR-ArcFace和Rotate-CLIP）为条件，增强身份保持，同时保持年龄特定特征，对第一阶段的转换图像进行去噪。两个阶段共同进行端到端训练。

**Result:** 在CelebA-HQ测试数据集上进行的广泛实验，通过Face++和Qwen-VL协议评估，表明Cradle2Cane在年龄准确性和身份一致性方面优于现有的人脸老化方法。

**Conclusion:** 本文提出的Cradle2Cane两阶段框架有效解决了人脸老化中的年龄准确性与身份保持之间的权衡问题，实现了更逼真、更一致的跨生命周期人脸老化效果，并在实验中表现出超越现有方法的性能。

> **ai_Abstract:** 本文提出了一种名为Cradle2Cane的两阶段人脸老化框架，旨在解决现有方法在年龄准确性和身份保持之间权衡的难题。该框架基于文本到图像扩散模型，第一阶段利用自适应噪声注入（AdaNI）机制解决年龄准确性，第二阶段通过身份感知嵌入（SVR-ArcFace和Rotate-CLIP）增强身份保持。实验结果表明，Cradle2Cane在年龄准确性和身份一致性方面均优于现有方法，实现了高保真度的跨生命周期人脸老化。

> **摘要翻译:** 人脸老化在计算机视觉中已成为一项关键任务，应用范围从娱乐到医疗保健。然而，现有方法在实现整个生命周期中逼真无缝的转换方面存在困难，尤其是在处理大年龄差距或极端头部姿势时。核心挑战在于平衡年龄准确性和身份保持——我们称之为年龄-身份权衡。大多数先前的方法要么以牺牲身份一致性为代价优先进行年龄转换，反之亦然。在这项工作中，我们通过提出一个名为Cradle2Cane的两阶段人脸老化框架来解决这个问题，该框架基于少量步骤的文本到图像（T2I）扩散模型。第一阶段通过引入自适应噪声注入（AdaNI）机制来解决年龄准确性问题。该机制通过包含给定人物的年龄和性别提示作为文本条件来引导。此外，通过调整噪声水平，我们可以控制老化强度，同时允许在人脸转换方面具有更大的灵活性。然而，为了促进更强的年龄转换，此处对身份保持的保障较弱。在第二阶段，我们通过以两个身份感知嵌入（IDEmb）：SVR-ArcFace和Rotate-CLIP为条件，增强身份保持，同时保持年龄特定特征。此阶段允许对第一阶段转换后的图像进行去噪，确保更强的身份保持而不损害老化准确性。两个阶段都以端到端的方式联合训练。在CelebA-HQ测试数据集上进行的广泛实验，通过Face++和Qwen-VL协议评估，表明我们的Cradle2Cane在年龄准确性和身份一致性方面优于现有的人脸老化方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [287] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
> *MedPrompt：用于医学图像分割和分类的LLM-CNN融合与权重路由*

*Shadman Sobhan, Kazi Abrar Mahmud, Abduz Zami* | **Category: cs.CV, eess.SP**

**Keywords:** 医学图像分析, LLM, CNN, 图像分割, 图像分类

**Comment:** 40 pages, 8 Tables, 9 Figures

> **TL;DR:** MedPrompt是一个统一框架，结合LLM进行任务规划和CNN进行图像处理，通过权重路由实现可扩展的医学图像分割和分类，在19个数据集上表现出色。

**AI_Comments:** MedPrompt的创新之处在于其LLM-CNN融合架构，特别是通过LLM进行权重路由以实现任务的动态适应性，这极大地提高了系统的可扩展性和灵活性，解决了传统医学图像分析系统任务特异性的痛点。其在多个数据集和任务上的验证表明了其实用价值和近实时应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的医学图像分析系统通常是针对特定任务的，需要独立的模型进行分类和分割，并且缺乏支持用户定义工作流的灵活性。

**Method:** MedPrompt是一个统一框架，结合了少量样本提示的大型语言模型（Llama-4-17B）用于高级任务规划，以及模块化卷积神经网络（DeepFusionLab）用于低级图像处理。LLM解释用户指令并生成结构化输出，以动态路由特定任务的预训练权重。这种权重路由方法避免了在添加新任务时重新训练整个框架，只需特定任务的权重。

**Result:** MedPrompt在19个公共数据集上进行了评估，涵盖5种成像模式的12项任务。系统在解释和执行提示驱动指令方面达到了97%的端到端正确性，平均推理延迟为2.5秒。DeepFusionLab实现了具有竞争力的分割精度（例如，肺部Dice 0.9856）和强大的分类性能（结核病F1 0.9744）。

**Conclusion:** MedPrompt通过结合LLM的可解释性与模块化CNN的效率，实现了可扩展的、提示驱动的医学成像。

> **ai_Abstract:** MedPrompt是一个创新的统一框架，旨在解决医学图像分析中任务特异性和缺乏灵活性的问题。它通过融合大型语言模型（LLM）进行高级任务规划和卷积神经网络（CNN）进行低级图像处理，实现了医学图像的分割和分类。该系统利用LLM动态路由任务特定的预训练权重，从而避免了在添加新任务时进行全面的模型再训练，显著提高了可扩展性。在19个数据集上的评估显示，MedPrompt在指令解释和执行方面达到97%的端到端正确性，平均推理延迟为2.5秒，同时DeepFusionLab在分割和分类任务上均表现出强大的性能。

> **摘要翻译:** 当前的医学图像分析系统通常是针对特定任务的，需要独立的模型进行分类和分割，并且缺乏支持用户定义工作流的灵活性。为了解决这些挑战，我们引入了MedPrompt，这是一个统一框架，它结合了用于高级任务规划的少量样本提示大型语言模型（Llama-4-17B）和用于低级图像处理的模块化卷积神经网络（DeepFusionLab）。LLM解释用户指令并生成结构化输出，以动态路由特定任务的预训练权重。这种权重路由方法避免了在添加新任务时重新训练整个框架——只需要特定任务的权重，从而增强了可扩展性和部署能力。我们在19个公共数据集上评估了MedPrompt，涵盖了5种成像模式的12项任务。该系统在解释和执行提示驱动指令方面达到了97%的端到端正确性，平均推理延迟为2.5秒，使其适用于近实时应用。DeepFusionLab实现了具有竞争力的分割精度（例如，肺部Dice 0.9856）和强大的分类性能（结核病F1 0.9744）。总的来说，MedPrompt通过结合LLM的可解释性与模块化CNN的效率，实现了可扩展的、提示驱动的医学成像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [289] [3D Scene-Camera Representation with Joint Camera Photometric Optimization](https://arxiv.org/abs/2506.20979)
> *联合相机光度优化下的三维场景-相机表示*

*Weichen Dai, Kangcheng Ma, Jiaxin Wang, Kecen Pan, Yuhang Ming, Hua Zhang, Wanzeng Kong* | **Category: cs.CV**

**Keywords:** 三维场景表示, 相机光度优化, 光度畸变, 深度正则化, 场景辐射场

**Comment:** 

> **TL;DR:** 提出了一种联合相机光度优化的三维场景-相机表示方法，通过引入完整的相机光度模型和深度正则化，有效分离了相机畸变引入的非场景信息，从而在存在图像退化的情况下也能获得高质量的三维场景表示。

**AI_Comments:** 这篇论文通过将相机光度模型整合到三维场景表示的优化过程中，提供了一个创新的视角来解决图像畸变问题。其核心在于联合优化相机参数和场景表示，并引入深度正则化来提升鲁棒性，这对于在实际复杂成像条件下获得高质量三维重建具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有从多视角图像表示三维场景的方法，由于相机成像中固有的光度畸变，可能会将与场景无关的错误信息引入三维场景表示中，从而降低表示质量。

**Method:** 提出了一种新颖的联合相机光度优化的三维场景-相机表示方法。该方法引入了内部和外部光度模型，构建了一个完整的相机光度模型和对应的相机表示。通过同时优化相机表示的参数，有效分离了与场景无关的信息。此外，在光度参数优化过程中引入了深度正则化，以防止三维场景表示拟合与场景无关的信息。最终构建了一个包含场景辐射场和相机光度模型的完整映射。

**Result:** 实验结果表明，即使在存在晕影和污垢等成像退化条件下，所提出的方法也能实现高质量的三维场景表示。

**Conclusion:** 该论文提出了一种通过联合相机光度优化来提高三维场景表示质量的方法，成功地将相机引入的非场景信息与真实场景分离，并在存在成像退化的情况下取得了优异的表现。

> **ai_Abstract:** 本文提出了一种新颖的联合相机光度优化的三维场景-相机表示方法，旨在解决相机光度畸变对三维场景表示质量的影响。通过引入完整的内部和外部光度模型以及深度正则化，该方法能够有效地将相机引入的非场景信息与真实三维场景表示分离。实验证明，即使在存在图像退化（如晕影和污垢）的情况下，该方法也能生成高质量的三维场景表示。

> **摘要翻译:** 从多视角图像表示场景是计算机视觉中一个关键任务，具有广泛的应用。然而，相机成像中固有的光度畸变会显著降低图像质量。如果不考虑这些畸变，三维场景表示可能会无意中包含与场景无关的错误信息，从而降低表示质量。在本文中，我们提出了一种新颖的联合相机光度优化的三维场景-相机表示方法。通过引入内部和外部光度模型，我们提出了一个完整的光度模型和相应的相机表示。基于同时优化相机表示的参数，所提出的方法有效地将与场景无关的信息从三维场景表示中分离出来。此外，在光度参数优化过程中，我们引入了深度正则化，以防止三维场景表示拟合与场景无关的信息。通过将相机模型作为映射过程的一部分，所提出的方法构建了一个包含场景辐射场和相机光度模型的完整映射。实验结果表明，即使在晕影和污垢等成像退化条件下，所提出的方法也能实现高质量的三维场景表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [292] [GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction](https://arxiv.org/abs/2506.21121)
> *GoIRL：面向图的逆强化学习用于多模态轨迹预测*

*Muleilan Pei, Shaoshuai Shi, Lu Zhang, Peiliang Li, Shaojie Shen* | **Category: cs.CV, cs.RO**

**Keywords:** 逆强化学习, 轨迹预测, 多模态, 图神经网络, 自动驾驶

**Comment:** Accepted by ICML 2025

> **TL;DR:** GoIRL提出了一种基于逆强化学习（IRL）的框架，用于自动驾驶中的多模态轨迹预测，该框架结合了图特征聚合、分层轨迹生成和置信度融合，在Argoverse和nuScenes基准测试中取得了最先进的性能和更好的泛化能力。

**AI_Comments:** GoIRL的创新之处在于将逆强化学习引入多模态轨迹预测，并结合了图结构信息和分层生成策略。与传统的监督学习方法相比，其IRL范式能够更好地处理轨迹预测固有的不确定性和多模态性，并通过推断奖励分布来生成更合理的未来轨迹。其在大型基准测试上的优异表现和泛化能力证明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中周围代理的轨迹预测由于其固有的不确定性和潜在的多模态性而具有挑战性。现有的数据驱动方法主要依赖于监督学习，本文旨在提出一种新颖的方法来解决这一问题。

**Method:** 本文引入了一种新颖的面向图的逆强化学习（GoIRL）框架，这是一种基于IRL的预测器，配备了向量化的上下文表示。它开发了一个特征适配器，将车道图特征有效地聚合到网格空间中，并与最大熵IRL范式集成，以推断奖励分布并获得可以采样以诱导多个合理计划的策略。此外，该方法还实现了分层参数化轨迹生成器，带有细化模块以提高预测精度，并使用概率融合策略以提高预测置信度。

**Result:** GoIRL方法在大型Argoverse和nuScenes运动预测基准测试中不仅实现了最先进的性能，而且与现有监督模型相比，还表现出卓越的泛化能力。

**Conclusion:** GoIRL框架通过结合逆强化学习、图特征聚合和分层轨迹生成，有效解决了自动驾驶中的多模态轨迹预测挑战，并在主要基准测试中取得了优异的性能和泛化能力。

> **ai_Abstract:** 本文提出了一种名为GoIRL的面向图的逆强化学习框架，用于自动驾驶中的多模态轨迹预测。该框架通过特征适配器将车道图特征聚合到网格空间，并利用最大熵IRL推断奖励分布以生成多模态计划。在此基础上，采用分层轨迹生成器和概率融合策略来提高预测精度和置信度。实验证明，GoIRL在Argoverse和nuScenes基准测试中达到了最先进的性能，并展现出优异的泛化能力。

> **摘要翻译:** 周围代理的轨迹预测是自动驾驶中一项具有挑战性的任务，因为其固有的不确定性和潜在的多模态性。与主要依赖监督学习的现有数据驱动方法不同，本文引入了一种新颖的面向图的逆强化学习（GoIRL）框架，这是一种基于IRL的预测器，配备了向量化的上下文表示。我们开发了一个特征适配器，以有效地将车道图特征聚合到网格空间中，从而实现与最大熵IRL范式的无缝集成，以推断奖励分布并获得可采样以诱导多个合理计划的策略。此外，以采样的计划为条件，我们实现了一个带有细化模块的分层参数化轨迹生成器，以提高预测精度，并使用概率融合策略以提高预测置信度。广泛的实验结果表明，我们的方法不仅在大型Argoverse和nuScenes运动预测基准测试中取得了最先进的性能，而且与现有监督模型相比，还表现出卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [293] [Rethink Sparse Signals for Pose-guided Text-to-image Generation](https://arxiv.org/abs/2506.20983)
> *重新思考稀疏信号在姿态引导的文本到图像生成中的应用*

*Wenjie Xuan, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao* | **Category: cs.CV**

**Keywords:** 稀疏信号, 姿态引导, 文本到图像生成, ControlNet, OpenPose

**Comment:** accepted by ICCV 2025

> **TL;DR:** 本文提出了一种名为Spatial-Pose ControlNet（SP-Ctrl）的新方法，通过扩展OpenPose并引入关键点概念学习，使稀疏姿态信号在文本到图像生成中具有强大的可控性，其性能优于现有稀疏姿态方法，甚至能与密集信号方法媲美。

**AI_Comments:** 该论文的创新点在于重新审视并有效利用了之前被认为不足的稀疏姿态信号，通过提出SP-Ctrl解决了密集信号的局限性。其重要性在于为姿态引导的文本到图像生成提供了一种更简单、更灵活且性能卓越的解决方案，尤其在编辑便利性和跨物种生成方面具有优势。

<details>
  <summary>Details</summary>

**Motivation:** 当前研究倾向于使用密集信号（如深度、DensePose）为姿态引导的文本到图像生成提供详细的空间指导，但密集表示带来了编辑困难和与文本提示不一致的新挑战。这促使作者重新审视稀疏信号（如OpenPose）在姿态引导中的应用，因为它们具有简单性和形状无关性，且其潜力尚未被充分探索。

**Method:** 本文提出了一种新颖的Spatial-Pose ControlNet (SP-Ctrl)。具体而言，该方法将OpenPose扩展为可学习的空间表示，使关键点嵌入具有判别性和表达性。此外，它引入了关键点概念学习，鼓励关键点标记关注每个关键点的空间位置，从而改善姿态对齐。

**Result:** 在以动物和人类为中心的图像生成任务上的实验表明，SP-Ctrl在稀疏姿态引导下优于当前的空间可控T2I生成方法，甚至能与基于密集信号的方法性能相匹配。此外，SP-Ctrl在通过稀疏信号进行多样化和跨物种生成方面显示出良好的能力。

**Conclusion:** 通过重新利用稀疏姿态信号并提出SP-Ctrl，本文成功地解决了密集信号在姿态引导的文本到图像生成中面临的挑战，并展示了稀疏信号在提供强大可控性和实现高性能方面的潜力，甚至在多样化和跨物种生成中表现出色。

> **ai_Abstract:** 本文针对姿态引导的文本到图像生成中密集信号的挑战，提出了一种名为Spatial-Pose ControlNet (SP-Ctrl) 的新方法，旨在重新利用稀疏信号。SP-Ctrl通过将OpenPose扩展为可学习的空间表示并引入关键点概念学习，显著提升了稀疏姿态信号的可控性和对齐性。实验证明，该方法在稀疏姿态引导下表现优异，甚至能与密集信号方法相媲美，并在多样化和跨物种生成中展现出潜力。

> **摘要翻译:** 最近的工作倾向于使用密集信号（例如深度、DensePose）作为稀疏信号（例如OpenPose）的替代品，为姿态引导的文本到图像生成提供详细的空间指导。然而，密集表示带来了新的挑战，包括编辑困难和与文本提示潜在的不一致性。这一事实促使我们重新审视稀疏信号在姿态引导中的应用，因为它们具有简单性和形状无关性，并且其潜力尚未被充分探索。本文提出了一种新颖的空间姿态控制网络（Spatial-Pose ControlNet，SP-Ctrl），使稀疏信号在姿态引导的图像生成中具有强大的可控性。具体而言，我们将OpenPose扩展为一种可学习的空间表示，使关键点嵌入具有判别性和表达性。此外，我们引入了关键点概念学习，鼓励关键点标记关注每个关键点的空间位置，从而改善姿态对齐。在以动物和人类为中心的图像生成任务上的实验表明，我们的方法在稀疏姿态引导下优于最近的空间可控T2I生成方法，甚至与基于密集信号的方法性能相匹配。此外，SP-Ctrl通过稀疏信号在多样化和跨物种生成方面显示出良好的能力。代码将在https://github.com/DREAMXFAR/SP-Ctrl提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [295] [EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning](https://arxiv.org/abs/2506.20986)
> *EVA：专家混合语义变体对齐用于组合零样本学习*

*Xiao Zhang, Yongqiang Ma, Haodong Jing, Nanning Zheng* | **Category: cs.CV**

**Keywords:** 组合零样本学习, 专家混合, 语义变体对齐, 原语表示, 泛化能力

**Comment:** 

> **TL;DR:** 本文提出了EVA框架，通过专家混合和语义变体对齐，改进组合零样本学习中的原语表示和匹配，显著优于现有方法。

**AI_Comments:** 这篇论文的创新点在于提出了一个专家混合（Mixture-of-Experts）的框架来处理组合零样本学习中的语义变体问题，并引入了域专家自适应和语义变体对齐这两个关键机制。这种方法能够更精细地建模和对齐原语概念，从而解决了现有方法在处理复杂语义组合时的局限性。其在多个基准测试上取得的显著优异性能，表明了该方法在提升CZSL泛化能力方面的重要性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有组合零样本学习（CZSL）方法在原语特征提取和跨模态匹配方面存在不足。简单的组合-原型映射次优，且一对多的跨模态原语匹配忽略了相同状态或对象内的组合差异，限制了细粒度的图像-组合对齐。

**Method:** 本文提出了EVA框架，一个专家混合语义变体对齐框架，用于CZSL。具体来说，引入了域专家自适应，利用多个专家实现令牌感知学习和建模高质量的原语表示。此外，提出了语义变体对齐，以选择语义相关的表示进行图像-原语匹配，从而实现准确的组合泛化。

**Result:** EVA方法在三种流行的基准测试中，无论是在封闭世界还是开放世界设置下，都显著优于其他最先进的CZSL方法。

**Conclusion:** 提出的EVA框架通过专家混合和语义变体对齐，有效解决了CZSL中原语表示和匹配的挑战，并取得了优异的性能。

> **ai_Abstract:** 本文提出了一个名为EVA的专家混合语义变体对齐框架，旨在解决组合零样本学习（CZSL）中现有方法在原语特征提取和图像-组合对齐方面的不足。EVA通过引入域专家自适应来学习高质量的原语表示，并通过语义变体对齐来选择最相关的表示进行匹配。实验结果表明，EVA在多个基准测试中显著超越了当前最先进的CZSL方法。

> **摘要翻译:** 组合零样本学习（CZSL）研究了基于学习到的原始概念识别未知状态-对象对的组合泛化能力。现有CZSL方法通常通过简单的组合-原型映射来推导原始特征，这对于可以分为不同语义子集的个体集合来说是次优的。此外，一对多的跨模态原始匹配忽略了相同状态或对象内的组合差异，限制了细粒度的图像-组合对齐。在本研究中，我们提出了EVA，一个用于CZSL的专家混合语义变体对齐框架。具体来说，我们引入了域专家自适应，利用多个专家实现令牌感知学习和建模高质量的原始表示。为了实现准确的组合泛化，我们进一步提出了语义变体对齐，以选择语义相关的表示进行图像-原始匹配。我们的方法在封闭世界和开放世界设置下，在三个流行的基准测试中显著优于其他最先进的CZSL方法，证明了所提出见解的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [298] [Segment Anything in Pathology Images with Natural Language](https://arxiv.org/abs/2506.20988)
> *使用自然语言在病理图像中分割一切*

*Zhixuan Chen, Junlin Hou, Liqi Lin, Yihui Wang, Yequan Bie, Xi Wang, Yanning Zhou, Ronald Cheong Kin Chan, Hao Chen* | **Category: cs.CV, cs.AI**

**Keywords:** 病理图像分割, 自然语言, 基础模型, 文本提示, 可解释AI

**Comment:** 

> **TL;DR:** PathSegmentor是首个用于病理图像分割的文本提示基础模型，它通过自然语言提示实现语义分割，性能优于现有方法，并提升了诊断模型的可解释性。

**AI_Comments:** 这项工作具有显著的创新性，首次将文本提示基础模型引入病理图像分割领域，极大地简化了分割操作，并提高了效率。其构建的大规模PathSeg数据集也为该领域提供了宝贵的资源。PathSegmentor不仅提升了分割性能，更重要的是，它通过增强诊断模型的可解释性，为精准肿瘤学中的AI应用提供了更可靠的依据，具有重要的临床转化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的病理图像分割方法在临床应用中面临标注数据有限和类别定义受限的重大挑战。

**Method:** 提出了PathSegmentor，这是首个专为病理图像设计的文本提示分割基础模型。同时引入了PathSeg，一个最大、最全面的病理分割数据集，包含来自17个公共来源的27.5万个图像-掩码-标签三元组，涵盖160个不同类别。PathSegmentor允许用户使用自然语言提示进行语义分割，无需繁琐的空间输入（如点或框）。

**Result:** PathSegmentor在准确性和适用性方面优于专用模型，并保持紧凑架构。在Dice分数上分别显著超越现有空间提示和文本提示模型0.145和0.429，在分割复杂结构和泛化到外部数据集方面表现出强大的鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和影像生物标志物发现增强了诊断模型的可解释性，为病理学家提供循证支持。

**Conclusion:** 这项工作推动了精准肿瘤学中可解释人工智能的发展。

> **ai_Abstract:** 本研究提出PathSegmentor，首个专为病理图像设计的文本提示分割基础模型，旨在解决现有病理图像分割方法在临床应用中面临的标注数据有限和类别定义受限的挑战。该模型结合了PathSeg数据集，一个包含160个类别、27.5万个图像-掩码-标签三元组的大型综合数据集，允许用户通过自然语言提示进行语义分割，无需空间输入。实验证明，PathSegmentor在准确性、适用性和泛化能力上均显著优于现有模型，并能增强诊断模型的可解释性，为临床决策提供支持。

> **摘要翻译:** 病理图像分割在计算病理学中对于分析与癌症诊断和预后相关的组织学特征至关重要。然而，由于标注数据有限和类别定义受限，当前方法在临床应用中面临重大挑战。为了解决这些限制，我们提出了PathSegmentor，这是首个专为病理图像设计的文本提示分割基础模型。我们还引入了PathSeg，这是最大、最全面的病理分割数据集，其构建自17个公共来源，包含160个不同类别的27.5万个图像-掩码-标签三元组。通过PathSegmentor，用户可以使用自然语言提示执行语义分割，无需费力的空间输入，例如点或框。大量实验表明，PathSegmentor以更高的准确性和更广泛的适用性优于专用模型，同时保持紧凑的架构。它在总体Dice分数上分别显著超越现有空间提示和文本提示模型0.145和0.429，在分割复杂结构和泛化到外部数据集方面显示出强大的鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和影像生物标志物发现增强了诊断模型的可解释性，为病理学家提供循证支持，从而辅助临床决策。这项工作推动了精准肿瘤学中可解释人工智能的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [300] [TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation](https://arxiv.org/abs/2506.20991)
> *TSDASeg：一种用于交互式点云分割的直接对齐两阶段模型*

*Chade Li, Pengju Zhang, Yihong Wu* | **Category: cs.CV**

**Keywords:** 交互式点云分割, 3D-文本对齐, 两阶段模型, 记忆模块, 视觉-语言模型

**Comment:** 

> **TL;DR:** TSDASeg提出了一种两阶段模型，通过直接跨模态对齐和记忆模块，解决了现有方法在交互式点云分割中缺乏3D-文本直接对齐的问题，并在多个数据集上达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了直接的3D-文本对齐机制以及一个动态记忆模块，以解决现有方法在交互式点云分割中缺乏局部特征与文本上下文关联的问题。这种方法通过显式对齐和记忆库来提升跨模态理解和结果的一致性，对于推动3D视觉-语言模型在实际点云处理任务中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D视觉-语言模型在点级别任务（如分割）中表现不佳，因为它们缺少直接的3D-文本对齐，这限制了它们将局部3D特征与文本上下文关联起来的能力。

**Method:** 我们提出了TSDASeg，一个结合了直接跨模态对齐模块和记忆模块的两阶段模型。直接跨模态对齐模块用于建立3D点云与文本/2D图像数据之间的显式对齐。记忆模块使用多个专门的记忆库分别存储文本特征、视觉特征及其跨模态对应映射。这些记忆库通过自注意力和交叉注意力机制动态利用，根据先前存储的数据更新场景特定特征，以解决不同场景中交互式分割结果的不一致性。

**Result:** 在多个3D指令、参考和语义分割数据集上进行的实验表明，所提出的方法实现了最先进的性能。

**Conclusion:** TSDASeg通过引入直接跨模态对齐和动态记忆模块，有效解决了交互式点云分割中3D-文本对齐不足的问题，并在各项任务中取得了领先的性能。

> **ai_Abstract:** TSDASeg是一种用于交互式点云分割的两阶段模型，旨在解决现有方法在3D-文本直接对齐方面的不足。该模型引入了直接跨模态对齐模块，以建立3D点云与文本/2D图像数据的显式关联，并设计了一个记忆模块，通过多记忆库和注意力机制动态更新场景特征，从而提高分割结果的一致性。实验证明，TSDASeg在多种3D分割任务上均取得了最先进的性能。

> **摘要翻译:** 3D视觉-语言模型（VLMs）的快速发展激发了人们对交互式点云处理任务的浓厚兴趣，尤其是在实际应用中。然而，现有方法在点级别任务（如分割）中往往表现不佳，原因在于缺少直接的3D-文本对齐，这限制了它们将局部3D特征与文本上下文关联的能力。为了解决这个问题，我们提出了TSDASeg，一个结合了直接跨模态对齐模块和记忆模块的两阶段模型，用于交互式点云分割。我们引入了直接跨模态对齐模块，以在3D点云和文本/2D图像数据之间建立显式对齐。在记忆模块内部，我们采用了多个专用记忆库，分别存储文本特征、视觉特征及其跨模态对应映射。这些记忆库通过自注意力和交叉注意力机制动态利用，根据先前存储的数据更新场景特定特征，从而有效解决了不同场景中交互式分割结果的不一致性。在多个3D指令、参考和语义分割数据集上进行的实验表明，所提出的方法实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [302] [Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping](https://arxiv.org/abs/2506.21234)
> *实时ESFP：估计、平滑、滤波和姿态映射*

*Qifei Cui, Yuang Zhou, Ruichen Deng* | **Category: cs.CV, cs.RO**

**Keywords:** 实时姿态估计, 机器人控制, 单目视频, 运动映射, Transformer

**Comment:** 

> **TL;DR:** ESFP是一个将单目RGB视频转换为低成本四自由度桌面机械臂可执行关节轨迹的端到端管道，包含估计、平滑、滤波和姿态映射四个模块。

**AI_Comments:** 这篇论文提出了一种新颖的端到端管道ESFP，用于将人体运动实时映射到低成本机械臂。其创新点在于引入了HPSTM Transformer进行平滑处理，通过结合时间上下文、可微分正向运动学解码器以及对骨骼长度和解剖合理性的强制约束，显著提高了姿态估计的质量和鲁棒性，同时提供了不确定性估计用于后续滤波。这对于低成本人机交互和自动化任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在开发一个端到端管道，将单目RGB视频转换为低成本四自由度桌面机械臂的可执行关节轨迹，实现从视频到机械臂控制的自动化。

**Method:** 论文提出了ESFP管道，包含四个顺序模块：1. 估计: 使用ROMP将每一帧视频提升为24个关节的3D骨架。2. 平滑: 引入HPSTM（一种带有自注意力机制的序列到序列Transformer），结合长时间范围的时间上下文和可微分的正向运动学解码器，以确保骨骼长度恒定和解剖学合理性，同时共同预测关节均值和完整协方差。3. 滤波: 根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，以抑制残余噪声。4. 姿态映射: 一个几何重定向层将肩-肘-腕三元组转换为uArm的极坐标工作空间，同时保留腕部方向。

**Result:** 论文展示了ESFP管道，能够将单目RGB视频转换为用于低成本4自由度桌面机械臂的可执行关节轨迹。该管道通过其四个模块（估计、平滑、滤波和姿态映射）实现了人体姿态到机械臂运动的实时转换。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** ESFP是一个创新的端到端系统，它能够将单目RGB视频实时转换为低成本四自由度桌面机械臂的可执行关节轨迹。该系统由四个关键模块组成：首先，利用ROMP进行3D骨架估计；其次，通过提出的HPSTM（一个结合了时间上下文和可微分正向运动学解码器的Transformer）对关节轨迹进行平滑处理，确保解剖学合理性并预测不确定性；接着，利用HPSTM的不确定性进行方差加权滤波以抑制噪声；最后，通过几何重定向层将人体姿态映射到机械臂的工作空间，同时保持腕部方向。

> **摘要翻译:** 这篇论文提出了ESFP，一个将单目RGB视频转换为低成本四自由度桌面机械臂可执行关节轨迹的端到端管道。ESFP包含四个顺序模块。(1) 估计：ROMP将每一帧提升为24个关节的3D骨架。(2) 平滑：所提出的HPSTM——一个带有自注意力机制的序列到序列Transformer——结合了长范围时间上下文和可微分正向运动学解码器，强制执行恒定的骨骼长度和解剖学合理性，同时共同预测关节均值和完整协方差。(3) 滤波：根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，以抑制残余噪声。(4) 姿态映射：一个几何重定向层将肩-肘-腕三元组转换为uArm的极坐标工作空间，同时保留腕部方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [305] [DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting](https://arxiv.org/abs/2506.20998)
> *DBMovi-GS：基于稀疏控制高斯泼溅的模糊单目视频动态视图合成*

*Yeon-Ji Song, Jaein Kim, Byung-Ju Kim, Byoung-Tak Zhang* | **Category: cs.CV**

**Keywords:** 动态视图合成, 模糊单目视频, 高斯泼溅, 3D重建, DBMovi-GS

**Comment:** CVPRW 2025, Neural Fields Beyond Conventional Cameras

> **TL;DR:** DBMovi-GS通过稀疏控制高斯泼溅技术，解决了从模糊单目视频合成动态场景新视图的挑战，提高了真实世界动态场景下的视觉质量。

**AI_Comments:** DBMovi-GS的创新之处在于其首次有效地解决了从模糊单目视频进行动态视图合成的难题，特别是通过引入稀疏控制高斯泼溅来处理运动模糊和动态场景。这对于在非理想真实世界条件下进行3D重建和视图合成具有重要意义，克服了现有方法对高分辨率和静态场景的限制。

<details>
  <summary>Details</summary>

**Motivation:** 现有新视图合成方法难以从模糊单目视频中合成动态场景，因为它们依赖高分辨率图像或对静态几何和刚性场景的强假设，导致在动态物体和相机运动的真实环境中表现不佳。

**Method:** 本文提出了DBMovi-GS，一种通过稀疏控制高斯泼溅技术，从模糊单目视频进行动态视图合成的方法。该模型生成密集的3D高斯，从模糊视频中恢复清晰度，并重建受动态运动变化影响的场景的详细3D几何。

**Result:** 模型在动态模糊场景下的新视图合成中实现了鲁棒性能，并在模糊单目视频输入下的真实感新视图合成方面树立了新基准。

**Conclusion:** DBMovi-GS成功地解决了从模糊单目视频进行动态视图合成的挑战，通过其创新的方法提高了视觉质量和鲁棒性，并为该领域设定了新的性能标准。

> **ai_Abstract:** 本文提出了DBMovi-GS，一种利用稀疏控制高斯泼溅技术，从模糊单目视频合成动态场景新视图的方法。针对现有方法在动态、模糊真实环境中表现不佳的问题，DBMovi-GS能够生成密集的3D高斯，恢复视频清晰度并重建受动态影响的场景3D几何，从而实现鲁棒的动态新视图合成，并为该领域设定了新基准。

> **摘要翻译:** 新视图合成是一项从未见过的视角生成场景的任务；然而，从模糊单目视频合成动态场景仍然是一个尚未有效解决的挑战。现有新视图合成方法通常受限于它们对高分辨率图像的依赖，或对静态几何和刚性场景的强假设。因此，它们的方法在具有动态物体和相机运动的真实世界环境中缺乏鲁棒性，导致不稳定和视觉保真度下降。为了解决这个问题，我们提出了DBMovi-GS（Motion-aware Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting），这是一种旨在从模糊单目视频进行动态视图合成的方法。我们的模型生成密集的3D高斯，从模糊视频中恢复清晰度并重建受动态运动变化影响的场景的详细3D几何。我们的模型在动态模糊场景下的新视图合成中实现了鲁棒性能，并在模糊单目视频输入下的真实感新视图合成方面树立了新基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [308] [ToosiCubix: Monocular 3D Cuboid Labeling via Vehicle Part Annotations](https://arxiv.org/abs/2506.21358)
> *ToosiCubix：通过车辆部件标注进行单目3D长方体标注*

*Behrooz Nasihatkon, Hossein Resani, Amirreza Mehrzadian* | **Category: cs.CV, cs.RO**

**Keywords:** 单目3D标注, 长方体标注, 车辆部件, 成本效益, 可扩展性

**Comment:** 

> **TL;DR:** ToosiCubix 是一种新的方法，仅使用单目图像和少量用户点击即可进行车辆3D长方体标注，提供了一种经济高效且可扩展的替代方案，以应对现有昂贵设置的局限性。

**AI_Comments:** ToosiCubix 的主要创新在于通过仅使用单目图像和少量用户交互，显著降低了3D长方体标注的成本和复杂性，使其适用于大规模数据收集和现有数据集的增强。其结合PnP和最小二乘优化以及概率尺寸先验来解决单目视觉固有的尺度和深度模糊性是其方法的精妙之处。这对于自动驾驶和计算机视觉领域的数据标注具有重要意义，因为它提供了一个更易于部署和扩展的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的车辆3D长方体标注方法依赖于昂贵且经过仔细校准的相机-LiDAR或立体设置，这限制了它们进行大规模数据采集的可及性。

**Method:** 本文引入了 ToosiCubix，一种仅使用单目图像和相机内参标注真实长方体的方法。该方法每个车辆仅需约10次用户点击，通过标注车辆不同部件的特定特征（例如车轮、汽车徽章、对称性），精确估计车辆的位置、方向和尺寸（8自由度，存在尺度模糊）。几何约束被表述为一个优化问题，通过坐标下降策略，在PnP（Perspective-n-Points）和最小二乘子问题之间交替求解。为了处理尺度和未观察到的尺寸等常见模糊性，该方法结合了概率尺寸先验，实现了9自由度的长方体放置。

**Result:** 通过在KITTI和Cityscapes3D数据集上验证，该方法为高质量3D长方体标注提供了一种经济高效且可扩展的解决方案。

**Conclusion:** ToosiCubix 提供了一种经济高效且可扩展的解决方案，用于高质量的3D长方体标注，仅需单目图像和少量用户交互即可实现。

> **ai_Abstract:** ToosiCubix 是一种创新的单目3D长方体标注方法，旨在克服现有基于昂贵多传感器设置的局限性。该方法仅需单目图像和相机内参，通过用户对车辆特定部件的少量点击（约10次/车），结合几何约束优化（PnP和最小二乘交替）和概率尺寸先验，实现车辆位置、方向和尺寸的精确估计（8或9自由度）。实验证明，ToosiCubix 在KITTI和Cityscapes3D数据集上表现出色，提供了一种经济高效且可扩展的高质量3D标注方案。

> **摘要翻译:** 许多现有的车辆3D长方体标注方法依赖于昂贵且经过仔细校准的相机-LiDAR或立体设置，这限制了它们进行大规模数据采集的可及性。我们引入了 ToosiCubix，一种简单而强大的方法，仅使用单目图像和相机内参即可标注真实长方体。我们的方法每个车辆仅需约10次用户点击，这使得它对于向最初未配备专业设备收集的现有数据集添加3D标注非常实用。通过标注车辆不同部件的特定特征（例如车轮、汽车徽章、对称性），我们准确估计了每个车辆的位置、方向和尺寸，但存在尺度模糊（8自由度）。几何约束被表述为一个优化问题，我们使用坐标下降策略求解，在PnP（Perspective-n-Points）和最小二乘子问题之间交替。为了处理尺度和未观察到的尺寸等常见模糊性，我们结合了概率尺寸先验，实现了9自由度的长方体放置。我们在KITTI和Cityscapes3D数据集上验证了我们的标注，表明我们的方法为高质量3D长方体标注提供了一种经济高效且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [309] [Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology](https://arxiv.org/abs/2506.21001)
> *风格对齐的图像合成用于细胞病理学中异常细胞的鲁棒检测*

*Qiuyi Qi, Xin Li, Ming Kong, Zikang Xu, Bingdi Chen, Qiang Zhu, S Kevin Zhou* | **Category: cs.CV**

**Keywords:** 细胞病理学, 异常细胞检测, 图像合成, 风格对齐, 数据增强

**Comment:** MIDL 2025 Oral

> **TL;DR:** 本文提出SAIC方法，通过合成高质量且风格一致的病理图像，以解决细胞病理学中异常细胞检测面临的数据挑战，显著提升了检测模型的性能和鲁棒性。

**AI_Comments:** 这篇论文通过提出SAIC方法，巧妙地解决了细胞病理学图像检测中数据稀缺和风格不一致的关键问题。其创新点在于结合了属性指导、高频特征重建和视觉-语言模型进行图像合成，有效提升了模型的鲁棒性和泛化能力，特别是在医疗图像分析这种对数据质量和多样性要求极高的领域，具有重要的实际应用价值。该方法无需额外训练的特点也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 细胞病理学中异常细胞的鲁棒检测面临高质量标注缺乏、数据分布长尾和染色风格不一致等挑战，这些都阻碍了神经网络模型的有效训练。

**Method:** 本文提出了一种风格对齐的图像合成（SAIC）方法。该方法无需额外训练，首先根据属性指导从异常细胞库中选择合适的候选细胞；然后利用高频特征重建技术实现异常细胞与病理背景的风格对齐和高保真合成；最后引入大型视觉-语言模型来过滤高质量的合成图像。

**Result:** 实验结果表明，结合SAIC合成的图像能有效提升尾部类别和风格的异常细胞检测性能和鲁棒性，从而提高整体检测性能。全面的质量评估也进一步证实了SAIC在临床应用场景中的泛化性和实用性。

**Conclusion:** SAIC方法通过合成高保真、风格对齐的图像，有效解决了细胞病理学中异常细胞检测面临的数据稀缺和风格不一致等挑战，显著提高了检测模型的性能和鲁棒性，并具有良好的临床应用前景。

> **ai_Abstract:** 本文针对细胞病理学中异常细胞检测面临的标注缺乏、长尾分布和风格不一致等挑战，提出了一种风格对齐的图像合成（SAIC）方法。SAIC通过属性指导选择细胞、高频特征重建实现风格对齐的高保真合成，并利用大型视觉-语言模型筛选高质量图像。实验证明，SAIC合成的图像能有效提升异常细胞检测模型在尾部类别和不同风格上的性能和鲁棒性，并具备在临床应用中的泛化性和实用性。

> **摘要翻译:** 细胞病理学中异常细胞的鲁棒检测面临着高质量标注缺乏、数据分布长尾和染色风格不一致等挑战，这些都对训练神经网络构成了重大障碍。本文提出了一种风格对齐的图像合成（SAIC）方法，该方法合成高保真且风格保留的病理图像，以增强检测模型的有效性和鲁棒性。SAIC无需额外训练，首先根据属性指导从异常细胞库中选择合适的候选细胞。然后，它采用高频特征重建技术，实现异常细胞与病理背景的风格对齐和高保真合成。最后，引入大型视觉-语言模型来过滤高质量的合成图像。实验结果表明，结合SAIC合成的图像能有效提升尾部类别和风格的异常细胞检测性能和鲁棒性，从而提高整体检测性能。全面的质量评估进一步证实了SAIC在临床应用场景中的泛化性和实用性。我们的代码将在https://github.com/Joey-Qi/SAIC发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [311] [EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting](https://arxiv.org/abs/2506.21420)
> *内窥镜流式SLAM：基于流约束高斯溅射的实时内窥镜SLAM*

*Taoyu Wu, Yiyi Miao, Zhuoxiao Li, Haocheng Zhao, Kang Dang, Jionglong Su, Limin Yu, Haoang Li* | **Category: cs.CV, cs.RO**

**Keywords:** 内窥镜SLAM, 3DGS, 光流, 深度正则化, 实时重建

**Comment:** 

> **TL;DR:** 本文提出EndoFlow-SLAM，一种新的内窥镜SLAM方法，通过引入光流损失和深度正则化来解决3DGS-SLAM在内窥镜场景中的光度不一致和动态运动问题，并在新视角合成和姿态估计方面优于现有方法。

**AI_Comments:** 该论文的创新点在于将3DGS与光流约束和深度正则化相结合，以解决内窥镜SLAM中特有的光度不一致和动态运动问题。这对于提升手术场景下的实时三维重建和可视化具有重要意义，其结合几何约束来增强基于外观的3DGS是值得关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在内窥镜等手术场景中，高效的三维重建和实时可视化至关重要。现有的基于3DGS的SLAM方法主要依赖外观约束，但在内窥镜场景中面临非朗伯表面导致的光度不一致和呼吸引起的动态运动等挑战，这些问题影响了SLAM系统的性能。

**Method:** 该方法引入光流损失作为几何约束，以有效约束场景的三维结构和相机运动。同时，提出深度正则化策略来减轻光度不一致问题，并确保3DGS深度渲染在内窥镜场景中的有效性。此外，通过关注渲染质量欠佳的关键帧对应的视点，改进了3DGS细化策略，以改善场景表示和渲染结果。

**Result:** 在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，该方法在新颖视图合成和姿态估计方面均优于现有最先进方法，在静态和动态手术场景中均表现出高性能。

**Conclusion:** EndoFlow-SLAM通过引入光流约束和深度正则化，有效解决了内窥镜场景中3DGS-SLAM面临的光度不一致和动态运动等挑战，并在三维重建和姿态估计方面取得了卓越的性能，从而提升了内窥镜手术的实时三维可视化能力。

> **ai_Abstract:** 本文提出EndoFlow-SLAM，一种结合3D Gaussian Splatting技术用于内窥镜手术的实时SLAM系统。针对内窥镜场景中非朗伯表面导致的光度不一致和呼吸引起的动态运动等挑战，该方法创新性地引入光流损失作为几何约束，并提出深度正则化策略。此外，通过优化3DGS细化策略，提升了场景表示质量。实验结果表明，EndoFlow-SLAM在新视角合成和姿态估计方面均超越现有最先进方法，在静态和动态手术场景中均展现出卓越性能。

> **摘要翻译:** 高效的三维重建和实时可视化在内窥镜等手术场景中至关重要。近年来，三维高斯溅射（3DGS）在高效三维重建和渲染方面表现出卓越的性能。大多数基于3DGS的同步定位与建图（SLAM）方法仅依赖于外观约束来优化3DGS和相机姿态。然而，在内窥镜场景中，挑战包括非朗伯表面引起的光度不一致以及呼吸导致的动态运动影响SLAM系统的性能。为了解决这些问题，我们额外引入了光流损失作为几何约束，它有效地约束了场景的三维结构和相机运动。此外，我们提出了一种深度正则化策略，以减轻光度不一致问题并确保3DGS深度渲染在内窥镜场景中的有效性。此外，为了改善SLAM系统中的场景表示，我们通过关注对应于渲染质量欠佳关键帧的视点来改进3DGS细化策略，从而获得更好的渲染结果。在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，我们的方法在新颖视图合成和姿态估计方面优于现有最先进方法，在静态和动态手术场景中均表现出高性能。源代码将在论文接受后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [312] [Inverse Scene Text Removal](https://arxiv.org/abs/2506.21002)
> *逆向场景文本移除*

*Takumi Yoshimatsu, Shumpei Takezaki, Seiichi Uchida* | **Category: cs.CV**

**Keywords:** 逆向场景文本移除, 场景文本移除, 文本检测, 图像修复, 滥用检测

**Comment:** 17 pages

> **TL;DR:** 该论文研究逆向场景文本移除 (ISTR)，旨在检测图像是否经过STR处理并定位被移除的文本区域，以应对STR的滥用风险。

**AI_Comments:** 这篇论文提出了一种新颖且重要的研究方向——逆向场景文本移除（ISTR），它从“防御”的角度审视了场景文本移除（STR）技术的潜在滥用问题。其创新点在于将检测STR处理和定位被移除文本区域作为核心任务，并验证了其可行性。这对于提高图像内容安全性和规范AI技术使用具有重要意义。同时，尝试恢复文本内容也为未来的研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 场景文本移除 (STR) 技术虽然通过神经网络和合成数据取得了进展，但其滥用风险也随之增加。因此，本研究的动机是开发一种能够分析STR处理过的图像，并检测图像是否经过STR处理以及定位被移除文本区域的方法，以识别潜在的滥用行为并改进STR技术。

**Method:** 本文研究逆向场景文本移除 (ISTR)，主要方法包括：1) 对图像进行二元分类，判断其是否经过STR处理；2) 定位图像中被移除的文本区域。此外，还尝试训练一个文本识别器来恢复被移除的文本内容，以评估其难度。

**Result:** 实验证明，二元分类和定位被移除文本区域的任务可以达到很高的准确率。恢复被移除文本内容的尝试也揭示了其难度。

**Conclusion:** 逆向场景文本移除（ISTR）技术在检测STR处理过的图像和定位被移除文本区域方面是可行的，并且能够达到高准确率，这有助于检测潜在的滥用并改进STR。恢复移除文本内容虽然困难，但也是一个值得探索的方向。

> **ai_Abstract:** 这篇论文介绍了逆向场景文本移除（ISTR）技术，旨在解决场景文本移除（STR）技术可能带来的滥用风险。ISTR主要通过二元分类来判断图像是否经过STR处理，并能够高精度地定位被移除的文本区域。研究还探索了恢复被移除文本内容的可能性和难度。实验结果表明，ISTR在检测和定位方面表现出色，有助于识别潜在的STR滥用并促进STR技术的改进。

> **摘要翻译:** 场景文本移除（STR）旨在从图像中擦除文本元素。它最初是为了从自然场景图像中移除隐私敏感或不需要的文本，但现在也应用于排版图像。STR通常会检测文本区域，然后对其进行修复。尽管STR通过神经网络和合成数据取得了进展，但滥用风险也随之增加。本文研究逆向STR（ISTR），它分析经过STR处理的图像，并侧重于二元分类（检测图像是否经过STR处理）和定位被移除的文本区域。我们在实验中证明，这些任务可以以高准确率实现，从而能够检测潜在的滥用并改进STR。我们还尝试通过训练一个文本识别器来恢复被移除的文本内容，以了解其难度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [316] [VisionGuard: Synergistic Framework for Helmet Violation Detection](https://arxiv.org/abs/2506.21005)
> *VisionGuard：头盔违规检测的协同框架*

*Lam-Huy Nguyen, Thinh-Phuc Nguyen, Thanh-Hai Nguyen, Gia-Huy Dinh, Minh-Triet Tran, Trung-Nghia Le* | **Category: cs.CV**

**Keywords:** 头盔违规检测, 协同框架, 交通安全, 目标检测, 数据不平衡

**Comment:** 

> **TL;DR:** VisionGuard是一个多阶段框架，通过自适应标注和上下文扩展模块，提高了头盔违规检测的准确性，解决了数据不一致和类别不平衡问题。

**AI_Comments:** VisionGuard通过结合跟踪和数据增强（虚拟边界框）来解决自动头盔检测中的关键挑战，即分类一致性和数据不平衡，这是一种创新且实用的方法。其模块化设计和在mAP上的提升表明了其在实际交通监控系统中的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 自动检测摩托车手头盔违规面临挑战，包括环境多变性、摄像机角度和数据不一致性，这些因素阻碍了可靠的摩托车和骑手检测以及一致的对象分类。现有的逐帧检测器在类别不平衡和标注不一致的情况下表现受限。

**Method:** 本文提出了VisionGuard，一个协同多阶段框架，包含两个关键组件：自适应标注模块和上下文扩展模块。自适应标注模块是一种基于跟踪的细化技术，通过利用跟踪算法在帧间分配持久标签并纠正错误分类来增强分类一致性。上下文扩展模块通过生成具有适当置信度分数的虚拟边界框来提高代表性不足类别的召回率，有效解决了数据不平衡的影响。

**Result:** 实验结果显示，VisionGuard相较于基线检测器，整体mAP提高了3.1%。

**Conclusion:** VisionGuard展示了其有效性以及在交通监控系统中实际部署的潜力，最终有助于提高道路安全和法规遵从性。

> **ai_Abstract:** 本文提出了VisionGuard，一个用于头盔违规检测的协同多阶段框架，旨在解决现有逐帧检测器在环境多变性、数据不一致和类别不平衡下的局限性。VisionGuard整合了自适应标注模块（通过跟踪提高分类一致性）和上下文扩展模块（通过生成虚拟边界框解决数据不平衡）。实验证明，VisionGuard相较于基线检测器，整体mAP提升了3.1%，显示出其在交通监控中提高安全和合规性的潜力。

> **摘要翻译:** 强制执行摩托车手头盔规定对于提高道路安全和确保交通管理系统的有效性至关重要。然而，由于环境多变性、摄像机角度和数据不一致性，头盔违规的自动检测面临着重大挑战。这些因素阻碍了摩托车和骑手的可靠检测，并扰乱了对象的一致分类。为了应对这些挑战，我们提出了VisionGuard，一个协同多阶段框架，旨在克服逐帧检测器的局限性，特别是在类别不平衡和标注不一致的场景中。VisionGuard集成了两个关键组件：自适应标注模块和上下文扩展模块。自适应标注模块是一种基于跟踪的细化技术，通过利用跟踪算法在帧间分配持久标签并纠正错误分类来增强分类一致性。上下文扩展模块通过生成具有适当置信度分数的虚拟边界框来提高代表性不足类别的召回率，有效解决了数据不平衡的影响。实验结果表明，与基线检测器相比，VisionGuard的整体mAP提高了3.1%，展示了其有效性以及在交通监控系统中实际部署的潜力，最终促进了安全和法规遵从性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [318] [SAM4D: Segment Anything in Camera and LiDAR Streams](https://arxiv.org/abs/2506.21547)
> *SAM4D：在相机和激光雷达流中分割一切*

*Jianyun Xu, Song Wang, Ziqian Ni, Chunyong Hu, Sheng Yang, Jianke Zhu, Qiang Li* | **Category: cs.CV, cs.RO**

**Keywords:** 多模态分割, 激光雷达, 相机, 自动化标注, 自动驾驶

**Comment:** Accepted by ICCV2025, Project Page: https://SAM4D-Project.github.io

> **TL;DR:** SAM4D是一个多模态时序基础模型，通过引入UMPE和MCMA实现相机和激光雷达流的提示式分割，并开发了一个自动化数据引擎，能快速生成高质量伪标签，在Waymo-4DSeg上表现出强大的跨模态分割和数据标注潜力。

**AI_Comments:** SAM4D的创新性在于其整合了多模态（相机和激光雷达）和时序信息，并通过UMPE和MCMA实现高效的跨模态交互和时间一致性。其提出的自动化数据引擎是解决自动驾驶领域大规模数据标注瓶颈的关键突破，显著提高了标注效率和质量。这使得SAM4D在实际应用中具有重要潜力，尤其是在需要大量高质量标注数据的自动驾驶场景。

<details>
  <summary>Details</summary>

**Motivation:** 解决相机和激光雷达流中提示式分割的需求，并克服传统标注方法的数据瓶颈。

**Method:** 1. 引入统一多模态位置编码（UMPE）以在共享3D空间中对齐相机和激光雷达特征。2. 提出运动感知跨模态记忆注意力（MCMA）以增强时间一致性和长时域特征检索。3. 开发多模态自动化数据引擎，结合VFM驱动的视频掩膜、时空4D重建和跨模态掩膜融合，生成相机-激光雷达对齐的伪标签。

**Result:** 在构建的Waymo-4DSeg数据集上进行了广泛实验，结果表明SAM4D具有强大的跨模态分割能力和在数据标注方面的巨大潜力。

**Conclusion:** SAM4D是一个有效且高效的多模态时序基础模型，能够实现跨相机和激光雷达流的提示式分割，并通过自动化数据引擎显著加速数据标注，为自动驾驶场景提供了强大的解决方案。

> **ai_Abstract:** SAM4D是一个为相机和激光雷达流设计的提示式多模态时序分割模型。它通过统一多模态位置编码（UMPE）对齐跨模态特征，并利用运动感知跨模态记忆注意力（MCMA）提升时间一致性。为解决数据标注问题，该模型还开发了一个多模态自动化数据引擎，能高效生成高质量伪标签。实验证明SAM4D在跨模态分割和数据标注方面表现出色。

> **摘要翻译:** 我们提出了SAM4D，一个多模态和时序基础模型，旨在实现相机和激光雷达流的提示式分割。引入了统一多模态位置编码（UMPE）以在共享3D空间中对齐相机和激光雷达特征，从而实现无缝的跨模态提示和交互。此外，我们提出了运动感知跨模态记忆注意力（MCMA），它利用自我运动补偿来增强时间一致性和长时域特征检索，确保在动态变化的自动驾驶场景中实现鲁棒分割。为了避免标注瓶颈，我们开发了一个多模态自动化数据引擎，该引擎协同VFM驱动的视频掩膜、时空4D重建和跨模态掩膜融合。该框架生成的相机-激光雷达对齐伪标签的速度比人工标注快几个数量级，同时在点云表示中保留了VFM导出的语义保真度。我们在构建的Waymo-4DSeg上进行了广泛实验，这些实验证明了所提出的SAM4D强大的跨模态分割能力和在数据标注方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [319] [Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning](https://arxiv.org/abs/2506.21006)
> *乳腺癌保乳术切缘的SAM结合前向-前向对比学习检测*

*Tyler Ward, Xiaoqin Wang, Braxton McFarland, Md Atik Ahamed, Sahar Nozad, Talal Arshad, Hafsa Nebbache, Jin Chen, Abdullah Imran* | **Category: cs.CV**

**Keywords:** 乳腺癌, 保乳术, 切缘检测, 对比学习, SAM, 深度学习

**Comment:** 19 pages, 7 figures, 3 tables

> **TL;DR:** 本文提出了一种结合SAM和前向-前向对比学习（FFCL）的深度学习框架，用于提高乳腺癌保乳术中切缘评估的速度和准确性，以减少二次手术率。

**AI_Comments:** 这项研究通过结合创新的前向-前向对比学习预训练策略和强大的SAM模型，有效解决了乳腺癌保乳术中切缘评估准确性低的临床痛点。其核心创新在于利用FFCL进行高效的特征学习和分类，并通过SAM实现高精度的分割，显著提升了术中决策的效率和可靠性。该方法对提高患者预后和降低医疗成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺癌保乳术中肿瘤切除不完全（切缘阳性）是导致复发的重要原因。当前使用的2D标本射线照相（SR）准确性有限，导致约四分之一的患者需要二次手术。

**Method:** 提出了一种结合“万物分割模型”（SAM）与“前向-前向对比学习”（FFCL）的深度学习框架。首先，对SR图像进行已知恶性区域、非恶性组织和病理确认切缘的标注。然后，使用FFCL预训练ResNet-18骨干网络进行切缘状态分类。最后，重建粗略的二值掩码以提示SAM进行精细的肿瘤切缘分割。

**Result:** 该方法在切缘分类上取得了0.8455的AUC。在分割切缘方面，与基线模型相比，Dice相似系数提高了27.4%。此外，每张图像的推理时间减少到47毫秒。

**Conclusion:** FFCL-SAM显著提高了术中切缘评估的速度和准确性，有望降低二次切除率并改善乳腺癌治疗的手术结果。

> **ai_Abstract:** 本文提出了一种名为FFCL-SAM的深度学习框架，旨在提高乳腺癌保乳术中切缘评估的准确性和速度。该框架结合了前向-前向对比学习（FFCL）进行补丁级分类预训练，并利用Segment Anything Model（SAM）进行精细的肿瘤切缘分割。实验结果表明，FFCL-SAM在切缘分类和分割性能上均显著优于现有方法，并大幅缩短了推理时间，有望减少患者二次手术的需求。

> **摘要翻译:** 乳腺癌保乳术中完整切除肿瘤并获得阴性切缘对于降低乳腺癌复发至关重要。然而，2D标本射线照相（SR）是目前用于评估术中标本切缘状态的方法，其准确性有限，导致近四分之一的患者需要额外手术。为了解决这个问题，我们提出了一种新颖的深度学习框架，将“万物分割模型”（SAM）与“前向-前向对比学习”（FFCL）相结合。FFCL是一种预训练策略，它利用局部和全局对比学习对SR图像进行补丁级分类。在对SR图像进行已知恶性区域、非恶性组织和病理确认切缘的标注后，我们使用FFCL预训练ResNet-18骨干网络以分类切缘状态，然后重建粗略的二值掩码以提示SAM进行精细的肿瘤切缘分割。我们的方法在切缘分类上取得了0.8455的AUC，并在分割切缘方面比基线模型提高了27.4%的Dice相似系数，同时将每张图像的推理时间减少到47毫秒。这些结果表明，FFCL-SAM显著提高了术中切缘评估的速度和准确性，具有降低二次切除率和改善乳腺癌治疗手术结果的巨大潜力。我们的代码可在https://github.com/tbwa233/FFCL-SAM/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [321] [Whole-Body Conditioned Egocentric Video Prediction](https://arxiv.org/abs/2506.21552)
> *全身条件化自我中心视频预测*

*Yutong Bai, Danny Tran, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik* | **Category: cs.CV, cs.AI, cs.LG, cs.MM, cs.RO**

**Keywords:** 自我中心视频预测, 人类动作, 3D身体姿态, 扩散变换器, 具身智能体

**Comment:** Project Page: https://dannytran123.github.io/PEVA

> **TL;DR:** 该研究训练模型，通过以相对3D身体姿态为条件，从人类动作预测自我中心视频，旨在模拟人类动作如何从第一视角塑造环境。

**AI_Comments:** 这项研究的创新之处在于通过结合全身姿态信息和扩散变换器来预测自我中心视频，这为理解和模拟人类与环境的交互提供了新视角。其重要性在于为具身智能体的行为预测和控制提供了基础，特别是在复杂真实世界场景下的应用潜力。通过大规模数据集和分层评估协议，确保了研究的严谨性和模型的全面分析能力。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在从人类视角出发，通过视频预测来解决建模复杂真实世界环境和具身智能体行为的挑战。

**Method:** 作者训练了名为PEVA的模型，该模型在给定过去视频和由相对3D身体姿态表示的动作的情况下，预测自我中心视频。模型通过身体关节层级结构化的运动姿态轨迹进行条件化。他们在一个名为Nymeria的大规模真实世界自我中心视频和身体姿态捕获数据集上训练了一个自回归条件扩散变换器。此外，他们还设计了一个分层评估协议。

**Result:** 该模型学会了模拟物理人类动作如何从第一人称视角塑造环境。分层评估协议能够对模型的具身预测和控制能力进行全面分析。

**Conclusion:** 这项工作代表了从人类视角通过视频预测来解决建模复杂真实世界环境和具身智能体行为挑战的初步尝试。

> **ai_Abstract:** 本研究训练了一个名为PEVA的模型，用于根据过去的视频和人类的相对3D身体姿态来预测自我中心视频。模型利用身体姿态轨迹作为条件，旨在模拟人类动作如何从第一人称视角影响环境。研究团队在一个大型真实世界数据集Nymeria上训练了一个自回归条件扩散变换器，并设计了分层评估协议来全面分析模型的具身预测和控制能力。这项工作是解决复杂真实世界环境和具身智能体行为建模挑战的初步探索。

> **摘要翻译:** 我们训练模型，在给定过去的视频和以相对3D身体姿态表示的动作的情况下，预测自我中心视频（PEVA）。通过以身体关节层级结构化的运动姿态轨迹为条件，我们的模型学会了从第一人称视角模拟物理人类动作如何塑造环境。我们在Nymeria（一个大规模真实世界自我中心视频和身体姿态捕获数据集）上训练了一个自回归条件扩散变换器。我们进一步设计了一个分层评估协议，包含越来越具挑战性的任务，从而能够对模型的具身预测和控制能力进行全面分析。我们的工作代表了从人类视角通过视频预测来解决建模复杂真实世界环境和具身智能体行为挑战的初步尝试。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [322] [The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion](https://arxiv.org/abs/2506.21008)
> *衰老多重宇宙：通过免训练扩散生成条件感知面部衰老树*

*Bang Gong, Luchao Qi, Jiaye Wu, Zhicheng Fu, Chunbo Song, David W. Jacobs, John Nicholson, Roni Sengupta* | **Category: cs.CV**

**Keywords:** 面部衰老, 扩散模型, 条件生成, 免训练, 衰老树

**Comment:** 

> **TL;DR:** 该研究引入“衰老多重宇宙”框架，通过免训练扩散方法从单张图像生成多条受环境、健康和生活方式等外部因素影响的 plausible 面部衰老路径，形成一个可视化多样化未来的衰老树，并在身份保持、年龄准确性和条件控制方面达到最先进水平。

**AI_Comments:** 这项研究的创新之处在于它突破了传统面部衰老模型单一路径的限制，首次提出了“衰老多重宇宙”的概念，并利用免训练扩散模型生成条件感知的多样化衰老轨迹。其引入的注意力混合和模拟衰老正则化策略是关键的技术贡献，有效解决了多因素影响下的面部老化生成难题。这对于数字内容创作、健康预测和个性化服务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的面部衰老模型通常将衰老视为单一的确定性路径，未能考虑外部因素如环境、健康和生活方式对衰老过程的多元影响，且在身份保持、年龄准确性和条件控制方面存在不足。

**Method:** 本文提出一种免训练的扩散方法，用于生成条件感知的面部衰老树。关键贡献包括：1. 注意力混合（attention mixing）以调节编辑强度。2. 模拟衰老正则化（Simulated Aging Regularization）策略以稳定编辑。该方法旨在平衡身份保持、年龄准确性和条件控制。

**Result:** 通过广泛的实验和用户研究，该方法在身份保持、衰老真实感和条件对齐方面展现出最先进的性能，优于现有未能充分考虑编辑标准的编辑和年龄进展模型。

**Conclusion:** 该方法将衰老转化为一个多维度、可控且可解释的过程，为数字故事讲述、健康教育和个性化可视化开辟了新的创意和实用途径。

> **ai_Abstract:** 本文提出了“衰老多重宇宙”框架，利用免训练扩散方法，从单一图像生成受外部因素（如环境、健康、生活方式）影响的多个 plausible 面部衰老轨迹，形成一个“衰老树”，以可视化多样化的未来。该方法通过注意力混合和模拟衰老正则化策略，有效平衡了身份保持、年龄准确性和条件控制，并在实验中展现出超越现有模型的顶尖性能，为面部衰老建模提供了多维度、可控和可解释的新范式。

> **摘要翻译:** 我们引入了“衰老多重宇宙”框架，该框架能够从单张图像生成多条合理的面部衰老轨迹，每条轨迹都受环境、健康和生活方式等外部因素的影响。与将衰老建模为单一确定性路径的现有方法不同，我们的方法创建了一个可视化多样化未来的衰老树。为实现这一点，我们提出了一种免训练的基于扩散的方法，该方法平衡了身份保持、年龄准确性和条件控制。我们的主要贡献包括用于调节编辑强度的注意力混合以及用于稳定编辑的模拟衰老正则化策略。广泛的实验和用户研究表明，在身份保持、衰老真实感和条件对齐方面，我们的方法达到了最先进的性能，优于现有常常未能考虑一个或多个编辑标准的编辑和年龄进展模型。通过将衰老转化为一个多维度、可控和可解释的过程，我们的方法在数字故事讲述、健康教育和个性化可视化方面开辟了新的创意和实用途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [324] [User-in-the-Loop View Sampling with Error Peaking Visualization](https://arxiv.org/abs/2506.21009)
> *用户在环的视图采样与误差峰值可视化*

*Ayaka Yasunaga, Hideo Saito, Shohei Mori* | **Category: cs.CV**

**Keywords:** 用户在环, 视图采样, 误差可视化, 增强现实, 辐射场重建

**Comment:** Accepted at IEEE ICIP 2025, Project Page:
  https://mediated-reality.github.io/projects/yasunaga_icip25/

> **TL;DR:** 本文提出一种用户在环的视图采样方法，通过可视化误差峰值来指导用户，减少了数据采集的负担并提高了效率。

**AI_Comments:** 本文的创新点在于提出了“误差峰值可视化”这一新颖的用户指导机制，有效解决了现有AR视图采样方法中用户心智负担重和采样区域受限的问题。通过将误差反馈给用户，实现了更智能、更高效的用户在环数据采集，对于移动视图合成和大规模辐射场重建具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的增强现实视图采样方法对用户来说心智负担重，且由于采样理论的限制，捕获区域小。为了让用户摆脱3D标注和有限的场景探索，作者提出了新的方法。

**Method:** 提出使用局部重建的光场，并通过可视化误差峰值来指导用户插入新的视图以消除误差。这种“误差峰值可视化”方法引导用户。

**Result:** 误差峰值可视化方法侵入性更小，减少了最终结果的失望，并且在移动视图合成系统中用更少的视图样本就能达到满意效果。该方法还有助于更大场景的辐射场重建（如3D高斯泼溅）。

**Conclusion:** 通过误差峰值可视化，可以有效改善用户在环的视图采样体验，提高数据采集效率和结果质量，并适用于更大场景的辐射场重建。

> **ai_Abstract:** 本文针对增强现实中新视图合成的数据采集痛点，提出一种用户在环的视图采样方法。该方法利用局部重建的光场并可视化需要通过插入新视图消除的误差峰值，从而指导用户。实验结果表明，这种误差峰值可视化方法能有效降低用户负担，减少视图样本数量，并适用于大规模场景的辐射场重建，提高了数据采集的效率和用户满意度。

> **摘要翻译:** 增强现实（AR）提供了可视化缺失视图样本以进行新视图合成的方法。现有方法为新的视图样本提供3D标注，并要求用户通过对齐AR显示器来拍摄图像。众所周知，这种数据收集任务对心智要求很高，并且由于理想但限制性的底层采样理论，将捕获区域限制在预定义的小区域内。为了将用户从3D标注和有限的场景探索中解放出来，我们提出使用局部重建的光场并可视化通过插入新视图需要消除的误差。我们的结果表明，误差峰值可视化侵入性更小，减少了最终结果的失望，并且在我们的移动视图合成系统中，用更少的视图样本就能达到满意效果。我们还表明，我们的方法可以促进对更大场景的近期辐射场重建，例如3D高斯泼溅。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [327] [Bridging Video Quality Scoring and Justification via Large Multimodal Models](https://arxiv.org/abs/2506.21011)
> *通过大型多模态模型连接视频质量评分与解释*

*Qizhi Xie, Kun Yuan, Yunpeng Qu, Jiachao Gong, Mingda Wu, Ming Sun, Chao Zhou, Jihong Zhu* | **Category: cs.CV**

**Keywords:** 视频质量评估, 大型多模态模型, 指令微调, 数据生成, 思维链

**Comment:** 15 pages, 4 figures, 8 tables

> **TL;DR:** 本文提出了一种基于分数的指令生成（SIG）管道来创建大规模视频质量指令数据（S2I），以提升大型多模态模型的视频质量评分和解释能力。

**AI_Comments:** 本文的创新点在于提出了一个自动化的数据生成管道SIG，解决了传统视频质量评估缺乏解释性的问题，并克服了当前大型多模态模型在视频质量领域数据稀缺和依赖人工标注的局限性。通过引入分层思维链模拟人类推理过程，使得生成的指令数据更具高质量和多样性。构建大规模S2I数据集和S2I-Bench基准测试对推动视频LMMs在VQA领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 经典的视频质量评估（VQA）方法只生成一个数值分数，无法描述视频复杂的质量维度，限制了其适用性。现有视频大型多模态模型（LMMs）在VQA上的应用，其数据生成过程主要依赖于人工标注和专有系统，限制了数据可扩展性和有效性。

**Method:** 提出了“基于分数的指令生成（SIG）”管道，该管道首先对未标注视频的多个质量维度进行评分并映射到文本级别，然后引入分层思维链（CoT）来模拟特定维度与整体质量之间的关联，模仿人类视觉系统推理。该自动化管道消除了对专家编写质量描述和专有系统的依赖。基于SIG，构建了Score2Instruct（S2I）数据集，包含超过320K个指令-响应对。设计了一种渐进式微调策略以同时提升视频LMMs的质量评分和解释能力。进一步策划了一个名为S2I-Bench的基准测试，包含400个开放式问题，用于评估视频LMMs的质量解释能力。

**Result:** 在S2I-Bench和现有基准测试上的实验结果表明，该方法持续改进了多个视频LMMs的质量评分和解释能力。

**Conclusion:** 通过提出的自动化指令生成管道和大规模数据集，本研究成功地弥合了视频质量评分和解释之间的鸿沟，显著提升了大型多模态模型在视频质量评估任务中的表现和解释能力。

> **ai_Abstract:** 本文提出了一种新颖的基于分数的指令生成（SIG）管道，旨在解决传统视频质量评估（VQA）仅提供数值分数而缺乏解释性的问题。SIG通过对视频多维度评分并结合分层思维链（CoT），自动化生成大规模高质量指令数据（Score2Instruct, S2I），避免了对人工标注和专有系统的依赖。S2I数据集包含超过320K个指令-响应对，为视频大型多模态模型（LMMs）的指令微调提供了基础。研究还提出了一种渐进式微调策略，并构建了S2I-Bench基准测试来评估模型的质量解释能力。实验结果验证了该方法能显著提升视频LMMs的质量评分和解释能力。

> **摘要翻译:** 经典的视频质量评估（VQA）方法生成一个数值分数来判断视频感知的视觉保真度和清晰度。然而，一个分数无法描述视频复杂的质量维度，限制了其适用性。受益于语言输出，通过指令微调将视频大型多模态模型（LMMs）应用于VQA有潜力解决这个问题。该方法的核心在于以视频质量为中心的指令数据。之前的探索主要集中在图像领域，并且它们的数据生成过程严重依赖于人工质量标注和专有系统，限制了数据的可扩展性和有效性。为了应对这些挑战，我们提出了基于分数的指令生成（SIG）管道。具体而言，SIG首先对未标注视频的多个质量维度进行评分，并将分数映射到文本定义的级别。然后，它明确地引入了分层思维链（CoT）来模拟特定维度与整体质量之间的关联，模仿人类视觉系统的推理过程。该自动化管道消除了对专家编写的质量描述和专有系统的依赖，确保了数据的可扩展性和生成效率。为此，生成的Score2Instruct（S2I）数据集包含超过320K个多样化的指令-响应对，为指令微调奠定了基础。此外，为了同时提升视频LMMs的质量评分和解释能力，我们设计了一种渐进式微调策略，以充分发挥S2I的潜力。基于SIG，我们进一步策划了一个名为S2I-Bench的基准测试，包含400个开放式问题，以更好地评估视频LMMs的质量解释能力。在S2I-Bench和现有基准测试上的实验结果表明，我们的方法持续改进了多个视频LMMs的质量评分和解释能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [330] [FedSC: Federated Learning with Semantic-Aware Collaboration](https://arxiv.org/abs/2506.21012)
> *FedSC：语义感知协作的联邦学习*

*Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Jiahua Shi, Jun Shen* | **Category: cs.CV**

**Keywords:** 联邦学习, 数据异构性, 语义感知, 原型学习, 对比学习

**Comment:** 12 pages, KDD 2025

> **TL;DR:** FedSC提出了一种新的联邦学习方法，通过构建语义级别的关系原型和一致原型来解决数据异构性问题，并引入了跨对比学习和差异聚合策略，同时提供了收敛性保证。

**AI_Comments:** FedSC的创新之处在于其通过语义感知协作来解决联邦学习中的数据异构性问题，特别是引入了关系原型和一致原型，以及跨对比学习和差异聚合等机制，有效地利用了数据固有的语义信息。此外，提供理论收敛性保证也增加了其方法的可靠性。该工作对提升联邦学习在非独立同分布数据环境下的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在数据隐私保护下进行模型协作训练面临数据异构性（客户端数据标签偏置）的挑战。现有方法常忽略客户端固有的语义信息，因此需要探索利用客户端内部语义知识来处理数据异构性。

**Method:** 本文提出了FedSC（Federated Learning with Semantic-Aware Collaboration）。FedSC的核心思想是在语义层面构建关系原型（relational prototypes）和一致原型（consistent prototypes）。它引入了跨对比学习（inter-contrastive learning）策略，使实例级嵌入与相同语义的关系原型更接近，并远离不同类。此外，FedSC通过差异聚合（discrepancy aggregation）方式设计了一致原型，作为正则化惩罚来约束局部模型的优化区域。该方法还提供了收敛性理论分析。

**Result:** 在各种挑战性场景下的实验结果表明，FedSC的有效性以及其关键组件的效率。

**Conclusion:** FedSC通过利用客户端内部的语义感知协作，有效地解决了联邦学习中的数据异构性问题，并提供了理论上的收敛性保证，实验证明其有效性和关键组件的效率。

> **ai_Abstract:** 本文提出了一种名为FedSC的联邦学习新框架，旨在解决数据异构性问题。FedSC通过在语义层面构建关系原型和一致原型，利用客户端内部的语义信息。它结合了跨对比学习策略来优化实例嵌入，并使用差异聚合来正则化局部模型。研究还提供了理论收敛性保证，并通过实验验证了FedSC在不同场景下的有效性。

> **摘要翻译:** 联邦学习（FL）旨在跨客户端协作训练模型，同时不共享数据以保护隐私。然而，一个主要的挑战是数据异构性问题，它指的是多个客户端的标签偏好存在偏差。许多现有的联邦学习方法试图在本地（例如，正则化本地模型）或全局（例如，微调全局模型）解决数据异构性问题，但往往忽略了每个客户端中固有的语义信息。为了探索利用客户端内部语义上有意义的知识来处理数据异构性的可能性，本文提出了语义感知协作的联邦学习（FedSC），以捕获异构客户端之间特定于客户端和与类别相关的知识。FedSC的核心思想是在语义层面构建关系原型和一致原型，旨在以原型协作的方式提供丰富的类别底层知识和稳定的收敛信号。一方面，FedSC引入了一种跨对比学习策略，使实例级嵌入更接近具有相同语义的关系原型，并远离不同的类别。另一方面，FedSC通过差异聚合方式设计了一致原型，作为正则化惩罚来约束局部模型的优化区域。此外，FedSC还提供了理论分析以确保收敛性。在各种挑战性场景下的实验结果证明了FedSC的有效性以及关键组件的效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [332] [HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for Skin Disease Image Generation](https://arxiv.org/abs/2506.21015)
> *HybridQ：用于皮肤病图像生成的混合经典-量子生成对抗网络*

*Qingyue Jiao, Kangyu Zheng, Yiyu Shi, Zhiding Liang* | **Category: cs.CV, cs.LG, quant-ph**

**Keywords:** 混合生成对抗网络, 量子计算, 皮肤病图像生成, 数据增强, 经典-量子融合

**Comment:** 

> **TL;DR:** HybridQ是一种新的混合经典-量子GAN，能够生成彩色皮肤病医学图像，与经典GAN相比，在图像质量和数据增强方面表现更好，参数和训练周期显著减少。

**AI_Comments:** 本文的创新点在于提出了首个能够生成彩色医学图像的混合经典-量子GAN，通过潜在空间融合技术克服了现有量子图像生成方法的局限性。其重要性体现在为医疗图像数据增强提供了一种高效且资源友好的新范式，特别是在数据稀缺和隐私敏感的皮肤病领域。模型在减少参数和训练时间方面的显著优势预示了量子计算在生成模型领域的广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 皮肤病诊断中的机器学习模型需要大量高质量数据，但现有数据集存在类别不平衡、隐私问题和对象偏差，需要数据增强。经典生成模型计算资源需求大，训练时间长。现有量子图像生成方法只能生成低质量灰度图像。

**Method:** 通过一种新颖的经典-量子潜在空间融合技术，引入了第一个能够生成彩色医学图像的经典-量子生成对抗网络（HybridQ）。

**Result:** HybridQ在图像生成质量和作为数据增强时的分类性能提升方面优于经典深度卷积GAN和现有混合经典-量子GAN。其性能提升与最先进的经典生成模型相当，但参数减少25倍以上，训练周期减少10倍。该模型在真实的IBM量子机器上表现出鲁棒性。

**Conclusion:** 量子图像生成具有广阔前景，随着量子硬件的发展，HybridQ展示了在生成高质量彩色医学图像方面的潜力，并且在资源效率方面优于经典方法。

> **ai_Abstract:** 本研究提出了一种名为HybridQ的混合经典-量子生成对抗网络，旨在解决皮肤病图像数据集的局限性并提高数据增强效率。通过创新的经典-量子潜在空间融合技术，HybridQ首次实现了彩色医学图像的生成，克服了现有量子生成方法仅能产生低质量灰度图像的限制。实验结果表明，HybridQ在图像生成质量和作为数据增强时的分类性能提升方面优于传统GAN和现有混合量子GAN，且在性能与最先进经典模型相当的同时，显著减少了模型参数和训练时间。这表明量子图像生成在未来具有巨大潜力，并且该模型在真实量子硬件上表现出良好的鲁棒性。

> **摘要翻译:** 机器学习辅助诊断在皮肤病检测中越来越受欢迎，但训练有效的模型需要大量高质量数据。皮肤病数据集常面临类别不平衡、隐私问题和对象偏差，使得数据增强至关重要。虽然经典生成模型被广泛使用，但它们需要大量的计算资源和漫长的训练时间。量子计算提供了一个有前景的替代方案，但现有的基于量子的图像生成方法只能产生灰度低质量图像。通过一种新颖的经典-量子潜在空间融合技术，我们的工作克服了这一限制，并引入了第一个能够生成彩色医学图像的经典-量子生成对抗网络（GAN）。我们的模型在图像生成质量和作为数据增强时的分类性能提升方面均优于经典深度卷积GAN和现有混合经典-量子GAN。此外，其性能提升与使用最先进的经典生成模型所达到的效果相当，但参数减少了25倍以上，训练周期减少了10倍。这些结果表明，随着量子硬件的进步，量子图像生成具有广阔的前景。最后，我们展示了我们的模型在具有硬件噪声的真实IBM量子机器上的鲁棒性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [335] [Multimodal Prompt Alignment for Facial Expression Recognition](https://arxiv.org/abs/2506.21017)
> *多模态提示对齐用于面部表情识别*

*Fuyan Ma, Yiran He, Bin Sun, Shutao Li* | **Category: cs.CV, cs.AI**

**Keywords:** 面部表情识别, 多模态, 提示学习, 视觉-语言模型, CLIP

**Comment:** To appear in ICCV2025

> **TL;DR:** MPA-FER框架通过多模态提示对齐解决VLM在面部表情识别中难以捕捉细粒度文本-视觉关系的问题，引入LLM生成硬提示并与软提示对齐，同时进行原型引导的视觉特征对齐和跨模态全局-局部对齐，显著提升了FER性能。

**AI_Comments:** 该论文的创新点在于将LLM生成的细粒度语义知识与VLM的提示学习相结合，有效提升了FER任务中细微表情差异的识别能力。通过引入硬提示与软提示的对齐、原型引导的视觉特征对齐以及跨模态全局-局部对齐，系统地解决了现有VLM在细粒度文本-视觉关系捕获上的不足，为多模态FER提供了一个有效且高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于视觉-语言模型（VLM）的面部表情识别（FER）方法难以捕获细粒度的文本-视觉关系，这对于区分面部表情的细微差异至关重要。

**Method:** 我们提出了一个名为MPA-FER的多模态提示对齐框架。该框架通过多粒度硬提示生成策略，利用大型语言模型（LLM）如ChatGPT生成每个面部表情的详细描述。LLM的外部知识通过最小化软提示和硬提示之间的特征差异来注入到软提示中。为了保留预训练CLIP模型的泛化能力，该方法结合了原型引导的视觉特征对齐，确保冻结图像编码器产生的提示视觉特征与特定类原型紧密对齐。此外，我们提出了一个跨模态全局-局部对齐模块，该模块关注与表情相关的面部特征，进一步改善了文本和视觉特征之间的对齐。

**Result:** 我们的框架在三个FER基准数据集上超越了最先进的方法，同时保留了预训练模型的优势并最小化了计算成本。

**Conclusion:** MPA-FER框架通过有效解决细粒度文本-视觉关系捕获的挑战，显著提升了面部表情识别的性能，并证明了多模态提示对齐的有效性。

> **ai_Abstract:** 本文提出了一个名为MPA-FER的多模态提示对齐框架，旨在解决现有VLM在面部表情识别（FER）中难以捕捉细粒度文本-视觉关系的问题。该框架通过LLM生成多粒度硬提示，并将其知识注入软提示中。同时，它引入了原型引导的视觉特征对齐和跨模态全局-局部对齐模块，以提升特征表示的精确度和可解释性。实验证明，MPA-FER在多个FER数据集上优于现有方法，且保持了预训练模型的泛化能力并降低了计算成本。

> **摘要翻译:** 提示学习已被广泛应用于高效地调整视觉-语言模型（VLM），如CLIP，以适应各种下游任务。尽管取得了成功，但当前基于VLM的面部表情识别（FER）方法难以捕获细粒度的文本-视觉关系，这对于区分面部表情的细微差异至关重要。为了解决这一挑战，我们提出了一个用于FER的多模态提示对齐框架，称为MPA-FER，它为提示视觉特征的学习过程提供细粒度的语义指导，从而产生更精确和可解释的表示。具体来说，我们引入了一种多粒度硬提示生成策略，该策略利用大型语言模型（LLM）如ChatGPT为每个面部表情生成详细描述。通过最小化软提示和硬提示之间的特征差异，将基于LLM的外部知识注入到软提示中。为了保留预训练CLIP模型的泛化能力，我们的方法结合了原型引导的视觉特征对齐，确保冻结图像编码器产生的提示视觉特征与特定类原型紧密对齐。此外，我们提出了一个跨模态全局-局部对齐模块，该模块关注与表情相关的面部特征，进一步改善了文本和视觉特征之间的对齐。大量的实验表明，我们的框架在三个FER基准数据集上超越了最先进的方法，同时保留了预训练模型的优势并最小化了计算成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [337] [LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection](https://arxiv.org/abs/2506.21018)
> *LASFNet：一种用于多模态目标检测的轻量级注意力引导自调制特征融合网络*

*Lei Hao, Lina Xu, Chang Liu, Yanni Dong* | **Category: cs.CV**

**Keywords:** 多模态目标检测, 特征融合, 注意力机制, 轻量级网络, 自调制

**Comment:** 

> **TL;DR:** LASFNet提出了一种轻量级单特征融合单元，通过注意力引导的自调制和特征注意力转换模块，显著降低多模态目标检测的计算成本和参数量，同时提高检测精度。

**AI_Comments:** LASFNet的创新点在于其轻量化设计和高效的特征融合策略。通过引入单特征级融合单元、ASFF模块和FATM，它有效地解决了多模态目标检测中计算效率低下的问题，并在精度上有所提升，展现了良好的实用价值和潜在的广泛应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态目标检测方法通过堆叠多个特征级融合单元，导致训练过程复杂和计算开销大。

**Method:** 提出LASFNet，一个基于单特征级融合单元的基线。LASFNet包含：新颖的注意力引导自调制特征融合（ASFF）模块，根据不同模态的注意力信息，自适应调整融合特征的全局和局部响应；轻量级特征注意力转换模块（FATM），在网络颈部增强对融合特征的关注并最小化信息损失。

**Result:** 在三个代表性数据集上，与SOTA方法相比，参数量和计算成本分别减少高达90%和85%，同时检测精度（mAP）提高1%-3%，实现了良好的效率-精度权衡。

**Conclusion:** LASFNet通过其轻量级设计和创新的融合模块，显著提高了多模态目标检测的效率和精度，解决了现有方法的计算开销问题。

> **ai_Abstract:** 本文针对多模态目标检测中现有特征融合方法计算开销大的问题，提出了一种轻量级注意力引导自调制特征融合网络（LASFNet）。该网络采用单一特征级融合单元，并引入了注意力引导自调制特征融合（ASFF）模块和轻量级特征注意力转换（FATM）模块，以自适应调整融合特征并减少信息损失。实验证明，LASFNet在显著降低计算成本和参数量的同时，有效提升了检测精度。

> **摘要翻译:** 通过特征级融合进行有效的深度特征提取对于多模态目标检测至关重要。然而，以往的研究通常涉及复杂的训练过程，通过堆叠多个特征级融合单元来整合模态特定特征，导致显著的计算开销。为了解决这个问题，我们提出了一种新的融合检测基线，该基线使用单个特征级融合单元来实现高性能检测，从而简化了训练过程。基于这种方法，我们提出了一种轻量级注意力引导自调制特征融合网络（LASFNet），它引入了一种新颖的注意力引导自调制特征融合（ASFF）模块，该模块根据来自不同模态的注意力信息，自适应地调整融合特征的全局和局部响应，从而促进全面和丰富的特征生成。此外，在LASFNet的颈部设计了一个轻量级特征注意力转换模块（FATM），以增强对融合特征的关注并最大程度地减少信息损失。在三个代表性数据集上进行的大量实验表明，与最先进的方法相比，我们的方法实现了良好的效率-精度权衡，将参数数量和计算成本分别降低了90%和85%，同时将检测精度（mAP）提高了1%-3%。代码将在https://github.com/leileilei2000/LASFNet开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [339] [Instella-T2I: Pushing the Limits of 1D Discrete Latent Space Image Generation](https://arxiv.org/abs/2506.21022)
> *Instella-T2I: 突破一维离散潜在空间图像生成的极限*

*Ze Wang, Hao Chen, Benran Hu, Jiang Liu, Ximeng Sun, Jialian Wu, Yusheng Su, Xiaodong Yu, Emad Barsoum, Zicheng Liu* | **Category: cs.CV**

**Keywords:** 图像生成, 1D潜在空间, 二值表示, 文本到图像, 高效标记化

**Comment:** 

> **TL;DR:** Instella-T2I引入一维二值图像潜在空间，用极少离散token实现高分辨率图像生成，大幅提升效率并达到SOTA性能。

**AI_Comments:** 本文的创新点在于引入了一维二值图像潜在空间，有效地将高分辨率图像表示为极少的离散token，这在计算效率上是一个重大突破。其重要性在于，在不牺牲性能的前提下，显著降低了图像生成模型的资源消耗，使得更大规模的模型训练和部署成为可能，尤其是在硬件资源有限或追求极致效率的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 图像标记化在降低高分辨率图像建模的计算需求方面起着关键作用，而现有方法仍有改进空间以进一步减少token数量并提升效率。

**Method:** 引入一维二值图像潜在空间，将每张图像表示为二值向量序列，而非传统one-hot码本token，从而在保持高分辨率细节的同时，维持一维潜在空间的紧凑性。

**Result:** 首次使用128个离散token实现高达1024x1024图像的扩散和自回归生成，达到具有竞争力的性能；与标准VQ-VAE相比，token数量减少高达32倍；显著提升了训练速度和推理速度；文本到图像模型可以在单个GPU节点（8个AMD MI300X GPU）上实现4096的全局批处理大小；训练可在200 GPU天内完成；在没有任何内部私有训练数据或后期训练优化的情况下，性能与现代图像生成模型相当。

**Conclusion:** Instella-T2I提出的1D二值潜在空间结合简单模型架构，为传统tokenization方法提供了一种可扩展且高效的替代方案，在减少token数量和提高效率方面取得了显著进展，同时保持了竞争力。

> **ai_Abstract:** 本文提出了Instella-T2I，一种基于一维二值图像潜在空间的新型图像生成方法，旨在大幅减少高分辨率图像建模所需的token数量。通过将图像表示为二值向量序列，该方法在保持图像细节的同时，实现了仅用128个token生成1024x1024图像，相比传统VQ-VAE减少了32倍token。此外，该方法显著提升了训练和推理速度，并在不依赖私有数据或后期优化的前提下，达到了与现有先进模型相当的性能，为高效图像生成提供了可扩展的替代方案。

> **摘要翻译:** 图像标记化在降低高分辨率图像建模的计算需求方面起着关键作用，显著提高了图像和多模态理解和生成的效率。一维潜在空间的最新进展通过消除对二维网格结构的需求，减少了所需的标记数量。在本文中，我们通过引入一维二值图像潜在空间，进一步推进了紧凑离散图像表示。通过将每张图像表示为二值向量序列，而不是使用传统的one-hot码本标记，我们的方法在保持一维潜在空间紧凑性的同时，保留了高分辨率细节。据我们所知，我们的文本到图像模型是第一个仅使用128个离散标记就能生成高达1024x1024图像并实现在扩散和自回归生成方面具有竞争力的性能的模型，与标准VQ-VAE相比，标记数量减少了高达32倍。所提出的一维二值潜在空间，结合简单的模型架构，显著提高了训练速度和推理速度。我们的文本到图像模型可以在单个GPU节点（配备8个AMD MI300X GPU）上实现4096的全局批处理大小，并且训练可以在200 GPU天内完成。我们的模型在没有任何内部私有训练数据或后期训练优化的情况下，与现代图像生成模型相比取得了有竞争力的性能，为传统的标记化方法提供了一种可扩展且高效的替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [341] [DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation](https://arxiv.org/abs/2506.21034)
> *DidSee：基于扩散的深度补全，用于材料无关的机器人感知和操作*

*Wenzhou Lyu, Jialing Lin, Wenqi Ren, Ruihao Xia, Feng Qian, Yang Tang* | **Category: cs.CV**

**Keywords:** 深度补全, 扩散模型, 非朗伯物体, 机器人感知, 语义分割

**Comment:** 

> **TL;DR:** DidSee 是一种新的基于扩散的深度补全框架，解决了传统方法在非朗伯物体上的不足，并通过引入新的噪声调度器、单步训练和语义增强器，实现了SOTA性能并改进了机器人任务。

**AI_Comments:** DidSee的创新之处在于其对扩散模型在深度补全任务中遇到的特定问题（如训练-推理偏差和非朗伯物体挑战）进行了深入分析并提出了针对性解决方案。通过结合噪声调度优化、单步训练策略和语义增强，该方法不仅提升了深度图的精度和泛化能力，还证明了其在实际机器人应用中的价值，对于提升机器人对复杂材质物体的感知能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 商用RGB-D相机在非朗伯物体上生成噪声大、不完整的深度图。传统深度补全方法因训练数据有限而泛化能力差。尽管扩散模型有所进步，但香草扩散框架中的训练-推理不匹配偏差和非朗伯区域缺乏视觉特征进一步阻碍了精确预测。

**Method:** 提出了DidSee，一个基于扩散的深度补全框架，用于非朗伯物体。主要方法包括：1. 集成一个重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差。2. 设计一个噪声无关的单步训练公式，以减轻暴露偏差引起的错误累积，并使用任务特定损失优化模型。3. 结合一个语义增强器，实现联合深度补全和语义分割，区分物体和背景，生成精确、细粒度的深度图。

**Result:** DidSee 在多个基准测试中取得了最先进的性能，展示了强大的真实世界泛化能力，并有效改进了下游任务，如类别级姿态估计和机器人抓取。

**Conclusion:** DidSee 通过创新的扩散模型改进和语义增强，有效解决了非朗伯物体深度补全的挑战，实现了卓越的性能和实际应用价值。

> **ai_Abstract:** 本文提出了DidSee，一个专为非朗伯物体深度补全设计的扩散模型框架。针对现有扩散模型在深度补全中存在的训练-推理偏差和非朗伯区域特征不足问题，DidSee引入了零终端信噪比的噪声调度器以消除信号泄漏，采用噪声无关的单步训练公式以减轻误差累积，并集成了语义增强器以实现联合深度补全与语义分割。实验证明，DidSee在多项基准测试中达到SOTA性能，并显著提升了机器人抓取等下游任务的效果。

> **摘要翻译:** 商用RGB-D相机在非朗伯物体上通常会产生嘈杂、不完整的深度图。传统的深度补全方法由于训练数据的多样性和规模有限，难以泛化。最近的进展利用预训练文本到图像扩散模型的视觉先验来增强密集预测任务的泛化能力。然而，我们发现香草扩散框架中训练-推理不匹配引起的偏差会显著损害深度补全性能。此外，非朗伯区域缺乏独特的视觉特征进一步阻碍了精确预测。为了解决这些问题，我们提出了\textbf{DidSee}，一个基于扩散的深度补全框架，用于非朗伯物体。首先，我们集成了一个重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差。其次，我们设计了一个噪声无关的单步训练公式，以减轻暴露偏差引起的错误累积，并使用任务特定损失优化模型。最后，我们结合了一个语义增强器，实现了联合深度补全和语义分割，区分物体和背景，生成精确、细粒度的深度图。DidSee 在多个基准测试中取得了最先进的性能，展示了强大的真实世界泛化能力，并有效改进了下游任务，如类别级姿态估计和机器人抓取。项目页面：https://wenzhoulyu.github.io/DidSee/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [343] [Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability](https://arxiv.org/abs/2506.21042)
> *利用扩散模型提升域泛化和自适应检测：适应性、泛化性和可迁移性*

*Boyong He, Yuxiang Ji, Zhuoyue Tan, Liaoni Wu* | **Category: cs.CV**

**Keywords:** 扩散模型, 域泛化, 域适应, 目标检测, 跨域

**Comment:** Accepted by ICCV2025. arXiv admin note: text overlap with
  arXiv:2503.02101

> **TL;DR:** 本文提出了一种基于扩散模型的新方法，通过提取单步扩散中间特征、构建以对象为中心的辅助分支以及特征和对象级对齐，显著降低了推理成本，同时提高了域泛化和自适应检测的性能。

**AI_Comments:** 该论文的创新点在于有效利用扩散模型，通过提取单步扩散中间特征来大幅降低推理成本，并结合对象中心辅助分支和一致性损失，在统一框架下同时优化了检测器的适应性、泛化性和可迁移性。这种方法不仅提升了性能，还显著提高了效率，为跨域视觉感知任务提供了新的思路和强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检测器在训练和测试数据之间存在域间隙时性能会下降。尽管最近的方法将扩散模型应用于域泛化（DG）和域适应（DA）任务，但它们仍面临高昂的推理成本，并且未能充分利用扩散模型的能力。

**Method:** 本文提出通过从单步扩散过程中提取中间特征来提高特征收集和融合，从而将推理时间减少75%并增强源域性能（适应性）。通过应用带类别提示的框掩蔽图像构建以对象为中心的辅助分支，以提取鲁棒且域不变的特征。同时应用一致性损失来对齐辅助分支和普通分支，平衡适应性和泛化性，防止过拟合。在一个统一的框架内，通过在源域（用于DG）和未标记目标域（用于DA）上进行特征级和对象级对齐，引导标准检测器。

**Result:** 该方法在3个DA基准和5个DG基准上取得了有竞争力的结果。在COCO泛化基准上的实验表明，该方法在大的域偏移和低数据场景下保持显著优势并显示出卓越的效率。

**Conclusion:** 本文的工作展示了将扩散模型应用于域泛化和自适应检测任务的优越性，并为跨不同领域的视觉感知任务提供了宝贵的见解。

> **ai_Abstract:** 本文提出了一种利用扩散模型解决域泛化（DG）和域适应（DA）中检测器性能下降及推理成本高昂的问题。通过从单步扩散中提取中间特征，显著降低了推理时间并提升了源域性能。引入以对象为中心的辅助分支，结合一致性损失，增强了特征的鲁棒性和域不变性，平衡了泛化性。此外，在一个统一框架内，通过特征级和对象级对齐，引导标准检测器进行跨域检测。实验证明，该方法在多个DG和DA基准上表现出色，尤其在域偏移大和数据量少的情况下效率显著。

> **摘要翻译:** 检测器经常由于训练和测试数据之间的域间隙而导致性能下降。最近的方法探索了将扩散模型应用于域泛化（DG）和域适应（DA）任务，但仍然面临高昂的推理成本，并且尚未充分利用扩散模型的能力。我们提出通过从单步扩散过程中提取中间特征来解决这些问题，从而改进特征收集和融合，将推理时间减少75%，同时提高源域性能（即适应性）。然后，我们通过应用带类别提示的框掩蔽图像来构建一个以对象为中心的辅助分支，以提取鲁棒且域不变的特征，这些特征专注于对象。我们还应用一致性损失来对齐辅助分支和普通分支，平衡适应性和泛化性，同时防止过拟合并提高目标域性能（即泛化性）。此外，在一个统一的框架内，标准检测器通过在源域（用于DG）和未标记目标域（用于DA）上的特征级和对象级对齐，由扩散检测器引导，从而提高跨域检测性能（即可迁移性）。我们的方法在3个DA基准和5个DG基准上取得了有竞争力的结果。此外，在COCO泛化基准上的实验表明，我们的方法保持显著优势，并在大域偏移和低数据场景中显示出卓越的效率。我们的工作展示了将扩散模型应用于域泛化和自适应检测任务的优越性，并为跨不同领域的视觉感知任务提供了宝贵的见解。代码可在https://github.com/heboyong/Fitness-Generalization-Transferability 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [345] [Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling](https://arxiv.org/abs/2506.21045)
> *通过引导和调度提高基于扩散的图像编辑的保真度*

*Hansam Cho, Seoung Bum Kim* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 扩散模型, 图像编辑, 保真度, 可编辑性, 引导和调度

**Comment:** preprint

> **TL;DR:** 提出FGS方法，通过保真度引导和调度策略，在图像编辑中平衡可编辑性和保真度，显著提高保真度。

**AI_Comments:** 该论文提出了一种新颖的方法FGS，通过结合保真度引导和调度策略，有效地解决了扩散模型图像编辑中长期存在的保真度与可编辑性之间的矛盾。其创新性在于精细化地平衡了这两个关键指标，使得图像编辑既能实现大幅修改又能保留原始细节。方法的兼容性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 文本引导扩散模型在图像编辑中面临可编辑性和保真度之间的固有权衡，难以同时实现最佳效果。

**Method:** 提出Faithfulness Guidance and Scheduling (FGS) 方法。FGS通过引入保真度引导来加强输入图像信息的保存，并采用调度策略解决可编辑性和保真度之间的错位问题。

**Result:** 实验结果表明，FGS在保持可编辑性的同时实现了卓越的保真度，并且与多种编辑方法兼容，能够实现精确、高质量的图像编辑。

**Conclusion:** FGS有效解决了扩散模型图像编辑中可编辑性和保真度之间的权衡问题，显著提升了图像编辑的质量和精确性，并具有广泛的适用性。

> **ai_Abstract:** 本文提出了Faithfulness Guidance and Scheduling (FGS) 方法，旨在解决文本引导扩散模型在图像编辑中可编辑性与保真度之间的权衡问题。FGS通过引入保真度引导来增强对原始图像信息的保留，并采用调度策略来协调可编辑性和保真度。实验证明，FGS在保持良好可编辑性的同时显著提升了图像编辑的保真度，并且能够与多种编辑方法兼容，实现高质量的图像编辑。

> **摘要翻译:** 文本引导扩散模型已成为高质量图像合成的关键，实现了动态图像编辑。在图像编辑中，两个关键方面是可编辑性（决定修改程度）和保真度（反映未改变元素的保留程度）。然而，由于可编辑性和保真度之间固有的权衡，实现最佳结果具有挑战性。为了解决这个问题，我们提出了保真度引导和调度（FGS），它在对可编辑性影响最小的情况下增强保真度。FGS结合了保真度引导以加强输入图像信息的保存，并引入了调度策略以解决可编辑性和保真度之间的错位。实验结果表明，FGS在保持可编辑性的同时实现了卓越的保真度。此外，它与各种编辑方法的兼容性使得能够在不同任务中实现精确、高质量的图像编辑。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [348] [Class-Agnostic Region-of-Interest Matching in Document Images](https://arxiv.org/abs/2506.21055)
> *文档图像中类别无关的感兴趣区域匹配*

*Demin Zhang, Jiahao Lyu, Zhijie Shen, Yu Zhou* | **Category: cs.CV**

**Keywords:** RoI-Matching, 类别无关, 文档理解, Siamese网络, 交叉注意力

**Comment:** Accepted by ICDAR2025

> **TL;DR:** 本文定义了一个名为“类别无关感兴趣区域匹配”（RoI-Matching）的新任务，旨在灵活、高效、多粒度地匹配文档图像中的自定义区域。为此，论文构建了一个基准数据集RoI-Matching-Bench，并提出了一个名为RoI-Matcher的框架，该框架采用Siamese网络和交叉注意力层。实验证明其方法有效，并可作为未来研究的基线。

**AI_Comments:** 本文的创新点在于提出了一个全新的“类别无关感兴趣区域匹配”任务，这解决了现有文档分析方法在灵活性和用户定制方面的不足。其提出的基准数据集和RoI-Matcher框架为该领域的研究提供了有价值的起点和基线。该方法的“简单程序”特性也暗示了其潜在的实用性，但作为“基线”也表明未来可能存在进一步优化的空间。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文档分析解决方案（如文档布局分析和关键信息提取）仅适用于固定的类别定义和粒度，无法实现用户定制的灵活应用。

**Method:** 本文定义了一个名为“类别无关感兴趣区域匹配”（RoI-Matching）的新任务。为此，论文构建了一个基准数据集RoI-Matching-Bench，并提出了宏观和微观评估指标。此外，还提出了一个名为RoI-Matcher的新框架，该框架采用Siamese网络提取参考和目标文档的多级特征，并使用交叉注意力层整合和对齐不同领域中的相似语义。

**Result:** 实验表明，本文提出的方法以简单的步骤在RoI-Matching-Bench上是有效的。

**Conclusion:** 本文提出的方法可以作为RoI-Matching任务的基线，为进一步的研究奠定基础。

> **ai_Abstract:** 本文针对现有文档分析解决方案缺乏灵活性的问题，提出了一项名为“类别无关感兴趣区域匹配”（RoI-Matching）的新任务，旨在实现文档图像中自定义区域的灵活、高效、多粒度匹配。为此，研究构建了RoI-Matching-Bench基准数据集和相应的评估指标，并提出RoI-Matcher框架，该框架利用Siamese网络提取多级特征并通过交叉注意力层进行语义对齐。实验证明该方法有效，并可作为未来研究的基线。

> **摘要翻译:** 文档理解和分析因其广泛的应用而受到广泛关注。然而，现有的文档分析解决方案，例如文档布局分析和关键信息提取，仅适用于固定的类别定义和粒度，无法实现用户定制的灵活应用。因此，本文定义了一项名为“类别无关感兴趣区域匹配”（简称“RoI-Matching”）的新任务，旨在以灵活、高效、多粒度、开放集的方式匹配自定义区域。参考文档和目标文档图像的视觉提示被输入到我们的模型中，而输出是目标文档图像中对应的边界框。为了满足上述要求，我们构建了一个基准RoI-Matching-Bench，该基准根据真实世界条件设置了三个难度级别，并提出了宏观和微观指标进行评估。此外，我们还提出了一个新的框架RoI-Matcher，该框架采用Siamese网络提取参考和目标领域的多级特征，并采用交叉注意力层整合和对齐不同领域中的相似语义。实验表明，我们的方法以简单的步骤在RoI-Matching-Bench上是有效的，并可作为进一步研究的基线。代码可在https://github.com/pd162/RoI-Matching获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification](https://arxiv.org/abs/2506.21056)
> *SAMURAI：形状感知多模态三维物体识别检索*

*Dinh-Khoi Vo, Van-Loc Nguyen, Minh-Triet Tran, Trung-Nghia Le* | **Category: cs.CV**

**Keywords:** 3D物体检索, 多模态检索, 形状感知, CLIP, ROOMELSA

**Comment:** 

> **TL;DR:** SAMURAI是一种新的方法，它利用形状和语言线索从带遮罩的2D图像和文本中检索3D物体，并在ROOMELSA挑战中表现出色。

**AI_Comments:** SAMURAI的创新之处在于其混合方法，有效地将CLIP强大的语义理解与新颖的形状引导重排序机制相结合。通过预处理管道明确解决嘈杂遮罩和扭曲视角等挑战，增加了其实用性。其在ROOMELSA等挑战性基准测试中取得的有竞争力的性能表明了其在现实世界中进行鲁棒3D物体检索的潜力，尤其是在3D上下文有限的情况下。该论文强调了多模态融合的重要性，尤其是结合语言线索和经常被忽视的几何形状先验。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂的室内环境中，仅使用遮罩的2D图像和自然语言描述来检索3D物体面临巨大挑战，尤其是在ROOMELSA挑战中，由于缺乏完整的3D场景上下文、扭曲的视角、无纹理区域、模糊的语言提示和嘈杂的分割遮罩，这些挑战进一步加剧。

**Method:** 本文提出了SAMURAI框架，它将基于CLIP的语义匹配与从遮罩区域的二值轮廓导出的形状引导重排序相结合，并辅以鲁棒的多数投票策略。此外，还包含一个专门的预处理管道，通过提取最大连通分量和去除背景噪声来提高遮罩质量。该框架是一个利用语言和形状线索的混合检索系统。

**Result:** 在ROOMELSA私人测试集上取得了有竞争力的性能。

**Conclusion:** 研究结果强调了将形状先验与语言理解相结合对于鲁棒的开放世界3D物体检索的重要性。

> **ai_Abstract:** 本文针对在复杂的室内环境中，仅使用遮罩的2D图像和自然语言描述进行3D物体检索的挑战性问题（特别是在ROOMELSA挑战的限制下）提出了解决方案。所提出的SAMURAI是一种混合多模态检索框架，它结合了基于CLIP的语义匹配、基于二值轮廓的形状引导重排序以及多数投票策略。该框架还包含一个专门的预处理管道以增强遮罩质量。SAMURAI利用语言和形状线索，在ROOMELSA私人测试集上表现出有竞争力的性能，从而强调了将形状先验与语言理解相结合对于鲁健的开放世界3D物体检索的关键作用。

> **摘要翻译:** 在复杂的室内环境中，仅使用遮罩的2D图像和自然语言描述来检索3D物体，带来了巨大的挑战。ROOMELSA挑战限制了对完整3D场景上下文的访问，使推理物体外观、几何形状和语义变得复杂。扭曲的视角、无纹理的遮罩区域、模糊的语言提示以及嘈杂的分割遮罩加剧了这些挑战。为了解决这个问题，我们提出了SAMURAI：形状感知多模态三维物体识别检索。SAMURAI将基于CLIP的语义匹配与从遮罩区域的二值轮廓导出的形状引导重排序相结合，并辅以鲁棒的多数投票策略。一个专门的预处理管道通过提取最大连通分量和去除背景噪声来提高遮罩质量。我们的混合检索框架利用语言和形状线索，在ROOMELSA私人测试集上取得了有竞争力的性能。这些结果突出了将形状先验与语言理解相结合对于鲁棒的开放世界3D物体检索的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [352] [PoseMaster: Generating 3D Characters in Arbitrary Poses from a Single Image](https://arxiv.org/abs/2506.21076)
> *PoseMaster：从单张图像生成任意姿态的3D角色*

*Hongyu Yan, Kunming Luo, Weiyu Li, Yixun Liang, Shengming Li, Jingwei Huang, Chunchao Guo, Ping Tan* | **Category: cs.CV**

**Keywords:** 3D角色生成, 姿态控制, 单图像, 端到端, 骨骼

**Comment:** 

> **TL;DR:** PoseMaster是一个端到端框架，能从单张图像生成任意姿态的3D角色，解决了现有方法在姿态标准化和3D重建中产生的失真问题。

**AI_Comments:** 本文提出了一种创新的端到端3D角色生成框架PoseMaster，有效解决了现有方法中姿态标准化导致的图像失真和几何质量问题。其将姿态转换和3D生成统一的流式框架，以及利用3D骨骼进行姿态控制的策略是其主要创新点。此外，通过随机清空条件和构建高质量数据集，显著提升了模型的泛化能力和控制精度，对3D角色建模领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像基方法使用两个独立模型进行姿态标准化和3D重建，但在姿态标准化阶段容易因自遮挡和视角导致图像失真和质量下降，进而影响后续重建的几何质量。

**Method:** 提出PoseMaster，一个端到端可控的3D角色生成框架。它将姿态转换和3D角色生成统一到一个基于流的3D原生生成框架中。通过利用可动画角色的骨骼中的3D身体骨骼作为姿态条件，实现精确的任意姿态控制。训练时随机清空姿态条件和图像条件以提高姿态控制的有效性和泛化性。创建了一个高质量的姿态控制数据集，该数据集来源于真实的字符动画数据，使模型能够学习骨骼和蒙皮权重之间的隐式关系。

**Result:** PoseMaster在A姿态角色生成方面，无论是在定性还是定量评估中都优于当前的SOTA技术，并展示了其在实现任意姿态精确控制方面的强大能力。

**Conclusion:** PoseMaster通过其统一的框架和创新的姿态控制机制，显著提高了从单张图像生成高质量、任意姿态3D角色的效率和准确性，克服了现有方法的局限性。

> **ai_Abstract:** PoseMaster是一个创新的端到端框架，旨在解决从单张图像生成3D角色时，现有方法因姿态标准化导致图像失真和几何质量下降的问题。它通过将姿态转换和3D生成整合到统一的流式框架中，并利用3D骨骼进行精确姿态控制，同时通过条件随机清空和高质量数据集训练来增强泛化能力。实验证明PoseMaster在A姿态生成和任意姿态控制方面均超越了现有技术。

> **摘要翻译:** 3D角色在我们的日常娱乐中扮演着至关重要的角色。为了提高3D角色建模的效率，最近基于图像的方法使用两个独立的模型来实现A姿态角色的姿态标准化和3D重建。然而，这些方法在姿态标准化阶段容易因自遮挡和视角而产生扭曲和退化的图像，这进一步影响了后续重建过程的几何质量。为了解决这些问题，我们提出了PoseMaster，一个端到端可控的3D角色生成框架。具体来说，我们将姿态转换和3D角色生成统一到一个基于流的3D原生生成框架中。为了实现精确的任意姿态控制，我们提出利用可动画角色的骨架中存在的3D身体骨骼作为姿态条件。此外，考虑到多条件控制的特殊性，我们在训练期间随机清空姿态条件和图像条件，以提高姿态控制的有效性和泛化性。最后，我们创建了一个高质量的姿态控制数据集，该数据集来源于真实的字符动画数据，使模型能够学习骨骼和蒙皮权重之间的隐式关系。大量的实验表明，PoseMaster在A姿态角色生成方面，无论是在定性还是定量评估中都优于当前的最新技术，同时展示了其实现任意姿态精确控制的强大能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [355] [EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception](https://arxiv.org/abs/2506.21080)
> *EgoAdapt: 自适应多感官蒸馏与策略学习，实现高效的第一人称感知*

*Sanjoy Chowdhury, Subrata Biswas, Sayan Nag, Tushar Nagarajan, Calvin Murdock, Ishwarya Ananthabhotla, Yijun Qian, Vamsi Krishna Ithapu, Dinesh Manocha, Ruohan Gao* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 第一人称感知, 多感官蒸馏, 策略学习, 模型效率, 动作识别

**Comment:** Accepted at ICCV 2025

> **TL;DR:** EgoAdapt是一个框架，通过自适应的多感官蒸馏和策略学习，显著提高了第一人称感知任务的效率，同时保持或超越了最先进的性能。

**AI_Comments:** 这篇论文通过引入自适应多感官蒸馏和策略学习，为第一人称感知任务的效率提升提供了一个创新方案。其核心贡献在于平衡了模型性能与计算成本，使其在边缘设备或资源受限场景下的实际部署成为可能，具有重要的应用价值。该方法的可扩展性（适应不同任务的动作空间）也是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现代多感官第一人称感知模型计算成本高昂，难以在资源受限环境中部署。

**Method:** 提出EgoAdapt框架，通过自适应地执行跨模态蒸馏和策略学习，实现不同第一人称感知任务（如动作识别、说话人定位、行为预测）的高效推理。其策略模块可适应特定任务的动作空间。

**Result:** 在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个数据集上，GMACs减少高达89.09%，参数减少高达82.02%，能耗降低高达9.6倍，同时性能与SOTA模型持平或超越。

**Conclusion:** EgoAdapt通过自适应多感官蒸馏和策略学习，显著提高了第一人称感知任务的效率，使其更适合实际部署。

> **ai_Abstract:** EgoAdapt是一个新颖的框架，旨在解决多感官第一人称感知模型计算成本高的问题。它通过自适应跨模态蒸馏和策略学习，显著提高了第一人称动作识别、说话人定位和行为预测等任务的推理效率。实验证明，EgoAdapt在保持甚至超越现有最佳性能的同时，大幅降低了计算资源消耗，使其更适用于资源受限的实际部署。

> **摘要翻译:** 现代感知模型，特别是为多感官第一人称任务设计的模型，已取得了卓越的性能，但通常伴随着巨大的计算成本。这些高要求对实际部署构成了挑战，尤其是在资源受限的环境中。在本文中，我们引入了EgoAdapt，一个自适应执行跨模态蒸馏和策略学习的框架，旨在实现不同第一人称感知任务（包括第一人称动作识别、主动说话人定位和行为预测）的高效推理。我们提出的策略模块可适应特定任务的动作空间，使其具有广泛的适用性。在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个具有挑战性的第一人称数据集上的实验结果表明，我们的方法显著提高了效率，将GMACs降低了高达89.09%，参数降低了高达82.02%，能耗降低了高达9.6倍，同时性能与相应的最先进模型持平，并且在许多情况下表现更优。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [358] [ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching](https://arxiv.org/abs/2506.21091)
> *ESMStereo: 增强型 ShuffleMixer 视差上采样，用于实时高精度立体匹配*

*Mahmoud Tahmasebi, Saif Huq, Kevin Meehan, Marion McAfee* | **Category: cs.CV**

**Keywords:** 立体匹配, 视差上采样, 实时, Shuffle Mixer, 深度学习

**Comment:** Under peer review

> **TL;DR:** ESMStereo提出了一种增强型Shuffle Mixer (ESM)来解决实时立体匹配中精度与速度的权衡问题，通过在小尺度代价体上进行特征融合和细化，实现了实时高精度视差估计。

**AI_Comments:** ESMStereo 的创新在于其提出的 ESM 模块，巧妙地解决了小尺度代价体在实时立体匹配中精度不足的问题。通过有效的特征融合和精炼机制，它在保持实时性能的同时显著提升了视差估计的准确性，这对于自动驾驶等需要高精度和低延迟的应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在计算机视觉中，开发兼具高精度和实时性的深度学习立体匹配模型是一个重大挑战。大型代价体计算量大，难以实时；小型代价体虽然实时，但精度不足。

**Method:** 本文提出了增强型 Shuffle Mixer (ESM) 来缓解小尺度代价体带来的信息丢失。ESM 通过将主要特征集成到视差上采样单元中来恢复关键细节，快速从初始视差估计中提取特征并与图像特征融合。这些特征通过混洗和层分割进行混合，并通过紧凑的特征引导沙漏网络进行细化，以恢复更详细的场景几何。ESM 专注于具有大感受野和低计算成本的局部上下文连接。

**Result:** ESMStereo 实现了实时高精度视差图重建。其紧凑版本在高端 GPU 上达到 116 FPS 的推理速度，在 AGX Orin 上达到 91 FPS。

**Conclusion:** ESMStereo 通过其增强型 Shuffle Mixer (ESM) 有效解决了实时立体匹配中精度和速度的权衡问题，实现了在保持高精度的同时达到实时性能的目标。

> **ai_Abstract:** ESMStereo 提出了一种名为增强型 Shuffle Mixer (ESM) 的方法，旨在解决深度学习立体匹配中实时性与高精度难以兼顾的问题。针对大型代价体计算量大、小型代价体信息不足的挑战，ESM 通过在视差上采样单元中集成和融合初始视差与图像特征，并利用混洗、层分割及紧凑的沙漏网络进行细化，有效恢复了小尺度代价体中的关键细节。该方法在保证低计算成本的同时，实现了高精度的实时视差图重建，在高端 GPU 上达到 116 FPS，在 AGX Orin 上达到 91 FPS。

> **摘要翻译:** 立体匹配已成为现代自主系统日益重要的组成部分。开发兼具高精度和实时性的深度学习立体匹配模型仍然是计算机视觉领域的一个主要挑战。在基于代价体的立体匹配领域，准确的视差估计严重依赖于大规模代价体。然而，这些大规模代价体存储了大量冗余信息，并且需要计算密集型的聚合单元进行处理和回归，从而无法实现实时性能。相反，小规模代价体加上轻量级聚合单元为实时性能提供了一条有前景的路线，但缺乏足够的信息来确保高精度的视差估计。为了解决这个挑战，我们提出了增强型 Shuffle Mixer (ESM) 来缓解与小规模代价体相关的信息丢失。ESM 通过将主要特征集成到视差上采样单元中来恢复关键细节。它快速从初始视差估计中提取特征并将其与图像特征融合。这些特征通过混洗和层分割进行混合，然后通过紧凑的特征引导沙漏网络进行细化，以恢复更详细的场景几何。ESM 专注于具有大感受野和低计算成本的局部上下文连接，从而实现了实时高精度视差图的重建。ESMStereo 的紧凑版本在高端 GPU 上实现了 116 FPS 的推理速度，在 AGX Orin 上实现了 91 FPS。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [360] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
> *HumanOmniV2: 从理解到基于上下文的全模态推理*

*Qize Yang, Shimin Yao, Weixuan Chen, Shenghao Fu, Detao Bai, Jiaxing Zhao, Boyuan Sun, Bowen Yin, Xihan Wei, Jingren Zhou* | **Category: cs.CV, cs.CL**

**Keywords:** 多模态推理, 强化学习, 大型语言模型, 上下文理解, 全模态基准

**Comment:** 

> **TL;DR:** 本文提出了HumanOmniV2，一个利用强化学习和多维度奖励机制（包括上下文、格式、准确性和逻辑奖励）来提升多模态大型语言模型推理能力的方法，旨在解决现有模型中上下文理解不足和捷径问题，并引入了一个新的全模态基准测试IntentBench。

**AI_Comments:** 这项工作通过引入多维度奖励机制，特别是LLM判断的上下文和逻辑奖励，为强化学习在多模态推理中的应用提供了新思路，有效解决了现有模型的上下文理解不足和捷径问题。新提出的IntentBench基准也对未来研究提供了有价值的评估工具。其创新性在于将LLM的能力用于指导RL的奖励设计，从而更精细地优化多模态推理过程。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（LLMs）需要深入理解和解释人类意图，这要求精细的推理能力。尽管强化学习（RL）在增强LLMs推理能力方面显示出潜力，但将其适应多模态数据和格式仍面临挑战。现有多模态推理模型存在全局上下文理解不足和捷径问题，导致模型错误解释上下文或忽略关键线索。

**Method:** 为了解决现有问题，论文强调模型需清晰理解多模态输入中的全局上下文。方法包括：1) 引入由大型语言模型（LLM）判断的上下文奖励，并结合格式和准确性奖励，以确保准确解释多模态上下文信息。2) 利用LLM评估逻辑奖励，以提高复杂推理能力，判断推理过程是否成功整合多模态信息与逻辑方法。3) 提出一个新的推理全模态基准测试IntentBench，用于评估模型理解复杂人类意图和情感的能力。

**Result:** 所提出的方法在多个全模态基准测试中，与其它开源全模态模型相比，展现出更高的性能。

**Conclusion:** 本文提出了HumanOmniV2框架，通过引入由LLM判断的多种奖励机制（上下文、格式、准确性和逻辑奖励），有效解决了多模态推理中全局上下文理解不足和捷径问题。同时，推出的IntentBench基准为评估模型理解复杂人类意图的能力提供了新工具。实验结果证明了该方法在全模态推理上的优越性。

> **ai_Abstract:** 本文提出了HumanOmniV2，一个旨在增强多模态大语言模型推理能力的方法。它通过引入上下文奖励、格式奖励、准确性奖励和逻辑奖励（由LLM判断）来解决现有模型中全局上下文理解不足和捷径问题。此外，该研究还推出了一个新的全模态基准测试IntentBench，用于评估模型对复杂人类意图和情感的理解。实验结果表明，HumanOmniV2在多个全模态基准测试中优于其他开源模型。

> **摘要翻译:** 随着多模态大型语言模型的快速发展，深入理解和解释人类意图的能力已成为一项关键能力，这需要详细而周密的推理。在最近的研究中，强化学习（RL）已显示出增强大型语言模型（LLM）推理能力的潜力。然而，将RL适应多模态数据和格式所面临的挑战在很大程度上仍未解决。在本文中，我们指出了现有多模态推理模型中的两个问题：全局上下文理解不足和捷径问题。当模型错误地解释多模态上下文，导致不正确的答案时，就会发生上下文理解不足。当模型忽略多模态输入中的关键线索，直接回答查询而不考虑多模态信息时，就会出现捷径问题。为了解决这些问题，我们强调模型需要清晰地理解多模态输入中的全局上下文进行推理。这种全局上下文理解可以有效地防止模型忽略关键的多模态线索，并确保彻底的推理过程。为了确保准确解释多模态上下文信息，我们实施了一个由大型语言模型判断的上下文奖励，以及格式和准确性奖励。此外，为了提高复杂的推理能力，我们利用LLM评估逻辑奖励，判断推理过程是否成功地将多模态信息与逻辑方法相结合。我们还引入了一个推理全模态基准测试IntentBench，旨在评估模型理解复杂人类意图和情感的能力。我们提出的方法在多个全模态基准测试中，与其它开源全模态模型相比，展现出更高的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [361] [OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography](https://arxiv.org/abs/2506.21101)
> *甲骨融合：以结构约束语义字体辅助甲骨文释读*

*Caoshuo Li, Zengmao Ding, Xiaobin Hu, Bang Li, Donghao Luo, AndyPian Wu, Chaoyang Wang, Chengjie Wang, Taisong Jin, SevenShu, Yunsheng Wu, Yongge Liu, Rongrong Ji* | **Category: cs.CV**

**Keywords:** 甲骨文释读, 语义字体, 多模态大语言模型, 结构约束, 甲骨结构向量融合

**Comment:** Accepted to ICCV 2025

> **TL;DR:** OracleFusion是一个两阶段的语义字体框架，利用多模态大语言模型和结构向量融合技术，辅助甲骨文释读，显著提升了可读性和美观性，并能为专家提供未见字符的洞察。

**AI_Comments:** 该论文提出了一种创新的方法，将先进的AI模型（MLLM）与结构约束相结合，用于甲骨文的辅助释读。其创新之处在于结合了视觉分析和语义字体生成，以解决古文字释读中的复杂结构和抽象意象问题。通过提供视觉增强的表示和专家级洞察，该工具对甲骨文研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 甲骨文作为最古老的文字之一，承载着古代文明的文化记录和思想表达。然而，已发现的约4500个甲骨文中有近1600个已被释读，剩余未释读的字符结构复杂、意象抽象，给释读带来了巨大挑战。

**Method:** 本文提出了一个名为OracleFusion的新型两阶段语义字体框架。第一阶段，该方法利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）分析甲骨文的字形结构并进行关键组件的视觉定位。第二阶段，引入甲骨结构向量融合（OSVF），结合字形结构约束和字形维护约束，以确保生成语义丰富的矢量字体。

**Result:** 广泛的定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形维护方面优于最先进的基线模型，显著增强了可读性和美学质量。此外，OracleFusion能为未见甲骨字符提供专家级的洞察。

**Conclusion:** OracleFusion是一个有价值的工具，能够推进甲骨文的释读工作，通过提供视觉增强的表示来辅助专家，并为未见字符提供专家级的洞察。

> **ai_Abstract:** 本文提出了一种名为OracleFusion的新型两阶段语义字体框架，旨在解决甲骨文（OBS）释读的挑战。该框架首先利用多模态大语言模型（MLLM）分析OBS字符的字形结构并进行视觉定位，然后通过甲骨结构向量融合（OSVF）生成受结构约束的语义丰富矢量字体。实验证明，OracleFusion在语义、视觉吸引力和字形维护方面优于现有模型，显著提高了OBS的可读性和美学质量，并能为专家提供未见字符的洞察，是推进OBS释读的宝贵工具。

> **摘要翻译:** 甲骨文作为最早的古老语言之一，承载着古代文明的文化记录和思想表达。尽管已发现大约4500个甲骨文字符，但只有约1600个已被释读。剩余未释读的字符，其复杂的结构和抽象的意象，给解释带来了巨大的挑战。为了解决这些挑战，本文提出了一种新颖的两阶段语义字体框架，命名为OracleFusion。在第一阶段，该方法利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）来分析甲骨文字符的字形结构并执行关键组件的视觉定位。在第二阶段，我们引入了甲骨结构向量融合（OSVF），结合字形结构约束和字形维护约束，以确保准确生成语义丰富的矢量字体。这种方法保留了字形结构的客观完整性，提供了视觉增强的表示，辅助专家释读甲骨文。广泛的定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形维护方面优于最先进的基线模型，显著增强了可读性和美学质量。此外，OracleFusion为未见甲骨文字符提供了专家般的见解，使其成为推进甲骨文释读工作的宝贵工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection](https://arxiv.org/abs/2506.21109)
> *突破权衡界限：紧凑而有效的遥感变化检测*

*Luosheng Xu, Dalin Zhang, Zhaohui Song* | **Category: cs.CV, cs.LG**

**Keywords:** 遥感变化检测, 轻量级模型, FlickCD, 计算效率, 性能-资源权衡

**Comment:** 12 pages

> **TL;DR:** 本文提出了一种名为FlickCD的轻量级模型，用于遥感变化检测，它在显著降低计算和存储开销的同时，保持了最先进的性能或仅有微小精度损失。

**AI_Comments:** 本文的创新点在于提出了FlickCD模型，它通过独特的设计（EDM和Local-Global Fusion Blocks）成功地在遥感变化检测领域实现了计算效率和检测精度之间的卓越平衡。其重要性体现在为资源受限环境（如星载处理）提供了切实可行的解决方案，挑战了当前深度学习模型盲目追求复杂度的趋势。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在遥感变化检测中面临模型复杂性和计算需求增加但精度提升不显著的问题，尤其是在星载处理中需要高效且资源消耗小的模型。

**Method:** 本文提出了FlickCD模型，它包含一个增强差异模块（EDM），用于放大关键特征差异并抑制无关变化，从而降低后续变化解码器的计算成本。此外，FlickCD解码器结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）来高效捕获多尺度语义信息，保留粗粒度和细粒度变化。

**Result:** 在四个基准数据集上的广泛实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最先进（SOTA）的性能或仅导致微小的（<1% F1）精度权衡。

**Conclusion:** FlickCD模型成功地在遥感变化检测中实现了性能与资源消耗之间的有效权衡，为轻量级、高效率的模型提供了解决方案，特别适用于资源受限的场景如星载处理。

> **ai_Abstract:** 本研究针对遥感变化检测领域深度学习模型日益增长的复杂性和资源消耗问题，提出了一种名为FlickCD的轻量级模型。FlickCD通过引入增强差异模块（EDM）来高效处理特征差异，并利用局部-全局融合块（包含SWSA和EGSA）来捕获多尺度语义信息。实验证明，FlickCD在显著减少计算和存储开销的同时，仍能保持最先进的性能或仅有极小的精度损失，尤其适用于资源受限的星载处理场景。

> **摘要翻译:** 遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，它能及时、准确、大规模地洞察动态景观变化。虽然深度学习彻底改变了变化检测，但现代模型日益增长的复杂性和计算需求并未必然带来显著的精度提升。本研究没有追随这一趋势，而是探索了一种更有效的方法，专注于在最小化资源消耗的同时保持高精度的轻量级模型，这是星载处理的基本要求。为此，我们提出了FlickCD，意为快速一瞥即可获得出色结果，它突破了性能-资源权衡的界限。FlickCD引入了一个增强差异模块（EDM），以放大时间阶段之间的关键特征差异，同时抑制光照和天气变化等无关变异，从而降低后续变化解码器中的计算成本。此外，FlickCD解码器结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）来高效捕获多尺度语义信息，保留粗粒度和细粒度变化。在四个基准数据集上的广泛实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最先进（SOTA）的性能或仅导致微小的（<1% F1）精度权衡。实现代码已在https://github.com/xulsh8/FlickCD公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [366] [IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes](https://arxiv.org/abs/2506.21116)
> *IPFormer-VideoLLM：增强多镜头场景的多模态视频理解*

*Yujia Liang, Jile Jiao, Zhicheng Wang, Xuetao Feng, Zixuan Ye, Yuan Wang, Hao Lu* | **Category: cs.CV, cs.AI**

**Keywords:** 视频大语言模型, 多镜头场景, 实例级特征, 数据集, 视频理解

**Comment:** 

> **TL;DR:** IPFormer-VideoLLM通过引入新的数据集MultiClip-Bench和IPFormer-VideoLLM模型，解决了现有VideoLLM在多镜头场景中理解能力不足的问题，显著提升了多场景视频理解性能。

**AI_Comments:** 该论文的创新点在于同时解决了多镜头视频理解的数据和模型两方面问题。通过构建专门的MultiClip-Bench数据集，弥补了现有数据集在多镜头标注上的不足，为多镜头场景的训练和评估提供了基础。同时，IPFormer-VideoLLM模型通过注入实例级特征作为提示，有效地聚合了跨场景的实例信息，解决了现有模型在处理实例身份连续性方面的挑战。这种数据和模型协同创新的方法，使其在多场景视频理解方面取得了显著进展，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频大语言模型（VideoLLMs）在处理多镜头场景（如具有不同摄像机角度或场景变化的视频片段）时表现不佳，导致实例身份遗忘和关键帧忽略等问题。作者将这一挑战归因于现有数据集中缺乏多镜头标注。

**Method:** 首先，引入了一个名为MultiClip-Bench的新数据集，该数据集具有密集的描述和针对多镜头场景的基于指令的问答对。其次，分析发现当前模型以离散或有损的方式编码实例特征，可能丢失身份信息，因此提出了IPFormer-VideoLLM模型。该模型的关键思想是通过高效的基于注意力的连接器，将实例级特征作为实例提示注入，从而聚合跨场景的实例特定信息。

**Result:** 实验证明，所提出的数据集和模型不仅显著增强了多场景视频理解能力，而且在各种视频基准测试中也表现出明显的优势。

**Conclusion:** 本文通过引入专为多镜头场景设计的新数据集和新模型IPFormer-VideoLLM，有效解决了现有VideoLLM在复杂多镜头场景理解中的局限性，显著提升了视频理解性能。

> **ai_Abstract:** 本文针对现有视频大语言模型（VideoLLMs）在多镜头场景理解中表现不佳的问题，提出了两项主要贡献：一是创建了新的多镜头场景数据集MultiClip-Bench，包含密集的描述和问答对，以弥补现有数据集中多镜头标注的不足；二是开发了IPFormer-VideoLLM模型，该模型通过注意力连接器注入实例级特征作为提示，有效聚合跨场景的实例信息，解决了现有模型在实例特征编码上的缺陷。实验证明，所提出的数据集和模型显著提升了多场景视频理解能力，并在多个视频基准上表现出色。

> **摘要翻译:** 视频大语言模型（VideoLLMs）展现出卓越的理解能力，但在处理多镜头场景时（例如，具有不同摄像机角度或场景变化的视频片段）却发现它们力不从心。这一挑战可能导致诸如实例身份遗忘和关键帧忽略等问题。在这项工作中，我们首先将这一挑战归因于现有数据集中缺乏多镜头标注，因此我们引入了一个名为MultiClip-Bench的新数据集，该数据集具有密集的描述和专门为多镜头场景定制的基于指令的问答对。我们凭经验发现，训练集显著提升了多镜头性能，而测试基准则为模型在多镜头场景中的能力提供了可靠的衡量标准。通过进一步分析并发现当前模型仅以离散或有损的方式编码实例特征，存在丢失身份信息的风险，我们随后贡献了一个新模型IPFormer-VideoLLM。其核心思想是通过高效的基于注意力的连接器，将实例级特征作为实例提示注入。这使得跨场景的实例特定信息得以聚合。实验表明，我们提出的数据集和模型不仅显著增强了多场景视频理解能力，而且在各种视频基准测试中也提供了独特的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization](https://arxiv.org/abs/2506.21117)
> *CL-Splats：基于局部优化的三维高斯泼溅持续学习*

*Jan Ackermann, Jonas Kulhanek, Shengqu Cai, Haofei Xu, Marc Pollefeys, Gordon Wetzstein, Leonidas Guibas, Songyou Peng* | **Category: cs.CV**

**Keywords:** 持续学习, 高斯泼溅, 局部优化, 3D重建, 动态场景

**Comment:** ICCV 2025, Project Page: https://cl-splats.github.io

> **TL;DR:** CL-Splats是一种增量更新高斯泼溅三维表示的方法，通过变化检测和局部优化实现高效更新和高质量重建，适用于动态3D环境。

**AI_Comments:** 本文的创新点在于将变化检测与局部优化相结合，应用于高斯泼溅的持续学习，显著降低了动态场景更新的计算成本，并提高了重建质量。其支持历史状态恢复的功能也为未来的场景分析应用提供了潜力。这对于需要实时、高效3D场景表示的应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在动态三维环境中，精确地随时间更新场景表示对于机器人、混合现实和具身AI应用至关重要。随着场景的演变，需要高效的方法来整合变化，以保持最新、高质量的重建，同时避免重新优化整个场景的计算开销。

**Method:** 本文提出了CL-Splats，它从稀疏场景捕获中增量更新基于高斯泼溅的三维表示。CL-Splats集成了一个鲁棒的变化检测模块，该模块能分割场景中更新和静态的组件，从而实现聚焦的局部优化，避免不必要的重新计算。此外，CL-Splats支持存储和恢复先前的场景状态。

**Result:** 广泛的实验表明，CL-Splats实现了高效更新，并且重建质量优于现有技术。

**Conclusion:** CL-Splats为未来3D场景重建任务中的实时适应奠定了坚实的基础。

> **ai_Abstract:** CL-Splats是一种用于动态3D环境中持续学习高斯泼溅三维表示的方法。它通过引入一个鲁棒的变化检测模块来识别场景中的更新和静态部分，从而实现聚焦的局部优化，避免了对整个场景的重新计算，提高了更新效率和重建质量。该方法还支持存储和恢复场景历史状态，为实时3D场景重建提供了新途径。

> **摘要翻译:** 在动态三维环境中，随时间准确更新场景表示对于机器人、混合现实和具身AI应用至关重要。随着场景的演变，需要高效的方法来整合变化，以保持最新、高质量的重建，同时避免重新优化整个场景的计算开销。本文介绍了CL-Splats，它从稀疏场景捕获中增量更新基于高斯泼溅的三维表示。CL-Splats集成了一个鲁棒的变化检测模块，该模块能分割场景中更新和静态的组件，从而实现聚焦的局部优化，避免不必要的重新计算。此外，CL-Splats支持存储和恢复先前的场景状态，有助于时间分割和新的场景分析应用。我们的广泛实验表明，CL-Splats实现了高效更新，并且重建质量优于现有技术。这为未来三维场景重建任务中的实时适应奠定了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [370] [Learning to See in the Extremely Dark](https://arxiv.org/abs/2506.21132)
> *在极暗环境下学习可见*

*Hai Jiang, Binhao Guan, Zhen Liu, Xiaohong Liu, Jian Yu, Zheng Liu, Songchen Han, Shuaicheng Liu* | **Category: cs.CV**

**Keywords:** 低光增强, RAW图像, 扩散模型, 数据合成, 极暗场景

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 针对极暗场景下（低至0.0001 lux）学习型低光RAW图像增强方法因缺乏数据集而受限的问题，本文提出了一种配对数据合成管线，生成了大规模的SIED数据集，并提出了一种基于扩散模型的框架，结合自适应光照校正模块（AICM）和色彩一致性损失，有效提升了极低信噪比RAW输入的图像质量。

**AI_Comments:** 本文的创新点在于通过合成数据解决了极暗场景下图像增强的数据稀缺性问题，并提出了一个专门针对此类挑战性条件优化的扩散模型。SIED数据集的创建是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型方法在极低光照（低至0.0001 lux）的极暗场景下的RAW图像增强能力尚未被充分探索，主要原因是缺乏相应的训练数据集。

**Method:** 本文提出了一种配对数据合成管线，能够生成在0.01-0.1 lux、0.001-0.01 lux和0.0001-0.001 lux三个精确照度范围内的校准良好的极低光RAW图像，并结合高质量sRGB参考图像构建了大规模的SIED数据集。此外，本文提出了一种基于扩散模型的框架，利用扩散模型的生成能力和内在去噪特性来从极低信噪比的RAW输入中恢复视觉上令人满意的结果，并引入了自适应光照校正模块（AICM）和色彩一致性损失以确保准确的曝光校正和色彩恢复。

**Result:** 在所提出的SIED数据集和公开基准上的大量实验证明了本文方法的有效性。

**Conclusion:** 本文提出的数据合成管线和基于扩散模型的方法能够有效解决极暗场景下RAW图像增强的数据稀缺问题，并显著提升图像的视觉质量。

> **ai_Abstract:** 本文针对极暗场景下低光RAW图像增强中数据集缺乏的问题，提出了一种创新的配对数据合成管线，构建了大规模的SIED数据集。在此基础上，提出了一种基于扩散模型的框架，该框架结合了自适应光照校正模块（AICM）和色彩一致性损失，能够有效地从极低信噪比的RAW输入中恢复高质量的图像。实验结果验证了所提方法的有效性。

> **摘要翻译:** 学习型方法在低光RAW图像增强方面取得了可喜的进展，但其在环境照度低至0.0001 lux的极暗场景中的能力仍有待探索，原因是缺乏相应的数据集。为此，我们提出了一种配对数据合成管线，能够生成在0.01-0.1 lux、0.001-0.01 lux和0.0001-0.001 lux三个精确照度范围内的校准良好的极低光RAW图像，并结合高质量sRGB参考图像，构成了一个名为See-in-the-Extremely-Dark (SIED) 的大规模配对数据集，用于评估低光RAW图像增强方法。此外，我们提出了一种基于扩散模型的框架，该框架利用扩散模型的生成能力和内在去噪特性，从极低信噪比的RAW输入中恢复视觉上令人满意的结果，其中引入了自适应光照校正模块（AICM）和色彩一致性损失，以确保准确的曝光校正和色彩恢复。在所提出的SIED数据集和公开基准上的大量实验证明了我们方法的有效性。代码和数据集可在https://github.com/JianghaiSCU/SIED获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
> *Logios：一个开源的希腊语多音素光学字符识别系统*

*Perifanos Konstantinos, Goutsos Dionisis* | **Category: cs.CV, cs.CL**

**Keywords:** 光学字符识别, 希腊语多音素, 深度学习, 开源, 文本数字化

**Comment:** 

> **TL;DR:** Logios是一个开源的希腊语多音素OCR系统，结合了卷积层和循环层，提高了识别准确性和效率。

**AI_Comments:** 该论文的创新之处在于其专门针对希腊语多音素文本的OCR系统设计，并结合了深度学习中的卷积层和循环层来解决这一特定挑战。其开源性质极大地促进了学术研究和应用发展，为希腊语文献的数字化提供了重要工具。

<details>
  <summary>Details</summary>

**Motivation:** 旨在克服传统OCR方法在处理希腊语多音素文本时的局限性，提高识别准确性和效率。

**Method:** 结合卷积层进行特征提取和循环层进行序列学习，以处理希腊语多音素文字的独特挑战。

**Result:** 显著提高了准确性和效率，并以开源库形式发布了底层模型，OCR平台可供学术使用。

**Conclusion:** Logios系统成功地为希腊语多音素文本提供了一个高准确度和效率的OCR解决方案，并且是开源的，有利于学术界使用和发展。

> **ai_Abstract:** 本文提出了Logios，一个开源的希腊语多音素光学字符识别（OCR）系统。该系统结合了卷积层和循环层，有效处理希腊语多音素文本的复杂性，显著提升了识别的准确性和效率。其底层模型已开源，平台可供学术使用。

> **摘要翻译:** 在本文中，我们介绍了一个光学字符识别（OCR）系统，该系统专门设计用于希腊语多音素文本的准确识别和数字化。通过利用卷积层进行特征提取和循环层进行序列学习的综合优势，我们的系统解决了希腊语多音素文字带来的独特挑战。这种方法旨在克服传统OCR方法的局限性，在准确性和效率方面提供了显著的改进。我们以开源库的形式发布了底层模型，并使我们的OCR平台可供学术使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [372] [YOLO-FDA: Integrating Hierarchical Attention and Detail Enhancement for Surface Defect Detection](https://arxiv.org/abs/2506.21135)
> *YOLO-FDA：集成层级注意力与细节增强的表面缺陷检测*

*Jiawei Hu* | **Category: cs.CV**

**Keywords:** 表面缺陷检测, YOLO-FDA, 细节增强, 注意力机制, 特征融合

**Comment:** 14 pages, 6 figures. Submitted to The 8th Chinese Conference on
  Pattern Recognition and Computer Vision

> **TL;DR:** YOLO-FDA是一种新的基于YOLO的检测框架，通过细节增强和注意力引导的特征融合，解决了工业表面缺陷检测中现有方法冗余特征、细节敏感度有限和多尺度鲁棒性差的问题，并在基准数据集上超越了现有SOTA方法。

**AI_Comments:** 该论文提出的YOLO-FDA框架在解决工业表面缺陷检测的挑战方面具有创新性。其核心贡献在于结合了细粒度细节增强和注意力引导的特征融合，特别是DDFM模块和两种新型注意力融合策略（AC和CAF）的设计，有效提升了模型对精细缺陷的识别能力和多尺度鲁棒性。这对于实际工业应用中高精度、高鲁棒性的缺陷检测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 工业场景中的表面缺陷检测至关重要且技术要求高，因为缺陷类型多样、形状尺寸不规则、要求精细且材质纹理复杂。尽管基于AI的检测器有所改进，但现有方法常存在特征冗余、细节敏感度有限以及多尺度条件下鲁棒性差的问题。

**Method:** 本文提出了YOLO-FDA，一个新颖的基于YOLO的检测框架，集成了细粒度细节增强和注意力引导的特征融合。具体来说，采用BiFPN风格的架构来加强YOLOv5骨干网络内的双向多级特征聚合。为更好地捕获精细结构变化，引入了细节方向融合模块（DDFM），该模块在第二低层引入定向非对称卷积以丰富空间细节，并将第二低层与低级特征融合以增强语义一致性。此外，提出了两种新颖的基于注意力的融合策略：注意力加权拼接（AC）和跨层注意力融合（CAF），以改善上下文表示并减少特征噪声。

**Result:** 在基准数据集上的大量实验表明，YOLO-FDA在各种缺陷类型和尺度下，在准确性和鲁棒性方面始终优于现有的最先进方法。

**Conclusion:** YOLO-FDA通过创新的细节增强和注意力引导的特征融合策略，有效解决了工业表面缺陷检测中的挑战，并在准确性和鲁棒性上达到了领先水平，证明了其在实际应用中的潜力。

> **ai_Abstract:** YOLO-FDA是一个针对工业表面缺陷检测提出的新型YOLO框架。它旨在解决现有方法在处理多变缺陷时面临的特征冗余、细节敏感度不足和鲁棒性差的问题。通过采用BiFPN风格的特征聚合、引入DDFM模块增强细节捕获，以及提出AC和CAF两种注意力融合策略，YOLO-FDA显著提升了上下文表示并降低了特征噪声。实验证明，该方法在准确性和鲁棒性上均超越了现有SOTA方法。

> **摘要翻译:** 工业场景中的表面缺陷检测既关键又技术要求高，因为缺陷类型广泛多变、形状和尺寸不规则、精细化要求以及复杂的材料纹理。尽管近期基于AI的检测器取得了进展，提高了性能，但现有方法通常存在特征冗余、细节敏感度有限以及多尺度条件下鲁棒性弱的问题。为了应对这些挑战，我们提出了YOLO-FDA，一个新颖的基于YOLO的检测框架，它集成了细粒度细节增强和注意力引导的特征融合。具体来说，我们采用了一种BiFPN风格的架构来加强YOLOv5骨干网络内的双向多级特征聚合。为了更好地捕获精细结构变化，我们引入了一个细节方向融合模块（DDFM），该模块在第二低层引入定向非对称卷积以丰富空间细节，并将第二低层与低级特征融合以增强语义一致性。此外，我们提出了两种新颖的基于注意力的融合策略，即注意力加权拼接（AC）和跨层注意力融合（CAF），以改善上下文表示并减少特征噪声。在基准数据集上的大量实验表明，YOLO-FDA在各种缺陷类型和尺度下，在准确性和鲁棒性方面始终优于现有的最先进方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [Tree-based Semantic Losses: Application to Sparsely-supervised Large Multi-class Hyperspectral Segmentation](https://arxiv.org/abs/2506.21150)
> *基于树的语义损失：应用于稀疏监督的大规模多类别高光谱分割*

*Junwen Wang, Oscar Maccormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren* | **Category: cs.CV**

**Keywords:** 语义损失, 高光谱分割, 树结构, 稀疏监督, 分布外检测

**Comment:** 

> **TL;DR:** 该研究引入了两种基于树的语义损失函数，利用标签的层次结构，以提高在稀疏标注的大规模多类别高光谱分割任务中的性能，并能有效检测分布外像素。

**AI_Comments:** 本文的创新点在于引入了基于树的语义损失函数，有效地利用了标签的层次结构，解决了传统损失函数对所有错误同等惩罚而忽略类间语义的问题。这对于处理类别众多且关系复杂的生物医学高光谱图像分割任务具有重要意义。此外，该方法能够检测分布外像素，增加了其实用性和鲁棒性，在实际外科应用中具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有生物医学分割任务的学习方法对所有错误同等惩罚，未能利用标签空间中的类间语义信息，尤其是在处理大规模、类别细微差异的高光谱图像分割时，这限制了高光谱成像在手术应用中的潜力。

**Method:** 本文提出了两种基于树的语义损失函数，这些函数利用了标签的层次组织结构。这些损失函数被整合到一种处理稀疏、无背景标注的训练方法中。

**Result:** 该方法在包含107个类别、按临床定义语义树结构组织的高光谱图像稀疏标注数据集上达到了最先进的性能。此外，该方法在不损害分布内像素分割性能的情况下，还能有效检测分布外（OOD）像素。

**Conclusion:** 基于树的语义损失函数能够有效利用标签的层次结构，显著提升大规模多类别高光谱分割的性能，并增强了对分布外像素的检测能力。

> **ai_Abstract:** 该论文针对大规模多类别高光谱图像分割中现有方法未能利用类间语义信息的问题，提出了两种基于树的语义损失函数。这些损失函数利用标签的层次结构，并被整合到处理稀疏标注的训练框架中。实验证明，该方法在包含107个类别的临床定义高光谱数据集上达到了最先进的性能，并能有效识别分布外像素，同时保持对分布内像素的分割精度。

> **摘要翻译:** 高光谱成像（HSI）在外科应用中展现出巨大潜力，能够提供超越肉眼所能感知的生物组织差异的详细信息。目前正在进行精细的标注工作，以训练视觉系统区分大量细微变化的类别。然而，生物医学分割任务中常用的学习方法对所有错误都进行同等惩罚，因此未能利用标签空间中的任何类间语义信息。在这项工作中，我们引入了两种基于树的语义损失函数，它们利用了标签的层次组织结构。我们进一步将我们的损失函数整合到最近提出的一种使用稀疏、无背景标注进行训练的方法中。大量的实验表明，我们提出的方法在一个稀疏标注的高光谱图像数据集上达到了最先进的性能，该数据集包含107个类别，这些类别以临床定义的语义树结构进行组织。此外，我们的方法能够在不损害分布内（ID）像素分割性能的情况下，有效检测分布外（OOD）像素。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [375] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
> *HalluSegBench：用于分割幻觉评估的反事实视觉推理*

*Xinzhuo Li, Adheesh Juvekar, Xingyou Liu, Muntasir Wahed, Kiet A. Nguyen, Ismini Lourentzou* | **Category: cs.CV, cs.AI, cs.CL, cs.LG**

**Keywords:** 分割幻觉, 反事实视觉推理, 视觉-语言分割, HalluSegBench, 视觉接地

**Comment:** Project webpage: https://plan-lab.github.io/hallusegbench/

> **TL;DR:** HalluSegBench是一个新的基准，用于通过反事实视觉推理评估视觉-语言分割模型中的分割幻觉。它包含一个新数据集和新指标，实验表明视觉驱动的幻觉比标签驱动的更普遍。

**AI_Comments:** 该论文的创新之处在于首次提出了一个基于反事实视觉推理的基准HalluSegBench，专门用于评估视觉-语言分割模型中的分割幻觉。通过引入新的数据集和指标，它能够更深入地诊断模型对视觉上下文变化的敏感性，揭示了视觉驱动幻觉的普遍性，这对于推动鲁棒的视觉接地理解至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉-语言分割模型常出现幻觉，即为图像中不存在或不相关的对象生成分割掩码。现有评估协议主要关注标签或文本幻觉，未能通过操纵视觉上下文来诊断关键故障，因此需要一种新的方法来评估视觉接地中的幻觉。

**Method:** 我们引入了HalluSegBench，这是第一个专门设计用于通过反事实视觉推理评估视觉接地中幻觉的基准。它包含一个由1340个反事实实例对组成的新数据集（涵盖281个独特的对象类别），以及一套新引入的指标，用于量化视觉连贯场景编辑下的幻觉敏感性。

**Result:** 在HalluSegBench上对最先进的视觉-语言分割模型进行的实验表明，视觉驱动的幻觉比标签驱动的幻觉更为普遍，模型经常持续出现错误的分割。

**Conclusion:** 本研究强调了需要反事实推理来诊断视觉接地保真度，以解决视觉-语言分割模型中普遍存在的视觉驱动幻觉问题。

> **ai_Abstract:** HalluSegBench是一个新颖的基准，旨在解决视觉-语言分割模型中普遍存在的分割幻觉问题。它通过引入一个包含1340个反事实实例对的数据集和一套新的评估指标，利用反事实视觉推理来诊断模型对视觉上下文变化的敏感性。实验结果揭示，视觉驱动的幻觉比标签驱动的更为普遍，强调了通过反事实方法评估模型视觉接地能力的重要性。

> **摘要翻译:** 最近视觉-语言分割的进展显著推动了基础视觉理解。然而，这些模型经常表现出幻觉，即为图像内容中未接地的对象生成分割掩码，或错误地标记不相关的区域。现有的分割幻觉评估协议主要关注标签或文本幻觉，而没有操纵视觉上下文，这限制了它们诊断关键故障的能力。因此，我们引入了HalluSegBench，这是第一个专门设计用于通过反事实视觉推理来评估视觉接地中幻觉的基准。我们的基准包含一个由1340个反事实实例对组成的新数据集，涵盖281个独特的对象类别，以及一套新引入的指标，用于量化视觉连贯场景编辑下的幻觉敏感性。在HalluSegBench上对最先进的视觉-语言分割模型进行的实验表明，视觉驱动的幻觉比标签驱动的幻觉更为普遍，模型经常持续出现错误的分割，这突出表明需要反事实推理来诊断接地保真度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [376] [Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels](https://arxiv.org/abs/2506.21151)
> *用于心脏MRI心肌疤痕分割的鲁棒深度学习，解决标签噪声问题*

*Aida Moafi, Danial Moafi, Evgeny M. Mirkes, Gerry P. McCann, Abbas S. Alatrany, Jayanth R. Arnold, Mostafa Mehdipour Ghazi* | **Category: cs.CV, cs.AI**

**Keywords:** 心肌疤痕分割, 深度学习, 标签噪声, 心脏MRI, 鲁棒性

**Comment:** MICCAI 2025

> **TL;DR:** 本研究提出了一种鲁棒的深度学习方法，用于心脏MRI中自动分割心肌疤痕，有效解决了半自动标注带来的标签噪声、数据异质性和类别不平衡等挑战，并在性能上超越了现有最先进的模型。

**AI_Comments:** 该论文的创新点在于其鲁棒的深度学习管道能够有效处理心脏MRI心肌疤痕分割中常见的标签噪声、数据异质性和类别不平衡问题。通过超越现有最先进模型并展现出强大的泛化能力，该研究为深度学习在心脏影像领域的临床应用奠定了坚实基础，具有重要的临床价值。

<details>
  <summary>Details</summary>

**Motivation:** 从心脏MRI中准确分割心肌疤痕对于临床评估和治疗规划至关重要。

**Method:** 本研究通过微调最先进的模型，提出了一种鲁棒的深度学习管道，用于全自动心肌疤痕检测和分割。该方法通过使用Kullback-Leibler损失和广泛的数据增强，明确解决了半自动标注产生的标签噪声、数据异质性和类别不平衡等挑战。

**Result:** 该模型在急性和慢性病例上均表现出色，即使在存在噪声标签的情况下也能生成准确且平滑的分割结果。特别是，该方法优于nnU-Net等最先进的模型，并在分布外测试集上显示出强大的泛化能力，突出了其在各种成像条件和临床任务中的鲁棒性。

**Conclusion:** 这些结果为自动化心肌疤痕量化奠定了可靠基础，并支持深度学习在心脏成像中更广泛的临床应用。

> **ai_Abstract:** 本研究提出了一种鲁棒的深度学习管道，用于心脏MRI中全自动的心肌疤痕分割。该方法通过引入Kullback-Leibler损失和广泛的数据增强，有效解决了半自动标注带来的标签噪声、数据异质性和类别不平衡问题。实验证明，该模型在急性和慢性病例中均能生成准确平滑的分割结果，并优于现有最先进的模型，在分布外测试集上显示出强大的泛化能力和鲁棒性，为心肌疤痕的自动化量化和深度学习在心脏成像中的临床应用提供了可靠基础。

> **摘要翻译:** 从心脏MRI中准确分割心肌疤痕对于临床评估和治疗规划至关重要。在本研究中，我们提出了一种鲁棒的深度学习管道，通过微调最先进的模型，实现全自动的心肌疤痕检测和分割。该方法通过使用Kullback-Leibler损失和广泛的数据增强，明确解决了半自动标注产生的标签噪声、数据异质性和类别不平衡等挑战。我们在急性和慢性病例上评估了模型的性能，并展示了其在存在噪声标签的情况下也能生成准确且平滑的分割结果的能力。特别是，我们的方法优于nnU-Net等最先进的模型，并在分布外测试集上显示出强大的泛化能力，突出了其在各种成像条件和临床任务中的鲁棒性。这些结果为自动化心肌疤痕量化奠定了可靠基础，并支持深度学习在心脏成像中更广泛的临床应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [377] [Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image](https://arxiv.org/abs/2506.21152)
> *几何与感知引导的高斯模型：从单幅图像生成多视角一致的3D对象*

*Pufan Li, Bi'an Du, Wei Hu* | **Category: cs.CV, 68, I.4.0**

**Keywords:** 单视角3D生成, 高斯Splatting, 几何先验, 感知先验, 多视角一致性

**Comment:** 10 pages, 5 figures

> **TL;DR:** 本文提出了一种新颖的方法，通过结合几何和感知先验来从单幅图像生成多视角一致且细节丰富的3D对象，无需额外训练，并在新视角合成和3D重建方面表现优异。

**AI_Comments:** 该论文的创新点在于无需额外模型训练，通过巧妙地结合几何先验（粗略形状）和感知先验（2D扩散模型增强多视角信息），并引入高斯噪声分支，形成多分支高斯模型进行3D重建。其通过分支间的相互作用和重投影深度一致性增强策略，有效提升了单视角3D生成的多视角一致性和几何细节，解决了现有方法的痛点。这种无训练整合多种先验的思路具有较高的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 从单视角图像生成逼真的3D对象需要自然的视觉效果、3D一致性以及捕捉未见区域多种可能解释的能力。现有方法（如微调2D扩散模型或直接通过网络推理或3D高斯Splatting生成3D信息）通常存在多视角一致性差和几何细节不足的问题。

**Method:** 本方法无需额外的模型训练，通过无缝整合几何和感知先验来重建详细的3D对象。具体地，训练三个不同的高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验捕获粗略的3D形状，而感知先验利用2D预训练扩散模型增强多视角信息。随后，通过几何和感知先验之间的相互作用来细化3D高斯分支，并通过基于重投影的策略进一步增强深度一致性。

**Result:** 实验证明，该方法重建结果具有更高的保真度，在新视角合成和3D重建方面优于现有方法，展示了鲁棒且一致的3D对象生成能力。

**Conclusion:** 本文提出了一种结合几何和感知先验的新方法，有效解决了单视角3D生成中多视角一致性和几何细节不足的问题，实现了高质量的3D重建和新视角合成。

> **ai_Abstract:** 本文提出了一种无需额外训练的单视角3D生成方法，通过整合几何与感知先验来解决现有方案中多视角一致性差和几何细节不足的问题。该方法初始化三个高斯分支（几何先验、感知先验、高斯噪声），利用几何先验获取粗略形状，感知先验结合2D扩散模型增强多视角信息，并通过两者相互作用和重投影策略细化高斯分支，最终实现高保真度的多视角一致3D对象生成，在新视角合成和3D重建上超越现有方法。

> **摘要翻译:** 从单视角图像生成逼真的3D对象需要自然的视觉效果、3D一致性以及捕捉未见区域多种可能解释的能力。现有方法通常依赖于微调预训练的2D扩散模型或通过快速网络推理或3D高斯Splatting直接生成3D信息，但其结果普遍存在多视角一致性差和几何细节不足的问题。为了解决这些问题，我们提出了一种新颖的方法，无需额外的模型训练，即可无缝整合几何和感知先验，从单幅图像重建详细的3D对象。具体地，我们训练了三个不同的高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验捕获粗略的3D形状，而感知先验利用2D预训练扩散模型来增强多视角信息。随后，我们通过几何和感知先验之间的相互作用来细化3D高斯分支，并通过基于重投影的策略进一步增强深度一致性。实验证明，我们的方法具有更高的保真度重建结果，在新视角合成和3D重建方面优于现有方法，展示了鲁棒且一致的3D对象生成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [379] [Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition](https://arxiv.org/abs/2506.21165)
> *拓扑感知建模用于无监督模拟到现实点云识别*

*Longkun Zou, Kangjun Liu, Ke Chen, Kailing Guo, Kui Jia, Yaowei Wang* | **Category: cs.CV**

**Keywords:** 拓扑感知建模, 无监督域适应, 点云识别, 模拟到现实, 自监督学习

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的拓扑感知建模（TAM）框架，通过利用全局空间拓扑和先进的自训练策略，有效解决了无监督模拟到现实（Sim2Real）点云识别中的领域鸿沟问题，并优于现有最先进方法。

**AI_Comments:** 本文的创新点在于提出了一个拓扑感知建模框架，通过显式地利用全局空间拓扑和局部几何特征的拓扑关系来解决Sim2Real领域鸿沟，这为无监督点云识别提供了一个新的视角。其结合自监督学习和先进自训练策略的设计，有效提升了模型对噪声的鲁棒性，并在实际应用中展现出优越的性能，对于提升点云分类器在不同采集环境下的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 三维物体形状点集的语义表示学习面临显著的几何变化挑战，主要是由于数据采集方法不同。训练数据通常由点模拟器生成，而测试数据则由不同的三维传感器收集，导致模拟到现实（Sim2Real）的领域鸿沟，这限制了点分类器的泛化能力。当前的无监督域适应（UDA）技术难以弥补这一鸿沟，因为它们通常缺乏能够捕获全局拓扑信息的鲁棒、域无关描述符，导致对源域有限语义模式的过拟合。

**Method:** 我们引入了一个新颖的拓扑感知建模（TAM）框架，用于物体点云的Sim2Real UDA。该方法通过利用以低级、高频三维结构为特征的全局空间拓扑，并通过新颖的自监督学习任务建模局部几何特征的拓扑关系来弥补领域鸿沟。此外，我们提出了一种先进的自训练策略，将跨域对比学习与自训练相结合，有效减少了噪声伪标签的影响，增强了适应过程的鲁棒性。

**Result:** 在三个公共Sim2Real基准上的实验结果验证了我们TAM框架的有效性，在所有评估任务中均显示出比现有最先进方法的一致改进。

**Conclusion:** 拓扑感知建模（TAM）框架通过有效利用全局空间拓扑和先进的自训练策略，成功解决了无监督模拟到现实点云识别中的领域鸿沟问题，显著提升了点分类器的泛化能力。

> **ai_Abstract:** 本文针对无监督模拟到现实（Sim2Real）点云识别中存在的领域鸿沟问题，提出了一种名为拓扑感知建模（TAM）的新框架。该框架通过利用全局空间拓扑信息和通过自监督学习建模局部几何特征的拓扑关系来弥补领域差异。此外，它还结合了跨域对比学习和自训练的先进策略，以减少伪标签噪声并增强适应性。实验证明，TAM在多个Sim2Real基准上均优于现有最先进方法，有效提升了点分类器的泛化能力。

> **摘要翻译:** 从三维物体形状点集中学习语义表示经常受到显著几何变化的挑战，这主要源于数据采集方法的差异。通常，训练数据通过点模拟器生成，而测试数据则由不同的三维传感器收集，导致模拟到现实（Sim2Real）的领域鸿沟，从而限制了点分类器的泛化能力。当前的无监督域适应（UDA）技术难以应对这一鸿沟，因为它们往往缺乏能够捕获全局拓扑信息的鲁棒、域无关描述符，导致对源域有限语义模式的过拟合。为了解决这个问题，我们引入了一种新颖的拓扑感知建模（TAM）框架，用于物体点云的Sim2Real UDA。我们的方法通过利用以低级、高频三维结构为特征的全局空间拓扑，并通过新颖的自监督学习任务建模局部几何特征的拓扑关系来弥补领域鸿沟。此外，我们提出了一种先进的自训练策略，将跨域对比学习与自训练相结合，有效减少了噪声伪标签的影响，增强了适应过程的鲁棒性。在三个公共Sim2Real基准上的实验结果验证了我们TAM框架的有效性，在所有评估任务中均显示出比现有最先进方法的一致改进。这项工作的源代码将在https://github.com/zou-longkun/TAG.git提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [380] [Task-Aware KV Compression For Cost-Effective Long Video Understanding](https://arxiv.org/abs/2506.21184)
> *面向成本效益型长视频理解的任务感知KV压缩*

*Minghao Qin, Yan Shu, Peitian Zhang, Kun Lun, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu* | **Category: cs.CV, cs.AI**

**Keywords:** KV compression, Long video understanding, MLLMs, Task-aware, Cost-effective

**Comment:** 14 pages, 3 figures, 6 tables

> **TL;DR:** Video-X^2L通过任务感知的双层KV压缩和选择性重载，显著提高了长视频理解的效率和性能，无需额外训练。

**AI_Comments:** Video-X^2L的创新之处在于其“任务感知”的双层KV压缩和选择性重载机制，有效解决了高压缩比下信息丢失的问题，同时保持了与现有模型的兼容性且无需额外训练，这使其具有很高的实用价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大型语言模型（MLLMs）在长视频理解（LVU）中面临巨大的计算成本挑战，且现有KV压缩方法在高压缩比下存在严重信息损失。

**Method:** 本文提出了Video-X^2L，它包含两个关键操作：
1. 双层KV压缩：在MLLM的预填充阶段，生成两种类型的压缩KVs：低压缩KVs（L-KVs）以捕获细粒度视频细节，高压缩KVs（H-KVs）以提供紧凑的视频表示。
2. 选择性KV重载：在MLLM的解码阶段，Video-X^2L选择性地为最关键的视频块重载L-KVs，同时为其他不那么重要的部分使用H-KVs。这使得MLLM能够充分利用任务特定的信息，同时保持整体的紧凑性。该方法无需额外训练，且直接兼容现有KV可压缩的MLLMs。

**Result:** Video-X^2L在VideoMME、MLVU、LongVideoBench和VNBench等多种流行的LVU基准测试中进行了评估。实验结果表明，Video-X^2L以巨大的优势超越了现有KV压缩方法，同时大幅节省了计算成本。

**Conclusion:** Video-X^2L是一个简单而有效的方法，能够灵活地为每个长视频理解任务保留关键视频信息，并在性能和计算成本效益上取得显著提升。

> **ai_Abstract:** 本文提出了Video-X^2L，一种针对长视频理解(LVU)中多模态大型语言模型(MLLM)高计算成本问题的任务感知KV压缩方法。Video-X^2L通过双层KV压缩（生成细粒度L-KVs和紧凑H-KVs）和选择性KV重载（根据任务重要性动态加载不同KVs）来灵活保留关键视频信息。该方法无需额外训练，且与现有MLLM兼容，在多个LVU基准测试中表现出显著优于现有KV压缩方法的性能，并大幅降低了计算成本。

> **摘要翻译:** 长视频理解（LVU）仍然是现有多模态大型语言模型（MLLMs）面临的严峻挑战，这主要是由于其高昂的计算成本。最近的方法探索了KV压缩来缓解这个问题，但它们在高压缩比下往往会遭受严重的信息损失。在本文中，我们引入了Video-X^2L，它能灵活地为每个LVU任务保留关键的视频信息。Video-X^2L涉及两个关键操作。第一个是双层KV压缩。在MLLM的预填充阶段，Video-X^2L生成两种类型的压缩KVs：低压缩KVs（L-KVs）以捕获细粒度视频细节，高压缩KVs（H-KVs）以提供紧凑的视频表示。第二个是选择性KV重载。在MLLM的解码阶段，Video-X^2L选择性地为最关键的视频块重载L-KVs，同时为其他不那么重要的部分使用H-KVs。这使得MLLM能够充分利用任务特定的信息，同时保持整体的紧凑性。Video-X^2L简单而有效：它无需额外训练，且直接兼容现有KV可压缩的MLLMs。我们在各种流行的LVU基准测试中评估了Video-X^2L，包括VideoMME、MLVU、LongVideoBench和VNBench。我们的实验结果表明，Video-X^2L以巨大的优势超越了现有KV压缩方法，同时大幅节省了计算成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [383] [GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding](https://arxiv.org/abs/2506.21188)
> *GroundFlow：一个用于3D点云序列定位中时序推理的即插即用模块*

*Zijun Lin, Shuting He, Cheston Tan, Bihan Wen* | **Category: cs.CV**

**Keywords:** 3D点云, 序列定位, 时序推理, 即插即用模块, 视觉定位

**Comment:** 

> **TL;DR:** GroundFlow是一个即插即用模块，通过引入时序推理能力，显著提高了3D点云序列定位的准确性，解决了现有方法无法有效处理多步骤指令和指代词的问题。

**AI_Comments:** GroundFlow的创新之处在于其作为“即插即用”模块的设计，能够轻松集成到现有3DVG模型中，从而赋予它们处理复杂序列指令的能力。它通过选择性地利用短期和长期历史信息，有效解决了多步骤指令中上下文依赖和指代词理解的关键挑战。该模块的引入显著提升了SG3D任务的性能，并超越了大型预训练模型，这突显了其在时序推理方面的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D视觉定位（3DVG）方法在处理多步骤文本指令时，未能有效提取时序信息，也无法理解指令中包含的指代词（如“它”、“这里”等），导致在3D点云序列定位（SG3D）任务中面临挑战，无法正确追踪和定位对象序列。

**Method:** 我们提出了GroundFlow，这是一个即插即用模块，用于3D点云序列定位中的时序推理。该模块能够选择性地提取与当前指令相关的短期和长期步骤信息，从而全面利用历史信息，并随着步骤数量的增加保持其时序理解优势。

**Result:** 将GroundFlow集成到3DVG基线方法中，在SG3D基准测试中显著提高了任务准确性（+7.5%和+10.2%），甚至优于在各种数据集上预训练的3D大型语言模型。它在五个数据集上实现了最先进的性能。

**Conclusion:** 我们的工作为现有3DVG模型引入了时序推理能力，并在SG3D基准测试中实现了最先进的性能。

> **ai_Abstract:** 本文提出了GroundFlow，一个针对3D点云序列定位（SG3D）的即插即用模块，旨在解决现有3D视觉定位（3DVG）方法在处理多步骤指令和指代词时缺乏时序推理能力的问题。GroundFlow通过选择性地提取短期和长期历史信息，有效理解上下文并追踪对象序列。实验结果表明，GroundFlow显著提升了基线方法的准确性，甚至超越了预训练的3D大型语言模型，并在五个数据集上达到了SG3D任务的最先进性能。该工作成功地为3DVG模型引入了时序推理能力。

> **摘要翻译:** 3D点云中的序列定位（SG3D）是指通过遵循详细步骤的日常活动文本指令来定位一系列对象。当前的3D视觉定位（3DVG）方法将多步骤文本指令作为一个整体处理，而没有从每个步骤中提取有用的时序信息。然而，SG3D中的指令通常包含代词，如“它”、“这里”和“相同”，以使语言表达简洁。这要求定位方法理解上下文并从之前的步骤中检索相关信息，以正确地定位对象序列。由于缺乏有效模块来收集相关的历史信息，最先进的3DVG方法在适应SG3D任务时面临重大挑战。为了填补这一空白，我们提出了GroundFlow——一个用于3D点云序列定位中时序推理的即插即用模块。首先，我们证明了在SG3D基准测试中，集成GroundFlow显著提高了3DVG基线方法的任务准确性（+7.5%和+10.2%），甚至优于在各种数据集上预训练的3D大型语言模型。此外，我们根据与当前指令的相关性选择性地提取短期和长期步骤信息，使GroundFlow能够全面查看历史信息，并随着步骤数量的增加保持其时序理解优势。总的来说，我们的工作为现有3DVG模型引入了时序推理能力，并在五个数据集的SG3D基准测试中实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [388] [BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models](https://arxiv.org/abs/2506.21209)
> *BitMark for Infinity：位级自回归图像生成模型的水印技术*

*Louis Kerner, Michel Meintz, Bihe Zhao, Franziska Boenisch, Adam Dziedzic* | **Category: cs.CV, cs.AI**

**Keywords:** 水印技术, 图像生成模型, 模型崩溃, 位级自回归, 放射性

**Comment:** 

> **TL;DR:** 为了防止像Infinity这样的位级自回归图像生成模型因其输出被重复用于训练而导致模型崩溃，本文引入了BitMark，一种鲁棒的位级水印框架。BitMark在生成过程中直接在比特层面嵌入水印，同时保持视觉保真度和生成速度，并具有高放射性，即使被用于训练新模型，水印仍可追溯。

**AI_Comments:** 本论文的创新点在于提出了BitMark水印框架，特别是其“放射性”特性。这意味着水印不仅能标识原始生成内容，还能在这些内容被用于训练新的生成模型时，将水印传播到新模型的输出中。这一点对于防止模型崩溃至关重要，因为它提供了一种长期且深层次的追溯机制，有助于维护未来生成模型的质量和数据来源的透明度。这种超越传统水印能力的设计，使其在应对AI生成内容滥用和模型退化方面具有显著的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的文本到图像模型（如Infinity）能够以极快的速度生成逼真的图像，但其强大的生成能力也带来了日益增长的风险：随着生成内容在互联网上大量出现，它们很可能被抓取并重新用作训练数据，这可能导致模型崩溃，即在生成内容（特别是模型自身先前版本的内容）上重复训练会导致性能逐渐下降。水印技术是一种有前景的缓解策略，它能将人眼不可见但可检测的信号嵌入到生成的图像中，从而实现对生成内容的识别。

**Method:** 本文介绍了BitMark，一个针对Infinity的鲁棒位级水印框架。我们的方法在Infinity的图像生成过程中，直接在令牌流的比特级别跨多个尺度（也称为分辨率）嵌入水印。我们的位级水印巧妙地影响比特，以保持视觉保真度和生成速度，同时对各种移除技术保持鲁棒性。

**Result:** BitMark对一系列移除技术表现出鲁棒性。此外，它还具有高放射性，即当带有水印的生成图像被用于训练另一个图像生成模型时，这个第二模型的输出也将带有水印。即使仅使用我们BitMark加水印的图像对扩散模型或图像自回归模型进行微调，放射性痕迹仍然可检测。

**Conclusion:** 总的来说，我们的方法通过实现对生成输出的可靠检测，为防止图像生成模型中的模型崩溃提供了原则性的一步。

> **ai_Abstract:** 鉴于像Infinity这样的位级自回归图像生成模型面临因其生成内容被重复用于训练而导致模型崩溃的风险，本文提出了一种名为BitMark的鲁棒位级水印框架。BitMark在图像生成过程中直接在令牌流的比特层面嵌入水印，能够在保持视觉保真度和生成速度的同时，有效抵抗水印移除攻击。其核心创新在于“放射性”特性，即使用BitMark加水印的图像训练出的新模型，其生成内容仍会带有可检测的水印痕迹，即使是微调模型也能保持可检测性。这项工作为通过可靠检测生成内容来防止图像生成模型中的模型崩溃迈出了重要一步。

> **摘要翻译:** 最先进的文本到图像模型，如Infinity，能以空前的速度生成逼真的图像。这些模型以位级自回归的方式操作，作用于实际上无限大小的离散令牌集。然而，它们令人印象深刻的生成能力伴随着日益增长的风险：随着它们的输出越来越多地充斥互联网，它们很可能被抓取并重新用作训练数据——甚至可能被同一模型利用。这种现象已被证明会导致模型崩溃，即在生成内容上重复训练，特别是来自模型自身先前版本的内容，会导致性能逐渐下降。一种有前景的缓解策略是水印技术，它将人眼不可见但可检测的信号嵌入到生成的图像中，从而能够识别生成内容。在这项工作中，我们引入了BitMark，一个针对Infinity的鲁棒位级水印框架。我们的方法在Infinity的图像生成过程中，直接在令牌流的比特级别跨多个尺度（也称为分辨率）嵌入水印。我们的位级水印巧妙地影响比特，以保持视觉保真度和生成速度，同时对各种移除技术保持鲁棒性。此外，它还表现出高放射性，即当带有水印的生成图像被用于训练另一个图像生成模型时，这个第二模型的输出也将带有水印。即使仅使用我们BitMark加水印的图像对扩散模型或图像自回归模型进行微调，放射性痕迹仍然可检测。总的来说，我们的方法通过实现对生成输出的可靠检测，为防止图像生成模型中的模型崩溃提供了原则性的一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [390] [ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.21233)
> *ReME：一个用于免训练开放词汇分割的数据中心框架*

*Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma* | **Category: cs.CV**

**Keywords:** 免训练OVS, 数据中心, 语义分割, 参考集, 数据质量

**Comment:** Accepted to ICCV 2025

> **TL;DR:** ReME通过关注高质量的参考数据集和简单的检索方法，显著提升了免训练开放词汇分割的性能，超越了现有方法。

**AI_Comments:** 本文的创新之处在于将研究重点从复杂的模型设计或检索过程转移到数据质量这一基本方面。这种以数据为中心的方法简化了过程，同时取得了卓越的成果，为免训练开放词汇分割提供了一个新的有效方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的免训练开放词汇语义分割（OVS）方法受限于所依赖模型的能力或参考集质量不佳。本文旨在解决这一被忽视的数据质量问题。

**Method:** 本研究提出了一个以数据质量为导向的框架ReME，包含一个数据管道用于构建具有良好配对的片段-文本嵌入的参考集，并采用简单的基于相似度的检索方法。

**Result:** 在十个基准数据集上的广泛评估表明，ReME方法优于所有现有的免训练OVS方法。

**Conclusion:** 数据中心设计对于无需训练的开放词汇分割的进步至关重要。

> **ai_Abstract:** ReME是一个新颖的以数据为中心的框架，用于免训练开放词汇语义分割。它解决了现有方法因参考集质量不佳而受到的限制。通过构建一个包含良好配对的片段-文本嵌入的高质量参考集，并采用简单的基于相似度的检索，ReME显著提升了性能。评估结果表明，它超越了所有当前的免训练OVS方法，强调了数据质量在此任务中的重要性。

> **摘要翻译:** 免训练开放词汇语义分割（OVS）旨在在不进行昂贵的模型微调的情况下，根据一组任意文本类别对图像进行分割。现有解决方案通常探索预训练模型（如CLIP）的注意力机制，或生成合成数据并设计复杂的检索过程来执行OVS。然而，它们的性能受限于所依赖模型的能力或参考集质量不佳。在这项工作中，我们调查了这项具有挑战性的密集场景理解任务中在很大程度上被忽视的数据质量问题，并发现高质量的参考集可以显著有益于免训练OVS。基于这一观察，我们引入了一个以数据质量为导向的框架，包括一个用于构建具有良好配对的片段-文本嵌入的参考集的数据管道，以及一个简单的基于相似度的检索方法，以揭示数据的本质影响。值得注意的是，在十个基准数据集上的广泛评估表明，我们的方法优于所有现有的免训练OVS方法，突出了以数据为中心的设计对于无需训练推进OVS的重要性。我们的代码可在https://github.com/xiweix/ReME 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [392] [DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation](https://arxiv.org/abs/2506.21237)
> *DiMPLe -- 解耦多模态提示学习：通过不变性和虚假特征分离增强分布外对齐*

*Umaima Rahman, Mohammad Yaqub, Dwarikanath Mahapatra* | **Category: cs.CV**

**Keywords:** 多模态学习, 提示学习, 分布外泛化, 特征解耦, 虚假相关性

**Comment:** 

> **TL;DR:** DiMPLe是一种新的多模态提示学习方法，通过解耦不变性和虚假特征来提高OOD性能和泛化能力。

**AI_Comments:** DiMPLe的创新之处在于其对多模态学习中不变和虚假特征的精细解耦，这超越了以往仅关注单一模态特征的方法。通过在模态内部和跨模态进行解耦，并结合精心设计的三个目标函数，它有效提升了模型在面对分布外数据时的泛化能力和鲁棒性，特别是对新类别的识别性能有显著提升，这对于实际应用中的模型可靠性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 视觉数据中的虚假相关性通常会阻碍分布外（OOD）性能。现有方法主要关注图像特征，未能有效解决跨模态的特征解耦问题，导致泛化能力和对分布偏移的鲁棒性不足。

**Method:** DiMPLe通过在视觉和语言模态中解耦不变特征和虚假特征，同时保持一致的对齐。它结合了三个关键目标：1) 不变特征和虚假特征之间的互信息最小化；2) 虚假特征正则化；3) 在不变特征上进行对比学习。

**Result:** DiMPLe在11个不同数据集上平均表现优于CoOp-OOD，在基类准确率上绝对提高了15.27，在新类准确率上绝对提高了44.31。

**Conclusion:** DiMPLe通过有效解耦多模态特征，显著提升了模型在分布外场景下的泛化能力和对分布偏移的鲁棒性。

> **ai_Abstract:** DiMPLe是一种新颖的多模态提示学习方法，旨在通过解耦视觉和语言模态中的不变特征和虚假特征来提高模型在分布外（OOD）场景下的性能。该方法结合了互信息最小化、虚假特征正则化和不变特征上的对比学习三个核心目标，以实现更好的泛化能力和对分布偏移的鲁棒性。实验证明，DiMPLe在多个数据集上显著优于现有方法，尤其在新类准确率上表现突出。

> **摘要翻译:** 我们引入了DiMPLe（解耦多模态提示学习），这是一种在多模态学习中解耦视觉和语言模态之间不变特征和虚假特征的新方法。视觉数据中的虚假相关性通常会阻碍分布外（OOD）性能。与以往仅关注图像特征的方法不同，DiMPLe在模态内部和跨模态解耦特征，同时保持一致的对齐，从而能够更好地泛化到新类别并对分布偏移具有鲁棒性。我们的方法结合了三个关键目标：（1）不变特征和虚假特征之间的互信息最小化，（2）虚假特征正则化，以及（3）在不变特征上进行对比学习。广泛的实验表明，DiMPLe在11个不同数据集上的平均性能优于CoOp-OOD，并在基类准确率上获得了15.27的绝对增益，在新类准确率上获得了44.31的绝对增益。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [393] [Temporal Rate Reduction Clustering for Human Motion Segmentation](https://arxiv.org/abs/2506.21249)
> *用于人体运动分割的时序速率降低聚类*

*Xianghan Meng, Zhengyu Tong, Zhiyuan Huang, Chun-Guang Li* | **Category: cs.CV**

**Keywords:** 人体运动分割, 时序速率降低聚类, 子空间聚类, 结构化表示, 视频分割

**Comment:** The paper is accepted by ICCV 2025. The first two authors are equally
  contributed

> **TL;DR:** 本文提出了一种名为时序速率降低聚类（TR²C）的新型人体运动分割（HMS）方法，旨在解决现有子空间聚类方法在处理复杂运动时UoS假设不适配的问题，并在多个基准数据集上取得了最先进的性能。

**AI_Comments:** 该论文通过提出TR²C方法，巧妙地解决了现有HMS子空间聚类方法中UoS假设的局限性。其创新点在于联合学习结构化表示和亲和力，使得学习到的表示既保持时间一致性又能更好地适应UoS结构。在多个基准数据集上取得最先进的性能，充分证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体运动分割（HMS）方法主要基于子空间聚类，其假设高维时序数据与子空间联合（UoS）分布对齐。然而，在捕捉复杂人体运动和杂乱背景的视频中，帧可能无法很好地与UoS分布对齐，这限制了现有方法的性能。

**Method:** 本文提出了一种新颖的HMS方法，名为时序速率降低聚类（TR²C）。该方法联合学习结构化表示和亲和力，以分割视频中的帧序列。TR²C学习到的结构化表示能够保持时间上的一致性，并与UoS结构良好对齐，这有利于HMS任务。

**Result:** 在五个基准HMS数据集上进行了广泛实验，TR²C使用不同的特征提取器均取得了最先进的性能。

**Conclusion:** 所提出的时序速率降低聚类（TR²C）方法通过学习鲁棒且时间上一致的表示，有效解决了传统基于UoS的人体运动分割方法的局限性，从而实现了卓越的分割性能。

> **ai_Abstract:** 本文提出了一种名为时序速率降低聚类（TR²C）的新型人体运动分割（HMS）方法，旨在解决现有子空间聚类方法中UoS假设在复杂背景下不适用的问题。TR²C通过联合学习结构化表示和亲和力来分割视频帧序列，其学习到的表示保持时间上的一致性并与UoS结构良好对齐。实验证明，TR²C在五个基准HMS数据集上取得了最先进的性能。

> **摘要翻译:** 人体运动分割（HMS）旨在将视频划分为不重叠的人体运动，最近引起了越来越多的研究关注。现有的HMS方法主要由子空间聚类方法主导，这些方法基于高维时序数据与子空间联合（UoS）分布对齐的假设。然而，捕捉复杂人体运动和杂乱背景的视频帧可能无法很好地与UoS分布对齐。在本文中，我们提出了一种新颖的HMS方法，名为时序速率降低聚类（TR²C），它联合学习结构化表示和亲和力以分割视频中的帧序列。具体而言，TR²C学习的结构化表示保持时间上的一致性并与UoS结构良好对齐，这有利于HMS任务。我们在五个基准HMS数据集上进行了广泛的实验，并使用不同的特征提取器取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [395] [DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic](https://arxiv.org/abs/2506.21260)
> *DuET：通过无样本任务算术的双重增量目标检测*

*Munish Monga, Vishal Chudasama, Pankaj Wasnik, Biplab Banerjee* | **Category: cs.CV**

**Keywords:** 增量学习, 目标检测, 任务算术, 域适应, 灾难性遗忘

**Comment:** Accepted at ICCV 2025

> **TL;DR:** DuET提出了一种双重增量目标检测（DuIOD）方法，通过无样本的任务算术框架同时处理类别和域的变化，并在多个数据集上优于现有方法。

**AI_Comments:** DuET的创新之处在于其提出了双重增量目标检测（DuIOD）这一更贴近实际的设置，并利用任务算术框架以无样本方式解决该问题。其检测器无关的特性大大增加了方法的普适性。此外，引入保留-适应性指数（RAI）为增量学习的评估提供了一个更全面的衡量标准，对于后续研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的类别增量目标检测（CIOD）和域增量目标检测（DIOD）方法分别在未见过的域中表现不佳或遭受灾难性遗忘，限制了它们在需要持续学习新类别并适应不断变化环境的真实世界目标检测系统中的应用。

**Method:** 我们引入了双重增量目标检测（DuIOD）设置，它以无样本的方式同时处理类别和域的转变。我们提出了DuET，一个基于任务算术的模型合并框架，通过新颖的方向一致性损失来缓解符号冲突，实现稳定的增量学习。DuET是检测器无关的，并引入了保留-适应性指数（RAI）来全面评估保留和适应性。

**Result:** DuET在Pascal系列（4个任务）上实现了+13.12%的RAI改进，同时保留了89.3%的平均保留指数（Avg RI）；在多样天气系列（3个任务）上实现了+11.39%的RAI改进，保留了88.57%的平均保留指数（Avg RI），均优于现有方法。

**Conclusion:** DuET通过其基于任务算术的模型合并框架和方向一致性损失，有效解决了双重增量目标检测的挑战，并在保留和适应性方面取得了显著改进，证明了其在实际应用中的优越性。

> **ai_Abstract:** 本研究提出了DuET，一个基于任务算术的框架，用于解决双重增量目标检测（DuIOD）问题，该问题要求系统同时学习新类别并适应不同的环境域，且无需存储旧样本。DuET通过引入方向一致性损失来稳定增量学习并缓解符号冲突，并且具有检测器无关的特性。为了全面评估，论文还提出了保留-适应性指数（RAI）。实验结果表明，DuET在多个数据集上显著优于现有方法，在保留旧知识和适应新域方面均表现出色。

> **摘要翻译:** 真实世界的目标检测系统，例如自动驾驶和监控中的系统，必须持续学习新的目标类别并同时适应不断变化的环境条件。现有的方法，即类别增量目标检测（CIOD）和域增量目标检测（DIOD）仅解决了这一挑战的一个方面。CIOD在未见过的域中表现不佳，而DIOD在学习新类别时遭受灾难性遗忘，限制了它们的实际应用。为了克服这些限制，我们引入了双重增量目标检测（DuIOD），这是一种更实用的设置，可以以无样本的方式同时处理类别和域的转变。我们提出了DuET，一个基于任务算术的模型合并框架，通过新颖的方向一致性损失来缓解符号冲突，实现稳定的增量学习。与之前的方法不同，DuET是检测器无关的，允许YOLO11和RT-DETR等模型作为实时增量目标检测器。为了全面评估保留和适应性，我们引入了保留-适应性指数（RAI），它将用于灾难性遗忘的平均保留指数（Avg RI）和用于域适应性的平均泛化指数结合到一个共同的基础中。在Pascal系列和多样天气系列上的大量实验证明了DuET的有效性，在Pascal系列（4个任务）上实现了+13.12%的RAI改进，同时保留了89.3%的平均保留指数（Avg RI），以及在多样天气系列（3个任务）上实现了+11.39%的RAI改进，保留了88.57%的平均保留指数（Avg RI），均优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [396] [Video Virtual Try-on with Conditional Diffusion Transformer Inpainter](https://arxiv.org/abs/2506.21270)
> *基于条件扩散Transformer修复器的视频虚拟试穿*

*Cheng Zou, Senlin Cheng, Bolei Xu, Dandan Zheng, Xiaobo Li, Jingdong Chen, Ming Yang* | **Category: cs.CV**

**Keywords:** 视频虚拟试穿, 扩散Transformer, 视频修复, 时空一致性

**Comment:** 10 pages, 6 figures

> **TL;DR:** 本文提出ViTI，一种基于条件扩散Transformer修复器的视频虚拟试穿方法，通过将视频试穿任务建模为条件视频修复，实现了更好的时空一致性和服装细节保留。

**AI_Comments:** 本文的创新点在于将视频虚拟试穿任务重新定义为条件视频修复任务，这与以往将图像试穿方法适配到视频或简单添加时间注意力的方法不同。通过利用带有全3D时空注意力的Diffusion Transformer，从视频生成角度出发，有效提升了时空一致性，这是该方法的核心优势。

<details>
  <summary>Details</summary>

**Motivation:** 视频虚拟试穿任务具有挑战性，需要良好的时空一致性和服装细节保留。传统基于图像的方法逐帧处理会导致严重不一致。近期扩散基视频试穿方法虽有改进，但仍存在不一致问题。

**Method:** 本文提出ViTI（Video Try-on Inpainter），将视频虚拟试穿建模为条件视频修复任务。该方法构建了一个基于Diffusion Transformer的视频修复框架，并使用全3D时空注意力。通过一系列掩码策略和多阶段训练，逐步将其应用于视频服装修复。最终，模型加入了服装条件以确保修复后的服装外观和细节符合预期。

**Result:** 定量和定性实验结果表明ViTI优于现有工作。

**Conclusion:** ViTI通过将视频试穿建模为条件视频修复任务，有效解决了时空一致性和服装细节保留问题，并优于现有方法。

> **ai_Abstract:** 视频虚拟试穿是一项要求高时空一致性和服装细节保留的挑战性任务。针对现有方法的不足，本文提出ViTI，将视频虚拟试穿重新定义为条件视频修复任务。ViTI基于带有全3D时空注意力的Diffusion Transformer构建，并通过多阶段训练和掩码策略逐步适应服装修复，最终加入服装条件以确保细节和外观。实验证明，ViTI在定量和定性上均优于现有方法，有效提升了视频虚拟试穿的效果。

> **摘要翻译:** 视频虚拟试穿旨在将服装自然地适配到连续视频帧中的目标人物。这是一项具有挑战性的任务，一方面，输出视频应具有良好的时空一致性；另一方面，给定服装的细节需要在所有帧中得到很好的保留。简单地逐帧使用基于图像的试穿方法会由于严重的不一致性而得到糟糕的结果。最近基于扩散的视频试穿方法，尽管数量很少，但碰巧与类似的解决方案不谋而合：将时间注意力插入基于图像的试穿模型中，以使其适应视频试穿任务，这虽然显示出改进，但仍然存在不一致性问题。在本文中，我们提出了ViTI（Video Try-on Inpainter），将视频虚拟试穿公式化并实现为条件视频修复任务，这与以前的方法不同。通过这种方式，我们从视频生成问题而不是基于图像的试穿问题开始，这从一开始就具有更好的时空一致性。具体来说，我们首先构建了一个基于Diffusion Transformer的视频修复框架，该框架具有完整的3D时空注意力，然后我们通过一系列掩码策略和多阶段训练，逐步将其适应于视频服装修复。经过这些步骤后，模型可以根据提示使用适当的服装像素修复被遮罩的服装区域，并具有良好的时空一致性。最后，像其他试穿方法一样，将服装条件添加到模型中，以确保修复后的服装外观和细节符合预期。定量和定性实验结果均表明ViTI优于现有工作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [WordCon: Word-level Typography Control in Scene Text Rendering](https://arxiv.org/abs/2506.21276)
> *WordCon：场景文本渲染中的词级排版控制*

*Wenda Shi, Yiren Song, Zihan Rao, Dengming Zhang, Jiaming Liu, Xingxing Zou* | **Category: cs.CV**

**Keywords:** 词级排版控制, 场景文本渲染, 参数高效微调, 文本-图像对齐, WordCon

**Comment:** 

> **TL;DR:** 本文提出了WordCon，一种混合参数高效微调方法，结合新的词级受控数据集和文本-图像对齐（TIA）框架，旨在解决生成图像中精确词级排版控制的挑战，并实现了超越现有技术的性能。

**AI_Comments:** 本文创新性地结合了新的数据集构建、跨模态对齐框架（TIA）和混合参数高效微调（WordCon），有效解决了图像生成中的词级排版控制难题。其提出的损失函数（掩蔽损失和联合注意力损失）进一步增强了模型对文本区域的聚焦和不同单词的解耦能力，提升了可控性。该方法的效率和可移植性也使其在艺术文本渲染、文本编辑等多种应用场景中具有广泛潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在生成图像中实现精确的词级排版控制仍然是一个持续的挑战。

**Method:** 本文构建了一个新的词级受控场景文本数据集，并引入了文本-图像对齐（TIA）框架，该框架利用接地模型提供的文本与局部图像区域之间的跨模态对应关系来增强文本到图像（T2I）模型训练。此外，提出了WordCon，一种混合参数高效微调（PEFT）方法，通过重新参数化选择性关键参数来提高效率和可移植性。为了增强可控性，还应用了潜在层面的掩蔽损失来引导模型集中学习图像中的文本区域，以及联合注意力损失提供特征级监督以促进不同单词之间的解耦。

**Result:** 定性和定量结果均表明该方法优于现有技术。

**Conclusion:** WordCon方法通过构建新的词级受控数据集、引入文本-图像对齐（TIA）框架以及提出混合参数高效微调（PEFT）技术，有效解决了生成图像中词级排版控制的挑战，并取得了优于现有技术的性能。

> **ai_Abstract:** 本文针对生成图像中词级排版控制的难题，提出了WordCon方法。该方法通过构建新的词级受控场景文本数据集，并引入文本-图像对齐（TIA）框架来增强Text-to-Image模型训练。WordCon本身是一种混合参数高效微调（PEFT）方法，它重新参数化了关键参数以提高效率和可移植性，并结合了掩蔽损失和联合注意力损失以增强对文本区域的学习和不同单词的解耦。实验结果表明，该方法在词级排版控制方面取得了优于现有技术的表现。

> **摘要翻译:** 在生成图像中实现精确的词级排版控制仍然是一个持续的挑战。为了解决这个问题，我们新构建了一个词级受控场景文本数据集，并引入了文本-图像对齐（TIA）框架。该框架利用了接地模型提供的文本与局部图像区域之间的跨模态对应关系，以增强文本到图像（T2I）模型的训练。此外，我们提出了WordCon，一种混合参数高效微调（PEFT）方法。WordCon重新参数化了选择性关键参数，提高了效率和可移植性。这使得它能够无缝集成到各种管道中，包括艺术文本渲染、文本编辑和图像条件文本渲染。为了进一步增强可控性，我们应用了潜在层面的掩蔽损失来引导模型集中学习图像中的文本区域，并且联合注意力损失提供了特征级监督以促进不同单词之间的解耦。定性和定量结果都表明我们的方法优于现有技术。数据集和源代码将可供学术使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [400] [HieraSurg: Hierarchy-Aware Diffusion Model for Surgical Video Generation](https://arxiv.org/abs/2506.21287)
> *HieraSurg：分层感知扩散模型用于手术视频生成*

*Diego Biagini, Nassir Navab, Azade Farshad* | **Category: cs.CV**

**Keywords:** 扩散模型, 手术视频生成, 分层感知, 语义分割, 视频合成

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** HieraSurg是一个分层感知的扩散模型框架，通过两个专门的扩散模型生成手术视频，解决了现有方法在手术动作和阶段一致性方面的不足，并能生成高质量、高帧率的手术视频。

**AI_Comments:** HieraSurg的创新之处在于其分层感知的双阶段扩散模型设计，有效解决了手术视频生成中关键的语义一致性问题。通过整合多层次的手术信息，模型不仅提升了生成视频的真实感和质量，还展现了优异的泛化能力和生成高帧率视频的能力。这对于需要高精度和上下文感知的手术模拟和训练场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的手术视频生成方法大多是无条件的，并且未能保持与手术动作和阶段的一致性，缺乏手术理解和细粒度指导，无法进行真实模拟。

**Method:** HieraSurg是一个分层感知的手术视频生成框架，包含两个专门的扩散模型。给定手术阶段和初始帧，首先通过分割预测模型预测未来的粗粒度语义变化。然后，第二阶段模型通过细粒度视觉特征增强这些时间分割图，生成最终视频，实现有效的纹理渲染和语义信息整合。该方法利用了多层抽象的手术信息，包括手术阶段、动作三元组和全景分割图。

**Result:** 在胆囊切除术视频生成上的实验结果表明，该模型在定量和定性上都显著优于现有工作，显示出强大的泛化能力和生成更高帧率视频的能力。当提供现有分割图时，模型表现出特别细粒度的依从性。

**Conclusion:** HieraSurg通过其分层感知的方法解决了手术视频生成中保持一致性和细粒度指导的挑战，其优异的性能和对现有分割图的细粒度依从性表明了其在实际手术应用中的巨大潜力。

> **ai_Abstract:** HieraSurg是一个新颖的分层感知扩散模型框架，旨在解决现有手术视频生成方法在保持手术动作和阶段一致性方面的不足。该框架包含两个专门的扩散模型：第一个模型预测未来的粗粒度语义变化，第二个模型则在此基础上生成包含细粒度视觉特征的最终视频。通过利用手术阶段、动作三元组和全景分割图等多层次抽象信息，HieraSurg能够生成高质量、高帧率的手术视频。实验结果表明，该模型在性能上显著优于现有技术，并具有强大的泛化能力和实际应用潜力。

> **摘要翻译:** 手术视频合成已成为一个有前景的研究方向，这得益于扩散模型在通用领域视频生成方面的成功。尽管现有方法实现了高质量的视频生成，但大多数是无条件的，并且未能保持与手术动作和阶段的一致性，缺乏真实模拟所需的手术理解和细粒度指导。我们通过提出HieraSurg来解决这些挑战，HieraSurg是一个分层感知的手术视频生成框架，由两个专门的扩散模型组成。给定手术阶段和初始帧，HieraSurg首先通过分割预测模型预测未来的粗粒度语义变化。然后，最终视频由第二阶段模型生成，该模型通过细粒度视觉特征增强这些时间分割图，从而在视频空间中实现有效的纹理渲染和语义信息整合。我们的方法利用了多个抽象层次的手术信息，包括手术阶段、动作三元组和全景分割图。在胆囊切除术视频生成上的实验结果表明，该模型在定量和定性上都显著优于现有工作，显示出强大的泛化能力和生成更高帧率视频的能力。当提供现有分割图时，模型表现出特别细粒度的依从性，表明其在实际手术应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [402] [Continual Self-Supervised Learning with Masked Autoencoders in Remote Sensing](https://arxiv.org/abs/2506.21312)
> *遥感领域基于掩码自编码器的持续自监督学习*

*Lars Möllenbrok, Behnood Rasti, Begüm Demir* | **Category: cs.CV**

**Keywords:** 持续学习, 自监督学习, 掩码自编码器, 遥感, 灾难性遗忘

**Comment:** Accepted to IEEE Geoscience and Remote Sensing Letters. Our code is
  available at https://git.tu-berlin.de/rsim/CoSMAE

> **TL;DR:** 提出CoSMAE，一种持续自监督学习方法，通过数据混合和模型混合知识蒸馏解决遥感持续学习中标签数据昂贵的问题，同时减少灾难性遗忘，性能显著提升。

**AI_Comments:** 这项工作通过引入数据混合和模型混合知识蒸馏，巧妙地将持续学习与自监督学习结合起来，解决了遥感领域获取大量标注数据困难的核心痛点。其创新性在于在无监督或弱监督场景下提升了持续学习的效率和鲁棒性，对于资源受限的遥感应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的遥感持续学习方法需要大量昂贵的标注训练样本来增强对灾难性遗忘的鲁棒性，这在遥感领域并不总是可行。

**Method:** 提出CoSMAE，一种持续自监督学习方法，包含两个组件：1) 数据混合：通过将当前任务图像与之前任务图像进行插值来保留旧数据分布信息；2) 模型混合知识蒸馏：通过插值过去模型和当前模型的权重来形成一个教师模型进行知识蒸馏。这两个组件在数据和模型层面规范化MAE，以促进更好的跨任务泛化并降低灾难性遗忘的风险。

**Result:** 实验结果表明，CoSMAE比应用于MAE的最先进持续学习方法实现了显著改进，性能提升高达4.94%。

**Conclusion:** CoSMAE通过其独特的数据混合和模型混合知识蒸馏机制，有效解决了遥感持续学习中对大量标注数据的依赖问题，并显著提高了模型在持续学习场景下的泛化能力和对灾难性遗忘的抵抗力。

> **ai_Abstract:** 本文提出CoSMAE，一种用于遥感领域的新型持续自监督学习方法，旨在解决现有持续学习方法对大量昂贵标注数据的依赖问题。CoSMAE通过数据混合和模型混合知识蒸馏两个核心组件，在数据和模型层面规范化掩码自编码器，有效保留旧知识、促进跨任务泛化并减轻灾难性遗忘。实验证明，CoSMAE在性能上显著优于现有先进方法。

> **摘要翻译:** 持续学习（CL）方法旨在从连续获取的训练数据中顺序学习新任务，其发展在遥感（RS）领域受到了广泛关注。遥感领域现有的CL方法在学习新任务的同时，通过使用大量标注训练样本来增强对灾难性遗忘的鲁棒性，但这成本高昂且在遥感领域并非总是可行。为了解决这个问题，我们提出了一种在掩码自编码器（MAE）背景下的新型持续自监督学习方法（记作CoSMAE）。所提出的CoSMAE由两个组件组成：i）数据混合；ii）模型混合知识蒸馏。数据混合通过将当前任务的图像与之前任务的图像进行插值来保留先前数据分布的信息。模型混合知识蒸馏通过插值过去模型和当前模型的权重来形成一个教师模型，从而同时从它们中蒸馏知识。这两个组件相互补充，在数据和模型层面规范化MAE，以促进更好的跨任务泛化并降低灾难性遗忘的风险。实验结果表明，CoSMAE比应用于MAE的最先进CL方法实现了高达4.94%的显著改进。我们的代码已公开可用：https://git.tu-berlin.de/rsim/CoSMAE。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images](https://arxiv.org/abs/2506.21316)
> *DrishtiKon: 多粒度视觉定位用于文本密集型文档图像*

*Badri Vishal Kasuba, Parag Chaudhuri, Ganesh Ramakrishnan* | **Category: cs.CV**

**Keywords:** 视觉定位, 文档图像, 视觉问答, 多粒度, 文本密集

**Comment:** Work in progress

> **TL;DR:** DrishtiKon是一个多粒度视觉定位框架，用于文本密集型文档图像，通过集成OCR、LLM和区域匹配算法，实现了SOTA的定位精度，提高了VQA系统的可解释性。

**AI_Comments:** 这项工作通过引入多粒度视觉定位和结合OCR、LLM及新颖区域匹配算法，有效解决了文本密集型文档图像中视觉问答的挑战，显著提升了定位精度和系统可解释性。其创新点在于多粒度定位和对现有VLM局限性的揭示，为未来文档理解系统提供了新的方向，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本密集型文档图像中的视觉定位对于文档智能和视觉问答（VQA）系统来说是一个关键但尚未充分探索的挑战。现有视觉-语言模型（VLM）在精确局部化方面存在局限性，需要提高VQA系统的可解释性和信任度。

**Method:** 提出了DrishtiKon框架，该框架集成了鲁棒的多语言OCR、大型语言模型（LLM）和一种新颖的区域匹配算法，以在块、行、单词和点级别准确地定位答案跨度。同时，从CircularsVQA测试集策划了一个新的基准，提供了多粒度的人工验证注释。

**Result:** 该方法在视觉定位精度上达到了最先进的水平，其中行级粒度在精度和召回率之间提供了最佳权衡。消融研究突出了多块和多行推理的优势。与领先的视觉-语言模型（VLM）的比较评估揭示了当前VLM在精确局部化方面的局限性，并强调了该结构化、基于对齐的方法的有效性。

**Conclusion:** 本研究的发现为在真实世界、以文本为中心的场景中构建更鲁棒和可解释的文档理解系统铺平了道路。

> **ai_Abstract:** 本文提出了DrishtiKon，一个用于文本密集型文档图像的多粒度视觉定位框架，旨在提高视觉问答（VQA）系统的可解释性和信任度。该框架结合了多语言OCR、大型语言模型和新颖的区域匹配算法，能够在块、行、单词和点级别精确定位答案跨度。通过在CircularsVQA数据集上构建的新基准进行实验，DrishtiKon在定位精度上达到了最先进的水平，尤其是在行级粒度上表现出最佳的精度-召回率权衡。研究还揭示了当前视觉-语言模型在精确局部化方面的不足，并证明了该结构化、基于对齐方法的优越性，为构建更鲁棒、可解释的文档理解系统奠定了基础。

> **摘要翻译:** 文本密集型文档图像中的视觉定位是文档智能和视觉问答（VQA）系统的一个关键但尚未充分探索的挑战。我们提出了\drishtikon，一个多粒度视觉定位框架，旨在增强复杂多语言文档中VQA的可解释性和信任度。我们的方法集成了鲁棒的多语言OCR、大型语言模型和一种新颖的区域匹配算法，以在块、行、单词和点级别准确地定位答案跨度。我们从CircularsVQA测试集策划了一个新的基准，提供了跨多个粒度的细粒度、人工验证的注释。广泛的实验表明，我们的方法达到了最先进的定位精度，其中行级粒度在精度和召回率之间提供了最佳权衡。消融研究进一步突出了多块和多行推理的优势。与领先的视觉-语言模型（VLM）的比较评估揭示了当前VLM在精确局部化方面的局限性，强调了我们结构化、基于对齐的方法的有效性。我们的发现为在真实世界、以文本为中心的场景中构建更鲁棒和可解释的文档理解系统铺平了道路。代码和数据集已在https://github.com/kasuba-badri-vishal/DhrishtiKon 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning](https://arxiv.org/abs/2506.21317)
> *LLaVA-Pose：通过关键点集成指令微调增强人体姿态和动作理解*

*Dewen Zhang, Tahir Hussain, Wangpeng An, Hayaru Shouno* | **Category: cs.CV**

**Keywords:** 人体姿态理解, 动作理解, 视觉-语言模型, 关键点集成, 指令微调

**Comment:** arXiv admin note: substantial text overlap with arXiv:2409.09306

> **TL;DR:** LLaVA-Pose通过整合人体关键点数据对现有视觉-语言模型进行指令微调，显著提升了模型在人体姿态和动作理解方面的性能，相较于原始LLaVA-1.5-7B模型提升了33.2%。

**AI_Comments:** 该论文的创新点在于提出了将人体关键点集成到视觉-语言指令微调数据中的方法，有效弥补了现有VLM在人体姿态和动作理解方面的不足。通过构建大规模的专用数据集和评估基准，为该领域的研究提供了宝贵的资源和明确的评估标准。33.2%的显著性能提升凸显了其方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前视觉-语言模型（VLMs）在处理与人体姿态和动作相关的复杂视觉任务时表现不佳，原因是缺乏专门的视觉-语言指令遵循数据。

**Method:** 该研究通过将人体关键点与传统视觉特征（如图像标题和边界框）相结合，生成了专门的视觉-语言指令遵循数据。基于此方法构建了一个包含200,328个样本的数据集，用于针对以人为中心的任务（对话、详细描述、复杂推理）进行模型微调。同时，建立了一个扩展人体姿态和动作理解基准（E-HPAUB）来评估模型性能。使用此数据集对LLaVA-1.5-7B模型进行微调，得到了LLaVA-Pose模型。

**Result:** 实验结果显示，LLaVA-Pose模型在E-HPAUB基准测试中取得了显著改进，相较于原始LLaVA-1.5-7B模型，整体性能提升了33.2%。

**Conclusion:** 关键点集成数据能够有效增强多模态模型在以人为中心的视觉理解任务中的性能。

> **ai_Abstract:** 该研究提出LLaVA-Pose模型，旨在解决现有视觉-语言模型在人体姿态和动作理解方面表现不足的问题。通过整合人体关键点与传统视觉特征，研究团队构建了一个包含20万样本的专用数据集，并基于此数据集对LLaVA-1.5-7B模型进行微调。为评估模型性能，还建立了一个扩展人体姿态和动作理解基准（E-HPAUB）。实验结果表明，LLaVA-Pose在人体姿态和动作理解方面取得了显著提升，相比原始模型整体性能提高了33.2%，验证了关键点集成数据在增强以人为中心的视觉理解方面的有效性。

> **摘要翻译:** 当前的视觉-语言模型（VLMs）已很好地适应了通用视觉理解任务。然而，由于缺乏专门的视觉-语言指令遵循数据，它们在处理与人体姿态和动作相关的复杂视觉任务时表现不足。我们引入了一种生成此类数据的方法，通过将人体关键点与传统视觉特征（如图像标题和边界框）相结合，从而实现对以人为中心场景更精确的理解。我们的方法构建了一个包含200,328个样本的数据集，专门用于微调以人为中心的任务模型，重点关注三个领域：对话、详细描述和复杂推理。我们建立了一个扩展人体姿态和动作理解基准（E-HPAUB）来评估模型在人体姿态和动作理解方面的性能。我们使用此数据集对LLaVA-1.5-7B模型进行微调，并在基准测试中评估了我们得到的LLaVA-Pose模型，取得了显著改进。实验结果显示，与原始LLaVA-1.5-7B模型相比，整体性能提升了33.2%。这些发现突出表明，关键点集成数据在增强多模态模型以实现以人为中心的视觉理解方面是有效的。代码可在https://github.com/Ody-trek/LLaVA-Pose获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [408] [Transferring disentangled representations: bridging the gap between synthetic and real images](https://arxiv.org/abs/2409.18017)
> *解耦表示迁移：弥合合成图像与真实图像之间的鸿沟*

*Jacopo Dapueto, Nicoletta Noceti, Francesca Odone* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 解耦表示, 合成数据, 真实图像, 迁移学习, 度量标准

**Comment:** Accepted to NeurIPS, 2024

> **TL;DR:** 本文研究了将解耦表示从合成数据迁移到真实数据的可能性和有效性，并提出了一种新的可解释的度量方法。

**AI_Comments:** 本文的创新点在于探索了将解耦表示从合成数据迁移到真实数据，这为解决真实世界数据中解耦表示学习的挑战提供了一个有前景的方向。提出的新度量标准也增加了研究的严谨性和可解释性。这项工作对于推动解耦表示学习在实际应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解耦表示学习在真实图像上尚未充分发挥其潜力，原因在于生成因素的相关性、分辨率以及对真实标签的有限访问。本文旨在解决这一问题，探索利用合成数据学习适用于真实数据的通用解耦表示。

**Method:** 本文研究了利用合成数据学习通用解耦表示，并探讨了微调的效果以及迁移后解耦属性的保留情况。此外，还提出了一种新的基于干预的可解释度量标准，用于衡量表示中编码因素的质量。

**Result:** 研究结果表明，将解耦表示从合成数据迁移到真实数据是可能且有效的，能在一定程度上实现解耦。

**Conclusion:** 通过将解耦表示从合成数据迁移到真实数据，可以有效弥合合成图像与真实图像之间的差距，实现一定程度的解耦表示学习。

> **ai_Abstract:** 本文探讨了将解耦表示从合成数据迁移到真实数据的可行性与有效性，旨在克服解耦表示学习在真实图像上遇到的挑战，如相关生成因素和真实标签的获取限制。研究通过实证分析了微调的影响及解耦属性的保留情况，并引入了一种新的基于干预的可解释度量标准来评估表示质量。结果表明，这种迁移方法能够实现一定程度的解耦，并取得了良好的效果。

> **摘要翻译:** 开发有意义且高效的表示，以分离数据生成机制的基本结构，在表示学习中至关重要。然而，解耦表示学习尚未在真实图像上充分发挥其潜力，原因在于生成因素的相关性、其分辨率以及对真实标签的有限访问。特别是在后者方面，我们研究了利用合成数据学习适用于真实数据的通用解耦表示的可能性，讨论了微调的效果以及迁移后解耦的哪些属性得以保留。我们提供了广泛的实证研究来解决这些问题。此外，我们提出了一种新的可解释的基于干预的度量标准，用于衡量表示中因子编码的质量。我们的结果表明，将表示从合成数据迁移到真实数据，一定程度的解耦是可能且有效的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [409] [Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models](https://arxiv.org/abs/2506.21330)
> *全局手术阶段识别与分层输入依赖状态空间模型*

*Haoyang Wu, Tsun-Hsuan Wang, Mathias Lechner, Ramin Hasani, Jennifer A. Eckhoff, Paul Pak, Ozanan R. Meireles, Guy Rosman, Yutong Ban, Daniela Rus* | **Category: cs.CV, cs.AI**

**Keywords:** 手术阶段识别, 状态空间模型, 机器人辅助手术, 视频分析, 分层模型

**Comment:** 

> **TL;DR:** 提出一种分层输入依赖状态空间模型，用于全局手术阶段识别，解决了长视频处理中Transformer模型的效率问题，并显著优于现有SOTA方法。

**AI_Comments:** 该论文的创新点在于引入了分层输入依赖状态空间模型来解决长手术视频分析中Transformer模型效率低下的问题。通过结合局部和全局动态捕捉能力，并利用状态空间模型的线性扩展特性，该方法有效地提高了手术阶段识别的准确性，并在多个基准数据集上取得了显著的性能提升，对机器人辅助手术的自动化分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人辅助手术中的手术流程分析至关重要，但长时间的手术视频给全面视频分析带来挑战。现有方法（如Transformer模型）的二次注意力机制限制了对长手术视频的有效处理。

**Method:** 提出一种新颖的分层输入依赖状态空间模型，利用状态空间模型的线性扩展特性，实现全长视频的决策，并捕捉局部和全局动态。该框架包含一个时间一致的视觉特征提取器，将状态空间模型头部附加到视觉特征提取器上以传播时间信息。模型由两个关键模块组成：一个局部聚合状态空间模型块（捕捉局部动态）和一个全局关系状态空间模型块（建模整个视频的时间依赖性）。模型采用混合离散-连续监督策略进行训练，其中离散阶段标签和连续阶段进度信号都通过网络传播。

**Result:** 该方法在Cholec80数据集上优于现有SOTA方法2.8%，在MICCAI2016数据集上优于4.3%，在Heichole数据集上优于12.9%。

**Conclusion:** 所提出的分层输入依赖状态空间模型有效解决了长手术视频分析的挑战，并在多个数据集上取得了显著优于现有最先进方法的性能，证明了其在全局手术阶段识别中的有效性。

> **ai_Abstract:** 本文提出一种新颖的分层输入依赖状态空间模型（HIDS），旨在解决机器人辅助手术中长视频分析的挑战。该模型利用状态空间模型的线性扩展特性，能够处理全长手术视频并捕捉局部与全局时间动态。HIDS包含一个时间一致的视觉特征提取器，并由局部聚合和全局关系两个状态空间模型块构成。通过混合离散-连续监督策略训练，实验结果表明HIDS在Cholec80、MICCAI2016和Heichole等数据集上显著超越了现有最先进方法，证明了其在全局手术阶段识别中的优越性。

> **摘要翻译:** 手术流程分析在机器人辅助手术中至关重要，然而此类手术的长时间特性给全面的视频分析带来了巨大挑战。最近的方法主要依赖于Transformer模型；然而，它们的二次注意力机制限制了对冗长手术视频的有效处理。在本文中，我们提出了一种新颖的分层输入依赖状态空间模型，该模型利用状态空间模型的线性缩放特性，能够在全长视频上进行决策，同时捕捉局部和全局动态。我们的框架包含一个时间一致的视觉特征提取器，它将一个状态空间模型头部附加到视觉特征提取器上以传播时间信息。所提出的模型由两个关键模块组成：一个有效捕捉复杂局部动态的局部聚合状态空间模型块，以及一个建模整个视频时间依赖性的全局关系状态空间模型块。该模型采用混合离散-连续监督策略进行训练，其中离散阶段标签和连续阶段进度的两种信号都通过网络传播。实验表明，我们的方法在Cholec80数据集上以2.8%的显著优势、在MICCAI2016数据集上以4.3%的优势、在Heichole数据集上以12.9%的优势超越了目前的最新技术。代码将在论文接收后公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [411] [PanSt3R: Multi-view Consistent Panoptic Segmentation](https://arxiv.org/abs/2506.21348)
> *PanSt3R: 多视角一致的全景分割*

*Lojze Zust, Yohann Cabon, Juliette Marrie, Leonid Antsfeld, Boris Chidlovskii, Jerome Revaud, Gabriela Csurka* | **Category: cs.CV**

**Keywords:** 全景分割, 3D场景, 多视角, 深度学习, 三维重建

**Comment:** Accepted at ICCV 2025

> **TL;DR:** PanSt3R是一种新的方法，用于从未定位的2D图像进行3D全景分割，通过一次前向传播联合预测3D几何和多视角全景分割，无需测试时优化，且比现有方法更快、更优。

**AI_Comments:** PanSt3R的创新之处在于其统一且集成的框架，它通过单次前向传播同时处理3D几何和多视角全景分割，从而避免了传统方法中耗时的测试时优化。这种方法不仅提高了效率，还在性能上超越了现有技术。它利用了3D重建的最新进展，并对多视角分割的后处理进行了改进，使其在实际应用中更具吸引力。

<details>
  <summary>Details</summary>

**Motivation:** 在仅依靠未定位的2D图像进行3D场景全景分割是一个具有挑战性的问题。现有方法通常依赖于2D全景分割，然后优化隐式几何表示（如NeRF）来融合2D预测，这种方法是次优的，因为它未能充分利用跨视图的空间关系，并且需要相机参数和计算成本高昂的测试时优化。

**Method:** 本文提出了一种统一的集成方法PanSt3R，通过在一次前向传播中联合预测3D几何和多视角全景分割，消除了测试时优化的需要。该方法建立在3D重建的最新进展之上，特别是MUSt3R（DUSt3R的可扩展多视角版本），并增强了语义感知和多视角全景分割能力。此外，还重新审视了标准的后处理掩码合并过程，并引入了一种更原则性的多视角分割方法，以及一种基于PanSt3R和3DGS预测生成新视角预测的简单方法。

**Result:** 所提出的PanSt3R概念简单、快速且可扩展，在多个基准测试中实现了最先进的性能，同时比现有方法快几个数量级。

**Conclusion:** PanSt3R提供了一种新颖、高效且有效的解决方案，用于从未定位的2D图像进行3D场景全景分割，显著优于现有方法，解决了测试时优化和计算效率低下的问题。

> **ai_Abstract:** PanSt3R提出了一种创新的方法，用于从无姿态的2D图像进行3D场景全景分割。与现有依赖2D分割和耗时测试时优化的方法不同，PanSt3R通过一次前向传播联合预测3D几何和多视角全景分割，实现了无测试时优化。该方法基于MUSt3R并增强了语义能力，同时改进了多视角分割的后处理。PanSt3R在概念上简单、快速且可扩展，在多项基准测试中达到了最先进的性能，并显著提高了速度。

> **摘要翻译:** 3D场景的全景分割，涉及场景密集3D重建中对象实例的分割和分类，是一个具有挑战性的问题，尤其是在仅依靠未定位的2D图像时。现有方法通常利用现成的模型提取每帧2D全景分割，然后优化隐式几何表示（通常基于NeRF）来整合和融合2D预测。我们认为，对于一个本质上是3D和多视角的问题，依赖2D全景分割可能是次优的，因为它未能充分利用跨视图的空间关系。除了需要相机参数外，这些方法还需要对每个场景进行计算成本高昂的测试时优化。相反，在这项工作中，我们提出了一种统一的集成方法PanSt3R，通过在一次前向传播中联合预测3D几何和多视角全景分割，消除了测试时优化的需要。我们的方法建立在3D重建的最新进展之上，特别是基于DUSt3R的可扩展多视角版本MUSt3R，并增强了语义感知和多视角全景分割能力。我们还重新审视了标准的后处理掩码合并过程，并引入了一种更原则性的多视角分割方法。我们还介绍了一种基于PanSt3R和普通3DGS的预测生成新视角预测的简单方法。总的来说，所提出的PanSt3R概念简单，但快速且可扩展，在多个基准测试中实现了最先进的性能，同时比现有方法快几个数量级。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models](https://arxiv.org/abs/2506.21356)
> *ShotBench：视觉语言模型中的专家级电影理解*

*Hongbo Liu, Jingwen He, Yi Jin, Dian Zheng, Yuhao Dong, Fan Zhang, Ziqi Huang, Yinan He, Yangguang Li, Weichao Chen, Yu Qiao, Wanli Ouyang, Shengjie Zhao, Ziwei Liu* | **Category: cs.CV**

**Keywords:** 电影理解, 视觉语言模型, ShotBench, ShotQA, ShotVL

**Comment:** 

> **TL;DR:** 本文介绍了ShotBench，一个用于评估视觉语言模型电影理解能力的基准测试，并发现现有模型存在显著局限性。为解决此问题，作者构建了ShotQA数据集并开发了ShotVL模型，该模型在ShotBench上取得了最先进的性能。

**AI_Comments:** 本文通过引入首个专门针对电影语言理解的基准ShotBench，填补了视觉语言模型在电影领域评估的空白。它不仅揭示了现有模型的局限性，还通过构建大规模数据集ShotQA和开发新模型ShotVL，为该领域提供了重要的资源和解决方案，展示了其在推动AI电影理解和生成方面的重要性和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型（VLMs）在理解电影中细致的电影语法方面能力有限，且缺乏鲁棒的评估方法。这一关键空白限制了细粒度视觉理解和AI辅助视频生成的精度。

**Method:** 1. 引入ShotBench，一个包含3.5k专家标注问答对的电影语言理解基准，数据来源于200多部电影，涵盖八个电影摄影维度。2. 在ShotBench上评估24个领先的VLM，揭示其局限性。3. 构建ShotQA，一个包含约70k电影问答对的大规模多模态数据集。4. 利用ShotQA，通过监督微调和群组相对策略优化开发ShotVL模型。

**Result:** 1. 对24个领先VLM的评估显示，即使表现最佳的模型平均准确率也低于60%，尤其在细粒度视觉线索和复杂空间推理方面表现不佳。2. ShotVL在ShotBench上显著优于所有现有开源和专有模型，建立了新的最先进性能。

**Conclusion:** 现有视觉语言模型在电影理解方面存在显著局限性。通过引入ShotBench基准、构建ShotQA数据集和开发ShotVL模型，本文成功提升了AI在电影理解和生成方面的能力，并为该领域的未来研究奠定了基础。

> **ai_Abstract:** 本文介绍了ShotBench，一个专门用于评估视觉语言模型（VLMs）电影理解能力的综合基准。研究发现现有VLMs在此方面存在显著不足。为弥补这一差距，作者构建了大规模电影问答数据集ShotQA，并基于此开发了ShotVL模型。ShotVL在ShotBench上取得了突破性进展，显著超越了现有模型，确立了电影理解的新技术水平，并开源了相关资源以推动领域发展。

> **摘要翻译:** 电影摄影作为电影最基本的视觉语言，对于传达叙事、情感和美学质量至关重要。尽管最近的视觉语言模型（VLMs）展示了强大的通用视觉理解能力，但它们在理解个体镜头中嵌入的细致电影语法方面的熟练程度仍未被充分探索，并且缺乏鲁棒的评估。这一关键空白限制了细粒度视觉理解和AI辅助视频生成的精度。为了解决这个问题，我们引入了ShotBench，一个专门为电影语言理解设计的综合基准。它包含来自图像和视频片段的3.5k多个专家标注的问答对，这些问答对经过精心策划，来源于200多部著名（主要是奥斯卡提名）电影，并涵盖了八个关键的电影摄影维度。我们对24个领先的VLM在ShotBench上的评估揭示了它们存在的显著局限性：即使是表现最佳的模型，其平均准确率也低于60%，尤其在细粒度视觉线索和复杂空间推理方面表现挣扎。为了促进该领域的进步，我们构建了ShotQA，一个包含大约70k电影问答对的大规模多模态数据集。利用ShotQA，我们通过监督微调和群组相对策略优化开发了ShotVL。ShotVL在ShotBench上显著优于所有现有开源和专有模型，建立了新的最先进性能。我们开源了我们的模型、数据和代码，以促进AI驱动的电影理解和生成这一关键领域的快速发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [413] [CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations](https://arxiv.org/abs/2506.21357)
> *CoPa-SG：具有参数化和原型关系图的密集场景图*

*Julian Lorenz, Mrunmai Phatak, Robin Schön, Katja Ludwig, Nico Hörmann, Annemarie Friedrich, Rainer Lienhart* | **Category: cs.CV**

**Keywords:** 场景图, CoPa-SG, 参数化关系, 原型关系, 数据集

**Comment:** 

> **TL;DR:** 提出了CoPa-SG数据集和参数化、原型关系，以解决场景图数据不足问题并增强表示和推理能力。

**AI_Comments:** 本文通过引入CoPa-SG数据集和参数化/原型关系，有效解决了场景图领域的数据稀缺和关系表示粒度不足的问题。特别是参数化关系和原型关系的概念，为场景图的表达能力和动态推理提供了新的视角，对于提升机器人规划和AI推理等下游应用的性能具有重要意义，展现了良好的创新性。

<details>
  <summary>Details</summary>

**Motivation:** 当前二维场景图工作面临缺乏准确场景图数据的瓶颈，且现有关系表示不够细致。

**Method:** 提出了CoPa-SG合成场景图数据集，具有精确的地面真值和详尽的关系标注。引入了两种新的基本概念：参数化关系（用角度或距离等参数丰富关系）和原型关系（编码假设关系，描述新对象加入时关系如何形成）。

**Result:** 使用CoPa-SG比较了各种场景图生成模型的性能。展示了新的关系类型如何集成到下游应用中以增强规划和推理能力。

**Conclusion:** CoPa-SG数据集和引入的参数化、原型关系能有效解决场景图数据不足问题，并提升场景图的表示细粒度和下游应用的规划推理能力。

> **ai_Abstract:** 本文针对二维场景图面临的准确数据稀缺问题，提出了CoPa-SG合成数据集，该数据集包含高精度真值和详尽的对象间关系标注。同时，文章引入了两种创新关系概念：参数化关系，通过增加角度、距离等参数实现更精细的关系描述；以及原型关系，用于编码假设性关系，预测新对象加入场景后的关系形成。研究利用CoPa-SG数据集评估了多种场景图生成模型的性能，并证明了新关系类型能有效提升下游应用的规划和推理能力。

> **摘要翻译:** 二维场景图为场景理解提供了一个结构化且可解释的框架。然而，目前的工作仍在努力解决缺乏准确场景图数据的问题。为了克服这一数据瓶颈，我们提出了CoPa-SG，一个合成场景图数据集，具有高度精确的地面真值和所有对象之间详尽的关系标注。此外，我们引入了参数化关系和原型关系，这是场景图的两个新的基本概念。前者通过用角度或距离等额外参数丰富关系，提供了比传统对应物更细粒度的表示。后者在场景图中编码假设关系，并描述了如果将新对象放置在场景中，关系将如何形成。使用CoPa-SG，我们比较了各种场景图生成模型的性能。我们展示了如何将我们的新关系类型集成到下游应用程序中，以增强规划和推理能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [416] [CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection](https://arxiv.org/abs/2506.21364)
> *CA-I2P: 通道自适应配准网络与全局最优选择*

*Zhixin Cheng, Jiacheng Deng, Xinjun Li, Xiaotian Yin, Bohao Liao, Baoqun Yin, Wenfei Yang, Tianzhu Zhang* | **Category: cs.CV, cs.AI**

**Keywords:** 图像到点云配准, 通道自适应, 全局最优选择, 跨模态匹配, 特征学习

**Comment:** ICCV 2025 accepted

> **TL;DR:** 提出CA-I2P，通过通道自适应调整和全局最优选择模块，解决了图像到点云配准中特征通道差异和相似结构冗余对应的问题，实现了最先进的性能。

**AI_Comments:** 这篇论文通过引入通道自适应调整模块和全局最优选择模块，创新性地解决了图像到点云配准中特征差异和冗余对应的问题。这种方法提升了跨模态匹配的鲁棒性和准确性，对于需要高精度多模态数据融合的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有无检测方法在图像与点云特征通道注意力差异和场景中相似结构导致的冗余对应问题，导致配准精度下降。

**Method:** 提出通道自适应调整模块（CAA）增强模态内特征并抑制跨模态敏感性，以及全局最优选择模块（GOS）用全局优化取代局部选择。

**Result:** 在RGB-D Scenes V2和7-Scenes数据集上，我们的方法在图像到点云配准中取得了最先进的性能。

**Conclusion:** CA-I2P通过其提出的CAA和GOS模块，有效解决了图像到点云配准中的关键挑战，显著提高了配准精度。

> **ai_Abstract:** 本文提出CA-I2P，一个用于图像到点云配准的通道自适应配准网络。该网络通过通道自适应调整模块（CAA）解决特征通道注意力差异问题，并通过全局最优选择模块（GOS）处理相似结构导致的冗余对应。实验证明，CA-I2P在图像到点云配准任务上达到了最先进的性能。

> **摘要翻译:** 无检测方法通常遵循从粗到精的流程，提取图像和点云特征进行补丁级匹配并细化密集的像素到点对应。然而，图像和点云之间特征通道注意力的差异可能导致匹配结果退化，最终损害配准精度。此外，场景中的相似结构可能导致跨模态匹配中出现冗余对应。为了解决这些问题，我们提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强模态内特征并抑制跨模态敏感性，而GOS用全局优化取代局部选择。在RGB-D Scenes V2和7-Scenes上的实验证明了我们方法的优越性，在图像到点云配准中取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [418] [GenFlow: Interactive Modular System for Image Generation](https://arxiv.org/abs/2506.21369)
> *GenFlow：交互式模块化图像生成系统*

*Duc-Hung Nguyen, Huu-Phuc Huynh, Minh-Triet Tran, Trung-Nghia Le* | **Category: cs.CV**

**Keywords:** GenFlow, 生成艺术, 模块化系统, 图像生成, 用户界面

**Comment:** 

> **TL;DR:** GenFlow是一个模块化系统，通过直观的界面和智能助手，使所有技能水平的用户都能轻松进行图像生成和生成艺术创作。

**AI_Comments:** GenFlow的创新之处在于其将复杂的生成艺术工作流程通过模块化、节点式编辑和NLP智能助手进行了极大的简化和用户友好化。这对于降低生成艺术的入门门槛，推广其应用具有重要意义。该系统通过自动化部署和减少技术障碍，使得更多非专业用户也能接触和使用前沿的生成艺术工具，有望推动该领域的普及和发展。其用户研究结果也验证了其在优化效率和提升用户体验方面的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 生成艺术虽然具有无限的创意潜力，但由于需要高级架构概念和计算工作流程方面的技术专业知识，其全部潜力尚未得到充分发挥。本研究旨在弥合这一差距，让所有用户都能轻松进行生成艺术创作。

**Method:** 本研究提出了GenFlow，一个新颖的模块化框架。该系统具有一个基于节点的编辑器，用于无缝定制，并配备了一个由自然语言处理驱动的智能助手。GenFlow通过自动化部署过程和最小化技术障碍，将复杂的工作流程创建转化为直观且易于访问的体验。

**Result:** 一项用户研究表明，GenFlow能够优化工作流程，减少任务完成时间，并通过其直观的界面和自适应功能增强用户理解。这些结果表明GenFlow重新定义了生成艺术领域的可访问性和效率。

**Conclusion:** GenFlow是一个开创性的解决方案，它通过提供直观、高效和易于访问的工具，重新定义了生成艺术领域的可访问性和效率，使得尖端生成艺术工具能够被所有人使用。

> **ai_Abstract:** GenFlow是一个创新的模块化系统，旨在降低生成艺术的创作门槛。它通过提供一个基于节点的直观编辑器和由自然语言处理驱动的智能助手，简化了复杂的图像生成工作流程。该系统自动化部署并减少技术障碍，使得所有技能水平的用户都能轻松创建生成艺术。用户研究证实，GenFlow能优化工作流程、缩短任务时间并提升用户理解，从而在生成艺术领域实现了更高的可访问性和效率。

> **摘要翻译:** 生成艺术开启了无限的创意可能性，但由于高级架构概念和计算工作流程所需的技术专业知识，其全部潜力尚未得到充分发挥。为了弥合这一差距，我们提出了GenFlow，一个新颖的模块化框架，它使所有技能水平的用户都能够精确、轻松地生成图像。GenFlow具有一个基于节点的编辑器，用于无缝定制，以及一个由自然语言处理驱动的智能助手，它将工作流程创建的复杂性转化为直观且易于访问的体验。通过自动化部署过程和最小化技术障碍，我们的框架使尖端生成艺术工具可供所有人使用。一项用户研究表明，GenFlow能够通过其直观的界面和自适应功能优化工作流程，减少任务完成时间，并增强用户理解。这些结果将GenFlow定位为一个开创性的解决方案，它重新定义了生成艺术领域的可访问性和效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [FastRef:Fast Prototype Refinement for Few-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.21398)
> *FastRef：用于少样本工业异常检测的快速原型细化*

*Long Tian, Yufei Li, Yuyang Dai, Wenchao Chen, Xiyang Liu, Bo Chen* | **Category: cs.CV**

**Keywords:** 少样本异常检测, 原型细化, 工业检测, 特性转移, 最优传输

**Comment:** 18pages, 7figures, 6tables

> **TL;DR:** FastRef提出了一种快速原型细化框架，通过查询特征的特性转移和异常抑制来解决少样本工业异常检测中原型代表性不足的问题，并在多个基准数据集上表现出有效性和计算效率。

**AI_Comments:** FastRef的创新点在于其通过迭代的两阶段过程精炼原型，特别是引入了“特性转移”和“异常抑制”的概念。通过结合查询图像统计数据来增强原型代表性，并利用最优传输处理非高斯特征，解决了少样本设置下异常重构概率增大的关键问题。这对于数据稀缺的工业应用具有重要意义，因为它提高了少样本异常检测的准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有少样本工业异常检测方法主要关注从有限的正常样本中派生原型，但通常忽略系统地结合查询图像统计数据来增强原型代表性，这在数据稀缺的实际自动化检测系统中是一个关键挑战。

**Method:** 本文提出了FastRef，一种新颖高效的少样本工业异常检测原型细化框架。该方法通过迭代的两阶段过程进行操作：(1) 通过可优化的变换矩阵将查询特征的特性转移到原型；(2) 通过原型对齐进行异常抑制。特性转移通过原型对查询特征进行线性重构实现。异常抑制则通过使用最优传输(OT)来测量和最小化原型与其细化对应物之间的差距，以处理非高斯采样特征，因为在少样本设置下异常重构的可能性更高。

**Result:** FastRef已与PatchCore, FastRecon, WinCLIP, 和 AnomalyDINO这四种有竞争力的基于原型的少样本工业异常检测方法集成。在MVTec, ViSA, MPDD和RealIAD四个基准数据集上，在1/2/4-shots设置下进行了广泛实验，结果证明了该方法的有效性和计算效率。

**Conclusion:** FastRef通过其创新的原型细化框架，有效解决了少样本工业异常检测中原型代表性不足的问题，并在实际应用中展现出良好的性能和效率。

> **ai_Abstract:** FastRef提出了一种新颖高效的原型细化框架，用于解决少样本工业异常检测（FS-IAD）中原型代表性不足的问题。该方法采用两阶段迭代过程：一是通过可优化变换矩阵将查询特征特性转移到原型，二是通过最优传输（OT）进行原型对齐以抑制异常。实验结果表明，FastRef在多个基准数据集上与现有FS-IAD方法集成后，在有限样本设置下具有显著的有效性和计算效率。

> **摘要翻译:** 少样本工业异常检测（FS-IAD）对在数据稀缺环境中运行的实际自动化检测系统提出了严峻挑战。虽然现有方法主要侧重于从有限的正常样本中提取原型，但它们通常忽略系统地结合查询图像统计数据来增强原型的代表性。为了解决这个问题，我们提出了FastRef，一种新颖高效的FS-IAD原型细化框架。我们的方法通过迭代的两阶段过程进行操作：(1) 通过可优化的变换矩阵将查询特征的特性转移到原型；(2) 通过原型对齐进行异常抑制。特性转移通过原型对查询特征进行线性重构实现，而异常抑制则解决了FS-IAD中的一个关键观察，即与具有丰富正常原型的传统IAD不同，有限样本设置使得异常重构的可能性更大。因此，我们采用最优传输（OT）处理非高斯采样特征，以测量和最小化原型与其细化对应物之间的差距，从而抑制异常。为了进行全面评估，我们将FastRef与三种有竞争力的基于原型的FS-IAD方法集成：PatchCore、FastRecon、WinCLIP和AnomalyDINO。在MVTec、ViSA、MPDD和RealIAD四个基准数据集上，在1/2/4-shots设置下进行了广泛实验，结果证明了我们方法的有效性和计算效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [421] [Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction](https://arxiv.org/abs/2506.21401)
> *曲线感知高斯泼溅用于三维参数曲线重建*

*Zhirui Gao. Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu* | **Category: cs.CV**

**Keywords:** 三维参数曲线重建, 高斯泼溅, 单阶段方法, 可微分渲染, CurveGaussian

**Comment:** Code: https://github.com/zhirui-gao/Curve-Gaussian Accepted by ICCV
  2025

> **TL;DR:** 提出一种名为CurveGaussian的单阶段端到端框架，通过曲线感知高斯表示实现从多视图边缘图直接重建三维参数曲线，克服了传统两阶段方法的误差累积问题，并实现了更高效和卓越的性能。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的单阶段框架，直接优化3D参数曲线，避免了传统两阶段方法的误差累积。核心贡献是“CurveGaussian”表示，它巧妙地结合了参数曲线和高斯泼溅的优势，实现了3D曲线的可微分渲染。此外，动态拓扑优化也增强了方法的实用性。这项工作为3D曲线重建提供了一个高效且鲁棒的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的三维参数曲线重建方法是两阶段的，先重建边缘点云再拟合曲线，导致误差累积和优化鸿沟。此外，参数曲线本身不适合基于渲染的多视图优化。

**Method:** 本文提出一个端到端的单阶段框架，直接从2D边缘图优化3D参数曲线。核心是引入参数曲线与边缘导向高斯分量之间的双向耦合机制，形成“CurveGaussian”表示，实现3D曲线的可微分渲染，从而允许由多视图证据引导的直接优化。此外，训练过程中还引入了动态自适应拓扑优化框架（通过线性化、合并、分割和修剪操作）来完善曲线结构。

**Result:** 在ABC数据集和真实世界基准测试中，该单阶段方法优于两阶段替代方案，尤其在生成更清晰、更鲁棒的重建方面。通过直接优化参数曲线，显著减少了训练过程中的参数数量，实现了更高的效率和卓越的性能。

**Conclusion:** 本文提出的单阶段CurveGaussian框架通过直接从2D边缘图优化3D参数曲线，有效解决了传统两阶段方法的误差累积问题，并在效率和重建质量上均超越现有方法。

> **ai_Abstract:** 本文提出了一种名为CurveGaussian的创新性单阶段框架，用于从多视图边缘图直接重建三维参数曲线。该方法通过引入参数曲线与边缘导向高斯分量的双向耦合机制，克服了传统两阶段方法中存在的误差累积和优化差距问题，实现了3D曲线的可微分渲染及直接优化。结合动态自适应拓扑优化，CurveGaussian在重建质量、效率和鲁棒性方面均显著优于现有方法。

> **摘要翻译:** 本文提出一个端到端框架，用于直接从多视图边缘图重建三维参数曲线。与现有遵循“边缘点云重建和参数曲线拟合”顺序管道的两阶段方法形成对比，我们的一阶段方法直接从2D边缘图优化3D参数曲线，消除了由不连贯阶段之间固有的优化差距引起的误差累积。然而，参数曲线本质上不适合基于渲染的多视图优化，因此需要一种互补的表示，既能保留其几何属性又能实现可微分渲染。我们提出了一种新颖的参数曲线与边缘导向高斯分量之间的双向耦合机制。这种紧密的对应关系形成了一种曲线感知高斯表示，\textbf{CurveGaussian}，它使得3D曲线的可微分渲染成为可能，从而允许由多视图证据引导的直接优化。此外，我们在训练过程中引入了一个动态自适应拓扑优化框架，通过线性化、合并、分割和修剪操作来完善曲线结构。在ABC数据集和真实世界基准上的全面评估表明，我们的一阶段方法优于两阶段替代方案，特别是在生成更清晰、更鲁棒的重建方面。此外，通过直接优化参数曲线，我们的方法显著减少了训练期间的参数数量，与现有方法相比，实现了更高的效率和卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [422] [XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation](https://arxiv.org/abs/2506.21416)
> *XVerse：通过DiT调制实现身份和语义属性的多主体一致性控制*

*Bowen Chen, Mengyi Zhao, Haomiao Sun, Li Chen, Xu Wang, Kang Du, Xinglong Wu* | **Category: cs.CV**

**Keywords:** XVerse, 多主体控制, DiT调制, 身份控制, 语义属性

**Comment:** Project Page: https://bytedance.github.io/XVerse Github Link:
  https://github.com/bytedance/XVerse

> **TL;DR:** XVerse是一个新的多主体图像生成模型，通过将参考图像转换为文本流调制的偏移量，解决了多主体文本到图像生成中身份和语义属性控制的挑战，实现了高保真、可编辑的多主体图像合成。

**AI_Comments:** XVerse通过其独特的“参考图像到偏移量”的转换机制，实现了对多主体身份和语义属性的精细控制，解决了DiTs在多主体生成中的一致性和可编辑性难题。这种不干扰图像潜在表示或特征的方法，是其创新点所在，对于个性化和复杂场景的图像生成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在文本到图像生成中，特别是对于多个主体，实现对主体身份和语义属性（姿态、风格、光照）的细粒度控制，往往会损害扩散变换器（DiTs）的可编辑性和连贯性。许多现有方法会引入伪影或遭受属性纠缠问题。

**Method:** 我们提出了一个新颖的多主体受控生成模型XVerse。通过将参考图像转换为针对特定token的文本流调制的偏移量，XVerse可以在不干扰图像潜在表示或特征的情况下，对特定主体进行精确且独立的控制。

**Result:** XVerse提供了高保真、可编辑的多主体图像合成，并能对个体主体特征和语义属性进行稳健控制。

**Conclusion:** 这项进展显著提高了个性化和复杂场景的生成能力。

> **ai_Abstract:** 本文提出了一种名为XVerse的新型多主体受控生成模型，旨在解决在文本到图像生成中，尤其是在多主体场景下，对主体身份和语义属性进行细粒度控制时，扩散变换器（DiTs）的可编辑性和连贯性受损，以及现有方法引入伪影和属性纠缠的问题。XVerse通过将参考图像转换为token特异性文本流调制的偏移量，实现了对特定主体的精确和独立控制，且不干扰图像的潜在表示或特征。最终，XVerse能够生成高保真、可编辑的多主体图像，并对个体主体的特征和语义属性进行稳健控制，从而显著提升了个性化和复杂场景的生成能力。

> **摘要翻译:** 在文本到图像生成中，特别是对于多个主体，实现对主体身份和语义属性（姿态、风格、光照）的细粒度控制，往往会损害扩散变换器（DiTs）的可编辑性和连贯性。许多方法会引入伪影或遭受属性纠缠。为了克服这些挑战，我们提出了一个新颖的多主体受控生成模型XVerse。通过将参考图像转换为针对特定token的文本流调制的偏移量，XVerse可以在不干扰图像潜在表示或特征的情况下，对特定主体进行精确且独立的控制。因此，XVerse提供了高保真、可编辑的多主体图像合成，并能对个体主体特征和语义属性进行稳健控制。这项进展显著提高了个性化和复杂场景的生成能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [HyperSORT: Self-Organising Robust Training with hyper-networks](https://arxiv.org/abs/2506.21430)
> *HyperSORT：基于超网络的自组织鲁棒训练*

*Samuel Joutard, Marijn Stollenga, Marc Balle Sanchez, Mohammad Farid Azampour, Raphael Prevost* | **Category: cs.CV**

**Keywords:** HyperSORT, 超网络, 鲁棒训练, 医学影像分割, 数据偏置, UNet

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** HyperSORT是一个使用超网络学习UNet参数复杂分布的框架，用于处理医学图像数据集中存在的偏置和错误标签，从而实现鲁棒的分割和偏置识别。

**AI_Comments:** 这篇论文提出了一种创新的方法来处理医学影像数据中常见的标注偏置和错误，这是一个重要的实际问题。通过引入超网络来学习UNet参数的分布，而不是单个网络，HyperSORT能够更灵活地适应数据中的变异性。其能够识别数据集中的系统性偏置和错误样本的特性，对于数据质量控制和模型解释性具有重要意义。这种方法有望提高深度学习模型在真实世界医疗数据上的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像数据集常包含异质性偏置，如错误标签和不一致的标注风格，这些偏置会严重影响深度分割网络的性能。然而，识别和表征这些偏置是一项繁琐且具挑战性的任务。

**Method:** 论文提出了HyperSORT框架，该框架利用一个超网络从代表图像和标注变异性的潜在向量中预测UNet的参数。超网络参数和对应每个训练数据样本的潜在向量集合是联合学习的。与优化单个神经网络拟合数据集不同，HyperSORT学习UNet参数的复杂分布，其中低密度区域可以捕获噪声特异性模式，而较大模式则以区分但有意义的方式稳健地分割器官。该方法在两个3D腹部CT公共数据集上进行了验证：一个是合成扰动版的AMOS数据集，另一个是包含真实未知偏置和错误的大规模TotalSegmentator数据集。

**Result:** 实验表明，HyperSORT创建了数据集的结构化映射，从而能够识别相关的系统性偏置和错误样本。潜在空间聚类产生的UNet参数能够根据底层学习到的系统性偏置执行分割任务。

**Conclusion:** HyperSORT能够有效处理医学影像数据中的异质性偏置，通过学习UNet参数的复杂分布，不仅实现了鲁棒的分割，还能识别并映射数据集中的系统性偏置和错误样本。

> **ai_Abstract:** HyperSORT是一种新颖的框架，通过利用超网络和联合学习策略，解决了医学影像数据集中存在的异质性偏置（如错误标签和不一致标注）对深度分割网络性能的负面影响。该方法不直接优化单一网络，而是学习UNet参数的复杂分布，使得网络能够捕获噪声模式并鲁棒地执行分割任务。实验证明，HyperSORT能有效识别数据集中的系统性偏置和错误样本，并通过潜在空间聚类生成适应特定偏置的分割参数。

> **摘要翻译:** 医学影像数据集通常包含异质性偏置，从错误的标签到不一致的标注风格。这些偏置会对深度分割网络的性能产生负面影响。然而，识别和表征这些偏置是一项特别繁琐和具有挑战性的任务。在本文中，我们引入了HyperSORT，这是一个使用超网络从代表图像和标注变异性的潜在向量中预测UNet参数的框架。超网络参数和对应训练集中每个数据样本的潜在向量集合是联合学习的。因此，HyperSORT不是优化单个神经网络来拟合数据集，而是学习UNet参数的复杂分布，其中低密度区域可以捕获噪声特异性模式，而较大模式则以差异化但有意义的方式稳健地分割器官。我们在两个3D腹部CT公共数据集上验证了我们的方法：首先是AMOS数据集的一个合成扰动版本，其次是TotalSegmentator，一个包含真实未知偏置和错误的大规模数据集。我们的实验表明，HyperSORT创建了数据集的结构化映射，从而能够识别相关的系统性偏置和错误样本。潜在空间聚类产生的UNet参数能够根据底层学习到的系统性偏置执行分割任务。代码和我们对TotalSegmentator数据集的分析已可用：https://github.com/ImFusionGmbH/HyperSORT

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [426] [Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation](https://arxiv.org/abs/2506.21444)
> *深度学习和视觉基础模型在非典型与正常有丝分裂分类中的基准测试及跨数据集评估*

*Sweta Banerjee, Viktoria Weiss, Taryn A. Donovan, Rutger A. Fick, Thomas Conrad, Jonas Ammeling, Nils Porsche, Robert Klopfleisch, Christopher Kaltenecker, Katharina Breininger, Marc Aubreville, Christof A. Bertram* | **Category: cs.CV**

**Keywords:** 非典型有丝分裂, 深度学习, 视觉基础模型, 迁移学习, LoRA

**Comment:** 

> **TL;DR:** 本研究对深度学习和视觉基础模型在非典型有丝分裂分类中的表现进行了基准测试，引入了新的数据集进行跨领域评估，并发现迁移学习和模型微调技术（特别是LoRA）能有效解决这一挑战性问题。

**AI_Comments:** 这项研究的重要性在于它系统地评估了前沿的深度学习和视觉基础模型在病理学中一个具有挑战性的分类任务上的表现。通过引入新的、多领域的数据集进行跨数据集评估，增强了研究结果的泛化性。特别是，发现LoRA等高效微调技术在解决类别不平衡和形态差异细微的问题上表现出色，为未来的病理图像分析提供了有价值的指导。公开代码和数据也促进了研究的透明度和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 非典型有丝分裂是肿瘤恶性程度的独立预后相关标志物，但其识别具有挑战性，原因包括患病率低、与正常有丝分裂形态差异细微、病理学家间判读一致性低以及数据集中类别不平衡。

**Method:** 本研究基于Atypical Mitosis dataset for Breast Cancer (AMi-Br)数据集，对用于自动化非典型有丝分裂（AMF）分类的深度学习方法进行了全面基准测试，包括基线模型、带有线性探测的基础模型以及使用低秩适应（LoRA）进行微调的基础模型。此外，引入了两个新的保留AMF数据集：AtNorM-Br（来自TCGA乳腺癌队列）和AtNorM-MD（来自MIDOG++训练集的多领域数据集）进行严格评估。

**Result:** 研究发现在域内AMi-Br数据集上平均平衡准确率最高可达0.8135，在域外AtNorM-Br和AtNorM-MD数据集上分别为0.7696和0.7705。其中，基于LoRA对Virchow系列基础模型的适应效果尤为出色。

**Conclusion:** 非典型有丝分裂分类是一个具有挑战性的问题，但通过利用迁移学习和模型微调技术（特别是LoRA）的最新进展，可以有效地解决。

> **ai_Abstract:** 本研究旨在解决非典型有丝分裂识别的挑战，对深度学习和视觉基础模型在非典型与正常有丝分裂分类中的性能进行了全面基准测试。研究使用了现有数据集并引入了两个新的跨领域数据集进行评估。结果显示，迁移学习和模型微调技术，特别是基于LoRA的基础模型适应，能有效提升分类准确率，为非典型有丝分裂的自动化识别提供了有效方案。

> **摘要翻译:** 非典型有丝分裂标志着细胞分裂过程的偏差，其可以作为肿瘤恶性程度的独立预后相关标志物。然而，由于患病率低、与正常有丝分裂形态有时差异细微、病理学家之间判读一致性低以及数据集中类别不平衡等原因，其识别仍然具有挑战性。本研究以乳腺癌非典型有丝分裂数据集（AMi-Br）为基础，对自动化非典型有丝分裂（AMF）分类的深度学习方法进行了全面基准测试，包括基线模型、带有线性探测的基础模型以及使用低秩适应（LoRA）进行微调的基础模型。为了进行严格评估，我们进一步引入了两个新的保留AMF数据集——AtNorM-Br，一个来自TCGA乳腺癌队列的有丝分裂数据集，以及AtNorM-MD，一个来自MIDOG++训练集的多领域有丝分裂数据集。我们发现在域内AMi-Br数据集上平均平衡准确率最高可达0.8135，在域外AtNorM-Br和AtNorM-MD数据集上分别为0.7696和0.7705，其中基于LoRA对Virchow系列基础模型的适应效果尤为出色。我们的工作表明，非典型有丝分裂分类虽然是一个具有挑战性的问题，但通过利用迁移学习和模型微调技术的最新进展可以有效地解决。本研究中使用的所有代码和数据均可在以下GitHub仓库获取：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [Controllable 3D Placement of Objects with Scene-Aware Diffusion Models](https://arxiv.org/abs/2506.21446)
> *基于场景感知扩散模型的可控三维物体放置*

*Mohamed Omran, Dimitris Kalatzis, Jens Petersen, Amirhossein Habibian, Auke Wiggers* | **Category: cs.CV**

**Keywords:** 3D物体放置, 扩散模型, 图像编辑, 场景感知, 修复

**Comment:** 

> **TL;DR:** 本文提出了一种利用视觉地图和粗略物体掩码结合修复扩散模型，实现图像中精确、灵活的3D物体放置的方法，并在汽车环境中展示了其有效性。

**AI_Comments:** 本文的创新之处在于利用“精心设计的视觉地图”和“粗略物体掩码”作为条件信号，实现了精确的3D物体放置，这比传统依赖复杂掩码或提示的方法有了显著改进。该方法专注于保持背景不变，并在实际汽车环境中进行验证，增加了其重要性。其处理非平凡形状变化以及结合位置与外观控制的能力，突显了其灵活性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像编辑方法在精确的3D物体放置方面存在挑战，因为这通常需要精心制作的修复掩码或提示，而且这些方法经常同时建模物体和背景，可能改变背景。

**Method:** 作者提出了一种方法，使用精心设计的视觉地图结合粗略的物体掩码作为修复扩散模型的条件信号。这种信号能够解决歧义，并允许灵活地改变物体的形状或方向。该设计确保了背景保持不变。

**Result:** 该方法在汽车环境中得到了有效验证，通过比较不同条件信号在新型物体放置任务中的表现。评估的编辑质量不仅包括外观，还包括姿态和位置精度，甚至涵盖了需要非平凡形状变化的情况。此外，还展示了精细的位置控制可以与外观控制相结合，用于将现有物体精确放置在场景中。

**Conclusion:** 该研究展示了其方法能够实现可控且精确的3D物体放置，同时保持背景不变，并且能够结合精细的位置和外观控制。

> **ai_Abstract:** 本文提出了一种利用场景感知扩散模型实现图像中可控三维物体放置的新方法。它通过引入基于视觉地图和粗略物体掩码的条件信号来解决精确物体定位的挑战，该信号在形状和方向上提供了灵活性，同时保留了背景。该方法基于修复模型构建，并在汽车环境中进行了演示，显示出高质量的物体放置效果，具有准确的姿态和位置，并能够将精细的位置控制与外观控制相结合。

> **摘要翻译:** 随着强大的文本条件生成模型的出现，图像编辑方法变得更加强大和灵活。然而，以精确的位置和方向在环境中放置物体仍然是一个挑战，因为这通常需要精心制作的修复掩码或提示。在这项工作中，我们表明精心设计的视觉地图与粗略的物体掩码相结合，足以实现高质量的物体放置。我们设计了一种条件信号，它能解决歧义，同时足够灵活，允许改变形状或物体方向。通过建立在修复模型的基础上，我们有意保持背景不变，这与联合建模物体和背景的方法形成对比。我们在汽车环境中展示了我们方法的有效性，在新的物体放置任务中比较了不同的条件信号。这些任务旨在不仅从外观方面，而且从姿态和位置精度方面衡量编辑质量，包括需要非平凡形状变化的情况。最后，我们展示了精细的位置控制可以与外观控制相结合，以将现有物体精确放置在场景中的特定位置。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [429] [A Comprehensive Dataset for Underground Miner Detection in Diverse Scenario](https://arxiv.org/abs/2506.21451)
> *针对多样化场景的井下矿工检测综合数据集*

*Cyrus Addy, Ajay Kumar Gurumadaiah, Yixiang Gao, Kwame Awuah-Offei* | **Category: cs.CV, cs.LG**

**Keywords:** 井下矿工检测, 热成像, 数据集, 目标检测, 采矿安全

**Comment:** 

> **TL;DR:** 本文提出了一个用于井下矿工检测的综合热成像数据集，并评估了SOTA目标检测算法，以解决现有训练数据不足的问题，为紧急情况下的矿工检测系统奠定基础。

**AI_Comments:** 这篇论文通过构建一个专门的热成像数据集，解决了井下矿工检测领域数据稀缺的关键问题，具有重要的实际应用价值。其创新点在于专注于热成像数据，这对于光照不足或烟雾弥漫的井下环境尤为重要。通过评估多种SOTA模型，为后续研究提供了有价值的基线。该数据集的发布将极大地推动井下安全和应急响应技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 井下采矿作业面临重大安全挑战，应急响应能力至关重要。虽然机器人有望协助搜救，但其有效性取决于可靠的矿工检测能力。深度学习算法提供了自动化矿工检测的潜在解决方案，但目前缺乏用于井下采矿环境的全面训练数据集。

**Method:** 本文提出了一个新颖的热成像数据集，专门用于开发和验证矿工检测系统，以应对潜在的紧急应用。研究人员系统地捕获了各种采矿活动和场景的热图像，以建立检测算法的坚实基础。为了建立基线性能指标，研究人员评估了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的几种最先进的目标检测算法在该数据集上的表现。

**Result:** 该工作证明了使用热成像进行矿工检测的可行性。该数据集是开发可靠的基于热成像的矿工检测系统的关键第一步。评估了多个SOTA目标检测算法并建立了基线性能指标。

**Conclusion:** 本文证明了使用热成像进行矿工检测的可行性，并为未来在此关键安全应用领域的研究奠定了基础，旨在最终部署到真实的紧急场景中。

> **ai_Abstract:** 本文针对井下矿工检测领域缺乏综合训练数据集的问题，提出了一个新颖的热成像数据集。该数据集通过系统捕获多样化的采矿活动和场景图像构建，旨在支持开发和验证用于紧急情况的矿工检测系统。研究人员利用该数据集评估了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的先进目标检测算法，并建立了基线性能。这项工作证明了热成像在矿工检测中的可行性，并为未来在该关键安全应用领域的研究奠定了基础。

> **摘要翻译:** 井下采矿作业面临重大的安全挑战，这使得应急响应能力至关重要。虽然机器人在协助搜救行动中显示出前景，但其有效性取决于可靠的矿工检测能力。深度学习算法为自动化矿工检测提供了潜在的解决方案，但目前缺乏用于井下采矿环境的全面训练数据集。本文提出了一个新颖的热成像数据集，专门用于开发和验证矿工检测系统，以应对潜在的紧急应用。我们系统地捕获了各种采矿活动和场景的热图像，以建立检测算法的坚实基础。为了建立基线性能指标，我们评估了包括YOLOv8、YOLOv10、YOLO11和RT-DETR在内的几种最先进的目标检测算法在该数据集上的表现。虽然未能涵盖所有可能的紧急情况，但该数据集是开发可靠的基于热成像的矿工检测系统的关键第一步，这些系统最终可能部署在真实的紧急场景中。这项工作证明了使用热成像进行矿工检测的可行性，并为未来在此关键安全应用领域的研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [430] [Rethinking Oversaturation in Classifier-Free Guidance via Low Frequency](https://arxiv.org/abs/2506.21452)
> *通过低频重新思考无分类器引导中的过饱和现象*

*Kaiyu Song, Hanjiang Lai* | **Category: cs.CV**

**Keywords:** 无分类器引导, 扩散模型, 过饱和, 低频信号, 图像生成

**Comment:** 

> **TL;DR:** 本文提出了一种名为LF-CFG的新方法，通过识别并减少低频信号中冗余信息的影响，有效缓解了无分类器引导（CFG）在高引导尺度下导致的过饱和和不真实伪影问题。

**AI_Comments:** 本文的创新点在于从低频信号的角度重新审视了无分类器引导中的过饱和问题，并提出了一个基于信息冗余的新颖解释。通过针对性地处理低频信号中的冗余信息，LF-CFG提供了一种有效的解决方案，具有良好的普适性，对提升扩散模型生成图像的质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 无分类器引导（CFG）在高引导尺度下能够增强条件项的性能，但常常导致图像过饱和和不真实伪影。本文旨在解决这一问题。

**Method:** 本文提出了一种基于低频信号的新视角，认为低频信号中冗余信息的积累是导致过饱和和不真实伪影的关键因素。在此基础上，提出低频改进无分类器引导（LF-CFG）方法。具体而言，该方法引入了一种基于自适应阈值的测量方法来定位冗余信息，通过分析先前和当前步骤之间低频信息的变化率来确定合理的阈值，然后应用降权策略来减少低频信号中冗余信息的影响。

**Result:** 实验结果表明，LF-CFG能够有效缓解各种扩散模型（包括Stable Diffusion-XL, Stable Diffusion 2.1, 3.0, 3.5, 和SiT-XL）中的过饱和和不真实伪影问题。

**Conclusion:** 通过关注低频信号中的冗余信息并对其进行降权处理，LF-CFG成功解决了无分类器引导在高引导尺度下产生的过饱和和不真实伪影，提升了条件扩散模型的图像生成质量。

> **ai_Abstract:** 本文针对无分类器引导（CFG）在高引导尺度下易导致图像过饱和和不真实伪影的问题，提出了一种新的解释：低频信号中冗余信息的积累是根本原因。基于此，论文引入了低频改进无分类器引导（LF-CFG）方法。LF-CFG通过自适应阈值测量定位冗余信息，并根据低频信息的变化率确定阈值，随后采用降权策略减少冗余信息的影响。实验证明，LF-CFG在多种扩散模型上有效改善了过饱和及伪影问题。

> **摘要翻译:** 无分类器引导（CFG）成功地应用于条件扩散模型，它使用引导尺度来平衡条件项和无条件项的影响。高引导尺度用于增强条件项的性能。然而，高引导尺度常常导致过饱和和不真实伪影。在本文中，我们引入了一种基于低频信号的新视角，将这些信号中冗余信息的积累识别为导致过饱和和不真实伪影的关键因素。基于这一见解，我们提出了低频改进无分类器引导（LF-CFG）来缓解这些问题。具体而言，我们引入了一种基于自适应阈值的测量方法来精确定位冗余信息的位置。我们通过分析先前和当前步骤之间低频信息的变化率来确定合理的阈值。然后，我们应用降权策略来减少低频信号中冗余信息的影响。实验结果表明，LF-CFG能够有效缓解各种扩散模型（包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL）中的过饱和和不真实伪影问题。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [432] [Evaluation of Traffic Signals for Daily Traffic Pattern](https://arxiv.org/abs/2506.21469)
> *日常交通模式下交通信号灯的评估*

*Mohammad Shokrolah Shirazi, Hung-Fu Chang* | **Category: cs.CV, cs.LG**

**Keywords:** 交通信号, 转向流量计数, 混合方法, 交通模拟, 日常交通模式

**Comment:** 

> **TL;DR:** 该研究评估了动态、静态和混合交通信号控制方法，利用转向流量计数（TMC）数据进行模拟，发现混合方法在双峰交通模式和加权交通中表现良好。

**AI_Comments:** 该论文引入了一种实用的基于视觉的TMC估算系统，具有实际应用价值。提出的混合信号方法能够适应日常交通的双峰模式，在灵活性和潜在效率方面优于纯静态或纯动态方法，具有创新性。利用SUMO进行仿真验证，增加了研究结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 转向流量计数（TMC）数据对于交通信号设计、交叉口几何规划、交通流和拥堵分析至关重要。日常交通流常呈现双峰模式，因此需要更有效的信号管理方法。

**Method:** 该研究提出了三种基于TMC的交通信号配置方法：动态、静态和混合。开发了一个基于视觉的跟踪系统，利用交通摄像头估算拉斯维加斯六个交叉口的TMC数据。将交叉口设计、路线和信号配置文件合成为兼容格式并导入到城市交通模拟软件（SUMO）中，使用真实数据进行信号评估。提出了一种混合信号方法，可在动态和静态方法之间切换，以适应高峰和非高峰交通状况。内置的交通生成模块创建了包含高峰时段在内的4小时车辆路线，信号设计模块根据静态、动态和混合方法生成信号调度周期。对每个区域（即西、北、东、南）的车辆计数分布进行不同加权，以生成多样化的交通模式。

**Result:** 初步实验结果表明，90秒和120秒的周期时间对所有交叉口效果最佳（基于估计的等待时间）。四个交叉口在动态信号配时配置下表现更好，而另外两个性能较低的交叉口其总车辆数与交叉口支路总车道数的比率较低。扩展实验结果表明，基于区域的交通模式分布会影响信号设计选择。静态方法适用于均匀的基于区域的交通分布，而混合方法对于西-东和北-南区域交叉口对的高加权交通表现良好。

**Conclusion:** 交通信号方法的选择（静态、动态、混合）取决于具体的交通模式分布，其中混合方法对于双峰模式和不均匀分布的交通是有效的。

> **ai_Abstract:** 本文评估了静态、动态和混合交通信号控制方法，这些方法基于转向流量计数（TMC）数据。研究开发了一个基于视觉的系统，用于估算拉斯维加斯六个交叉口的TMC，并在SUMO中进行模拟验证。针对日常交通流的双峰特性，本文提出了一种混合信号方法，该方法能够在高峰和非高峰时段动态切换静态和动态控制策略。实验结果表明，90至120秒的周期时间效果最佳，并且虽然静态方法适用于均匀交通分布，但混合方法在处理高加权交通模式时表现更优，强调了基于区域的交通分布在信号设计选择中的重要性。

> **摘要翻译:** 转向流量计数数据对于交通信号设计、交叉口几何规划、交通流和拥堵分析至关重要。本研究提出了三种基于TMC的交通信号灯方法，分别称为动态、静态和混合配置。开发了一个基于视觉的跟踪系统，利用交通摄像头估算拉斯维加斯六个交叉口的TMC。将交叉口设计、路线（例如车辆移动方向）和兼容格式的信号配置文件合成并导入城市交通模拟软件（SUMO）中，用于真实数据下的信号评估。基于估计等待时间的初步实验结果表明，90秒和120秒的周期时间对所有交叉口效果最佳。此外，四个交叉口在动态信号配时配置下表现更好，而另外两个性能较低的交叉口其总车辆数与交叉口总车道数的比率较低。由于日常交通流通常呈现双峰模式，我们提出了一种混合信号方法，可在动态和静态方法之间切换，以适应高峰和非高峰交通状况，从而改善交通流管理。因此，一个内置的交通生成模块创建了4小时的车辆路线，包括高峰时段，一个信号设计模块根据静态、动态和混合方法生成信号调度周期。对每个区域（即西、北、东、南）的车辆计数分布进行不同加权，以生成多样化的交通模式。对六个交叉口进行4小时模拟的扩展实验结果表明，基于区域的交通模式分布会影响信号设计选择。尽管静态方法对于均匀的基于区域的交通分布效果很好，但混合方法对于西-东和北-南区域交叉口对的高加权交通效果良好。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [Global and Local Entailment Learning for Natural World Imagery](https://arxiv.org/abs/2506.21476)
> *自然世界图像的全局和局部蕴涵学习*

*Srikumar Sastry, Aayush Dhakal, Eric Xing, Subash Khanal, Nathan Jacobs* | **Category: cs.CV**

**Keywords:** 蕴涵学习, 层次结构, 视觉-语言模型, 传递性, 径向跨模态嵌入

**Comment:** Accepted at ICCV 2025

> **TL;DR:** 该论文引入了径向跨模态嵌入（RCME）框架，用于明确建模视觉-语言模型中数据的传递性蕴涵，以学习层次结构。实验证明，RCME在层次物种分类和层次检索任务中表现优于现有SOTA模型。

**AI_Comments:** 该论文的创新点在于明确建模了蕴涵的传递性，这对于准确表示视觉-语言模型中的层次结构至关重要。RCME框架的提出为处理复杂数据层次结构提供了一种有效的新方法。将该方法应用于“生命之树”的表示，展示了其在生物学等真实世界数据中的巨大应用潜力。此外，代码和模型的开源也促进了相关领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉-语言模型中学习数据的层次结构是一个重大挑战。现有方法在处理蕴涵学习时，未能明确建模蕴涵的传递性，而这种传递性对于在表示空间中建立顺序和语义关系至关重要。

**Method:** 该论文提出了径向跨模态嵌入（RCME）框架，旨在明确建模传递性强制的蕴涵。该框架优化了视觉-语言模型中概念的部分顺序。通过RCME，研究人员开发了一个能够表示生命之树层次结构的层次视觉-语言基础模型。

**Result:** 在层次物种分类和层次检索任务上的实验表明，与现有最先进的模型相比，RCME模型的性能得到了增强。

**Conclusion:** RCME框架通过明确建模传递性蕴涵，有效解决了视觉-语言模型中数据层次结构学习的挑战，并在相关任务中取得了优于现有SOTA模型的性能，证明了其在表示复杂层次结构方面的潜力。

> **ai_Abstract:** 该论文提出了径向跨模态嵌入（RCME）框架，以解决视觉-语言模型中数据层次结构学习的挑战。RCME通过明确建模蕴涵的传递性，优化了概念的部分顺序，弥补了现有蕴涵学习方法未能处理传递性的不足。基于RCME，研究人员开发了一个层次视觉-语言基础模型，并成功应用于表示“生命之树”的层次结构。实验结果表明，RCME模型在层次物种分类和层次检索任务上均优于现有的最先进模型。

> **摘要翻译:** 学习视觉-语言模型中数据的层次结构是一个重大挑战。以前的工作试图通过使用蕴涵学习来解决这个挑战。然而，这些方法未能明确地建模蕴涵的传递性，而传递性在表示空间中建立了顺序和语义之间的关系。在这项工作中，我们引入了径向跨模态嵌入（RCME），这是一个能够明确建模传递性强制蕴涵的框架。我们提出的框架优化了视觉-语言模型中概念的部分顺序。通过利用我们的框架，我们开发了一个能够表示生命之树中层次结构的层次视觉-语言基础模型。我们在层次物种分类和层次检索任务上的实验表明，与现有最先进的模型相比，我们的模型性能有所提高。我们的代码和模型已在 https://vishu26.github.io/RCME/index.html 开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [437] [TITAN: Query-Token based Domain Adaptive Adversarial Learning](https://arxiv.org/abs/2506.21484)
> *TITAN: 基于查询令牌的领域自适应对抗学习*

*Tajamul Ashraf, Janibul Bashir* | **Category: cs.CV, cs.AI**

**Keywords:** 领域自适应, 目标检测, 对抗学习, 伪标签, 源数据不可用

**Comment:** ICCV 2025

> **TL;DR:** 针对源数据不可用的领域自适应目标检测问题，TITAN通过分离目标域的“简单”和“困难”子集，并引入基于查询令牌的对抗模块，显著提升了伪标签的可靠性和模型的性能。

**AI_Comments:** TITAN的创新点在于其目标域的“简单”和“困难”子集划分策略，以及利用检测方差来估计与源域的相似性，这有效缓解了伪标签噪声问题。此外，引入查询令牌对抗模块进一步缩小了领域差距。这项工作在无源域自适应目标检测领域取得了显著进展，特别是在提升伪标签可靠性方面具有重要意义。其在多个数据集上大幅提升性能，证明了方法的有效性和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 在源数据不可用的领域自适应目标检测(SF-DAOD)中，现有的学生-教师(ST)框架常因伪标签的高噪声（源于领域偏差、差异和显著的领域偏移）导致教师模型崩溃，进而使学生模型性能大幅下降。

**Method:** 提出了一种基于目标的迭代查询令牌对抗网络(TITAN)。该方法将目标图像分为“简单”（与源域相似）和“困难”（与源域不相似）两个子集，并提出一种利用检测方差估计来划分目标域的策略，认为高检测方差对应高召回率和与源域的更高相似性。此外，将基于查询令牌的对抗模块整合到学生-教师基线框架中，以减少两种特征表示之间的领域差距。

**Result:** 在四个自然图像数据集和两个挑战性医学数据集上，TITAN的表现优于现有最先进的方法。在C2F、C2B、S2C和K2C基准测试中，mAP分别比当前SOTA提升了+22.7%、+22.2%、+21.1%和+3.7%。

**Conclusion:** TITAN通过其创新的目标域划分策略和查询令牌对抗模块，有效解决了SF-DAOD中伪标签噪声问题，显著提升了模型在多种数据集上的性能，证明了其优越性。

> **ai_Abstract:** 本文针对源数据不可用的领域自适应目标检测(SF-DAOD)中伪标签噪声导致的学生模型性能下降问题，提出了一种名为TITAN的新方法。TITAN通过将目标域图像划分为“简单”和“困难”子集，并利用检测方差进行划分，以生成更可靠的伪标签。同时，它将基于查询令牌的对抗模块融入学生-教师框架，以缩小领域差距。实验结果表明，TITAN在多个自然和医学数据集上均显著超越了现有最先进的方法。

> **摘要翻译:** 我们关注源数据在自适应过程中不可用且模型必须适应未标记目标域的无源领域自适应目标检测（SF-DAOD）问题。解决该问题的大多数方法采用学生-教师（ST）框架下的自监督方法，通过源预训练模型生成伪标签以进行进一步微调。我们观察到，由于教师模型的崩溃，学生模型的性能通常会急剧下降，这主要是由伪标签中的高噪声引起的，而高噪声又源于领域偏差、差异以及跨领域显著的领域偏移。为了获得可靠的伪标签，我们提出了一种基于目标的迭代查询令牌对抗网络（TITAN），它将目标图像分为两个子集：与源域相似的（简单）和不相似的（困难）。我们提出了一种估计方差来划分目标域的策略。这种方法利用了高检测方差对应高召回率和与源域更高相似性的见解。此外，我们将基于查询令牌的对抗模块整合到学生-教师基线框架中，以减少两种特征表示之间的领域差距。在四个自然图像数据集和两个具有挑战性的医学数据集上进行的实验证实了TITAN优于现有最先进（SOTA）方法。我们报告在C2F、C2B、S2C和K2C基准测试中，mAP分别比当前SOTA提高了+22.7、+22.2、+21.1和+3.7个百分点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [438] [Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection](https://arxiv.org/abs/2506.21486)
> *迈向可靠的空闲空间检测：用于目标检测的条件标记点过程*

*Tobias J. Riedlinger, Kira Maag, Hanno Gottschalk* | **Category: cs.CV, cs.LG, math.PR**

**Keywords:** 目标检测, 空间统计, 条件标记点过程, 不确定性量化, 空闲空间检测

**Comment:** 15 pages, 4 figures, 3 tables

> **TL;DR:** 本文提出了一种基于空间统计学的目标检测模型，利用条件标记点过程来可靠地量化未检测区域（空闲空间）的不确定性，从而提高自动驾驶等应用的安全性。

**AI_Comments:** 该论文的创新之处在于将空间统计学中的条件标记点过程引入到目标检测领域，解决了现有深度学习模型无法可靠量化未检测区域不确定性的关键问题。这对于自动驾驶等需要高安全性的应用尤为重要。其贡献在于提供了一个具有明确概率基础的框架，能够为“空闲”空间提供置信度评估，弥补了传统目标检测器只关注“有物体”区域的不足。

<details>
  <summary>Details</summary>

**Motivation:** 当前深度学习目标检测模型在检测性能上表现出色，但其置信度估计常常不准确，并且无法量化未检测区域（即边界框之外的区域）的不确定性。这在自动驾驶等安全关键应用中构成了风险，因为模型未能评估无障碍区域是否真正安全。

**Method:** 本文提出了一种基于空间统计学的方法。将边界框数据视为标记点过程的实现，其中边界框中心是空间点事件，而标记则描述了边界框的空间扩展和类别。这种统计框架支持基于似然的训练，并为区域是否可行驶（即无障碍）提供了明确定义的置信度估计。

**Result:** 通过校准评估和性能评估，证明了所提出方法的有效性。

**Conclusion:** 本文提出的基于条件标记点过程的目标检测模型，为检测空闲空间提供了可靠的置信度估计，解决了现有模型在量化未检测区域不确定性方面的不足，从而提高了自动驾驶等应用的安全性和可靠性。

> **ai_Abstract:** 本文提出了一种基于空间统计学的目标检测模型，利用条件标记点过程来解决现有深度学习模型在量化未检测区域不确定性方面的不足。通过将边界框数据视为标记点过程的实现，该方法能够进行基于似然的训练，并为“空闲”或可行驶区域提供明确定义的置信度估计。实验结果表明，该方法在校准和性能方面均有效，有助于提高自动驾驶等安全关键应用的可靠性。

> **摘要翻译:** 深度神经网络在边界框检测和语义分割等计算机视觉任务中取得了最先进的成果。目标检测器和分割模型为其预测分配置信度分数，反映了模型在目标检测或像素级分类中的不确定性。然而，这些置信度估计常常不准确，因为它们的架构和损失函数是为任务性能而非概率基础量身定制的。即使预测经过良好校准，目标检测器也无法量化检测到的边界框之外的不确定性，即模型没有对没有检测到对象的区域是否真正没有障碍物进行概率评估。这在自动驾驶等应用中构成了安全风险，因为空闲区域的不确定性仍未被探索。在这项工作中，我们提出了一种基于空间统计学的目标检测模型。边界框数据与标记点过程的实现相匹配，该过程通常用于描述被识别为边界框中心的空间点事件的概率发生，其中标记用于描述边界框和类别的空间扩展。我们的统计框架支持基于似然的训练，并为区域是否可行驶（即无障碍）提供了明确定义的置信度估计。我们通过校准评估和性能评估证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [439] [Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration](https://arxiv.org/abs/2506.21509)
> *缓解大型视觉-语言模型幻觉的动态Logits校准方法*

*Jiahe Chen, Jiaying He, Qian Shao, Qiyuan Chen, Jiahe Ying, Hongxia Xu, Jintai Chen, Jianwei Zheng, Jian Wu* | **Category: cs.CV**

**Keywords:** 大型视觉-语言模型, 幻觉缓解, 动态Logits校准, 免训练解码, CLIP

**Comment:** 

> **TL;DR:** 提出动态Logits校准（DLC）框架，通过在推理时动态调整输出logits，有效减少大型视觉-语言模型（LVLMs）的幻觉。

**AI_Comments:** 该论文的创新点在于提出了一种无需训练的、动态的解码时解决方案来缓解LVLM的幻觉问题。与现有静态或低效的方法不同，DLC能够自适应地调整，避免了多次前向传播，从而提高了效率。通过将视觉证据与文本生成动态对齐，DLC有效提升了LVLMs的可靠性和实用性，是一个重要的进展。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）尽管在多模态理解方面取得进展，但常受幻觉困扰，即生成与视觉输入矛盾的文本。现有免训练解码策略存在局限性，包括使用静态约束、低效（需多次前向传播）以及过度干预导致细节丢失。

**Method:** 论文引入动态Logits校准（DLC），一种新型免训练解码框架。在解码阶段，DLC逐步利用CLIP评估输入图像与生成文本序列的语义对齐。通过动态更新的上下文基线评估候选token的相对视觉优势（RVA），自适应调整输出logits以偏向视觉接地（visually grounded）的token。此外，一个由实时上下文对齐分数指导的自适应加权机制平衡视觉引导，同时确保文本输出的整体质量。

**Result:** 在不同基准和LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的广泛实验表明，DLC显著减少了幻觉，优于现有方法，并通过避免多次前向传播保持了高推理效率。

**Conclusion:** 论文提出了一种有效且高效的解码时解决方案来缓解幻觉，从而提高LVLMs的可靠性以用于更多实践。

> **ai_Abstract:** 本论文提出了一种名为动态Logits校准（DLC）的新型免训练解码框架，旨在解决大型视觉-语言模型（LVLMs）中常见的幻觉问题。DLC在推理时通过逐步利用CLIP评估视觉-文本对齐，并基于动态更新的上下文基线调整候选token的相对视觉优势（RVA），自适应地调整输出logits以优先选择视觉上更合理的token。结合自适应加权机制，DLC在显著减少LVLM幻觉的同时，保持了高效的推理速度，并在多种LVLM架构上展现出优于现有方法的性能。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但它们经常受到幻觉的困扰——即生成与视觉输入矛盾的文本。现有的免训练解码策略存在关键局限性，包括使用静态约束，这些约束在生成过程中不适应语义漂移；由于需要多次前向传播而导致效率低下；以及由于过于僵硬的干预规则而导致细节退化。为了克服这些挑战，本文引入了动态Logits校准（DLC），这是一种新颖的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步利用CLIP评估输入图像与生成文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选token的相对视觉优势（RVA），自适应地调整输出logits以偏向视觉接地的token。此外，一个由实时上下文对齐分数指导的自适应加权机制，在确保文本输出整体质量的同时，仔细平衡了视觉引导。在各种基准和不同LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的广泛实验表明，DLC显著减少了幻觉，优于当前方法，同时通过避免多次前向传播保持了高推理效率。总的来说，我们提出了一种有效且高效的解码时解决方案来缓解幻觉，从而增强了LVLMs在更多实践中的可靠性。代码将在Github上发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [440] [GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation](https://arxiv.org/abs/2506.21513)
> *GGTalker：基于可泛化高斯先验和身份特异性适应的说话人头部合成*

*Wentao Hu, Shunkai Li, Ziqiao Peng, Haoxian Zhang, Fan Shi, Xiaoqiang Liu, Pengfei Wan, Di Zhang, Hui Tian* | **Category: cs.CV**

**Keywords:** 说话人头部合成, 3D先验, 高斯先验, 身份适应, 语音驱动

**Comment:** ICCV 2025, Project page: https://vincenthu19.github.io/GGTalker/

> **TL;DR:** GGTalker提出了一种结合可泛化高斯先验和身份特异性适应的两阶段训练策略，解决了高质量、可泛化的语音驱动3D说话人头部合成中大头部旋转、OOD音频和耗时训练的挑战，实现了SOTA的渲染质量、3D一致性、唇形同步精度和训练效率。

**AI_Comments:** GGTalker的创新之处在于其两阶段的“先验-适应”训练策略，它有效地结合了通用先验知识和个性化适应能力，解决了传统方法在泛化性和训练效率上的痛点。特别是引入高斯头部先验来增强3D外推能力，以及颜色MLP和Body Inpainter用于提高视觉真实感，使其在高质量语音驱动3D说话人头部合成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前方法在固定视角和小规模音频变化下效果尚可，但在大头部旋转和域外（OOD）音频方面表现不佳，且受限于耗时的身份特异性训练。核心问题在于缺乏足够的3D先验，限制了合成说话人头部的外推能力。

**Method:** GGTalker通过结合可泛化先验和身份特异性适应来合成说话人头部。它引入了两阶段的“先验-适应”训练策略：学习高斯头部先验并适应个体特征。具体包括训练“音频-表情”和“表情-视觉”先验以捕捉唇部动作的普遍模式和头部纹理的普遍分布。在定制适应阶段，精确建模个体说话风格和纹理细节。此外，引入了颜色MLP生成精细、运动对齐的纹理，并使用Body Inpainter将渲染结果与背景融合，生成逼真的视频帧。

**Result:** GGTalker在渲染质量、3D一致性、唇形同步精度和训练效率方面均达到了最先进的性能。

**Conclusion:** GGTalker通过引入可泛化高斯先验和身份特异性适应的两阶段训练策略，成功解决了高质量、可泛化语音驱动3D说话人头部合成的挑战，并在多个关键指标上实现了最先进的性能。

> **ai_Abstract:** GGTalker提出了一种新颖的语音驱动3D说话人头部合成系统，旨在解决现有方法在大头部旋转、域外音频和耗时训练方面的局限性。该系统引入了两阶段的“先验-适应”训练策略，首先学习通用的高斯头部先验（包括音频-表情和表情-视觉先验），然后进行身份特异性适应以捕捉个体特征。GGTalker还结合了颜色MLP生成精细纹理和Body Inpainter进行背景融合，最终实现了高渲染质量、3D一致性、准确的唇形同步和高训练效率。

> **摘要翻译:** 创建高质量、可泛化的语音驱动3D说话人头部仍然是一个持续的挑战。以前的方法在固定视角和小规模音频变化下取得了令人满意的结果，但它们在大头部旋转和域外（OOD）音频方面表现不佳。此外，它们受到耗时的身份特异性训练的限制。我们认为核心问题在于缺乏足够的3D先验，这限制了合成说话人头部的外推能力。为了解决这个问题，我们提出了GGTalker，它通过结合可泛化先验和身份特异性适应来合成说话人头部。我们引入了两阶段的“先验-适应”训练策略来学习高斯头部先验并适应个体特征。我们训练“音频-表情”和“表情-视觉”先验以捕捉唇部动作的普遍模式和头部纹理的普遍分布。在定制适应阶段，精确建模个体说话风格和纹理细节。此外，我们引入了一个颜色MLP来生成精细、运动对齐的纹理，并引入一个Body Inpainter将渲染结果与背景融合，生成无法区分的逼真视频帧。全面的实验表明，GGTalker在渲染质量、3D一致性、唇形同步精度和训练效率方面均达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [441] [G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](https://arxiv.org/abs/2506.21514)
> *G$^{2}$D: 梯度引导蒸馏提升多模态学习*

*Mohammed Rakib, Arunkumar Bagavathi* | **Category: cs.CV**

**Keywords:** 多模态学习, 梯度引导蒸馏, 模态不平衡, 知识蒸馏, 模态优先级

**Comment:** Accepted at ICCV 2025

> **TL;DR:** G$^{2}$D是一种梯度引导蒸馏框架，通过自定义损失函数和动态模态优先级技术解决多模态学习中的模态不平衡问题，提升弱模态的重要性并超越现有SOTA方法。

**AI_Comments:** G$^{2}$D的创新之处在于其结合了知识蒸馏、自定义损失函数以及动态模态优先级技术，有效解决了多模态学习中长期存在的模态不平衡问题。通过提升弱模态的重要性，该方法有望在实际应用中更全面地利用多源数据，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统多模态模型存在模态不平衡问题，即部分模态在模型优化中占据主导，导致特征表示不佳和弱模态利用不足。

**Method:** 本文引入了梯度引导蒸馏 (G$^{2}$D) 框架，该框架通过自定义损失函数融合单模态和多模态目标来优化模型。G$^{2}$D还结合了动态顺序模态优先级 (SMP) 技术，确保每个模态都能主导学习过程，避免强模态掩盖弱模态。

**Result:** G$^{2}$D在多个真实世界数据集上得到了验证，结果表明G$^{2}$D在训练过程中增强了弱模态的重要性，并在分类和回归任务中超越了现有最先进的方法。

**Conclusion:** G$^{2}$D框架通过解决多模态学习中的模态不平衡问题，显著提升了弱模态的利用率和整体模型性能，在分类和回归任务上表现优异。

> **ai_Abstract:** 本文提出G$^{2}$D，一个梯度引导蒸馏框架，旨在解决多模态学习中的模态不平衡问题。G$^{2}$D通过结合自定义损失函数（融合单模态与多模态目标）和动态顺序模态优先级（SMP）技术，确保弱模态在训练中得到充分利用。实验证明，G$^{2}$D在多个真实数据集上能有效提升弱模态的重要性，并在分类和回归任务中超越现有SOTA方法。

> **摘要翻译:** 多模态学习旨在利用不同数据模态的信息以实现更全面的性能。然而，传统的多模态模型常受模态不平衡问题困扰，即一个或少数模态在模型优化中占据主导，导致次优的特征表示和弱模态的利用不足。为解决这一挑战，我们引入了梯度引导蒸馏 (G$^{2}$D)，这是一个知识蒸馏框架，它通过融合单模态和多模态目标的自定义损失函数来优化多模态模型。G$^{2}$D在学习过程中进一步整合了动态顺序模态优先级 (SMP) 技术，以确保每个模态都能主导学习过程，避免强模态掩盖弱模态的弊端。我们在多个真实世界数据集上验证了G$^{2}$D，并表明G$^{2}$D在训练时增强了弱模态的重要性，并在分类和回归任务中超越了最先进的方法。我们的代码可在 https://github.com/rAIson-Lab/G2D 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [442] [MADrive: Memory-Augmented Driving Scene Modeling](https://arxiv.org/abs/2506.21520)
> *MADrive：记忆增强驾驶场景建模*

*Polina Karpikova, Daniil Selikhanovych, Kirill Struminsky, Ruslan Musaev, Maria Golitsyna, Dmitry Baranchuk* | **Category: cs.CV**

**Keywords:** 场景重建, 记忆增强, 3D高斯泼溅, 自动驾驶, 车辆合成

**Comment:** 

> **TL;DR:** MADrive是一个记忆增强的重建框架，通过从外部记忆库检索和集成3D车辆资产，实现对自动驾驶场景中车辆的逼真替换和新场景合成。

**AI_Comments:** MADrive的创新之处在于其记忆增强的方法，通过引入外部大规模3D资产库来克服传统重建方法对原始观测的依赖。这为自动驾驶场景的灵活编辑和新颖场景生成提供了新的可能性。MAD-Cars数据集的发布也为相关研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅场景重建方法虽然能实现高度逼真的自动驾驶环境建模，但重建结果与原始观测紧密相关，难以支持显著改变或新颖驾驶场景的光真实感合成。

**Method:** 本工作提出了MADrive，一个记忆增强的重建框架。它通过从大规模外部记忆库中检索视觉上相似的3D资产来替换观察到的车辆。具体来说，该框架发布了MAD-Cars数据集（包含约7万个野外捕获的360度汽车视频），并提出了一个检索模块，该模块能从记忆库中找到最相似的汽车实例，从视频中重建相应的3D资产，并通过方向对齐和重新打光将其集成到目标场景中。

**Result:** 替换后的车辆提供了场景中完整的、多视图的车辆表示，实验证明这使得能够光真实感地合成显著改变的配置。

**Conclusion:** MADrive通过引入记忆增强的车辆替换机制，显著扩展了现有场景重建方法的能力，实现了对自动驾驶场景中车辆的逼真合成和新场景生成。

> **ai_Abstract:** MADrive是一个创新的记忆增强重建框架，旨在解决现有3D场景重建方法在自动驾驶环境中合成显著改变或新颖场景时的局限性。该框架通过从一个名为MAD-Cars的大规模外部记忆库中检索并集成逼真的3D车辆资产来替换原始场景中的车辆。MADrive包含一个检索模块，能够找到最相似的车辆实例，从视频重建其3D模型，并通过方向对齐和重新打光将其无缝集成到目标场景中。实验证明，这种方法能够实现对车辆配置的光真实感合成，从而扩展了自动驾驶场景建模的能力。

> **摘要翻译:** 自动驾驶（AD）环境的场景重建近期取得了进展，3D高斯泼溅技术实现了高度逼真的建模。然而，由此产生的重建结果仍然与原始观测紧密相关，难以支持显著改变或新颖驾驶场景的光真实感合成。本工作引入了MADrive，一个记忆增强的重建框架，旨在通过用从大型外部记忆库中检索到的视觉相似的3D资产替换观察到的车辆，来扩展现有场景重建方法的能力。具体来说，我们发布了MAD-Cars，一个包含约7万个在野外捕获的360度汽车视频的精选数据集，并提出了一个检索模块，该模块能在记忆库中找到最相似的汽车实例，从视频中重建相应的3D资产，并通过方向对齐和重新打光将其集成到目标场景中。由此产生的替换提供了场景中车辆的完整多视图表示，使得能够光真实感地合成显著改变的配置，正如我们在实验中所展示的。项目页面：https://yandex-research.github.io/madrive/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [WAFT: Warping-Alone Field Transforms for Optical Flow](https://arxiv.org/abs/2506.21526)
> *WAFT：用于光流的独立形变场变换*

*Yihan Wang, Jia Deng* | **Category: cs.CV**

**Keywords:** 光流, 形变场变换, 成本体, 零样本泛化, 元架构

**Comment:** 

> **TL;DR:** WAFT是一种新的光流方法，通过高分辨率形变取代成本体，实现了更高的精度、更低的内存消耗，并在基准测试中表现优异。

**AI_Comments:** WAFT的创新之处在于其挑战了光流领域中成本体构建的传统范式，通过引入高分辨率形变实现了性能和效率的显著提升。其“独立形变”的设计思路简化了架构，减少了归纳偏置，使其具有更强的灵活性和泛化能力。在性能上，它在多个主流基准测试中均表现出色，尤其在速度和零样本泛化方面具有重要优势，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在挑战传统观念，即构建成本体对于实现光流的强大性能是必需的，并提供一种简单、有效、低内存成本且高性能的光流方法。

**Method:** 本文引入了独立形变场变换（WAFT），这是一种用于光流的简单灵活的元架构。它类似于RAFT，但用高分辨率形变取代了成本体。

**Result:** WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳的零样本泛化能力，并且比性能相似的方法快4.1倍。

**Conclusion:** WAFT证明了即使没有构建成本体，也能实现强大的光流性能，提供了一种简单、灵活、高效且高性能的光流解决方案。

> **ai_Abstract:** 本文提出了一种名为WAFT（Warping-Alone Field Transforms）的光流方法。WAFT通过采用高分辨率形变而非成本体，显著提高了精度并降低了内存消耗。该方法挑战了光流领域中构建成本体是必要条件的传统认知。WAFT被设计为一种简单灵活的元架构，具有最小的归纳偏置。实验结果表明，WAFT在Spring和KITTI基准测试中均位列第一，并在KITTI上展现出卓越的零样本泛化能力，同时比同等性能的方法快4.1倍。

> **摘要翻译:** 我们引入了独立形变场变换（WAFT），这是一种简单有效的光流方法。WAFT与RAFT相似，但用高分辨率形变取代了成本体，以更低的内存成本实现了更高的精度。这种设计挑战了构建成本体对于实现强大性能是必要的传统观念。WAFT是一种简单灵活的元架构，具有最小的归纳偏置和对自定义设计的依赖。与现有方法相比，WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳的零样本泛化能力，同时比性能相似的方法快4.1倍。代码和模型权重可在https://github.com/princeton-vl/WAFT获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [445] [StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning](https://arxiv.org/abs/2506.21541)
> *StruMamba3D：探索结构化Mamba用于自监督点云表示学习*

*Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang* | **Category: cs.CV**

**Keywords:** Mamba, 点云, 自监督学习, 状态空间模型, 表示学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** StruMamba3D通过引入空间状态、状态更新策略和序列长度自适应策略，解决了现有Mamba模型在点云处理中破坏邻接性和长序列记忆不足的问题，并在多项下游任务中取得了SOTA性能。

**AI_Comments:** StruMamba3D的创新之处在于其针对Mamba模型在点云处理中固有缺陷的精准优化。通过引入空间状态、精细化的状态更新机制以及对序列长度的自适应处理，该工作显著提升了Mamba模型在三维数据上的表现力。其在多个基准测试中达到SOTA性能，证明了其重要性和有效性，为点云表示学习领域提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于Mamba的点云表示学习方法存在两个主要问题：一是在SSM处理过程中破坏了3D点的邻接性；二是随着下游任务输入长度的增加，难以保留长序列记忆，从而限制了SSM的潜力。

**Method:** 本文提出StruMamba3D，一种新的自监督点云表示学习范式。它通过设计空间状态作为代理来保留点之间的空间依赖性；通过状态更新策略增强SSM，并结合轻量级卷积促进空间状态间的交互以实现高效结构建模；通过引入序列长度自适应策略，降低预训练Mamba模型对不同输入长度的敏感性。

**Result:** 在四项下游任务中的实验结果表明，StruMamba3D表现优越。此外，该方法在ModelNet40上达到了95.1%的SOTA准确率，在ScanObjectNN最具挑战性的分割上达到了92.75%的准确率（无需投票策略）。

**Conclusion:** StruMamba3D成功解决了现有Mamba模型在点云处理中的关键问题，并在多个基准测试中展现出卓越的性能和最先进的准确率，证明了其在自监督点云表示学习领域的有效性和潜力。

> **ai_Abstract:** 本文提出StruMamba3D，一种新颖的自监督点云表示学习框架，旨在解决现有Mamba模型在点云处理中破坏3D点邻接性和长序列记忆不足的问题。StruMamba3D通过引入空间状态来保留空间依赖性，采用状态更新策略和轻量级卷积进行高效结构建模，并通过序列长度自适应策略提高对不同输入长度的鲁棒性。实验证明，StruMamba3D在多项下游任务中表现优异，并在ModelNet40和ScanObjectNN上取得了SOTA准确率。

> **摘要翻译:** 最近，基于Mamba的方法通过利用状态空间模型（SSM）及其高效的上下文建模能力和线性复杂度，在点云表示学习中展现出令人印象深刻的性能。然而，这些方法仍然面临两个限制SSM潜力的关键问题：在SSM处理过程中破坏了3D点的邻接性，以及在下游任务中随着输入长度的增加未能保留长序列记忆。为了解决这些问题，我们提出了StruMamba3D，一种用于自监督点云表示学习的新范式。它具有多项优点。首先，我们设计了空间状态并将其用作代理，以保留点之间的空间依赖性。其次，我们通过状态更新策略增强了SSM，并结合了轻量级卷积以促进空间状态之间的交互，从而实现高效的结构建模。第三，我们的方法通过引入序列长度自适应策略，降低了预训练Mamba模型对不同输入长度的敏感性。在四项下游任务中的实验结果展示了我们方法的卓越性能。此外，我们的方法在ModelNet40上达到了95.1%的SOTA准确率，在ScanObjectNN最具挑战性的分割上达到了92.75%的准确率（无需投票策略）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [446] [DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion](https://arxiv.org/abs/2506.21544)
> *DeOcc-1-to-3：通过自监督多视角扩散从单张图像进行3D去遮挡*

*Yansong Qu, Shaohui Dai, Xinyang Li, Yuze Wang, You Shen, Liujuan Cao, Rongrong Ji* | **Category: cs.CV**

**Keywords:** 3D去遮挡, 单图像重建, 多视角扩散, 自监督学习, 遮挡感知重建

**Comment:** 

> **TL;DR:** DeOcc-1-to-3提出了一种端到端框架，通过自监督多视角扩散从单张部分遮挡图像生成一致的新视角，从而实现高质量的3D去遮挡重建。

**AI_Comments:** 该论文在处理3D重建中的真实世界遮挡问题上迈出了重要一步，通过提出的自监督多视角扩散框架，有效解决了现有扩散模型在遮挡情况下的局限性。其创新之处在于无需预先修复或手动标注即可直接从遮挡图像生成一致的新视角，并联合学习补全和多视角生成。此外，引入首个遮挡感知重建基准对于推动该领域未来的研究和评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从单张图像重建3D物体是一个长期存在的挑战，尤其是在真实世界遮挡下。现有的基于扩散的视角合成模型在物体部分被遮挡时会失效，导致视角不一致和3D重建质量下降。

**Method:** 提出一个端到端的遮挡感知多视角生成框架，直接从单张部分遮挡图像合成六个结构一致的新视角。利用Pix2Gestalt数据集构建自监督训练流程，使用遮挡-未遮挡图像对和伪真值视角来训练模型学习结构感知补全和视角一致性。通过微调视角合成模型，使其联合学习补全和多视角生成。此外，引入了首个用于遮挡感知重建的基准。

**Result:** 模型能够从单张部分遮挡图像合成六个结构一致的新视角，无需预先修复或手动标注，从而实现高质量的3D重建。还创建了第一个遮挡感知重建基准，涵盖了不同的遮挡水平、物体类别和遮罩模式，为未来方法的评估提供了标准化协议。

**Conclusion:** 该论文提出了一个名为DeOcc-1-to-3的端到端框架，通过自监督多视角扩散从单张部分遮挡图像进行3D去遮挡，并生成一致的新视角，有效解决了现有方法在遮挡情况下的局限性。同时，还首次引入了一个用于遮挡感知重建的标准化基准。

> **ai_Abstract:** 本论文提出了DeOcc-1-to-3，一个用于从单张部分遮挡图像进行3D去遮挡的端到端框架。该方法通过自监督多视角扩散，直接合成六个结构一致的新视角，从而在无需预先修复或手动标注的情况下实现高质量的3D重建。作者利用Pix2Gestalt数据集构建了自监督训练流程，并微调了视角合成模型以联合学习补全和多视角生成。此外，论文还首次引入了一个用于遮挡感知重建的标准化基准。

> **摘要翻译:** 从单张图像重建3D物体是一个长期存在的挑战，尤其是在真实世界的遮挡下。虽然最近基于扩散的视角合成模型可以从单张RGB图像生成一致的新视角，但它们通常假设输入是完全可见的，并且在物体部分被遮挡时会失效。这会导致视角不一致和3D重建质量下降。为了克服这一限制，我们提出了一个用于遮挡感知多视角生成的端到端框架。我们的方法直接从单张部分遮挡图像合成六个结构一致的新视角，从而实现下游的3D重建，而无需预先修复或手动标注。我们使用Pix2Gestalt数据集构建了一个自监督训练流程，利用遮挡-未遮挡图像对和伪真值视角来教导模型结构感知补全和视角一致性。在不修改原始架构的情况下，我们完全微调了视角合成模型，以联合学习补全和多视角生成。此外，我们引入了第一个用于遮挡感知重建的基准，涵盖了不同的遮挡水平、物体类别和遮罩模式。这个基准为未来在部分遮挡下的方法评估提供了标准化协议。我们的代码可在https://github.com/Quyans/DeOcc123获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [447] [SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark](https://arxiv.org/abs/2506.21549)
> *SiM3D：单实例多视角多模态多设置3D异常检测基准*

*Alex Costanzino, Pierluigi Zama Ramirez, Luigi Lella, Matteo Ragaglia, Alessandro Oliva, Giuseppe Lisanti, Luigi Di Stefano* | **Category: cs.CV**

**Keywords:** 3D异常检测, 多视角, 多模态, 单实例, 基准

**Comment:** 

> **TL;DR:** SiM3D是一个新的3D异常检测与分割基准，首次整合了多视角和多模态信息，并专注于制造业中单实例和合成-真实数据泛化的挑战，提供了一个新的数据集和评估方法。

**AI_Comments:** SiM3D是一个重要的贡献，因为它填补了3D异常检测领域的一个关键空白，即多视角、多模态数据集成以及对单实例和合成-真实泛化挑战的关注。其提供的高质量数据集和详细标注对于推动该领域的研究具有重大价值，尤其是在工业应用中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D异常检测和分割基准未能充分整合多视角和多模态信息，也未有效解决制造业中常见的单实例异常检测场景以及从合成数据到真实数据泛化的问题。

**Method:** 本文提出了SiM3D基准，用于全面的3D异常检测和分割。它包含一个新颖的多模态多视角数据集，该数据集使用顶级工业传感器和机器人采集，包括高分辨率图像（12 Mpx）和点云（7M点），涵盖8种对象类型的333个实例，并附带每种类型的CAD模型。同时，还提供了异常测试样本的手动标注3D分割真值。为了建立多视角3D ADS任务的参考基线，研究人员调整了著名的单视角方法，并使用操作于异常体积的新型度量标准评估其性能。

**Result:** 本文提出了SiM3D，这是第一个整合多视角和多模态信息进行全面3D异常检测和分割的基准。它专注于单实例异常检测场景，并首次解决了从合成训练数据泛化到真实测试数据的挑战。SiM3D提供了一个包含高分辨率图像和点云的新型多模态多视角数据集，以及手动标注的3D分割真值。此外，还为所提出的多视角3D ADS任务建立了参考基线，并引入了基于异常体积的新型评估指标。

**Conclusion:** SiM3D提供了一个至关重要的新基准和数据集，通过整合多样化的数据源并解决单实例学习和合成-真实泛化等实际挑战，推动了3D异常检测和分割领域的发展，尤其对制造业应用具有重要意义。

> **ai_Abstract:** SiM3D是一个新颖的3D异常检测与分割（ADS）基准，首次整合了多视角和多模态信息。它专注于制造业中的单实例异常检测场景，并解决了从合成数据到真实数据泛化的挑战。SiM3D包含一个使用工业级传感器获取的独特数据集，该数据集拥有高分辨率图像、点云数据和CAD模型，并提供了手动标注的3D分割真值。该基准还为多视角3D ADS任务建立了参考基线，并引入了基于异常体积的新度量标准。

> **摘要翻译:** 我们提出了SiM3D，这是第一个考虑整合多视角和多模态信息以进行全面3D异常检测和分割（ADS）的基准，其任务是生成基于体素的异常体积。此外，SiM3D专注于制造业中备受关注的场景：单实例异常检测，即仅有一个对象（无论是真实的还是合成的）可用于训练。在这方面，SiM3D是第一个解决从合成训练数据泛化到真实测试数据挑战的ADS基准。SiM3D包含一个使用顶级工业传感器和机器人采集的新型多模态多视角数据集。该数据集包含八种对象类型的333个实例的多视角高分辨率图像（12 Mpx）和点云（7M点），以及每种类型的CAD模型。我们还为异常测试样本提供了手动标注的3D分割真值。为了为所提出的多视角3D ADS任务建立参考基线，我们调整了著名的单视角方法，并使用操作于异常体积的新型度量标准评估其性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [6] [Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots](https://arxiv.org/abs/2506.20748)
> *探索聊天机器人拟人化和人类同理心对人类对聊天机器人亲社会行为的影响*

*Jingshu Li, Zicheng Zhu, Renwen Zhang, Yi-Chieh Lee* | **Category: cs.HC, cs.AI**

**Keywords:** 聊天机器人拟人化, 人类同理心, 亲社会行为, 人机交互, CASA框架

**Comment:** 

> **TL;DR:** 聊天机器人的拟人化和情感表达能增强人类对其的同理心和亲社会行为。

**AI_Comments:** 该研究创新性地探讨了人类对聊天机器人亲社会行为的影响因素，填补了该领域的空白。通过结合CASA框架、量化实验和定性分析，研究提供了有力证据，证明了聊天机器人拟人化和情感表达在诱发人类同理心和亲社会行为中的关键作用。这对于设计更具吸引力、协作性和用户福祉的AI系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人类帮助聊天机器人能带来多方面益处（如提升聊天机器人性能、人类福祉和协作成果），但目前鲜有研究探讨促使人类帮助聊天机器人的因素。本研究旨在填补这一空白。

**Method:** 本研究基于“计算机是社会角色”（CASA）框架，通过一项在线实验（N=244）进行。实验中，聊天机器人在协作图像标注任务中犯错并向参与者解释原因，随后测量了参与者对聊天机器人的亲社会行为和意图。研究探讨了聊天机器人拟人化（包括类人身份、情感表达和非语言表达）如何影响人类对聊天机器人的同理心及其随后的亲社会行为和意图。

**Result:** 研究发现，聊天机器人的类人身份和情感表达增加了参与者对聊天机器人的亲社会行为和意图，且同理心在这些影响中起到了中介作用。定性分析进一步识别出参与者亲社会行为的两种动机：对聊天机器人的同理心和将聊天机器人视为类人。

**Conclusion:** 本研究的结果对于理解和促进人类对聊天机器人的亲社会行为具有重要意义，并可指导未来人机协作系统的设计。

> **ai_Abstract:** 本研究探讨了聊天机器人的拟人化（包括类人身份和情感表达）如何通过影响人类的同理心进而促进人类对聊天机器人的亲社会行为。一项在线实验（N=244）显示，聊天机器人的类人身份和情感表达显著增加了用户对其的亲社会行为和意图，且同理心在此过程中发挥了中介作用。定性分析揭示，对聊天机器人的同理心和将其视为类人是促使人类提供帮助的主要动机。研究结果为理解和促进人机协作中的亲社会行为提供了理论依据和实践指导。

> **摘要翻译:** 聊天机器人日益融入人们的生活，并被广泛用于帮助人们。最近，人们对相反的方向——人类帮助聊天机器人——的兴趣也日益增长，这带来了包括更好的聊天机器人性能、人类福祉和协作成果在内的诸多益处。然而，很少有研究探讨促使人们帮助聊天机器人的因素。为了弥补这一空白，我们借鉴了“计算机是社会角色”（CASA）框架，研究聊天机器人拟人化——包括类人身份、情感表达和非语言表达——如何影响人类对聊天机器人的同理心以及随后的亲社会行为和意图。我们还探讨了人们对他们帮助聊天机器人亲社会行为的自身解释。我们进行了一项在线实验（N = 244），其中聊天机器人在协作图像标注任务中犯错并向参与者解释了原因。然后，我们测量了参与者对聊天机器人的亲社会行为和意图。我们的研究结果表明，聊天机器人的类人身份和情感表达增加了参与者对聊天机器人的亲社会行为和意图，同理心在这些影响中起中介作用。定性分析进一步确定了参与者亲社会行为的两种动机：对聊天机器人的同理心和将聊天机器人视为类人。我们讨论了这些结果对于理解和促进人类对聊天机器人的亲社会行为的启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [23] ["TikTok, Do Your Thing": User Reactions to Social Surveillance in the Public Sphere](https://arxiv.org/abs/2506.20884)
> *“TikTok，做你的事”：用户对公共领域社会监控的反应*

*Meira Gilbert, Miranda Wei, Lindah Kotut* | **Category: cs.HC, cs.CY**

**Keywords:** TikTok, 社会监控, 用户反应, 众包, 公共领域

**Comment:** 

> **TL;DR:** 该研究通过对TikTok视频和评论的定性分析，探讨了用户对“TikTok，做你的事”这一通过众包识别陌生人的趋势的反应，发现支持者多于反对者，并讨论了人际监控的常态化。

**AI_Comments:** 本研究通过关注TikTok上独特的“TikTok，做你的事”趋势，提供了一个关于社交媒体时代人际监控和隐私观念演变的重要视角。其创新之处在于聚焦于由用户自身发起的众包监控行为，而非传统的政府或企业监控。研究结果揭示了用户对这种新型监控行为的复杂态度，特别是支持者多于反对者这一发现，对于理解数字时代社群、隐私和同意的边界具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了理解用户对“TikTok，做你的事”（一种通过众包识别公共领域陌生人的病毒式趋势）的反应。

**Method:** 对60个TikTok视频和1,901条用户评论进行了定性分析。

**Result:** 在审查的60个视频中，成功识别了19个人。发现表达反对的评论有310条，而表达支持的评论数量是其两倍多（883条）。支持性评论表现出真正的兴趣和同情，反映了社区和算法参与观念的演变。反对性评论则强调了对不当关系、跟踪、同意和性别双重标准的担忧。

**Conclusion:** 研究结果讨论了人际监控、在线跟踪的常态化，以及社会监控的演变，为用户对公共领域人际监控和识别的看法提供了新视角。

> **ai_Abstract:** 本文对TikTok上“TikTok，做你的事”这一通过众包识别陌生人的病毒式趋势进行了研究。通过对60个视频和1901条评论的定性分析，发现该趋势成功识别了一些人，且用户支持度远高于反对度。研究探讨了用户对这种由同伴而非政府或企业主导的公共领域监控行为的复杂反应，揭示了人际监控常态化、在线跟踪以及社会监控演变的新视角。

> **摘要翻译:** “TikTok，做你的事”是一个病毒式趋势，用户试图通过信息众包来识别他们在公共场合看到的陌生人。这个趋势早在2021年就开始了，用户通常出于浪漫目的参与其中（类似于“寻人启事”个人广告）。这种做法包括在公共领域的监控和识别行为，尽管是由同伴而非政府或企业进行的。为了理解用户对这个趋势的反应，我们对60个TikTok视频和1,901条用户评论进行了定性分析。在审查的60个视频中，我们发现有19个人被成功识别。我们还发现，虽然有表达反对的评论（n=310），但表达支持的评论数量是其两倍多（n=883）。支持性评论表现出真正的兴趣和同情，反映了社区和算法参与观念的演变。另一方面，反对性评论则强调了对不当关系、跟踪、同意和性别双重标准的担忧。我们结合人际监控的常态化、在线跟踪以及社会监控的演变来讨论这些见解，从而为用户对公共领域人际监控和识别的看法提供新视角。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [47] [Effect of Haptic Feedback on Avoidance Behavior and Visual Exploration in Dynamic VR Pedestrian Environment](https://arxiv.org/abs/2506.20952)
> *触觉反馈对动态VR行人环境中避让行为和视觉探索的影响*

*Kyosuke Ishibashi, Atsushi Saito, Zin Y. Tun, Lucas Ray, Megan C. Coram, Akihiro Sakurai, Allison M. Okamura, Ko Yamamoto* | **Category: cs.HC, cs.RO**

**Keywords:** 触觉反馈, 虚拟现实, 行人行为, 碰撞避让, 视觉探索

**Comment:** 

> **TL;DR:** 研究发现VR中的触觉反馈会改变用户在拥挤行人流中的避碰行为和视觉探索，提高对碰撞的敏感性。

**AI_Comments:** 这项研究创新性地探讨了触觉反馈在VR行人模拟中的具体作用，揭示了其对避让行为和空间感知的重要影响。研究结果对于提升VR沉浸感、优化虚拟训练（如紧急疏散）以及改进虚拟环境中的人机交互具有重要意义。局限性可能在于用户研究的规模和特定VR设备的使用。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟现实中的人群模拟在紧急疏散训练和建筑布局评估中有潜在应用，但触觉反馈对密集动态行人流中行走行为的影响尚不明确。

**Method:** 通过一项用户研究，调查触觉反馈如何改变用户在VR拥挤行人流中的行走运动。测量指标包括行走轨迹长度、骨盆角度变化、侧向位置位移、骨盆角度瞬时响应以及行走速度变化。

**Result:** 触觉反馈改变了用户的碰撞避让运动，表现为行走轨迹长度增加和骨盆角度变化。即使NPC在视野内，用户对与NPC碰撞的瞬时响应中，侧向位置和骨盆角度的位移也增加了。当NPC从侧面和后面接近时，触觉反馈增强了用户的意识和视觉探索。触觉反馈增加了行走速度的变化。

**Conclusion:** 这些结果表明触觉反馈增强了用户在VR环境中对碰撞的敏感性。

> **ai_Abstract:** 这项研究探讨了虚拟现实中触觉反馈对用户在拥挤行人流中行为的影响。通过用户研究发现，触觉反馈显著改变了用户的避碰动作，增加了行走轨迹长度、骨盆角度变化以及对碰撞的瞬时反应。它还提升了用户对侧面和后面接近的NPC的感知和视觉探索，并增加了行走速度的变异性。研究结论是触觉反馈能增强用户在VR环境中对碰撞的敏感度。

> **摘要翻译:** 虚拟现实（VR）中的人群模拟是一个强大的工具，在紧急疏散训练和建筑布局评估等领域具有潜在应用。尽管VR中的触觉反馈能增强沉浸式体验，但其对密集动态行人流中行走行为的影响尚不明确。通过一项用户研究，我们调查了触觉反馈如何改变用户在VR拥挤行人流中的行走运动。结果表明，触觉反馈改变了用户的碰撞避让运动，表现为行走轨迹长度增加和骨盆角度变化。即使当非玩家角色（NPC）在视野内时，用户对与NPC碰撞的瞬时响应中，侧向位置和骨盆角度的位移也增加了。触觉反馈还增强了当NPC从侧面和后面接近时用户的意识和视觉探索。此外，触觉反馈增加了行走速度的变化。这些结果表明触觉反馈增强了用户在VR环境中对碰撞的敏感性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [71] [Follow the user meaningfully and product growth will follow: A mixed methods case study tying UX Point of View & Growth leading to measurable impact](https://arxiv.org/abs/2506.21195)
> *追随用户需求，产品增长自然到来：一项将用户体验视角与增长联系起来并带来可衡量影响的混合方法案例研究*

*Neha Raghuvanshi* | **Category: cs.HC**

**Keywords:** 混合方法, 用户体验研究, 产品主导增长, 案例研究, 用户价值, 业务增长

**Comment:** 

> **TL;DR:** 本案例研究展示了用户体验研究（UXR）和数据科学团队如何利用混合方法战略性地影响产品主导增长，从而实现用户价值最大化和业务增长的双赢。

**AI_Comments:** 这篇论文通过一个具体的案例研究，展示了用户体验研究和数据科学的结合如何在实际业务中发挥战略性作用，实现用户价值与商业增长的双赢。其创新之处在于强调了“混合方法”和“用户体验视角（POV）”在产品增长中的实际应用，并提供了可衡量的影响。对于面临用户价值和业务增长平衡挑战的团队来说，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨跨职能团队如何在最大化用户价值和实现业务增长之间取得平衡，以达到双赢局面。

**Method:** 用户体验研究（UXR）和数据科学团队使用混合方法研究，战略性地影响了拥有百万以上用户的密码管理器的产品主导增长（PLG）。该研究与用户体验研究的“观点金字塔”（POV）方法论相结合。

**Result:** 通过混合方法，成功帮助用户、内部团队和业务实现共赢，并带来了可衡量的用户和业务影响。

**Conclusion:** 本案例研究提供了利用混合方法来最大化用户价值、实现业务增长目标、影响跨职能团队以及衡量用户和业务影响的实用经验和技术。

> **ai_Abstract:** 本案例研究探讨了跨职能团队如何通过平衡用户价值和业务增长实现双赢。具体地，它展示了用户体验研究（UXR）和数据科学团队如何利用混合方法研究，成功地战略性影响了拥有百万以上用户的密码管理器的产品主导增长（PLG），从而实现了用户、团队和业务的共同成功。该研究提供了一系列实用经验，旨在帮助读者利用混合方法最大化用户价值、达成业务增长目标、影响跨职能团队并衡量用户和业务影响，并与用户体验研究的“观点金字塔”方法论紧密结合。

> **摘要翻译:** 你想过跨职能团队如何平衡用户价值最大化和业务增长以实现双赢局面吗？本案例研究展示了用户体验研究（UXR）和数据科学团队如何利用混合方法研究，战略性地影响一款拥有百万以上用户的密码管理器的产品主导增长（PLG），从而使我们的用户、内部团队和业务都取得了成功。读者将从中汲取利用混合方法的实用经验/技术，以：a. 在满足业务增长目标的同时最大化用户价值；b. 影响跨职能团队；c. 衡量用户和业务影响。本案例研究可以轻松地与用户体验研究的“观点金字塔”（POV）[2]联系起来，该金字塔代表了一种构建观点的方法论，并进一步深入探讨如何将观点付诸行动以创造可衡量的用户和业务影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [95] [Subtitled Media Adaptations for People with Aphasia: Ongoing Accessibility Barriers and Emerging Design Practices](https://arxiv.org/abs/2506.21201)
> *失语症患者的字幕媒体改编：持续存在的无障碍障碍和新兴设计实践*

*Zihao You, Michael Crabb* | **Category: cs.HC**

**Keywords:** 失语症, 字幕, 无障碍, 个性化, 包容性设计

**Comment:** 3 pages, 1 figure, Access InContext Workshop at CHI 2025 on 26th of
  April

> **TL;DR:** 针对失语症患者，当前字幕的“一刀切”方法存在可访问性障碍；本研究呼吁通过原型工具和方法，开发个性化且更具包容性的媒体解决方案，以纳入失语症患者的意见。

**AI_Comments:** 这篇论文强调了一个重要的社会问题：数字媒体辅助工具（如字幕）在设计上可能无意中排除特定用户群体，特别是失语症患者。其创新之处在于提出“个性化”和“包容性设计”作为解决当前“一刀切”方法的关键，并特别强调在设计过程中纳入受影响人群（失语症患者）的意见。这种以用户为中心、强调公平包容的设计理念具有重要的实践意义，有助于推动更公平的数字无障碍环境。

<details>
  <summary>Details</summary>

**Motivation:** 当前字幕的“一刀切”方法无法满足具有复杂无障碍需求的人群（尤其是失语症患者）的需求，导致他们在理解字幕文本时面临显著挑战，进而可能被边缘化。因此，需要开发个性化和更具包容性的媒体解决方案。

**Method:** 本文旨在调查如何为失语症患者开发未来的媒体解决方案，以创建更具包容性的媒体观看环境。作者认为关键在于使用适当的原型工具和方法，以确保在系统设计过程中公平地纳入失语症患者的意见。

**Result:** Not mentioned in abstract

**Conclusion:** 本文呼吁采取更具包容性的实践，强调在媒体研究中纳入失语症患者的观点和意见，并通过原型工具和方法开发个性化媒体解决方案，以实现更具包容性的媒体观看环境。

> **ai_Abstract:** 本文指出当前字幕的“一刀切”方法无法满足失语症患者等具有复杂无障碍需求人群的需求，导致他们难以理解字幕。作者呼吁采取更具包容性的实践，通过研究和开发个性化的媒体解决方案，并利用适当的原型工具和方法，将失语症患者的观点和意见纳入系统设计过程，从而为他们创造一个更具包容性的媒体观看环境。

> **摘要翻译:** 电视、笔记本电脑和智能手机上的字幕消费有可能因其复杂的无障碍需求而使人们被边缘化。当前这种“一刀切”的无障碍辅助方法已不再适用，需要研究如何根据个人语境、内容和消费习惯进行个性化调整。例如，失语症患者在理解字幕文本方面遇到了重大挑战。我们将我们的工作视为一项行动呼吁，旨在推行更具包容性的实践，重点关注如何将失语症患者的想法和意见纳入媒体研究。我们的工作旨在调查如何为失语症患者开发未来的媒体解决方案，以创建更具包容性的媒体观看环境。我们相信，实现这一目标的关键在于适当的原型工具和方法，以实现在系统设计过程中的公平包容。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [118] [Multimodal LLMs for Visualization Reconstruction and Understanding](https://arxiv.org/abs/2506.21319)
> *用于可视化重建和理解的多模态大型语言模型*

*Can Liu, Chunlin Da, Xiaoxiao Long, Yuxiao Yang, Yu Zhang, Yong Wang* | **Category: cs.HC, cs.CV**

**Keywords:** 多模态LLMs, 可视化理解, 数据提取, 图表重建, 矢量化表示

**Comment:** 

> **TL;DR:** 本文提出了一个新数据集并训练了专门的多模态LLM，以解决现有模型在理解可视化方面（特别是数据到视觉映射和结构化信息提取）的不足，并在数据提取和图表重建方面取得了显著改进。

**AI_Comments:** 这项研究的创新之处在于其专注于解决多模态LLMs在理解复杂数据可视化方面的特定挑战，特别是通过引入专门的数据集和利用矢量化表示来提高数据到视觉映射的解码能力和结构化信息提取的准确性。这对于提升AI在数据分析和解释领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 可视化对于数据交流至关重要，但理解它们需要同时理解视觉元素和底层数据关系。当前的多模态大型模型在自然图像理解方面表现出色，但由于无法解码数据到视觉的映射规则和提取结构化信息，因此在理解可视化方面存在困难。

**Method:** 为了解决这些挑战，本文提出了一个新颖的数据集，并训练了专门用于理解可视化的多模态可视化LLM。该方法将图表图像与其对应的矢量化表示、编码方案和数据特征相结合。提出的矢量格式能够紧凑而准确地重建可视化内容。

**Result:** 实验结果表明，在数据提取准确性和图表重建质量方面都有显著改进。

**Conclusion:** 通过引入专门的数据集和训练方法，本文成功地提升了多模态LLMs在可视化重建和理解方面的能力，解决了现有模型在处理复杂数据可视化时的局限性。

> **ai_Abstract:** 本文提出了一种新颖的方法，通过构建专门的数据集并训练多模态可视化大型语言模型（LLMs），以解决现有通用多模态模型在理解和重建数据可视化方面的不足。该方法结合了图表图像、矢量化表示、编码方案和数据特征，并利用一种紧凑的矢量格式进行可视化内容重建。实验证明，该方法显著提高了数据提取的准确性和图表重建的质量。

> **摘要翻译:** 可视化对于数据交流至关重要，但理解它们需要同时理解视觉元素和底层数据关系。当前的多模态大型模型在自然图像理解方面表现出色，但由于无法解码数据到视觉的映射规则和提取结构化信息，因此在理解可视化方面存在困难。为了解决这些挑战，我们提出了一个新颖的数据集并训练了专门用于理解可视化的多模态可视化LLMs。我们的方法将图表图像与其对应的矢量化表示、编码方案和数据特征相结合。所提出的矢量格式能够紧凑而准确地重建可视化内容。实验结果表明，在数据提取准确性和图表重建质量方面都有显著改进。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [138] ["Who Should I Believe?": User Interpretation and Decision-Making When a Family Healthcare Robot Contradicts Human Memory](https://arxiv.org/abs/2506.21322)
> *"我该相信谁？"：当家庭医疗机器人与人类记忆矛盾时用户的解释与决策*

*Hong Wang, Natalia Calvo-Barajas, Katie Winkle, Ginevra Castellano* | **Category: cs.HC, cs.RO**

**Keywords:** 家庭医疗机器人, 用户信任, 信息冲突, 透明度, 决策制定

**Comment:** 8 pages

> **TL;DR:** 研究家庭医疗机器人信息与用户记忆冲突时，机器人透明度和社交性对用户信任和决策的影响。

**AI_Comments:** 这项研究通过探讨家庭医疗机器人与用户记忆冲突这一具体场景，揭示了机器人设计中透明度机制的关键作用。其创新之处在于量化了透明度对用户归因的影响，并提出了用户可能存在的过度信任风险，这对于未来家庭医疗机器人的设计和部署具有重要的实践指导意义。特别是在多用户家庭环境中，系统访问控制的重要性被凸显，为后续研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着智能医疗机器人在家庭环境中部署的可能性增加，当机器人提供的信息与用户记忆矛盾时，会引发用户信任和决策问题。

**Method:** 采用2x2被试间在线研究，176名参与者观看Furhat机器人作为家庭医疗助手，建议虚构用户在不同于其记忆的时间服药的视频。研究考察机器人透明度和社交性对用户解释、决策和信任的影响。

**Result:** 机器人透明度影响用户对信息差异的解释：低透明度机器人下，用户倾向认为自己记错了时间；高透明度机器人下，用户更倾向归因于外部因素（如伴侣修改了信息）。参与者表现出过度信任倾向，即使怀疑系统故障或第三方干扰，也常优先采纳机器人建议。

**Conclusion:** 研究强调了机器人系统中透明度机制的影响、多用户家庭机器人系统访问控制的复杂性和重要性，以及用户在医疗等敏感领域过度依赖机器人的潜在风险。

> **ai_Abstract:** 本文研究了当家庭医疗机器人提供的信息与用户记忆冲突时，机器人透明度和社交性对用户解释、决策和信任的影响。一项2x2在线研究发现，机器人透明度影响用户对信息差异的归因，高透明度下用户更倾向归因于外部因素。研究还揭示用户存在对机器人的过度信任倾向，即使怀疑系统问题也优先采纳机器人建议。这些结果强调了透明度机制、多用户系统访问控制的重要性以及过度依赖机器人的潜在风险。

> **摘要翻译:** "我该相信谁？"：当家庭医疗机器人与人类记忆矛盾时用户的解释与决策

摘要：
随着机器人提供身体协助、心理支持和日常健康管理能力的进步，在不久的将来，在家庭环境中部署智能医疗机器人变得越来越可行。然而，当这些机器人提供的信息与用户的记忆相矛盾时，挑战随之出现，引发了用户信任和决策方面的担忧。本文提出了一项研究，探讨了当机器人提供冲突信息时，改变机器人的透明度和社交性水平如何影响用户的解释、决策和感知信任。在一项2x2被试间在线研究中，176名参与者观看了Furhat机器人扮演家庭医疗助手，建议虚构用户在不同于其记忆的时间服药的视频。结果表明，机器人透明度影响了用户对信息差异的解释：对于低透明度机器人，最常见的假设是用户没有正确记住时间，而对于高透明度机器人，参与者更有可能将差异归因于外部因素，例如伴侣或另一个家庭成员修改了机器人的信息。此外，参与者表现出过度信任的倾向，即使怀疑系统故障或第三方干扰，也经常优先采纳机器人的建议而非用户的记忆。这些发现强调了透明度机制在机器人系统中的影响、与家庭环境中部署的多用户机器人系统访问控制相关的复杂性和重要性，以及用户在医疗等敏感领域过度依赖机器人的潜在风险。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [154] [A Systematic Review of Human-AI Co-Creativity](https://arxiv.org/abs/2506.21333)
> *人机协同创造的系统综述*

*Saloni Singh, Koen Hndriks, Drik Heylen, Kim Baraka* | **Category: cs.HC, cs.AI, I.2.11**

**Keywords:** 人机协同创造, 系统综述, 设计考量, 用户控制, 人工智能协作

**Comment:** 

> **TL;DR:** 本文对62篇关于协同创造系统的论文进行了系统综述，识别了关键设计维度和24个设计考量，发现高用户控制和适应性主动系统能提升用户满意度和协作，但也存在早期创意阶段支持有限等挑战。

**AI_Comments:** 这是一篇有价值的系统综述，它系统地梳理了人机协同创造领域的设计考量和现有挑战。其创新之处在于提炼出关键的设计维度和具体的设计考量，为未来的协同创造系统开发提供了清晰的指导。论文强调了用户控制和系统主动性在协作中的重要性，并指出了该领域仍需关注的空白，如早期创意阶段的支持。这对于推动人机交互和人工智能在创意领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 协同创造社区在开发更复杂和定制化的系统以支持和增强人类创造力方面取得了显著进展。先前的设计考量可以为未来的系统提供有价值且高效的基础。为支持这项工作，本文旨在对协同创造系统进行系统文献综述。

**Method:** 本文对62篇关于协同创造系统的论文进行了系统文献综述。这些论文涵盖了视觉艺术、设计和写作等多种应用，其中AI不仅作为工具，而且作为创意过程中的积极协作者。

**Result:** 从综述中，本文识别了几个与系统设计相关的关键维度：创意过程的阶段、创意任务、系统的主动行为、用户控制、系统体现和AI模型类型。研究结果表明，提供高用户控制的系统能带来更高的满意度、信任和对创意成果更强的归属感。此外，主动系统在适应性和上下文敏感时可以增强协作。本文还提取了24个设计考量，强调了鼓励用户外化思想以及增加系统的社会存在感和透明度以培养信任的价值。

**Conclusion:** 尽管最近取得了进展，但仍存在重要空白，例如对问题澄清等早期创意阶段的支持有限，以及用户适应AI系统相关的挑战。高用户控制和适应性主动系统对提升用户满意度和协作至关重要，未来的系统应关注填补现有空白。

> **ai_Abstract:** 本文对62篇关于人机协同创造系统的文献进行了系统综述，旨在为未来系统设计提供基础。研究识别了创意过程阶段、任务、系统主动性、用户控制、系统体现和AI模型类型等关键设计维度，并提出了24个设计考量。结果表明，高用户控制能提升用户满意度和归属感，适应性主动系统能增强协作。同时，也指出了早期创意阶段支持不足和用户适应挑战等现有差距。

> **摘要翻译:** 协同创造社区在开发更复杂和定制化的系统以支持和增强人类创造力方面取得了显著进展。先前的设计考量可以为未来的系统提供有价值且高效的基础。为支持这项工作，我们对62篇关于协同创造系统的论文进行了系统文献综述。这些论文涵盖了视觉艺术、设计和写作等多种应用，其中AI不仅作为工具，而且作为创意过程中的积极协作者。从本次综述中，我们识别了几个与系统设计相关的关键维度：创意过程的阶段、创意任务、系统的主动行为、用户控制、系统体现和AI模型类型。我们的发现表明，提供高用户控制的系统能带来更高的满意度、信任和对创意成果更强的归属感。此外，主动系统在适应性和上下文敏感时可以增强协作。我们还提取了24个设计考量，强调了鼓励用户外化思想以及增加系统的社会存在感和透明度以培养信任的价值。尽管最近取得了进展，但仍存在重要空白，例如对问题澄清等早期创意阶段的支持有限，以及用户适应AI系统相关的挑战。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [168] [An evaluation of level of detail degradation in head-mounted display peripheries](https://arxiv.org/abs/2506.21441)
> *头戴式显示器外围细节层次降级评估*

*Benjamin Watson, Neff Walker, Larry F Hodges, Martin Reddy* | **Category: cs.HC, cs.GR**

**Keywords:** 细节层次, 头戴式显示器, 虚拟环境, 用户研究, 外围视觉

**Comment:** 

> **TL;DR:** 本研究提出了一种在虚拟环境中管理细节层次的设计范式，并通过用户研究评估了头戴式显示器中高细节镶嵌的有效性。结果显示，对于简单搜索任务，无镶嵌的高细节显示器与有镶嵌的显示器在搜索时间或准确性上没有显著差异，只有无镶嵌的低细节显示器表现出显著差异。

**AI_Comments:** 这项研究为头戴式显示器中细节层次管理的设计提供了初步的实证证据。其创新之处在于通过用户研究评估了高细节镶嵌的实际效果。重要性在于它挑战了高细节镶嵌在所有场景下都带来显著优势的假设，特别是对于简单任务。局限性在于研究仅限于简单的搜索任务，未来需要探索不同任务复杂度和参数（如镶嵌尺寸）的影响。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在提出一种在虚拟环境中管理细节层次的系统设计范式，并作为原型设计步骤的实例，评估头戴式显示器中高细节镶嵌的有效性。

**Method:** 研究采用用户研究方法，让10名受试者执行一个简单的目标搜索任务。受试者使用了七种不同的显示器（自变量），这些显示器在镶嵌尺寸和外围细节上有所不同。帧率、目标位置、受试者输入方法和显示器使用顺序均受到控制。主要因变量是正确识别试验的搜索时间和所有试验的正确识别百分比。数据通过方差分析（ANOVAs）进行分析。

**Result:** 方差分析结果显示，无镶嵌的高细节显示器与有镶嵌的显示器在搜索时间或准确性上没有显著差异。事实上，只有无镶嵌的低细节显示器产生了显著不同的结果。

**Conclusion:** 对于简单的搜索任务，在头戴式显示器中使用高细节镶嵌可能不会比无镶嵌的高细节显示器带来显著的性能提升。只有当细节层次完全降低且无镶嵌时，性能才会显著下降。

> **ai_Abstract:** 本研究提出了一种虚拟环境细节层次管理系统设计范式，并通过用户研究评估了头戴式显示器中高细节镶嵌的有效性。实验中，10名受试者在不同镶嵌和细节设置的显示器上执行简单搜索任务。结果显示，对于简单任务，无镶嵌的高细节显示器与带镶嵌的显示器在性能上无显著差异，仅无镶嵌的低细节显示器导致性能显著下降。这表明高细节镶嵌对简单任务的效用可能有限。

> **摘要翻译:** 本文提出了一种在虚拟环境中管理细节层次的系统设计范式。作为该范式中原型设计步骤的一个例子，我们进行了一项用户研究，以评估头戴式显示器中使用高细节镶嵌的有效性。十名受试者被分配了一个简单的搜索任务，要求定位和识别一个目标物体。所有受试者使用七种不同的显示器（自变量），这些显示器在镶嵌尺寸和外围细节上有所不同，来执行此任务。帧率、目标位置、受试者输入方法和显示器使用顺序都得到了控制。主要的因变量是正确识别试验的搜索时间，以及所有正确识别试验的百分比。结果的方差分析表明，无镶嵌的高细节显示器与有镶嵌的显示器在搜索时间或准确性上没有显著差异。事实上，只有无镶嵌的低细节显示器返回了显著不同的结果。正在进行进一步的研究，以检查不同任务复杂性、镶嵌尺寸和细节层次的影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [174] [Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation](https://arxiv.org/abs/2506.21417)
> *轻量化指甲触觉设备：无阻碍指腹力和振动反馈，增强虚拟灵巧操作*

*Yunxiu Xu, Siyu Wang, Shoichi Hasegawa* | **Category: cs.HC, H.5.2; I.3.6**

**Keywords:** 指甲触觉设备, 轻量化, 虚拟灵巧操作, 触觉反馈, 可穿戴设备

**Comment:** 14 pages, 15 figures, 2 tables. Published in IEEE Transactions on
  Haptics (Early Access)

> **TL;DR:** 该研究提出了一种轻量级指甲触觉设备，通过指甲提供力觉和振动反馈，显著提高了虚拟灵巧操作效率，同时不影响真实世界互动。

**AI_Comments:** 该研究的创新之处在于其独特的指甲附着设计，实现了极低的重量和对指腹的无阻碍，解决了传统手套式触觉设备笨重和影响真实操作的问题。其重要性体现在为虚拟现实和增强现实中的灵巧操作提供了更自然、更沉浸的交互方式，具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有触觉设备在提供反馈的同时，常会阻碍真实世界的互动或增加设备重量。本研究旨在开发一种轻量化、不影响真实世界操作的触觉设备，以增强虚拟环境中的灵巧操作。

**Method:** 研究团队设计了一种轻量级（每根手指1.55克）可穿戴指尖触觉设备，通过连接到指甲的细线和执行器提供基于物理的触觉反馈。该设备集成了物理引擎，能够提供握力、碰撞和滑动振动等多种反馈。通过压力感知、滑移反馈、灵巧操作任务和日常操作进行评估，并收集了用户主观体验。

**Result:** 参与者能够感知并响应压力和振动反馈。通过灵巧操作实验，证明了这些微小的触觉提示显著提高了虚拟任务效率。该设备在保持触觉感知和最小化对真实世界操作的阻碍方面，优于手套式触觉设备。

**Conclusion:** 本研究提供了一种潜在的解决方案，用于设计平衡轻量化构造、灵巧操作触觉反馈和日常佩戴性的触觉界面。该轻量化指甲触觉设备能有效增强虚拟操作性能，同时不依赖复杂机制。

> **ai_Abstract:** 本研究介绍了一种创新的轻量化指甲触觉设备，该设备通过连接到指甲的细线和执行器，为虚拟环境中的灵巧操作提供力觉和振动反馈。其设计仅重1.55克/指，确保了手指灵活性和对真实世界操作的无阻碍。实验证明，该设备能有效传递压力和振动反馈，并显著提升虚拟任务效率。与传统手套式设备相比，其保持触觉感知和日常佩戴性的优势，使其成为一种平衡轻量化、高效反馈和实用性的触觉界面解决方案。

> **摘要翻译:** 本研究提出了一种轻量级、可穿戴的指尖触觉设备，为虚拟环境中的灵巧操作提供基于物理的触觉反馈，同时不阻碍真实世界互动。该设备采用连接到指甲的细线和执行器设计，确保了最小重量（每根手指1.55克），并保持了手指的灵活性。通过将软件与物理引擎集成，可提供多种类型的触觉反馈（握力、碰撞和滑动振动反馈）。我们评估了设备在压力感知、滑移反馈、典型灵巧操作任务和日常操作中的性能，并通过主观评估收集了用户体验。我们的结果表明，参与者能够感知并响应压力和振动反馈。通过灵巧操作实验，我们进一步证明这些微小的触觉提示显著提高了虚拟任务效率，展示了轻量级触觉反馈如何在没有复杂机制的情况下增强操作性能。该设备保持触觉感知并最小化对真实世界操作的阻碍的能力是其相对于手套式触觉设备的关键优势。这项研究为设计平衡轻量化结构、灵巧操作触觉反馈和日常佩戴性的触觉界面提供了一种潜在的解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [185] [Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles](https://arxiv.org/abs/2506.21456)
> *通过头部追踪的周边退化管理细节水平：一个模型和由此产生的设计原则*

*Benjamin Watson, Neff Walker, Larry F Hodges* | **Category: cs.HC, cs.GR**

**Keywords:** 细节水平管理, 头部追踪, 周边退化, 心理物理学模型, 显示器设计

**Comment:** 

> **TL;DR:** 本文提出一个基于心理物理学的模型，解释了头部追踪大视场显示器中周边细节水平下降的有效性，并通过实验验证了中心高细节区域的面积而非形状对搜索性能的影响，并据此提出了设计原则。

**AI_Comments:** 本文的创新之处在于提出了一个基于心理物理学的模型来解释周边细节退化的有效性，并通过实验验证了该模型，为大视场显示器的优化设计提供了具体的指导原则，特别是关于高细节中心区域的面积而非形状的重要性。这对于提升虚拟现实或增强现实等应用的用户体验和系统效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究证明了在头部追踪的大视场显示器中，降低周边细节水平（LOD）的实用性。本文旨在提供一个基于心理物理学的模型，解释周边退化的有效性，并据此提出周边退化显示器的设计原则。

**Method:** 进行了一项实验，评估了周边退化显示器中高细节中心区域（内嵌区域）的形状和面积对搜索性能的影响。

**Result:** 实验结果表明，内嵌区域的形状对性能不是一个显著因素。然而，内嵌区域的面积是显著的：水平和垂直视角至少为30度的显示器，其性能与未退化显示器的性能没有显著差异。

**Conclusion:** 实验结果与本文提出的模型一致，证明了该模型能够解释周边细节退化的有效性并指导设计。

> **ai_Abstract:** 本文提出一个基于眼/头运动权衡的心理物理学模型，旨在解释头部追踪大视场显示器中周边细节水平下降的有效性，并指导其设计。通过实验验证了中心高细节区域的形状对搜索性能无显著影响，而面积则有显著影响，发现水平和垂直视角至少30度的显示器性能与未退化显示器相当。这些结果支持了所提出的模型。

> **摘要翻译:** 以前的工作已经证明了在头部追踪、大视场显示器中，降低周边细节水平（LOD）的实用性。本文提供了一个基于心理物理学的模型，该模型围绕眼/头运动权衡，解释了周边退化的有效性，并提出了如何设计周边退化显示器。进行了一项实验，评估了周边退化显示器中高细节中心区域（内嵌区域）的形状和面积对搜索性能的影响，结果表明内嵌区域的形状对性能不是一个显著因素。然而，内嵌区域的面积是显著的：水平和垂直视角至少为30度的显示器，其性能与未退化显示器的性能没有显著差异。这些结果与所提出的模型一致。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [5] [Domain Knowledge in Requirements Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.20754)
> *需求工程中的领域知识：一项系统映射研究*

*Marina Araújo, Júlia Araújo, Romeu Oliveira, Lucas Romao, Marcos Kalinowski* | **Category: cs.SE**

**Keywords:** 需求工程, 领域知识, 系统映射研究, 知识管理, 需求规范

**Comment:** Accepted for publication at the 51st Euromicro Conference Series on
  Software Engineering and Advanced Applications (SEAA) 2025

> **TL;DR:** 本研究通过系统映射研究，全面概述了在需求工程中有效利用领域知识的现有方法、技术和工具，并指出了未来的研究方向。

**AI_Comments:** 这项研究通过系统映射的方式，对需求工程中领域知识的应用进行了全面的梳理，填补了该领域系统性整合的空白。其价值在于为研究人员和实践者提供了一个宝贵的资源，帮助他们理解现有方法、识别未解决的问题，并指明了未来研究的重点，特别是强调了自动化和可持续解决方案的重要性。其创新性体现在通过严格的系统映射方法，对分散的文献进行了有效的整合和分析。

<details>
  <summary>Details</summary>

**Motivation:** 尽管领域知识在需求工程（RE）中至关重要，但现有科学文献缺乏对其在RE中如何有效使用和操作化的系统性整合。

**Method:** 我们采用混合搜索策略进行了系统映射研究，结合了数据库搜索以及迭代的向前和向后滚雪球法。

**Result:** 共发现了75篇符合纳入标准的论文。分析揭示了所处理的需求类型、最常考虑的质量属性，以及领域知识形式化、获取和长期维护中的常见挑战。研究结果为研究人员和实践者识别既定方法和未解决问题提供了支持，并为未来研究指明了方向，强调开发可扩展、自动化和可持续的解决方案。

**Conclusion:** 本研究通过提供全面的概述，为知识驱动的需求工程构建概念和方法论基础做出了贡献。

> **ai_Abstract:** 本系统映射研究旨在弥补在需求工程（RE）中有效利用和操作化领域知识的文献空白。研究通过混合搜索策略识别了75篇相关论文，并分析了领域知识在RE中的应用、挑战和质量属性。研究结果为研究人员和实践者提供了现有方法的洞察，并指明了未来在开发可扩展、自动化和可持续解决方案方面的研究方向，最终为知识驱动的RE奠定了概念和方法论基础。

> **摘要翻译:** [背景] 领域知识被认为是需求工程（RE）成功的关键组成部分，因为它提供了理解系统上下文、确保与利益相关者需求对齐以及减少需求规范模糊性所需的概念支持。尽管其具有相关性，但科学文献仍然缺乏对领域知识如何在RE中有效使用和操作化的系统性整合。[目标] 本文通过全面概述现有贡献，包括将领域知识纳入RE实践的方法、技术和工具，来弥补这一空白。[方法] 我们采用混合搜索策略进行了系统映射研究，该策略结合了数据库搜索和迭代的向前和向后滚雪球法。[结果] 我们总共找到了75篇符合我们纳入标准的论文。分析强调了所处理的需求主要类型、最常考虑的质量属性，以及领域知识形式化、获取和长期维护中的常见挑战。研究结果为研究人员和实践者识别既定方法和未解决问题提供了支持。该研究还概述了未来研究的有前景方向，强调开发可扩展、自动化和可持续的解决方案，以将领域知识整合到RE过程中。[结论] 本研究通过提供全面的概述，有助于为知识驱动的需求工程构建概念和方法论基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [22] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
> *机器学习的敏捷管理：一项系统性映射研究*

*Lucas Romao, Hugo Villamizar, Romeu Oliveira, Silvio Alonso, Marcos Kalinowski* | **Category: cs.SE, cs.AI**

**Keywords:** 敏捷管理, 机器学习, 系统性映射研究, 项目管理, 软件开发

**Comment:** Accepted for publication at the 51st Euromicro Conference Series on
  Software Engineering and Advanced Applications (SEAA) 2025

> **TL;DR:** 本研究对机器学习系统敏捷管理的现状进行了系统性映射，识别了现有框架、实践和主要挑战，并指出仍需更多实证评估。

**AI_Comments:** 这项研究通过系统性映射为机器学习项目管理领域提供了宝贵的概览，特别是在敏捷方法应用方面。其创新之处在于识别并分类了ML特有的敏捷实践和工件。重要性体现在揭示了该领域的主要挑战（如工作量估算）和未来研究方向（如实证验证）。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习（ML）驱动的系统日益普及，但其开发过程的动态性（实验周期、数据快速变化）对传统项目管理构成挑战。敏捷方法看似适用，但如何在ML系统中有效应用尚不明确，需要量身定制的方法。本文旨在概述机器学习系统敏捷管理的现状。

**Method:** 我们采用混合搜索策略进行了一项系统性映射研究，结合了数据库搜索以及向前和向后滚雪球迭代。

**Result:** 研究识别了2008年至2024年间发表的27篇论文，从中归纳出8个框架，并将推荐和实践分为8个关键主题，例如迭代灵活性、创新的ML特定工件和最小可行模型。研究中发现的主要挑战是ML相关任务的准确工作量估算。

**Conclusion:** 本研究通过绘制该领域的现状图并识别开放性差距做出了贡献。尽管存在相关工作，但仍需要更稳健的实证评估来验证这些贡献。

> **ai_Abstract:** 本系统性映射研究旨在概述机器学习（ML）系统敏捷管理的现状。通过对2008-2024年间27篇论文的分析，研究识别了8个现有框架，并将相关实践和推荐归纳为8个关键主题，如迭代灵活性和最小可行模型。研究强调了ML任务估算准确性是主要挑战，并指出尽管已有相关工作，但仍需更强的实证评估来验证现有贡献。

> **摘要翻译:** [背景] 机器学习（ML）驱动的系统已遍布我们的社会，推动着重大的数字化转型。ML开发的动态性，以实验周期和数据快速变化为特征，对传统项目管理提出了挑战。敏捷方法凭借其灵活性和增量交付，似乎非常适合应对这种动态性。然而，目前尚不清楚如何在ML驱动系统的背景下有效应用这些方法，因为这些挑战需要量身定制的方法。
[目标] 我们的目标是概述ML驱动系统敏捷管理的现状。
[方法] 我们采用混合搜索策略进行了一项系统性映射研究，该策略结合了数据库搜索以及向前和向后滚雪球迭代。
[结果] 我们的研究识别了2008年至2024年间发表的27篇论文。从中，我们识别了八个框架，并将推荐和实践分为八个关键主题，例如迭代灵活性、创新的ML特定工件和最小可行模型。研究中发现的主要挑战是ML相关任务的准确工作量估算。
[结论] 本研究通过绘制该领域的现状图并识别开放性差距做出了贡献。尽管存在相关工作，但仍需要更稳健的实证评估来验证这些贡献。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [46] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
> *通过自动化集成数据生成可靠不良事件档案（GRAPH-AID）：一种半自动化本体构建方法*

*Srikar Reddy Gadusu, Larry Callahan, Samir Lababidi, Arunasri Nishtala, Sophia Healey, Hande McGinty* | **Category: cs.SE, cs.AI, cs.DB**

**Keywords:** 本体构建, Neo4j, OWL, Python, 不良事件报告

**Comment:** 

> **TL;DR:** 本论文提出了一种用户友好的半自动化方法，利用Python和rdflib库将Neo4j数据库中的不良事件数据集成到OWL本体中，以解决现有方法对描述逻辑语法要求高的问题，从而支持药物安全监测。

**AI_Comments:** 该论文的创新之处在于提供了一种半自动化且用户友好的方法来桥接Neo4j数据库和OWL本体之间的集成鸿沟，特别是在处理不良事件数据方面。它通过利用Python和rdflib库，并开发自动化脚本来生成本体结构，降低了对用户描述逻辑语法知识的要求，提高了本体构建的可访问性。这对于快速变化和增长的数据集（如药物不良事件数据）尤其重要，有助于改进药物安全监测和公共卫生决策，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着数据和知识的快速增长，本体生成系统化方法变得至关重要。数据量和内容变化日益频繁，对存储和检索信息以创建知识图谱的数据库需求日益紧迫。虽然KNARM方法论为解决这些挑战提供了系统方法，但它突显了Neo4j数据库与Web本体语言（OWL）无缝集成存在的挑战。现有将Neo4j数据集成到本体中的尝试通常需要用户理解描述逻辑（DL）语法，这对于许多用户来说可能不熟悉，因此需要一种更易于访问的方法来弥补这一差距。

**Method:** 本研究提出了一种用户友好的方法，利用Python及其rdflib库支持本体开发。作者通过集成美国食品药品监督管理局（FDA）不良事件报告系统（FAERS）数据库的数据创建了一个Neo4j数据库，并以此展示了他们的新方法。他们开发了一个Python脚本，自动生成所需的类及其公理，从而促进了更顺畅的集成过程。

**Result:** 该方法成功地将FDA不良事件报告系统（FAERS）的数据从Neo4j数据库集成到OWL本体中，并通过自动生成类和公理的Python脚本，实现了平滑的集成过程。这提供了一个实用的解决方案，应对快速增长的不良药物事件数据集背景下的本体生成挑战。

**Conclusion:** 该论文提供了一种实用的解决方案，解决了在快速增长的不良药物事件数据集背景下本体生成所面临的挑战，支持改进药物安全监测和公共卫生决策。

> **ai_Abstract:** 本论文提出了一种名为GRAPH-AID的半自动化本体构建方法，旨在解决将Neo4j数据库与OWL本体集成时面临的挑战，特别是现有方法对描述逻辑语法要求高的问题。研究人员利用Python及其rdflib库开发了一个用户友好的方法，并通过集成FDA不良事件报告系统（FAERS）数据构建的Neo4j数据库进行了展示。他们开发了一个Python脚本，能够自动生成本体所需的类和公理，从而实现了数据向本体的平滑集成。该方法为在快速增长的不良药物事件数据背景下进行本体生成提供了一个实用且可访问的解决方案，有助于提升药物安全监测和公共卫生决策的效率。

> **摘要翻译:** 随着数据和知识的快速扩展，采用系统方法进行本体生成已变得至关重要。随着数据量的日常增加和内容的频繁变化，对存储和检索信息以创建知识图谱的数据库的需求变得日益紧迫。先前建立的知识获取和表示方法论（KNARM）概述了一种系统方法来解决这些挑战并创建知识图谱。然而，遵循这种方法论突出了将Neo4j数据库与Web本体语言（OWL）无缝集成存在的现有挑战。之前将Neo4j数据集成到本体中的尝试已被讨论，但这些方法通常需要理解描述逻辑（DL）语法，这可能对许多用户不熟悉。因此，需要一种更易于访问的方法来弥补这一差距。本文提出了一种用户友好的方法，利用Python及其rdflib库支持本体开发。我们通过我们创建的Neo4j数据库展示了我们的新方法，该数据库通过集成美国食品药品监督管理局（FDA）不良事件报告系统（FAERS）数据库的数据而创建。使用该数据集，我们开发了一个Python脚本，自动生成所需的类及其公理，从而促进了更顺畅的集成过程。这种方法为在快速增长的不良药物事件数据集背景下本体生成所面临的挑战提供了一个实用解决方案，支持改进药物安全监测和公共卫生决策。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [70] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
> *为真实世界应用构建RAG系统：设计、开发与评估*

*Md Toufique Hasan, Muhammad Waseem, Kai-Kristian Kemell, Ayman Asad Khan, Mika Saari, Pekka Abrahamsson* | **Category: cs.SE, cs.AI, cs.IR, D.2.11; I.2.6; H.3.3**

**Keywords:** RAG系统, 大型语言模型, 真实世界应用, 实证研究, 经验教训

**Comment:** Accepted as a full paper to the 51st Euromicro Conference on Software
  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This
  is the preprint version and not the final camera ready version

> **TL;DR:** 本文介绍了为政府、网络安全、农业、工业研究和医学诊断等领域开发的五个真实世界RAG应用，通过100名用户的评估，并总结了12条关于RAG系统可靠性和可用性的实践经验。

**AI_Comments:** 本文的创新之处在于提供了RAG系统在多个真实世界应用场景下的实证开发、部署和用户评估数据。这对于推动RAG技术从理论走向实际应用具有重要意义。所总结的十二条经验教训，特别是对技术、操作和伦理挑战的深入分析，为未来RAG系统的工程化提供了宝贵的实践指导和警示，有助于研究人员和开发者构建更可靠、更实用的RAG解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究缺乏关于基于真实世界用例、通过用户参与评估并系统记录经验教训的RAG系统开发的实证研究。

**Method:** 本文开发了五个针对真实世界场景的领域特定RAG应用，涵盖治理、网络安全、农业、工业研究和医学诊断。每个系统都集成了多语言OCR、通过向量嵌入进行的语义检索以及领域适应的LLM。通过一项涉及100名参与者的基于网络的评估，从易用性、相关性、透明度、响应性、准确性和推荐可能性六个维度对系统进行了评估。

**Result:** 基于用户反馈和开发经验，本文记录了十二条关键经验教训，强调了影响RAG系统在实践中可靠性和可用性的技术、操作和伦理挑战。

**Conclusion:** 本文通过开发和评估多个真实世界的RAG系统，填补了该领域实证研究的空白，并提供了关于RAG系统在实际应用中设计、开发和部署的关键经验和挑战的宝贵见解。

> **ai_Abstract:** 本文旨在弥补真实世界RAG系统开发和评估实证研究的不足。研究设计并实现了五个领域特定的RAG应用，涵盖政府、网络安全、农业、工业研究和医学诊断等多个实际场景。这些系统整合了多语言OCR、语义检索和领域适应的LLM。通过一项由100名用户参与的在线评估，从易用性、相关性、透明度、响应性、准确性和推荐可能性等六个维度对系统进行了综合评估。基于开发经验和用户反馈，论文总结了十二条关键经验教训，揭示了在实际部署RAG系统时面临的技术、操作和伦理挑战，为提升系统可靠性和可用性提供了实践指导。

> **摘要翻译:** 检索增强生成（RAG）系统正成为将大型语言模型（LLM）基于外部知识的关键方法，以解决事实准确性和上下文相关性方面的局限性。然而，目前缺乏关于基于真实世界用例、通过普通用户参与评估并伴随系统性经验教训文档的RAG实现开发的实证研究。本文介绍了为治理、网络安全、农业、工业研究和医学诊断等真实世界场景开发的五个领域特定RAG应用。每个系统都集成了多语言OCR、通过向量嵌入进行的语义检索以及领域适应的LLM，通过本地服务器或云API部署以满足不同的用户需求。一项涉及总共100名参与者的基于网络的评估从六个维度对系统进行了评估：(i)易用性、(ii)相关性、(iii)透明度、(iv)响应性、(v)准确性，以及(vi)推荐可能性。基于用户反馈和我们的开发经验，我们记录了十二条关键经验教训，强调了影响RAG系统在实践中可靠性和可用性的技术、操作和伦理挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [94] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
> *不确定人类指导下通过强化学习进行的复杂模型转换*

*Kyanna Dagenais, Istvan David* | **Category: cs.SE, cs.AI, cs.LG**

**Keywords:** 模型转换, 强化学习, 人类指导, 模型驱动工程, 人机协作

**Comment:** Accepted for ACM/IEEE MODELS'25

> **TL;DR:** 本文提出了一种结合强化学习和不确定人类指导的方法，用于开发复杂的模型转换序列，并证明了人类指导能显著提高RL性能。

**AI_Comments:** 该论文的创新点在于将强化学习应用于复杂的模型转换问题，并引入了“不确定人类指导”的概念来克服RL在复杂问题上的性能瓶颈。这一方法通过有效整合人类领域知识和RL的探索能力，提高了模型转换的效率和准确性，对于推进模型驱动工程的自动化和人机协作具有重要意义。未来研究可以进一步探索如何量化和优化不确定性指导的效用。

<details>
  <summary>Details</summary>

**Motivation:** 模型驱动工程中的复杂模型转换（MTs）手动开发容易出错且不可行。强化学习（RL）可以缓解这些问题，但在复杂问题中存在性能问题。因此，需要一种结合人类指导的方法来提高RL在复杂MTs开发中的表现。

**Method:** 本文提出了一种方法和技术框架，通过强化学习并结合可能不确定的人类建议来开发复杂的模型转换序列。该框架允许将用户定义的MTs映射到RL原语，并将其作为RL程序执行以找到最佳MT序列。

**Result:** 评估结果表明，即使是不确定的人类指导也能显著提高强化学习的性能，并使得复杂模型转换的开发更加高效。

**Conclusion:** 通过权衡人类建议的确定性和及时性，该方法向着强化学习驱动的人机协作工程方法迈进了一步。

> **ai_Abstract:** 本文针对模型驱动工程中复杂模型转换（MTs）手动开发困难的问题，提出了一种结合强化学习（RL）与不确定人类指导的方法。该方法通过将用户定义的MTs映射到RL原语并执行，旨在找到最优的MT序列。实验结果表明，即使是不确定的人类指导也能显著提升RL的性能，从而更高效地开发复杂的MTs，为RL驱动的人机协作工程提供了新的方向。

> **摘要翻译:** 模型驱动工程问题通常需要复杂的模型转换（MTs），即以广泛序列链接的MTs。此类问题的相关示例包括模型同步、自动化模型修复和设计空间探索。手动开发复杂的MTs是一个容易出错且通常不可行的过程。强化学习（RL）是缓解这些问题的合适方法。在RL中，自主代理通过试错探索状态空间，以识别有益的动作序列，例如MTs。然而，RL方法在复杂问题中表现出性能问题。在这些情况下，人类指导具有很高的效用。在本文中，我们提出了一种通过强化学习开发复杂MT序列的方法和技术框架，该框架由可能不确定的人类建议指导。我们的框架允许将用户定义的MTs映射到RL原语，并将其作为RL程序执行以找到最佳MT序列。我们的评估表明，人类指导，即使是不确定的，也能显著提高RL性能，并导致更高效的复杂MT开发。通过权衡人类建议的确定性和及时性，我们的方法向着RL驱动的人机协作工程方法迈进了一步。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [117] [Boosting Vulnerability Detection with Inter-function Multilateral Association Insights](https://arxiv.org/abs/2506.21014)
> *通过函数间多边关联洞察提升漏洞检测*

*Shaojian Qiu, Mengyang Huang, Jiahao Cheng* | **Category: cs.SE**

**Keywords:** 漏洞检测, 函数间关联, 超图, 超边卷积, 深度学习

**Comment:** 

> **TL;DR:** 提出IFMA-VD框架，通过构建代码行为超图并利用超边卷积来提取多边关联特征，从而提升漏洞检测能力。

**AI_Comments:** 该论文的创新点在于引入了“函数间多边关联”的概念，并首次提出使用超图（特别是超边卷积）来建模和提取这种复杂关系，以增强漏洞检测。这克服了传统方法仅关注独立函数或简单二元关系的局限性，为漏洞检测领域提供了一个新颖且有效的视角。其方法论严谨，通过超图捕捉更丰富的上下文信息，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的深度学习漏洞检测方法主要关注独立函数，忽略了复杂的函数间相互关系，特别是多边关联，这可能导致无法检测到这些关系中的漏洞。

**Method:** 提出IFMA-VD框架，其核心是构建代码行为超图并利用超边卷积来提取多边关联特征。具体步骤包括：首先将函数解析为代码属性图以生成函数内特征；然后通过分割程序依赖图构建代码行为超图，将行为特征编码到超边中；最后利用超图网络捕获多边关联知识以增强漏洞检测。

**Result:** 在三个广泛使用的漏洞数据集上评估了IFMA-VD，与基线方法相比，F-measure和Recall有所提高。此外，研究表明多边关联特征可以增强代码特征表示，并在真实世界数据集上验证了IFMA-VD的有效性。

**Conclusion:** 通过考虑函数间多边关联，IFMA-VD框架能够有效提升漏洞检测的性能，并增强代码特征表示。

> **ai_Abstract:** 该论文提出了一个名为IFMA-VD的框架，旨在解决现有深度学习漏洞检测方法忽略函数间复杂多边关联的问题。IFMA-VD通过构建代码行为超图并利用超边卷积来提取这些多边关联特征，从而增强漏洞检测能力。实验结果表明，与基线方法相比，IFMA-VD在多个漏洞数据集上提高了F-measure和Recall，并能有效提升代码特征表示，验证了其在真实世界数据集上的有效性。

> **摘要翻译:** 漏洞检测是确保软件系统安全的关键但具有挑战性的技术。目前，大多数基于深度学习的漏洞检测方法侧重于独立函数，忽略了复杂的函数间相互关系，特别是多边关联。这种疏忽可能导致无法检测到这些相互关系中的漏洞。为了解决这一差距，我们提出了一个用于漏洞检测的函数间多边关联分析框架（IFMA-VD）。IFMA-VD的基石在于构建代码行为超图并利用超边卷积来提取多边关联特征。具体来说，我们首先将函数解析为代码属性图以生成函数内特征。在此之后，我们通过分割程序依赖图来构建代码行为超图，以隔离并将行为特征编码到超边中。最后，我们利用超图网络捕获多边关联知识以增强漏洞检测。我们在三个广泛使用的漏洞数据集上评估了IFMA-VD，并展示了与基线方法相比，F-measure和Recall的改进。此外，我们说明了多边关联特征可以提升代码特征表示，并验证了IFMA-VD在真实世界数据集上的有效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [137] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
> *合成需求有多好？评估用于AI4RE的LLM生成数据集*

*Abdelkarim El-Hajjami, Camille Salinesi* | **Category: cs.SE, cs.AI**

**Keywords:** 合成需求, LLM, AI4RE, 数据集生成, 数据质量

**Comment:** 

> **TL;DR:** 鉴于AI4RE领域标注需求数据集的短缺，本文提出了Synthline v1，一种增强的产品线方法，用于生成合成需求数据。研究表明，通过多样本提示等策略，LLM生成的合成数据在特定任务上可以与甚至超越人工数据，为缓解数据集稀缺性提供了可行路径。

**AI_Comments:** 本文通过系统性地探索LLM生成合成需求数据的质量控制与优化方法，展现了创新性。其重要性在于，它不仅证明了合成数据在AI4RE领域的可行性，更指出在特定任务上合成数据甚至能超越人工数据，为解决数据稀缺性提供了强有力的替代方案。对于提示优化结果的任务依赖性以及策展对性能的复杂影响的深入分析，也提供了宝贵的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能需求工程（AI4RE）领域面临公开可用、带标签的需求数据集严重短缺的重大障碍。尽管大型语言模型（LLMs）在合成数据生成方面展现出前景，但系统性地控制和优化生成需求质量的方法仍未得到充分探索。

**Method:** 本文提出了Synthline v1，一种增强的产品线方法，用于生成合成需求数据，该版本在v0基础上增加了高级生成策略和策展技术。研究通过评估提示策略（多样本与单样本）、自动化提示优化（PACE）和生成后策展对数据质量的影响，探讨了四个研究问题。评估涵盖四种分类任务：缺陷检测、功能性与非功能性、质量与非质量、以及安全性与非安全性。

**Result:** 多样本提示显著提升了实用性和多样性，F1分数提高了6到44分。PACE自动化提示优化结果因任务而异，显著改善了功能分类（+32.5分），但在其他任务上性能下降。基于相似度的策展提高了多样性，但往往损害分类性能，表明某些冗余可能有助于机器学习模型。最重要的是，合成需求在特定任务上可以与或优于人工撰写的需求，例如在安全性（+7.8分）和缺陷分类（+15.4分）上超越了人工数据。

**Conclusion:** 这些发现为AI4RE提供了实用见解，并为通过系统性合成生成来缓解数据集稀缺性描绘了一条可行路径，表明合成数据在特定任务上可以匹配甚至超越人工数据。

> **ai_Abstract:** 为解决AI4RE领域标注需求数据集稀缺的问题，本文提出了Synthline v1，一种利用大型语言模型生成合成需求的增强产品线方法。研究系统评估了提示策略、自动化提示优化和生成后策展对数据质量的影响，涵盖多种分类任务。结果显示，多样本提示能显著提升数据效用与多样性，并且在安全性与缺陷检测等特定任务上，合成数据表现甚至优于人工数据，证明了其作为缓解数据集稀缺性有效手段的潜力。

> **摘要翻译:** 公开可用、带标签的需求数据集的短缺仍然是推进人工智能需求工程（AI4RE）的主要障碍。尽管大型语言模型在合成数据生成方面提供了有前景的能力，但系统地控制和优化生成需求质量的方法仍未得到充分探索。本文提出了Synthline v1，一种增强的产品线方法，用于生成合成需求数据，该方法通过高级生成策略和策展技术扩展了我们早期的v0版本。我们调查了四个研究问题，评估了提示策略、自动化提示优化和生成后策展如何影响四种分类任务（缺陷检测、功能性与非功能性、质量与非质量、安全与非安全）的数据质量。我们的评估表明，多样本提示显著提升了单样本生成的实用性和多样性，F1分数提高了6到44分。使用PACE（提示行动者-评论家编辑）进行自动化提示优化产生了依赖于任务的结果，极大地改善了功能分类（+32.5分），但降低了其他任务的性能。有趣的是，基于相似度的策展提高了多样性，但通常损害分类性能，这表明某些冗余可能有助于机器学习模型。最重要的是，我们的结果表明，合成需求在特定任务上可以与或优于人工撰写的需求，其中合成数据在安全性（+7.8分）和缺陷分类（+15.4分）方面超越了人工数据。这些发现为AI4RE提供了实用见解，并为通过系统性合成生成来缓解数据集稀缺性描绘了一条可行路径。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [153] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
> *$T^3$: 基于多级树的大语言模型自动程序修复*

*Quanming Liu, Xupeng Bu, Zhichao Yan, Ru Li* | **Category: cs.SE, cs.AI**

**Keywords:** 自动程序修复, 大语言模型, 思维链, 树搜索, 自动化调试

**Comment:** 

> **TL;DR:** 提出 $T^3$ 框架，结合大语言模型和树搜索，提升自动程序修复的精度和效率。

**AI_Comments:** 该论文的创新之处在于将大语言模型的强大推理能力与树搜索机制相结合，以解决自动程序修复中复杂逻辑和多步推理的挑战。这种结合有望显著提升修复方案的生成精度，为软件开发中的自动化调试提供新的有效途径，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型（LLMs）和思维链（CoT）技术取得了显著进展，但由于自动程序修复（APR）任务需要复杂的逻辑和多步推理能力，CoT技术在APR领域的应用仍显不足。

**Method:** 本研究系统评估了几种常见思维链（CoT）技术在自动程序修复（APR）任务中的表现，并提出了一个创新的 $T^3$ 框架，该框架将大语言模型（LLMs）的强大推理能力与树搜索相结合。

**Result:** $T^3$ 有效提高了生成候选修复方案的精度，并为自动程序修复（APR）任务中的样本选择和修复策略优化提供了有价值的指导。

**Conclusion:** $T^3$ 为实现高效的自动化调试建立了一个稳健的框架。

> **ai_Abstract:** 本文针对自动程序修复（APR）中思维链（CoT）技术应用不足的问题，提出了一个名为 $T^3$ 的创新框架。该框架将大型语言模型（LLM）的推理能力与树搜索相结合，旨在提高生成候选修复方案的精度。研究表明，$T^3$ 不仅提升了修复精度，还为APR任务的样本选择和修复策略优化提供了指导，最终为高效自动化调试构建了一个稳健的框架。

> **摘要翻译:** 自动程序修复（APR）是软件开发和维护中的一项核心技术，旨在以最少的人工干预实现自动化缺陷修复。近年来，大型语言模型（LLMs）和思维链（CoT）技术的巨大进步显著增强了这些模型的推理能力。然而，由于APR领域所需的复杂逻辑和多步推理能力，CoT技术在该领域的应用仍然不足。本研究系统评估了几种常见CoT技术在APR任务中的性能，并提出了一个创新的框架$T^3$，该框架将LLMs强大的推理能力与树搜索相结合，有效提高了生成候选修复方案的精度。此外，$T^3$ 为优化APR任务中的样本选择和修复策略提供了宝贵的指导，为实现高效的自动化调试建立了一个稳健的框架。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [173] [KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks](https://arxiv.org/abs/2506.21266)
> *KOALA：一个用于在解决编程任务时收集IDE数据的可配置工具*

*Daniil Karol, Elizaveta Artser, Ilya Vlasov, Yaroslav Golubev, Hieke Keuning, Anastasiia Birillo* | **Category: cs.SE, cs.CY**

**Keywords:** IDE数据收集, 编程教育, 可配置工具, 学生行为分析, JetBrains IDE

**Comment:** Accepted to CompEd'25, 7 pages, 4 figures

> **TL;DR:** KOALA是一个高度可配置的工具，用于在学生解决编程任务时收集IDE数据，克服了现有工具在数据粒度控制和事件收集方面的局限性。

**AI_Comments:** KOALA的创新之处在于其高度可配置性、能够收集更细粒度和更全面的IDE行为数据（如热键和焦点切换），以及支持将数据转换为ProgSnap2标准格式，这对于促进编程教育领域的数据共享和研究具有重要意义。它直接解决了现有工具在数据粒度控制和特定环境事件收集方面的不足。

<details>
  <summary>Details</summary>

**Motivation:** 现有的编程任务数据收集工具存在局限性，例如无法控制代码收集的粒度、不收集特定编程环境事件以及难以配置。研究人员和教育工作者需要这些数据来验证学生对概念的应用或发现其误解。

**Method:** 本文提出了KOALA，一个方便且高度可配置的工具，用于收集学生在JetBrains IDE中解决编程任务时的代码快照和功能使用数据。该插件可安装在IDE中，配置提供任务、启用/禁用IDE功能和运行调查。它收集配置粒度的代码快照、所有IDE操作（如运行、调试）、热键使用和文件焦点切换等数据。收集到的数据发送到配套服务器存储，并可转换为ProgSnap2格式。

**Result:** 为了展示该工具，研究人员从28名学生那里收集了在IDE中解决两个课程任务的数据，并从中获得了一些见解。

**Conclusion:** KOALA是一个克服现有局限性的可配置工具，能够收集更细致和全面的学生编程行为数据，对研究人员和教育工作者有价值。

> **ai_Abstract:** 本文介绍了KOALA，一个为克服现有工具局限性而设计的高度可配置工具，用于在学生使用JetBrains IDE解决编程任务时收集详细的编程行为数据。KOALA能够以可配置的粒度收集代码快照、IDE操作、热键使用和文件焦点切换等数据，并将其存储为ProgSnap2格式。通过在28名学生中进行数据收集，展示了该工具的有效性及其在教育研究中的应用潜力。

> **摘要翻译:** 收集学生解决编程任务的数据对研究人员和教育工作者来说非常有价值。它允许验证学生是否正确应用了所学的特性和概念，或者发现学生的错误概念。然而，现有数据收集工具存在局限性，例如无法控制所收集代码的粒度，不收集所使用的编程环境的特定事件，以及总体上难以配置。
为了克服这些局限性，我们提出了KOALA，一个方便且高度可配置的工具，用于收集学生在JetBrains IDE中解决编程任务时的代码快照和功能使用情况。该插件可以安装在IDE中，并配置为向学生提供必要的任务，启用或禁用某些IDE功能（如代码自动补全），以及运行调查。在解决问题期间，该插件会以配置的粒度收集代码快照，所有IDE操作（如运行和调试），以及一些先前工作中未收集到的数据，例如使用的快捷键和文件之间焦点切换。收集到的数据会发送到工具附带的服务器，在那里存储并可以转换为标准化的ProgSnap2格式。为了展示该工具，我们收集了28名学生在IDE中解决两门课程任务的数据，并强调了这些数据的一些见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [189] [Exploring Micro Frontends: A Case Study Application in E-Commerce](https://arxiv.org/abs/2506.21297)
> *探索微前端：一个电子商务中的案例研究应用*

*Ricardo Hideki Hangai Kojo, Luiz Fernando Corte Real, Renato Cordeiro Ferreira, Thatiane de Oliveira Rosa, Alfredo Goldman* | **Category: cs.SE, cs.DC, D.2.11; D.2.13; D.2.7**

**Keywords:** 微前端, 电子商务, 架构, 案例研究, 微服务

**Comment:** 11 pages, 2 figures (2 diagrams), submitted to the workshop AMP 2025

> **TL;DR:** 本文通过文献调查和在一个手工艺品电商平台上的案例研究，评估了微前端架构的适用性，发现尽管微前端成功实施，但对于满足公司需求并非绝对必要，其便利性主要得益于与现有微服务和单体解耦策略的协同。

**AI_Comments:** 本文通过案例研究深入探讨了微前端在真实工业环境中的应用，其创新之处在于不仅验证了微前端的可行性，还通过量化评估指出了其并非总是最佳或唯一选择，这为业界提供了宝贵的决策参考。论文强调了与现有架构（如微服务）的协同作用是成功实施的关键，而非微前端本身。局限性可能在于案例研究的通用性，以及问卷调查的主观性。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在理解何时值得采用微前端架构，特别是在工业背景下，以解决现有系统紧密耦合、技术过时和开发者体验不佳等问题。

**Method:** 研究方法包括对微前端领域最新进展的调查（基于学术和灰色文献），然后在一个已使用微服务的电商平台实施微前端架构，并通过对开发者进行半开放式问卷调查来评估实施效果。

**Result:** 微前端架构的采用是成功的，但并非严格必要，单体前端等其他替代方案也能达到类似效果。微前端成为最便捷的选择，是因为单体解耦和微服务采用促进了基础设施重用和团队间知识共享。

**Conclusion:** 尽管微前端成功实施，但对于满足公司需求而言并非绝对必要。其在公司背景下成为最便捷的选择，是由于单体解耦和微服务采用，促进了实施过程中的基础设施重用和团队间知识共享。

> **ai_Abstract:** 本研究探讨了在电子商务领域采用微前端架构的适用性。通过文献回顾和在一个手工艺品电商平台上的案例研究，评估了微前端的实施效果。研究发现，尽管微前端成功地解决了现有系统耦合、技术过时和开发者体验问题，但其并非满足公司需求的唯一或严格必要的选择。其便利性主要源于与现有微服务和单体解耦策略的协同作用，实现了基础设施复用和知识共享。

> **摘要翻译:** 在微前端架构风格中，前端被划分为更小的组件，范围从简单的按钮到整个页面。目标是提高可扩展性、弹性和团队独立性，尽管代价是增加复杂性和基础设施需求。本文旨在理解何时值得采用微前端，特别是在工业背景下。为此，我们对微前端的最新技术状况进行了调查，基于学术和灰色文献。然后，我们在一个已经使用微服务的手工艺品市场中实现了这种架构风格。最后，我们通过对开发者进行半开放式问卷调查来评估了实施效果。在所研究的电商公司中，由于其主系统（Java 单体）与专用前端系统之间的紧密耦合，以及存在废弃技术和糟糕的开发者体验，因此出现了架构变革的需求。为了解决这些问题，采用了微前端架构，以及 API 网关和后端即前端模式，以及 Svelte 和 Fastify 等技术。尽管微前端的采用是成功的，但对于满足公司需求而言并非严格必要。根据对混合问卷答复的分析，其他替代方案，如单体前端，也可以达到类似的结果。在公司背景下，使采用微前端成为最便捷选择的原因是单体解耦和微服务采用，这通过基础设施重用和团队间知识共享促进了实施。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [202] [An object-centric core metamodel for IoT-enhanced event logs](https://arxiv.org/abs/2506.21300)
> *一个面向对象的物联网增强事件日志核心元模型*

*Yannis Bertrand, Christian Imenkamp, Lukas Malburg, Matthias Ehrendorfer, Marco Franceschetti, Joscha Grüger, Francesco Leotta, Jürgen Mangler, Ronny Seiger, Agnes Koschmider, Stefanie Rinderle-Ma, Barbara Weber, Estefania Serral* | **Category: cs.SE**

**Keywords:** 物联网, 过程挖掘, 数据集成, 元模型, 事件日志

**Comment:** 

> **TL;DR:** 本文提出了一个核心元模型，用于整合物联网数据和流程数据，以解决现有数据模型碎片化的问题，从而促进过程挖掘领域的数据共享与协作。

**AI_Comments:** 该论文解决了物联网数据与传统流程数据集成中的一个关键问题，即数据模型碎片化。其创新点在于提出了一个综合现有模型特征的核心元模型，旨在提供一个通用的数据共享和协作基础。这对于过程挖掘领域的发展具有重要意义，因为它能有效降低数据交换的复杂性，促进跨领域研究。

<details>
  <summary>Details</summary>

**Motivation:** 物联网技术的发展使得物联网设备与业务流程的集成变得普遍，产生了大量的物联网数据，有助于通过过程挖掘发现新的业务洞察。然而，由于物联网数据和传统流程数据特性差异大（如粒度），两者结合面临挑战。现有数据模型碎片化，阻碍了数据交换和协作。

**Method:** 本文提出了一个核心元模型，该模型综合了现有数据模型最重要的特征，并基于共同的需求。通过一个原型Python实现，对该模型进行了评估，并针对各种用例进行了验证，证明其满足这些共同需求。

**Result:** 所提出的核心模型极大地促进了物联网增强事件日志领域的数据共享和协作，并且通过原型Python实现验证，该模型满足了共同的需求。

**Conclusion:** 本文提出的核心元模型解决了物联网数据与流程数据集成中现有数据模型碎片化的问题，通过提供一个基于共同需求的核心模型，极大地促进了数据共享和协作，为过程挖掘领域带来了便利。

> **ai_Abstract:** 本文提出了一种面向对象的物联网增强事件日志核心元模型，旨在解决物联网数据与传统业务流程数据集成时面临的挑战，特别是现有数据模型碎片化的问题。该模型综合了现有数据模型的重要特征，并基于共同需求构建，旨在促进过程挖掘领域的数据共享与协作。一个原型Python实现验证了该模型在不同用例下满足通用要求。

> **摘要翻译:** 物联网（IoT）技术的进步促使物联网设备与各行各业（如制造业、医疗保健和智能空间）的业务流程（BP）进行整合。物联网设备的普及导致了大量物联网数据的生成，这些数据为业务流程的物理上下文提供了窗口，从而有助于使用过程挖掘（PM）技术发现关于业务流程的新洞察。然而，为了实现这些益处，物联网数据需要与传统流程（事件）数据相结合，这由于物联网数据和流程数据在粒度等方面的显著差异而具有挑战性。最近，提出了几种数据模型来整合物联网数据和流程数据，每个模型都基于不同的假设和要求，侧重于数据集成的不同方面。这种碎片化阻碍了过程挖掘领域的数据交换和协作，例如，使得研究人员共享数据变得繁琐。在本文中，我们提出了一个核心模型，该模型综合了现有数据模型最重要的特征。由于该核心模型基于共同的需求，它极大地促进了该领域的数据共享和协作。一个原型Python实现被用于根据各种用例评估该模型，并证明它满足这些共同需求。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [10] [Establishing validated standards for Home and Work location Detection](https://arxiv.org/abs/2506.20679)
> *建立家庭和工作地点检测的验证标准*

*Silvia de Sojo, Lorenzo Lucchini, Ollin D. Langle-Chimal, Samuel P. Fraiberger, Laura Alessandretti* | **Category: cs.SI, cs.CY**

**Keywords:** 家庭和工作地点检测, 移动数据, HoWDe, 准确性, 标准化

**Comment:** 

> **TL;DR:** 提出了HoWDe算法，用于从智能手机数据中准确识别家庭和工作地点，并经验证具有高精度和可重复性，解决了现有方法的标准化问题。

**AI_Comments:** HoWDe的创新在于其鲁棒性，能够处理不同质量和缺失的移动数据，并结合大规模地面真实数据进行验证，这在现有方法中是缺失的。其重要性在于建立了家庭和工作地点检测的标准化方法，显著提高了研究结果的可比性和可重复性，对城市规划、通勤分析和失业估计等下游应用具有重要意义。此外，它还促进了隐私保护数据的共享，这在当前数据隐私日益受关注的背景下尤为关键。

<details>
  <summary>Details</summary>

**Motivation:** 智能手机位置数据对城市交通研究至关重要，但大规模利用存在方法学挑战。准确识别家庭和工作地点对通勤分析、失业估计和城市可达性研究至关重要。现有家庭-工作地点检测方法缺乏考虑不同数据质量并经过地面真实验证的标准化框架，限制了研究结果的可比性和可重复性。

**Method:** 本文提出了HoWDe算法，一种用于从移动数据中识别家庭和工作地点的鲁棒算法，专门设计用于处理缺失数据和个体之间不同的数据质量。该算法使用来自80多个国家的5100多名个体的两个独特的地面真实数据集进行验证。

**Result:** HoWDe算法在家庭和工作地点检测方面分别达到高达97%和88%的准确率，并且在不同国家和人口群体中表现一致。研究还检查了参数选择如何影响准确性和用户保留之间的权衡，并展示了这些方法学决策如何影响失业估计和通勤模式分析等下游应用。

**Conclusion:** HoWDe工具和发现建立了方法学标准，支持在个体和城市尺度上进行更稳健、可扩展和可重复的移动性研究。通过透明和经过验证的管道支持内部预处理，HoWDe还促进了隐私保护移动数据的共享。

> **ai_Abstract:** 本论文介绍了HoWDe，一种创新的算法，旨在通过处理数据缺失和质量差异，从智能手机移动数据中准确识别家庭和工作地点。该算法利用超过5100个个体的大规模地面真实数据集进行验证，实现了高达97%的家庭地点检测准确率和88%的工作地点检测准确率，并在不同国家和人口群体中表现出一致性。HoWDe通过提供一个标准化且经验证的框架，解决了现有方法在可比性和可重复性方面的限制，从而支持更稳健、可扩展和可重复的城市移动性研究，并促进隐私保护数据的共享。

> **摘要翻译:** 智能手机位置数据已经改变了城市交通研究，提供了前所未有的洞察力，了解人们如何在城市中导航和互动。然而，大规模利用位置数据带来了方法学挑战。准确识别个人家庭和工作地点对于一系列应用至关重要，包括通勤分析、失业估计和城市可达性研究。尽管广泛使用，家庭-工作地点检测方法缺乏一个标准化框架，该框架能够考虑不同的数据质量并根据地面真实观测进行验证。这限制了研究结果在不同研究和数据集之间的可比性和可重复性。在本文中，我们提出了HoWDe，一种从移动数据中识别家庭和工作地点的鲁棒算法，明确设计用于处理缺失数据和个体之间不同的数据质量。使用包含来自80多个国家的5100多名个体的两个独特的地面真实数据集，HoWDe在家庭和工作地点检测方面分别达到高达97%和88%的准确率，并且在不同国家和人口群体中表现一致。我们检查了参数选择如何影响准确性和用户保留之间的权衡，并展示了这些方法学决策如何影响失业估计和通勤模式分析等下游应用。通过透明和经过验证的管道支持内部预处理，HoWDe还促进了隐私保护移动数据的共享。总而言之，我们的工具和发现建立了方法学标准，支持在个体和城市尺度上进行更稳健、可扩展和可重复的移动性研究。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [26] [Malicious earworms and useful memes, how the far-right surfs on TikTok audio trends](https://arxiv.org/abs/2506.20695)
> *恶意耳虫和有用模因：极右翼如何利用TikTok音频趋势*

*Marloes Geboers, Marcus Bösch* | **Category: cs.SI, cs.CY**

**Keywords:** TikTok, 极右翼, 音频趋势, 模因, 仇外内容

**Comment:** 

> **TL;DR:** 研究发现TikTok的声音基础设施被极右翼利用，通过模糊的模因和用户生成的声音传播仇外内容，即使有害内容不被个性化推荐，仍通过与良性趋势结合而传播。

**AI_Comments:** 这篇论文揭示了社交媒体平台在内容审核方面面临的复杂挑战，特别是针对那些通过声音和模糊模因进行隐蔽传播的恶意内容。其创新之处在于关注了“声音基础设施”这一常被忽视的方面，并指出其如何被滥用。研究强调了平台需要更精细的策略来识别和打击那些不明显但具有潜在危害性的内容，而不仅仅是关注显而易见的有害挑战。论文的重要性在于其揭示了数字平台在政治极化和虚假信息传播中的潜在作用，尤其是在选举背景下。

<details>
  <summary>Details</summary>

**Motivation:** 探讨TikTok作为模因传播平台，其声音基础设施如何被右翼极端主义利用来传播仇外内容，尤其是在2024年德国州选举背景下，以及平台现有审核机制的不足。

**Method:** 本研究以声音的作用及其与模糊模因的交叉点为中心，探测了与2024年德国州选举相关的右翼极端主义形成。分析了TikTok声音基础设施如何支持仇外内容的持续存在。

**Result:** 分析表明，TikTok的声音基础设施使得仇外内容能够持续存在，这些内容常常通过本土化的交流方式进行伪装。这些伪装行为受益于允许用户生成声音持续发布并迅速传播的声学基础设施。这些声音通常不易被识别为极端主义内容的传播者。含有仇恨歌词的歌曲虽然不符合个性化推送的条件，但仍在线上，并与良性模因趋势结合，使其在搜索结果中可见。

**Conclusion:** TikTok的声音基础设施存在漏洞，使得极右翼能够以不易察觉的方式传播仇外内容，即使平台有审核机制，这些内容仍能通过与良性趋势的结合而获得可见性。平台需要进一步加强对声音内容的审核和识别。

> **ai_Abstract:** 这项研究探讨了极右翼如何利用TikTok的声音基础设施和模因趋势传播仇外内容。研究发现，尽管TikTok有内容审核和DSA响应措施，其平台上的用户生成声音和模糊模因仍被用来伪装和传播仇外信息，尤其是在德国选举背景下。这些内容即使不被个性化推荐，也能通过与良性趋势结合而获得可见性，揭示了平台在应对恶意内容传播方面的挑战。

> **摘要翻译:** 凭借其混音功能，TikTok是模因制作和传播的指定平台。视频、表情符号和滤镜的创意组合带来了源源不断的由声音激活的模因和趋势。该平台已将其审核重点放在维护人身安全上，因此投资于有害挑战的检测。为了响应《数字服务法案》(DSA)，TikTok实施了个性化推送的退出选项，并提供了允许用户举报非法内容的功能。与此同时，该平台仍受到审查。本研究以声音的作用及其与模糊模因的交叉点为中心，探讨了与2024年德国州选举相关的右翼极端主义形成。分析证据表明，TikTok的声音基础设施如何支持仇外内容的持续存在，这些内容通常通过本土化的交流方式进行伪装。这些伪装行为受益于一种声音基础设施，该基础设施允许用户生成的声音持续发布，并通过“使用此声音”按钮迅速传播。重要的是，这些声音通常不易被明确识别为极端主义内容的传播者。确实含有仇恨歌词的歌曲不符合个性化推送的条件，但它们仍然在线上，并受益于与良性模因趋势的交叉，使其在搜索结果中可见。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [50] [Where is AIED Headed? Key Topics and Emerging Frontiers (2020-2024)](https://arxiv.org/abs/2506.20971)
> *AIED 何去何从？关键主题与新兴前沿 (2020-2024)*

*Shihui Feng, Huilin Zhang, Dragan Gašević* | **Category: cs.SI**

**Keywords:** 教育人工智能, 大型语言模型, 生成式AI, 知识共现网络分析, 新兴前沿

**Comment:** 

> **TL;DR:** 本研究分析了2020-2024年间2398篇AIED研究文章，利用知识共现网络分析揭示了该领域的知识结构、演变趋势和新兴前沿。研究发现AIED仍以技术为中心，并识别出大型语言模型（LLMs）、生成式AI（GenAI）、多模态学习分析和人机协作作为新兴前沿，强调以人为中心的AI教育发展趋势。

**AI_Comments:** 这项研究的创新之处在于它首次对AIED领域在生成式AI时代进行大规模、领域级的转型映射。通过结合大规模文献分析和知识共现网络分析，它提供了对该领域当前状态和未来方向的宝贵见解，特别是在LLMs和GenAI兴起背景下。研究结果对于研究人员、政策制定者和教育实践者理解AIED的发展趋势及其对教育的潜在影响具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在分析2020年至2024年期间AIED领域的研究文章，以揭示该领域的知识结构、演变中的知识集群以及新兴前沿，并提供AIED在生成式AI时代转型的首次大规模领域级映射，从而为未来的研究发展和教育实践提供启示。

**Method:** 研究分析了2020年至2024年间在八个核心会议上发表的2,398篇AIED研究文章。采用三步知识共现网络分析方法，分析了知识结构、演变知识集群和新兴前沿，并通过追踪过去五年的桥接关键词来识别新兴前沿。

**Result:** 研究发现AIED研究仍强烈关注技术，持续的主题包括智能辅导系统、学习分析和自然语言处理，同时对大型语言模型（LLMs）和生成式人工智能（GenAI）的兴趣日益增长。识别出AIED的四个新兴前沿：LLMs、GenAI、多模态学习分析和人机协作。目前GenAI的研究兴趣集中在GAI驱动的个性化、自主学习、反馈、评估、动机和伦理。

**Conclusion:** AIED的关键研究兴趣和新兴前沿反映出对协同自适应、以人为中心的教育AI的日益重视。该研究首次大规模地映射了AIED在生成式AI时代的转型，并为未来的研究发展和教育实践提供了启示。

> **ai_Abstract:** 本研究通过对2020-2024年间2398篇AIED论文进行三步知识共现网络分析，系统地描绘了该领域的知识结构、演变趋势及新兴前沿。研究发现AIED仍以技术为重心，并识别出LLMs、GenAI、多模态学习分析和人机协作等四个新兴前沿。特别指出GenAI在个性化、自主学习、反馈、评估、动机和伦理方面的应用兴趣。该研究强调了AIED向协同自适应、以人为中心的AI教育发展的趋势，并首次提供了AIED在GenAI时代转型的宏观图景，对未来研究和实践具有指导意义。

> **摘要翻译:** 在这项研究中，我们分析了2020年至2024年期间在八个与教育人工智能（AIED）领域相关的核心场所发表的2,398篇研究文章。通过采用三步知识共现网络分析，我们分析了该领域的知识结构、不断演变的知识集群以及新兴前沿。我们的研究结果显示，AIED研究仍然强烈地以技术为中心，持续的主题包括智能辅导系统、学习分析和自然语言处理，同时对大型语言模型（LLMs）和生成式人工智能（GenAI）的兴趣日益增长。通过追踪过去五年中的桥接关键词，我们确定了AIED的四个新兴前沿——LLMs、GenAI、多模态学习分析和人机协作。目前GenAI的研究兴趣集中在GAI驱动的个性化、自主学习、反馈、评估、动机和伦理。AIED中的关键研究兴趣和新兴前沿反映出对协同自适应、以人为中心的教育AI的日益重视。这项研究首次提供了AIED在GenAI时代转型的大规模领域级映射，并为未来的研究发展和教育实践提供了启示。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [74] [Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs](https://arxiv.org/abs/2506.20980)
> *增强同质性-异质性分离：异构图中的关系感知学习*

*Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu* | **Category: cs.SI, cs.AI**

**Keywords:** 异构图, 节点异质性, 对比学习, 关系感知学习, 同质性-异质性分离

**Comment:** accepted by KDD 2025

> **TL;DR:** 本文提出RASH，一个新颖的对比学习框架，用于在异构图中有效处理节点异质性问题，通过关系感知学习来分离同质性和异质性模式。

**AI_Comments:** 本文提出的RASH框架通过引入关系感知机制和对比学习，有效解决了异构图中节点异质性学习的痛点。其创新点在于显式建模多关系高阶语义，并能自适应分离同质和异质模式，避免了传统方法信息丢失的问题。该方法对于理解和处理复杂异构网络中的节点关系具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界网络中普遍存在节点异质性，即连接的节点特征或标签不同。同质图中的异质性问题已得到广泛研究，但在异构图中仍未充分探索，因为异构图包含多种节点和边类型，同时考虑节点/边异构性和节点异质性极具挑战。现有方法通常将异构图转换为同质图来学习节点异质性，但这会不可避免地丢失异构关系所传达的潜在异质性。

**Method:** 本文提出了关系感知同质异质分离（RASH），一个新颖的对比学习框架。RASH通过以下方式显式建模异构交互的高阶语义并自适应地分离同质和异质模式：1. 引入双重异构超图来编码多关系二分图；2. 基于关系重要性动态构建同质图和异质图；3. 设计多关系对比损失，通过最大化互信息来对齐异构视图以及同质/异质视图。

**Result:** 在基准数据集上的大量实验表明，RASH在各种下游任务中都表现出有效性。

**Conclusion:** RASH框架能够同时解决异构图中异构性和异质性的挑战，并在多个下游任务中表现出优异的性能，有效增强了异构图中的同质性-异质性分离。

> **ai_Abstract:** 本文提出了一种名为RASH（关系感知同质异质分离）的新型对比学习框架，旨在解决异构图中节点异质性学习的挑战。针对现有方法在转换异构图时丢失异质性信息的缺点，RASH通过引入双重异构超图、动态构建同质/异质图以及设计多关系对比损失，显式地建模异构交互的高阶语义，并自适应地分离同质和异质模式。实验结果表明RASH在处理异构图的异构性和异质性问题上表现出有效性。

> **摘要翻译:** 现实世界网络通常具有节点异质性，即连接的节点通常具有不同的特征或不同的标签。这种异质性问题已在同质图中得到广泛研究，但在异构图中仍未充分探索，异构图包含多种类型的节点和边。在异构图中捕获节点异质性非常具有挑战性，因为节点/边异构性和节点异质性都应仔细考虑。现有方法通常将异构图转换为同质图来学习节点异质性，这将不可避免地丢失异构关系所传达的潜在异质性。为了弥补这一差距，我们提出了关系感知同质异质分离（RASH），一个新颖的对比学习框架，它显式建模异构交互的高阶语义并自适应地分离同质和异质模式。特别是，RASH引入了双重异构超图来编码多关系二分图，并基于关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息来对齐异构视图以及同质/异质视图。通过这种方式，RASH同时解决了异构图中异构性和异质性的挑战。在基准数据集上的大量实验证明了RASH在各种下游任务中的有效性。代码可在：https://github.com/zhengziyu77/RASH 获取。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [11] [Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks](https://arxiv.org/abs/2506.20762)
> *漂移自适应切片式合作ISAC网络资源管理*

*Shisheng Hu, Jie Gao, Xue Qin, Conghao Zhou, Xinyu Huang, Mushu Li, Mingcheng He, Xuemin Shen* | **Category: cs.NI, eess.SP**

**Keywords:** 漂移自适应, 切片式资源管理, ISAC网络, 数字孪生, 非平稳分布

**Comment:** Accepted by IEEE Transactions on Cognitive Communications and
  Networking

> **TL;DR:** 本文提出了一种新颖的漂移自适应切片式资源管理方案，通过构建数字孪生来应对移动设备和感知目标的非平稳空间分布，从而提高ISAC网络的资源管理效率和用户满意度。

**AI_Comments:** 这篇论文的创新点在于引入了数字孪生技术来应对ISAC网络中移动设备和感知目标的非平稳动态特性，通过漂移自适应模型实现了更鲁棒和高效的资源管理。这种将DTs应用于网络切片资源管理以处理动态不确定性的方法具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的资源管理方案难以应对移动设备和感知目标非平稳空间分布导致的建模漂移和无效规划决策问题。

**Method:** 提出了一种漂移自适应切片式资源管理方案。该方案为感知和通信服务建立两个网络切片，并在大时间尺度规划中划分感知感兴趣区域并预留资源。为应对非平稳空间分布，构建了切片的数字孪生（DTs），每个DT中开发了漂移自适应统计模型和仿真功能，以实现闭式决策和高效验证。

**Result:** 与基准方案相比，所提出的漂移自适应切片式资源管理方案可以将服务满意度提高多达18%，并减少资源消耗多达13.1%。

**Conclusion:** 提出的漂移自适应切片式资源管理方案能有效应对ISAC网络中移动设备和感知目标的非平稳分布，显著提升服务满意度和资源利用效率。

> **ai_Abstract:** 本文提出了一种针对合作ISAC网络的新型漂移自适应切片式资源管理方案。该方案通过建立感知和通信网络切片，并引入数字孪生来处理移动设备和感知目标的非平稳空间分布问题。数字孪生内部集成了漂移自适应统计模型和仿真功能，以优化资源规划和决策验证。数值结果显示，该方案显著提升了服务满意度并降低了资源消耗。

> **摘要翻译:** 在本文中，我们提出了一种新颖的漂移自适应切片式合作集成感知与通信（ISAC）网络资源管理方案。具体而言，我们建立了两个网络切片，分别提供感知和通信服务。在切片的大时间尺度规划中，我们划分了每个移动设备的感知感兴趣区域（RoI），并相应地预留了网络资源，从而促进了小时间尺度下基于距离的低复杂度感知目标分配。为了应对移动设备和感知目标的非平稳空间分布，这些分布可能导致建模漂移和无效的规划决策，我们构建了切片的数字孪生（DTs）。在每个DT中，分别为相应切片中的空间分布开发了漂移自适应统计模型和仿真功能，分别有助于闭式决策和规划决策的有效验证。数值结果表明，与基准方案相比，所提出的漂移自适应切片式资源管理方案可以将服务满意度提高多达18%，并减少资源消耗多达13.1%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [27] [Flowcut Switching: High-Performance Adaptive Routing with In-Order Delivery Guarantees](https://arxiv.org/abs/2506.21406)
> *Flowcut 交换：高性能自适应路由与按序交付保证*

*Tommaso Bonato, Daniele De Sensi, Salvatore Di Girolamo, Abdulla Bataineh, David Hewson, Duncan Roweth, Torsten Hoefler* | **Category: cs.NI**

**Keywords:** 自适应路由, 按序交付, 超级计算机, 网络性能, Flowcut 交换

**Comment:** 

> **TL;DR:** Flowcut 交换是一种新的自适应路由算法，它解决了现有方法在超算网络中可能导致乱序数据包的问题，确保在任何网络条件下都能按序交付，同时保持高性能。

**AI_Comments:** 这项工作针对超算网络中自适应路由导致的乱序问题，提出了Flowcut交换。其创新点在于能够在任何网络条件下保证数据包的按序交付，并且对非突发流量也有效，这对于需要严格按序传输的协议（如RDMA）尤其重要，有助于提升应用性能并降低CPU开销。

<details>
  <summary>Details</summary>

**Motivation:** 网络延迟严重影响超级计算机应用的性能。自适应路由算法旨在减少延迟和提高网络利用率，但可能导致同一流的数据包乱序到达，这对于TCP、QUIC和RoCE等传输协议可能导致性能大幅下降或CPU利用率显著增加。

**Method:** 提出了一种名为“Flowcut 交换”的新型自适应路由算法。与现有基于突发流量假设且可能导致乱序的解决方案（如flowlet 交换）不同，Flowcut 交换在任何网络条件下都能保证按序交付，并且对非突发流量（如RDMA）也有效。

**Result:** Flowcut 交换提供了高性能的按序数据包交付，解决了现有自适应路由算法可能导致的乱序问题，并且适用于非突发流量。

**Conclusion:** Flowcut 交换是一种能够保证数据包按序交付的高性能自适应路由算法，克服了现有解决方案的局限性，尤其适用于需要严格按序传输的场景（如RDMA）。

> **ai_Abstract:** 这篇论文介绍了一种名为Flowcut交换的新型自适应路由算法，旨在解决现有方法在超级计算机网络中可能导致数据包乱序的问题。现有自适应路由虽能降低延迟，但可能因多路径传输导致乱序，进而影响TCP、QUIC等协议的性能。Flowcut交换保证在任何网络条件下都能实现高性能的按序数据包交付，且对非突发流量（如RDMA）同样有效，克服了传统Flowlet交换等方法的局限性。

> **摘要翻译:** 网络延迟严重影响超级计算机上运行应用程序的性能。自适应路由算法通过不同的可用路径路由数据包，以减少延迟并提高网络利用率。然而，如果交换机将属于同一网络流的数据包路由到不同的路径，由于这些路径的延迟差异，它们可能会乱序到达目的地。对于某些传输协议，如TCP、QUIC和RoCE，乱序（OOO）数据包可能会导致性能大幅下降或显著增加CPU利用率。在这项工作中，我们提出了流剪切（flowcut）交换，这是一种新的自适应路由算法，可提供高性能的按序数据包交付。与现有解决方案（如flowlet 交换）不同，后者基于突发流量的假设并可能仍然重新排序数据包，流剪切交换在任何网络条件下都能保证按序交付，并且对于非突发流量（RDMA常见情况）也有效。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [19] [Entropic additive energy and entropy inequalities for sums and products](https://arxiv.org/abs/2506.20813)
> *熵加性能量与和积的熵不等式*

*Rupert Li, Lampros Gavalakis, Ioannis Kontoyiannis* | **Category: cs.IT, math.CO, math.IT, 94A17 (Primary) 11B13 (Secondary)**

**Keywords:** 熵不等式, 加性能量, 微分熵, 和积现象, 加性组合学

**Comment:** 26 pages, no figures

> **TL;DR:** 本文在加性组合学和熵理论交叉领域取得了进展，为连续随机变量的和、积、和积组合的微分熵建立了新的界限，引入了连续随机变量对的加性能量概念并证明其与和熵的关系，推广了Balog-Szemerédi-Gowers定理，提出了新的环Plünnecke-Ruzsa熵不等式，并探讨了离散熵及Erdős-Szemerédi和积现象的熵类比。

**AI_Comments:** 这篇论文在熵理论和加性组合学之间架起了桥梁，将组合学中的重要概念和定理（如加性能量、Balog-Szemerédi-Gowers定理、Plünnecke-Ruzsa不等式、Erdős-Szemerédi和积现象）推广到微分熵和离散熵的语境中。其创新性在于为连续随机变量提供了新的熵不等式，并对离散熵的“大倍增”情况进行了刻画，深化了对熵与结构之间关系的理解。

<details>
  <summary>Details</summary>

**Motivation:** 本研究受到过去15年通过加性组合学思想和工具建立熵不等式的研究日益增多的趋势启发。具体而言，部分受到Goh关于离散熵版本“加性能量”近期工作的启发，引入了连续随机变量对的加性能量概念。此外，部分受到Máthé和O'Regan近期工作的启发，旨在建立一系列新的连续随机变量的积与和积组合的微分熵不等式。

**Method:** 本研究引入了连续随机变量对的加性能量概念，并证明了“加性能量大当且仅当和的熵小”的各种版本。同时，证明了微分熵的Balog-Szemerédi-Gowers定理的一个版本。此外，建立了一系列新的连续随机变量的积与和积组合的微分熵不等式，特别是证明了一个新的、通用的环Plünnecke-Ruzsa熵不等式。文章还探讨了离散熵下具有“大倍增”离散随机变量的刻画，并考虑了整数值随机变量的Erdős-Szemerédi和积现象的自然熵类比。

**Result:** 本工作获得了连续随机变量的和、积以及和积组合的微分熵的许多新界。证明了“加性能量大当且仅当和的熵小”的各种版本，以及微分熵的Balog-Szemerédi-Gowers定理的一个版本。证明了一个新的、通用的环Plünnecke-Ruzsa熵不等式。提供了离散熵下具有“大倍增”的离散随机变量的刻画。此外，研究表明，如果Erdős-Szemerédi和积现象的熵类比成立，则其参数范围将必然比其预期的组合对应物受到显著更多的限制。

**Conclusion:** 本文在连续随机变量的熵不等式方面取得了多项新进展，通过引入加性能量概念并建立其与熵的关系，成功将加性组合学中的关键定理推广到微分熵领域。研究还对离散熵和和积现象的熵类比进行了深入探讨，为理解熵与结构之间的关系提供了新的视角和工具。

> **ai_Abstract:** 本文在加性组合学和熵理论的交叉领域取得了进展，为连续随机变量的和、积及和积组合的微分熵建立了新的界限。研究引入了连续随机变量对的加性能量概念，并证明了其与和熵之间的关系，同时将Balog-Szemerédi-Gowers定理推广至微分熵。此外，文章还提出了新的环Plünnecke-Ruzsa熵不等式，并探讨了离散熵中“大倍增”随机变量的刻画，以及Erdős-Szemerédi和积现象的熵类比。

> **摘要翻译:** 遵循过去15年通过加性组合学思想和工具建立熵不等式的研究日益增多的趋势，本工作获得了连续随机变量的和、积以及和积组合的微分熵的许多新界。部分受Goh关于“加性能量”离散熵版本的近期工作的启发，我们引入了连续随机变量对的加性能量，并证明了“加性能量大当且仅当和的熵小”的各种版本，以及微分熵的Balog-Szemerédi-Gowers定理的一个版本。然后，部分受Máthé和O'Regan近期工作的启发，我们建立了一系列新的连续随机变量的积与和积组合的微分熵不等式。特别是，我们证明了一个新的、通用的环Plünnecke-Ruzsa熵不等式。我们简要地回到离散熵的情况，并提供了具有“大倍增”的离散随机变量的刻画，类似于Tao在小倍增情况下的Freiman型逆和集理论。最后，我们考虑了整数值随机变量的Erdős-Szemerédi和积现象的自然熵类比。我们表明，如果它确实成立，那么它成立的参数范围将必然比其预期的组合对应物受到显著更多的限制。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [34] [Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications](https://arxiv.org/abs/2506.21078)
> *用于以物联网为中心的集成感知与通信的恒模波形*

*Tian Han, Shalanika Dayarathna, Rajitha Senanayake, Peter Smith, Aryan Kaushik, Alain Mourad, Richard A. Stirling-Gallacher, Jamie Evans* | **Category: cs.IT, eess.SP, math.IT**

**Keywords:** 集成感知与通信, 物联网, 恒模波形, 高峰均功率比, 单载波

**Comment:** Submitted for publication to IEEE Communications Standards Magazine

> **TL;DR:** 本文提出了适用于资源受限物联网场景的恒模波形设计，以解决多载波波形（如OFDM）在高峰均功率比（PAPR）方面的问题，并对其感知和通信性能进行了全面讨论。

**AI_Comments:** 该论文创新性地将恒模波形引入物联网集成感知与通信领域，有效解决了OFDM等传统波形在资源受限IoT设备中高PAPR带来的挑战。其提出的单载波频率/相位调制波形设计，对于推动低功耗、低复杂度的ISAC系统发展具有重要意义。对各项性能指标的全面讨论也增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 集成感知与通信（ISAC）是支持物联网（IoT）应用场景的关键技术。然而，传统的多载波波形（如OFDM）由于其高峰均功率比（PAPR），在资源受限的物联网应用中会导致性能下降或系统复杂性增加，使其不适用。

**Method:** 本文提出了以物联网为中心的恒模波形设计，利用其单位高峰均功率比（PAPR）的优势。具体而言，研究了多种单载波频率和/或相位调制波形。

**Result:** 基于雷达模糊函数、带宽特性、数据速率和通信接收机复杂性等性能指标，对所提出的恒模波形的雷达感知和通信性能进行了全面讨论。

**Conclusion:** 恒模波形利用其单位高峰均功率比（PAPR）的优势，更适用于资源受限的物联网集成感知与通信场景。

> **ai_Abstract:** 本文针对物联网（IoT）中集成感知与通信（ISAC）场景的需求，提出了一种新的恒模波形设计。鉴于传统多载波波形（如OFDM）在高PAPR下不适用于资源受限的IoT设备，该研究利用恒模波形单位PAPR的优势，设计了多种单载波频率和/或相位调制波形。论文全面分析了这些波形在雷达感知和通信方面的性能，证明了其在资源受限环境下的适用性。

> **摘要翻译:** 集成感知与通信（ISAC）被认为是支持物联网（IoT）等应用场景的关键使能技术，在这些场景中，通信和感知都扮演着重要角色。多载波波形，如正交频分复用（OFDM），因其高通信数据速率和良好的感知时间带宽特性，被认为是ISAC的良好候选。然而，其高峰均功率比（PAPR）值会导致性能下降或系统复杂性增加。这可能使得OFDM不适用于在功率、系统复杂性、硬件尺寸或成本方面资源不足的物联网应用。本文提供了以物联网为中心的恒模波形设计，利用了单位高峰均功率比的优势，因此更适用于资源受限的场景。更具体地说，本文考虑了几种单载波频率和/或相位调制波形。基于雷达模糊函数、带宽特性、数据速率和通信接收机复杂性等性能指标，对其雷达感知和通信性能进行了全面讨论。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [58] [Semantic-aware Digital Twin for AI-based CSI Acquisition](https://arxiv.org/abs/2506.21126)
> *基于AI的CSI采集的语义感知数字孪生*

*Jiajia Guo, Yiming Cui, Shi Jin* | **Category: cs.IT, math.IT**

**Keywords:** 语义感知数字孪生, AI, CSI采集, 信道状态信息, 数字孪生

**Comment:** This article has been accepted by IEEE Communications Standards
  Magazine

> **TL;DR:** AI增强CSI采集受限于单模态信息和部署挑战，本文探讨语义感知数字孪生如何提升AI-based CSI采集，包括集成和辅助部署两类。

**AI_Comments:** 本文提出了将语义感知数字孪生应用于AI-based CSI采集的新颖视角，旨在解决AI在CSI采集中面临的数据集收集和部署难题。其创新点在于将DT与AI结合，为未来无线通信中的CSI获取提供了潜在的解决方案，对提升AI在实际通信系统中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能（AI）显著提升了信道状态信息（CSI）采集性能，但受限于对单模态信息的依赖以及部署挑战，特别是在数据集收集方面。

**Method:** 本文首先介绍了AI驱动CSI采集和语义感知数字孪生在空口应用中的动机和进展。然后，详细探讨了语义感知数字孪生如何增强AI-based CSI采集，将其分为通过与DT集成来增强和使用DT辅助AI-based CSI部署两类。文中还介绍了潜在的集成框架。

**Result:** Not mentioned in abstract

**Conclusion:** 总结并概述了语义感知数字孪生辅助AI-based CSI采集中的潜在研究方向。

> **ai_Abstract:** 本文探讨了语义感知数字孪生（DT）如何解决AI驱动信道状态信息（CSI）采集面临的单模态信息依赖和部署挑战。研究将语义感知DT应用于AI-based CSI采集分为与DT集成和DT辅助部署两类，并介绍了潜在的集成框架，最后指出了未来的研究方向。

> **摘要翻译:** 标题：基于AI的CSI采集的语义感知数字孪生
摘要：人工智能（AI）显著提升了信道状态信息（CSI）采集性能，但受限于对单模态信息的依赖和部署挑战，特别是在数据集收集方面。本文研究了使用语义感知数字孪生（DT）来增强基于AI的CSI采集。我们首先简要介绍了AI驱动的CSI采集的动机和最新进展，以及语义感知DT在空口应用中的部署。然后，我们深入探讨了语义感知DT如何增强基于AI的CSI采集。我们将用于基于AI的CSI采集的语义感知DT分为两类：通过与DT集成增强基于AI的CSI采集，以及使用DT辅助基于AI的CSI部署。详细介绍了潜在的集成框架。最后，我们总结并概述了语义感知DT辅助基于AI的CSI采集中的潜在研究方向。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [81] [Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications](https://arxiv.org/abs/2506.21370)
> *低轨卫星通信中用于快速迭代MIMO检测的聚类感知两阶段方法*

*Jiuyu Liu, Yi Ma, Qihao Peng, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT**

**Keywords:** MIMO检测, 卫星通信, 聚类感知, 两阶段方法, 快速迭代

**Comment:** This work has been accepted by IEEE/CIC ICCC 2025

> **TL;DR:** 本文提出了一种用于低轨卫星通信的聚类感知两阶段MIMO检测方法，通过利用卫星MIMO信道的特性，显著提高了迭代检测器的收敛速度和效率，即使存在信道估计误差也能保持鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了一个两阶段的聚类感知方法，有效地利用了卫星MIMO信道的特定物理特性（同簇信道相关性），从而解决了传统迭代检测器收敛慢的问题。这种方法通过分解问题，将复杂的全局干扰消除转化为更易处理的簇内和簇间干扰消除，显著提升了计算效率和收敛速度，对下一代卫星通信系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在卫星MIMO通信中，同一地理簇内的用户由于物理接近，其信道特性高度相关，这通常会阻碍传统迭代MIMO检测器的收敛。因此，需要一种计算效率更高的方法来解决这一问题。

**Method:** 提出了一种聚类感知两阶段MIMO检测方法。第一阶段利用计算高效的小矩阵求逆消除簇内干扰；第二阶段利用这些预计算的矩阵来加速标准迭代MIMO检测器（如高斯-赛德尔和对称逐次超松弛），以有效消除簇间干扰。

**Result:** 在理想信道状态信息下，所提出的方法实现了超过12倍的收敛速度提升。即使考虑到信道估计误差，该方法仍能保持9倍的收敛速度提升。

**Conclusion:** 所提出的聚类感知两阶段MIMO检测方法在低轨卫星通信中表现出鲁棒性和有效性，适用于下一代卫星MIMO通信。

> **ai_Abstract:** 本文针对直通蜂窝卫星通信提出了一种聚类感知两阶段MIMO检测方法。该方法利用卫星MIMO信道中同簇用户信道相关性高的特点，通过先消除簇内干扰，再加速传统迭代检测器消除簇间干扰，显著提高了计算效率和收敛速度。仿真结果表明，该方法在理想和非理想信道条件下均能实现显著的收敛速度提升，展现了其在未来卫星MIMO通信中的潜力和鲁棒性。

> **摘要翻译:** 本文提出了一种用于直通蜂窝卫星通信的聚类感知两阶段多输入多输出（MIMO）检测方法。该方法通过利用卫星MIMO信道的独特特性实现了计算效率，即同一地理簇内的用户由于物理接近而表现出高度相关的信道特性，这通常会阻碍传统迭代MIMO检测器的收敛。所提出的方法采用两阶段策略，首先使用计算高效的小矩阵求逆消除簇内干扰，然后利用这些预计算的矩阵来加速标准迭代MIMO检测器（如高斯-赛德尔（GS）和对称逐次超松弛（SSOR）），以有效消除簇间干扰。计算机仿真结果表明，在理想信道状态信息下，所提出的方法实现了超过12倍的收敛速度提升。即使考虑到信道估计误差，该方法仍能保持9倍的收敛速度提升，这表明其对下一代卫星MIMO通信的鲁棒性和有效性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [12] [Post-Quantum and Blockchain-Based Attestation for Trusted FPGAs in B5G Networks](https://arxiv.org/abs/2506.21073)
> *B5G网络中基于后量子和区块链的可信FPGA认证*

*Ilias Papalamprou, Nikolaos Fotos, Nikolaos Chatzivasileiadis, Anna Angelogianni, Dimosthenis Masouros, Dimitrios Soudris* | **Category: cs.AR**

**Keywords:** 后量子密码, 区块链, FPGA, 远程认证, B5G网络

**Comment:** 

> **TL;DR:** 本文提出了一种结合后量子密码学和区块链的混合硬件-软件解决方案，用于安全配置FPGA并确保其在B5G网络中的可信性，相较于非PQC方法仅增加2%的开销。

**AI_Comments:** 该论文的创新点在于将后量子密码学与区块链技术结合起来，为B5G网络中的FPGA提供了一个全面的安全配置和认证机制，有效应对了量子计算带来的潜在威胁。其低开销的性能表现也增强了方案的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 5G及未来网络的发展需要高性能硬件如FPGA来部署服务。然而，FPGA常部署在非保护环境中，易受攻击。量子计算的兴起对现有密码算法构成威胁，因此急需健壮的安全基础设施来保护用户应用。

**Method:** 本文提出了一种混合硬件-软件解决方案，利用远程认证来安全配置FPGA，并集成了后量子密码（PQC）算法以增强安全性。此外，为确保整个边缘计算连续体的可信度，解决方案还集成了区块链基础设施，以安全存储任何安全证据。

**Result:** 在两种FPGA系列中，使用不同的PQC算法评估了所提出的安全配置过程，结果显示与非PQC方法相比，开销仅为2%。

**Conclusion:** 本文提出的基于后量子和区块链的混合硬件-软件方案能够为B5G网络中的可信FPGA提供安全配置，且性能开销极低，有效应对了未来网络的安全挑战。

> **ai_Abstract:** 本文提出了一种针对B5G网络中FPGA安全配置的混合硬件-软件解决方案。该方案通过远程认证技术，结合后量子密码算法增强安全性，并利用区块链基础设施确保安全证据的存储和整个边缘计算的可信度。实验结果表明，与非PQC方法相比，该方案的开销仅为2%。

> **摘要翻译:** 5G及未来网络的出现带来了性能更高的网络，促进了服务更靠近用户的部署。为了满足性能要求，这些服务需要专用硬件，例如现场可编程门阵列（FPGA）。然而，FPGA通常部署在不受保护的环境中，导致用户的应用程序容易受到多种攻击。随着量子计算的兴起，它威胁到广泛使用的密码算法的完整性，对健壮安全基础设施的需求变得更加关键。在本文中，我们引入了一种混合硬件-软件解决方案，利用远程认证来安全配置FPGA，同时集成了后量子密码（PQC）算法以增强安全性。此外，为了在整个边缘计算连续体中实现可信度，我们的解决方案集成了区块链基础设施，确保安全存储任何安全证据。我们在两种FPGA系列中，使用不同的PQC算法评估了所提出的安全配置过程，结果显示与非PQC方法相比，开销仅为2%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [28] [Accelerating GNN Training through Locality-aware Dropout and Merge](https://arxiv.org/abs/2506.21414)
> *通过局部性感知Dropout和合并加速GNN训练*

*Gongjian Sun, Mingyu Yan, Dengke Han, Runzhen Xue, Duo Wang, Xiaochun Ye, Dongrui Fan* | **Category: cs.AR**

**Keywords:** GNN训练, 数据局部性, 硬件加速, Dropout, 内存合并

**Comment:** under review in TPDS. extend version of DATE 2025

> **TL;DR:** LiGNN通过局部性感知的特征丢弃和内存访问合并来加速GNN训练，显著减少DRAM访问并提高性能。

**AI_Comments:** LiGNN的创新之处在于将数据局部性优化与GNN的Dropout机制结合，提出了硬件感知的特征丢弃，并结合DRAM行级合并策略，从硬件层面解决了GNN训练中的数据局部性瓶颈。这对于提高GNN在实际应用中的部署效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** GNN训练中不规则的邻居聚合导致低效的DRAM访问和数据局部性差，从而降低性能。现有加速器未能彻底解决DRAM不规则访问问题。

**Method:** 本文提出了LiGNN，一个基于硬件的解决方案，旨在通过在邻居聚合期间应用丢弃和合并技术来提高数据局部性，从而加速GNN训练。LiGNN引入了一种局部性感知特征丢弃机制，该机制在数据局部性感知下选择性地丢弃节点特征，以有效减少不规则DRAM访问，同时不影响模型精度。此外，LiGNN利用对内存布局和组织（包括关键对齐约束）的详细了解，在GNN级语义的指导下，在DRAM行级别战略性地合并邻居聚合期间的内存访问，以最小的额外成本显著改善数据局部性。

**Result:** 在普遍采用的0.5丢弃率下，LiGNN比现有最佳方法提速1.48~3.02倍，DRAM访问减少34%~55%，DRAM行激活降低59%~82%，同时保持了模型精度。

**Conclusion:** LiGNN通过其局部性感知丢弃和内存合并策略，显著提高了GNN训练效率和性能，有效解决了数据局部性差的问题，同时保持了模型准确性。

> **ai_Abstract:** 本文提出LiGNN，一种基于硬件的GNN训练加速方案，旨在解决不规则邻居聚合导致的数据局部性差和DRAM访问效率低的问题。LiGNN通过引入局部性感知特征丢弃机制，选择性地减少不规则DRAM访问，并在DRAM行级别战略性合并内存访问，从而显著提高数据局部性。实验结果表明，LiGNN在保持模型精度的同时，显著加速GNN训练并减少DRAM访问和行激活。

> **摘要翻译:** 图神经网络 (GNN) 在图学习中取得了显著成功，并被广泛应用于各种关键领域。然而，顶点之间不规则的连接导致低效的邻居聚合，从而产生大量不规则和粗粒度的DRAM访问。这种数据局部性的缺失给执行平台带来了巨大挑战，最终降低了性能。虽然之前的加速器设计利用了片上内存和数据访问调度策略来解决这个问题，但它们仍然不可避免地从DRAM访问不规则地址的特征。在这项工作中，我们提出了LiGNN，一种基于硬件的解决方案，通过在邻居聚合期间应用丢弃和合并技术来提高数据局部性，从而加速GNN训练。与主要旨在提高精度而忽视硬件成本的传统算法级丢弃方法不同，LiGNN引入了一种局部性感知特征丢弃机制。这种方法在数据局部性感知下选择性地丢弃节点特征，在不影响模型精度的情况下有效减少不规则DRAM访问。此外，通过利用对内存布局和组织（包括关键对齐约束）的详细了解，LiGNN在GNN级语义的指导下，在DRAM行级别战略性地合并邻居聚合期间的内存访问。这种优化以最小的额外成本显著提高了数据局部性。在普遍采用的0.5丢弃率下，LiGNN优于现有最佳方法，实现了1.48~3.02倍的加速，DRAM访问减少34%~55%，DRAM行激活降低59%~82%，同时保持了模型精度。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [52] [OptGM: An Optimized Gate Merging Method to Mitigate NBTI in Digital Circuits](https://arxiv.org/abs/2506.21487)
> *OptGM：一种优化门合并方法以减轻数字电路中的NBTI效应*

*Maryam Ghane, Amir M. Hajisadeghi, Hamid R. Zarandi* | **Category: cs.AR**

**Keywords:** NBTI, 门合并, 数字电路, 延迟退化, 性能功耗比

**Comment:** 

> **TL;DR:** OptGM是一种优化门合并方法，通过识别并消除NBTI关键节点，有效减轻数字电路中的NBTI效应，同时显著减少关键晶体管数量和延迟退化，并提升性能功耗比。

**AI_Comments:** 本文提出了一种新颖的门合并方法OptGM，通过针对性地消除NBTI关键节点来缓解数字电路的NBTI效应。其创新点在于结合了关键节点识别和优化的门合并算法，并在减少NBTI影响的同时实现了显著的性能提升和面积优化，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 数字电路中的负偏压温度不稳定性（NBTI）是一个重要的可靠性问题，会导致电路性能退化。本文旨在提出一种有效的方法来减轻NBTI效应。

**Method:** 本文提出了OptGM方法。首先，识别信号概率超过预设阈值的NBTI关键内部节点。其次，基于优化的算法，将驱动关键节点的敏感门和被其馈入的敏感门合并成一个新的复杂门，该复杂门在保留原始逻辑的同时消除了NBTI关键节点。最后，在多种组合和时序基准电路上评估OptGM的有效性。

**Result:** 仿真结果表明，OptGM平均减少了89.29%的NBTI关键晶体管（即连接到关键节点的PMOS晶体管），23.87%的NBTI引起的延迟退化，以及6.47%的总晶体管数量。此外，OptGM平均提升了12.8%的性能功耗比（PPC），且面积开销极小。

**Conclusion:** OptGM是一种有效的门合并方法，能够显著减轻数字电路中的NBTI效应，同时带来晶体管数量减少、延迟退化降低以及性能功耗比提升等多方面益处，且面积开销小。

> **ai_Abstract:** OptGM是一种优化的门合并方法，旨在减轻数字电路中的NBTI效应。该方法通过识别信号概率高的NBTI关键内部节点，并将驱动和被驱动这些关键节点的门合并为新的复杂门，从而在保持逻辑功能的同时消除关键节点。在基准电路上的评估显示，OptGM显著减少了NBTI关键晶体管数量（89.29%）、NBTI引起的延迟退化（23.87%）和总晶体管数量（6.47%），同时以最小的面积开销平均提升了12.8%的性能功耗比。

> **摘要翻译:** 本文提出了一种名为OptGM的优化门合并方法，旨在减轻数字电路中的负偏压温度不稳定性（NBTI）。首先，该方法有效地识别NBTI关键内部节点，这些节点被定义为信号概率超过预设阈值的节点。接下来，基于所提出的优化算法，驱动关键节点的敏感门和被其馈入的敏感门被合并成一个新的复杂门。这个复杂门在保留原始逻辑的同时消除了NBTI关键节点。最后，为了评估OptGM的有效性，我们在几个组合和时序基准电路上进行了评估。仿真结果表明，NBTI关键晶体管（即连接到关键节点的PMOS晶体管）、NBTI引起的延迟退化以及总晶体管数量平均分别减少了89.29%、23.87%和6.47%。此外，OptGM平均将性能功耗比（PPC）提高了12.8%，且面积开销极小。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [16] [ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data](https://arxiv.org/abs/2506.20673)
> *ClusterRCA：使用多模态数据进行HPC系统网络故障诊断*

*Yongqian Sun, Xijie Pan, Xiao Xiong, Lei Tao, Jiaju Wang, Shenglin Zhang, Yuan Yuan, Yuqi Li, Kunlin Jian* | **Category: cs.DC, cs.AI**

**Keywords:** HPC系统, 网络故障诊断, 多模态数据, 根本原因分析, 图算法

**Comment:** 

> **TL;DR:** ClusterRCA是一个用于HPC系统网络故障诊断的新框架，它利用多模态数据，结合分类器和图方法，以高精度定位故障节点并确定故障类型。

**AI_Comments:** ClusterRCA的创新之处在于其专门针对HPC系统中的多模态数据异构性问题，并结合了分类器和图方法进行故障诊断。这种结合使得它能够更准确地定位根本原因。其重要性体现在解决了HPC系统网络故障诊断的痛点，提高了诊断精度和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 网络故障诊断对于高性能计算（HPC）系统来说具有挑战性但至关重要。现有方法由于数据异构性和缺乏准确性，无法直接应用于HPC场景。

**Method:** 本文提出了一个名为ClusterRCA的新颖框架。它通过从拓扑连接的网络接口控制器（NIC）对中提取特征来分析HPC系统中的多样化多模态数据。为了准确地定位罪魁祸首节点并确定故障类型，ClusterRCA结合了基于分类器和基于图的方法。它根据状态分类器的输出构建一个故障图，然后在该图上执行定制的随机游走以定位根本原因。

**Result:** 在由顶级全球HPC设备供应商收集的数据集上进行的实验表明，ClusterRCA在诊断HPC系统网络故障方面实现了高精度。ClusterRCA在不同的应用场景中也保持了稳健的性能。

**Conclusion:** ClusterRCA是一种有效且准确的网络故障诊断框架，专门为HPC系统设计，能够处理多模态数据并保持在不同场景下的鲁棒性。

> **ai_Abstract:** ClusterRCA是一个专门为高性能计算（HPC）系统设计的网络故障诊断框架。针对现有方法在HPC场景中因数据异构性和准确性不足而无法直接应用的问题，ClusterRCA利用多模态数据，通过从网络接口控制器（NIC）对中提取特征，并结合基于分类器和基于图的方法来定位故障节点并确定故障类型。实验证明，该框架在诊断HPC系统网络故障方面具有高精度，并在不同应用场景下表现出稳健的性能。

> **摘要翻译:** 网络故障诊断对于高性能计算（HPC）系统来说具有挑战性但至关重要。现有方法由于数据异构性和缺乏准确性，无法直接应用于HPC场景。本文提出了一个名为ClusterRCA的新颖框架，通过利用多模态数据来定位罪魁祸首节点并确定故障类型。ClusterRCA从拓扑连接的网络接口控制器（NIC）对中提取特征，以分析HPC系统中多样化的多模态数据。为了准确地定位罪魁祸首节点并确定故障类型，ClusterRCA结合了基于分类器和基于图的方法。它根据状态分类器的输出构建一个故障图，然后在该图上执行定制的随机游走以定位根本原因。在由顶级全球HPC设备供应商收集的数据集上进行的实验表明，ClusterRCA在诊断HPC系统网络故障方面实现了高精度。ClusterRCA在不同的应用场景中也保持了稳健的性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [31] [Scalable GPU Performance Variability Analysis framework](https://arxiv.org/abs/2506.20674)
> *可扩展GPU性能变异性分析框架*

*Ankur Lahiry, Ayush Pokharel, Seth Ockerman, Amal Gueroudji, Line Pouchard, Tanzima Z. Islam* | **Category: cs.DC, cs.PF**

**Keywords:** GPU性能分析, 分布式框架, 性能变异性, 高性能计算, Nsight Compute

**Comment:** 

> **TL;DR:** 现有GPU性能分析慢且耗内存。本文提出一个分布式框架，通过数据分片并发处理，减少内存并避免瓶颈，实现对大规模HPC/AI跟踪数据的快速分析。

**AI_Comments:** 该论文的创新点在于提出了一个分布式、可扩展的GPU性能分析框架，通过数据分片和并发处理解决了传统工具在处理大规模高性能计算（HPC）和AI工作负载时面临的内存和时间瓶颈。这对于加速性能诊断和集成分析到自动化流程中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分析大规模GPU性能日志需要数TB内存和数小时运行时间，阻碍及时洞察和自动化集成。现有分析工具顺序处理数据，不适用于日益增长的HPC跟踪复杂性和数据量。

**Method:** 引入一个分布式数据分析框架，该框架将数据集划分为可独立分析的分片，并跨MPI等级并发处理。此设计旨在减少每节点内存压力并避免中心瓶颈。

**Result:** 将该框架应用于实际HPC和AI工作负载的Nsight Compute跟踪，展示了其诊断性能变异性的能力，并揭示了内存传输延迟对GPU内核行为的影响。

**Conclusion:** 该分布式框架有效解决了大规模GPU性能分析的挑战，能够更快地诊断性能变异性并深入理解GPU行为。

> **ai_Abstract:** 本文提出一个可扩展的分布式数据分析框架，旨在解决现有GPU性能日志分析工具在处理大规模数据时面临的内存和时间限制。该框架通过将数据集划分为独立的分片并进行并发处理，有效降低了内存压力并消除了中心瓶颈，从而实现了对高维跟踪数据的低延迟探索。实验证明，该框架能够诊断实际HPC和AI工作负载中的性能变异性，并揭示内存传输延迟对GPU内核行为的影响。

> **摘要翻译:** 分析来自GPU性能分析器的大规模性能日志通常需要数TB的内存和数小时的运行时间，即使是进行基本的汇总。这些限制阻碍了及时洞察，并妨碍了性能分析集成到自动化工作流程中。现有的分析工具通常按顺序处理数据，这使得它们不适合处理日益增长的跟踪复杂性和数据量的HPC工作流程。我们引入了一个分布式数据分析框架，该框架可以随数据集大小和计算可用性进行扩展。我们的系统不是将数据集视为一个单一实体，而是将其划分为可独立分析的分片，并跨MPI等级并发处理它们。这种设计减少了每节点内存压力，避免了中心瓶颈，并实现了高维跟踪数据的低延迟探索。我们将该框架应用于来自实际HPC和AI工作负载的端到端Nsight Compute跟踪，展示了其诊断性能变异性的能力，并揭示了内存传输延迟对GPU内核行为的影响。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [55] [Utility-Driven Speculative Decoding for Mixture-of-Experts](https://arxiv.org/abs/2506.20675)
> *效用驱动的专家混合模型推测解码*

*Anish Saxena, Po-An Tsai, Hritvik Taneja, Aamer Jaleel, Moinuddin Qureshi* | **Category: cs.DC, cs.AI, cs.LG**

**Keywords:** 推测解码, 专家混合模型, LLM推理, 效用驱动, 动态调整

**Comment:** 

> **TL;DR:** 推测解码在MoE模型中效率低下并可能导致减速。本文提出了Cascade框架，通过动态调整和选择性启用推测解码来使其在MoE模型中实用化，显著提高了吞吐量并避免了减速。

**AI_Comments:** 这篇论文的创新点在于提出了一个实用的框架Cascade，解决了推测解码在专家混合（MoE）模型中遇到的核心挑战。以往，推测解码在MoE模型中因其特有的稀疏激活模式而导致性能下降，使其难以应用。Cascade通过引入“推测效用”这一动态指标，并结合测试/设置阶段的自适应策略，有效地规避了减速风险并优化了K值选择，从而显著提高了MoE模型的推理效率。这一工作的重要性在于，它使得一种在密集型LLM中行之有效的优化技术得以推广到新兴且高效的MoE架构中，为未来LLM的低延迟推理提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** GPU内存带宽是LLM推理的瓶颈。推测解码通过使用轻量级草稿器提出K个token并由LLM并行验证来提高token吞吐量。然而，研究发现推测解码对新兴的专家混合（MoE）模型无效，因为它导致数据移动和验证时间增加2-3倍，甚至可能导致高达1.5倍的减速。这使得推测解码在MoE模型中不实用，即使有用，最佳K值也因任务、模型和请求而异。因此，需要一种方法来解决推测解码在MoE模型中的局限性。

**Method:** 本文提出了Cascade，一个效用驱动的框架，用于选择性地启用推测解码以避免减速，并动态调整K值以加速MoE服务。Cascade使用一个轻量级指标——推测效用（token收益与验证成本之比），该指标显示出迭代级别的局部性，从而可以通过短测试阶段和长设置阶段进行周期性决策。对于每个请求，如果效用在测试期间低于1，Cascade会禁用推测解码；如果效用超过1，则测试多个K值以选择在设置阶段最大化效用的K值。该框架在vLLM中实现，并在五种流行的MoE模型上进行了评估。

**Result:** Cascade框架将推测解码导致的减速限制在5%以内（相比于无Cascade时的1.5倍减速），并且比静态K值方法提高了7-14%的吞吐量。

**Conclusion:** Cascade框架使得推测解码在专家混合（MoE）模型中变得实用，显著解决了其在MoE模型中因增加数据移动和验证时间而导致的效率低下和减速问题。

> **ai_Abstract:** 该论文解决了推测解码在专家混合（MoE）模型中效率低下且可能导致性能下降的问题。尽管推测解码在密集型LLM中能有效提高吞吐量，但对于MoE模型，它会显著增加数据移动和验证时间，导致高达1.5倍的减速。为解决此问题，作者提出了Cascade框架，该框架通过引入“推测效用”指标，能够选择性地启用推测解码并在运行时动态调整K值。Cascade在测试阶段评估效用，若效用低则禁用推测，若效用高则选择最佳K值。实验结果表明，Cascade成功将推测解码导致的减速限制在5%以内，并相对静态K值方法提高了7-14%的吞吐量，从而使推测解码在MoE模型中变得实用。

> **摘要翻译:** GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。推测解码利用空闲的GPU计算能力，通过使用轻量级草稿器提出K个token，然后由LLM并行验证，从而提高token吞吐量。在传统的密集型LLM中，每次迭代都会获取所有模型权重，因此推测解码不会增加延迟开销。新兴的专家混合（MoE）模型每个token只激活一部分权重，大大减少了数据移动。然而，我们发现推测解码对MoE模型无效：草稿token会共同激活更多的权重，使数据移动和验证时间增加2-3倍。当token吞吐量增益无法抵消这一开销时，推测解码会导致高达1.5倍的减速，使其不可行。即使有用，最佳K值也因任务、模型，甚至请求和迭代而异。因此，尽管在密集型LLM中广泛使用，推测解码在领先的MoE模型中仍然不实用。
我们提出了Cascade，一个效用驱动的框架，它选择性地启用推测解码以避免减速，并动态调整K值以加速MoE服务。Cascade使用一个轻量级指标——推测效用，即token收益与验证成本之比，该指标显示出迭代级别的局部性，从而可以通过短测试阶段和长设置阶段进行周期性决策。对于每个请求，如果效用在测试期间低于1，Cascade会禁用推测解码；当效用超过1时，它会测试多个K值以选择在设置阶段最大化效用的K值。我们在vLLM中实现了Cascade，并在五种流行的MoE模型上进行了评估，工作负载涵盖代码、数学、提取和混合任务。Cascade将减速限制在5%以内（相比于1.5倍），并比静态K值方法提高了7-14%的吞吐量，使得推测解码在MoE模型中变得实用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [78] [ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks](https://arxiv.org/abs/2506.20938)
> *ParEval-Repo：一个用于评估LLM在仓库级HPC翻译任务中表现的基准测试套件*

*Joshua H. Davis, Daniel Nichols, Ishan Khillan, Abhinav Bhatele* | **Category: cs.DC**

**Keywords:** LLM, 代码翻译, GPGPU, 基准测试, HPC

**Comment:** 11 pages, 5 figures

> **TL;DR:** 提出了ParEval-Repo，一个基准测试套件，用于评估LLM在GPGPU代码库翻译任务中的能力，发现LLM对小程序可行，但大型代码库面临构建系统和跨文件依赖挑战。

**AI_Comments:** 本文提出了一个及时且重要的基准测试套件ParEval-Repo，解决了GPGPU架构多样化带来的代码移植挑战，并探索了LLM在此领域的应用潜力。其创新点在于专注于仓库级别的代码翻译，并评估了LLM在处理跨文件依赖和构建系统方面的能力。研究结果指出了LLM在代码翻译领域的局限性，特别是在处理大型复杂项目时的挑战，这为未来研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，GPGPU架构日益多样化，导致了多种专用编程模型和软件栈的出现。尽管存在可移植的执行模型，但将代码移植并优化到不同硬件架构仍需大量的开发人员工作。大型语言模型（LLMs）的最新进展有望减轻这种编程负担。

**Method:** 本文提出了一个名为ParEval-Repo的新型基准测试和测试框架，用于评估基于LLM的方法在自动翻译GPGPU执行模型间整个代码库的效率。ParEval-Repo包含多个科学计算和AI小型应用程序，涵盖多种编程模型和仓库复杂性。作者使用ParEval-Repo评估了一系列最先进的开源和商业LLM，采用了非代理和自上而下的代理方法。评估指标包括代码的可编译性、功能正确性、构建错误的类别以及翻译成本（推理token数量）。

**Result:** 结果表明，LLM翻译科学应用程序对于小型程序是可行的，但生成功能性构建系统和处理跨文件依赖的困难对扩展到更大的代码库构成了挑战。

**Conclusion:** LLM在GPGPU代码库翻译方面对于小型程序具有潜力，但在处理复杂构建系统和跨文件依赖时，其有效性在大规模应用中受到限制。

> **ai_Abstract:** 本文介绍了ParEval-Repo，一个新颖的基准测试套件和框架，旨在评估大型语言模型（LLMs）在自动将整个代码库从一种GPGPU执行模型翻译到另一种执行模型方面的能力。ParEval-Repo包含多种科学计算和AI小型应用程序，涵盖不同编程模型和仓库复杂性。研究评估了多种LLM，并根据可编译性、功能正确性、构建错误和推理成本进行衡量。结果显示LLM对小型程序的代码翻译可行，但在处理复杂构建系统和跨文件依赖时，扩展到大型代码库面临挑战。

> **摘要翻译:** 近年来，GPGPU架构变得异常多样化，这导致了各种专用编程模型和软件栈的出现以支持它们。尽管存在可移植的执行模型，但它们仍然需要开发人员付出大量努力才能移植到不同的硬件架构并进行优化。大型语言模型（LLMs）的最新进展可以帮助我们减轻部分编程负担。在本文中，我们提出了一个新颖的基准测试和测试框架ParEval-Repo，它可以用于评估基于LLM的方法在GPGPU执行模型之间自动翻译整个代码库的效率。ParEval-Repo包含多个科学计算和AI小型应用程序，涵盖了多种编程模型和仓库复杂性级别。我们使用ParEval-Repo评估了一系列最先进的开源和商业LLM，采用了非代理和自上而下的代理方法。我们根据可编译性、功能正确性、构建错误的类别以及翻译成本（推理token数量）来评估LLM和方法生成的代码。我们的结果表明，LLM翻译科学应用程序对于小型程序是可行的，但生成功能性构建系统和处理跨文件依赖的困难对扩展到更大的代码库构成了挑战。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [101] [Portable High-Performance Kernel Generation for a Computational Fluid Dynamics Code with DaCe](https://arxiv.org/abs/2506.20994)
> *使用 DaCe 为计算流体动力学代码生成可移植高性能核*

*Måns I. Andersson, Martin Karp, Niclas Jansson, Stefano Markidis* | **Category: cs.DC, cs.PF**

**Keywords:** DaCe, HPC, 自动代码生成, CFD, 可移植性

**Comment:** 

> **TL;DR:** 为了应对高性能计算（HPC）硬件多样性带来的挑战，本研究利用数据中心并行编程框架 DaCe 自动生成高性能内核。通过将 DaCe 应用于计算流体动力学（CFD）代码 Neko，证明了生成代码在不同 GPU 平台上的可移植性和竞争力，从而提高了大规模科学应用的长期可持续性。

**AI_Comments:** 该论文通过利用 DaCe 框架解决高性能计算领域中日益增长的硬件多样性问题，具有重要的创新性。它提供了一种自动生成可移植高性能内核的解决方案，从而显著减轻了开发者为不同架构重写代码的负担。这种方法对于提高大规模科学应用的可持续性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着新的高性能计算（HPC）加速器（如 Nvidia 和 AMD GPU）的出现，有效针对多样化硬件架构已成为 HPC 应用程序开发者的主要挑战。HPC 系统中不断增长的硬件多样性通常需要开发特定于架构的代码，这阻碍了大规模科学应用的可持续性。

**Method:** 本研究利用 DaCe 这一数据中心并行编程框架来自动化高性能内核的生成。DaCe 能够为多核处理器和各种加速器自动生成代码，从而减轻了开发者为每个新架构重写代码的负担。具体而言，研究将 DaCe 的自动代码生成应用于计算流体动力学（CFD）中使用的关键计算内核（Neko，一个基于 Fortran 的谱元法求解器，依赖于小型张量操作）。研究详细阐述了使用 DaCe 的有状态数据流多图（SDFG）表示来制定此计算内核，并讨论了这种方法如何促进高性能代码生成。此外，还概述了将 DaCe 生成的代码无缝集成到 Neko 求解器中的工作流程。

**Result:** 结果突出显示了所生成代码在多个平台（包括 Nvidia GH200、Nvidia A100 和 AMD MI250X GPU）上的可移植性和性能，并取得了有竞争力的性能结果。

**Conclusion:** 通过展示自动代码生成的潜力，本研究强调了使用可移植解决方案确保大规模科学应用长期可持续性的可行性。

> **ai_Abstract:** 本研究旨在解决高性能计算（HPC）领域中由于硬件多样性导致的应用程序可持续性挑战。为此，论文引入了 DaCe，一个数据中心并行编程框架，用于自动化高性能内核的生成。研究将 DaCe 应用于一个关键的计算流体动力学（CFD）内核（Neko 求解器），详细说明了使用 DaCe 的有状态数据流多图（SDFG）表示进行代码生成和集成的工作流程。实验结果表明，DaCe 生成的代码在 Nvidia GH200、Nvidia A100 和 AMD MI250X 等多种 GPU 平台上均表现出良好的可移植性和竞争力，证明了自动代码生成对于确保大规模科学应用长期可持续性的潜力。

> **摘要翻译:** 随着新的高性能计算（HPC）加速器（如 Nvidia 和 AMD GPU）的出现，有效针对多样化硬件架构已成为 HPC 应用程序开发者的主要挑战。HPC 系统中不断增长的硬件多样性通常需要开发特定于架构的代码，这阻碍了大规模科学应用的可持续性。在这项工作中，我们利用数据中心并行编程框架 DaCe 来自动化高性能内核的生成。DaCe 能够为多核处理器和各种加速器自动生成代码，从而减轻了开发者为每个新架构重写代码的负担。我们的研究通过将 DaCe 的自动代码生成应用于计算流体动力学（CFD）中使用的关键计算内核，展示了 DaCe 的能力。具体而言，我们专注于 Neko，一个基于 Fortran 的求解器，它采用谱元法，该方法依赖于小型张量操作。我们详细阐述了使用 DaCe 的有状态数据流多图（SDFG）表示来制定此计算内核，并讨论了这种方法如何促进高性能代码生成。此外，我们概述了将 DaCe 生成的代码无缝集成到 Neko 求解器中的工作流程。我们的结果突出显示了所生成代码在多个平台（包括 Nvidia GH200、Nvidia A100 和 AMD MI250X GPU）上的可移植性和性能，并取得了有竞争力的性能结果。通过展示自动代码生成的潜力，我们强调了使用可移植解决方案确保大规模科学应用长期可持续性的可行性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [122] [BLOCKS: Blockchain-supported Cross-Silo Knowledge Sharing for Efficient LLM Services](https://arxiv.org/abs/2506.21033)
> *BLOCKS：区块链支持的跨孤岛知识共享，实现高效LLM服务*

*Zhaojiacheng Zhou, Hongze Liu, Shijing Yuan, Hanning Zhang, Jiong Lou, Chentao Wu, Jie Li* | **Category: cs.DC**

**Keywords:** 区块链, 知识共享, 大型语言模型, 幻觉问题, 知识孤岛

**Comment:** 

> **TL;DR:** 提出一个基于区块链的框架BLOCKS，解决LLM幻觉问题，通过协调分散的知识孤岛，安全高效地为LLM提供外部知识。

**AI_Comments:** 该论文创新性地将区块链技术应用于解决LLM的幻觉问题，通过构建去中心化的知识共享机制，有效克服了传统中心化方案在隐私和安全方面的障碍。其提出的信誉机制和交叉验证确保了知识的可靠性，而API接口则提升了LLM获取外部知识的便捷性。该框架为未来LLM的知识增强提供了一个有前景的方向，特别是在涉及敏感数据和多方协作的场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）存在幻觉问题，外部知识增强是解决方案。然而，由于隐私和安全问题，大量下游任务相关知识分散在各种“孤岛”中，难以访问。

**Method:** 提出一个区块链外部知识框架，BLOCKS。该框架将本地数据中的知识提炼成提示，并在区块链上执行交易和记录。此外，引入信誉机制和交叉验证以确保知识质量并激励参与，并设计了一个查询生成框架提供直接API接口用于大型模型检索。

**Result:** 实验结果表明，所提出的框架在区块链环境中实现了高效的LLM服务知识共享。

**Conclusion:** 该论文成功提出了一个基于区块链的框架BLOCKS，有效地解决了LLM的幻觉问题，通过安全、高效地协调分散的知识孤岛，为LLM提供了可靠的外部知识。

> **ai_Abstract:** 本文提出了BLOCKS，一个基于区块链的外部知识框架，旨在解决大型语言模型（LLM）的幻觉问题。针对现有知识因隐私和安全顾虑而分散在不同“孤岛”的挑战，BLOCKS通过在区块链上记录提炼的知识提示、引入信誉机制和交叉验证以保证知识质量，并提供API接口实现LLM的知识检索。实验证明，该框架能有效促进区块链环境下LLM服务的高效知识共享。

> **摘要翻译:** 大型语言模型（LLM）的幻觉问题日益受到关注。用外部知识增强LLM是解决此问题的一个有前景的方案。然而，由于隐私和安全问题，大量与下游任务相关的知识分散并孤立在各种“孤岛”中，难以访问。为了弥合这一知识鸿沟，我们提出了一个基于区块链的外部知识框架，该框架协调多个知识孤岛，为大型模型检索提供可靠的基础知识，同时确保数据安全。技术上，我们将本地数据中的知识提炼成提示，并在区块链上执行交易和记录。此外，我们引入了信誉机制和交叉验证，以确保知识质量并激励参与。再者，我们设计了一个查询生成框架，为大型模型检索提供直接的API接口。为了评估我们所提出框架的性能，我们对各种知识源进行了广泛的实验。结果表明，所提出的框架在区块链环境中实现了高效的LLM服务知识共享。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [141] [Bridding OT and PaaS in Edge-to-Cloud Continuum](https://arxiv.org/abs/2506.21072)
> *在边缘到云连续体中连接OT和PaaS*

*Carlos J Barrios, Yves Denneulin* | **Category: cs.DC, cs.PF**

**Keywords:** 运营技术, 平台即服务, 边缘计算, 云计算, 工业转型

**Comment:** 

> **TL;DR:** 运营技术平台即服务（OTPaaS）提供了一个用于高效数据管理和存储的框架，旨在改善工业环境中的安全性、可靠性、数据主权和能源效率，适用于边缘到云的连续体。

**AI_Comments:** 该论文创新性地将OT（运营技术）与PaaS（平台即服务）结合，创建了OTPaaS，解决了工业转型中，特别是在边缘到云连续体的数据主权和效率方面，关键的需求。其重要性在于为管理复杂的工业数据环境提供了一种结构化的方法。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是提供一个结构化的框架（OTPaaS），用于高效的数据管理和存储，以确保卓越的响应时间，并提高安全性、可靠性、数据和技术主权、鲁棒性以及能源效率，这些对于工业转型和数据主权至关重要。

**Method:** 本文阐述了OTPaaS的成功部署、适应性强的应用程序管理以及满足边缘和云环境的各种集成组件。它利用了平台即服务模型的优势，并强调了针对特定用例已解决的关键挑战。

**Result:** 文中阐述了成功的部署、适应性强的应用程序管理以及满足边缘和云环境的各种集成组件。针对特定用例的关键挑战已得到解决。

**Conclusion:** OTPaaS有效地连接了OT和PaaS，提供了一个结构化框架，可增强边缘到云连续体中的数据管理、安全性与效率，从而推动工业转型。

> **ai_Abstract:** 本文介绍了运营技术平台即服务（OTPaaS）倡议，这是一个旨在工业环境中高效管理和存储数据的结构化框架。OTPaaS旨在提高安全性、可靠性、数据主权、鲁棒性和能源效率，这些对于工业转型至关重要。该论文展示了其在边缘和云环境中的成功部署、适应性强的应用程序管理和集成组件，并强调了其如何利用PaaS模型来解决特定挑战。

> **摘要翻译:** 运营技术平台即服务（OTPaaS）倡议提供了一个用于高效管理和存储数据的结构化框架。它确保了卓越的响应时间，同时提高了安全性、可靠性、数据和技术主权、鲁棒性和能源效率，这些对于工业转型和数据主权至关重要。本文阐述了成功的部署、适应性强的应用程序管理以及满足边缘和云环境的各种集成组件。它利用了平台即服务模型的优势，并强调了针对特定用例已解决的关键挑战。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [159] [Enabling Bitcoin Smart Contracts on the Internet Computer](https://arxiv.org/abs/2506.21327)
> *在互联网计算机上实现比特币智能合约*

*Ryan Croote, Islam El-Ashi, Thomas Locher, Yvonne-Anne Pignolet* | **Category: cs.DC**

**Keywords:** 比特币智能合约, 互联网计算机, 无桥接集成, 去中心化应用, 图灵完备

**Comment:** Published at ICDCS 2025, waiting for DOI

> **TL;DR:** 该研究提出了一种在互联网计算机（IC）上直接执行图灵完备比特币智能合约的新架构，无需桥接，实现快速低成本的比特币DApp。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需桥接机制就能在互联网计算机上直接执行比特币智能合约的架构，有效解决了传统桥接方案带来的安全隐患。通过直接节点交互和对概率性与最终性问题的协调，该方案显著提升了比特币可编程性和其在去中心化应用中的实用性，降低了复杂应用的开发门槛和成本。

<details>
  <summary>Details</summary>

**Motivation:** 比特币本身的可编程性有限，但人们对其锁定的价值进行编程访问的兴趣日益增长。现有的方法大多是在比特币上构建新功能或通过桥接机制使用“包装”比特币，但这些方法存在局限性或安全风险。

**Method:** 论文提出了一种新架构，允许在互联网计算机（IC）上直接执行图灵完备的比特币智能合约。该架构通过IC和比特币节点之间的直接交互，而非使用桥接机制，从而消除了桥接带来的潜在安全风险。它还引入了新概念来协调比特币的概率性与IC上最终状态变化的不可逆性。

**Result:** 基于主网上的比特币集成测量评估结果显示，该集成能在几秒内完成最终确认，且执行成本低。

**Conclusion:** 这种集成使得以前在实践中不可行或经济上不可行的复杂比特币去中心化应用程序成为可能。

> **ai_Abstract:** 本文提出了一种在互联网计算机（IC）上实现图灵完备比特币智能合约的新颖架构。与现有依赖桥接或在比特币上构建新功能的方法不同，该架构通过IC和比特币节点直接交互，旨在消除桥接带来的安全风险。它还解决了比特币概率性与IC状态最终性之间的协调问题。评估结果表明，该集成具有快速最终确认和低成本的特点，为开发此前难以实现或不经济的复杂比特币去中心化应用提供了可能。

> **摘要翻译:** 比特币本身的可编程性有限，但人们对通过编程访问其锁定价值的兴趣日益增长。近年来提出了各种方法，其中绝大多数提出的机制要么在比特币之上构建新功能，要么利用桥接机制在完全不同的平台上启用使用“包装”比特币的智能合约。
在这项工作中，提出了一种采用不同方法的架构。该架构使得图灵完备的比特币智能合约能够在互联网计算机（IC）上执行，互联网计算机是一个用于托管和执行去中心化应用程序的区块链平台。IC和比特币节点直接交互，而不是使用桥接，从而消除了使用桥接可能带来的安全风险。这种集成需要新颖的概念，特别是为了协调比特币的概率性与IC上最终状态变化的不可逆性，这可能具有独立的意义。
除了介绍架构外，我们还提供了基于主网上运行的比特币集成测量结果的评估。评估结果表明，通过几秒钟内的最终确认和低执行成本，这种集成使得以前在实践中不可行或经济上不可行的复杂比特币去中心化应用程序成为可能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [177] [Carbon-Aware Microservice Deployment for Optimal User Experience on a Budget](https://arxiv.org/abs/2506.21422)
> *碳感知微服务部署，以在预算内实现最佳用户体验*

*Kevin Kreutz, Philipp Wiesner, Monica Vitali* | **Category: cs.DC**

**Keywords:** 碳感知, 微服务, 部署, 用户体验, 碳预算

**Comment:** LOCO 2024, December 3, 2024, Glasgow/Online

> **TL;DR:** 针对数据中心碳足迹问题，本文提出一种碳感知的微服务部署方法，通过选择合适的版本和水平扩展，在碳预算内最大化用户体验和收益，并能适应工作负载变化。

**AI_Comments:** 这篇论文的创新点在于将碳感知策略从传统的批处理领域扩展到了服务导向型微服务应用，解决了现有方法不适用于实时、低延迟服务的问题。其重要性在于提供了一种在环保约束下优化云服务性能和经济效益的实际解决方案。通过考虑微服务的版本选择和水平扩展，它提供了一个更细粒度的控制机制，以平衡碳足迹、用户体验和运营成本。

<details>
  <summary>Details</summary>

**Motivation:** 数据中心的碳足迹日益成为关键问题。现有的碳感知策略主要关注批处理，通过调整工作负载执行的时间和地点来利用调度灵活性，但这些方法不适用于需要始终可达且低延迟的服务导向型云应用。

**Method:** 提出一种在每小时碳预算下运行微服务的碳感知方法。通过为每个微服务选择最合适的版本和水平扩展，该策略在遵守预算限制的同时最大化用户体验和收益。

**Result:** 跨各种应用配置和碳预算进行的实验表明，该方法能够很好地适应不断变化的工作负载和碳强度。

**Conclusion:** 本文提出的碳感知微服务部署方法，通过智能选择微服务版本和扩展规模，在严格的碳预算下成功优化了用户体验和收益，并表现出对动态环境的良好适应性。

> **ai_Abstract:** 鉴于数据中心日益增长的碳足迹问题以及现有碳感知策略不适用于服务导向型应用的局限性，本文提出了一种新颖的碳感知微服务部署方法。该方法在每小时碳预算内运行微服务，通过智能选择微服务的版本和水平扩展，旨在最大化用户体验和收入。实验证明，该方法能有效适应动态的工作负载和碳强度变化。

> **摘要翻译:** 数据中心的碳足迹最近已成为一个关键问题。迄今为止，大多数碳感知策略都侧重于利用调度决策的灵活性，通过改变工作负载执行的时间和位置来进行批处理。然而，此类方法无法应用于面向服务的云应用程序，因为它们必须在任何时间点都可达，并且通常需要低延迟。我们提出了一种碳感知方法，用于在每小时碳预算下运行微服务。通过为每个微服务选择最合适的版本和水平扩展，我们的策略在保持预算限制的同时最大化用户体验和收益。跨各种应用程序配置和碳预算进行的实验表明，该方法能够很好地适应不断变化的工作负载和碳强度。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [193] [exa-AMD: A Scalable Workflow for Accelerating AI-Assisted Materials Discovery and Design](https://arxiv.org/abs/2506.21449)
> *exa-AMD：一个加速AI辅助材料发现与设计的可扩展工作流*

*Maxim Moraru, Weiyi Xia, Zhuo Ye, Feng Zhang, Yongxin Yao, Ying Wai Li, Cai-Zhuang Wang* | **Category: cs.DC**

**Keywords:** 材料发现, AI/ML, 可扩展工作流, Parsl, 量子力学计算

**Comment:** We intend to publish the paper to the Journal of Open Source Software

> **TL;DR:** exa-AMD是一个基于Python的应用，利用Parsl库集成AI/ML、材料数据库和量子力学计算，创建可扩展的工作流，加速材料发现与设计，并实现工作流逻辑与执行配置的分离，方便研究人员在不同计算资源上扩展。

**AI_Comments:** 该论文介绍的exa-AMD在AI辅助材料发现领域具有重要意义，其创新点在于利用Parsl库实现了工作流的解耦和高度可扩展性。这意味着研究人员可以更高效地利用不同计算资源进行材料研究，大大降低了在多平台部署和扩展工作流的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在加速功能材料的发现与设计。

**Method:** exa-AMD是一个基于Python的应用，通过集成AI/ML工具、材料数据库和量子力学计算来构建可扩展、高性能的工作流。其执行模型依赖于Parsl（一个任务并行编程库），Parsl使得工作流逻辑与执行配置解耦，从而实现了在从笔记本电脑到超级计算机的任何计算资源上的灵活执行。

**Result:** exa-AMD能够将工作流逻辑与执行配置解耦，使得研究人员无需为每个系统重新实现工作流即可对其进行扩展。

**Conclusion:** exa-AMD使研究人员能够轻松地在各种计算资源上扩展其材料发现与设计工作流。

> **ai_Abstract:** exa-AMD是一个利用Python和Parsl库开发的应用程序，它集成了AI/ML、材料数据库和量子力学计算，以创建一个可扩展、高性能的工作流。该工作流旨在加速功能材料的发现与设计。通过Parsl，exa-AMD实现了工作流逻辑与执行配置的解耦，使得研究人员能够在各种计算资源上灵活且便捷地扩展其材料发现工作流，而无需进行重复的实现工作。

> **摘要翻译:** exa-AMD是一个基于Python的应用程序，旨在通过将AI/ML工具、材料数据库和量子力学计算集成到可扩展、高性能的工作流中，从而加速功能材料的发现和设计。exa-AMD的执行模型依赖于Parsl，这是一个任务并行编程库，它可以在从笔记本电脑到超级计算机的任何计算资源上实现任务的灵活执行。通过使用Parsl，exa-AMD能够将工作流逻辑与执行配置解耦，从而使研究人员能够在不为每个系统重新实现工作流的情况下扩展其工作流。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [205] [Efficient and Reuseable Cloud Configuration Search Using Discovery Spaces](https://arxiv.org/abs/2506.21467)
> *高效可复用的基于发现空间的云配置搜索*

*Michael Johnston, Burkhard Ringlein, Christoph Hagleitner, Alessandro Pomponio, Vassilis Vassiliadis, Christian Pinto, Srikumar Venugopal* | **Category: cs.DC, C.4**

**Keywords:** 云配置, 发现空间, 优化, 知识复用, 大规模搜索

**Comment:** 

> **TL;DR:** 提出“发现空间”抽象，解决大规模云资源配置优化问题，实现高效数据共享和知识复用，显著加速搜索过程。

**AI_Comments:** 这项工作通过引入“发现空间”这一抽象概念，为解决复杂的云资源配置优化问题提供了一个新颖且高效的框架。其创新点在于将配置问题形式化，并支持数据共享和知识复用，从而显著提升了搜索效率。特别是90%以上的速度提升，突显了其实用价值和潜在影响。该方法在通用性方面的展示也增加了其适用范围。

<details>
  <summary>Details</summary>

**Motivation:** 在满足服务水平协议的前提下，以最低成本为给定工作负载寻找最优云资源配置是一个活跃的研究领域。由于云提供商和应用参数众多，配置空间巨大，包含数百万种部署选项，使得这一任务复杂且具有挑战性。

**Method:** 提出“发现空间”抽象，形式化描述工作负载配置问题，并具备结构化、健壮和分布式调查大型搜索空间所需的特性。同时描述了其具体实现，并展示了其在大型语言模型推理和大数据分析等多样化工作负载上的通用性。

**Result:** 该方法实现了在最优配置检测中，最佳优化器执行之间安全、透明的数据共享，提高了效率。此外，发现空间使知识在相似搜索空间之间进行转移和复用，将配置搜索速度提升了90%以上。

**Conclusion:** 发现空间抽象及其实现能够有效解决大规模云配置搜索的复杂性，通过数据共享和知识复用显著提高搜索效率和速度。

> **ai_Abstract:** 本文提出了“发现空间”抽象，旨在解决在海量配置选项中寻找最优云资源配置的挑战。该抽象形式化了工作负载配置问题，并支持对大型搜索空间的结构化、健壮和分布式调查。作者展示了其具体实现，并证明其在不同工作负载（如LLM推理和大数据分析）中的通用性。实验结果表明，该方法通过安全透明的数据共享提高了配置检测效率，并通过知识复用使搜索速度提升超过90%。

> **摘要翻译:** 在满足既定服务水平协议的前提下，以最低成本为给定工作负载寻找最优云资源配置是一个活跃的研究领域。将云提供商提供的计算、存储和服务的大量选择中适用的数十个参数与类似数量的应用程序特定参数相结合，导致配置空间包含数百万个部署选项。
在本文中，我们提出了“发现空间”（Discovery Space），这是一种抽象，它形式化了工作负载配置问题的描述，并展现了对大型搜索空间进行结构化、健壮和分布式调查所需的一系列特性。我们描述了发现空间抽象的一个具体实现，并表明它可以在诸如大型语言模型推理和大数据分析等多样化工作负载中通用。
我们证明了我们的方法能够在最佳优化器执行之间实现安全、透明的数据共享，从而提高大型搜索空间中最佳配置检测的效率。我们还展示了发现空间如何实现知识在相似搜索空间之间的转移和复用，从而使配置搜索速度提升90%以上。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [15] [Our Coding Adventure: Using LLMs to Personalise the Narrative of a Tangible Programming Robot for Preschoolers](https://arxiv.org/abs/2506.20982)
> *我们的编程冒险：使用大型语言模型为学龄前儿童的实体编程机器人个性化叙事*

*Martin Ruskov* | **Category: cs.CY, cs.RO, K.3.1**

**Keywords:** 大型语言模型, 实体编程机器人, 学龄前儿童, 个性化叙事, 教育技术

**Comment:** accepted at D-SAIL Workshop - Transformative Curriculum Design:
  Digitalization, Sustainability, and AI Literacy for 21st Century Learning

> **TL;DR:** 该研究探索使用大型语言模型（LLMs）为学龄前儿童的实体编程机器人Cubetto生成个性化故事，作为教师辅助工具，避免儿童直接接触LLMs，并解决了内容一致性和幻觉问题。

**AI_Comments:** 该论文提出了一种新颖且负责任地将大型语言模型应用于学龄前教育的方法，通过为实体编程机器人提供个性化叙事，既利用了LLMs的能力，又避免了儿童直接暴露于潜在风险。其强调作为教师辅助工具而非直接面向儿童的策略，以及对模型普适性和可复现性的关注，都体现了严谨性。同时，论文也坦诚地指出了LLMs在内容一致性和“幻觉”方面存在的问题，并记录了克服这些问题的尝试，这对于LLMs在教育领域的实际应用具有重要的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 在教育领域平衡使用大型语言模型（LLMs）面临挑战，尤其对于幼儿而言，存在对技术理解不足和屏幕时间过长的风险。本研究旨在探索一种利用LLMs能力的方法，为学龄前儿童提供个性化叙事，以帮助他们适应编程机器人操作，同时避免儿童直接接触LLMs。

**Method:** 研究团队与实体编程机器人Cubetto合作，提出了一种利用LLMs生成个性化故事的方法，以帮助学龄前儿童熟悉机器人指令。通过行动研究，开发了一个早期形式化的流程，用于快速原型化Cubetto的游戏故事。该方法使用开放权重模型，具有可复现性，并对模型具有普适性，因为它在5种不同的LLMs上进行了测试。研究记录了过程、所用材料、提示词、学习经验和成果。儿童不直接接触LLMs，而是教师使用该技术开发个性化叙事。

**Result:** 该方法生成的故事被认为成功地达到了作为教师辅助工具的目的。该方法具有可复现性，且对模型具有普适性（在5种不同LLMs上测试）。在4种不同的任务场景中测试模型时，研究人员遇到了内容一致性和“幻觉”问题，并记录了相应的评估过程以及克服这些问题的尝试（部分成功）。

**Conclusion:** 研究人员认为他们的方法适用于学龄前课堂，并计划在真实的教育环境中进行进一步的实验。

> **ai_Abstract:** 本研究提出了一种利用大型语言模型（LLMs）为学龄前儿童的实体编程机器人Cubetto生成个性化叙事的方法。旨在克服LLMs在儿童教育中应用的挑战，避免儿童直接接触LLMs，而是作为教师辅助工具。该方法通过行动研究开发，测试了多种LLMs，并记录了流程、材料和结果。尽管在一致性和“幻觉”方面存在挑战，但生成的叙事被认为是成功的教师辅助工具。研究认为该方法适用于学龄前教育，并计划进行实地实验。

> **摘要翻译:** 在教育中平衡使用大型语言模型（LLMs）是一个挑战，因为存在对技术理解不足和受众易受影响的固有风险。对于年幼的儿童来说尤其如此，他们已知在屏幕时间过长方面存在困难。我们与一个名为Cubetto的实体编程机器人合作，提出了一种方法，通过在个性化故事的准备中使用LLMs来利用其能力，这对于学龄前儿童适应指挥机器人的实践是必要的。我们进行行动研究，开发了一个早期版本的规范化流程，用于快速原型化Cubetto的游戏故事。我们的方法既有可复现的结果，因为它使用了开放权重模型，又与模型无关，因为我们在5种不同的LLMs上对其进行了测试。我们一方面记录了过程、使用的材料和提示词，另一方面记录了学习体验和成果。我们认为生成对于将结果用作教师辅助的预期目的而言是成功的。在4种不同的任务场景中测试模型时，我们遇到了内容一致性和幻觉问题，并记录了相应的评估过程以及克服这些问题的尝试（有些成功，有些不成功）。重要的是，这个过程不会让儿童直接接触LLMs。相反，这项技术被用来帮助教师轻松地开发关于儿童喜欢主题的个性化叙事。我们相信我们的方法适用于学龄前课堂，我们计划在真实的教育环境中进一步进行实验。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [220] [When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact](https://arxiv.org/abs/2506.20442)
> *当服务器遇到物种：计算对生物多样性影响的全生命周期视角*

*Tianyao Shi, Ritbik Kumar, Inez Hua, Yi Ding* | **Category: cs.CY, cs.AR, cs.DC**

**Keywords:** 生物多样性影响, 可持续计算, EBI, OBI, FABRIC

**Comment:** Accepted by HotCarbon' 25

> **TL;DR:** 本文首次端到端分析了计算系统对生物多样性的影响，引入了EBI和OBI两个新指标以及FABRIC建模框架，强调在可持续计算设计中需同时考虑生物多样性、碳和水。

**AI_Comments:** 本文的创新之处在于首次将生物多样性这一关键的行星边界问题与计算系统联系起来，并提出了具体的量化指标（EBI和OBI）和建模框架（FABRIC），为可持续计算领域拓展了新的研究维度。其重要性在于填补了现有研究的空白，为未来构建更全面的可持续计算策略提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 生物多样性丧失是一个关键的行星边界问题，但计算领域以往的可持续性努力主要关注碳和水，忽视了生物多样性，因为缺乏合适的衡量指标和建模框架。本文旨在填补这一空白。

**Method:** 本文提出了计算系统对生物多样性影响的首次端到端分析。引入了两个新指标：具身生物多样性指数（Embodied Biodiversity Index, EBI）和运行生物多样性指数（Operational Biodiversity Index, OBI），用于量化计算系统全生命周期的生物多样性影响。同时，提出了FABRIC建模框架，将计算工作负载与生物多样性影响联系起来。

**Result:** 评估结果强调，在可持续计算的设计和优化中，需要将生物多样性与碳和水一同考虑。代码已开源。

**Conclusion:** 计算系统对生物多样性的影响是真实存在的，并且需要被纳入可持续计算的设计和优化考量中，与碳和水同等重要。

> **ai_Abstract:** 本文首次全面分析了计算系统对生物多样性的影响，指出以往研究忽视了这一领域。为解决缺乏衡量标准的问题，作者提出了具身生物多样性指数（EBI）和运行生物多样性指数（OBI）两个新指标，并开发了FABRIC建模框架，旨在量化并关联计算工作负载与生物多样性影响。研究强调，未来的可持续计算设计和优化应将生物多样性与碳、水消耗一同纳入考量。

> **摘要翻译:** 生物多样性丧失是一个关键的行星边界，然而其与计算的联系在很大程度上仍未被检验。计算领域以往的可持续性努力主要集中在碳和水，由于缺乏适当的衡量指标和建模框架，生物多样性被忽视了。本文首次对计算系统对生物多样性的影响进行了端到端分析。我们引入了两个新的指标——具身生物多样性指数（EBI）和运行生物多样性指数（OBI）——以量化全生命周期的生物多样性影响，并提出了FABRIC，一个将计算工作负载与生物多样性影响联系起来的建模框架。我们的评估强调，在可持续计算设计和优化中，需要将生物多样性与碳和水一同考虑。代码可在 https://github.com/TianyaoShi/FABRIC 获取。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [13] [A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion](https://arxiv.org/abs/2506.20763)
> *基于相场法的耦合问题广义建模框架：应用于热机械断裂、水力压裂、氢脆和腐蚀*

*Y. Navidtehrani, C. Betegón, E. Martínez-Pañeda* | **Category: cs.CE, cs.NA, math.NA, physics.app-ph**

**Keywords:** 相场, 耦合问题, 断裂, 氢脆, 腐蚀

**Comment:** 

> **TL;DR:** 本文提出了一种通用的相场多物理场耦合建模框架，用于处理结构完整性问题。该框架利用传热方程的通用性，易于在商业有限元软件中实现，并通过应用于热机械断裂、水力压裂、氢致开裂和金属腐蚀等问题，验证了其与实验数据和现有解决方案的良好一致性。

**AI_Comments:** 该论文的创新之处在于提供了一个广义且易于实现的框架，利用现有有限元工具（如Abaqus）处理复杂的耦合问题。其多功能性和开放源代码的用户子程序具有重要意义，有助于推动相关领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提出一种新颖的、广义的公式，通过结合相场和多物理场建模来处理耦合结构完整性问题，并使其易于在商业有限元软件包中实现。

**Method:** 研究提出了一种结合相场和多物理场建模的广义理论和计算框架，该方法利用传热方程的通用性，并通过在有限元软件包Abaqus中实现简单的UMAT和UMATHT子程序来处理耦合多变量现象。该框架被应用于热机械断裂、水力压裂、氢致开裂和金属腐蚀等问题。

**Result:** 结果显示，该框架与实验数据以及现有数值和解析解具有非常好的一致性。

**Conclusion:** 所提出的广义理论和计算框架能够有效且准确地模拟各种耦合结构完整性问题。

> **ai_Abstract:** 本文提出了一种新颖的、基于相场的广义框架，用于模拟耦合结构完整性问题。该框架结合了相场和多物理场建模，并利用传热方程的通用性，使得在Abaqus等商业有限元软件中通过UMAT/UMATHT子程序实现变得容易。该框架被成功应用于热机械断裂、水力压裂、氢致开裂和金属腐蚀等问题，并显示出与实验数据和现有解决方案的高度一致性。

> **摘要翻译:** 我们提出了一种新颖的、广义的公式，通过结合相场和多物理场建模来处理耦合结构完整性问题。该方法利用了传热方程的通用性，因此非常适合在商业有限元软件包中采用，仅需要积分点级别的实现。本文通过在有限元软件包Abaqus中通过简单的UMAT和UMATHT子程序实现耦合的多变量现象来证明了这一点。所提出的广义理论和计算框架被专门应用于四个具有工程和科学相关性的问题：热机械断裂、水力压裂、氢致开裂和金属腐蚀。考虑了二维和三维问题。结果显示与实验数据以及现有数值和解析解具有非常好的一致性。所开发的用户子程序可在https://mechmat.web.ox.ac.uk/codes免费获取。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [29] [A Hereditary Integral, Transient Network Approach to Modeling Permanent Set and Viscoelastic Response in Polymers](https://arxiv.org/abs/2506.20773)
> *聚合物永久形变和粘弹性响应建模的遗传积分瞬态网络方法*

*Stephen T. Castonguay, Joshua B. Fernandes, Michael A. Puso, Sylvie Aubry* | **Category: cs.CE**

**Keywords:** 聚合物, 粘弹性, 永久形变, 瞬态网络理论, 遗传积分

**Comment:** 

> **TL;DR:** 提出了一种基于遗传积分瞬态网络理论的高效数值框架，用于模拟聚合物的粘弹性和永久形变，通过引入递归关系避免了对整个时间历史的积分，并能处理复杂加载历史下的速率依赖响应和残余应变。

**AI_Comments:** 该论文的关键创新在于将遗传积分瞬态网络理论与递归关系相结合，从而极大地提高了模拟聚合物粘弹性和永久形变的效率。这种方法避免了传统方法中对整个时间历史的积分需求，使其在处理复杂加载历史时更具计算优势。其能够处理不同材料模型和复杂加载条件下的材料响应，显示了其广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了建立一个高效的数值框架来模拟聚合物的粘弹性和永久形变。

**Method:** 该方法基于瞬态网络理论的遗传积分形式，其中聚合物链属于不同的网络，每个网络具有不同的自然平衡状态。链不断从先前形成的旧网络中脱离，并在零应力状态下重新连接到新网络。网络的自由能是相对于网络生成时的构型变形梯度给出的。通过对各种自由能的核进行分解，建立了一个递归关系，从而避免了对所有时间历史的积分。该技术通过使用新胡克、布拉茨-科、叶奥和奥格登-希尔材料模型，适用于高度可压缩和近乎不可压缩的材料。

**Result:** 该框架能够处理复杂加载历史下的速率依赖响应和残余应变，并通过多个例子进行了展示。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种基于遗传积分瞬态网络理论的高效数值框架，用于模拟聚合物的粘弹性和永久形变。该模型通过链的动态脱离和重新连接来描述网络行为，并引入了递归关系以避免对整个时间历史的积分。该方法适用于多种材料模型，并能有效处理复杂加载历史下的速率依赖响应和残余应变。

> **摘要翻译:** 本文提出了一种用于模拟聚合物粘弹性和永久形变的高效数值框架。该框架基于瞬态网络理论的遗传积分形式，其中聚合物链属于不同的网络，每个网络具有不同的自然平衡状态。链不断从先前形成的旧网络中脱离，并在零应力状态下重新连接到新网络。这些网络的自由能是根据相对于网络诞生时构型的变形梯度给出的。通过对各种自由能的核进行分解，可以建立一个递归关系，从而避免了对所有时间历史的积分。该技术通过使用新胡克、布拉茨-科、叶奥和奥格登-希尔材料模型，适用于高度可压缩和近乎不可压缩的材料。文章给出了多个例子，展示了其在复杂加载历史下处理速率依赖响应和残余应变的能力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [53] [Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation](https://arxiv.org/abs/2506.21362)
> *基于有用性评估的在线平台质量评估和更公平投票的反事实投票调整*

*Chang Liu, Yixin Wang, Moontae Lee* | **Category: cs.CE**

**Keywords:** 反事实投票调整, 因果推断, 在线平台, 质量评估, 投票偏见

**Comment:** 

> **TL;DR:** 在线平台上的有用性投票常因位置和先前投票而存在偏差，导致内容质量评估不公。本文提出了反事实投票调整（CVA），一个因果框架，用于校正这些偏差，从而实现更公平、准确的内容质量评估和排名。

**AI_Comments:** 本文的创新之处在于引入了一个因果框架（CVA）来纠正在线平台有用性投票中的固有偏差，这超越了传统的投票聚合或非因果模型。其重要性在于，通过提供更公平、更准确的内容质量评估，它对于在线平台有效获取高质量信息至关重要。在真实实验中利用GPT-4o进行质量评估是一个值得注意的现代化验证。此外，从嵌入中获得对专家用户群体行为动态的额外洞察也增加了研究的价值。

<details>
  <summary>Details</summary>

**Motivation:** 在线平台上的内容有用性投票常受到位置差异和先前投票级联效应的偏见，这阻碍了高效获取高质量信息并导致了不公平的内容评估。因此，需要一种方法来更公平地评估信息质量。

**Method:** 本文提出了反事实投票调整（CVA），这是一个因果框架，用于解释个人投票所处的上下文。CVA旨在有效地建模和消除位置偏见和羊群效应偏见，以准确恢复内容的真实质量。

**Result:** 通过初步和半合成实验，CVA被证明能有效建模位置和羊群偏见，并准确恢复预定义的内容质量。在真实实验中，基于CVA学习到的质量进行的内容重新排名，与用户情绪和GPT-4o评估的质量表现出更强的一致性，优于基于汇总投票的系统排名以及没有因果推断的模型重新排名。此外，CVA的嵌入还提供了对120个主要StackExchange社区中专家用户群体行为动态的比较性见解。

**Conclusion:** CVA通过解决在线平台投票中的固有偏差，提供了一种更公平、更准确的内容质量评估方法，从而显著改善了内容排名并提供了对用户行为的深入洞察。

> **ai_Abstract:** 本文提出了反事实投票调整（CVA），一个因果框架，旨在纠正在线平台上有用性投票中存在的偏见（如位置偏见和羊群效应），从而实现更公平、准确的内容质量评估。实验结果表明，CVA能够有效地建模这些偏见，准确恢复真实内容质量，并且基于CVA学习到的质量对内容进行重新排名，与用户情绪和GPT-4o评估的质量表现出更强的一致性，优于传统方法。此外，CVA的嵌入还为分析专家用户行为动态提供了有价值的见解。

> **摘要翻译:** 在线平台高效获取高质量信息至关重要。为了推广更有用的信息，用户不仅创建新内容，还会通过有用性投票来评估现有内容。尽管汇总投票有助于服务提供商对用户内容进行排名，但这些投票常常受到不同位置可访问性以及先前投票级联影响的偏见。为了更公平地评估信息质量，我们提出了反事实投票调整（CVA），这是一个因果框架，它考虑了个人投票所处的上下文。通过初步和半合成实验，我们表明CVA有效地模拟了位置和羊群偏见，准确地恢复了预定义的内容质量。在真实实验中，我们证明基于CVA学习到的质量对内容进行重新排名，与用户情绪和GPT-4o评估的质量都表现出更强的一致性，优于基于汇总投票的系统排名以及没有因果推断的模型重新排名。除了个体质量推断之外，我们的嵌入还在120个主要StackExchange社区中提供了对专家用户群体行为动态的比较性见解。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [36] [Distributed Lyapunov Functions for Nonlinear Networks](https://arxiv.org/abs/2506.20728)
> *非线性网络的分布式Lyapunov函数*

*Yiming Wang, Arthur N. Montanari, Adilson E. Motter* | **Category: eess.SY, cond-mat.dis-nn, cs.SY, math.DS**

**Keywords:** 分布式Lyapunov函数, 非线性网络, 吸引域, SOS优化, 高维系统

**Comment:** Codes are available at our GitHub repository
  https://github.com/YimingSci/Distributed-Lya-Func

> **TL;DR:** 本文提出一种基于局部信息的分布式方法来构建高维非线性网络中的Lyapunov函数，以准确近似吸引域。

**AI_Comments:** 本文提出了一种新颖的分布式方法来解决高维非线性系统中Lyapunov函数构建和吸引域表征的难题。其创新点在于利用局部信息和增广比较引理，将复杂的高维问题分解为可迭代优化的子问题，最终聚合得到全局有效的Lyapunov函数。这对于理解和控制复杂非线性动态系统具有重要意义，尤其是在大规模网络分析中展现出巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 非线性网络通常具有复杂的吸引域（ROAs）形态，难以分析和计算。此外，高维状态空间使得传统优化方法（如SOS编程）难以自动构建Lyapunov函数。

**Method:** 提出一种基于局部信息的分布式Lyapunov函数构建方法。该方法建立了一个增广比较引理来表征部分Lyapunov函数的存在条件，并考虑维度降低的残余效应。通过迭代的SOS优化构建部分函数，最终聚合形成复合Lyapunov函数。

**Result:** 所构建的复合Lyapunov函数能够提供吸引域（ROAs）体积和形状的精确凸近似。该方法在van der Pol和Ising振荡器网络上得到验证，证明其在表征具有非凸吸引域的高维系统方面的有效性。

**Conclusion:** 本文提出了一种分布式方法来构建非线性网络的Lyapunov函数，克服了高维下传统方法的挑战，并成功地表征了具有复杂吸引域的高维系统。

> **ai_Abstract:** 本文针对非线性网络中吸引域（ROAs）表征的挑战以及高维状态空间下Lyapunov函数构建的困难，提出了一种创新的分布式方法。该方法仅依赖局部信息，通过建立增广比较引理和迭代的SOS优化，构建部分Lyapunov函数并聚合为复合Lyapunov函数。实验结果表明，该方法能够准确地凸近似ROAs的体积和形状，并有效应用于高维非凸ROAs系统。

> **摘要翻译:** 非线性网络通常是多稳态的，表现出共存的稳定状态和竞争的吸引域（ROAs）。因此，吸引域可能具有复杂的“触手状”形态，这在分析或计算上都具有挑战性。此外，状态空间的高维性使得使用最先进的优化方法（如平方和（SOS）编程）自动构建Lyapunov函数变得困难。在这封信中，我们提出了一种基于局部信息的分布式方法来构建Lyapunov函数。为此，我们建立了一个增广比较引理，它表征了部分Lyapunov函数的存在条件，同时考虑了由相关维度降低引起的残余效应。这些理论结果使我们能够制定一个SOS优化问题，迭代地构建这些部分函数，它们的聚合形成一个复合Lyapunov函数。由此产生的复合函数提供了吸引域体积和形状的精确凸近似。我们在van der Pol和Ising振荡器网络上验证了我们的方法，证明了其在表征具有非凸吸引域的高维系统方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [60] [Noise-Tolerant Hybrid Approach for Data-Driven Predictive Control](https://arxiv.org/abs/2506.20780)
> *容噪混合数据驱动预测控制方法*

*Mahmood Mazare, Hossein Ramezani* | **Category: eess.SY, cs.SY**

**Keywords:** 数据驱动预测控制, 噪声容忍, Hankel矩阵, 奇异值分解, 混合方法

**Comment:** 

> **TL;DR:** 提出一种容噪数据驱动预测控制（NTDPC）框架，通过SVD处理测量噪声对Hankel矩阵的影响，提高混合数据驱动预测控制的鲁棒性和效率。

**AI_Comments:** 这篇论文的创新点在于提出了一个专门处理测量噪声的混合数据驱动预测控制框架，通过引入SVD有效分离噪声，并提供了敏感度指标来优化预测范围。这对于提高数据驱动控制在实际应用中的可靠性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 混合数据驱动预测控制中，测量噪声对Hankel矩阵的影响是一个关键挑战，现有混合方法在轨迹估计时常忽略其影响。

**Method:** 提出容噪数据驱动预测控制（NTDPC）框架，该框架将奇异值分解（SVD）集成到降阶Hankel矩阵中，以分离系统动态和噪声。文中还引入了一个灵敏度指标，以支持在不同噪声水平下的预测范围选择。

**Result:** 仿真结果表明，与现有混合方法相比，NTDPC提高了鲁棒性和效率，能够以更短的数据范围和更低的计算量进行准确预测。

**Conclusion:** NTDPC框架有效解决了混合数据驱动预测控制中测量噪声的影响问题，提升了系统的性能。

> **ai_Abstract:** 本文针对混合数据驱动预测控制中测量噪声对Hankel矩阵的关键影响，提出了容噪数据驱动预测控制（NTDPC）框架。该框架利用奇异值分解在降阶Hankel矩阵中分离系统动态和噪声，从而实现更短数据范围和更低计算量的精确预测。此外，引入了灵敏度指标以辅助不同噪声水平下的预测范围选择。仿真结果验证了NTDPC在鲁棒性和效率上优于现有混合方法。

> **摘要翻译:** 这篇论文关注混合数据驱动预测控制中的一个关键挑战：测量噪声对Hankel矩阵的影响。虽然直接和间接方法能够处理噪声，但混合方法在轨迹估计时通常会忽略其影响。我们提出了一种容噪数据驱动预测控制（NTDPC）框架，该框架集成了奇异值分解，用于在降阶Hankel矩阵中分离系统动态和噪声。这使得在更短的数据范围和更低的计算量下实现精确预测成为可能。文中引入了一个灵敏度指标，以支持在不同噪声水平下的预测范围选择。仿真结果表明，与现有混合方法相比，该方法提高了鲁棒性和效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [83] [DPLib: A Standard Benchmark Library for Distributed Power System Analysis and Optimization](https://arxiv.org/abs/2506.20819)
> *DPLib：一个用于分布式电力系统分析与优化的标准基准库*

*Milad Hasanzadeh, Amin Kargarian* | **Category: eess.SY, cs.SY**

**Keywords:** DPLib, 分布式电力系统, 基准库, 最优潮流, ADMM

**Comment:** 

> **TL;DR:** DPLib是一个开源的MATLAB基准库，为分布式电力系统分析和优化提供标准测试用例和分区工具，填补了现有集中式工具的空白。

**AI_Comments:** DPLib通过提供一个标准化的、可复现的基准库和测试用例，填补了分布式电力系统研究领域的一个重要空白。其创新之处在于提供了易于使用的分区工具包和集成的分布式OPF求解器，极大地促进了分布式电力系统算法的开发和验证。这对于推动现代电力系统的可扩展性、隐私性和弹性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分布式和去中心化方法对于现代电力系统日益重要，因其提供了可扩展性、隐私保护和对单点故障的弹性。然而，与MATPOWER等集中式工具不同，目前尚无适用于分布式电力系统研究的通用、可复现的数据库包。

**Method:** DPLib通过提供一个标准的电力系统库来填补这一空白，该库包含20多个不同规模的多区域基准测试用例，以及一个基于图的分区工具包，可将任何MATPOWER测试系统分解为多个电学上连贯的区域。此外，DPLib还提供了模块化、易于使用的分布式最优潮流(OPF)求解器：一个基于ADMM的DC-OPF求解器（在YALMIP中实现）和一个基于ADMM的AC-OPF求解器（利用IPOPT）。

**Result:** 数值结果验证了所生成的测试用例，并且所提供的求解器验证了生成的测试系统适用于分布式优化应用。

**Conclusion:** DPLib为可复现的分布式电力系统研究奠定了基础。

> **ai_Abstract:** DPLib是一个开源的MATLAB基准库，旨在解决分布式电力系统研究中缺乏标准化、可复现数据包的问题。它提供了20多个多区域测试用例和一个将MATPOWER系统分解为连贯区域的分区工具包。此外，DPLib还集成了基于ADMM的DC-OPF和AC-OPF求解器，用于验证测试系统。DPLib的推出为可复现的分布式电力系统研究提供了坚实的基础。

> **摘要翻译:** DPLib是一个开源的MATLAB基准库，旨在支持分布式和去中心化电力系统分析与优化的研究与开发。分布式和去中心化方法具有可扩展性、隐私保护和对单点故障的弹性，这使得它们对现代电力系统越来越重要。然而，与MATPOWER等集中式工具不同，目前尚无适用于分布式电力系统研究的通用、可复现的数据库包。DPLib通过提供一个标准的电力系统库来填补这一空白，该库包含20多个不同规模的多区域基准测试用例，以及一个基于图的分区工具包，可将任何MATPOWER测试系统分解为多个电学上连贯的区域。该分区工具包是一个易于使用的MATLAB代码，可生成标准化的.mat和.m文件，以及用于直观理解的区域可视化。我们还提供了模块化、易于使用的分布式最优潮流（OPF）求解器：一个基于交替方向乘子法（ADMM）的DC-OPF求解器（在YALMIP中实现），以及一个利用IPOPT的基于ADMM的AC-OPF求解器。这些求解器验证了生成的测试系统适用于分布式优化应用。数值结果验证了生成的测试用例，从而将DPLib确立为可复现分布式电力系统研究的基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [106] [Resilience Through Escalation: A Graph-Based PACE Architecture for Satellite Threat Response](https://arxiv.org/abs/2506.20882)
> *通过升级实现韧性：一种基于图的卫星威胁响应PACE架构*

*Anouar Boumeftah, Sarah McKenzie-Picot, Peter Klimas, Gunes Karabulut Kurt* | **Category: eess.SY, cs.SY**

**Keywords:** 卫星韧性, PACE架构, 威胁响应, 故障恢复, 空间资产

**Comment:** 

> **TL;DR:** 本文提出了一种基于PACE（主用、备用、应急、紧急）方法的分层状态转换模型，用于提高卫星系统对动态多向量威胁的韧性，并通过三种PACE变体评估了其有效性。

**AI_Comments:** 本文创新性地将军事领域的PACE方法引入卫星系统韧性设计，并通过结合威胁评分框架和分层状态转换模型，提供了一种新颖的威胁响应策略。其强调轻量级、决策感知的故障恢复机制，对于提升未来空间资产的生存能力和运行连续性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 卫星系统日益面临来自干扰、网络攻击和电磁中断的运行风险，而传统的冗余策略在面对动态、多向量威胁时往往失效。

**Method:** 本文引入了一种基于PACE方法（源自军事战术通信）的韧性设计框架，并通过分层状态转换模型将其应用于卫星系统，该模型结合了CVSS、DREAD和NASA风险矩阵等威胁评分框架。研究定义了动态韧性指数来量化系统适应性，并实现了三种PACE变体：静态、自适应和基于softmax的决策模型，以评估在不同中断场景下的韧性。

**Result:** 所提出的方法突出了轻量级、决策感知的故障恢复机制在提高下一代空间资产生存能力和运行连续性方面的有效性。

**Conclusion:** 轻量级、决策感知的故障恢复机制可以有效提高下一代空间资产的生存能力和运行连续性。

> **ai_Abstract:** 本文针对卫星系统面临的动态多向量威胁，提出了一种基于PACE方法的分层状态转换韧性设计框架。该框架借鉴军事领域的PACE理念，并结合威胁评分模型，定义了动态韧性指数。通过实现静态、自适应和softmax三种PACE决策模型，验证了轻量级、决策感知的故障恢复机制能有效提升下一代空间资产的生存能力和运行连续性。

> **摘要翻译:** 卫星系统日益面临来自干扰、网络攻击和电磁中断的运行风险。传统的冗余策略在应对动态、多向量威胁时往往失效。本文引入了一种基于PACE（主用、备用、应急、紧急）方法论的韧性设计框架，该方法论最初为军事行动中的战术通信而开发，通过结合CVSS、DREAD和NASA风险矩阵等威胁评分框架的分层状态转换模型，将其应用于卫星系统。我们定义了一个动态韧性指数来量化系统适应性，并实现了三种PACE变体：静态、自适应和基于softmax的决策模型，以评估在不同中断场景下的韧性。所提出的方法突出了轻量级、决策感知的故障恢复机制在提高下一代空间资产生存能力和运行连续性方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [127] [Optimal Parameter Design for Power Electronic Converters Using a Probabilistic Learning-Based Stochastic Surrogate Model](https://arxiv.org/abs/2506.20987)
> *基于概率学习随机代理模型的电力电子变换器最优参数设计*

*Akash Mahajan, Shivam Chaturvedi, Srijita Das, Wencong Su, Van-Hai Bui* | **Category: eess.SY, cs.SY**

**Keywords:** 电力电子变换器, 参数优化, 概率学习, 随机代理模型, 多目标优化

**Comment:** 

> **TL;DR:** 提出一种基于概率学习的随机代理建模框架，用于电力电子变换器参数优化，显著减少设计时间，提高预测精度和优化结果。

**AI_Comments:** 该论文的创新点在于结合了概率学习和随机代理模型来解决电力电子变换器参数设计的复杂多目标优化问题，特别是在处理不确定性和确保实际可行性方面。通过引入神经网络分类器过滤不切实际的输入和使用惩罚项，提高了优化结果的实用性。与多种现有优化算法的比较也增强了其方法的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 电力电子变换器参数选择需要在效率和热约束之间取得平衡，以确保高性能和安全性，同时设计阶段耗时较长。

**Method:** 该方法包含三个阶段：首先，使用神经网络分类器评估参数配置的可行性，过滤不安全/不切实际的输入；其次，使用概率预测模型估计变换器效率和温度，并量化预测不确定性；最后，采用启发式优化模型优化多目标函数，以最大化效率并遵守热约束，并加入惩罚项。此外，使用先进的启发式优化方法寻找最优解，并与遗传算法（GA）、粒子群优化（PSO）、模拟退火（SA）、禁忌搜索（TS）和随机爬山（SHC）等算法进行比较。

**Result:** 结果表明，该方法显著提高了预测精度和优化结果。

**Conclusion:** 该方法为推进电力电子设计提供了一个稳健的解决方案。

> **ai_Abstract:** 本文提出一种基于概率学习的随机代理建模框架，旨在优化电力电子变换器参数设计，以平衡效率和热约束并缩短设计时间。该框架通过神经网络分类器筛选可行配置，利用概率预测模型评估性能并量化不确定性，最后采用启发式优化方法解决多目标优化问题，以最大化效率并满足热约束。实验结果显示，该方法在预测精度和优化效果上均有显著提升，为电力电子设计提供了有效方案。

> **摘要翻译:** 电力电子变换器参数的最优设计选择涉及平衡效率和热约束，以确保高性能而不损害安全性。本文介绍了一种基于概率学习的随机代理建模框架，以解决这一挑战并显著减少设计阶段所需的时间。该方法首先使用神经网络分类器评估参数配置的可行性，有效过滤掉不安全和/或不切实际的输入。随后，概率预测模型估计变换器的效率和温度，同时量化预测不确定性，提供性能洞察和可靠性指标。最后，采用基于启发式优化的模型来优化多目标函数，该函数在遵守热约束的同时最大化效率。优化过程结合了惩罚项，以阻止违反实际阈值的解决方案，确保可操作和实际的建议。使用先进的启发式优化方法来寻找最优解，并与几种知名的搜索算法进行比较，包括遗传算法（GA）、粒子群优化（PSO）、模拟退火（SA）、禁忌搜索（TS）和随机爬山（SHC）。结果表明，预测精度和优化结果显著改善，为推进电力电子设计提供了稳健的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [145] [Coordinated Control of Autonomous Vehicles for Traffic Density Reduction at a Signalized Junction: An MPC Approach](https://arxiv.org/abs/2506.21302)
> *信号交叉口交通密度降低的自动驾驶车辆协同控制：一种MPC方法*

*Rudra Sen, Subashish Datta* | **Category: eess.SY, cs.SY**

**Keywords:** 车联网自动驾驶车辆, 模型预测控制, 交通密度降低, 信号交叉口, 协同变道

**Comment:** 

> **TL;DR:** 本文提出了一种双模态模型预测控制（MPC）架构，用于在信号交叉口降低交通密度并促进车联网自动驾驶车辆（CAVs）的协同变道，并通过数值仿真验证了其有效性。

**AI_Comments:** 该论文利用车联网自动驾驶车辆（CAVs）的能力，解决了城市交通中的一个重要问题。其创新点在于提出了一种双模态MPC架构，并通过集成在线计算的最大控制不变终端集来确保其递归可行性和收敛性，这增强了方法的理论严谨性。然而，方法的有效性目前仅通过数值仿真验证，实际部署可能面临更多挑战。

<details>
  <summary>Details</summary>

**Motivation:** 由于城市交通系统的快速发展，有效和安全地管理交通是一个关键问题。车联网自动驾驶车辆（CAVs）能够相互连接并与相邻基础设施连接，为增强交通流和协调性提供了新机遇。本研究旨在通过为CAVs提供响应式决策，从而提高城市出行的效率和安全性。

**Method:** 本文提出了一种双模态模型预测控制（MPC）架构，旨在解决信号交叉口的交通密度缓解和高密度交通条件下的无缝协同变道这两个相互关联的问题。此外，通过集成在线计算的最大控制不变终端集，确保了所提出的MPC方案的递归可行性和收敛性。

**Result:** 所提出的方法通过数值仿真验证了其有效性。

**Conclusion:** 本研究旨在通过为车联网自动驾驶车辆（CAVs）提供响应式决策，从而提高城市出行的效率和安全性。

> **ai_Abstract:** 本文提出了一种双模态模型预测控制（MPC）架构，用于车联网自动驾驶车辆（CAVs）在信号交叉口进行交通管理。该架构旨在降低交通密度并促进高密度条件下的协同变道，最终提升城市出行的效率和安全性。该MPC方案通过集成在线计算的最大控制不变终端集来确保递归可行性和收敛性，并通过数值仿真验证了其有效性。

> **摘要翻译:** 城市交通系统的快速发展使得交通的有效和安全管理成为一个关键问题。车联网自动驾驶车辆（CAVs）具备相互连接和与相邻基础设施连接的能力，为增强交通流和协调性带来了新的机遇。这项工作提出了一种双模态模型预测控制（MPC）架构，解决了两个相互关联的问题：缓解信号交叉口的交通密度，以及在高密度交通条件下促进无缝、协作的变道。这项工作的目标是促进CAVs的响应式决策，从而提高城市出行的效率和安全性。此外，我们通过集成在线计算的最大控制不变终端集，确保了所提出的MPC方案的递归可行性和收敛性。最后，通过数值仿真验证了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [164] [Estimating Technical Loss without Power Flows: A Practical, Data-Driven Approach for Loss Estimation in Distribution Grids](https://arxiv.org/abs/2506.21311)
> *在没有潮流的情况下估计技术损耗：一种针对配电网损耗估计的实用数据驱动方法*

*Mohini Bariya, Genevieve Flaspohler* | **Category: eess.SY, cs.SY**

**Keywords:** 技术损耗, 配电网, 数据驱动, 电压测量, 中低收入国家

**Comment:** 6 pages, 3 figures

> **TL;DR:** 中低收入国家电网技术损耗高且难以估计，本文提出一种无需潮流数据、仅利用稀疏电压测量值即可估计技术损耗的新方法。

**AI_Comments:** 这项研究解决了中低收入国家电网在技术损耗估计方面的实际痛点，其创新之处在于提出了一种无需昂贵潮流传感数据、仅依赖更易获取的稀疏电压测量值的解决方案。这大大降低了损耗估计的门槛，对于提升这些地区电网的运行效率和经济效益具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 全球中低收入国家（LMICs）的电网面临严峻挑战，需承担巨大负荷增长并整合分布式可再生能源，但其基础设施薄弱、老化，导致技术损耗（尤其在配电层面）过高，常远超20%。现有损耗估计方法依赖昂贵且在LMIC电网中普遍缺乏的潮流传感数据，因此难以有效识别和解决技术损耗问题。

**Method:** 本研究提出了一种新颖的数据驱动方法，用于技术损耗估计。该方法无需传统的潮流数据，而是利用电网中稀疏位置更易获得的电压幅值测量数据来进行损耗估计和定位。

**Result:** 该方法使全球中低收入国家电网的技术损耗估计和定位成为可能。

**Conclusion:** 该方法为全球中低收入国家电网提供了关键工具，使其能够有效设计、实施和评估损耗降低干预措施，从而提升电网的物理和经济实力。

> **ai_Abstract:** 中低收入国家电网因基础设施薄弱而面临高技术损耗（常超20%），但现有损耗估计方法依赖其缺乏的昂贵潮流传感数据。本文提出一种创新的数据驱动方法，利用电网中稀疏位置的电压幅值测量数据即可估计技术损耗，无需潮流数据。该方法使中低收入国家电网能有效进行损耗估计和定位，为制定减损策略提供了关键工具。

> **摘要翻译:** 全球中低收入国家（LMICs）的电网面临严峻挑战。为了支持全球脱碳努力并帮助数百万人摆脱能源贫困，这些电网必须承担巨大的负荷增长，同时整合分布式可再生能源发电。然而，数十年来快速且资金不足的基础设施扩张，导致许多中低收入国家的国家电网紧张而薄弱，由老化、故障和规模不足的基础设施组成。这种薄弱的一个原因和症状是能源输送过程中电网基础设施内部，特别是在配电层面，存在过度的技术损耗；与高收入国家5%的基线相比，电网损耗通常估计远超20%。通过有针对性的干预措施解决技术损耗对于增强电网的物理和经济实力至关重要。不幸的是，当前估计和定位技术损耗的方法需要昂贵、广泛的潮流传感，这在中低收入国家的配电系统中基本不存在。我们提出了一种无需潮流数据即可进行技术损耗估计的新颖方法，该方法利用电网中稀疏位置更易获得的电压幅值测量数据。这种估计器使全球中低收入国家电网的损耗估计和定位成为可能，并为有效设计、实施和评估损耗降低干预措施提供了关键工具。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [182] [Joint Scheduling of DER under Demand Charges: Structure and Approximation](https://arxiv.org/abs/2506.21510)
> *分布式能源在需量电价下的联合调度：结构与近似*

*Ruixiao Yang, Gulai Shen, Ahmed S. Alahmed, Chuchu Fan* | **Category: eess.SY, cs.SY**

**Keywords:** 分布式能源调度, 需量电价, 随机动态规划, 近似算法, 储能系统

**Comment:** 15 pages, 4 tables, 4 figures

> **TL;DR:** 研究了在需量电价下分布式能源（DERs）的联合调度问题，提出了一个高效的近似算法来解决其高计算复杂性，并通过仿真验证了其性能优于现有基准。

**AI_Comments:** 本文创新性地解决了在需量电价下分布式能源联合调度的复杂性问题。通过深入分析最优控制策略的结构，并提出了一种计算效率高（线性复杂度）的近似算法，极大地提升了该问题在实际应用中的可行性。其对理论最优解的接近程度，以及在与强化学习等方法比较中的优越性，都凸显了该方法的实用价值和重要性。该研究对于推动智能电网中分布式能源的优化管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在净计量框架和需量电价下，对包括柔性负荷、可再生能源发电和电池储能系统在内的表后分布式能源（DERs）进行联合调度，以最大化预期运营盈余并应对可再生能源发电的不确定性。由于最优控制策略的组合式复杂性，需要开发高效的近似算法来克服计算挑战。

**Method:** 问题被公式化为一个随机动态规划，旨在最大化预期运营盈余，同时考虑可再生能源发电的不确定性。分析性地描述了最优控制策略的结构，并表明它具有基于阈值的形式。为了克服通用公式中的高计算复杂性，提出了一种高效的近似算法，该算法在轻度松弛问题下搜索峰值需求。该算法的计算复杂度与调度周期呈线性关系。通过使用两个开源数据集的广泛仿真来验证所提出的算法，并将其性能与包括强化学习在内的不同DER控制策略进行比较。

**Result:** 最优控制策略呈现基于阈值的形式，但由于储能和需量电价约束的强时间耦合，策略中的条件分支数量随调度周期呈组合式增长，导致计算复杂度高。提出的近似算法能够将计算复杂度降低到与调度周期呈线性关系。仿真结果表明，在不同的储能和电价参数下，所提出的算法在实现相对较小的解差距方面优于各种基准，与理论上限相比表现出色。

**Conclusion:** 该研究成功地为需量电价下的分布式能源联合调度问题提出了一种高效的近似算法，该算法在计算效率和性能上均优于现有方法，为实际应用提供了有效工具。

> **ai_Abstract:** 本研究探讨了在需量电价下，包括柔性负荷、可再生能源和电池储能系统在内的分布式能源（DERs）的联合调度问题。该问题被建模为随机动态规划以最大化运营盈余，并发现最优策略具有基于阈值的结构，但存在组合式计算复杂性。为解决此问题，论文提出了一种高效的近似算法，该算法通过搜索松弛问题下的峰值需求，实现了与调度周期线性相关的计算复杂度。广泛的仿真结果证明，该算法在性能上优于多种现有DER控制策略，并能达到接近理论最优的解。

> **摘要翻译:** 我们研究了在具有需量电价的净计量框架下，包括柔性负荷、可再生能源发电和电池储能系统在内的表后分布式能源（DERs）的联合调度问题。该问题被公式化为一个随机动态规划，旨在最大化预期运营盈余，同时考虑可再生能源发电的不确定性。我们分析性地描述了最优控制策略的结构，并表明它具有基于阈值的形式。然而，由于储能和需量电价约束的强时间耦合，策略中的条件分支数量随调度周期呈组合式增长，因为它需要对未来状态进行展望。为了克服通用公式中的高计算复杂性，提出了一种高效的近似算法，该算法在轻度松弛问题下搜索峰值需求。我们表明该算法的计算复杂度与调度周期呈线性关系。使用两个开源数据集进行的广泛仿真验证了所提出的算法，并将其性能与包括基于强化学习的策略在内的不同DER控制策略进行了比较。在不同的储能和电价参数下，结果表明所提出的算法在实现与理论上限相比相对较小的解差距方面优于各种基准。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [37] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
> *基于幅度测量的DFT码本的精确近场波束训练*

*Zijun Wang, Shawn Tsai, Rama Kiran, Rui Zhang* | **Category: eess.SP**

**Keywords:** 近场通信, 波束训练, DFT码本, 幅度测量, 距离估计

**Comment:** 

> **TL;DR:** 本文提出了一种低复杂度的近场波束训练方案，利用传统DFT码本，通过幅度测量实现高精度距离估计和波束训练，性能接近理想信道信息。

**AI_Comments:** 该论文创新性地将传统为远场设计的DFT码本应用于近场波束训练，并实现了低复杂度。通过深入的理论分析和高效的估计方法，解决了近场距离估计的挑战，并且仅依赖幅度测量，具有较高的实际应用价值和工程可行性。

<details>
  <summary>Details</summary>

**Motivation:** 极端大天线阵列 (ELAAs) 在高频段运行，推动了近场通信的发展，进而对波束训练和信号处理设计提出了更高的要求。

**Method:** 该方案利用为远场设计的传统DFT码本，通过分析近场接收波束图，推导了波束宽度和中心增益的闭式表达式，并定义了修正瑞利距离。在此基础上，开发了一种复杂度为O(1)的用户距离直接估计方法，并通过简单细化提高精度。此外，还提出了一种基于最大似然估计 (MLE) 的细化方法，利用信号幅度的莱斯分布来进一步增强估计精度。

**Result:** 仿真结果表明，在单用户和多用户设置中，信噪比相对于穷举搜索提高了高达2.38 dB。MLE细化方法实现了接近克拉默-拉奥界 (CRB) 的精度。单用户和多用户可实现速率均能接近通过理想信道状态信息获得的速率。

**Conclusion:** 本文提出的基于DFT码本的低复杂度近场波束训练方案，通过深入的理论分析和高效的距离估计方法，实现了高精度的波束训练，其性能在信噪比和可实现速率方面均表现出色，接近理想信道信息下的水平。

> **ai_Abstract:** 本文提出了一种低复杂度的近场波束训练方案，该方案创新性地利用了为远场设计的传统DFT码本，并仅基于幅度测量。通过对近场波束图的深入分析，推导了关键参数并定义了修正瑞利距离。在此基础上，开发了O(1)复杂度的高效用户距离估计方法，并通过基于最大似然估计的细化进一步提升了精度，实现了接近克拉默-拉奥界的高性能。仿真结果验证了该方案在信噪比增益和可实现速率方面均表现出色，接近理想信道信息下的性能。

> **摘要翻译:** 极端大天线阵列 (ELAAs) 在高频段运行，推动了近场通信的发展，进而促进了波束训练和信号处理设计方面的进步。在这项工作中，我们提出了一种低复杂度的近场波束训练方案，该方案充分利用了为远场用户设计的传统离散傅里叶变换 (DFT) 码本。我们首先分析了近场中的接收波束图，并推导了波束宽度和中心增益的闭式表达式。这些分析结果使得能够定义一个与角度相关的修正瑞利距离，该距离有效地区分了近场和远场用户区域。在此分析的基础上，我们开发了一种直接且计算高效的用户距离估计方法，其复杂度为 O(1)，并通过简单的细化进一步提高了其精度。仿真结果表明，在单用户和多用户设置中均实现了显著增益，相对于穷举搜索，信噪比提高了高达 2.38 dB。为了进一步提高估计精度，我们额外提出了一种基于最大似然估计 (MLE) 的细化方法，该方法利用信号幅度的莱斯分布，实现了接近克拉默-拉奥界 (CRB) 的精度。仿真表明，单用户和多用户可实现速率均能接近通过理想信道状态信息获得的速率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [61] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
> *基于纠缠的远距离卫星链路量子密钥分发的物理极限*

*Mohammad Taghi Dabiri, Mazen Hasna, Saif Al-Kuwari, Khalid Qaraqe* | **Category: eess.SP**

**Keywords:** 量子密钥分发, 卫星链路, 纠缠, 物理极限, 性能分析

**Comment:** 

> **TL;DR:** 本文对基于纠缠的卫星间量子密钥分发(SatQKD)进行了全面的性能分析，特别关注光子级建模和实际损伤的影响，并提出了可操作的设计见解。

**AI_Comments:** 本文解决了基于纠缠的卫星量子密钥分发在实际长距离链路中面临的关键物理层挑战，填补了现有文献的空白。其创新之处在于提出了全面的光子级建模和分析表达式，并揭示了系统性能对关键参数的非线性敏感性。通过提供可操作的设计见解，该研究对未来卫星QKD系统的可靠和高效部署具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文献未能解决在长距离卫星间自由空间光(FSO)信道上实现基于纠缠的量子密钥分发(QKD)协议所面临的关键物理层挑战，特别是由于光束发散、指向误差和背景噪声引起的光子损耗会严重降低密钥生成速率和量子误码率(QBER)。

**Method:** 本文对基于纠缠的卫星间量子密钥分发进行了全面的性能分析，专注于光子级建模和实际损伤的影响。研究人员开发了信号检测概率、背景光子影响、多对发射和QBER的分析表达式，并纳入了链路距离、发射机跟踪抖动、接收机失准和光子对生成速率等关键参数。

**Result:** 仿真结果揭示了系统性能对跟踪误差和视场(FoV)限制的非线性敏感性，并强调了在保持QBER低于可接受阈值的同时，共同最大化秘密密钥速率的最佳参数范围。

**Conclusion:** 所提出的模型为可靠高效地部署基于纠缠的卫星量子密钥分发系统提供了可操作的设计见解。

> **ai_Abstract:** 本文针对基于纠缠的卫星量子密钥分发(SatQKD)在长距离卫星间自由空间光链路中面临的物理层挑战进行了深入分析。研究建立了光子级模型，并推导了信号检测概率、背景噪声、多对发射和量子误码率(QBER)的分析表达式，考虑了链路距离、跟踪抖动等关键参数。仿真结果揭示了系统性能对跟踪误差和视场限制的非线性敏感性，并确定了能同时优化密钥速率和QBER的最佳参数范围。该模型为设计和部署可靠高效的基于纠缠的SatQKD系统提供了实用指导。

> **摘要翻译:** 基于纠缠的量子密钥分发（QKD）协议，如E91和BBM92，提供了强大的信息理论安全性，并且天然适用于卫星到卫星的QKD（SatQKD）链路。然而，在长距离卫星间自由空间光（FSO）信道上实现这些协议带来了现有文献中尚未解决的关键物理层挑战。特别是，由于光束发散、指向误差和背景噪声引起的光子损耗会严重降低密钥生成速率和量子误码率（QBER），尤其是在窄接收机视场（FoV）限制下。本文对基于纠缠的卫星间QKD进行了全面的性能分析，重点关注光子级建模和实际损伤的影响。我们开发了信号检测概率、背景光子影响、多对发射和QBER的分析表达式，并纳入了链路距离、发射机跟踪抖动、接收机失准和光子对生成速率等关键参数。仿真结果揭示了系统性能对跟踪误差和FoV限制的非线性敏感性，并强调了在保持QBER低于可接受阈值的同时，共同最大化秘密密钥速率的最佳参数范围。所提出的模型为可靠高效地部署基于纠缠的SatQKD系统提供了可操作的设计见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [84] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
> *用于实时评估基于OAM的星间链路的紧凑分析模型*

*Mohammad Taghi Dabiri, Mazen Hasna* | **Category: eess.SP**

**Keywords:** OAM, 星间链路, 指向误差, 分析模型, 实时评估

**Comment:** 

> **TL;DR:** 本文提出了一个紧凑的分析模型，用于在指向误差下实时评估基于OAM的星间链路性能，比传统蒙特卡洛方法更快、更准确，并设计了性能更优的非对称OAM模式集。

**AI_Comments:** 该论文的创新之处在于提出了一个紧凑且高效的分析模型，用于实时评估OAM星间链路在指向误差下的性能，显著优于计算量大的传统蒙特卡洛方法。其对非对称OAM模式集的设计和验证，为提高系统鲁棒性提供了新途径。这对于高动态的LEO卫星网络具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统蒙特卡洛方法在评估基于轨道角动量（OAM）的星间链路性能时计算量大，难以满足动态低地球轨道（LEO）卫星星座网络拓扑和信道条件快速变化对实时链路适应的需求。

**Method:** 本文首先开发了一个精确的分析模型来表征OAM星间链路中由光束未对准引起的模间串扰。在此模型基础上，推导了用于分析和优化误码率（BER）系统性能的有效表达式。此外，系统地设计和评估了非对称OAM模式集。

**Result:** 所提出的方法能够提供准确的性能预测，显著减少计算时间并保持高精度。非对称OAM模式集在存在指向误差的情况下显著优于对称配置。研究结果还揭示了光束发散、跟踪精度和链路距离之间的关键相互作用，表明该框架能够高保真地实时优化系统参数。

**Conclusion:** 分析结果通过广泛的蒙特卡洛模拟得到了严格验证，证实了其在LEO卫星网络等高移动性光无线系统中的实际适用性。

> **ai_Abstract:** 本文提出了一个紧凑的分析模型，用于在指向误差下实时评估基于OAM的星间链路性能。该模型通过表征模间串扰并推导误码率分析表达式，实现了比传统蒙特卡洛方法更高的计算效率和准确性。研究还系统地设计并验证了在指向误差下性能更优的非对称OAM模式集，并揭示了光束发散、跟踪精度和链路距离之间的相互作用。该框架对于需要实时链路适应的动态LEO卫星星座尤为重要，其分析结果已通过蒙特卡洛模拟验证。

> **摘要翻译:** 本文提出了一种高效的分析框架，用于评估在指向误差下利用轨道角动量（OAM）光束的星间通信系统的性能。首先，开发了一个精确的分析模型来表征基于OAM的星间链路中由光束未对准引起的模间串扰。在此模型基础上，我们推导了分析和优化误码率（BER）系统性能的有效表达式。与计算密集型的传统蒙特卡洛方法不同，所提出的方法提供了准确的性能预测。这使得计算时间大幅减少，同时通过使用串扰和BER的分析表达式保持了高精度。这种快速准确的评估能力对于动态低地球轨道（LEO）卫星星座尤其关键，因为其网络拓扑和信道条件变化迅速，需要实时链路适应。此外，我们系统地设计和评估了非对称OAM模式集，它们在存在指向误差的情况下显著优于对称配置。我们的结果还揭示了光束发散、跟踪精度和链路距离之间相互作用的关键见解，表明所提出的框架能够高保真地实时优化系统参数。分析结果通过广泛的蒙特卡洛模拟得到了严格验证，证实了其在LEO卫星网络等高移动性光无线系统中的实际适用性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [107] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
> *LoRa直连卫星通信中的多普勒估计与补偿技术*

*Jamil Farhat, Gianni Pasolini, Enrico Paolini, Muhammad Asad Ullah, Richard Demo Souza* | **Category: eess.SP**

**Keywords:** LoRa, 直连卫星通信, 多普勒效应, 补偿技术, 物联网

**Comment:** 

> **TL;DR:** 本文提出了四种多普勒效应估计与补偿框架，以提高LoRa直连卫星通信性能。

**AI_Comments:** 本文解决了LoRa直连卫星通信中一个关键且实际的问题——多普勒效应，这对于扩展物联网覆盖范围至关重要。通过提出并比较多种补偿框架，并深入分析关键参数的权衡，为实际系统部署提供了有价值的指导，具有较高的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** LoRaWAN技术因其低成本、低功耗和长距离通信能力在物联网应用中受到关注，尤其是在直连卫星（DtS）通信中扩展覆盖范围。然而，低地球轨道（LEO）卫星的移动性导致的多普勒效应严重降低了LoRa DtS的性能，因此需要有效的多普勒估计和补偿技术。

**Method:** 本文提出了四种用于LoRa直连卫星连接中的多普勒效应估计和补偿框架。通过数值比较这些框架的性能，并与没有多普勒效应的理想场景进行对比。此外，还分析了扩频因子与多普勒效应相关关键参数之间的相互作用，以研究这些框架的权衡。

**Result:** 结果提供了关于如何为直连卫星连接实现鲁棒LoRa配置的见解。

**Conclusion:** 通过提出的多普勒估计和补偿框架以及对关键参数权衡的分析，可以为LoRa直连卫星通信找到鲁棒的配置，从而有效解决多普勒效应带来的性能下降问题。

> **ai_Abstract:** 本文针对LoRa直连卫星（DtS）通信中低地球轨道（LEO）卫星移动性导致的多普勒效应严重影响性能的问题，提出了四种多普勒估计与补偿框架。研究通过数值比较这些框架的性能，并分析扩频因子等关键参数与多普勒效应之间的权衡，旨在为LoRa DtS连接提供鲁棒的配置指导。

> **摘要翻译:** 在LPWAN框架内，LoRaWAN技术采用的LoRa调制因其提供低成本、低功耗和长距离通信的能力，作为物联网应用的连接解决方案受到了广泛关注。LoRa的一个新兴用例是DtS连接，它将覆盖范围扩展到偏远地区以支持物联网操作。卫星物联网行业主要偏好LEO，因为它与地球同步轨道相比具有更低的发射成本和更小的路径损耗。然而，LEO卫星的一个主要缺点是其移动性引起的多普勒效应的影响。早期的研究已经证实，多普勒效应显著降低了LoRa DtS的性能。在本文中，我们提出了四种用于LoRa DtS连接中的多普勒估计和补偿框架，并将其性能与没有多普勒效应的理想场景进行数值比较。此外，我们通过分析扩频因子与多普勒效应相关的其他关键参数之间的相互作用，研究了这些框架之间的权衡。结果提供了关于如何为DtS连接实现鲁棒LoRa配置的见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [128] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
> *量子加速无线通信：概念、连接与启示*

*Naoki Ishikawa, Giuseppe Thadeu Freitas de Abreu, Petar Popovski, Robert W. Heath Jr* | **Category: eess.SP, quant-ph**

**Keywords:** 量子计算, 无线通信, 量子加速, 跨学科研究, 互补优势

**Comment:** 7 pages, 6 figures

> **TL;DR:** 本文探讨了量子计算如何应用于无线通信系统，揭示了量子与经典计算的互补优势，旨在促进跨学科研究。

**AI_Comments:** 这篇论文通过系统梳理量子计算与无线通信的结合点，为该新兴领域的跨学科研究提供了清晰的路线图和概念框架。其创新之处在于强调了经典与量子计算的互补性，而非单纯的替代关系，这对于实际工程应用具有重要指导意义。论文内容全面，对于希望进入量子通信领域的无线研究人员而言，具有很高的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管量子计算在特定问题上能提供加速，但在通信系统中找到能产生工程效益的用例仍非易事。本文旨在向通信界介绍量子计算基础，揭示量子与无线系统间的数学和谐，并促进量子信息处理与未来通信系统间的跨学科研究。

**Method:** 本文以通信界熟悉的方式介绍了量子计算的基础知识，概述了容错量子计算的当前限制，并揭示了量子与无线系统之间的数学和谐。此外，通过系统回顾开创性和最先进的研究，提炼了量子加速通信系统研发的常见设计趋势，并强调了经验教训。

**Result:** 关键的见解是经典启发式方法可以优化某些量子参数，这强调了经典计算和量子计算的互补优势。

**Conclusion:** 本文旨在促进量子信息处理与未来通信系统前沿的跨学科研究。

> **ai_Abstract:** 本文探讨了量子计算在无线通信系统中的应用前景。文章向通信领域研究者介绍了量子计算的基础，并揭示了量子与无线系统间的数学关联。通过对现有研究的系统性回顾，论文提炼了量子加速通信系统的设计趋势，并指出经典与量子计算具有互补优势，即经典启发式方法可优化量子参数。该研究旨在推动量子信息处理与未来通信系统领域的跨学科合作。

> **摘要翻译:** 量子计算有望重新定义通信系统的算法基础。尽管量子叠加和纠缠能为特定问题带来二次或指数级的加速，但识别这些优势能够产生工程效益的用例仍然并非易事。本文以通信界熟悉的方式介绍了量子计算的基础知识，概述了容错量子计算的当前限制，并揭示了量子与无线系统之间的数学和谐，这使得该主题对无线研究人员更具吸引力。基于对开创性和最先进研究的系统回顾，我们提炼了量子加速通信系统研发的常见设计趋势，并强调了经验教训。关键的见解是经典启发式方法可以优化某些量子参数，这强调了经典计算和量子计算的互补优势。本文旨在促进量子信息处理与未来通信系统前沿的跨学科研究。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [146] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
> *低空无线网络中传感、通信与控制的协同设计*

*Haijia Jin, Jun Wu, Weijie Yuan, Fan Liu, Yuanhao Cui* | **Category: eess.SP**

**Keywords:** 无人机, 协同设计, SC², 低空无线网络, 优化

**Comment:** 

> **TL;DR:** 本文研究了低空无线网络中多无人机协作系统的传感、通信与控制（SC²）协同设计。通过构建一个加权优化问题，平衡控制稳定性和定位精度，并提出了一种基于交替优化（AO）、凸函数差分（DC）规划和投影梯度下降（PGD）的非凸问题求解方法，以实现资源分配、无人机部署和调度优化。

**AI_Comments:** 本文提出了一种新颖的SC²协同设计框架，用于多无人机系统，这对于未来的物联网和6G应用具有高度相关性。通过结合LQR和FIM的加权优化问题以及利用AO结合DC/PGD来解决复杂的非凸问题，是解决该领域的创新方法。对控制和传感性能之间权衡的分析也提供了一个有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 物联网（IoT）服务的快速发展和向第六代（6G）的演进，使得无人机（UAVs）成为低空无线网络（LAWNs）的关键使能者。为了确保稳定控制和定位未知传感目标，需要对多无人机协作系统中的集成传感、通信和控制（SC²）进行协同设计。

**Method:** 本文首先将控制性能（通过线性二次调节器LQR成本）和定位性能（通过费舍尔信息矩阵FIM的行列式）联合考虑，构建了一个加权优化问题。为了解决这个非凸问题，首先推导了LQR成本的闭式表达式，然后利用交替优化（AO）方法将其分解为一系列子问题，并采用凸函数差分（DC）规划和投影梯度下降（PGD）方法来获得高效的近最优解。此外，还分析了所提出算法的收敛性和计算复杂性。

**Result:** 大量的仿真结果验证了所提出方法相对于基准方案的有效性，并揭示了控制和传感性能之间的权衡。

**Conclusion:** 本文提出的协同设计方法有效地集成了多无人机系统中的传感、通信和控制，并通过仿真结果证明了其有效性，同时揭示了控制稳定性与传感精度之间的性能权衡。

> **ai_Abstract:** 本文针对物联网和6G背景下低空无线网络中多无人机协作系统，提出了集成传感、通信与控制（SC²）的协同设计。研究构建了一个非凸加权优化问题，以平衡控制稳定性（LQR成本）和定位精度（FIM行列式）。为解决该问题，论文提出了一种基于交替优化（AO）的方法，并结合凸函数差分（DC）规划和投影梯度下降（PGD）技术来获得近最优解。仿真结果验证了所提方法的有效性，并揭示了控制与传感性能之间的权衡关系。

> **摘要翻译:** 物联网（IoT）服务的快速发展和向第六代（6G）的演进，已将无人机（UAV）定位为低空无线网络（LAWNs）的关键使能者。这项工作研究了多无人机协作系统中集成传感、通信和控制（SC²）的协同设计，并采用有限块长（FBL）传输。具体而言，无人机持续监测地面机器人的状态并将其观测结果传输给机器人控制器，以确保稳定控制，同时协作定位未知传感目标（ST）。为此，首先通过联合考虑线性二次调节器（LQR）成本和费舍尔信息矩阵（FIM）行列式来衡量控制和定位性能，从而构建了一个加权优化问题。由此产生的问题，即优化资源分配、无人机部署位置和多用户调度，是非凸的。为了规避这一挑战，我们首先推导了LQR成本相对于其他变量的闭式表达式。随后，利用交替优化（AO）方法将非凸优化问题分解为一系列子问题，其中采用凸函数差分（DC）规划和投影梯度下降（PGD）方法来获得高效的近最优解。此外，本文还彻底分析了所提出算法的收敛性和计算复杂性。大量的仿真结果验证了我们提出的方法与基准方案相比的有效性，并揭示了控制和传感性能之间的权衡。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [165] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
> *线性差分麦克风阵列的零点相关波束图测量和信号量化效应分析*

*Shweta Pal, Arun Kumar, Monika Agrawal* | **Category: eess.SP**

**Keywords:** 差分麦克风阵列, 零点深度, 零点宽度, 信号量化, 波束图

**Comment:** 10 pages, 15 Figures, 3 Tables

> **TL;DR:** 本文提出了评估差分麦克风阵列 (DMA) 波束图中零点性能的新测量方法（零点深度和零点宽度），并研究了信号量化对不同阶数和波束图类型DMA性能的影响，通过仿真和实验验证了结果。

**AI_Comments:** 本文的创新点在于首次提出了专门用于评估差分麦克风阵列中零点性能的量化测量方法（零点深度和零点宽度），并系统地研究了信号量化对DMA性能的影响。这对于需要精确控制零点以抑制干扰的应用具有重要意义，填补了现有研究的空白。通过结合理论分析、仿真和实验验证，研究结果具有较高的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献缺乏直接评估零点有效性的测量方法，且未在差分麦克风阵列 (DMA) 的背景下研究零点相关测量。差分麦克风阵列能以较宽的波束峰值换取尖锐的零点，这对于需要消除或衰减干扰源的应用非常有用。

**Method:** 本文提出了表征DMA波束图中零点的新测量方法，即零点深度 (ND) 和零点宽度 (NW)。研究了信号量化对一阶、二阶和三阶线性DMA以及偶极子、心形、超心形和超指向性等不同波束图的影响。推导了任意N阶DMA量化波束形成输出的解析表达式。通过仿真研究了ND随量化位数的变化以及NW随深度水平的变化。在全消声室进行了实验室实验以支持仿真结果。

**Result:** 仿真结果展示了ND随量化位数的变化以及NW随深度水平的变化。实验室实验结果显示出显著的零点深度，证实了实验设置的有效性，并支持了仿真结果。

**Conclusion:** 本文提出了新的零点相关测量方法（零点深度和零点宽度），并成功地将它们应用于差分麦克风阵列。研究表明，这些测量方法对于评估DMA的性能非常有效，并且量化效应在实际应用中需要考虑。

> **ai_Abstract:** 本文针对差分麦克风阵列（DMA）波束图中零点评估的现有空白，提出了零点深度（ND）和零点宽度（NW）两种新的测量方法。研究了这些零点相关测量在DMA中的性能，并分析了信号量化对不同阶数和波束图类型DMA的影响。文章推导了量化波束形成输出的解析表达式，并通过仿真和消声室实验验证了所提方法的有效性及量化效应。

> **摘要翻译:** 差分麦克风阵列（DMA）能够以相对较宽的波束功率图峰值为代价获得尖锐的零点。这可用于需要抵消或衰减干扰源的应用。据我们所知，现有文献缺乏直接评估零点有效性的测量方法，并且尚未在差分麦克风阵列（DMA）的背景下研究零点相关测量。本文通过提出表征其波束功率图中零点的测量方法，为DMA的实用性提供了新的见解。我们通过呈现和评估零点相关测量，即零点深度（ND）和零点宽度（NW），作为相对于波束功率图最大值的深度水平的函数，来研究差分波束形成器的性能。本文还研究了由于数据采集引起的一阶、二阶和三阶线性DMA以及偶极子、心形、超心形和超指向性等不同波束图的信号量化效应。本文推导出了任意N阶DMA量化波束形成输出的解析表达式。本文还给出了ND随量化位数变化以及NW随深度变化关系的仿真结果，并从中得出推论。在全消声室进行了实验室实验以支持仿真结果。测得的波束图显示出显著的零点深度，证实了实验设置的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [183] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
> *基于点云环境的信道知识图谱构建*

*Yancheng Wang, Wei Guo, Guanying Chen, Ye Zhang, Shuguang Cui* | **Category: eess.SP**

**Keywords:** 信道知识图谱, 点云, 环境感知通信, 机器学习, 信道建模

**Comment:** 

> **TL;DR:** 该文提出一种结合点云数据的模型与数据驱动方法，用于构建精确的信道知识图谱，性能优于现有方法。

**AI_Comments:** 本文的创新之处在于利用详细的点云数据和模型与数据相结合的方法，克服了现有CKM构建中环境模型过于简化的局限性。这显著提高了CKM的准确性，对环境感知通信至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有信道知识图谱(CKM)构建方案采用过于简化的环境信息，导致准确性显著降低。

**Method:** 本文提出一种模型驱动与数据驱动相结合的方法来构建CKM，利用点云环境数据和少量带位置标签的信道信息样本。首先，提出一种新颖的点选择器，通过基于不同到达时间（ToAs）构建共焦椭球来识别与多径信道增益相关的点云子集。然后，训练一个神经信道增益估计器，利用真实世界数据集学习选定子集与相应信道增益之间的映射。

**Result:** 对于功率延迟剖面(PDP)的CKM构建，所提方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法实现的7.32 dB。对于接收功率值（即无线电图）的CKM构建，它实现了1.04 dB的RMSE，优于克里金插值法1.68 dB的RMSE。

**Conclusion:** 该方法通过有效利用点云环境数据，显著提高了功率延迟剖面(PDP)和接收功率值(无线电图)的信道知识图谱构建精度。

> **ai_Abstract:** 信道知识图谱(CKM)对环境感知通信至关重要，但现有方法因环境信息简化而准确性不足。本文提出一种结合点云环境数据和信道样本的模型与数据驱动方法来构建CKM。该方法通过点选择器识别相关点云子集，并训练神经信道增益估计器。实验结果表明，所提方法在功率延迟剖面CKM构建中，RMSE为2.95 dB，优于传统射线追踪的7.32 dB；在接收功率值CKM构建中，RMSE为1.04 dB，优于克里金插值的1.68 dB，显著提高了CKM的准确性。

> **摘要翻译:** 信道知识图谱（CKM）为感兴趣区域提供一定程度的信道状态信息（CSI），通过减少频繁CSI获取的开销，成为环境感知通信的关键使能技术。然而，现有的CKM构建方案采用过于简化的环境信息，这显著损害了其准确性。为解决此问题，本文提出一种模型驱动与数据驱动相结合的方法，通过利用点云环境数据以及少量带位置标签的信道信息样本来构建CKM。首先，我们提出了一种新颖的点选择器，通过基于不同到达时间（ToAs）构建一组共焦椭球，来识别包含与多径信道增益相关的环境信息的点云子集。然后，我们利用通过实地测量收集的真实世界数据集（包含环境点云和相应的信道数据），训练了一个神经信道增益估计器，以学习每个选定子集与其相应信道增益之间的映射。最后，实验结果表明：对于功率延迟剖面（PDP）的CKM构建，所提方法实现了2.95 dB的均方根误差（RMSE），显著低于传统射线追踪方法实现的7.32 dB；对于接收功率值（即无线电图）的CKM构建，它实现了1.04 dB的RMSE，超过了克里金插值法1.68 dB的RMSE。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [198] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
> *里德堡原子双频信号与双能级耦合接收特性研究*

*Hao Wu, Chongwu Xie, Xinyuan Yao, Kang-Da Wu, Shanchi Wu, Rui Ni, Guo-Yong Xiang, Chen Gong* | **Category: eess.SP**

**Keywords:** 里德堡原子传感器, 双频信号, 多用户干扰, 误码率, 符号误码率

**Comment:** 

> **TL;DR:** 本文研究了里德堡原子传感器接收双频信号时，由于不同能级信号同时下变频到基带导致的多用户干扰问题，并分析了其相互干扰特性、误码率和符号误码率，并通过实验进行了验证。

**AI_Comments:** 这篇论文解决了里德堡原子传感器在多用户通信中面临的一个关键挑战——多用户干扰，这是由于其独特的信号下变频机制引起的。通过理论分析和实验验证，该研究为理解和减轻这种干扰提供了重要见解，对于推动里德堡原子传感器在实际通信系统中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 里德堡原子传感器在射频测量和多频信号传感方面具有吸引力，但其接收多频信号时，不同频率信号对应不同能级，会同时下变频到基带，导致多用户干扰，这与传统天线多频信号正交不同。因此，需要分析这种干扰特性。

**Method:** 本文分析了不同载波频率的两个射频信号耦合不同能级时的相互干扰特性。引入了基于接收机特性的联合响应系数，分析了一个用户对另一个用户的干扰。分析了耦合两个不同能级的两个信号的误码率（BER）和符号误码率（SER）。并进行了实验验证BER和SER结果。

**Result:** 通过分析和实验，验证了里德堡原子传感器在双频信号接收中，不同能级耦合导致的相互干扰对误码率（BER）和符号误码率（SER）的影响。

**Conclusion:** 本文研究了里德堡原子传感器接收双频信号时，由于不同能级信号同时下变频到基带导致的多用户干扰问题，并通过理论分析和实验验证了其相互干扰特性以及对误码率和符号误码率的影响。

> **ai_Abstract:** 本文研究了里德堡原子传感器在接收双频信号时面临的多用户干扰问题。与传统天线不同，里德堡原子传感器中不同频率的信号会同时下变频到基带，导致干扰。文章分析了两个不同载波频率信号耦合不同能级时的相互干扰特性，引入了联合响应系数，并详细分析了误码率（BER）和符号误码率（SER），最后通过实验验证了理论分析结果。

> **摘要翻译:** 里德堡原子传感器已被用于新型射频（RF）测量技术，其对多频信号的传感能力使其在多用户通信中具有吸引力。然而，与传统天线中多频信号正交不同，原子传感器接收到的对应不同能级的信号会同时下变频到基带，导致多用户干扰。因此，本文分析了两个不同载波频率的射频信号耦合不同能级时的相互干扰特性。我们引入了基于接收机特性的联合响应系数，并分析了一个用户对另一个用户的干扰。我们分析了两个耦合不同能级的信号的误码率（BER）和符号误码率（SER）。我们还进行了实验来验证BER和SER结果。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [210] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
> *对抗训练：增强无线资源分配学习的分布外泛化能力*

*Shengjie Liu, Chenyang Yang* | **Category: eess.SP**

**Keywords:** 对抗训练, 分布外泛化, 无线资源分配, 深度神经网络, 混合预编码

**Comment:** 

> **TL;DR:** 本文提出了一种改进的对抗训练方法，以增强深度神经网络在无线资源分配中对抗分布外变化的泛化能力，并通过混合预编码验证了其有效性。

**AI_Comments:** 本文创新性地将对抗训练应用于无线资源分配中的深度神经网络，以解决其分布外泛化能力差的问题，这对于提升无线通信系统在复杂动态环境下的性能具有重要意义。提出的单步梯度上升方法简化了对抗训练过程。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在资源分配优化中广泛应用，但其性能容易受到训练和测试数据之间分布变化（如信道变化）的影响，导致泛化能力下降。

**Method:** 提出了一种改进的对抗训练 (AT) 方法，以增强无监督训练的深度神经网络的分布外 (OOD) 泛化能力。具体地，重新构建了 AT 以捕捉 OOD 性能下降，并提出了一种单步梯度上升方法进行 AT。该方法通过优化混合预编码进行验证。

**Result:** 仿真结果表明，当仅使用瑞利衰落信道进行训练时，所提出的方法能够增强多种深度神经网络在各种信道分布下的 OOD 性能。

**Conclusion:** 对抗训练可以有效提升深度神经网络在无线资源分配任务中面对信道分布变化的泛化能力。

> **ai_Abstract:** 本文针对深度神经网络在无线资源分配中面临的分布外泛化能力差的问题，提出了一种改进的对抗训练方法。该方法通过重新构建对抗训练并采用单步梯度上升，旨在提升无监督训练的深度神经网络在不同信道分布下的鲁棒性。实验结果验证了所提方法能有效增强多种DNNs的分布外性能。

> **摘要翻译:** 深度神经网络（DNNs）在优化资源分配方面有着广泛的应用。然而，它们的性能容易受到训练和测试数据之间分布变化（例如信道）的影响。在这封信中，我们采用对抗训练（AT）来增强以无监督方式训练的DNNs的分布外（OOD）泛化能力。我们重新构建了AT以捕捉OOD性能下降，并提出了一种用于AT的单步梯度上升方法。所提出的方法通过优化混合预编码得到了验证。仿真结果表明，当仅使用瑞利衰落信道进行训练时，多种DNNs在各种信道分布下都表现出增强的OOD性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [224] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
> *近场通信中基于定位的波束聚焦*

*Nima Mozaffarikhosravi, Prathapasinghe Dharmawansa, Italo Atzeni* | **Category: eess.SP**

**Keywords:** 近场通信, 波束聚焦, 定位, 2D-MUSIC, 6G, 毫米波, 视距传播

**Comment:** 

> **TL;DR:** 针对6G及以上系统近场区域扩展对波束赋形和用户定位方案的影响，本文提出一种基于定位的波束聚焦策略，该策略利用毫米波和亚太赫兹频率下主导的视距传播，并通过分析2D-MUSIC算法进行距离估计。数值结果表明，该方法在视距主导传播、短相干块和高噪声功率条件下更有效。

**AI_Comments:** 这篇论文提出了一种新颖的基于定位的波束聚焦方法，特别适用于6G及以上系统在更高频段（毫米波和亚太赫兹）下近场通信的挑战。其创新点在于将用户定位与波束赋形紧密结合，并利用了高频段特有的LoS传播优势。通过分析2D-MUSIC算法并进行性能比较，研究验证了该方法在特定高噪声和LoS主导环境下的有效性，这对于未来无线通信系统的设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 6G及未来无线通信系统向更高频段发展以及大规模MIMO阵列的应用，将扩展近场区域，进而影响波束赋形和用户定位方案。

**Method:** 提出一种基于定位的波束聚焦策略，利用毫米波和亚太赫兹频率下主导的视距(LoS)传播。为支持此方法，分析了2D-MUSIC算法在简化设置下的距离估计性能。最后，将该方法（通过2D-MUSIC估计位置）与基于导频信道估计的零迫使方法在上行链路总频谱效率方面进行比较。

**Result:** 数值结果表明，所提出的方法在视距主导传播、短相干块以及高载波频率和大带宽下出现的强噪声功率条件下变得更有效。

**Conclusion:** 所提出的基于定位的波束聚焦策略在特定高频通信场景下，尤其是在视距传播和高噪声环境下，表现出优于传统方法的性能，为未来6G及以上系统的波束赋形提供了新思路。

> **ai_Abstract:** 本文针对6G及未来通信中近场区域扩展对波束赋形的影响，提出了一种基于定位的波束聚焦策略。该策略利用毫米波和亚太赫兹频段的视距传播特性，并通过分析2D-MUSIC算法进行距离估计。研究将该方法与传统零迫使方法进行比较，结果表明其在视距主导、短相干块及高噪声功率等条件下具有更高的频谱效率。

> **摘要翻译:** 随着6G及更高版本无线通信系统转向更高频段以及大规模多输入多输出阵列的利用，近场区域将扩大，影响波束赋形和用户定位方案。本文提出一种基于定位的波束聚焦策略，该策略利用毫米波和亚太赫兹频率下主导的视距（LoS）传播。为了支持这种方法，我们通过在天线和用户数量最少、可处理的简化设置中检查2D-MUSIC算法的频谱，分析了其距离估计能力。最后，我们比较了所提出的基于定位的波束聚焦（通过2D-MUSIC估计位置）与基于导频信道估计的零迫使方法在上行链路总频谱效率方面的性能。我们的数值结果表明，所提出的方法在视距主导传播、短相干块以及高载波频率和大带宽下出现的强噪声功率条件下变得更有效。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [236] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
> *集成可移动天线和智能反射面以增强覆盖范围*

*Ying Gao, Qingqing Wu, Weidong Mei, Guangji Chen, Wen Chen, Ziyuan Zheng* | **Category: eess.SP**

**Keywords:** 可移动天线, 智能反射面, 覆盖增强, 最差情况信噪比, 非凸优化

**Comment:** 13 pages, 8 figures, submitted to an IEEE journal for possible
  publication on on May 8, 2025

> **TL;DR:** 本文研究了IRS辅助的可移动天线系统，通过联合优化MA位置、IRS反射系数和发射波束成形来最大化目标区域的无线覆盖，并提出了三种方案和一种算法框架，仿真结果表明MA方案优于FPA方案。

**AI_Comments:** 这篇论文的创新点在于将可移动天线与智能反射面相结合，以解决无线覆盖增强问题，并考虑了性能与成本的权衡。提出的三种方案和通用的算法框架为实际部署提供了指导。尤其对成本效益比的分析，为系统设计提供了实用见解。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过联合优化可移动天线（MA）位置、智能反射面（IRS）反射系数和发射波束成形，最大化多个指定目标区域内的最差情况信号信噪比（SNR），从而扩展无线覆盖。

**Method:** 提出了三种覆盖增强方案：区域自适应MA-IRS方案、区域自适应MA-staIRS方案和共享MA-staIRS方案（其中staIRS指静态IRS）。针对由此产生的非凸优化问题，设计了一个通用的算法框架来高效地解决，尽管是次优解。

**Result:** 1) 所提出的基于MA的方案在各种IRS配置下均优于固定位置天线（FPA）方案，其中区域自适应MA-IRS方案实现了最佳的最差情况信噪比性能。2) 当发射天线数量远少于IRS单元时，区域自适应MA-staIRS方案可能不如基线FPA方案与区域自适应IRS的组合，但增加天线数量可改善。3) 在固定总成本下，最差情况信噪比最大化的最优MA与IRS单元比例与它们单位成本比的倒数成正比。

**Conclusion:** 本文证明了集成可移动天线和智能反射面可以显著增强无线覆盖。通过提出的多种方案和通用的算法框架，论文验证了MA方案相对于FPA方案的性能优势，并提供了关于MA与IRS单元之间成本效益比的实用指导。

> **ai_Abstract:** 本文研究了IRS辅助的可移动天线系统，旨在通过联合优化MA位置、IRS反射系数和发射波束成形来最大化多目标区域的无线覆盖（最差情况信噪比）。为平衡性能与成本，论文提出了三种覆盖增强方案（区域自适应MA-IRS、区域自适应MA-staIRS和共享MA-staIRS）并设计了一个通用的次优算法框架来解决由此产生的非凸优化问题。仿真结果表明，MA方案在覆盖性能上优于FPA方案，特别是区域自适应MA-IRS表现最佳，并揭示了MA与IRS单元的成本效益比例。

> **摘要翻译:** 本文研究了一种智能反射面（IRS）辅助的可移动天线（MA）系统，其中多个IRS与多MA基站协作，将无线覆盖扩展到多个指定目标区域。目标是通过联合优化MA位置、IRS反射系数和发射波束成形，最大化这些区域内所有位置的最差情况信噪比（SNR）。为了在平衡性能与成本权衡的同时实现这一目标，我们提出了三种覆盖增强方案：区域自适应MA-IRS方案、区域自适应MA-staIRS方案和共享MA-staIRS方案，其中staIRS表示反射系数在安装时仅配置一次的静态IRS。这些方案导致具有隐式目标函数的挑战性非凸优化问题，难以找到最优解。为了解决这些问题，我们提出了一种通用的算法框架，可以有效地（尽管是次优地）应用于解决每个问题。仿真结果表明：1）所提出的基于MA的方案在区域自适应和静态IRS配置下均始终优于其基于固定位置天线（FPA）的对应方案，其中区域自适应MA-IRS方案实现了最佳的最差情况信噪比性能；2）由于发射天线通常远少于IRS单元，区域自适应MA-staIRS方案在最差情况信噪比方面可能低于基线FPA方案与区域自适应IRS的组合，但适度增加天线数量可以逆转此趋势；3）在固定总成本下，经验发现最差情况信噪比最大化的最优MA与IRS单元比例与其单位成本比的倒数成正比。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [39] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
> *用于心脏MRI和ECG联合表示的全局和局部对比学习*

*Alexander Selivanov, Philip Müller, Özgün Turgut, Nil Stolt-Ansó, Daniel Rückert* | **Category: eess.IV, cs.AI, cs.CV, eess.SP**

**Keywords:** 对比学习, 心电图, 心脏磁共振, 多模态学习, 心脏功能预测

**Comment:** accepted to MICCAI 2025 (Springer LNCS)

> **TL;DR:** 本研究提出PTACL，一个多模态对比学习框架，通过全局和局部对比损失，将心脏MRI（CMR）的时空信息整合到心电图（ECG）表示中，以提高ECG在心脏表型检索和功能参数预测方面的诊断能力。

**AI_Comments:** PTACL的创新之处在于其结合了全局和局部对比学习策略，有效整合了多模态数据（ECG和CMR）的优势，从而在不增加模型复杂度的前提下，提升了单一模态（ECG）的诊断信息量。这对于成本效益高但信息有限的ECG而言，是一个重要的突破，有望推动非侵入性心脏诊断的发展。该方法在大量真实世界数据上的验证也增加了其可信度。

<details>
  <summary>Details</summary>

**Motivation:** 心电图（ECG）虽成本效益高，但无法直接测量心室容积和射血分数等功能参数，而心脏磁共振（CMR）虽是金标准但昂贵且不易获得。为了弥合这一差距，本研究旨在通过整合CMR信息来增强ECG的表示能力。

**Method:** 本文提出了PTACL（Patient and Temporal Alignment Contrastive Learning），一个多模态对比学习框架。PTACL利用全局患者级对比损失来对齐来自同一患者的ECG和CMR嵌入，同时推开不同患者的嵌入。此外，它还使用局部时间级对比损失，通过对比编码的ECG片段与对应的编码CMR帧，强制在每个患者内部进行细粒度的时间对齐。此方法在不引入新可学习权重的情况下，丰富了ECG表示并促进了模态间信息传递。

**Result:** PTACL在英国生物样本库的27,951名受试者的配对ECG-CMR数据上进行了评估。与基线方法相比，PTACL在两个临床相关任务中取得了更好的性能：1）检索具有相似心脏表型的患者；2）预测CMR衍生的心脏功能参数（如心室容积和射血分数）。

**Conclusion:** PTACL的实验结果突出表明，该框架有潜力通过增强ECG来改进非侵入性心脏诊断。

> **ai_Abstract:** 本研究提出PTACL，一个创新的多模态对比学习框架，旨在通过整合心脏磁共振（CMR）的时空信息来增强心电图（ECG）的诊断能力。该框架结合了全局患者级和局部时间级对比损失，以实现ECG与CMR的联合表示。实验结果表明，PTACL在检索具有相似心脏表型的患者和预测CMR衍生的心脏功能参数方面，优于基线方法，展示了其在非侵入性心脏诊断中的巨大潜力。

> **摘要翻译:** 心电图（ECG）是一种广泛使用、成本效益高的工具，用于检测心脏的电生理异常。然而，它不能直接测量功能参数，如心室容积和射血分数，这些参数对评估心脏功能至关重要。心脏磁共振（CMR）是测量这些参数的金标准，能提供详细的结构和功能洞察，但其成本高昂且可及性较低。为了弥合这一差距，我们提出了PTACL（Patient and Temporal Alignment Contrastive Learning），一个多模态对比学习框架，通过整合来自CMR的时空信息来增强ECG表示。PTACL使用全局患者级对比损失和局部时间级对比损失。全局损失通过将来自同一患者的ECG和CMR嵌入拉近，同时将不同患者的嵌入推开，从而对齐患者级表示。局部损失通过对比编码的ECG片段与对应的编码CMR帧，在每个患者内部强制执行细粒度的时间对齐。这种方法在不引入新的可学习权重的情况下，用超越电活动的诊断信息丰富了ECG表示，并比单独的全局对齐在模态之间传递了更多的洞察。我们在英国生物样本库中来自27,951名受试者的配对ECG-CMR数据上评估了PTACL。与基线方法相比，PTACL在两个临床相关任务中取得了更好的性能：（1）检索具有相似心脏表型的患者；（2）预测CMR衍生的心脏功能参数，如心室容积和射血分数。我们的结果突出了PTACL通过使用ECG增强非侵入性心脏诊断的潜力。代码可在：https://github.com/alsalivan/ecgcmr 获得。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [63] [Building Lightweight Semantic Segmentation Models for Aerial Images Using Dual Relation Distillation](https://arxiv.org/abs/2506.20688)
> *使用双重关系蒸馏构建航空图像的轻量级语义分割模型*

*Minglong Li, Lianlei Shan, Weiqiang Wang, Ke Lv, Bin Luo, Si-Bao Chen* | **Category: eess.IV**

**Keywords:** 双重关系蒸馏, 语义分割, 知识蒸馏, 航空图像, 轻量级模型

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的双重关系蒸馏（DRD）技术，通过传递空间和通道关系，显著提升了轻量级语义分割模型的性能，同时不增加计算开销。

**AI_Comments:** 这项工作在知识蒸馏领域具有创新性，特别是在语义分割任务中引入了同时蒸馏空间和通道关系的双重机制。它有效解决了轻量级模型精度不足的问题，对于资源受限的实际应用具有重要意义。该方法的普适性通过在遥感和通用场景数据集上的验证得到了体现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语义分割CNN模型虽然精度高，但通常模型庞大且推理速度慢，限制了其实际应用。

**Method:** 我们提出了一种新颖的双重关系蒸馏（DRD）技术。该技术将笨重模型（教师）的特征图中的空间和通道关系同时传递给紧凑模型（学生）。具体而言，我们分别为教师和学生模型计算空间和通道关系图，然后通过最小化它们之间的距离来对齐相应的关系图。

**Result:** 在三个分割数据集（包括Vaihingen、Potsdam和Cityscapes）上进行了综合实验。实验结果表明，我们新颖的蒸馏框架可以在不产生额外计算开销的情况下显著提升学生网络的性能。

**Conclusion:** 双重关系蒸馏（DRD）方法能够有效地将教师模型的丰富空间和通道关联信息传递给学生模型，从而显著提高轻量级语义分割模型的准确性，同时保持其高效性。

> **ai_Abstract:** 本文提出了一种名为双重关系蒸馏（DRD）的新型知识蒸馏技术，旨在解决语义分割CNN模型在精度和效率之间的权衡问题。DRD通过将教师模型的特征图中的空间和通道关系同时传递给学生模型，使学生模型更好地模仿教师的特征分布，从而提高其分割准确性。实验证明，该方法在不增加计算开销的情况下，显著提升了轻量级学生模型在多个遥感和通用场景数据集上的性能。

> **摘要翻译:** 近年来，用于语义分割的CNN模型在准确性方面取得了显著进步。然而，这些模型通常很笨重，推理速度慢，这限制了它们的实际应用。为了解决这个问题，知识蒸馏已成为一种有前途的方法，可以在分割精度和效率之间实现良好的权衡。在本文中，我们提出了一种新颖的双重关系蒸馏（DRD）技术，该技术将特征图中的空间和通道关系从笨重模型（教师）转移到紧凑模型（学生）。具体而言，我们分别为教师和学生模型计算空间和通道关系图，然后通过最小化它们之间的距离来对齐相应的关系图。由于教师模型通常比学生模型学习到更多的信息并收集更丰富的空间和通道关联，因此将这些关联从教师转移到学生可以帮助学生在特征分布方面更好地模仿教师，从而提高学生模型的分割准确性。我们在三个分割数据集上进行了综合实验，包括遥感领域中两个广泛采用的基准（Vaihingen和Potsdam数据集）和一个通用场景中的流行基准（Cityscapes数据集）。实验结果表明，我们新颖的蒸馏框架可以在不产生额外计算开销的情况下显著提升学生网络的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [86] [U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs](https://arxiv.org/abs/2506.20689)
> *U-R-VEDA：集成UNET、残差连接、边缘和双重注意力、以及视觉Transformer用于CMR的精确语义分割*

*Racheal Mukisa, Arvind K. Bansal* | **Category: eess.IV, cs.AI, cs.CV, cs.LG, I.4.6; I.2; I.5.2; I.5.1**

**Keywords:** 语义分割, CMR, UNet, 视觉Transformer, 注意力机制

**Comment:** 15 pages, 3 figures

> **TL;DR:** U-R-VEDA是一个新的深度学习模型，结合了UNet、残差连接、边缘检测、双重注意力和视觉Transformer，显著提高了CMR图像的语义分割精度。

**AI_Comments:** 该论文提出了一种创新的UNet变体，通过集成视觉Transformer、多种注意力机制和边缘信息跳跃连接，有效提升了医学图像分割的性能。其亮点在于多组件的融合，解决了传统UNet在特征提取和信息损失方面的局限性。尤其在心脏MR图像分割上的高精度表现，预示着其在临床诊断辅助方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动化医学图像分析对于心脏疾病的诊断和管理至关重要。精确的心脏图像描绘是量化和自动化诊断心脏疾病的必要第一步。

**Method:** 提出了一种名为U-R-VEDA的增强型UNet深度学习模型。该模型整合了卷积变换、视觉Transformer、残差连接、通道注意力、空间注意力以及基于边缘检测的跳跃连接。它通过组合卷积块（嵌入通道和空间注意力）和视觉Transformer提取局部特征及其相互关系。结合边缘信息与通道和空间注意力作为跳跃连接，减少了卷积变换过程中的信息损失。

**Result:** U-R-VEDA在DSC指标上达到了平均95.2%的准确率。该模型在DSC和HD指标上优于其他模型，尤其在描绘右心室和左心室心肌方面表现突出。

**Conclusion:** U-R-VEDA模型显著改善了CMR图像的语义分割，这对于改进医学图像分析至关重要。

> **ai_Abstract:** 本文提出了一种名为U-R-VEDA的深度学习模型，旨在实现心脏磁共振（CMR）图像的精确全自动语义分割。U-R-VEDA是一个增强型UNet模型，创新性地结合了卷积变换、视觉Transformer、残差连接、通道注意力、空间注意力以及基于边缘检测的跳跃连接。通过嵌入双重注意力和利用边缘信息，模型有效提取和保留了特征，减少了信息损失。实验结果表明，U-R-VEDA在DSC指标上达到了95.2%的平均准确率，并优于其他模型，尤其在右心室和左心室心肌的描绘上表现出色，对自动化医学图像分析具有重要意义。

> **摘要翻译:** 人工智能，包括深度学习模型，将在心脏疾病诊断和管理中的自动化医学图像分析中发挥变革性作用。心脏图像的自动化精确描绘是心脏疾病量化和自动化诊断的第一个必要初始步骤。在本文中，我们提出了一种基于深度学习的增强型UNet模型U-R-Veda，该模型集成了卷积变换、视觉Transformer、残差连接、通道注意力、空间注意力以及基于边缘检测的跳跃连接，用于心脏磁共振（CMR）图像的精确全自动语义分割。该模型通过一系列组合卷积块（其中嵌入了通道和空间注意力）和视觉Transformer提取局部特征及其相互关系。卷积块中通道和空间注意力的深度嵌入识别重要的特征及其空间定位。结合边缘信息与通道和空间注意力作为跳跃连接减少了卷积变换过程中的信息损失。整个模型显著改善了CMR图像的语义分割，这对于改进医学图像分析是必要的。本文还介绍了一种双重注意力模块（通道和空间注意力）的算法。性能结果显示，U-R-Veda在DSC指标上达到了平均95.2%的准确率。该模型在DSC和HD指标上优于其他模型所达到的准确率，尤其是在描绘右心室和左心室心肌方面。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [109] [Development of MR spectral analysis method robust against static magnetic field inhomogeneity](https://arxiv.org/abs/2506.20897)
> *开发对静磁场不均匀性具有鲁棒性的MR光谱分析方法*

*Shuki Maruyama, Hidenori Takeshima* | **Category: eess.IV, cs.CV**

**Keywords:** MR光谱分析, 深度学习, B0不均匀性, 建模光谱, 代谢物分析

**Comment:** 11 pages, 6 figures

> **TL;DR:** 本文开发了一种新的深度学习MR光谱分析方法，利用建模光谱来提高在静磁场不均匀性下的分析准确性，并显示出比传统方法更低的误差。

**AI_Comments:** 该论文的创新点在于利用大量“建模光谱”来训练深度学习模型，以克服MR光谱分析中静磁场不均匀性带来的挑战。这种方法有效地增加了训练数据量，并提升了模型对复杂B0不均匀性的鲁棒性，从而显著提高了分析准确性。其重要性在于为临床MR光谱应用提供了一种更可靠、更精确的分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发一种在静磁场B0不均匀性存在下提高光谱分析准确性的方法。

**Method:** 作者提出了一种新的光谱分析方法，利用在模拟光谱上训练的深度学习模型。这些模拟光谱通过B0图和健康人脑的代谢物比例生成，能够一致地表示由B0不均匀性引起的光谱变化。B0图被划分为子区域，分别估计的代谢物和基线成分被平均并整合。通过均方误差（MSEs）和平均绝对百分比误差（MAPEs）评估了所提出方法的性能，并与LCModel进行了比较。

**Result:** 模拟光谱根据B0不均匀性表现出加宽和变窄的光谱峰，并与测量光谱定量接近。使用测量光谱和模拟光谱训练的分析模型，与仅使用测量光谱训练的模型相比，MSEs提高了49.89%；与使用测量光谱和模拟光谱训练的模型相比，MSEs提高了26.66%。性能随着模拟光谱数量从0增加到1,000而提高。该模型在两种B0不均匀性下均显示出比LCModel显著更低的MAPE。

**Conclusion:** 开发了一种使用建模光谱训练的新的光谱分析深度学习模型。结果表明，所提出的方法通过增加光谱训练样本，有潜力提高光谱分析的准确性。

> **ai_Abstract:** 本文提出了一种基于深度学习的MR光谱分析新方法，旨在解决静磁场B0不均匀性导致的光谱分析准确性问题。该方法通过生成并利用大量建模光谱来训练深度学习模型，这些建模光谱能有效模拟B0不均匀性下的光谱变化。实验结果表明，与传统方法LCModel及仅使用测量或模拟光谱训练的模型相比，所提出的方法显著提高了代谢物比例的分析准确性，证明了其在实际应用中提升MR光谱分析质量的潜力。

> **摘要翻译:** 目的：开发一种在静磁场B0不均匀性存在下提高光谱分析准确性的方法。方法：作者提出了一种新的光谱分析方法，利用在模拟光谱上训练的深度学习模型，这些模型能够一致地表示由B0不均匀性引起的光谱变化。这些模拟光谱由健康人脑的B0图和代谢物比例生成。B0图被划分为补丁大小的子区域，分别估计的代谢物和基线成分被平均然后整合。通过视觉和定量评估，将模拟光谱的质量与测量光谱进行了比较。分析模型使用测量光谱、模拟光谱和建模光谱进行训练。所提出方法的性能通过代谢物比例的均方误差（MSEs）进行评估。在两种B0不均匀性下采集的体模光谱分析中，还将代谢物比例的平均绝对百分比误差（MAPEs）与LCModel进行了比较。结果：模拟光谱根据B0不均匀性表现出加宽和变窄的光谱峰，并与测量光谱定量接近。使用测量光谱和建模光谱训练的分析模型，与仅使用测量光谱训练的模型相比，MSEs提高了49.89%；与使用测量光谱和模拟光谱训练的模型相比，MSEs提高了26.66%。性能随着建模光谱数量从0增加到1,000而提高。该模型在两种B0不均匀性下均显示出比LCModel显著更低的MAPE。结论：开发了一种使用建模光谱训练的新的光谱分析深度学习模型。结果表明，所提出的方法通过增加光谱训练样本，有潜力提高光谱分析的准确性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [130] [A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation](https://arxiv.org/abs/2506.21162)
> *将3D超声整合到经皮肝肿瘤消融中的新颖框架*

*Shuwei Xing, Derek W. Cool, David Tessier, Elvis C. S. Chen, Terry M. Peters, Aaron Fenster* | **Category: eess.IV, cs.AI**

**Keywords:** 3D超声, 肝肿瘤消融, 图像配准, 多模态成像, 经皮介入

**Comment:** 11 pages, 5 figures

> **TL;DR:** 该论文提出了一种将3D超声整合到肝肿瘤消融中的新颖框架，其核心是一个2D超声-CT/MRI配准方法，旨在提高准确性和效率。

**AI_Comments:** 该研究的创新之处在于利用3D超声作为2D超声-CT/MRI配准的中间体，有效简化了复杂的配准问题。其报告的准确性（2-4毫米误差）和速度（0.22秒）在临床实时应用中具有显著潜力。这项工作对于弥合先进成像技术与肝肿瘤消融临床干预之间的差距具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D超声成像在增强经皮肝肿瘤消融效果方面显示出显著益处，但肿瘤识别的挑战阻碍了其更广泛的临床应用和整合。

**Method:** 提出了一种将3D超声整合到标准消融工作流程中的新颖框架。关键组成部分是利用3D超声作为中介来降低配准复杂度的临床可行的2D超声-CT/MRI配准方法。同时提出了一种直观的多模态图像可视化技术，以促进配准工作流程的有效验证。

**Result:** 2D超声-CT/MRI配准的标志点距离误差约为2-4毫米，每对图像的运行时间为0.22秒。此外，与刚性配准相比，非刚性配准将平均对齐误差减少了约40%。

**Conclusion:** 所提出的2D超声-CT/MRI配准工作流程被证明是有效的。该整合框架提升了3D超声成像在改善经皮肿瘤消融方面的能力，展示了扩大3D超声在临床干预中治疗作用的潜力。

> **ai_Abstract:** 该论文介绍了一种新颖的框架，旨在将3D超声（US）整合到经皮肝肿瘤消融中，以克服肿瘤识别和临床应用方面的挑战。其核心组件是利用3D超声作为中间体来简化过程的2D超声-CT/MRI配准方法。该框架还包含一种多模态图像可视化技术，用于验证。实验结果表明，2D超声-CT/MRI配准实现了2-4毫米的标志点距离误差，运行速度快，并且非刚性配准显著提高了对齐精度。该框架增强了3D超声在经皮肿瘤消融中的能力，预示着其治疗作用的扩大。

> **摘要翻译:** 3D超声(US)成像在增强经皮肝肿瘤消融效果方面显示出显著益处。其临床整合对于将3D超声转化为治疗领域至关重要。然而，超声图像中肿瘤识别的挑战持续阻碍其更广泛的应用。在这项工作中，我们提出了一种将3D超声整合到标准消融工作流程中的新颖框架。我们提出了一个关键组成部分，一种临床可行的2D超声-CT/MRI配准方法，利用3D超声作为中介来降低配准复杂性。为了促进配准工作流程的有效验证，我们还提出了一种直观的多模态图像可视化技术。在我们的研究中，2D超声-CT/MRI配准实现了约2-4毫米的标志点距离误差，每对图像的运行时间为0.22秒。此外，与刚性配准相比，非刚性配准将平均对齐误差减少了约40%。结果证明了所提出的2D超声-CT/MRI配准工作流程的有效性。我们的整合框架提升了3D超声成像在改善经皮肿瘤消融方面的能力，展示了扩大3D超声在临床干预中治疗作用的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [147] [Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations](https://arxiv.org/abs/2506.21171)
> *在DCT中发掘宝藏：通过利用潜在相关性推进JPEG图像质量增强*

*Jing Yang, Qunliang Xing, Mai Xu, Minglang Qiao* | **Category: eess.IV, cs.CV**

**Keywords:** JPEG质量增强, DCT域, 相关性, 压缩伪影, AJQE

**Comment:** 

> **TL;DR:** 本文提出了一种在DCT域直接增强JPEG图像质量的新方法AJQE，通过利用DCT系数中的潜在相关性，实现了比像素域方法更好的性能和更低的计算成本。

**AI_Comments:** 这项工作创新性在于深入挖掘DCT域的内在相关性，并成功将其应用于JPEG质量增强，解决了长久以来像素域方法计算开销大和DCT域方法性能不足的痛点。其能够使现有像素域模型在DCT域复用，具有很强的实用价值和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** JPEG压缩会引入伪影；现有像素域增强方法计算成本高；现有DCT域方法性能有限。

**Method:** 识别JPEG图像DCT系数中的两种关键相关性，并提出高级DCT域JPEG质量增强（AJQE）方法，充分利用这些相关性，使像素域模型能适应DCT域。

**Result:** 相比像素域方法，AJQE在PSNR上平均提升0.35 dB，增强吞吐量平均增加60.5%。

**Conclusion:** 通过利用DCT系数的内在相关性，可以在DCT域高效且高性能地进行JPEG图像质量增强，且能将现有像素域模型迁移到DCT域。

> **ai_Abstract:** 本文针对JPEG图像压缩伪影问题，提出了一种名为AJQE的先进DCT域质量增强方法。该方法通过识别并利用DCT系数中的关键相关性，克服了现有像素域方法计算成本高和DCT域方法性能有限的缺点。AJQE能够将成熟的像素域模型有效地迁移到DCT域，从而在提升图像质量（PSNR提高0.35 dB）的同时，显著提高增强效率（吞吐量增加60.5%）。

> **摘要翻译:** 联合图像专家组（JPEG）通过量化离散余弦变换（DCT）系数实现数据压缩，这不可避免地引入了压缩伪影。大多数现有的JPEG质量增强方法在像素域操作，受限于解码带来的高计算成本。因此，直接在DCT域对JPEG图像进行增强受到了越来越多的关注。然而，当前的DCT域方法通常表现出有限的性能。为了解决这一挑战，我们识别了JPEG图像DCT系数中的两种关键相关性。基于这一洞察，我们提出了一种高级DCT域JPEG质量增强（AJQE）方法，该方法充分利用了这些相关性。AJQE方法使得许多成熟的像素域模型能够适应到DCT域，以更低的计算复杂度实现卓越的性能。与像素域的对应方法相比，我们方法导出的DCT域模型在PSNR上平均提高了0.35 dB，增强吞吐量平均增加了60.5%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [167] [GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models](https://arxiv.org/abs/2506.21245)
> *GANet-Seg: 基于混合生成模型的脑肿瘤分割对抗学习*

*Qifei Cui, Xinyu Lu* | **Category: eess.IV, cs.CV**

**Keywords:** 脑肿瘤分割, 对抗学习, GAN, Unet, 医疗图像

**Comment:** 

> **TL;DR:** GANet-Seg是一个结合预训练GAN和Unet的脑肿瘤分割新框架，通过对抗学习提升精度，并利用多模态MRI和合成数据增强解决标注数据有限的问题，在BraTS数据集上表现出色。

**AI_Comments:** GANet-Seg的创新之处在于结合了GAN和Unet的优势，并通过对抗学习和合成数据增强有效解决了医疗图像分割中常见的标注数据稀缺问题。其可扩展性及其在BraTS数据集上的优异表现，使其在临床脑肿瘤分割领域具有重要的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 脑肿瘤分割面临标注数据有限的挑战，且需要高精度和鲁棒性。本文旨在开发一种减少对完全标注数据依赖的有效分割方法。

**Method:** 本文提出了GANet-Seg框架，结合预训练GAN和Unet架构。它包含一个全局异常检测模块和一个精细掩膜生成网络，通过对抗损失约束迭代提升分割精度。使用多模态MRI数据和合成图像增强来提高鲁棒性并解决标注数据不足问题。

**Result:** 在BraTS数据集上的实验结果表明，该方法在病灶级Dice和HD95指标上均取得了比基线更高的灵敏度和准确性。

**Conclusion:** GANet-Seg是一种可扩展的脑肿瘤分割方法，能有效减少对完全标注数据的依赖，为临床实践中的实际应用铺平了道路。

> **ai_Abstract:** GANet-Seg是一个创新的脑肿瘤分割框架，它融合了预训练的GAN和Unet模型。该方法通过结合异常检测和精细掩膜生成网络，并利用对抗性损失进行迭代优化，实现了高精度的肿瘤区域识别。为克服标注数据稀缺问题，研究采用了多模态MRI和合成数据增强。在BraTS数据集上的实验证明，GANet-Seg在分割灵敏度和准确性上均优于基线，展现了其在减少数据依赖方面的潜力，适用于实际临床应用。

> **摘要翻译:** 这项工作引入了一个利用预训练GAN和Unet架构进行脑肿瘤分割的新颖框架。通过将全局异常检测模块与精细掩膜生成网络相结合，所提出的模型能够准确识别肿瘤敏感区域，并利用对抗性损失约束迭代地提高分割精度。采用多模态MRI数据和合成图像增强来提高鲁棒性并解决标注数据集有限的挑战。BraTS数据集上的实验结果表明，该方法在病灶级Dice和HD95指标上均表现出比基线更高的灵敏度和准确性。这种可扩展的方法最大限度地减少了对完全标注数据的依赖，为临床环境中的实际应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [184] [Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising](https://arxiv.org/abs/2506.21499)
> *轻量级物理信息零样本超声平面波去噪*

*Hojat Asgariandehkordi, Mostafa Sharifzadeh, Hassan Rivaz* | **Category: eess.IV, cs.CV**

**Keywords:** 超声去噪, 零样本学习, 相干平面波复合, 自监督学习, 物理信息

**Comment:** 

> **TL;DR:** 本文提出了一种轻量级的物理信息零样本去噪框架，用于低角度超声相干平面波复合(CPWC)图像，通过自监督残差学习在不依赖外部训练数据的情况下提高对比度并保留结构。

**AI_Comments:** 该论文提出了一种创新的零样本去噪方法，通过利用超声物理特性进行自监督学习，解决了传统监督方法对大量配对数据和领域特异性微调的需求。其轻量级架构和无需外部训练数据的特点，使其在实际应用中具有高度的适应性和效率，对于临床超声图像质量的提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 超声相干平面波复合(CPWC)虽然能增强图像对比度，但增加角度会显著降低帧率并引入模糊伪影；此外，有限传输角度下的复合图像仍易受噪声影响。

**Method:** 该方法将可用的传输角度分为两个不相交的子集，每个子集用于形成包含更高噪声水平的复合图像。这些新的复合图像通过自监督残差学习方案训练一个深度模型，使其能够抑制非相干噪声同时保留解剖结构。通过物理信息配对，网络可以学习区分不一致的伪影和一致的组织信号。模型采用轻量级架构（仅包含两个卷积层），无需领域特定微调或配对数据。

**Result:** 在仿真、体模和体内数据上的评估表明，与经典和基于深度学习的去噪方法相比，该方法在对比度增强和结构保留方面表现出优越性。

**Conclusion:** 该轻量级物理信息零样本去噪框架能有效提高低角度超声CPWC图像的对比度并保留结构，且具有高适应性和计算效率，无需外部训练数据。

> **ai_Abstract:** 本文提出了一种轻量级的物理信息零样本去噪框架，专门用于解决低角度超声CPWC图像的噪声问题。该方法通过将传输角度分成两组，自监督训练一个深度模型来识别并抑制噪声，同时保留组织结构。其创新之处在于无需外部训练数据或特定微调，且计算成本低。实验结果表明，该方法在对比度增强和结构保留方面优于现有去噪技术。

> **摘要翻译:** 超声相干平面波复合(CPWC)通过结合来自多个转向传输的回波来增强图像对比度。虽然增加角度数量通常能提高图像质量，但这会显著降低帧率，并可能在快速移动目标中引入模糊伪影。此外，复合图像仍然容易受到噪声影响，尤其是在传输次数有限的情况下采集时。我们提出了一种专为低角度CPWC采集定制的零样本去噪框架，该框架无需单独的训练数据集即可增强对比度。该方法将可用的传输角度分为两个不相交的子集，每个子集用于形成包含更高噪声水平的复合图像。然后，这些新的复合图像通过自监督残差学习方案训练一个深度模型，使其能够抑制非相干噪声同时保留解剖结构。由于角度依赖性伪影在子集之间有所不同，而底层组织响应相似，这种物理信息配对允许网络学习将不一致的伪影与一致的组织信号分离。与监督方法不同，我们的模型不需要领域特定的微调或配对数据，使其能够适应不同的解剖区域和采集设置。由于采用了轻量级架构（仅包含两个卷积层），整个管道支持高效训练且计算成本低。在仿真、体模和体内数据上的评估表明，与经典和基于深度学习的去噪方法相比，该方法在对比度增强和结构保留方面表现出优越性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [199] [Exploring the Design Space of 3D MLLMs for CT Report Generation](https://arxiv.org/abs/2506.21535)
> *探索用于CT报告生成的3D多模态大语言模型的设计空间*

*Mohammed Baharoon, Jun Ma, Congyu Fang, Augustin Toma, Bo Wang* | **Category: eess.IV, cs.CV, cs.LG**

**Keywords:** 3D MLLMs, CT报告生成, 放射学报告生成, 设计空间, 知识增强

**Comment:** 

> **TL;DR:** 该论文系统性地探索了用于CT报告生成的3D多模态大语言模型（MLLMs）的设计空间，并引入了两种基于知识的报告增强方法，在MICCAI 2024 AMOS-MM挑战赛中获得第二名。研究发现，LLM大小对放射学报告生成（RRG）影响有限，而分割掩码的使用能提高性能。

**AI_Comments:** 该论文对3D MLLMs在CT报告生成这一实际应用中的设计选择进行了系统性探索。所引入的基于知识的增强方法以及关于LLM大小和体积大小/预训练的经验性发现，为医学图像分析和多模态AI的未来研究和发展提供了宝贵的见解。代码的公开也具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 自动化放射学报告生成（RRG），特别是利用多模态大语言模型（MLLMs）进行3D CT报告生成。

**Method:** 系统地研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术。引入了两种基于知识的报告增强方法。在AMOS-MM数据集的1,687个病例上进行了实验。

**Result:** 1. 基于知识的报告增强方法将GREEN分数性能提高了高达10%。2. 在MICCAI 2024 AMOS-MM挑战赛中获得第二名。3. 在相同训练协议下，RRG在很大程度上与LLM的大小无关。4. 如果原始ViT是在较小体积上进行预训练的，则较大的体积大小并不总能提高性能。5. 使用分割掩码和CT体积一起可以提高性能。

**Conclusion:** 该研究探索了3D MLLMs在CT报告生成中的各种设计选择，强调了基于知识的增强和分割掩码的有效性，并指出LLM大小和预训练条件下的较大体积大小可能不是关键因素。

> **ai_Abstract:** 本文系统性地探索了用于3D CT放射学报告生成的3D多模态大语言模型（MLLMs）的设计空间，研究了包括视觉输入表示、投影器、LLMs和微调技术在内的多个组件。作者提出了两种基于知识的报告增强方法，使GREEN分数提高了10%，并在MICCAI 2024 AMOS-MM挑战赛中获得第二名。主要发现包括LLM大小对性能影响有限，当ViT在较小体积上预训练时，较大体积不总能提高性能，以及使用分割掩码与CT体积结合能显著提高性能。

> **摘要翻译:** 多模态大语言模型（MLLMs）已成为自动化放射学报告生成（RRG）的一种有前景的方法。在这项工作中，我们系统地研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和用于3D CT报告生成的微调技术。我们还引入了两种基于知识的报告增强方法，将GREEN分数性能提高了高达10%，在MICCAI 2024 AMOS-MM挑战赛中获得第二名。我们对AMOS-MM数据集1,687个病例的结果表明，在相同的训练协议下，RRG在很大程度上与LLM的大小无关。我们还表明，如果原始ViT是在较小体积上进行预训练的，那么较大的体积大小并不总能提高性能。最后，我们表明使用分割掩码和CT体积一起可以提高性能。代码已在https://github.com/bowang-lab/AMOS-MM-Solution 公开。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [38] [CodecSlime: Temporal Redundancy Compression of Neural Speech Codec via Dynamic Frame Rate](https://arxiv.org/abs/2506.21074)
> *CodecSlime：基于动态帧率的神经语音编解码器时间冗余压缩*

*Hankun Wang, Yiwei Guo, Chongtian Shao, Bohan Li, Xie Chen, Kai Yu* | **Category: eess.AS, cs.SD**

**Keywords:** 神经语音编解码器, 动态帧率, 时间冗余, 语音压缩, CodecSlime

**Comment:** 16 pages, 5 figures, 9 tables

> **TL;DR:** CodecSlime首次为神经语音编解码器引入动态帧率（DFR），通过压缩时间冗余，显著降低了语音识别错误率，并支持灵活的质量-比特率权衡，优于传统的固定帧率方法。

**AI_Comments:** CodecSlime的创新点在于首次将动态帧率引入神经语音编解码器，以解决时间冗余问题。其插件式、无监督和架构无关的特性使其具有很强的通用性和实用性。通过显著降低WER并提供灵活的质量-比特率权衡，该方法对语音压缩领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前主流的神经语音编解码器采用固定帧率（FFR），为每个等时长片段分配相同数量的token。然而，语音在时间信息密度上是非均匀的，导致在长元音和静音等稳态片段上浪费了大量token。

**Method:** CodecSlime是一种插件式方法，通过支持神经语音编解码器上的动态帧率（DFR）来压缩时间冗余。它是一种无监督且与架构无关的方法，结合了ScheDFR（用于推理）和Melt-and-Cool（用于训练）两个关键创新。

**Result:** 当集成到典型的VQ-GAN编解码器骨干并以40 Hz DFR（约600 bps）运行时，CodecSlime的重建WER相对于具有相同模型架构和相似比特率的传统FFR基线降低了高达46%，同时其他指标也具有竞争力。CodecSlime还实现了重建质量和比特率之间的灵活权衡：单个模型支持多帧率推理，并始终优于相应帧率下的FFR模型。

**Conclusion:** CodecSlime通过引入动态帧率有效解决了神经语音编解码器中的时间冗余问题，显著提高了压缩效率和性能，并提供了灵活的质量-比特率控制，使其成为传统固定帧率方法的优越替代方案。

> **ai_Abstract:** 本文提出了CodecSlime，一种首次应用于神经语音编解码器的插件式动态帧率（DFR）方法，旨在解决固定帧率（FFR）编解码器在语音稳态段中浪费token的问题。该方法是无监督且与架构无关的，结合了ScheDFR和Melt-and-Cool进行推理和训练。实验结果表明，CodecSlime在相似比特率下可将语音识别错误率（WER）降低高达46%，并支持灵活的质量-比特率权衡，在多帧率推理方面持续优于FFR模型。

> **摘要翻译:** 神经语音编解码器已广泛应用于音频压缩和各种下游任务。当前主流的编解码器是固定帧率（FFR）的，它们为每个等时长切片分配相同数量的token。然而，语音在时间信息密度上是固有非均匀的。因此，许多token浪费在长元音和静音等稳态片段上。为了解决这种不匹配，我们提出了CodecSlime，这是一种插件式方法，首次通过支持神经语音编解码器上的动态帧率（DFR）来压缩时间冗余。我们的方法是无监督且与架构无关的，结合了ScheDFR和Melt-and-Cool两项关键创新，分别用于适应推理和训练。当集成到典型的VQ-GAN编解码器骨干并以40 Hz DFR（约600 bps）运行时，CodecSlime的重建WER相对于具有相同模型架构和相似比特率的传统FFR基线降低了高达46%，同时其他指标也具有竞争力。CodecSlime还实现了重建质量和比特率之间的灵活权衡：单个模型支持多帧率推理，并始终优于相应帧率下的FFR模型。音频样本可在https://acadarmeria.github.io/codecslime/获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [62] [Post-training for Deepfake Speech Detection](https://arxiv.org/abs/2506.21090)
> *用于深度伪造语音检测的后训练*

*Wanying Ge, Xin Wang, Xuechen Liu, Junichi Yamagishi* | **Category: eess.AS**

**Keywords:** 深度伪造语音检测, 后训练, 自监督学习, 鲁棒性, 泛化能力

**Comment:** 

> **TL;DR:** 本文提出了一种后训练方法，用于深度伪造语音检测，通过弥合通用预训练和领域特定微调之间的差距，使自监督学习模型适应此任务，并在实验中表现出强大的鲁棒性和泛化能力，超越现有最先进的检测器。

**AI_Comments:** 本文的创新点在于提出了“后训练”这一概念，有效地将通用预训练模型与特定领域任务相结合，显著提升了深度伪造语音检测的性能和泛化能力。其使用的大规模多语言数据集也增强了模型的实用性和鲁棒性。该方法为未来深度伪造检测领域的研究提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过引入一种后训练方法来弥合通用预训练和领域特定微调之间的差距，从而使自监督学习（SSL）模型适用于深度伪造语音检测。

**Method:** 研究人员提出了一种名为 AntiDeepfake 的后训练模型系列，这些模型是使用一个大规模多语言语音数据集开发的，该数据集包含超过 56,000 小时真实语音和 18,000 小时带有各种伪影的语音，涵盖一百多种语言。

**Result:** 实验结果表明，后训练模型对未见过的深度伪造语音已经表现出强大的鲁棒性和泛化能力。当在 Deepfake-Eval-2024 数据集上进一步微调时，这些模型持续超越了不利用后训练的现有最先进检测器。

**Conclusion:** 后训练方法能够显著提高自监督学习模型在深度伪造语音检测任务上的性能、鲁棒性和泛化能力，使其超越现有的最先进方法。

> **ai_Abstract:** 本文提出了一种针对深度伪造语音检测的后训练方法，旨在弥合自监督学习模型预训练和领域特定微调之间的差距。研究人员开发了 AntiDeepfake 模型系列，并使用包含大量多语言真实和伪造语音的数据集进行训练。实验证明，这些后训练模型对未知深度伪造语音具有强大的鲁棒性和泛化能力，并且在进一步微调后，其性能优于现有最先进的检测器。

> **摘要翻译:** 我们引入了一种后训练方法，通过弥合通用预训练和领域特定微调之间的差距，使自监督学习（SSL）模型适应深度伪造语音检测。我们提出了 AntiDeepfake 模型，这是一系列使用大规模多语言语音数据集开发的后训练模型，该数据集包含超过 56,000 小时真实语音和 18,000 小时带有各种伪影的语音，涵盖一百多种语言。实验结果表明，后训练模型对未见过的深度伪造语音已经表现出强大的鲁棒性和泛化能力。当在 Deepfake-Eval-2024 数据集上进一步微调时，这些模型持续超越了不利用后训练的现有最先进检测器。模型检查点和源代码可在网上获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [85] [Performance improvement of spatial semantic segmentation with enriched audio features and agent-based error correction for DCASE 2025 Challenge Task 4](https://arxiv.org/abs/2506.21174)
> *DCASE 2025 挑战任务 4 中，通过丰富音频特征和基于代理的错误校正来改进空间语义分割的性能*

*Jongyeon Park, Joonhee Lee, Do-Hyeon Lim, Hong Kook Kim, Hyeongcheol Geum, Jeong Eun Lim* | **Category: eess.AS, cs.LG**

**Keywords:** 空间语义分割, 音频特征, 代理校正, DCASE 2025, CA-SDRi

**Comment:** DCASE 2025 challenge Task4, 5 pages

> **TL;DR:** 本文提出DCASE 2025挑战任务4的提交系统，通过融合额外音频特征、应用基于代理的标签校正系统和优化训练数据集，显著提升了空间语义分割的性能。

**AI_Comments:** 这篇论文通过多方面创新提升了空间语义分割的性能。它不仅通过引入补充音频特征（如谱滚降和色度）来丰富音频表示，还通过基于代理的错误校正系统有效降低了假阳性，同时通过数据精炼解决了低性能类别的问题。这种多策略结合的方法，特别是对音频特征的深度挖掘和后处理校正，为声场景分析领域提供了有益的参考，展现了其在复杂声学环境下的鲁棒性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 混音音频中包含仅靠梅尔谱图难以捕捉的细微线索，因此需要额外的特征来提供替代视角。此外，需要减少假阳性并提升低性能类别的分类准确性。

**Method:** 1. 将额外的音频特征（谱滚降和色度特征）融入到从梅尔谱特征中提取的嵌入特征中，以改进空间语义分割 (S5) 系统中音频标注模型的分类能力。2. 应用基于代理的标签校正系统对S5系统处理的输出进行校正，以减少假阳性。3. 通过移除不相关样本和整合外部数据来优化训练数据集，以增强低性能类别的分类准确性。

**Result:** 实验表明，所提交的系统与DCASE 2025挑战任务4的基线相比，CA-SDRi相对提升高达14.7%。

**Conclusion:** 通过融合丰富的音频特征、应用代理纠错和优化数据集，可以显著提升空间语义分割的性能，并在DCASE 2025挑战中取得了优异表现。

> **ai_Abstract:** 本文针对 DCASE 2025 挑战任务 4，提出了一种改进空间语义分割性能的系统。该系统通过整合谱滚降和色度等额外音频特征，增强了音频标注模型的分类能力，以捕捉梅尔谱图难以捕捉的微妙线索。此外，引入了基于代理的标签校正系统来减少假阳性，并优化了训练数据集以提升低性能类别的准确性。实验结果显示，该方法使CA-SDRi指标相对于基线提高了高达14.7%。

> **摘要翻译:** 这份技术报告介绍了 DCASE 2025 挑战任务 4 的提交系统。该模型将额外的音频特征（谱滚降和色度特征）融入到从梅尔谱特征中提取的嵌入特征中，以提高声场景空间语义分割 (S5) 系统中音频标注模型的分类能力。这种方法的原因是，混音音频通常包含仅凭梅尔谱图难以捕捉的细微线索。因此，这些额外的特征为模型提供了替代视角。其次，将一个基于代理的标签校正系统应用于 S5 系统处理后的输出。该系统减少了假阳性，提高了最终的类别感知信噪比改善 (CA-SDRi) 指标。最后，我们通过移除不相关样本和整合外部数据来优化训练数据集，以增强低性能类别的分类准确性。也就是说，音频混合物是由有限的数据点生成的；因此，即使少量类外数据点也可能降低模型性能。实验表明，与 DCASE 2025 挑战任务 4 的基线相比，采用这些方法的提交系统使 CA-SDRi 相对提高了高达 14.7%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [108] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
> *混合深度学习与信号处理在低资源环境下阿拉伯语方言识别中的应用*

*Ghazal Al-Shwayyat, Omer Nezih Gerek* | **Category: eess.AS, cs.CL, cs.SD, eess.SP**

**Keywords:** 阿拉伯语方言识别, 混合深度学习, 信号处理, 低资源, MFCC-CNN

**Comment:** 

> **TL;DR:** 本研究探讨了在低资源环境下，结合信号处理和深度学习的混合模型在阿拉伯语方言识别中的应用，其中MFCC+CNN模型表现最佳。

**AI_Comments:** 该研究的创新点在于结合了传统的信号处理技术（如MFCC）与现代深度学习架构（CNN），有效解决了低资源环境下阿拉伯语方言识别的难题。MFCC+CNN模型的优异表现证明了这种混合策略的有效性。其重要性在于为资源匮乏的语言技术领域提供了可行的解决方案，并为未来的研究指明了方向，如采用更大的数据集和更先进的模型。局限性在于数据集大小和标签潜在的区域重叠，这可能影响模型的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 阿拉伯语方言识别面临重大挑战，原因在于阿拉伯语的语言多样性以及大型标注数据集的稀缺性，特别是对于代表性不足的方言。

**Method:** 开发并评估了两种混合模型：(1) 梅尔频率倒谱系数 (MFCC) 结合卷积神经网络 (CNN)，以及 (2) 离散小波变换 (DWT) 特征结合循环神经网络 (RNN)。模型在Common Voice阿拉伯语数据集的方言过滤子集上进行训练，方言标签根据说话人元数据分配。

**Result:** MFCC + CNN架构取得了卓越的性能，准确率达到91.2%，并具有强大的精确度、召回率和F1分数，显著优于小波 + RNN 配置，后者准确率为66.5%。这些发现突出了利用谱特征与卷积模型进行阿拉伯语方言识别的有效性，尤其是在处理有限标注数据时。

**Conclusion:** 该研究为资源受限环境下阿拉伯语方言识别的未来发展奠定了坚实的基础。研究还指出了与数据集大小、标签中潜在的区域重叠以及模型优化相关的局限性，并为未来的研究提供了路线图，包括采用更大的标注语料库、整合自监督学习技术以及探索更先进的神经网络架构。

> **ai_Abstract:** 本文针对低资源环境下阿拉伯语方言识别的挑战，提出并评估了两种结合信号处理与深度学习的混合模型：MFCC+CNN和DWT+RNN。实验结果表明，MFCC+CNN模型表现最优，准确率达91.2%，突显了谱特征与卷积模型在有限数据下的有效性。研究还讨论了数据集局限性及未来改进方向，为该领域研究奠定了基础。

> **摘要翻译:** 阿拉伯语方言识别在语音技术中面临重大挑战，原因在于阿拉伯语的语言多样性以及大型标注数据集的稀缺性，特别是对于代表性不足的方言。本研究调查了结合经典信号处理技术与深度学习架构的混合建模策略，以解决低资源场景下的这一问题。开发并评估了两种混合模型：(1) 梅尔频率倒谱系数 (MFCC) 结合卷积神经网络 (CNN)，以及 (2) 离散小波变换 (DWT) 特征结合循环神经网络 (RNN)。这些模型在Common Voice阿拉伯语数据集的方言过滤子集上进行训练，方言标签根据说话人元数据分配。实验结果表明，MFCC + CNN架构取得了卓越的性能，准确率达到91.2%，并具有强大的精确度、召回率和F1分数，显著优于小波 + RNN 配置，后者准确率为66.5%。这些发现突出了利用谱特征与卷积模型进行阿拉伯语方言识别的有效性，尤其是在处理有限标注数据时。该研究还指出了与数据集大小、标签中潜在的区域重叠以及模型优化相关的局限性，为未来的研究提供了路线图。进一步改进的建议包括采用更大的标注语料库、整合自监督学习技术以及探索更先进的神经网络架构，例如Transformer。总的来说，这项研究为资源受限环境下阿拉伯语方言识别的未来发展奠定了坚实的基础。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [129] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
> *ThinkSound：多模态大型语言模型中用于音频生成与编辑的思维链推理*

*Huadai Liu, Jialei Wang, Kaicheng Luo, Wen Wang, Qian Chen, Zhou Zhao, Wei Xue* | **Category: eess.AS, cs.CV, cs.SD**

**Keywords:** 思维链, 多模态大语言模型, 音频生成, 视频到音频, 音频编辑

**Comment:** 

> **TL;DR:** ThinkSound是一个利用思维链推理的多模态大语言模型框架，用于视频的逐步、交互式音频生成和编辑，并在视频到音频生成上达到了SOTA性能。

**AI_Comments:** ThinkSound的创新之处在于将思维链推理引入多模态大语言模型，用于视频音频生成和编辑，模仿专业人士的推理过程，实现了分阶段、交互式的控制，显著提升了音频的保真度和与视觉内容的匹配度。这种分阶段、可交互的框架是其主要亮点。引入AudioCoT数据集也对未来研究有重要贡献，为该领域提供了新的基准和研究资源。

<details>
  <summary>Details</summary>

**Motivation:** 虽然端到端视频到音频生成已大大改进，但生成能真实捕捉视觉内容细微差别的高保真音频仍然具有挑战性。这需要像创意产业专业人士一样，对视觉动态、声学环境和时间关系等进行复杂的推理。

**Method:** 提出ThinkSound框架，利用思维链（CoT）推理实现视频的逐步、交互式音频生成和编辑。该方法将过程分解为三个互补阶段：创建语义连贯声景的基础拟音生成、通过精确用户交互实现交互式以对象为中心的细化、以及自然语言指令引导的定向编辑。在每个阶段，多模态大语言模型生成与上下文对齐的CoT推理，指导统一的音频基础模型。此外，引入AudioCoT数据集，包含结构化推理标注，建立了视觉内容、文本描述和声音合成之间的联系。

**Result:** ThinkSound在视频到音频生成方面，无论是在音频指标还是CoT指标上都达到了最先进的性能，并在分布外Movie Gen Audio基准测试中表现出色。

**Conclusion:** ThinkSound通过引入思维链推理和分阶段处理，显著提升了视频到音频生成和编辑的质量和交互性，达到了最先进的性能，解决了现有方法在生成高保真音频方面的挑战。

> **ai_Abstract:** ThinkSound是一个创新的框架，它利用多模态大型语言模型的思维链（CoT）推理，实现了视频的逐步、交互式音频生成和编辑。该方法将复杂的音频生成过程分解为基础拟音生成、交互式对象细化和自然语言引导编辑三个阶段，每个阶段都由上下文对齐的CoT推理指导统一的音频基础模型。为支持此研究，还引入了AudioCoT数据集。实验证明，ThinkSound在视频到音频生成方面达到了最先进的性能，尤其在处理复杂和分布外数据时表现优异，有效解决了生成高保真视频音频的挑战。

> **摘要翻译:** 虽然端到端视频到音频生成已大大改进，但生成能真实捕捉视觉内容细微差别的高保真音频仍然具有挑战性。就像创意产业的专业人士一样，这种生成需要对视觉动态、声学环境和时间关系等项目进行复杂的推理。我们提出了ThinkSound，这是一个新颖的框架，它利用思维链（CoT）推理来实现视频的逐步、交互式音频生成和编辑。我们的方法将过程分解为三个互补阶段：创建语义连贯声景的基础拟音生成、通过精确用户交互实现交互式以对象为中心的细化、以及自然语言指令引导的定向编辑。在每个阶段，多模态大型语言模型生成与上下文对齐的CoT推理，指导统一的音频基础模型。此外，我们引入了AudioCoT，一个包含结构化推理标注的综合数据集，建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound在视频到音频生成方面，无论是在音频指标还是CoT指标上都达到了最先进的性能，并在分布外Movie Gen Audio基准测试中表现出色。演示页面可在https://ThinkSound-Demo.github.io获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [42] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
> *面向表格数据的概率问答*

*Chen Shen, Sajjadur Rahman, Estevam Hruschka* | **Category: cs.CL, 68T50, 68T37, I.2.7**

**Keywords:** 概率问答, 表格数据, 贝叶斯网络, 大型语言模型, LUCARIO

**Comment:** 

> **TL;DR:** 本文提出了LUCARIO基准和框架，用于处理大型表格数据上的概率问答，通过从表格中推断贝叶斯网络并将自然语言查询转换为概率查询，结合大型语言模型生成答案，显著优于基线方法。

**AI_Comments:** 该论文的创新点在于提出了一个专门针对表格数据上概率问答的新基准和框架，填补了现有NL2SQL系统在不确定性推理方面的空白。其结合贝叶斯网络和大型语言模型的混合方法，为处理复杂概率查询提供了有效途径，展示了符号推理与神经网络结合的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的表格数据问答方法（如NL2SQL系统）在事实性问题上表现良好，但对于需要不确定性推理的概率性问题表现不佳。

**Method:** 本文引入了一个新的基准LUCARIO和一个用于大型表格数据上概率问答的框架。该方法从表格中推断贝叶斯网络，将自然语言查询转换为概率查询，并使用大型语言模型（LLMs）生成最终答案。

**Result:** 实证结果表明，与基线方法相比有显著改进，突出了混合符号-神经推理的优势。

**Conclusion:** 混合符号-神经推理的方法在处理表格数据的概率问答方面表现出显著优势，能够有效解决现有方法在不确定性推理上的不足。

> **ai_Abstract:** 本文针对现有表格数据问答系统在处理不确定性概率问题上的不足，提出了一个名为LUCARIO的新基准和框架。该框架通过从表格数据中构建贝叶斯网络，将自然语言问题转化为概率查询，并结合大型语言模型生成答案。实验结果表明，该混合符号-神经推理方法在概率问答任务上显著优于现有基线。

> **摘要翻译:** 当前针对表格数据的问答（QA）方法，例如NL2SQL系统，在答案可以直接从表格中检索的事实性问题上表现良好。然而，它们在需要不确定性推理的概率性问题上表现不足。在本文中，我们引入了一个新的基准LUCARIO和一个用于大型表格数据上概率问答的框架。我们的方法从表格中推断贝叶斯网络，将自然语言查询转换为概率查询，并使用大型语言模型（LLMs）生成最终答案。实证结果表明，与基线方法相比有显著改进，突出了混合符号-神经推理的优势。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [66] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
> *大型语言模型的多语言功能评估*

*Victor Ojewale, Inioluwa Deborah Raji, Suresh Venkatasubramanian* | **Category: cs.CL**

**Keywords:** 多语言评估, 大型语言模型, 功能基准, 鲁棒性, 跨语言

**Comment:** 

> **TL;DR:** 本文创建了新的多语言功能基准测试，以更好地评估大型语言模型在多语言环境下的实际性能和鲁棒性，发现现有静态基准的评估效果差异显著。

**AI_Comments:** 这项研究通过引入“功能性”评估的概念，为大型语言模型的多语言能力评估提供了一个更实用和深入的视角，弥补了传统静态基准的不足。其创新之处在于构建了跨语言的功能性测试集，并量化了不同静态基准与实际功能性能之间的差距。这对于理解和改进多语言LLM的实际应用性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的多语言能力评估通常依赖静态数据基准，但这些评估往往无法充分理解模型在多语言环境下的实际性能和鲁棒性。

**Method:** 研究人员通过将现有的英语功能基准模板翻译成法语、西班牙语、印地语、阿拉伯语和约鲁巴语五种额外语言，创建了多语言功能基准测试：跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval）。

**Result:** 结果显示，一些静态多语言基准比其他基准更能反映功能性能（例如，M-GSM与CL-GSM Symbolic之间在英语、法语和西班牙语中的性能分别下降了24%、17%和18%；Belebele与CL-IFEval之间在各语言中性能下降了15-24%；而M-MMLU与CL-IFEval之间仅下降了0.5%-3%）。同时，模型在不同语言间的鲁棒性差异显著，其中阿拉伯语和英语在评估迭代中表现最为稳定。

**Conclusion:** 该研究通过引入多语言功能基准测试，揭示了现有静态多语言评估的局限性，并提供了对大型语言模型在不同语言环境下实际性能和鲁棒性更深入的理解。结果表明，不同静态基准捕获功能性能的程度不同，且模型的跨语言鲁棒性存在显著差异。

> **ai_Abstract:** 本研究旨在解决现有静态基准测试在评估大型语言模型多语言功能和鲁棒性方面的不足。为此，作者创建了两个新的多语言功能基准测试：CL-GSM Symbolic和CL-IFEval，通过将英语模板翻译成五种不同语言。实验结果表明，不同静态基准对功能性能的捕获能力差异显著，且模型的跨语言鲁棒性表现不一，其中阿拉伯语和英语表现最为稳定。

> **摘要翻译:** 大型语言模型的多语言能力通常通过Belebele、M-MMLU和M-GSM等静态数据基准进行评估。然而，这些评估往往无法充分理解模型在多语言环境下的实际性能和鲁棒性。为此，我们通过将现有的英语功能基准模板翻译成五种额外的语言，包括法语、西班牙语、印地语、阿拉伯语和约鲁巴语，创建了多语言功能基准测试——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval）。我们的结果显示，一些静态多语言基准比其他基准更能密切地反映功能性能（即，在不同模型中，M-GSM与CL-GSM Symbolic之间在英语、法语和西班牙语中的性能分别下降了24%、17%和18%；同样，Belebele与CL-IFEval之间在各语言中性能下降了15-24%，而M-MMLU与CL-IFEval之间仅下降了0.5%-3%）。类似地，我们发现模型在不同语言间的鲁棒性差异显著，某些语言（例如阿拉伯语、英语）在评估迭代中表现最为稳定。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [89] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
> *构思-执行差距：LLM生成与人类研究想法的执行结果*

*Chenglei Si, Tatsunori Hashimoto, Diyi Yang* | **Category: cs.CL, cs.AI, cs.CY, cs.HC, cs.LG**

**Keywords:** 大型语言模型, 科研想法生成, 构思-执行差距, 研究评估, 人工智能局限性

**Comment:** main paper is 14 pages

> **TL;DR:** 本研究发现，尽管大型语言模型（LLM）生成的科研想法在构思阶段可能被认为更具新颖性，但在经过专家执行后，其效果显著低于人类生成的想法，揭示了LLM在生成真正有效研究想法方面的局限性。

**AI_Comments:** 这项研究非常重要，因为它揭示了当前LLM在科研辅助方面的深层局限性。虽然LLM能够生成看似新颖的构思，但其有效性在实际执行中却大打折扣，这对于依赖LLM进行科研创新的领域是一个重要的警示。研究方法严谨，通过专家执行和盲审确保了结果的可靠性。其创新点在于从“构思”到“执行”的完整链条进行验证，而非仅仅停留在构思阶段的评价。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在加速科学研究流程方面展现出潜力，尤其是在生成新颖研究想法方面。然而，一个好的想法不仅要新颖，还应在执行后产生更好的研究成果。本研究旨在检验AI生成的想法是否能带来更好的研究成果，以弥补构思与执行之间的差距。

**Method:** 本研究招募了43位专家研究员，随机分配执行由专家撰写或由LLM生成的想法。每位专家投入超过100小时实施想法，并撰写一份4页的短论文记录实验。所有执行后的项目均由专家NLP研究员进行盲审。通过比较想法在执行前后的评估分数来分析结果。

**Result:** 与执行前相比，LLM生成的想法在执行后，其分数在所有评估指标（新颖性、兴奋度、有效性和总体；p < 0.05）上均显著下降，且降幅远大于专家撰写的想法，从而弥合了在构思阶段观察到的LLM与人类想法之间的差距。在比较执行研究的汇总评审分数时，甚至发现在许多指标上排名发生了逆转，人类想法得分高于LLM想法。

**Conclusion:** 本研究揭示的构思-执行差距突出了当前大型语言模型在生成真正有效的研究想法方面的局限性，以及在缺乏执行结果的情况下评估研究想法的挑战。

> **ai_Abstract:** 本研究旨在探究大型语言模型（LLM）生成的科研想法在实际执行后的效果。通过一项实验，43位专家研究员分别执行LLM或人类生成的想法，并由独立专家进行盲审。结果显示，尽管LLM想法在构思阶段可能显得新颖，但在执行后，其表现显著劣于人类想法，且分数下降幅度更大。这表明当前LLM在生成真正有效的研究想法方面存在局限性，并强调了在没有实际执行结果的情况下评估研究想法的挑战。

> **摘要翻译:** 大型语言模型（LLM）在加速科学研究流程方面展现出潜力。这一过程的一个关键能力是生成新颖的研究想法，并且先前的研究发现，在某些情况下，LLM生成的想法被判断为比人类专家想法更具新颖性。然而，一个好的想法不应仅仅看起来新颖，它还应在执行后产生更好的研究成果。为了测试AI生成的想法是否能带来更好的研究成果，我们进行了一项执行研究，招募了43位专家研究员来执行随机分配的想法，这些想法要么由专家撰写，要么由LLM生成。每位专家投入超过100小时实施想法，并撰写了一份4页的短论文来记录实验。所有执行后的项目都由专家NLP研究员进行盲审。比较想法在执行前后的评审分数，LLM生成的想法在所有评估指标（新颖性、兴奋度、有效性和总体；p < 0.05）上均显著下降，降幅远大于专家撰写的想法，从而弥合了在构思阶段观察到的LLM与人类想法之间的差距。在比较执行研究的汇总评审分数时，我们甚至观察到，在许多指标上排名发生了逆转，人类想法得分高于LLM想法。这种构思-执行差距突出了当前LLM在生成真正有效的研究想法方面的局限性，以及在缺乏执行结果的情况下评估研究想法的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [112] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
> *MultiFinRAG：一个用于金融问答的优化多模态检索增强生成（RAG）框架*

*Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh* | **Category: cs.CL, cs.AI, cs.CE, 68T50, 68T07 (Primary) 68P20, 91G15, 91G70, 68U10 (Secondary), I.2.7; I.2.10; H.3.3; H.2.8; I.5.4; J.1**

**Keywords:** MultiFinRAG, 多模态RAG, 金融问答, 检索增强生成, 跨模态推理

**Comment:** Preprint Copy

> **TL;DR:** MultiFinRAG是一个为金融问答设计的多模态RAG框架，通过优化多模态信息提取和检索策略，在商品硬件上比ChatGPT-4o在复杂金融问答任务上提高了19%的准确率。

**AI_Comments:** MultiFinRAG的创新之处在于其专门为金融领域设计的多模态处理和检索策略，有效解决了金融文档的复杂性问题。通过结合轻量级多模态LLM进行信息提取和分层检索，它显著提高了跨模态推理能力。该框架在商品硬件上实现了优于ChatGPT-4o的性能，凸显了其在实际部署中的潜力和成本效益。

<details>
  <summary>Details</summary>

**Motivation:** 金融文档（如10-K、10-Q和投资者演示）篇幅巨大且包含文本、表格和图像等多种模态，回答这些内容的问题需要跨模态联合推理。传统的大型语言模型（LLMs）和检索增强生成（RAG）管道因令牌限制、布局丢失和碎片化的跨模态上下文而难以应对。

**Method:** MultiFinRAG首先通过将表格和图像分组并发送到轻量级、量化的开源多模态LLM进行多模态提取，生成结构化JSON输出和简洁文本摘要。然后，这些输出与叙述性文本一起通过模态感知相似性阈值进行嵌入和索引，以实现精确检索。最后，采用分层回退策略，根据需要动态地从仅文本上下文升级到文本+表格+图像上下文，从而实现跨模态推理并减少不相关上下文。

**Result:** MultiFinRAG在包含文本、表格、图像和组合多模态推理的复杂金融问答任务上，即使在商品硬件上运行，也比ChatGPT-4o（免费版）的准确率高出19个百分点。

**Conclusion:** MultiFinRAG通过其优化的多模态信息处理和检索策略，显著提升了金融领域复杂问答的准确性，超越了现有先进模型，证明了其在实际应用中的有效性。

> **ai_Abstract:** MultiFinRAG是一个针对金融问答优化的多模态检索增强生成（RAG）框架。它旨在解决传统LLMs和RAG在处理包含文本、表格和图像的复杂金融文档时面临的挑战，如令牌限制和跨模态上下文碎片化。MultiFinRAG通过轻量级多模态LLM进行多模态信息提取，生成结构化JSON和文本摘要，并结合叙述文本进行模态感知索引。其分层回退检索策略允许根据需要动态整合跨模态上下文。实验结果表明，MultiFinRAG在商品硬件上运行，在复杂金融问答任务上比ChatGPT-4o的准确率高出19个百分点。

> **摘要翻译:** 金融文档——例如10-K、10-Q和投资者演示——长达数百页，并结合了多种模态，包括密集的叙述性文本、结构化表格和复杂的图形。对这些内容进行问题回答通常需要跨模态的联合推理，这由于令牌限制、布局丢失和碎片化的跨模态上下文而使传统的大型语言模型（LLMs）和检索增强生成（RAG）管道面临压力。我们引入了MultiFinRAG，一个专为金融问答而构建的检索增强生成框架。MultiFinRAG首先通过将表格和图形图像分批并发送到轻量级、量化的开源多模态LLM进行多模态提取，生成结构化的JSON输出和简洁的文本摘要。这些输出与叙述性文本一起，通过模态感知相似性阈值进行嵌入和索引，以实现精确检索。然后，当需要时，分层回退策略会动态地从仅文本上下文升级到文本+表格+图像上下文，从而实现跨模态推理，同时减少不相关的上下文。尽管在商品硬件上运行，MultiFinRAG在涉及文本、表格、图像和组合多模态推理的复杂金融问答任务上，比ChatGPT-4o（免费版）的准确率高出19个百分点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [133] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
> *揭示大型语言模型中隐藏的暴力倾向：通过行为短篇故事进行人口统计学分析*

*Quintin Myers, Yanjun Gao* | **Category: cs.CL, cs.AI**

**Keywords:** 大型语言模型, 暴力倾向, 偏见, 人口统计学, 行为短篇故事

**Comment:** Under review

> **TL;DR:** 本研究评估了大型语言模型（LLMs）处理道德模糊情景的能力，发现其表面输出与内部暴力倾向不符，且暴力倾向因人口统计学特征而异，与人类行为研究结果相悖。

**AI_Comments:** 该论文通过将经过验证的社会科学工具（VBVQ）应用于LLM评估，展现了创新性，超越了传统的内容审核方法，深入探讨了模型的道德推理和潜在偏藏。其重要性在于揭示了关键且反直觉的发现：LLMs可能在内部倾向于暴力，尽管其输出表面上看似无害，且其偏见与已知的人类人口统计学模式相悖。这揭示了LLMs在应用于内容检测等敏感领域时存在的显著局限性，敦促对LLMs的伦理对齐和内部机制进行更深入的研究。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）被广泛应用于在线暴力内容的检测和响应，但它们对道德模糊的现实世界情景进行推理的能力尚未得到充分检验。本研究旨在评估LLMs的这种能力，并分析其潜在的偏见。

**Method:** 研究首次使用经社会科学验证的暴力行为短篇故事问卷（VBVQ）来评估LLMs。通过基于角色的提示，在美国境内改变种族、年龄和地理身份，以评估潜在偏见。在统一的零样本设置下，评估了来自不同地缘政治和组织背景的六个LLM。

**Result:** 1. LLMs的表面文本生成常常与其内部对暴力反应的偏好存在差异。2. 它们的暴力倾向因人口统计学特征而异，这经常与犯罪学、社会科学和心理学中已有的发现相矛盾。

**Conclusion:** 大型语言模型在处理道德模糊情景时，其内部可能存在与表面输出不符的暴力倾向，并且这些倾向表现出与人类社会科学研究相悖的人口统计学偏见，这表明在将其应用于敏感领域时需要谨慎。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在理解和应对道德模糊的现实世界暴力情景方面的能力，指出其相关能力尚未得到充分检验。研究首次采用经社会科学验证的暴力行为短篇故事问卷（VBVQ）来评估LLMs，并通过基于角色的提示在美国境内引入了种族、年龄和地理身份等人口统计学变量，以评估潜在偏见。研究在统一的零样本设置下评估了六个LLMs，结果发现LLMs的表面文本生成与其内部对暴力反应的偏好存在差异，且其暴力倾向因人口统计学特征而异，这经常与犯罪学、社会科学和心理学中已有的发现相矛盾。

> **摘要翻译:** 大型语言模型（LLM）越来越多地被提议用于在线暴力内容的检测和响应，但它们对道德模糊的现实世界情景进行推理的能力仍未得到充分检验。我们提出了第一个使用经过验证的社会科学工具来评估LLM的研究，该工具旨在衡量人类对日常冲突的反应，即暴力行为短篇故事问卷（VBVQ）。为了评估潜在偏见，我们引入了基于角色的提示，其中在美国境内改变了种族、年龄和地理身份。在统一的零样本设置下，评估了来自不同地缘政治和组织背景的六个LLM。我们的研究揭示了两个关键发现：（1）LLM的表面文本生成通常与其内部对暴力反应的偏好存在差异；（2）它们的暴力倾向因人口统计学特征而异，这经常与犯罪学、社会科学和心理学中已有的发现相矛盾。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [150] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
> *少做决策，多做沟通：论医学领域端到端事实核查的构念效度*

*Sebastian Joseph, Lily Chen, Barry Wei, Michael Mackert, Iain J. Marshall, Paul Pu Liang, Ramez Kouzy, Byron C. Wallace, Junyi Jessy Li* | **Category: cs.CL**

**Keywords:** 事实核查, 医学, 端到端系统, 沟通, 构念效度

**Comment:** 

> **TL;DR:** 医学领域的端到端事实核查系统因其在连接声明与证据、处理歧义和主观性方面的挑战而未被充分利用。研究表明，事实核查应被视为一个交互式沟通问题，而非简单的端到端过程。

**AI_Comments:** 该论文对医学领域的事实核查提出了重要的批判性视角，指出当前端到端方法的局限性。其创新之处在于将事实核查重新定义为一个交互式沟通问题，这为未来的研究和系统开发提供了新的方向。该研究的发现对于理解自动化系统在复杂、高风险领域（如医疗保健）中的应用瓶颈具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自动化事实核查技术取得了进步，并且在公共卫生和医学领域的需求日益增长（由于医疗决策的高风险性质和评估大量医学文献的挑战），但现有的端到端事实核查系统仍未被充分利用。研究旨在理解为何这些系统在医学领域中未能被广泛采用。

**Method:** 本研究首次通过调查临床专家如何综合医学证据来核实社交媒体上的真实声明，以探究端到端事实核查的上限。

**Result:** 研究揭示了在医学领域应用端到端事实核查的根本挑战：难以将网络上的声明与临床试验形式的科学证据联系起来；不明确的声明与不匹配的意图混合导致的歧义；以及固有的主观真实性标签。

**Conclusion:** 研究认为，事实核查应被视为一个交互式沟通问题来处理和评估，而非一个简单的端到端过程。

> **ai_Abstract:** 本研究探讨了医学领域端到端事实核查系统未被广泛采用的原因。通过分析临床专家如何核实社交媒体上的医疗声明，研究揭示了现有系统在连接声明与证据、处理歧义和主观性方面的根本挑战。作者提出，事实核查应被视为一个交互式沟通问题，而非一个端到端过程。

> **摘要翻译:** 技术进步使得曾被认为是挑战性的任务取得了具体进展，例如自动化事实核查。由于医疗决策的高风险性质以及批判性评估大量多样化医学文献的挑战，在公共卫生和医学领域采用这些系统的兴趣日益增长。循证医学与每个人息息相关，但其本质是高度技术性的，导致大多数用户的医学素养不足以充分驾驭该领域。医学沟通中的此类问题为端到端事实核查代理奠定了基础：针对当前的医学文献核查声明并返回一个有证据支持的结论。然而，此类系统仍未被广泛使用。为了理解这一点，我们提出了第一个研究，通过综合医学证据来检查临床专家如何核实社交媒体上的真实声明。在寻找这个上限的过程中，我们揭示了在医学领域应用端到端事实核查的根本挑战：难以将网络上的声明与临床试验形式的科学证据联系起来；不明确的声明与不匹配的意图混合导致的歧义；以及固有的主观真实性标签。我们认为，事实核查应被视为一个交互式沟通问题来处理和评估，而非一个端到端过程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [170] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
> *优化下游任务的语言模型：一个后训练视角*

*Zhengyan Shi* | **Category: cs.CL, cs.AI**

**Keywords:** 语言模型优化, 后训练, 下游任务, 参数高效微调, 持续预训练

**Comment:** PhD Thesis

> **TL;DR:** 本论文提出了一系列后训练方法，旨在提高语言模型在下游任务中的适应性、效率和鲁棒性，解决了现有微调方法的局限性。

**AI_Comments:** 该论文从后训练的角度，系统性地解决了大型语言模型在下游任务适应性上的关键挑战，特别是针对现有微调方法中存在的计算成本高、数据利用不足和过拟合等问题。其创新点在于提出了一系列综合性的方法，包括利用无标注数据的持续预训练、参数高效微调以及改进的监督微调，这些方法协同作用，显著提升了模型的效率、鲁棒性和泛化能力。此外，引入新的评估方法也提升了对模型能力的全面评估。这项工作对于推动语言模型在实际应用中的落地具有重要意义，并对实现通用人工智能的目标做出了贡献。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型在NLP中表现出色，但将其高效、鲁棒地适应特定任务仍然具有挑战性。随着模型规模和复杂性的增长，在标注数据上进行微调常常导致未标注数据利用不足、在小型任务特定数据集上过拟合以及产生显著的计算成本。这些限制阻碍了语言模型在实际开放式语言任务中的应用。

**Method:** 本论文提出了一系列优化语言模型以适应下游应用的方法：首先，探索从无标注数据中提取任务相关知识的策略，引入了一种超越现有半监督方法的持续预训练技术。其次，提出了一种参数高效的微调方法，显著降低了内存和计算成本，同时保持了竞争力。此外，还引入了改进的监督微调方法，使语言模型能够更好地遵循指令，尤其是在标注数据稀缺时，从而提高其在包括开放式生成在内的多种NLP任务中的性能。最后，开发了新的评估方法和基准，例如多跳空间推理任务，以更全面地评估语言模型的能力和适应性。

**Result:** 通过在各种NLP任务中进行广泛的实证研究，结果表明这些方法显著提高了语言模型的鲁棒性、效率和泛化能力，使其能够更好地适应广泛的应用。

**Conclusion:** 这些进展标志着在构建更鲁棒、更高效的语言模型方面迈出了重要一步，使我们更接近通用人工智能的目标。

> **ai_Abstract:** 本论文针对语言模型在下游任务适应性方面的挑战，提出了一系列后训练方法。这些方法包括利用无标注数据的持续预训练、参数高效的微调、改进的监督微调以处理数据稀缺情况，以及新的评估基准。实证研究表明，这些方法显著提升了语言模型的鲁棒性、效率和泛化能力，使其更适用于广泛的实际应用，并朝着通用人工智能迈进。

> **摘要翻译:** 语言模型（LMs）在自然语言处理（NLP）中展示了卓越的能力，然而，如何高效且稳健地将它们适应特定任务仍然是一个挑战。随着其规模和复杂性的增长，在标注数据上对语言模型进行微调往往会导致未标注数据利用不足，在小型任务特定数据集上过度拟合，并带来显著的计算成本。这些限制阻碍了它们在现实世界开放式语言任务中的应用。

本论文提出了一系列方法，旨在更好地使语言模型适应下游应用。首先，我们探索了从无标注数据中提取任务相关知识的策略，引入了一种新颖的持续预训练技术，其性能优于最先进的半监督方法。其次，我们提出了一种参数高效的微调方法，该方法显著降低了内存和计算成本，同时保持了竞争力。我们还引入了改进的监督微调方法，使语言模型能够更好地遵循指令，尤其是在标注数据稀缺时，从而增强了它们在包括开放式生成在内的一系列NLP任务中的性能。最后，我们开发了新的评估方法和基准，例如多跳空间推理任务，以更全面地评估语言模型的能力和适应性。

通过在各种NLP任务中进行广泛的实证研究，我们的结果表明，这些方法显著提高了语言模型的鲁棒性、效率和泛化能力，使它们能够更好地适应广泛的应用。这些进步标志着在构建更鲁棒、更高效的语言模型方面迈出了重要一步，使我们更接近通用人工智能的目标。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [186] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
> *FineWeb2：一个管道搞定一切——使预训练数据处理适应每种语言*

*Guilherme Penedo, Hynek Kydlíček, Vinko Sabolčec, Bettina Messmer, Negar Foroutan, Amir Hossein Kargaran, Colin Raffel, Martin Jaggi, Leandro Von Werra, Thomas Wolf* | **Category: cs.CL**

**Keywords:** 预训练数据, 多语言LLM, FineWeb2, 数据处理, 数据集平衡

**Comment:** 

> **TL;DR:** 本文介绍了一个基于FineWeb的新型预训练数据集整理管道，该管道可以自动适应任何语言，并用于创建比现有数据集性能更好的非英语语料库。该研究还引入了一种重新平衡数据集的方法，并最终扩展到1000多种语言，生成了20TB的FineWeb2多语言数据集。

**AI_Comments:** 这项工作在解决多语言大型语言模型预训练数据处理的挑战方面具有重要意义。其创新之处在于开发了一个可自动适应多种语言的通用管道，极大地简化了多语言数据集的构建过程。发布大规模的FineWeb2数据集以及相关的代码库，将对多语言LLM的开放研究和发展产生积极影响。该方法通过系统性的消融实验和数据集重新平衡策略，确保了数据质量和模型性能的提升。

<details>
  <summary>Details</summary>

**Motivation:** 预训练最先进的大型语言模型（LLMs）需要大量干净且多样化的文本数据。尽管高质量英语预训练数据集的开放开发取得了实质性进展，但训练高性能多语言LLMs仍然是一个挑战，这主要是因为为大量语言定制过滤和去重管道固有的困难。

**Method:** 本文引入了一个基于FineWeb的新预训练数据集整理管道，该管道可以自动适应任何语言。研究人员在九种不同语言上对管道设计选择进行了广泛的消融实验，并引入了一种简单且有原则的方法来重新平衡数据集，该方法考虑了重复计数和质量。最终，他们将管道扩展到1000多种语言，使用了近100个Common Crawl快照来生成FineWeb2。

**Result:** 该管道可用于创建比现有数据集性能更好的非英语语料库。此外，重新平衡数据集的方法提供了额外的性能提升。最终生成了FineWeb2，一个20TB（50亿文档）的多语言数据集。

**Conclusion:** 本文成功开发并扩展了一个可自动适应任何语言的预训练数据处理管道，并创建了大规模、高质量的多语言数据集FineWeb2，显著提升了多语言LLMs的性能。

> **ai_Abstract:** 本文提出了FineWeb2，一个可自动适应任何语言的预训练数据处理管道，旨在解决多语言LLM训练中数据处理的挑战。该管道基于FineWeb，并经过广泛的消融实验验证，能够生成比现有数据集性能更优的非英语语料库。此外，研究引入了一种考虑重复计数和质量的数据集重新平衡方法，进一步提升了模型性能。最终，该管道被扩展到1000多种语言，利用近100个Common Crawl快照生成了20TB的FineWeb2多语言数据集，并随代码库一同发布。

> **摘要翻译:** 预训练最先进的大型语言模型（LLMs）需要大量干净且多样化的文本数据。尽管大型高质量英语预训练数据集的开放开发最近取得了实质性进展，但训练高性能多语言LLMs仍然是一个挑战，这在很大程度上是由于为大量语言定制过滤和去重管道固有的困难。在这项工作中，我们引入了一个基于FineWeb的新型预训练数据集整理管道，该管道可以自动适应以支持任何语言。我们在一组九种不同语言上广泛消融了我们的管道设计选择，并由一组有意义且信息丰富的评估任务指导，这些任务是通过基于可测量标准的新颖选择过程选出的。最终，我们表明我们的管道可用于创建比现有数据集产生更高性能模型的非英语语料库。我们还引入了一种直接且有原则的方法来重新平衡数据集，该方法同时考虑了重复计数和质量，提供了额外的性能提升。最后，我们使用近100个Common Crawl快照将我们的管道扩展到1000多种语言，以生产FineWeb2，这是一个新的20TB（50亿文档）多语言数据集，我们随同我们的管道、训练和评估代码库一起发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [200] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
> *KaLM-Embedding-V2：卓越的训练技术和数据启发了多功能嵌入模型*

*Xinping Zhao, Xinshuo Hu, Zifei Shan, Shouzheng Huang, Yao Zhou, Zetian Sun, Zhenyu Liu, Dongfang Li, Xinyuan Wei, Qian Chen, Youcheng Pan, Yang Xiang, Meishan Zhang, Haofen Wang, Jun Yu, Baotian Hu, Min Zhang* | **Category: cs.CL**

**Keywords:** 文本嵌入, KaLM-Embedding-V2, 多阶段训练, 难负样本, MTEB

**Comment:** Technical Report; 26 pages 12 tables 1 figure. arXiv admin note:
  substantial text overlap with arXiv:2501.01028

> **TL;DR:** KaLM-Embedding-V2是一个紧凑的多功能文本嵌入模型，通过先进的训练技术和大规模高质量数据，在MTEB中表现优异，超越同等规模模型并媲美大型模型。

**AI_Comments:** 该论文的创新点在于结合了架构改进（全双向Transformer与均值池化）、精细的多阶段训练策略（大规模预训练、高质量微调、模型汤）、以及有效的难样本处理机制（焦点式重加权、在线难负样本混合）。其重要性体现在证明了在保持模型紧凑（小于1B参数）的同时，通过优化训练技术和数据，可以实现与大型模型相当甚至超越同等规模模型的性能，这对于资源受限的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过利用卓越的训练技术和数据，开发一个在通用文本嵌入任务中表现出色的多功能紧凑型嵌入模型。

**Method:** 该模型移除了因果注意力掩码，采用全双向Transformer架构并结合简单有效的均值池化生成固定长度嵌入。训练采用多阶段流程：(i) 在大规模弱监督开源语料库上进行预训练；(ii) 在高质量检索和非检索数据集上进行微调；(iii) 使用模型汤参数平均以实现鲁棒泛化。此外，引入了焦点式重加权机制以集中学习困难样本，并采用在线难负样本混合策略持续丰富难负样本。预训练数据超过20类，微调数据超过100类。

**Result:** 在海量文本嵌入基准（MTEB）中文和英文上的广泛评估表明，KaLM-Embedding-V2显著优于同等规模的其他模型。它能够与3倍、14倍、18倍和26倍大的嵌入模型竞争，为参数少于1B的多功能紧凑型嵌入模型树立了新标准。

**Conclusion:** KaLM-Embedding-V2通过创新的架构、多阶段训练、难样本处理机制以及大规模多样化数据，实现了卓越的性能，证明了在紧凑模型尺寸下达到先进性能的可能性。

> **ai_Abstract:** KaLM-Embedding-V2是一种新型紧凑型多功能文本嵌入模型，通过改进Transformer架构、采用多阶段训练（包括大规模预训练和高质量微调，并结合模型汤）、引入焦点式重加权和在线难负样本混合策略，以及利用多样化的大规模数据集，在MTEB基准测试中展现出卓越性能，超越同等规模模型并能与数倍大的模型竞争，为紧凑型嵌入模型设定了新标准。

> **摘要翻译:** 在本文中，我们提出了KaLM-Embedding-V2，一个多功能且紧凑的嵌入模型，它通过利用卓越的训练技术和数据，在通用文本嵌入任务中取得了令人印象深刻的性能。我们的主要创新包括：(1) 为了更好地使架构与表示学习对齐，我们移除了因果注意力掩码，并采用了一个带有简单而有效的均值池化的全双向Transformer来生成固定长度的嵌入；(2) 我们采用了多阶段训练流程：(i) 在大规模弱监督开源语料库上进行预训练；(ii) 在高质量检索和非检索数据集上进行微调；以及(iii) 模型汤参数平均以实现鲁棒泛化。此外，我们引入了一种焦点式重加权机制，将学习集中在困难样本上，以及一种在线难负样本混合策略，无需昂贵的离线挖掘即可持续丰富难负样本；(3) 我们收集了超过20类数据用于预训练，100类数据用于微调，以提升嵌入模型的性能和泛化能力。在海量文本嵌入基准（MTEB）中文和英文上的广泛评估表明，我们的模型显著优于同等规模的其他模型，并能与3倍、14倍、18倍和26倍大的嵌入模型竞争，为参数少于1B的多功能紧凑型嵌入模型树立了新标准。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [204] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
> *“医生，你好吗？”：分析用户如何在大型对话式AI数据集中寻求健康信息*

*Akshay Paruchuri, Maryam Aziz, Rohit Vartak, Ayman Ali, Best Uchehara, Xin Liu, Ishan Chatterjee, Monica Agrawal* | **Category: cs.CL, cs.AI, cs.CY**

**Keywords:** 健康信息查询, 大型语言模型, 对话式AI, HealthChat-11K, 用户行为分析

**Comment:** 25 pages, 6 figures, 4 tables, corresponds to initial HealthChat-11K
  dataset release

> **TL;DR:** 本文通过构建HealthChat-11K数据集并结合临床医生分类法，系统研究了用户在大型语言模型（LLM）中寻求健康信息的行为模式、潜在风险，并强调LLM在医疗保健支持能力方面需改进。

**AI_Comments:** 这项研究通过构建和分析一个大规模的真实医疗对话数据集（HealthChat-11K），填补了LLM在医疗健康信息查询领域对话性质和风险探索的空白。其创新之处在于使用了临床医生驱动的分类法来系统地研究用户行为，并揭示了LLM在医疗健康领域面临的具体挑战，如上下文理解和避免诱导奉承。这对于提升LLM在医疗领域的可靠性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人们越来越多地通过交互式聊天机器人向大型语言模型（LLM）寻求医疗保健信息，但这些对话的性质和固有风险仍未得到充分探索。

**Method:** 通过过滤大型对话式AI数据集，构建了HealthChat-11K，一个包含1.1万个真实对话和2.5万条用户消息的精选数据集。然后，使用HealthChat-11K和一个由临床医生驱动的分类法，系统地研究了用户在21个不同健康专业中与LLM进行医疗信息查询时的互动。

**Result:** 分析揭示了用户如何以及为何寻求健康信息的性质的见解，例如常见交互、上下文不完整的情况、情感行为，以及可能诱导奉承的交互（例如，引导性问题）。

**Conclusion:** 强调了部署为对话式AI的LLM在医疗保健支持能力方面需要改进。

> **ai_Abstract:** 本文通过构建名为HealthChat-11K的1.1万个真实医疗对话数据集，并结合临床医生分类法，系统分析了用户在21个健康专业中如何与大型语言模型（LLM）进行健康信息查询。研究揭示了用户交互的常见模式、上下文缺失、情感表现以及可能导致LLM产生奉承性回应的交互方式（如引导性问题）。研究结果强调了当前LLM在提供医疗保健支持时存在不足，亟需改进其能力。

> **摘要翻译:** 人们越来越多地通过交互式聊天机器人向大型语言模型（LLM）寻求医疗保健信息，但这些对话的性质和固有风险仍未得到充分探索。在本文中，我们过滤了大型对话式AI数据集，以获得HealthChat-11K，这是一个包含1.1万个真实对话和2.5万条用户消息的精选数据集。我们使用HealthChat-11K和一个由临床医生驱动的用户与LLM在寻求医疗保健信息时交互方式的分类法，系统地研究了21个不同健康专业中的用户交互。我们的分析揭示了用户如何以及为何寻求健康信息的性质的见解，例如常见交互、上下文不完整的情况、情感行为，以及可能诱导奉承的交互（例如，引导性问题），这强调了部署为对话式AI的LLM在医疗保健支持能力方面需要改进。用于检索我们分析并将其组合成精选数据集的代码和工件可以在此处找到：https://github.com/yahskapar/HealthChat

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [211] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
> *提示引导的轮流预测*

*Koji Inoue, Mikey Elmers, Yahui Fu, Zi Haur Pang, Divesh Lala, Keiko Ochi, Tatsuya Kawahara* | **Category: cs.CL, cs.SD, eess.AS**

**Keywords:** 轮流预测, 文本提示, Transformer, 对话系统, 大型语言模型

**Comment:** This paper has been accepted for presentation at SIGdial Meeting on
  Discourse and Dialogue 2025 (SIGDIAL 2025) and represents the author's
  version of the work

> **TL;DR:** 本文提出了一种新的提示引导模型，用于口语对话系统中的轮流预测，该模型可以根据文本提示动态控制轮流，并提高了预测精度。

**AI_Comments:** 该论文的创新点在于提出了一个可以通过文本提示动态控制轮流预测的模型，这为对话系统提供了更灵活和直观的交互方式。此外，利用大型语言模型生成合成训练数据以克服数据稀缺性问题，也体现了其方法上的新颖性。

<details>
  <summary>Details</summary>

**Motivation:** 轮流预测模型是口语对话系统和会话机器人中必不可少的部分。

**Method:** 本文提出了一种新颖的模型，可以通过文本提示动态控制轮流预测。该方法允许通过“更快”或“更平静”等指令进行直观和明确的控制，从而动态适应会话伙伴和上下文。所提出的模型基于Transformer的语音活动投影（VAP）模型，将文本提示嵌入整合到通道内Transformer和跨通道Transformer中。由于现有数据集中缺乏文本提示数据，研究人员利用大型语言模型（LLM）生成了合成提示句。

**Result:** 实验结果表明，所提出的模型提高了预测精度，并能根据文本提示有效地改变轮流时机行为。

**Conclusion:** 所提出的提示引导模型能够提高轮流预测的准确性，并允许根据文本提示动态调整轮流时机行为。

> **ai_Abstract:** 本文提出了一种新颖的、由文本提示引导的轮流预测模型，旨在使口语对话系统和会话机器人中的轮流行为能够动态调整。该模型基于Transformer的语音活动投影（VAP）架构，通过将文本提示嵌入集成到其内部，实现了对轮流时机的直观控制，如“更快”或“更平静”。为解决数据稀缺问题，研究人员利用大型语言模型生成了合成提示数据。在超过950小时的人与人对话数据上的实验表明，该模型不仅提高了预测准确性，还能有效地根据文本提示调整轮流时机行为。

> **摘要翻译:** 轮流预测模型是口语对话系统和会话机器人中必不可少的部分。最近的方法利用基于Transformer的架构来连续实时地预测语音活动。在这项研究中，我们提出了一种新颖的模型，该模型可以通过文本提示动态控制轮流预测。这种方法允许通过“更快”或“更平静”等指令进行直观和明确的控制，从而动态适应会话伙伴和上下文。所提出的模型基于Transformer的语音活动投影（VAP）模型，将文本提示嵌入整合到通道内Transformer和跨通道Transformer中。我们使用超过950小时的人与人对话数据评估了我们方法的可行性。由于现有数据集中没有可用于所提出方法的文本提示数据，我们利用大型语言模型（LLM）生成了合成提示句。实验结果表明，所提出的模型提高了预测精度，并能根据文本提示有效地改变轮流时机行为。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [213] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
> *一种用于电商查询分类的半监督可伸缩统一框架*

*Chunyuan Yuan, Chong Zhang, Zheng Fang, Ming Pang, Xue Jiang, Changping Peng, Zhangang Lin, Ching Law* | **Category: cs.CL, cs.AI, cs.IR**

**Keywords:** 电商查询分类, 半监督学习, 统一框架, 知识增强, 标签增强

**Comment:** Accepted by ACL 2025

> **TL;DR:** 本文提出了一种名为SSUF的半监督可伸缩统一框架，通过知识增强、标签增强和结构增强模块，解决了电商查询分类中信息不足、对后验标签依赖高以及缺乏统一框架的问题，并在实验中显著优于现有模型。

**AI_Comments:** 该论文的创新点在于提出了一个统一的、模块化的框架SSUF，解决了电商查询分类中普遍存在的短查询信息不足和对后验点击数据过度依赖的问题。通过引入知识增强、标签增强和结构增强等独立但可插拔的模块，SSUF提升了模型的泛化能力和优化效率。其半监督的特性也有效缓解了标注数据稀缺的问题。该框架在实际电商场景中具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 电商查询分类面临以下挑战：查询短、缺乏上下文，标签间信息未被利用导致先验信息不足；现有方法依赖用户后验点击行为构建训练样本，导致马太效应；查询分类的子任务缺乏统一框架，导致算法优化效率低下。

**Method:** 本文提出了一种新颖的半监督可伸缩统一框架（SSUF），包含多个增强模块以统一查询分类任务。知识增强模块利用世界知识增强查询表示，解决查询信息不足的问题。标签增强模块利用标签语义和半监督信号，减少对后验标签的依赖。结构增强模块基于复杂的标签关系增强标签表示。每个模块都高度可插拔，可根据子任务需要添加或移除输入特征。

**Result:** 广泛的离线和在线A/B实验结果表明，SSUF显著优于最先进的模型。

**Conclusion:** SSUF通过其创新的多模块统一框架，有效解决了电商查询分类中的多项核心挑战，并取得了显著优于现有技术的性能，为该领域提供了一个高效且可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种名为SSUF的半监督可伸缩统一框架，旨在解决电商查询分类中查询信息不足、对后验标签依赖性高以及缺乏统一框架的问题。SSUF包含知识增强、标签增强和结构增强三大模块，分别通过引入世界知识、利用标签语义和半监督信号以及增强标签关系来提升分类性能。该框架的模块化设计使其具有高度可插插拔性。实验结果表明，SSUF在离线和在线A/B测试中均显著优于现有SOTA模型。

> **摘要翻译:** 查询分类，包括意图和类别预测等多个子任务，对电商应用至关重要。电商查询通常较短且缺乏上下文，标签之间的信息无法利用，导致建模的先验信息不足。大多数现有工业查询分类方法依赖用户的后验点击行为来构建训练样本，导致马太效应的恶性循环。此外，查询分类的子任务缺乏统一框架，导致算法优化效率低下。
在本文中，我们提出了一种新颖的半监督可伸缩统一框架（SSUF），包含多个增强模块以统一查询分类任务。知识增强模块利用世界知识增强查询表示，解决查询信息不足的问题。标签增强模块利用标签语义和半监督信号，减少对后验标签的依赖。结构增强模块基于复杂的标签关系增强标签表示。每个模块都高度可插拔，可根据每个子任务的需要添加或移除输入特征。我们进行了广泛的离线和在线A/B实验，结果表明SSUF显著优于最先进的模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [214] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
> *梯度下降可以模拟提示吗？*

*Eric Zhang, Leshem Choshen, Jacob Andreas* | **Category: cs.CL, cs.LG**

**Keywords:** 梯度下降, 提示, 元学习, 语言模型, 微调

**Comment:** 14 pages, 2 figures

> **TL;DR:** 本文提出了一种元训练语言模型的方法，使得梯度更新能够模拟提示的效果，从而使微调在某些任务上达到与提示相当的性能。

**AI_Comments:** 本文的创新点在于提出了一种无需真实标签的元训练方法，使得微调能够模拟提示的效果，这在传统上被认为是两种截然不同的信息整合方式。其重要性体现在揭示了梯度下降的潜在表达能力，并为长上下文建模和理解基于梯度学习的泛化提供了新的研究方向。这种方法可能为未来语言模型的高效适应和知识注入提供新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型整合新信息主要有两种方式：改变提示或改变参数（如微调）。尽管参数更新没有长期存储成本，但在许多情况下，提示却显著更有效，尤其是在单示例泛化和逻辑推理方面。因此，本文旨在探讨是否可以通过修改模型，使微调能够模拟提示的效果。

**Method:** 本文描述了一种元训练语言模型的方法，使得梯度更新能够模拟对新信息进行条件化的效果。该方法利用了基于梯度的元学习工具，但使用语言模型自身的提示预测作为目标，从而消除了对真实标签的需求。

**Result:** 随后的梯度下降训练恢复了部分（有时是全部）提示模型的性能，在“逆转诅咒”任务上显示出改进，并且在单次梯度更新后能够回答关于文本段落的问题。

**Conclusion:** 这些结果表明，通过适当的初始化，梯度下降可以具有惊人的表达能力。本文的结果为长上下文建模提供了新的途径，并为基于梯度的学习的泛化能力提供了见解。

> **ai_Abstract:** 本文研究了梯度下降能否模拟语言模型中的提示效果。研究发现，尽管提示在某些任务上比微调更有效，但通过一种元训练方法，可以使梯度更新模拟提示对新信息的影响。该方法利用基于梯度的元学习，并以模型自身的提示预测为目标，无需真实标签。实验结果表明，这种方法能使梯度下降训练恢复部分甚至全部提示性能，并在“逆转诅咒”任务和单次更新后的文本问答中显示出改进。这表明适当初始化的梯度下降具有强大的表达能力，为长上下文建模和梯度学习的泛化提供了新思路。

> **摘要翻译:** 将新信息整合到语言模型（LM）中有两种主要方式：改变其提示或改变其参数（例如通过微调）。参数更新不会产生模型更改的长期存储成本。然而，对于许多模型更新，提示明显更有效：提示模型可以从单个示例中稳健地泛化，并进行标准微调中不会出现的逻辑推理。那么，是否可以修改模型，使微调能够模拟提示呢？本文描述了一种元训练语言模型的方法，使得梯度更新能够模拟对新信息进行条件化的效果。我们的方法利用了基于梯度的元学习工具，但使用语言模型自身的提示预测作为目标，从而消除了对真实标签的需求。随后的梯度下降训练恢复了部分（有时是全部）提示模型的性能——在“逆转诅咒”任务上显示出改进，并在单次梯度更新后回答关于文本段落的问题。这些结果表明，通过适当的初始化，梯度下降可以具有惊人的表达能力。我们的结果为长上下文建模提供了新的途径，并为基于梯度的学习的泛化能力提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [226] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
> *SAC：一种用于测量和诱导LLM中人格特质并动态控制其强度的方法框架*

*Adithya Chittem, Aishna Shrivastava, Sai Tarun Pendela, Jagat Sesh Challa, Dhruv Kumar* | **Category: cs.CL, cs.AI, cs.HC**

**Keywords:** LLMs, 人格特质, 动态强度控制, SAC, 16PF

**Comment:** Under review

> **TL;DR:** 本文提出SAC框架，通过扩展MPI并结合16PF模型，实现了对大型语言模型（LLMs）人格特质的精细化测量和动态强度控制，发现连续强度建模比二元开关更有效。

**AI_Comments:** 这项工作具有显著的创新性，它超越了传统“大五”人格模型的局限性，引入了更细致的16PF模型，并且关键性地解决了人格特质强度动态控制的问题。通过提出SAC框架和连续强度建模，该研究为LLM展现更真实、可控的类人个性提供了有效途径，对于未来人机交互，尤其是在高敏感度领域（如医疗、教育）的应用具有重要意义。其发现LLM能内化多维度人格结构也为LLM的心理建模提供了新的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM人格模型主要基于“大五”人格框架，维度粗糙且缺乏对特质强度的控制机制。为了满足LLM在交互中展现类人个性的日益增长的期望，需要解决这些局限性。

**Method:** 作者通过将原使用“大五”模型的机器个性清单（MPI）扩展至包含16种人格因素（16PF）模型，从而实现对十六种不同特质的表达控制。同时，开发了一个名为“特定属性控制”（SAC）的结构化框架，用于评估和动态诱导LLM的特质强度。该方法引入了基于形容词的语义锚定来指导特质强度表达，并利用了跨越五个强度因素（频率、深度、阈值、努力和意愿）的行为问题。

**Result:** 实验发现，将强度建模为连续谱比二元特质切换能产生更一致和可控的个性表达。此外，观察到目标特质强度的变化会系统性地影响密切相关的特质，方向符合心理学上的连贯性，这表明LLM内化了多维度的人格结构，而不是孤立地处理特质。

**Conclusion:** 这项工作为医疗保健、教育和面试等领域中受控且细致的人机交互开辟了新途径，使我们更接近真正类人的社交机器。

> **ai_Abstract:** 本文提出了SAC（特定属性控制）框架，旨在解决现有LLM人格模型在特质维度粗糙和强度控制方面的不足。通过将机器个性清单（MPI）扩展到16种人格因素（16PF）模型，并引入基于形容词的语义锚定和五种强度因素的行为问题，SAC实现了对LLM人格特质的精细化测量和动态强度控制。实验证明，连续的强度建模能提供更一致和可控的个性表达，并且LLM能够内化多维度的人格结构。该研究为实现更细致、类人的人机交互奠定了基础。

> **摘要翻译:** 近年来，大型语言模型（LLM）在广泛领域获得了显著关注。人们也越来越期望它们在交互中展现出类人个性。为了满足这一期望，许多研究提出了通过心理测量评估来建模LLM个性化。然而，大多数现有模型面临两大局限性：它们依赖于“大五”（OCEAN）框架，该框架仅提供粗略的个性维度；并且它们缺乏控制特质强度的机制。在本文中，我们通过扩展最初使用“大五”模型的机器个性清单（MPI），以纳入16种人格因素（16PF）模型，从而解决这一空白，实现对十六种不同特质的表达控制。我们还开发了一个名为“特定属性控制”（SAC）的结构化框架，用于评估和动态诱导LLM中的特质强度。我们的方法引入了基于形容词的语义锚定来指导特质强度表达，并利用了跨越五个强度因素：频率、深度、阈值、努力和意愿的行为问题。通过实验，我们发现将强度建模为连续谱比二元特质切换能产生更一致和可控的个性表达。此外，我们观察到目标特质强度的变化会系统性地影响密切相关的特质，方向符合心理学上的连贯性，这表明LLM内化了多维度的人格结构，而不是孤立地处理特质。我们的工作为医疗保健、教育和面试等领域中受控且细致的人机交互开辟了新途径，使我们更接近真正类人的社交机器。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [229] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
> *维护 MTEB：迈向嵌入基准的长期可用性和可复现性*

*Isaac Chung, Imene Kerboua, Marton Kardos, Roman Solomatin, Kenneth Enevoldsen* | **Category: cs.CL, cs.AI, cs.SE**

**Keywords:** MTEB, 嵌入基准, 可复现性, 可用性, 持续集成

**Comment:** 

> **TL;DR:** 本文关注MTEB（大规模文本嵌入基准）的工程维护，以确保其长期可用性和可复现性，通过持续集成管道、设计选择和社区贡献策略实现。

**AI_Comments:** 本文的创新之处在于其将工程实践（如持续集成）应用于机器学习基准的维护，解决了长期可用性和可复现性这一关键但常被忽视的问题。这对于确保评估结果的可靠性和未来研究的进步至关重要。其重要性在于提供了一套实用的维护策略，对于任何大型、持续演进的机器学习评估平台都具有借鉴意义。

<details>
  <summary>Details</summary>

**Motivation:** MTEB已成为文本嵌入模型评估的标准平台，但之前的研究主要集中于核心基准方法。本文的动机是解决工程方面的问题，以确保MTEB的持续可复现性和可扩展性。

**Method:** 本文介绍了维护健壮的持续集成管道的方法，包括验证数据集完整性、自动化测试执行和评估基准结果的泛化性。详细阐述了增强可复现性和可用性的设计选择，并讨论了处理社区贡献以及通过新任务和数据集扩展基准的策略。

**Result:** 这些工程实践有助于MTEB变得更全面，同时保持质量和领域相关性。

**Conclusion:** 作者的经验为面临类似挑战（在机器学习评估框架中确保可复现性和可用性）的基准维护者提供了宝贵的见解。

> **ai_Abstract:** 本文聚焦于大规模文本嵌入基准（MTEB）的工程维护，旨在确保其长期可用性和可复现性。作者详细介绍了如何通过建立健壮的持续集成管道来验证数据集、自动化测试并评估结果泛化性。文中还探讨了提升可复现性和可用性的设计选择，以及管理社区贡献和扩展基准的策略。这些工程实践对MTEB的规模化和质量维持至关重要，并为其他基准维护者提供了宝贵经验。

> **摘要翻译:** 大规模文本嵌入基准（MTEB）已成为文本嵌入模型的一个标准评估平台。虽然先前的工作已经建立了核心基准方法，但本文专注于工程方面，以确保MTEB的持续可复现性和可扩展性。我们提出了维护健壮持续集成管道的方法，这些管道验证数据集完整性、自动化测试执行并评估基准结果的泛化性。我们详细介绍了共同增强可复现性和可用性的设计选择。此外，我们讨论了处理社区贡献以及通过新任务和数据集扩展基准的策略。这些工程实践在使MTEB变得更全面、同时保持质量并最终保持与该领域的相关性方面发挥了重要作用。我们的经验为面临在机器学习评估框架中确保可复现性和可用性方面类似挑战的基准维护者提供了宝贵的见解。MTEB存储库可在以下地址获取：https://github.com/embeddings-benchmark/mteb

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [238] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
> *通过句法检索增强大型语言模型的自动术语提取*

*Yongchan Chun, Minhyuk Kim, Dongjun Kim, Chanjun Park, Heuiseok Lim* | **Category: cs.CL, cs.IR**

**Keywords:** 自动术语提取, 大型语言模型, 句法检索, 少样本学习, 自然语言处理

**Comment:** 

> **TL;DR:** 该研究提出了一种利用句法检索增强大型语言模型在少样本设置下进行自动术语提取（ATE）的方法，通过关注句法相似性来选择示例，从而提高了性能。

**AI_Comments:** 该论文的创新之处在于提出了一种基于句法而非语义相似性的检索方法，用于在少样本设置下增强大型语言模型的自动术语提取能力。这种方法与领域无关，并且在捕获术语边界方面提供了更可靠的指导，为利用LLM处理结构化语言任务开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 自动术语提取（ATE）对于机器翻译和信息检索等下游任务至关重要。尽管大型语言模型（LLM）在多种NLP任务中取得了显著进展，但其在ATE领域的潜力尚未得到充分探索。

**Method:** 提出了一种基于检索的提示策略，用于少样本设置下的ATE。该策略根据句法而非语义相似性选择示例。这种句法检索方法与领域无关，并能为捕获术语边界提供更可靠的指导。

**Result:** 在三个专门的ATE基准测试上的实验表明，句法检索提高了F1分数。研究还分析了查询句子与其检索到的示例之间的词汇重叠如何影响性能。

**Conclusion:** 这些发现强调了在将大型语言模型应用于术语提取任务时，句法线索的重要性。

> **ai_Abstract:** 本文提出了一种新颖的少样本自动术语提取（ATE）方法，该方法利用大型语言模型（LLM）并采用句法检索策略。该策略根据句法相似性选择示例，具有领域无关性，并有助于识别术语边界。在三个ATE基准测试上的评估表明，所提出的句法检索显著提高了F1分数，强调了句法线索在将LLM应用于术语提取任务中的关键作用。

> **摘要翻译:** 自动术语提取（ATE）识别领域特定的表达，这些表达对于机器翻译和信息检索等下游任务至关重要。尽管大型语言模型（LLM）已显著推动了各种自然语言处理任务，但其在ATE方面的潜力却鲜有研究。我们提出了一种基于检索的提示策略，在少样本设置下，该策略根据句法而非语义相似性选择示例。这种句法检索方法与领域无关，为捕获术语边界提供了更可靠的指导。我们在域内和跨域设置中评估了该方法，分析了查询句子与其检索到的示例之间的词汇重叠如何影响性能。在三个专门的ATE基准测试上的实验表明，句法检索提高了F1分数。这些发现强调了在将LLM应用于术语提取任务时句法线索的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [239] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
> *大型语言模型在特许会计领域表现出色*

*Jatin Gupta, Akhil Sharma, Saransh Singhania, Mohammad Adnan, Sakshi Deo, Ali Imam Abidi, Keshav Gupta* | **Category: cs.CL, cs.AI**

**Keywords:** 大型语言模型, 特许会计, 金融知识, 基准测试, CA-Ben

**Comment:** Accepted for publication at MoStart 2025: International Conference on
  Digital Transformation in Education and Applications of Artificial
  Intelligence, Bosnia and Herzegovina, 2025

> **TL;DR:** 本研究引入了CA-Ben基准测试，用于评估大型语言模型（LLMs）在印度特许会计领域的金融、法律和定量推理能力。结果显示，GPT-4o和Claude 3.5 Sonnet表现突出，但在数值计算和法律解释方面仍存在挑战。

**AI_Comments:** 本研究通过引入CA-Ben基准测试，首次系统性地评估了大型语言模型在印度特许会计这一高度专业化领域的表现，填补了现有研究的空白。其创新之处在于利用真实世界的专业考试数据来构建评估体系，使得评估结果更具实际参考价值。研究揭示了当前LLMs在处理复杂金融和法律问题时的能力边界，特别是在数值计算和精确法律解释方面的不足，这为LLM的未来发展指明了方向，即需要更深入的领域知识集成和更强大的推理机制。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正在显著改变金融实践，但它们在捕捉和应用领域特定金融知识方面的有效性尚不确定。为了填补印度金融领域的关键空白，本研究旨在评估LLMs在特许会计领域的金融、法律和定量推理能力。

**Method:** 本研究引入了CA-Ben，这是一个专门为评估LLMs金融、法律和定量推理能力而设计的特许会计基准测试。CA-Ben包含来自印度特许会计师协会（ICAI）严格考试的结构化问答数据集，涵盖基础、中级和高级CA课程阶段。研究使用标准化协议评估了六个主流LLMs，包括GPT 4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4。

**Result:** 评估结果显示LLMs的性能存在差异。其中，Claude 3.5 Sonnet和GPT-4o表现优于其他模型，尤其是在概念和法律推理方面。然而，在数值计算和法律解释方面出现了显著挑战。

**Conclusion:** 研究结果强调了当前LLMs的优势和局限性。未来可通过混合推理和检索增强生成方法来改进LLMs，特别是在定量分析和准确的法律解释方面。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）在印度特许会计领域的应用能力。为此，论文提出了CA-Ben基准测试，该测试基于印度特许会计师协会（ICAI）的考试数据。通过对包括GPT-4o和Claude 3.5 Sonnet在内的六个主流LLMs进行评估，研究发现顶级模型在概念和法律推理方面表现出色，但在处理数值计算和法律解释时仍面临挑战。研究强调了当前LLMs的潜力和局限性，并建议未来通过结合混合推理和检索增强生成技术来提升其性能。

> **摘要翻译:** 先进的智能系统，特别是大型语言模型（LLMs），正通过自然语言处理（NLP）的进步显著改变金融实践。然而，这些模型捕捉和应用领域特定金融知识的程度仍不确定。为解决印度广阔金融背景下的一个关键空白，本文引入了CA-Ben，这是一个专门设计用于评估LLMs金融、法律和定量推理能力的特许会计基准测试。CA-Ben包含从印度特许会计师协会（ICAI）进行的严格考试中提取的结构化问答数据集，涵盖了基础、中级和高级CA课程阶段。研究使用标准化协议评估了六个主流LLMs，即GPT 4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4。结果显示性能存在差异，其中Claude 3.5 Sonnet和GPT-4o表现优于其他模型，尤其是在概念和法律推理方面。在数值计算和法律解释方面出现了显著挑战。研究结果强调了当前LLMs的优势和局限性，并提出了未来通过混合推理和检索增强生成方法进行改进的建议，特别是针对定量分析和准确的法律解释。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [248] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
> *小型编码器在检测基础性方面可与大型解码器媲美*

*Istabrak Abbes, Gabriele Prato, Quentin Fournier, Fernando Rodriguez, Alaa Boukhary, Adam Elwood, Sarath Chandar* | **Category: cs.CL, cs.AI, cs.IR, cs.LG**

**Keywords:** 基础性检测, 大型语言模型, 编码器模型, 推理效率, 幻觉

**Comment:** 

> **TL;DR:** 研究表明，轻量级编码器模型在检测LLM生成内容的基础性方面，表现可与大型LLM媲美，同时显著降低推理时间和资源消耗。

**AI_Comments:** 这篇论文的创新点在于证明了小型、任务专用的编码器模型在特定任务（如基础性检测）上可以超越或媲美大型通用LLMs的性能，尤其是在效率方面。这对于资源受限或需要低延迟的应用场景具有重要意义，提供了一种更经济、更快速的LLM辅助方案，有助于解决LLM幻觉问题。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在外部上下文不足时易产生“幻觉”，即生成无根据的猜测或依赖内部知识，导致事实不一致和不可信。为确保LLMs输出的事实一致性和可信度，并在昂贵的答案生成之前减少推理时间和资源消耗，有必要开发一种机制来检测查询是否基于提供的文档上下文。

**Method:** 本研究使用RoBERTa和NomicBERT等轻量级、任务专用的编码器模型，在精选数据集上进行微调，以检测给定查询是否基于提供的文档上下文。随后，将这些编码器模型的性能与Llama3 8B和GPT4o等最先进的LLMs在基础性检测任务上的表现进行比较。

**Result:** 轻量级、任务专用的编码器模型（如RoBERTa和NomicBERT）在基础性检测方面，可以达到与Llama3 8B和GPT4o等最先进的LLMs相当的准确性。同时，这些编码器模型显著降低了几个数量级的推理延迟。

**Conclusion:** 轻量级编码器模型是检测LLM生成内容基础性的有效且高效的替代方案，它们能够在保持高准确性的同时，显著降低计算成本和推理时间，从而有助于确保LLMs的可靠性。

> **ai_Abstract:** 本研究探讨了在大型语言模型（LLMs）生成答案前，检测其输出是否基于给定上下文的重要性，以解决LLMs在上下文不足时产生幻觉的问题。研究发现，经过精心微调的轻量级编码器模型（如RoBERTa和NomicBERT）在检测基础性方面，能达到与Llama3 8B和GPT4o等大型LLMs相媲美的准确性，同时大幅降低推理时间和资源消耗，为确保LLMs的可靠性提供了一种高效的解决方案。

> **摘要翻译:** 将大型语言模型（LLMs）与外部上下文结合显著提高了它们在自然语言处理（NLP）任务中的性能。然而，当提供的上下文缺乏信息时，LLMs难以可靠地回答查询，经常诉诸于无根据的猜测或内部知识。基础性——即生成严格由上下文支持的响应——对于确保事实一致性和可信度至关重要。本研究侧重于在LLMs进行昂贵的答案生成之前，检测给定查询是否基于所提供的文档上下文。这种检测机制可以显著减少推理时间和资源消耗。我们表明，轻量级、任务专用的编码器模型，如RoBERTa和NomicBERT，在精选数据集上进行微调后，在基础性检测方面可以达到与Llama3 8B和GPT4o等最先进的LLMs相当的准确性，同时将推理延迟降低了几个数量级。代码可在：https://github.com/chandarlab/Hallucinate-less 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [249] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
> *从用户交互中校准口语对话模型*

*Anne Wu, Laurent Mazaré, Neil Zeghidour, Alexandre Défossez* | **Category: cs.CL, cs.LG, cs.SD, eess.AS**

**Keywords:** 语音对话模型, 偏好对齐, 用户交互, 实时对话, 全双工模型

**Comment:** Accepted at ICML 2025

> **TL;DR:** 提出了一种新颖的偏好对齐框架，通过大规模数据集和离线对齐方法改进实时口语对话模型，使其更真实、安全、上下文对齐。

**AI_Comments:** 这篇论文的创新点在于将偏好对齐技术应用于实时语音对话领域，克服了现有方法主要面向文本的局限性。通过构建大规模语音偏好数据集和微调全双工语音模型，有效提升了实时对话系统的性能，使其更符合人类交互习惯。其对实时语音动态平衡的强调，为未来自然对话系统发展提供了重要见解。

<details>
  <summary>Details</summary>

**Motivation:** 当前的偏好学习方法主要关注基于文本的语言模型，不适用于实时语音交互的复杂性（如中断、插话、无明确轮次分割）。

**Method:** 提出了一个新颖的偏好对齐框架；创建了一个包含超过150,000个偏好对的大规模数据集，数据来源于原始多轮语音对话，并用AI反馈进行标注；利用离线对齐方法微调了一个全双工自回归语音到语音模型；进行了广泛的实验和整体人工评估。

**Result:** 事实证明，对通用对话的反馈可以持续有效地改进口语对话模型，使其产生更真实、更安全、更上下文对齐的交互；发现各种动态之间良好校准的平衡对于自然的实时语音对话系统至关重要。

**Conclusion:** 论文强调了在实时语音对话系统中，各种动态（如中断、插话）之间良好校准的平衡的重要性，并通过提出的框架和方法有效提升了模型的表现。

> **ai_Abstract:** 本文提出了一种新颖的偏好对齐框架，旨在通过用户交互改进实时口语对话模型。针对现有文本偏好学习方法不适用于实时语音复杂性的问题，研究团队构建了一个包含超过15万个偏好对的大规模语音对话数据集，并利用离线对齐技术微调了一个全双工语音到语音模型。实验结果表明，该方法能有效提升模型生成更真实、安全且上下文对齐的交互，并强调了实时语音对话中各种动态平衡的重要性。

> **摘要翻译:** 我们提出了一种新颖的偏好对齐框架，用于通过用户交互改进实时对话中的口语对话模型。当前的偏好学习方法主要关注基于文本的语言模型，不直接适用于实时语音交互的复杂性，后者具有更丰富的动态（例如中断、插话）且说话人轮次之间没有明确的分割。我们从原始多轮语音对话中创建了一个包含超过150,000个偏好对的大规模数据集，并用AI反馈进行标注，以涵盖语言内容和时间上下文变化的偏好。我们利用离线对齐方法微调了一个全双工自回归语音到语音模型。广泛的实验表明，对通用对话的反馈可以持续有效地改进口语对话模型，使其产生更真实、更安全、更上下文对齐的交互。我们部署了微调后的模型并进行了整体人工评估，以评估其在单轮对话之外的影响。我们的发现揭示了各种动态之间良好校准的平衡的重要性，这对于自然的实时语音对话系统至关重要。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [254] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
> *CBF-AFA：基于块的多自监督学习融合用于自动流利度评估*

*Papa Séga Wade, Mihai Andries, Ioannis Kanellos, Thierry Moudenc* | **Category: cs.CL, cs.AI, eess.AS**

**Keywords:** 自动流利度评估, 自监督学习, 语音块, 多模型融合, 非母语语音

**Comment:** 5 pages, accepted for presentation at EUSIPCO 2025

> **TL;DR:** 提出了一种基于语音块的多自监督学习模型融合方法CBF-AFA，用于提高非母语使用者自动流利度评估的准确性，并在多个数据集上取得了显著提升。

**AI_Comments:** 该论文的创新点在于提出了“基于块的多SSL融合”方法，有效结合了不同SSL模型的互补优势，并通过细粒度的块级分析和上下文捕捉提升了自动流利度评估的准确性。其重要性在于解决了非母语者语音流利度评估中的关键挑战，特别是对语音节奏和不流利现象的捕捉。局限性在于未来需要探索其对具有不规则韵律方言的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 自动流利度评估（AFA）仍然具有挑战性，特别是在捕捉非母语使用者语音节奏、停顿和不流利现象方面。

**Method:** 本文引入了一种基于语音块的方法，通过Silero VAD将语音分割成呼吸组块。该方法集成了Wav2Vec2、HuBERT和WavLM等自监督学习（SSL）模型，并通过可学习的加权机制融合SSL嵌入。融合后的嵌入辅以块级流利度标记（如语速、停顿持续时间、n-gram重复），并送入分层的CNN-BiLSTM框架以捕捉局部和长期依赖。

**Result:** 在Avalinguo和Speechocean762数据集上进行评估，与单SSL基线相比，在Speechocean762上F1分数提高了2.8，皮尔逊相关系数提高了6.2个点；在Avalinguo上F1分数提高了4.2，皮尔逊相关系数提高了4.0个点。该方法超越了基于Pyannote.audio的分割基线。

**Conclusion:** 这些发现强调了基于块的多SSL融合对于鲁棒流利度评估的有效性，但未来的工作应探索其对具有不规则韵律方言的泛化能力。

> **ai_Abstract:** 本文提出了一种名为CBF-AFA的自动流利度评估新方法，通过将语音分割成呼吸组块，并融合Wav2Vec2、HuBERT和WavLM等多个自监督学习模型的嵌入，结合块级流利度标记和CNN-BiLSTM框架，以有效捕捉非母语使用者的语音节奏、停顿和不流利现象。实验结果表明，该方法在Avalinguo和Speechocean762数据集上均显著优于现有基线。

> **摘要翻译:** 自动流利度评估（AFA）仍然具有挑战性，尤其是在捕捉非母语使用者的语音节奏、停顿和不流利现象方面。我们引入了一种基于语音块的方法，该方法集成了自监督学习（SSL）模型（Wav2Vec2、HuBERT和WavLM），这些模型因其在语音、韵律和嘈杂语音建模方面的互补优势而被选中，并结合了分层的CNN-BiLSTM框架。语音使用Silero语音活动检测（Silero-VAD）分割成呼吸组块，从而实现细粒度的时序分析，同时减轻过度分割的伪影。SSL嵌入通过可学习的加权机制进行融合，平衡了声学和语言特征，并富含块级流利度标记（例如，语速、停顿持续时间、n-gram重复）。CNN-BiLSTM捕捉块间的局部和长期依赖。在Avalinguo和Speechocean762数据集上进行评估，我们的方法在Speechocean762上比单一SSL基线在F1分数上提高了2.8，皮尔逊相关系数提高了6.2个点，在Avalinguo上F1分数提高了4.2，皮尔逊相关系数提高了4.0个点，超越了基于Pyannote.audio的分割基线。这些发现强调了基于块的多SSL融合对于鲁棒流利度评估的有效性，尽管未来的工作应探索其对具有不规则韵律方言的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [257] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
> *利用LLM辅助查询理解实现实时检索增强生成*

*Guanting Dong, Xiaoxi Li, Yuyao Zhang, Mengjie Deng* | **Category: cs.CL, cs.AI, cs.IR**

**Keywords:** RAG, LLM, 查询理解, 实时系统, 检索增强生成

**Comment:** Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)

> **TL;DR:** 提出Omni-RAG框架，通过LLM辅助查询理解，处理实时RAG系统中复杂、噪声和多意图的用户查询，提升系统鲁棒性和有效性。

**AI_Comments:** Omni-RAG的创新点在于其利用LLM进行深度查询理解和分解，从而能有效处理真实世界中常见的复杂、噪声和多意图查询，这是当前RAG系统面临的主要挑战。通过将查询预处理与意图感知检索和重排序相结合，该框架有望显著提升RAG在实时应用中的实用性和性能。

<details>
  <summary>Details</summary>

**Motivation:** 实时检索增强生成（RAG）系统在处理嘈杂、模糊和包含多重意图的用户查询时面临显著挑战，现有系统通常难以应对此类复杂输入，因为它们多在更干净的数据上进行训练或评估。

**Method:** 论文引入了Omni-RAG框架，通过LLM辅助查询理解来预处理用户输入，包括三个关键模块：1. 深度查询理解与分解：利用LLM和定制提示去噪查询（如纠正拼写错误），并将多意图查询分解为结构化子查询。2. 意图感知知识检索：对每个子查询从语料库（如FineWeb使用OpenSearch）执行检索并聚合结果。3. 重排序与生成：重排序器（如BGE）在LLM（如Falcon-10B）使用思维链提示生成最终响应之前，优化文档选择。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 论文提出了Omni-RAG框架，旨在解决实时RAG系统处理复杂、嘈杂和多意图用户查询的挑战。该框架通过LLM辅助查询理解，包含深度查询理解与分解（去噪和子查询分解）、意图感知知识检索（对子查询进行检索并聚合结果）以及重排序与生成（优化文档选择并生成最终响应）三个核心模块，以提升RAG系统在开放域环境中的鲁棒性和有效性。

> **摘要翻译:** 实时检索增强生成（RAG）系统在处理通常嘈杂、模糊且包含多重意图的用户查询时面临显著挑战。虽然RAG通过外部知识增强了大型语言模型（LLM），但当前的系统通常难以应对此类复杂输入，因为它们通常在更干净的数据上进行训练或评估。本文介绍了一种名为Omni-RAG的新颖框架，旨在提高RAG系统在实时、开放域设置中的鲁棒性和有效性。Omni-RAG采用LLM辅助查询理解来通过三个关键模块预处理用户输入：（1）深度查询理解和分解，该模块利用带有定制提示的LLM来去噪查询（例如，纠正拼写错误）并将多意图查询分解为结构化子查询；（2）意图感知知识检索，该模块从语料库（即使用OpenSearch的FineWeb）对每个子查询执行检索并聚合结果；（3）重排序与生成，在该模块中，重排序器（即BGE）在LLM（即Falcon-10B）使用思维链提示生成最终响应之前，优化文档选择。Omni-RAG旨在通过稳健地处理复杂和嘈杂的查询，弥合当前RAG能力与真实世界应用需求之间的差距，例如SIGIR 2025 LiveRAG挑战赛所强调的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [258] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
> *MT2-CSD：一种用于会话立场检测的新数据集和多语义知识融合方法*

*Fuqiang Niu, Genan Dai, Yisha Lu, Jiayu Liao, Xiang Li, Hu Huang, Bowen Zhang* | **Category: cs.CL**

**Keywords:** 会话立场检测, 数据集, 大语言模型, MT2-CSD, LLM-CRAN

**Comment:** 

> **TL;DR:** 本文提出了MT2-CSD数据集，一个用于多目标、多轮会话立场检测的大规模数据集，并引入了LLM-CRAN模型，该模型利用大语言模型提升会话理解，并在新数据集上取得了显著优于基线模型的性能。

**AI_Comments:** 本文的创新点在于构建了目前最大的多目标、多轮会话立场检测数据集MT2-CSD，其大规模和深会话的特性为该领域带来了新的挑战和研究机会。同时，提出的LLM-CRAN模型巧妙地将大语言模型的推理能力融入会话理解，为解决复杂会话场景下的立场检测问题提供了有效途径，展示了LLM在特定任务上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前立场检测研究多针对单一实例，难以有效建模社交媒体中典型的多方会话；此外，缺乏真实捕捉社交媒体互动动态的数据集，阻碍了会话立场检测的进一步发展。

**Method:** 本文引入了MT2-CSD，一个用于多目标、多轮会话立场检测的综合数据集，据称是目前最大的同类数据集，包含24,457个标注实例，并具有最大的会话深度。为应对这些挑战，本文提出了一种大语言模型增强会话关系注意力网络（LLM-CRAN），该网络利用大语言模型的推理能力来提高会话理解能力。

**Result:** 实验结果表明，LLM-CRAN在会话立场检测任务中显著优于强大的基线模型。

**Conclusion:** MT2-CSD数据集的引入及其带来的挑战，以及LLM-CRAN模型的有效性，共同推动了多轮会话立场检测领域的研究进展，尤其在处理复杂会话深度方面表现出色。

> **ai_Abstract:** 本文针对传统立场检测研究在建模多方会话和数据集稀缺方面的不足，提出了MT2-CSD，一个目前最大的多目标、多轮会话立场检测数据集，包含24,457个实例。为应对新数据集带来的挑战，作者提出LLM-CRAN模型，该模型利用大语言模型增强会话理解能力。实验证明，LLM-CRAN在会话立场检测任务中显著优于基线模型。

> **摘要翻译:** 在当代社交媒体领域，自动立场检测对于意见挖掘至关重要，因为它综合并审查用户对有争议话题的看法，以揭示普遍趋势和情绪。传统的立场检测研究通常针对单个实例，从而限制了其建模真实社交媒体场景中典型的多方讨论的能力。这一缺点很大程度上源于缺乏真实捕捉社交媒体互动动态的数据集，从而阻碍了会话立场检测的进展。在本文中，我们介绍了MT2-CSD，一个用于多目标、多轮会话立场检测的综合数据集。据我们所知，MT2-CSD是目前可用于此目的的最大数据集，包含24,457个标注实例，并展现出最大的会话深度，从而为立场检测带来了新的挑战。为了应对这些挑战，我们提出了大语言模型增强会话关系注意力网络（LLM-CRAN），它利用LLM的推理能力来改进会话理解。我们进行了广泛的实验来评估LLM-CRAN在MT2-CSD数据集上的有效性。实验结果表明，LLM-CRAN在会话立场检测任务中显著优于强大的基线模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [264] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
> *跨语言Text2Cypher：评估超越英语的基础模型*

*Makbule Gulcin Ozsoy, William Tai* | **Category: cs.CL, cs.IR**

**Keywords:** Text2Cypher, 多语言, 基础模型, 跨语言评估, 自然语言处理

**Comment:** 

> **TL;DR:** 本文研究了基础LLM在多语言Text2Cypher任务上的表现，发现英语表现最佳，西班牙语次之，土耳其语最差，并发布了多语言测试集，强调了多语言查询生成中更具包容性评估的必要性。

**AI_Comments:** 这篇论文通过构建多语言测试集并评估基础模型在非英语Text2Cypher任务上的性能，填补了现有研究的空白，具有重要意义。它揭示了当前LLM在多语言理解和生成方面的局限性，特别是对低资源语言。论文指出的训练数据和语言特性差异是导致性能差距的关键因素，为未来多语言LLM的开发提供了明确方向。其创新点在于首次系统性地评估了跨语言Text2Cypher，并明确指出提示翻译影响不大，这对于多语言NLP研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自然语言到数据库查询（如Text2Cypher）的研究主要集中在英语，对其他语言的评估有限，因此需要研究基础LLM在多语言Text2Cypher任务上的表现。

**Method:** 本文创建并发布了一个多语言测试集，通过将英语问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，以实现公平的跨语言比较。研究使用标准化提示和指标评估了多个基础模型，并探索了将任务提示翻译成西班牙语和土耳其语的影响。

**Result:** 模型性能呈现一致的模式：英语最高，其次是西班牙语，土耳其语最低，这归因于训练数据可用性和语言特征的差异。此外，提示翻译对评估指标影响很小或没有影响。

**Conclusion:** 研究结果强调了在多语言查询生成中进行更具包容性的评估和开发的必要性。未来的工作包括模式本地化和跨不同语言的微调。

> **ai_Abstract:** 本文研究了基础大型语言模型在多语言Text2Cypher任务上的表现，旨在解决当前研究主要集中于英语的局限性。研究团队构建了一个包含英语、西班牙语和土耳其语的多语言测试集，并评估了多个基础模型。结果显示，模型在英语上的表现最佳，其次是西班牙语，土耳其语最差，这可能与训练数据和语言特性有关。研究还发现提示翻译对模型性能影响甚微。论文强调了在多语言查询生成领域进行更广泛评估和开发的必要性。

> **摘要翻译:** 大型语言模型的最新进展使得自然语言接口能够将用户问题转换为数据库查询，例如Text2SQL、Text2SPARQL和Text2Cypher。虽然这些接口增强了数据库的可访问性，但目前大多数研究只专注于英语，对其他语言的评估有限。本文研究了基础LLM在跨多种语言的Text2Cypher任务上的性能。我们通过将英语问题翻译成西班牙语和土耳其语，同时保留原始的Cypher查询，创建并发布了一个多语言测试集，从而实现了公平的跨语言比较。我们使用标准化提示和指标评估了多个基础模型。我们的结果显示出一致的性能模式：英语最高，其次是西班牙语，土耳其语最低。我们将其归因于训练数据可用性和语言特征的差异。此外，我们探讨了将任务提示翻译成西班牙语和土耳其语的影响。结果显示评估指标几乎没有变化，表明提示翻译影响很小。我们的发现强调了在多语言查询生成中进行更具包容性的评估和开发的必要性。未来的工作包括模式本地化和跨不同语言的微调。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [265] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
> *DALR：多模态句子表示学习的双层对齐学习*

*Kang He, Yuzhe Ding. Haining Wang, Fei Li, Chong Teng, Donghong Ji* | **Category: cs.CL**

**Keywords:** 多模态学习, 句子表示, 对齐学习, 语义相似性, 排序蒸馏

**Comment:** Accepted by ACL 2025 Findings

> **TL;DR:** DALR通过双层对齐学习解决了多模态句子表示中跨模态和模态内对齐的挑战，并在STS和TR任务上表现优异。

**AI_Comments:** 该论文的创新点在于提出了双层对齐学习框架（DALR），同时解决了跨模态和模态内对齐的挑战。通过引入一致性学习和排序蒸馏，DALR能够实现更细致、更准确的多模态句子表示，对提升跨模态理解能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在粗粒度对齐上存在跨模态错位偏差和模态内语义发散的问题，导致句子表示质量显著下降。

**Method:** 提出DALR（多模态句子表示的双层对齐学习）。对于跨模态对齐，引入一致性学习模块，通过软化负样本并利用辅助任务的语义相似性实现细粒度对齐。对于模态内对齐，将排序蒸馏与全局模态内对齐学习结合，以捕获更复杂的句子关系并提高表示质量。

**Result:** 在语义文本相似性（STS）和迁移（TR）任务上的全面实验验证了方法的有效性，持续证明其优于最先进的基线。

**Conclusion:** DALR通过双层对齐学习有效解决了多模态句子表示中跨模态错位偏差和模态内语义发散的挑战，显著提升了句子表示质量。

> **ai_Abstract:** 本文提出了DALR（多模态句子表示的双层对齐学习）模型，旨在解决现有方法在多模态句子表示学习中面临的跨模态错位偏差和模态内语义发散问题。DALR通过引入一致性学习模块实现细粒度跨模态对齐，并通过结合排序蒸馏和全局模态内对齐学习来捕获复杂的句子关系。实验结果表明，DALR在语义文本相似性（STS）和迁移（TR）任务上均优于现有最先进的方法。

> **摘要翻译:** 以往的多模态句子表示学习方法取得了令人印象深刻的性能。然而，大多数方法侧重于在粗粒度级别对齐图像和文本，面临两个关键挑战：跨模态错位偏差和模态内语义发散，这些问题显著降低了句子表示质量。为了解决这些挑战，我们提出了DALR（多模态句子表示的双层对齐学习）。对于跨模态对齐，我们提出了一种一致性学习模块，该模块软化负样本并利用辅助任务的语义相似性来实现细粒度跨模态对齐。此外，我们认为句子关系超越了二元正负标签，呈现出更复杂的排序结构。为了更好地捕获这些关系并提高表示质量，我们将排序蒸馏与全局模态内对齐学习相结合。在语义文本相似性（STS）和迁移（TR）任务上的全面实验验证了我们方法的有效性，持续证明其优于最先进的基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [270] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
> *skLEP：一个斯洛伐克通用语言理解基准*

*Marek Šuppa, Andrej Ridzik, Daniel Hládek, Tomáš Javůrek, Viktória Ondrejová, Kristína Sásiková, Martin Tamajka, Marián Šimko* | **Category: cs.CL, cs.AI, cs.IR, cs.LG, 68T50, I.2.7**

**Keywords:** 斯洛伐克语, 自然语言理解, 基准, skLEP, 语言模型评估

**Comment:** ACL 2025 Findings

> **TL;DR:** 引入了skLEP，首个用于评估斯洛伐克自然语言理解模型的综合基准，包含九项任务，并发布了数据集、工具包和排行榜。

**AI_Comments:** 这项工作的创新之处在于首次为斯洛伐克语NLU领域构建了一个全面且多样的评估基准，填补了该语言在NLU研究中的空白。通过提供九项不同粒度的任务、原创数据集和翻译资源，skLEP为斯洛伐克语NLU模型的发展提供了重要的基础设施。此外，开源工具包和公共排行榜的发布，极大地促进了研究的可复现性和社区协作，对推动斯洛伐克语NLU的未来研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决斯洛伐克自然语言理解（NLU）模型缺乏专门评估基准的问题，从而提供一个全面的模型能力评估工具，并促进该领域的研究。

**Method:** 研究人员引入了skLEP，一个专门为评估斯洛伐克NLU模型设计的综合基准。他们汇编了九项涵盖词汇级、句子对和文档级挑战的多样化任务。为了创建这个基准，他们整理了新的原创斯洛伐克语数据集，并精心翻译了已有的英语NLU资源。同时，他们还使用skLEP任务对各种斯洛伐克语特有、多语言和英语预训练语言模型进行了首次系统而广泛的评估。

**Result:** 引入了skLEP，这是第一个专门用于评估斯洛伐克自然语言理解（NLU）模型的综合基准。该基准包含九项多样化的任务，涵盖词汇级、句子对和文档级挑战。研究人员还对斯洛伐克语特有、多语言和英语预训练语言模型进行了首次系统而广泛的评估。此外，他们还发布了完整的基准数据、一个用于模型微调和评估的开源工具包，以及一个公共排行榜。

**Conclusion:** 该研究引入了skLEP，一个全面的斯洛伐克语NLU评估基准，并通过发布完整数据、开源工具包和公共排行榜，旨在促进斯洛伐克语NLU领域的可复现性并推动未来的研究。

> **ai_Abstract:** 本论文介绍了skLEP，首个针对斯洛伐克语自然语言理解（NLU）模型的综合性评估基准。skLEP包含九项多样化任务，涵盖词汇、句子和文档级别，旨在全面评估模型能力。为构建该基准，研究者创建了新的斯洛伐克语数据集并翻译了现有英语NLU资源。论文还首次系统评估了多种斯洛伐克语、多语言及英语预训练语言模型。为促进可复现性和未来研究，完整的基准数据、开源工具包和公共排行榜已对外发布。

> **摘要翻译:** 在这项工作中，我们介绍了skLEP，这是第一个专门为评估斯洛伐克自然语言理解（NLU）模型而设计的综合基准。我们编译了skLEP，使其包含九项多样化的任务，涵盖了词汇级、句子对和文档级挑战，从而提供了对模型能力的全面评估。为了创建这个基准，我们整理了为斯洛伐克语量身定制的全新原创数据集，并精心翻译了已有的英语NLU资源。在这篇论文中，我们还使用skLEP任务，首次对各种斯洛伐克语特有、多语言和英语预训练语言模型进行了系统而广泛的评估。最后，我们还发布了完整的基准数据、一个便于模型微调和评估的开源工具包，以及一个位于https://github.com/slovak-nlp/sklep的公共排行榜，以期促进斯洛伐克语NLU领域的可复现性并推动未来的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [271] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
> *ComRAG：面向工业实时社区问答的动态向量存储检索增强生成*

*Qinwen Chen, Wenbiao Tao, Zhiwei Zhu, Mingfan Xi, Liangzhong Guo, Yuan Wang, Wei Wang, Yunshi Lan* | **Category: cs.CL, cs.AI**

**Keywords:** 社区问答, 检索增强生成, 动态向量存储, 实时系统, 工业应用

**Comment:** 7 pages, 4 figures. Accepted at ACL 2025 Industry Track

> **TL;DR:** ComRAG是一个为工业实时社区问答设计的检索增强生成框架，它通过基于质心的记忆机制有效整合动态和静态知识，并在实际工业数据集上显著提升了性能。

**AI_Comments:** ComRAG的创新之处在于其动态向量存储和基于质心的记忆机制，这使其能够有效处理实时CQA场景中的动态知识更新和高效存储问题。其在工业数据集上的显著性能提升（尤其是在降低延迟和块增长方面）表明了其在实际工业部署中的巨大潜力。该方法为解决大规模、实时知识库的挑战提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 社区问答（CQA）平台是重要的知识库，但现有方法在实时场景中未能充分利用外部知识、动态历史问答上下文，或缺乏适用于工业部署的记忆机制，导致难以有效利用历史交互和领域知识。

**Method:** 本文提出了ComRAG，一个用于实时工业CQA的检索增强生成框架。它通过一个为检索、生成和高效存储设计的基于质心的记忆机制，将静态知识与动态历史问答对相结合。

**Result:** 在三个工业CQA数据集上的评估显示，ComRAG持续优于所有基线：向量相似性提升高达25.9%，延迟降低8.7%至23.3%，迭代过程中块增长从20.23%降至2.06%。

**Conclusion:** ComRAG通过其创新的动态向量存储和基于质心的记忆机制，有效解决了工业实时CQA中知识利用和效率的挑战，并在多项关键指标上取得了显著改进。

> **ai_Abstract:** 本文提出了ComRAG，一个专门针对工业实时社区问答（CQA）的检索增强生成框架。该框架通过引入基于质心的记忆机制，有效整合了静态领域知识与动态历史问答对，旨在解决现有方法在知识利用、动态上下文整合和工业部署适应性方面的不足。实验结果表明，ComRAG在工业CQA数据集上显著优于基线，在向量相似性、延迟和数据块增长率方面均取得了显著改进，证明了其在实际应用中的高效性和优越性。

> **摘要翻译:** 社区问答（CQA）平台可被视为社区中重要的知识库，但如何有效利用历史交互和领域知识在实时场景中仍然是一个挑战。现有方法往往未充分利用外部知识，未能整合动态的历史问答上下文，或缺乏适用于工业部署的记忆机制。我们提出了ComRAG，一个用于实时工业CQA的检索增强生成框架，它通过一个为检索、生成和高效存储设计的基于质心的记忆机制，将静态知识与动态历史问答对相结合。在三个工业CQA数据集上的评估显示，ComRAG持续优于所有基线——向量相似性提升高达25.9%，延迟降低8.7%至23.3%，迭代过程中块增长从20.23%降至2.06%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [277] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
> *Progtuning: 基于Transformer的语言模型的渐进式微调框架*

*Xiaoshuang Ji, Zhendong Zhao, Xiaojun Chen, Xin Zhao, Zeyao Liu* | **Category: cs.CL, cs.AI**

**Keywords:** Progtuning, 微调, Transformer, 参数高效, 渐进式学习

**Comment:** Accepted by ICONIP 2024

> **TL;DR:** Progtuning是一种新的渐进式微调框架，通过根据Transformer块的贡献逐步减少更新参数，从而优化资源分配并保持性能。

**AI_Comments:** Progtuning的创新之处在于其渐进式学习策略，它智能地利用了Transformer块贡献的不均衡性来优化资源分配，这对于处理日益增长的大型语言模型尤其重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有的微调和参数高效微调方法在更新参数时忽略了Transformer块贡献的不均衡性，导致计算资源分配效率低下，尤其是在模型尺寸不断增长的情况下。

**Method:** 本文提出了Progtuning框架，它结合了渐进式学习，并根据Transformer块的贡献，逐步减少需要更新的Transformer块的数量。

**Result:** Progtuning优化了资源分配，减少了约25%的更新参数，同时保持了有竞争力的性能。它还与参数高效微调方法表现出高度的适应性，在各种适应场景中展示了出色的性能。

**Conclusion:** Progtuning通过智能地减少更新参数，成功地提高了微调的效率，同时保持了性能，并且具有良好的兼容性。

> **ai_Abstract:** 本文提出了Progtuning，一个针对基于Transformer的语言模型的渐进式微调框架。该方法通过根据Transformer块的贡献逐步减少更新的参数数量，解决了传统微调和参数高效微调中计算资源分配效率低下的问题。Progtuning能够优化资源分配，在减少约25%更新参数的同时保持竞争力性能，并与现有参数高效微调方法良好兼容。

> **摘要翻译:** 微调是一种在下游任务中利用基于Transformer的语言模型的有前景的技术。随着模型尺寸的不断增长，更新所有模型参数变得越来越昂贵。参数高效微调方法通过选择性地更新一小部分参数有效地解决了这个问题。然而，微调和大多数现有的参数高效微调方法需要更新与初始尺寸相同数量的参数，忽略了Transformer块之间贡献的不均衡性，导致计算资源分配效率极低。在本文中，我们提出了Progtuning，这是一种结合了渐进式学习的基于Transformer的语言模型的新型微调框架。具体来说，Progtuning根据贡献逐步减少需要更新的Transformer块的数量。值得注意的是，Progtuning优化了资源分配，减少了大约25%的更新参数，同时仍保持了有竞争力的性能。它还与参数高效微调方法表现出高度的适应性，在各种适应场景中展示了出色的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [280] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
> *文本扩散建模的压缩平滑潜在空间*

*Viacheslav Meshchaninov, Egor Chimbulatov, Alexander Shabalin, Aleksandr Abramov, Dmitry Vetrov* | **Category: cs.CL**

**Keywords:** 文本扩散模型, 潜在空间, 文本生成, 自编码器, Cosmos

**Comment:** 

> **TL;DR:** 提出Cosmos，一种在压缩平滑潜在空间中进行文本扩散生成的方法，解决了现有文本生成模型的速度和连贯性问题，并实现了更快的推理速度和可比或更优的生成质量。

**AI_Comments:** Cosmos的创新之处在于其将文本扩散模型应用于一个专门学习的压缩平滑潜在空间，有效解决了高维度表示的挑战，并通过自编码器结合语义对齐确保了生成质量。其重要性体现在显著提升了文本生成的速度和效率，同时保持或超越了现有模型的生成质量，为未来高效、高质量的文本生成提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 自回归语言模型解码慢且难以保持全局连贯性；扩散模型应用于文本生成受限于高维度的token级表示。

**Method:** 引入Cosmos，一种在为扩散量身定制的压缩、平滑潜在空间中操作的文本生成方法。该空间通过一个自编码器学习，该自编码器同时进行token级重建和与预训练语言编码器冻结激活的对齐。

**Result:** 文本表示可压缩8倍，同时保持与token级扩散模型相当的生成质量。增加潜在序列长度使Cosmos超越了基于扩散和自回归的基线模型。在四种生成任务（故事生成、问题生成、摘要、去毒）上评估，Cosmos实现了可比或更优的生成质量，并提供超过2倍的推理速度。

**Conclusion:** Cosmos通过在压缩、平滑的潜在空间中进行文本扩散，有效克服了传统文本生成模型的局限性，在生成质量和推理速度上均表现出色。

> **ai_Abstract:** 本文提出了Cosmos，一种新颖的文本扩散生成方法，它在学习到的压缩且平滑的潜在空间中操作，以解决传统自回归模型速度慢和全局连贯性差的问题，以及扩散模型在文本上高维度表示的挑战。Cosmos通过一个同时进行token重建和语义对齐的自编码器学习该潜在空间。实验证明，Cosmos能将文本表示压缩8倍，同时保持生成质量，并在增加潜在序列长度时超越现有基线，还在多项任务上实现了更优或相当的生成质量和超过2倍的推理速度。

> **摘要翻译:** 自回归语言模型主导了现代文本生成，但其顺序性引入了根本性限制：解码速度慢，并且难以保持全局连贯性。扩散模型通过实现并行生成和灵活控制提供了有前景的替代方案；然而，它们在文本生成中的应用受到token级表示高维度的阻碍。我们引入了Cosmos，一种新颖的文本生成方法，它完全在为扩散专门定制的压缩、平滑潜在空间中操作。这个空间通过一个自编码器学习，该自编码器同时进行token级重建和与预训练语言编码器冻结激活的对齐，从而提供强大的语义基础并实现有效的基于扰动的增强。经验上，我们证明文本表示可以被压缩8倍，同时保持与token级扩散模型相当的生成质量。此外，增加潜在序列长度使得Cosmos能够超越基于扩散和自回归的基线模型。我们在四种不同的生成任务上评估了Cosmos，包括故事生成、问题生成、摘要和去毒，并将其与各种生成范式进行比较。Cosmos实现了可比或更优的生成质量，同时提供超过2倍的推理速度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [294] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
> *智能体奖励基准：迈向真实世界多模态智能体在感知、规划和安全方面的统一奖励建模基准*

*Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao* | **Category: cs.CL, cs.AI**

**Keywords:** 智能体奖励建模, 多模态大语言模型, 统一基准, 感知, 规划, 安全

**Comment:** ACL 2025 Main

> **TL;DR:** 提出了Agent-RewardBench，一个用于评估多模态大语言模型在真实世界多模态智能体中奖励建模能力的统一基准。

**AI_Comments:** 这项工作提出了一个急需的统一基准Agent-RewardBench，旨在解决多模态智能体在奖励建模方面的评估空白。其多维度、步级评估和高质量数据确保了评估的全面性和可靠性，对于推动多模态智能体在真实世界任务中的自校正和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态智能体在缺乏外部反馈时难以自我纠正和泛化。奖励模型是一个有前景的方法，但目前缺乏针对智能体的奖励模型选择标准，因此迫切需要构建一个智能体奖励基准。

**Method:** 提出了Agent-RewardBench，一个旨在评估多模态大语言模型（MLLMs）奖励建模能力的基准。该基准具有三个关键特征：1) 涵盖感知、规划和安全等7个真实世界智能体场景的多维度评估；2) 步级奖励评估，提供更细粒度的性能视图；3) 适当的难度和高质量，通过从10个不同模型中采样、难度控制和人工验证确保数据完整性。

**Result:** 实验表明，即使是最先进的多模态模型也表现出有限的性能。

**Conclusion:** 迫切需要针对智能体奖励建模进行专门训练。

> **ai_Abstract:** 本文提出了Agent-RewardBench，一个用于评估多模态大语言模型在真实世界多模态智能体中奖励建模能力的统一基准。该基准在感知、规划和安全等多个维度和步级进行评估，并确保数据的适当难度和高质量。实验结果表明，当前先进的多模态模型在奖励建模方面表现有限，强调了专门训练的必要性。

> **摘要翻译:** 随着多模态大语言模型（MLLMs）的进步，多模态智能体在网络导航和具身智能等真实世界任务中展现出前景。然而，由于缺乏外部反馈的限制，这些智能体在自我纠正和泛化方面面临困难。一个有前景的方法是使用奖励模型作为外部反馈，但目前尚不清楚如何为智能体选择奖励模型。因此，迫切需要建立一个针对智能体的奖励基准。为了解决这些挑战，我们提出了Agent-RewardBench，一个旨在评估MLLMs中奖励建模能力的基准。该基准具有三个关键特征：(1) 多维度和真实世界智能体场景评估。它涵盖了感知、规划和安全等7个场景；(2) 步级奖励评估。它允许在任务的单个步骤评估智能体能力，从而在规划过程中提供更细粒度的性能视图；以及(3) 适当的难度和高质量。我们从10个不同的模型中仔细采样，控制难度以保持任务挑战性，并进行人工验证以确保数据的完整性。实验表明，即使是最先进的多模态模型也表现出有限的性能，这凸显了对智能体奖励建模进行专门训练的需求。代码可在github上获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [297] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
> *猫捉老鼠——虚假文本生成能否超越检测系统？*

*Andrea McGlinchey, Peter J Barclay* | **Category: cs.CL**

**Keywords:** 虚假文本检测, 大型语言模型, 文本生成, Gemini, GPT

**Comment:** (Submitted for publication)

> **TL;DR:** 大型语言模型生成的虚假文本能否被检测系统持续有效识别？研究发现，在经典侦探小说风格的虚假文本生成中，Gemini模型的欺骗性有所增强，而GPT没有，表明即使模型越来越大，可靠检测仍可能可行，但新的模型架构可能会提高其欺骗性。

**AI_Comments:** 本文通过具体实验对比了不同LLM在生成欺骗性文本方面的表现，为虚假文本检测的未来趋势提供了初步见解。其创新点在于将“猫捉老鼠”的博弈概念应用于LLM生成与检测领域，并指出模型架构而非单纯的模型规模可能是影响欺骗性的关键因素。这对于理解AI内容安全和发展更有效的检测策略具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于大型语言模型（LLMs）能够生成令人信服的“虚假文本”，并且检测这些文本的方法不断发展，本文旨在探讨这种“军备竞赛”是否会达到一个瓶颈，即生成模型的能力是否会超越检测系统。

**Method:** 研究人员通过检查统计分类器识别经典侦探小说风格的“虚假文本”的能力来解决这个问题。具体比较了Gemini和GPT模型在版本更新后的欺骗性。

**Result:** 在0.5版本更新后，Gemini模型生成欺骗性文本的能力有所增强，而GPT模型则没有表现出这种趋势。

**Conclusion:** 研究结果表明，即使面对不断增大的模型，虚假文本的可靠检测仍然是可行的。然而，新的模型架构可能会提高其欺骗性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）生成的虚假文本与检测系统之间的“猫捉老鼠”式竞争。研究发现，尽管LLMs不断增大且资源消耗更多，但相对简单的分类器仍能有效检测。通过分析统计分类器识别经典侦探小说风格虚假文本的能力，结果显示Gemini在版本升级后生成欺骗性文本的能力有所提高，而GPT没有。这暗示着虚假文本的可靠检测即使面对大型模型仍可能实现，但新型模型架构可能增强其欺骗性。

> **摘要翻译:** 大型语言模型可以在学术写作、产品评论和政治新闻等领域生成令人信服的“虚假文本”。许多方法已被研究用于检测人工智能生成的文本。虽然这似乎预示着一场无休止的“军备竞赛”，但我们注意到，更新的LLM使用了越来越多的参数、训练数据和能源，而相对简单的分类器则以适度的资源展示了良好的检测准确性。为了探讨模型击败检测器的能力是否因此达到一个平台期，我们检查了统计分类器识别经典侦探小说风格的“虚假文本”的能力。在0.5版本升级后，我们发现Gemini生成欺骗性文本的能力有所增强，而GPT则没有。这表明，即使对于越来越大的模型，虚假文本的可靠检测可能仍然可行，尽管新的模型架构可能会提高其欺骗性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [299] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
> *Double-Checker：通过自我批判微调增强慢思考LLMs的推理能力*

*Xin Xu, Tianhao Chen, Fan Zhang, Wanlong Liu, Pengxiang Li, Ajay Kumar Jaiswal, Yuchen Yan, Jishan Hu, Yang Wang, Hao Chen, Shiwei Liu, Shizhe Diao, Can Yang, Lu Yin* | **Category: cs.CL**

**Keywords:** LLMs, 自我批判, 推理, 微调, Double-Checker

**Comment:** 10 pages

> **TL;DR:** Double-Checker是一个通过自我批判微调来增强慢思考LLMs推理能力的框架，显著提升了其在推理基准上的表现，尤其是在AIME测试中。

**AI_Comments:** Double-Checker的创新之处在于其通过“自我批判微调”来增强LLMs的推理能力，这是一种新颖且有效的提升模型反思和纠错能力的方法。该方法通过迭代地自我评估和完善输出，显著提升了模型在复杂推理任务上的性能，尤其是在数学推理方面。这对于构建更自主、更值得信赖的AI系统具有重要意义，因为它让LLMs能够像人类一样进行内部的反思和修正，而不是简单地输出首次生成的结果。

<details>
  <summary>Details</summary>

**Motivation:** 慢思考大型语言模型（LLMs）虽然展现出类似反思的推理能力，但其生成信息性批判和完善先前解决方案的能力有限。

**Method:** 本文引入了Double-Checker框架，旨在通过促进明确的自我批判和对其先前解决方案的迭代完善来增强慢思考LLMs的推理能力。该框架通过对1,730个自我批判实例进行微调，使long-CoT LLMs能够在推理过程中迭代地批判和完善其输出，直到它们根据自我生成的批判将解决方案评估为正确。

**Result:** Double-Checker在全面的推理基准测试中验证了其有效性，表明迭代自我批判显著增强了long-CoT LLMs的推理能力。值得注意的是，与原始的long-CoT LLMs相比，Double-Checker将具有挑战性的AIME基准测试中的pass@1性能从4.4%提高到18.2%。

**Conclusion:** 这些结果为开发更值得信赖、更有效的、能够进行结构化自我批判的LLMs指明了一个有前途的方向。

> **ai_Abstract:** 本文提出了Double-Checker，一个旨在通过自我批判微调来提升慢思考LLMs推理能力的框架。通过对1,730个自我批判实例的精细训练，Double-Checker使LLMs能迭代地批判并完善其解决方案，直至自我评估为正确。实验结果表明，该方法显著提升了LLMs在多项推理基准上的表现，特别是在AIME测试中将pass@1性能从4.4%提高到18.2%，为开发更可靠且具自我批判能力的LLMs提供了新方向。

> **摘要翻译:** 虽然慢思考大型语言模型（LLMs）展现出类似反思的推理能力，通常被称为“顿悟时刻”，但它们生成信息性批判和完善先前解决方案的能力仍然有限。在本文中，我们引入了Double-Checker，这是一个旨在通过促进明确的自我批判和对其先前解决方案的迭代完善来增强慢思考LLMs推理能力的原则性框架。通过对我们精选的1,730个自我批判实例进行微调，Double-Checker使long-CoT LLMs能够在推理过程中迭代地批判和完善其输出，直到它们根据自我生成的批判将解决方案评估为正确。我们在全面的推理基准测试中验证了Double-Checker的有效性，表明迭代自我批判显著增强了long-CoT LLMs的推理能力。值得注意的是，我们的Double-Checker将具有挑战性的AIME基准测试中的pass@1性能从原始long-CoT LLMs的4.4%提高到18.2%。这些结果为开发更值得信赖、更有效的、能够进行结构化自我批判的LLMs指明了一个有前途的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [304] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
> *使用自回归语言模型检测视觉接地对话中的指称表达*

*Bram Willemsen, Gabriel Skantze* | **Category: cs.CL, cs.AI**

**Keywords:** 指称表达检测, 视觉接地对话, 自回归语言模型, 纯文本方法, 多模态

**Comment:** Accepted for publication at XLLM @ ACL 2025

> **TL;DR:** 本文探讨了使用纯文本自回归语言模型从视觉接地对话中提取指称表达，发现即使是纯文本方法在语言上下文的帮助下也能有效，但该任务本质上是多模态的。

**AI_Comments:** 本文创新性地探索了在视觉接地对话中，纯文本语言模型在指称表达检测任务上的潜力，并强调了语言上下文的重要性。其重要性在于证明了在某些情况下，即使缺乏视觉信息，语言模型也能在多模态任务中取得一定效果。然而，作者也明确指出了纯模态方法的局限性，即该任务的本质是多模态的，这为未来的研究指明了方向，即需要结合视觉信息来解决该问题。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探究仅凭语言上下文能在多大程度上帮助检测在对话视觉上下文中具有（视觉上可感知）指代物的提及。

**Method:** 采用纯文本、自回归语言建模方法。具体地，通过下一词元预测来划定文本中的提及范围边界，从而将预训练的大型语言模型（LLM）适配到对话中进行粗粒度提及范围标注。

**Result:** 研究结果表明，即使使用中等规模的LLM、相对较小的数据集和参数高效的微调，纯文本方法也能有效，这突出了语言上下文对于此任务的相对重要性。

**Conclusion:** 尽管纯文本方法有效，但作者认为该任务本质上是一个多模态问题，并讨论了单模态方法的根本局限性。

> **ai_Abstract:** 本文研究了在视觉接地对话中，仅使用文本的自回归语言模型来检测指称表达的可行性。研究通过调整一个预训练LLM，利用下一词元预测进行提及范围标注。结果显示，即使在资源有限的情况下，纯文本方法也能有效识别指称表达，这强调了语言上下文的重要性。但作者也指出，指称表达检测本质上是多模态问题，并讨论了单模态方法的局限性。

> **摘要翻译:** 在本文中，我们探索了使用一种仅基于文本的自回归语言建模方法，从视觉接地对话中提取指称表达。更具体地说，目标是调查仅凭语言上下文能在多大程度上帮助检测在对话视觉上下文中具有（视觉上可感知）指代物的提及。为此，我们调整了一个预训练的大型语言模型（LLM），通过下一词元预测在文本中划定提及范围边界，从而在展开的对话中执行相对粗粒度的提及范围标注。我们的发现表明，即使在使用中等规模的LLM、相对较小的数据集和参数高效的微调时，纯文本方法也能有效，这突出了语言上下文对于此任务的相对重要性。然而，我们认为该任务代表了一个固有的多模态问题，并讨论了单模态方法固有的局限性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [307] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
> *人工智能文学批评的结构主义方法：利用格雷马斯符号方阵处理大型语言模型*

*Fangzhou Dong, Yifan Zeng, Yingpeng Sang, Hong Shen* | **Category: cs.CL**

**Keywords:** 大型语言模型, 文学批评, 格雷马斯符号方阵, 结构主义, 叙事分析

**Comment:** Accepted in CogSci 2025

> **TL;DR:** 本文提出了GLASS框架，一个基于格雷马斯符号方阵的结构化分析框架，以增强大型语言模型进行深度文学分析的能力，并创建了首个相关数据集和量化指标，实验结果显示其表现出色，并成功应用于经典作品。

**AI_Comments:** 本文的创新之处在于将结构主义的格雷马斯符号方阵引入到人工智能文学批评领域，为大型语言模型提供了一个系统化的分析框架。通过构建专门的数据集和量化指标，该研究为LLMs进行深度文学分析提供了新的路径，并展示了其在生成高质量文学分析方面的潜力。这对于文学研究和教育领域具有重要意义，尤其是在自动化和辅助分析复杂文本方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在理解和生成文本方面表现出色，但在为思想深刻、叙事复杂的作品提供专业文学批评方面存在困难。

**Method:** 本文提出了GLASS（Greimas Literary Analysis via Semiotic Square）框架，这是一个基于格雷马斯符号方阵（GSS）的结构化分析框架，旨在增强LLMs进行深度文学分析的能力。研究者提出了首个基于GSS的文学批评数据集，包含48部作品的详细分析，并使用“LLM即评判者”范式提出了基于GSS的文学批评的量化指标。

**Result:** GLASS框架的结果与专家批评以及多个作品和LLMs的比较显示出高性能。此外，GLASS被应用于39部经典作品，产生了原创且高质量的分析，填补了现有研究空白。

**Conclusion:** 这项研究提供了一个基于人工智能的文学研究和教育工具，为文学参与背后的认知机制提供了见解。

> **ai_Abstract:** 本文提出了一种名为GLASS（Greimas Literary Analysis via Semiotic Square）的结构化分析框架，旨在解决大型语言模型（LLMs）在提供专业文学批评方面的不足。GLASS基于格雷马斯符号方阵（GSS），能够帮助LLMs深入剖析叙事作品的结构和深层含义。研究者构建了首个基于GSS的文学批评数据集（包含48部作品），并引入了使用“LLM即评判者”范式的量化评估指标。实验结果表明，GLASS在与专家批评和不同LLMs的比较中表现出色。该框架成功应用于39部经典作品，生成了高质量的原创分析，填补了现有研究空白。这项工作为文学研究和教育提供了一个AI工具，并有助于理解文学认知机制。

> **摘要翻译:** 大型语言模型（LLMs）在理解和生成文本方面表现出色，但在为思想深刻、叙事复杂的作品提供专业文学批评方面存在困难。本文提出了GLASS（Greimas Literary Analysis via Semiotic Square），一个基于格雷马斯符号方阵（GSS）的结构化分析框架，以增强LLMs进行深度文学分析的能力。GLASS有助于快速剖析叙事作品中的叙事结构和深层含义。我们提出了首个用于基于GSS的文学批评的数据集，其中包含48部作品的详细分析。然后，我们使用“LLM即评判者”范式提出了基于GSS的文学批评的量化指标。我们的框架结果，与多个作品和LLMs的专家批评进行比较，显示出高性能。最后，我们将GLASS应用于39部经典作品，产生了原创且高质量的分析，解决了现有研究空白。这项研究提供了一个基于人工智能的文学研究和教育工具，为文学参与背后的认知机制提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [314] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
> *领域知识增强型大型语言模型用于欺诈和概念漂移检测*

*Ali Şenol, Garima Agrawal, Huan Liu* | **Category: cs.CL, cs.AI**

**Keywords:** 领域知识, 大型语言模型, 欺诈检测, 概念漂移, 对话检测

**Comment:** 

> **TL;DR:** 本文提出一个领域知识增强型LLM框架，用于检测欺诈性对话和概念漂移，通过集成结构化领域知识显著提高了检测准确性和鲁棒性。

**AI_Comments:** 这项研究通过将领域知识与大型语言模型相结合，为风险敏感型自然语言处理任务提供了一个创新性解决方案，尤其是在欺诈检测和概念漂移识别方面。其模块化设计和在实际数据集上的高精度表现，凸显了领域知识在提升LLM性能和鲁棒性方面的关键作用，为未来高风险应用中的LLM部署提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 在动态平台上检测欺骗性对话日益困难，因为语言模式不断演变和概念漂移（语义或主题变化）的出现，这些变化会模糊恶意意图或模仿正常对话，使得准确分类具有挑战性。虽然大型语言模型（LLMs）在自然语言任务中表现出色，但在风险敏感场景中它们经常面临上下文歧义和幻觉问题。

**Method:** 本文提出了一个领域知识（DK）增强型LLM框架，将预训练的LLMs与结构化、任务特定的洞察相结合，以执行欺诈和概念漂移检测。该架构包含三个主要组件：1）一个DK-LLM模块用于检测虚假或欺骗性对话；2）一个漂移检测单元（OCDD）用于确定是否发生了语义漂移；3）第二个DK-LLM模块用于将漂移分类为良性或欺诈性。研究首先使用虚假评论数据集验证了领域知识的价值，然后将完整框架应用于SEConvo多轮对话数据集。

**Result:** 结果表明，该系统能够高精度地检测虚假对话，并有效分类漂移的性质。在结构化提示的指导下，基于LLaMA的实现达到了98%的分类准确率。与零样本基线进行的对比研究表明，整合领域知识和漂移感知显著提高了高风险NLP应用中的性能、可解释性和鲁棒性。

**Conclusion:** 整合领域知识和漂移感知能够显著提升大型语言模型在检测欺诈性对话和概念漂移方面的性能、可解释性和鲁棒性，尤其是在高风险的自然语言处理应用中。

> **ai_Abstract:** 本文提出了一种领域知识（DK）增强型大型语言模型（LLM）框架，旨在解决动态平台中欺诈性对话和概念漂移检测的挑战。该框架通过集成结构化、任务特定的领域知识来增强预训练LLMs，以应对上下文歧义和幻觉问题。其核心包含三个模块：检测欺骗性对话的DK-LLM、识别语义漂移的OCDD，以及分类漂移性质的第二个DK-LLM。实验证明，该系统在检测虚假对话和分类漂移方面表现出高准确性，其中基于LLaMA的实现达到了98%的分类精度。研究结果表明，引入领域知识和漂移感知能够显著提升高风险NLP应用中的性能、可解释性和鲁棒性。

> **摘要翻译:** 在动态平台上检测欺骗性对话因语言模式的演变和概念漂移（即随着时间推移改变交互上下文或意图的语义或主题转变）而日益困难。这些转变可能掩盖恶意意图或模仿正常对话，使得准确分类具有挑战性。尽管大型语言模型（LLMs）在自然语言任务中表现出强大的性能，但在风险敏感场景中它们经常面临上下文歧义和幻觉问题。为了解决这些挑战，我们提出了一个领域知识（DK）增强型LLM框架，该框架将预训练的LLMs与结构化、任务特定的洞察相结合，以执行欺诈和概念漂移检测。所提出的架构包含三个主要组件：(1) 一个DK-LLM模块用于检测虚假或欺骗性对话；(2) 一个漂移检测单元（OCDD）用于确定是否发生了语义漂移；以及 (3) 第二个DK-LLM模块用于将漂移分类为良性或欺诈性。我们首先使用一个虚假评论数据集验证了领域知识的价值，然后将我们的完整框架应用于SEConvo，一个包含各种类型欺诈和垃圾邮件攻击的多轮对话数据集。结果显示，我们的系统能够高精度地检测虚假对话，并有效分类漂移的性质。在结构化提示的指导下，基于LLaMA的实现达到了98%的分类准确率。与零样本基线进行的对比研究表明，整合领域知识和漂移感知显著提高了高风险NLP应用中的性能、可解释性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [323] [TopK Language Models](https://arxiv.org/abs/2506.21468)
> *TopK 语言模型*

*Ryosuke Takahashi, Tatsuro Inaba, Kentaro Inui, Benjamin Heinzerling* | **Category: cs.CL**

**Keywords:** TopK 语言模型, 可解释性, 稀疏自编码器, Transformer, 神经元干预

**Comment:** 

> **TL;DR:** 本文提出了一种名为 TopK 语言模型的新型 Transformer 架构，通过在选定层引入 TopK 激活函数，解决了稀疏自编码器（SAE）在语言模型可解释性方面存在的训练后置、特征不稳定和概念发现不明确等问题，实现了与 SAEs 相当的可解释性，同时保持模型能力，并促进了对语言模型学习过程的深入分析。

**AI_Comments:** 这项工作具有重要的创新性，它将可解释性从一个独立的后处理步骤整合到模型架构本身。通过在训练阶段直接生成可解释的稀疏表示，TopK LMs 解决了传统 SAE 的主要痛点，如训练依赖性、特征稳定性和概念归属问题。这种内建的可解释性不仅提高了分析效率，也为未来更深入地理解和控制大型语言模型提供了坚实的基础，特别是在追踪概念学习和进行神经元干预方面展现出巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏自编码器（SAE）是分析和解释 Transformer 语言模型（LM）激活空间的重要工具，但存在多项缺点，包括：训练后置导致无法确定概念发现失败的原因是 SAE 还是底层 LM；训练条件和架构选择影响 SAE 特征学习；以及特征稳定性差导致难以比较不同检查点间的 SAE 特征。

**Method:** 作者对 Transformer 架构进行了修改，在选定层引入了 TopK 激活函数，使模型的隐藏状态等同于 TopK SAE 的潜在特征。这种方法消除了对后置训练的需求，同时提供了与 SAE 相当的可解释性。

**Result:** TopK 语言模型在模型大小、计算效率和可解释性之间取得了有利的权衡。尽管架构变化简单，TopK 语言模型保持了其原始能力，并提供了强大的可解释性优势。实验表明，TopK 语言模型学习到的稀疏表示能够通过有针对性的神经元干预实现成功的引导，并有助于详细分析跨检查点和层的神经元形成过程。

**Conclusion:** TopK 语言模型提供了一种稳定可靠的工具，用于理解语言模型如何学习和表示概念，有望显著推动未来在模型可解释性和可控性方面的研究。

> **ai_Abstract:** 本文提出了一种名为 TopK 语言模型的新型 Transformer 架构，旨在解决稀疏自编码器（SAE）在解释语言模型时面临的挑战，如训练后置性、特征不稳定和概念发现模糊性。通过在 Transformer 的选定层集成 TopK 激活函数，TopK LMs 直接在模型训练过程中生成与 TopK SAE 潜在特征等效的隐藏状态，从而无需事后训练。这种方法在保持原始模型能力的同时，提供了与 SAE 相当甚至更优的可解释性，并在模型大小、计算效率和可解释性之间实现了良好平衡。实验证明，TopK LMs 学习到的稀疏表示能够实现有效的神经元干预和对概念形成过程的深入分析，使其成为理解语言模型学习机制的稳定可靠工具，有望推动模型可解释性和可控性领域的发展。

> **摘要翻译:** 稀疏自编码器（SAE）已成为分析和解释基于 Transformer 的语言模型（LM）激活空间的重要工具。然而，SAE 存在一些缺点，降低了其实用性和内部有效性。由于 SAE 是事后训练的，因此不清楚未能发现特定概念是 SAE 的问题，还是底层 LM 未表示该概念。训练条件和架构选择影响 SAE 学习哪些特征，这使得这个问题更加严重。在追踪 LM 在训练期间如何学习概念时，特征稳定性的缺乏也使得难以比较不同检查点之间的 SAE 特征。为了解决这些限制，我们对 Transformer 架构进行了修改，在选定层引入了 TopK 激活函数，使模型的隐藏状态等同于 TopK SAE 的潜在特征。这种方法消除了对事后训练的需求，同时提供了与 SAE 相当的可解释性。由此产生的 TopK LM 在模型大小、计算效率和可解释性之间提供了有利的权衡。尽管这种简单的架构改变，TopK LM 仍保持其原始能力，同时提供强大的可解释性益处。我们的实验表明，TopK LM 学习到的稀疏表示能够通过有针对性的神经元干预实现成功的引导，并促进对跨检查点和层的神经元形成过程的详细分析。这些特性使 TopK LM 成为理解语言模型如何学习和表示概念的稳定可靠工具，我们相信这将显著推动未来在模型可解释性和可控性方面的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [326] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
> *弥合LLMs的离线和在线强化学习*

*Jack Lanchantin, Angelica Chen, Janice Lan, Xian Li, Swarnadeep Saha, Tianlu Wang, Jing Xu, Ping Yu, Weizhe Yuan, Jason E Weston, Sainbayar Sukhbaatar, Ilia Kulikov* | **Category: cs.CL**

**Keywords:** 强化学习, 大型语言模型, 微调, 在线学习, 离线学习

**Comment:** 

> **TL;DR:** 研究发现，在线和半在线强化学习方法在微调大型语言模型时，显著优于离线方法，并且DPO和GRPO表现相似。

**AI_Comments:** 本文的创新点在于系统地比较了不同在线程度的强化学习方法（离线、半在线、在线）在LLM微调中的表现，并发现在线方法显著优于离线方法，这对于LLM的持续学习和适应性非常重要。同时，DPO和GRPO的相似表现也提供了实际应用中的选择灵活性。多任务学习的发现也很有价值，表明可以同时优化不同类型的奖励。

<details>
  <summary>Details</summary>

**Motivation:** 探索强化学习方法在大型语言模型微调中，从离线到半在线再到完全在线场景的有效性，涵盖可验证和不可验证任务。

**Method:** 研究调查了在可验证的数学任务和不可验证的指令遵循任务上，将强化学习方法应用于LLM微调。具体比较了在线和半在线的直接偏好优化（DPO）和组奖励策略优化（GRPO）目标。

**Result:** 发现在线和半在线的DPO与GRPO在性能和收敛性上表现相似，并且它们都显著优于离线方法。此外，将可验证和不可验证奖励进行多任务联合训练可以提高两种任务类型的性能。

**Conclusion:** 在LLM微调中，在线和半在线强化学习方法比离线方法更有效，且DPO和GRPO表现相当；多任务学习可进一步提升性能。

> **ai_Abstract:** 本文探讨了强化学习方法在大型语言模型微调中从离线到在线的有效性，涵盖可验证和不可验证任务。研究发现，在线和半在线的DPO与GRPO在性能和收敛性上表现相似，且均显著优于离线方法。此外，多任务联合训练可进一步提升LLM在不同任务类型上的性能。

> **摘要翻译:** 我们研究了强化学习方法在大型语言模型微调中从离线到半在线再到完全在线方案的有效性，涵盖可验证和不可验证任务。我们的实验包括在可验证的数学任务和不可验证的指令遵循任务上进行训练，并对两者进行了一系列基准评估。在这些设置中，我们广泛比较了在线和半在线的直接偏好优化（Direct Preference Optimization）和组奖励策略优化（Group Reward Policy Optimization）目标，并惊奇地发现这些变体在性能和收敛性上相似，它们都显著优于离线方法。我们提供了详细的训练动态和超参数选择策略分析，以实现最佳结果。最后，我们展示了将可验证和不可验证奖励进行多任务联合训练可以提高两种任务类型的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [329] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
> *通过交互式大型语言模型对齐增强社交驱动对话中的用户参与度*

*Jiashuo Wang, Kaitao Song, Chunpu Xu, Changhe Song, Yang Xiao, Dongsheng Li, Lili Qiu, Wenjie Li* | **Category: cs.CL**

**Keywords:** 用户参与度, 社交驱动对话, 交互式大型语言模型, 直接偏好优化, i×MCTS

**Comment:** 

> **TL;DR:** 该研究提出了一种通过将用户反应作为奖励信号来对齐交互式大型语言模型的方法，以增强社交驱动对话中的用户参与度。通过用户模拟器和i×MCTS收集数据，并使用DPO进行模型对齐，实验证明其能有效提升用户参与度。

**AI_Comments:** 本研究的创新之处在于直接将用户反应作为LLM对齐的奖励信号，这解决了传统方法无法保证用户参与度的微妙问题。此外，利用用户模拟器和i×MCTS进行数据收集，为DPO的应用提供了可能，这也是一个显著的贡献。该研究的重要性在于提升了LLMs在社交语境中的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究优化模型以推理相关知识或规划对话行为流程，但这些方法与用户参与度之间的关系是微妙的，并不能保证在社交驱动对话中的用户参与度。因此，需要一种更直接、更有效的方法来学习和提升用户参与度。

**Method:** 该方法将用户在互动后与对话意图相关的反应作为直接且相关的用户参与度指标，并以此作为奖励来对齐交互式大型语言模型（LLMs）。为此，研究开发了一个用户模拟器与目标LLMs进行互动，并利用i×MCTS（用于交互的蒙特卡洛树搜索）来探索用户与LLM系统之间的互动，从而收集包含高质量和低质量体验对的数据集。最后，通过直接偏好优化（DPO）来对齐交互式LLMs以实现高水平的用户参与度。

**Result:** 在两种社交驱动对话场景（情感支持对话和劝善）中进行的实验表明，所提出的方法能够有效增强交互式大型语言模型中的用户参与度。

**Conclusion:** 该方法在社交驱动对话场景中，能够有效增强交互式大型语言模型中的用户参与度。

> **ai_Abstract:** 本论文提出了一种新颖的方法，通过直接将交互式大型语言模型（LLMs）与用户反应对齐，从而增强社交驱动对话中的用户参与度。与以往侧重于知识或对话行为的方法不同，本研究将互动后的用户反应作为奖励信号。论文引入了一个用户模拟器和i×MCTS来收集偏好数据，并利用这些数据通过直接偏好优化（DPO）来训练LLMs。在情感支持和劝善对话场景中的实验表明，该方法能够有效提升用户参与度。

> **摘要翻译:** 通过互动增强用户参与度在社交驱动的对话中扮演着至关重要的角色。尽管先前的研究已经优化了模型以推理相关知识或规划对话行为流程，但用户参与度与知识或对话行为之间的关系是微妙的，并不能保证在社交驱动对话中的用户参与度。为此，我们通过利用对话未来发展中的信号，使交互式大型语言模型能够学习用户参与度。具体而言，我们采用一个更直接、更相关的用户参与度指标，即用户在互动后与对话意图相关的反应，作为奖励来对齐交互式大型语言模型。为了实现这一点，我们开发了一个用户模拟器来与目标交互式大型语言模型互动，并通过i×MCTS（用于交互的蒙特卡洛树搜索）探索用户与交互式大型语言模型系统之间的互动。通过这种方式，我们使用i×MCTS收集了一个包含高质量和低质量体验对的数据集，并相应地通过直接偏好优化（DPO）对齐交互式大型语言模型以实现高水平的用户参与度。在两种社交驱动对话场景（情感支持对话和劝善）中进行的实验表明，我们的方法有效增强了交互式大型语言模型中的用户参与度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [334] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
> *大型语言模型中的波将金式理解*

*Marina Mancoridis, Bec Weeks, Keyon Vafa, Sendhil Mullainathan* | **Category: cs.CL, cs.AI**

**Keywords:** 大型语言模型, 基准测试, 波将金式理解, 概念不连贯性, 评估

**Comment:** 

> **TL;DR:** 大型语言模型在基准测试上的成功可能只是“波将金式理解”（虚假理解），而非真正的人类式理解，因为它们的内部概念表征存在不连贯性。

**AI_Comments:** 这篇论文提出了一个关于当前大型语言模型评估方法有效性的关键问题。它挑战了基准测试高分等同于真实人类式理解的假设，引入了“波将金式理解”这一概念。这强调了需要开发更复杂的评估指标，以深入探究LLM概念表征的内部一致性和与人类认知的对齐程度，超越表面性能的评估。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在探讨用于评估大型语言模型（LLMs）的基准测试的有效性。作者质疑基于LLMs在特定问题集上的表现来推断其能力是否合理，并指出如果LLMs的误解方式与人类不同，那么这些基准测试的有效性就会受到质疑。

**Method:** 论文首先提出了一个形式化框架来解决这一问题。接着，它提出了两种量化“波将金式理解”的方法：一种是使用在三个领域中特别设计的基准测试，另一种是提供其普遍性下限的通用程序。

**Result:** 研究发现，“波将金式理解”在不同模型、任务和领域中普遍存在。这些失败不仅反映了不正确的理解，而且反映了概念表征中更深层次的内部不连贯性。

**Conclusion:** 大型语言模型在基准测试上的成功可能只是一种“波将金式理解”，即理解的假象，其答案与人类对概念的解释方式不符，这源于其内部概念表征的深层不连贯性。

> **ai_Abstract:** 该论文引入了一个形式化框架，旨在审视大型语言模型（LLMs）基准测试的有效性。文章提出，如果LLMs的误解方式未能反映人类的误解，那么它们在基准测试上的成功可能仅是“波将金式理解”——一种理解的假象。通过两种量化程序，包括一个专门设计的基准测试，研究发现“波将金式理解”在不同模型、任务和领域中普遍存在，这揭示了LLMs内部概念表征的深层不连贯性，而非仅仅是错误的理解。

> **摘要翻译:** 大型语言模型（LLMs）通常使用基准数据集进行评估。但是，基于LLM对一系列精心策划问题的回答来推断其能力，这种做法的合理性何在？本文首先提出了一个形式化框架来解决这个问题。关键在于，用于测试LLMs的基准测试——例如AP考试——也用于测试人类。然而，这带来了一个隐含的推论：只有当LLMs对概念的误解方式与人类的误解方式相似时，这些基准测试才是有效的。否则，基准测试的成功仅证明了波将金式理解：一种由与任何人类解释概念的方式不符的答案所驱动的理解幻觉。我们提出了两种量化波将金存在的程序：一种是使用在三个领域中特别设计的基准测试，另一种是提供其普遍性下限的通用程序。我们发现波将金式理解在各种模型、任务和领域中普遍存在。我们还发现这些失败不仅反映了不正确的理解，而且反映了概念表征中更深层次的内部不连贯性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [338] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
> *语言模型训练中的数据效能*

*Yalun Dai, Yangyu Huang, Xin Zhang, Wenshan Wu, Chong Li, Wenhui Lu, Shijie Cao, Li Dong, Scarlett Li* | **Category: cs.CL**

**Keywords:** 数据效能, 语言模型训练, 数据组织, DELT, 可学习性-质量评分, 折叠排序

**Comment:** 

> **TL;DR:** 本文引入了“数据效能”概念，旨在优化语言模型训练数据的组织方式。提出了DELT范式，包含数据评分（如LQS）和数据排序（如FO），实验证明其在不增加数据或模型规模的情况下显著提升了LM性能。

**AI_Comments:** 这篇论文提出了一个新颖且重要的视角——“数据效能”，与现有专注于“数据效率”的研究形成互补。通过强调训练数据的组织而非仅仅选择，它为提高语言模型性能开辟了新的途径。所提出的DELT范式及其LQS和FO方法提供了实现这一目标的具体方案，并在不增加计算资源的情况下显示出显著的性能提升，这体现了其关键创新性。

<details>
  <summary>Details</summary>

**Motivation:** 当前语言模型训练研究主要集中在“数据效率”（选择最优数据子集）上，而“数据效能”（优化训练数据组织）这一方向相对未被充分探索。本文旨在通过探索数据效能来补充数据效率，从而最大化模型性能。

**Method:** 本文定义了数据效能，即通过优化训练数据组织来最大化性能。提出了一种通用范式DELT，包含数据评分、数据选择和数据排序三个组件。具体设计了可学习性-质量评分（LQS）作为数据评分的新实例，从梯度一致性角度考虑数据样本的可学习性和质量；设计了折叠排序（FO）作为数据排序的新颖实例，以解决模型遗忘和数据分布偏差问题。

**Result:** 实验验证了语言模型训练中的数据效能：1. 所提出的DELT的各种实例在不增加数据规模和模型大小的情况下，不同程度地提升了LM性能。2. 其中，LQS用于数据评分和Folding用于数据排序的组合实现了最显著的改进。3. 数据效能可以通过应用数据选择与数据效率协同实现。

**Conclusion:** 数据效能是语言模型训练中一个有前景的基础领域。

> **ai_Abstract:** 本文引入了“数据效能”这一新概念，旨在通过优化语言模型训练数据的组织方式来最大化性能，以补充现有的“数据效率”研究。作者提出了DELT通用范式，包含数据评分、数据选择和数据排序三个核心组件。特别地，论文设计了可学习性-质量评分（LQS）和折叠排序（FO），分别用于评估数据样本的学与质量以及解决模型遗忘和数据分布偏差。实验结果表明，DELT，尤其是LQS和FO的结合，能在不增加数据或模型规模的前提下显著提升LM性能，突显了数据效能作为LM训练中一个基础且有前景的研究方向。

> **摘要翻译:** 数据是语言模型（LM）训练的基础。最近的研究致力于数据效率，旨在通过选择最小或最优的训练数据子集来最大化性能。数据过滤、采样和选择等技术在此领域发挥着关键作用。为了补充这一点，我们定义了数据效能，它侧重于通过优化训练数据的组织来最大化性能，并且相对未被充分探索。这项工作引入了一种通用的范式DELT，用于在LM训练中考虑数据效能，强调了训练数据组织的重要性。DELT包含三个组件：数据评分、数据选择和数据排序。在这些组件中，我们设计了可学习性-质量评分（LQS）作为数据评分的一个新实例，它从梯度一致性的角度考虑了每个数据样本的可学习性和质量。我们还设计了折叠排序（FO）作为数据排序的一个新颖实例，它解决了模型遗忘和数据分布偏差等问题。全面的实验验证了LM训练中的数据效能，表明：首先，所提出的DELT的各种实例在不增加数据规模和模型大小的情况下，不同程度地提升了LM性能。其次，在这些实例中，我们提出的用于数据评分的LQS和用于数据排序的折叠（Folding）的组合实现了最显著的改进。最后，通过应用数据选择，数据效能可以与数据效率一起实现。因此，我们认为数据效能是LM训练中一个有前景的基础领域。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [20] [Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions](https://arxiv.org/abs/2506.20677)
> *自适应混合排序：针对不同数据分布的动态策略选择以实现最优排序*

*Shrinivass Arunachalam Balasubramanian* | **Category: cs.DS, cs.DB, cs.PF**

**Keywords:** 自适应排序, 混合排序, 动态策略选择, 数据分布, XGBoost

**Comment:** 11 Pages, 5 figures

> **TL;DR:** 本文提出了一种自适应混合排序范式，通过实时监测输入数据模式，自动选择最有效的排序算法（计数排序、基数排序或快速排序），以在执行时间、灵活性和效率方面显著优于传统静态排序算法。

**AI_Comments:** 该论文的创新点在于提出了一个动态自适应的混合排序框架，通过机器学习（XGBoost）和状态机来智能选择最佳排序策略，有效解决了单一排序算法无法适应多样化数据分布的挑战。其重要性在于提升了排序操作在实际应用中的效率和灵活性，特别是在大数据和资源受限环境中具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的排序算法无法在所有数据分布下都达到最优性能，这影响了大规模数据系统、实时系统和嵌入式计算的性能。

**Method:** 该方法首先通过特征提取模块计算数据量、值范围和熵等关键参数。然后，这些参数被发送到一个决策引擎，该引擎结合有限状态机和XGBoost分类器来智能选择最优排序策略。具体实现为：在小键范围上使用计数排序，在大范围、低熵键结构化输入上使用基数排序，在通用排序上使用快速排序。

**Result:** 在合成数据集和真实数据集上的实验结果表明，所提出的解决方案在执行时间、灵活性和效率方面显著优于传统的静态排序算法。

**Conclusion:** 所提出的自适应混合排序框架提供了一个可扩展、高性能且适用于大数据分析、边缘计算和硬件受限系统等广泛数据处理操作的解决方案。

> **ai_Abstract:** 本文提出了一种自适应混合排序范式，旨在解决传统排序算法在不同数据分布下性能不一的问题。该范式通过特征提取模块（计算数据量、值范围、熵）和决策引擎（结合有限状态机和XGBoost分类器），实时监测输入数据模式，并动态选择最适合的排序算法（计数排序、基数排序或快速排序）。实验结果表明，该方法在执行时间、灵活性和效率上显著优于传统静态排序算法，为大数据分析、边缘计算等领域提供了可扩展、高性能的解决方案。

> **摘要翻译:** 排序是计算机科学中一项基本操作，直接影响大规模数据系统、实时系统和嵌入式计算的性能。然而，没有一种排序算法能在所有数据分布下都达到最优。本文提出了一种新的自适应混合排序范式，该范式通过实时监测输入数据模式，自动选择最有效的排序算法，包括计数排序、基数排序或快速排序。该架构首先通过一个特征提取模块计算数据量、值范围和熵等重要参数。这些参数被发送到一个决策引擎，该引擎结合有限状态机和XGBoost分类器，以智能有效地选择最优排序策略。它在小键范围上实现计数排序，在大范围、低熵键结构化输入上实现基数排序，并在通用排序上实现快速排序。在合成数据集和真实数据集上的实验结果证实，所提出的解决方案在执行时间、灵活性和效率方面显著优于传统的静态排序算法。所提出的框架是可扩展、高性能的，并适用于广泛的数据处理操作，如大数据分析、边缘计算和具有硬件限制的系统。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [35] [Review of Three Variants of the k-d Tree](https://arxiv.org/abs/2506.20687)
> *k-d树三种变体的综述*

*Russell A. Brown* | **Category: cs.DS**

**Keywords:** k-d树, 数据分区, 计算复杂度, 树变体, 双线程执行

**Comment:** 29 pages, 11 figures, one listing, one table

> **TL;DR:** 本文综述并对比了k-d树的三种变体，重点关注其分区技术对构建复杂度的影响，并提出了一种双线程执行方案。

**AI_Comments:** 本文解决了k-d树构建中的一个核心挑战，即在不使用传统重平衡技术的情况下实现平衡。通过回顾和比较不同的分区方法，并提出新颖的双线程执行方案，该研究为优化k-d树的性能和构建效率提供了见解。对分区技术的关注对于k-d树的实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** k-d树的重平衡技术不适用，导致构建平衡k-d树需要通过中位数查找和数据分区实现，而这些技术显著影响构建的计算复杂度。

**Method:** 本文描述并对比了三种k-d树变体，这些变体在数据分区技术上有所不同，并比较了它们的性能。此外，还针对其中一种变体提出了双线程执行方案并进行了分析。

**Result:** 本文描述并对比了三种k-d树变体，并比较了它们的性能。同时，针对其中一种变体提出了双线程执行方案并进行了分析。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文综述了k-d树的三种变体，着重分析了它们不同的数据分区技术如何影响构建时的计算复杂度。文章指出，传统的重平衡方法不适用于k-d树，因此构建平衡树依赖于中位数查找。论文对比了这些变体的性能，并为其中一种引入了双线程执行方案。

> **摘要翻译:** k-d树的原始描述认识到，重新平衡技术，例如用于构建AVL树或红黑树的技术，不适用于k-d树。因此，为了构建一个平衡的k-d树，有必要在每次递归细分数据集时找到该数据集的中位数。用于查找中位数以及围绕该中位数划分数据集的排序或选择技术，强烈影响构建k-d树的计算复杂度。本文描述并对比了k-d树的三种变体，它们在用于划分数据集的技术上有所不同，并比较了这些变体的性能。此外，还针对其中一种变体提出了双线程执行方案并进行了分析。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [59] [A Framework for Building Data Structures from Communication Protocols](https://arxiv.org/abs/2506.20761)
> *一种从通信协议构建数据结构的框架*

*Alexandr Andoni, Shunhua Jiang, Omri Weinstein* | **Category: cs.DS**

**Keywords:** 数据结构, 通信协议, 模式匹配, 部分匹配, 集合不交性

**Comment:** 53 pages, STOC 2025

> **TL;DR:** 本文提出了一种通用框架，通过通信模型设计高效的高维模式匹配数据结构，并将其应用于部分匹配问题，显著提升了查询时间。

**AI_Comments:** 本文的创新之处在于将数据结构设计问题与通信复杂度理论相结合，提供了一个通用的、基于理论基础的框架。通过将问题归约为UAM通信复杂度，并开发了针对特定通信问题的改进协议，作者们成功地在部分匹配等高维模式匹配问题上取得了突破性的性能提升。这种方法论上的创新，即利用通信模型的洞察力来构建数据结构，为该领域开辟了新的研究方向。其重要性在于，它不仅提供了更高效的算法，还加深了我们对数据结构与信息论之间关系的理解。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过通信模型为高维模式匹配问题设计高效的数据结构，特别是针对现有线性空间数据结构在部分匹配问题上的查询时间限制（例如，Cole, Gottlieb 和 Lewenstein (STOC'04) 的查询时间为 $2^w = n^c$，仅在 $c<1$ 时非平凡）。

**Method:** 该框架将数据结构问题归结为乘积分布下函数 $f(x,y)$ 的无歧义阿瑟-梅林（UAM）通信复杂度。具体地，研究人员开发了一种针对乘积分布下 Set-Disjointness 的单边 $\epsilon$ 误差通信协议，其复杂度为 $\tilde{\Theta}(\sqrt{d\log(1/\epsilon)})$，并在此基础上证明了乘积分布下 $w$-稀疏 Set-Disjointness 的无歧义 AM 通信复杂度为 $\tilde{O}(\sqrt{w \log(1/\epsilon)})$，与环境维度 $d$ 无关。

**Result:** 将该框架应用于部分匹配问题，当数据库包含 $n$ 个 $d$ 维点且查询中 $\star$ 的数量至多为 $w = c\log n$ 时，该框架生成的数据结构查询时间为 $n^{1-1/(c \log^2 c)}$，空间接近线性，显著优于先前最快的线性空间数据结构（Cole, Gottlieb 和 Lewenstein, STOC'04）的查询时间 $t \approx 2^w = n^c$。此外，开发了一种改进的 Set-Disjointness 通信协议。

**Conclusion:** 本文提出的框架为从通信协议构建数据结构提供了一种通用方法，特别是在高维模式匹配问题上显示出其强大能力，通过利用数据依赖的数据结构并将其简化为乘积分布下更易处理的情况，取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一个通用框架，通过将数据结构问题归结为通信复杂度，来构建高维模式匹配的高效数据结构。该框架成功应用于部分匹配问题，在查询时间上显著超越了现有最佳线性空间方法，实现了 $n^{1-1/(c \log^2 c)}$ 的查询时间。其核心在于开发了一种新的、改进的乘积分布下 Set-Disjointness 通信协议，并证明了其无歧义 AM 通信复杂度与维度无关，这对于实际应用至关重要。该工作突出了数据依赖数据结构在处理复杂问题时的强大能力。

> **摘要翻译:** 我们提出了一个通用框架，用于通过通信模型设计高效的高维模式匹配问题数据结构（存在？$i\in[n], f(x_i,y)=1$），其中 $f(x,y)$ 允许亚线性通信协议，且误差呈指数级小。具体而言，我们将数据结构问题归结为乘积分布下 $f(x,y)$ 的无歧义阿瑟-梅林（UAM）通信复杂度。我们将我们的框架应用于部分匹配问题（又称带通配符匹配），其底层通信问题是稀疏集合不交性。当数据库包含 $n$ 个 $d$ 维点，且查询中 $\star$ 的数量最多为 $w = c\log n \;(\ll d)$ 时，已知最快的线性空间数据结构（Cole, Gottlieb 和 Lewenstein, STOC'04）的查询时间 $t \approx 2^w = n^c$，仅当 $c<1$ 时才非平凡。相比之下，我们的框架生成的数据结构查询时间为 $n^{1-1/(c \log^2 c)}$，空间接近线性。为了实现这一点，我们开发了一种在乘积分布下具有 $\tilde{\Theta}(\sqrt{d\log(1/\epsilon)})$ 复杂度的单边 $\epsilon$ 误差通信协议，改进了 Babai, Frankl 和 Simon (FOCS'86) 的经典结果。在此协议的基础上，我们表明在乘积分布下，具有 $\epsilon$ 误差的 $w$-稀疏集合不交性的无歧义 AM 通信复杂度为 $\tilde{O}(\sqrt{w \log(1/\epsilon)})$，与环境维度 $d$ 无关，这对部分匹配结果至关重要。我们的框架进一步阐明了数据依赖数据结构的力量，这对于简化到（更容易的）乘积分布情况至关重要。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [82] [Practical and Accurate Local Edge Differentially Private Graph Algorithms](https://arxiv.org/abs/2506.20828)
> *实用且准确的局部边缘差分隐私图算法*

*Pranay Mundra, Charalampos Papamanthou, Julian Shun, Quanquan C. Liu* | **Category: cs.DS, cs.CR, cs.DB**

**Keywords:** 局部差分隐私, 图算法, k-核分解, 三角形计数, 隐私保护

**Comment:** To appear in VLDB 2025

> **TL;DR:** 本论文提出了新的局部差分隐私(LDP)算法，用于k-核分解和三角形计数，通过利用图的退化度和最大度来显著提高准确性，并在分布式模拟中首次进行了评估。

**AI_Comments:** 本文的创新点在于其将图的退化度和最大度等输入依赖私有属性引入LDP算法设计，从而显著收紧了误差界限，并首次在分布式模拟中验证了LDP图算法的实用性。这对于在敏感数据上进行大规模图分析具有重要意义，克服了现有LDP方法在准确性和可扩展性方面的局限。

<details>
  <summary>Details</summary>

**Motivation:** 大规模网络数据分析中存在敏感数据隐私泄露的担忧，需要一种在个体层面保障隐私的机制，即局部差分隐私（LDP），以应对现有中心化模型对可信第三方的假设。

**Method:** 本文提出了两种新的LDP算法，分别用于k-核分解和三角形计数。这些算法利用图的输入依赖私有属性，特别是退化度和最大度，以提高理论效用。与现有方法不同，其误差界限由最大度而非总边数决定。对于三角形计数，算法通过私有出度定向、改进的随机响应技术和新颖的分析，实现了基于图退化度的误差界限。此外，本研究首次在分布式模拟中评估了局部DP算法。

**Result:** 实验结果显示显著的准确性提升：k-核分解算法的误差在精确值的三倍以内，远优于基线方法的131倍误差。三角形计数算法将乘法近似误差降低了多达六个数量级，同时保持了有竞争力的运行时间。

**Conclusion:** 本文提出了实用且准确的局部差分隐私图算法，用于k-核分解和三角形计数，通过引入新的理论方法和在分布式环境中的首次评估，显著提高了准确性并解决了现有LDP图算法的局限性。

> **ai_Abstract:** 本论文针对大规模网络数据分析中的隐私问题，提出了两种实用且准确的局部差分隐私（LDP）图算法，分别用于k-核分解和三角形计数。通过利用图的退化度和最大度等输入依赖私有属性，新算法的误差界限由最大度而非总边数决定，从而显著提高了理论效用。在三角形计数方面，算法通过私有出度定向和改进的随机响应技术，实现了基于图退化度的更强保证。此外，本文首次在分布式模拟中评估了LDP算法。实验结果表明，与现有基线相比，k-核分解的误差大幅降低，三角形计数算法的近似误差减少了多达六个数量级，同时保持了高效的运行时间。

> **摘要翻译:** 大规模网络在不同领域的兴起，使得复杂的图分析变得必要，这往往涉及敏感数据并引发隐私担忧。本文使用局部差分隐私（LDP）来解决这些挑战，LDP在个体层面强制执行隐私，不信任任何第三方实体，这与假设存在可信策展者的中心化模型不同。我们引入了用于两种基本图统计量的新型LDP算法：k-核分解和三角形计数。我们的方法利用输入依赖的私有图属性，特别是图的退化度和最大度，以提高理论效用。与现有方法不同，我们的误差界限由最大度而非总边数决定，从而产生了显著更紧密的保证。对于三角形计数，我们改进了Imola、Murakami和Chaudhury~\[IMC21locally, IMC21communication\]的工作，他们的误差界限以边数表示。相反，我们的算法通过利用私有出度定向（Eden等人~\[ELRS23\]随机响应技术的改进变体）和新颖的分析，实现了基于图退化度的界限，从而获得了比现有工作更强的保证。除了理论收益，我们是第一个在分布式模拟中评估局部DP算法的研究，而以往的工作仅在单个处理器上进行测试。在真实世界图上的实验显示出显著的准确性提升：我们的k-核分解误差在精确值的3倍以内，远优于Dhulipala等人~\[DLRSSY22\]基线中131倍的误差。我们的三角形计数算法将乘法近似误差减少了多达六个数量级，同时保持了有竞争力的运行时间。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [105] [Almost Tight Additive Guarantees for \boldmath $k$-Edge-Connectivity](https://arxiv.org/abs/2506.20906)
> *关于$k$-边连通性的几乎紧致加性保证*

*Nikhil Kumar, Chaitanya Swamy* | **Category: cs.DS, F.2.2; G.2**

**Keywords:** k-边连通性, 生成子图, 近似算法, LP松弛, 度数受限问题

**Comment:** 

> **TL;DR:** 该论文为$k$-边连通生成子图 (kECSS) 问题提出了几乎最优的算法，改进了现有结果的解质量和简洁性，并扩展到$k$-边连通生成多图 (kECSM) 和度数受限版本。

**AI_Comments:** 该论文通过为已知的APX-hard问题提供几乎最优的加性保证，做出了重要贡献。在解质量和算法简洁性方面对现有工作的改进值得关注。扩展到多图和度数受限版本，特别是后者首次实现了加性违反的结果，突出了其技术的通用性和影响力。使用LP松弛作为基准是标准做法，并证明了其界限相对于理论最优的强度。

<details>
  <summary>Details</summary>

**Motivation:** 该论文研究了$k$-边连通生成子图 (kECSS) 问题，该问题是APX-hard的。其动机是为该问题及相关变体寻找更好的近似解，并旨在改进现有工作。

**Method:** 论文提出了一种多项式时间算法。其技术还扩展到kECSS和kECSM的度数受限版本。这些算法实现了边连通性和度数限制的加性保证。

**Result:** 对于kECSS中的偶数$k$，计算出成本至多为$LP^*$的$(k-2)$-边连通子图；对于奇数$k$，获得成本至多为$LP^*$的$(k-3)$-边连通子图。对于kECSS的替代保证，获得成本至多为$1.5\cdot LP^*$的$(k-1)$-边连通子图；对于单位边成本，成本保证提高到$(1+\frac{4}{3k})\cdot LP^*$。对于kECSM，偶数$k$获得$(1+2/k)$-近似算法，奇数$k$获得$(1+3/k)$-近似算法。对于度数受限版本，获得了与原始问题相同的成本和连通性保证，但在度数限制方面有大约2的加性违反。

**Conclusion:** 由于kECSS是APX-hard的，因此该结果几乎是最优的。它们在解决方案质量和算法及其分析的简单性方面显著改进了Hershkowitz等人的近期工作。对于度数受限的{kECSS,kECSM}问题，这些是首次获得解成本至多为最优值且连通性约束有加性常数违反的结果。

> **ai_Abstract:** 该论文解决了APX-hard的$k$-边连通生成子图 (kECSS) 问题，提供了多项式时间算法，实现了几乎紧致的加性保证。对于偶数$k$，它找到了一个$(k-2)$-边连通子图；对于奇数$k$，找到了一个$(k-3)$-边连通子图，两者成本均达到最优LP松弛值。它还提供了一个$(k-1)$-边连通子图，成本至多为$1.5\cdot LP^*$（或对于单位成本为$(1+4/(3k))\cdot LP^*$）。这些方法扩展到$k$-边连通生成多图 (kECSM) 问题，产生了改进的近似比率，并扩展到度数受限版本，对度数约束有加性违反。这些结果在解质量和算法简洁性方面显著提升了现有技术水平。

> **摘要翻译:** 我们考虑$k$-边连通生成子图 (kECSS) 问题，其中给定一个具有非负边成本的无向图$G = (V, E)$，我们寻求一个最小成本的$k$-边连通子图$H$。对于偶数$k$，我们提出了一个多项式时间算法，该算法计算一个$(k-2)$-边连通子图，其成本至多为kECSS的自然LP-松弛的最优值$LP^*$；对于奇数$k$，我们获得一个$(k-3)$-边连通子图，其成本至多为$LP^*$。由于kECSS对于所有$k\geq 2$都是APX-hard的，我们的结果几乎是最优的。它们还在解决方案质量以及算法及其分析的简单性方面显著改进了Hershkowitz等人最近的工作。我们的技术还提供了一个替代保证，即我们获得一个$(k-1)$-边连通子图，其成本至多为$1.5\cdot LP^*$；对于单位边成本，成本保证提高到$(1+\frac{4}{3k})\cdot LP^*$，这改进了单位边成本的最新近似算法，但边连通性损失了一个单位。我们的kECSS结果也为$k$-边连通生成多图 (kECSM) 问题带来了结果，其中可以选择边的多个副本：对于偶数$k$，我们获得一个$(1+2/k)$-近似算法；对于奇数$k$，我们获得一个$(1+3/k)$-近似算法。我们的技术扩展到kECSS和kECSM的度数受限版本，其中我们还对节点施加度数下限和上限。对于这些度数受限版本，我们获得了相同的成本和连通性保证，但在度数限制方面有（大约）2的加性违反。这些是度数受限{kECSS,kECSM}问题的首次结果，其解决方案成本至多为最优值，并且连通性约束被一个加性常数违反。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [126] [Courcelle's Theorem for Lipschitz Continuity](https://arxiv.org/abs/2506.21118)
> *Lipschitz连续性的Courcelle定理*

*Tatsuya Gima, Soh Kumabe, Yuichi Yoshida* | **Category: cs.DS**

**Keywords:** Lipschitz连续性, Courcelle定理, 元定理, 树宽有界图, 近似算法

**Comment:** ESA 2025, 27 pages

> **TL;DR:** 提出了第一个针对Lipschitz连续算法的元定理，为有界树宽图上的MSO_2约束问题提供了近似算法，并构建了Baker分解的Lipschitz连续版本。

**AI_Comments:** 这项工作的重要性在于首次提出了Lipschitz连续算法的元定理，极大地提升了该领域算法设计的通用性。它将经典的Courcelle定理思想推广到稳定性分析，为在特定图结构（如树宽有界图）上设计鲁棒性好的近似算法提供了通用框架，对可重复科学和可靠决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有Lipschitz连续算法是针对特定问题的，需要为每个问题单独设计，缺乏通用性。

**Method:** 提出了Lipschitz连续算法领域的第一个算法元定理，可以看作是Courcelle定理的Lipschitz连续模拟。该方法用于解决有界树宽图上受MSO_2逻辑约束的顶点集问题，以及有界团宽图上受MSO_1约束的问题。

**Result:** 对于有界树宽图，对于任意ε>0，存在一个具有多对数Lipschitz常数的(1±ε)-近似算法，该算法在近似性和/或Lipschitz连续性方面优于大多数现有算法。此外，对于有界团宽图上受MSO_1约束的问题，也提供了类似的结果。另外，利用该元定理作为子程序，构建了Baker分解的Lipschitz连续版本。

**Conclusion:** 该研究通过引入一个通用的算法元定理，显著推进了Lipschitz连续算法领域的发展，解决了现有算法特异性的问题，并为特定图类上的优化问题提供了高性能的稳定算法。

> **ai_Abstract:** 本文提出了Lipschitz连续算法领域的首个算法元定理，作为Courcelle定理的Lipschitz连续性类比。该元定理解决了现有Lipschitz连续算法特异性的问题，为有界树宽图上受MSO_2逻辑约束的顶点集优化问题提供了具有多对数Lipschitz常数的(1±ε)-近似算法，并在近似性和稳定性方面超越了现有方法。研究还为有界团宽图上受MSO_1约束的问题提供了类似结果，并利用该元定理构建了Baker分解的Lipschitz连续版本。

> **摘要翻译:** Kumabe和Yoshida（FOCS'23）引入的算法的Lipschitz连续性，衡量了算法对小输入扰动的稳定性。具有小Lipschitz连续性的算法是理想的，因为它们能确保可靠的决策和可重复的科学研究。一些研究已经为各种组合优化问题提出了Lipschitz连续算法，但这些算法是针对特定问题的，需要为每个问题单独设计。为了解决这个问题，我们提供了Lipschitz连续算法领域的第一个算法元定理。我们的结果可以看作是Courcelle定理的Lipschitz连续模拟，它为有界树宽图上的问题提供了Lipschitz连续算法。具体来说，我们考虑了在图中找到一个顶点集，该顶点集在满足单子二阶逻辑（MSO_2）表达的约束下，使总权重最大化或最小化的问题。我们表明，对于任意$\varepsilon>0$，对于有界树宽图上的该问题，存在一个具有多对数Lipschitz常数的$(1\pm \varepsilon)$-近似算法。在这些图上，我们的结果在近似性和/或Lipschitz连续性方面优于大多数现有Lipschitz连续算法。此外，我们还为有界团宽图上受MSO_1约束的问题提供了类似的结果。另外，我们利用我们的元定理作为子程序，构建了Baker分解的Lipschitz连续版本。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [144] [On Minimizing Wiggle in Stacked Area Charts](https://arxiv.org/abs/2506.21175)
> *最小化堆叠面积图中的“摆动”*

*Alexander Dobler, Martin Nöllenburg* | **Category: cs.DS**

**Keywords:** 堆叠面积图, 摆动最小化, NP-难, 混合整数线性规划, 计算复杂性

**Comment:** 19 pages, 3 figures

> **TL;DR:** 本文正式分析了堆叠面积图中最小化“摆动”的计算复杂性，证明其是NP-难甚至难以近似的，并提出了一个精确的混合整数线性规划公式。

**AI_Comments:** 本文的创新之处在于首次从理论计算复杂性角度深入分析了堆叠面积图“摆动”最小化问题，填补了现有研究主要集中于启发式算法的空白。证明NP-难性对于理解问题本质和指导未来算法设计具有重要意义。提出的混合整数线性规划公式为寻找精确解提供了一条途径，尽管计算成本可能较高。对特殊情况的分析进一步增强了结论的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 堆叠面积图中的“摆动”（时间序列边界的垂直变化量）是影响可读性的主要美学标准。尽管已有许多启发式算法来最小化“摆动”，但其计算复杂性尚未得到正式分析。

**Method:** 本文证明了“摆动”最小化的不同变体是NP-难的，甚至难以近似。同时，提出了一个精确的混合整数线性规划（MILP）公式，并将其性能与最先进的启发式算法进行了实验比较。此外，还考虑了“摆动”最小化的一种特殊情况，即排序一组数字以最小化其绝对前缀和之和，并给出了该问题的复杂性结果。

**Result:** 研究表明，“摆动”最小化的不同变体是NP-难的，并且难以近似。论文提出了一个精确的混合整数线性规划公式，并在实验评估中与现有启发式算法进行了性能比较。对于最小化绝对前缀和之和的特殊情况，也得出了多个复杂性结果，这些结果也支持了“摆动”最小化的某些难度结论。

**Conclusion:** 本文首次对堆叠面积图中最小化“摆动”的计算复杂性进行了正式分析，揭示了其NP-难甚至难以近似的特性，并提供了一个精确的混合整数线性规划解决方案，同时通过分析一个相关的特殊问题进一步证实了其计算难度。

> **ai_Abstract:** 本文首次对堆叠面积图中最小化“摆动”的计算复杂性进行了正式分析。研究发现，最小化“摆动”的各种变体是NP-难的，甚至难以近似。为了解决这一问题，论文提出了一个精确的混合整数线性规划公式，并与现有启发式算法进行了性能对比。此外，通过分析一个特殊的数学排序问题（最小化绝对前缀和之和），进一步揭示了“摆动”最小化的内在计算难度。

> **摘要翻译:** 堆叠面积图是一种广泛用于数值时间序列的可视化技术。x轴代表时间，时间序列显示为水平、可变高度的层，彼此堆叠。每层的高度对应于每个时间点的时间序列值。优化堆叠面积图可读性的主要美学标准是可视化中时间序列之间边界的垂直变化量，称为“摆动”。尽管已经开发了许多启发式算法来最小化“摆动”，但最小化“摆动”的计算复杂性尚未得到正式分析。在本文中，我们证明了“摆动”最小化的不同变体是NP-难的，甚至难以近似。我们还提出了一个精确的混合整数线性规划公式，并在实验评估中将其性能与最先进的启发式算法进行了比较。最后，我们考虑了“摆动”最小化的一种特殊情况，它对应于对一组数字进行排序以最小化其绝对前缀和之和这一根本上有趣且自然的问题。我们展示了该问题的几个复杂性结果，这些结果也暗示了“摆动”最小化的某些难度结果。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [163] [Edge Clique Partition and Cover Beyond Independence](https://arxiv.org/abs/2506.21216)
> *边团划分与覆盖超越独立集*

*Fedor V. Fomin, Petr A. Golovach, Danil Sagunov, Kirill Simonov* | **Category: cs.DS, cs.DM**

**Keywords:** 边团划分, 边团覆盖, 参数化复杂性, 最大独立集, 稀疏图

**Comment:** An extended abstract of this paper appears in the proceedings of ESA
  2025

> **TL;DR:** 本文研究了边团覆盖和划分问题在“超独立集大小”参数化下的计算复杂性，发现边团划分问题是FPT，而边团覆盖问题大部分情况是NP完全，但在结合最大团大小作为参数时变为FPT。

**AI_Comments:** 本文创新性地提出了将问题参数化为“超越最大独立集大小”这一新颖视角，有效解决了传统参数化在稀疏图上的局限性。通过对比分析两种变体（覆盖与划分）在不同参数化下的复杂性，揭示了它们之间深刻的计算差异。特别是在考虑稀疏图特性时，引入最大团大小作为参数的FPT结果具有重要的理论和实际价值。该研究为图论中的边覆盖和划分问题提供了新的理解和解决思路。

<details>
  <summary>Details</summary>

**Motivation:** 经典图论问题中，边团覆盖和划分的参数化通常以总团数作为参数，但这对于稀疏图意义不大。然而，在许多实际场景中，所需团数接近最大独立集的大小。受此观察启发，作者研究了超越最大独立集大小的参数化。

**Method:** 引入并研究了两种新的参数化问题：超独立集边团覆盖（ECC/\alpha）和超独立集边团划分（ECP/\alpha），其目标是使用最多 \alpha(G) + k 个团来覆盖或划分图的所有边，其中 k 是参数。

**Result:** 研究结果揭示了两种变体截然不同的复杂性：ECP/\alpha 是固定参数可解（FPT）的；ECC/\alpha 对于所有 k \geq 2 都是 NP 完全的，但对于 k \in {0,1} 可以在多项式时间内求解。此外，当参数化为 k + \omega(G)（其中 \omega(G) 是最大团的大小）时，ECC/\alpha 变为 FPT，这对于稀疏图尤为重要。对于 H-minor-free 图，设计了一个次指数算法，运行时间为 f(H)^{\sqrt{k}}n^{O(1)}。

**Conclusion:** 这些发现突出了边团覆盖和边团划分这两个问题在超越自然下界参数化视角下的显著差异。ECC/\alpha 在特定参数化下对稀疏图具有可解性。

> **ai_Abstract:** 本文探讨了经典图论问题——边团覆盖和边团划分——在新的参数化视角下的计算复杂性。鉴于传统参数化（总团数）对稀疏图的局限性，作者提出并研究了“超越最大独立集大小”（\alpha(G) + k）的参数化。研究发现，边团划分问题（ECP/\alpha）是固定参数可解的，而边团覆盖问题（ECC/\alpha）在 k \geq 2 时是 NP 完全的，但在 k \in {0,1} 时可多项式时间求解。此外，当结合最大团大小（k + \omega(G)）作为参数时，ECC/\alpha 变为固定参数可解，这对于稀疏图具有重要意义。文章还为 H-minor-free 图设计了次指数算法。

> **摘要翻译:** 将图的边覆盖和划分为团是组合优化和图论交叉领域的经典问题，已通过一系列算法和复杂性理论视角进行研究。尽管这些问题在以总团数作为参数时具有众所周知的固定参数可解性，但这种参数化对于稀疏图通常意义不大。另一方面，在许多实际实例中，边覆盖或划分中的最小团数可以非常接近最大独立集 \alpha(G) 的大小。受此观察启发，我们研究了边团覆盖和划分问题在“超 \alpha”参数化下的情况。具体来说，我们引入并研究了超独立集边团覆盖（ECC/\alpha）和超独立集边团划分（ECP/\alpha），其目标是使用最多 \alpha(G) + k 个团来覆盖或划分图的所有边，其中 k 是参数。我们的主要结果揭示了这两种变体截然不同的复杂性图景。我们证明 ECP/\alpha 是固定参数可解的，而 ECC/\alpha 对于所有 k \geq 2 都是 NP 完全的，但对于 k \in {0,1} 可以在多项式时间内求解。这些发现突出了这两个问题在超越自然下界参数化视角下的有趣差异。
最后，我们证明当以 k + \omega(G) 作为参数时，ECC/\alpha 变为固定参数可解的，其中 \omega(G) 是图 G 的最大团的大小。这个结果对于稀疏图尤其相关，因为在稀疏图中 \omega 通常很小。对于不含 H-次图的图，我们设计了一个运行时间为 f(H)^{\sqrt{k}}n^{O(1)} 的次指数算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [181] [Vantage Point Selection Algorithms for Bottleneck Capacity Estimation](https://arxiv.org/abs/2506.21418)
> *瓶颈容量估计的视点选择算法*

*Vikrant Ashvinkumar, Rezaul Chowdhury, Jie Gao, Mayank Goswami, Joseph S. B. Mitchell, Valentin Polishchuk* | **Category: cs.DS**

**Keywords:** 瓶颈容量估计, 视点选择, 非自适应算法, 自适应算法, 近似算法

**Comment:** 

> **TL;DR:** 本文研究了在互联网上估计瓶颈容量的视点选择问题，旨在从图中选择K个视点以揭示最大数量的瓶颈边容量，并提出了非自适应和自适应设置下的近似算法和界限。

**AI_Comments:** 本文创新性地将瓶颈容量估计问题转化为图论中的视点选择问题，并针对非自适应和自适应两种不同信息获取模式进行了深入研究。其提出的近似算法和理论界限，尤其是对NP-难问题的近似解，具有重要的理论和实践意义。对特定图结构（树和平面图）的分析也增强了结果的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决互联网上瓶颈容量估计的问题。

**Method:** 本文将问题建模为在给定图G=(V, E)中选择k个视点，以揭示沿最短路径的最大数量的瓶颈边容量。研究了两种设置：非自适应设置（所有k个视点在容量揭示前选择）和自适应设置（每个视点选择后即时揭示容量）。在非自适应设置中，考虑了一个边容量从随机排列中抽取的宽松模型，并提出了一个1-1/e近似算法。在自适应设置中，采用边容量任意固定但未知的模型，并与特定输入实例的最佳解进行比较，为实例最优近似算法提供了下界，并为树和平面图提供了上界。

**Result:** 在非自适应设置中，对于边容量从随机排列中抽取的宽松模型，提出了一个1-1/e近似算法。在自适应设置中，为实例最优近似算法提供了下界，并为树和平面图提供了上界。

**Conclusion:** 本文通过对视点选择问题的形式化研究，在非自适应和自适应设置下分别提出了近似算法和理论界限，为互联网瓶颈容量估计提供了理论支持和算法基础。

> **ai_Abstract:** 本文研究了为互联网瓶颈容量估计而进行的视点选择问题。作者将问题建模为在图中选择K个视点以最大化揭示的瓶颈边容量。研究分为非自适应和自适应两种设置：非自适应设置下，提出了一个1-1/e近似算法；自适应设置下，为实例最优近似算法提供了下界，并为特定图类型（树和平面图）提供了上界。

> **摘要翻译:** 本文的动机是解决互联网上瓶颈容量估计的问题，我们因此提出并研究了视点选择问题。我们给定一个图$G=(V, E)$，其边的容量值未知，需要被发现。从一个视点，即顶点$v 
otin V$沿着从$v$到所有其他顶点的最短路径进行探测，可以揭示每条路径上的瓶颈边容量。我们的目标是从$V$中选择$k$个视点，以揭示最大数量的瓶颈边容量。
我们考虑了两种设置：非自适应设置，其中所有$k$个视点在任何瓶颈容量被揭示之前被选择；以及自适应设置，其中每个视点选择会立即揭示从该点开始的所有最短路径上的瓶颈容量。在非自适应设置中，通过考虑一个宽松模型，其中边容量从随机排列中抽取（这仍然使得最大化预期揭示边数的问题是NP-难的），我们能够给出一个1-1/e的近似算法。在自适应设置中，我们采用最不宽松的模型，其中边容量是任意固定但未知的。我们与特定输入实例的最佳解决方案（即通过枚举所有$k$元组的选择）进行比较，并为实例最优近似算法提供了下界，同时为树和平面图提供了上界。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [196] [Succinct Preferential Attachment Graphs](https://arxiv.org/abs/2506.21436)
> *简洁的优先连接图*

*Ziad Ismaili Alaoui, Namrata, Sebastian Wild* | **Category: cs.DS, cs.IT, math.IT, math.PR**

**Keywords:** 简洁数据结构, 优先连接图, 图压缩, 空间效率, Barabási-Albert模型

**Comment:** WG 2025

> **TL;DR:** 该研究设计了一种新的数据结构，用于压缩图数据，使其空间使用量随图的可压缩性自动优化，并支持高效导航，尤其适用于优先连接图模型。

**AI_Comments:** 这项工作在图数据结构领域具有重要意义，它通过引入空间自适应性，解决了传统简洁数据结构在图压缩方面存在的局限性，即对特定图类和最坏情况空间使用的依赖。特别地，它将压缩计算的优势扩展到更广泛的图类型，并通过实例最优空间分析展现了其理论上的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有图的压缩数据结构支持不完善，通常限制于特定图类且空间使用量为最坏情况，无法根据图的可压缩性自动优化空间效率。

**Method:** 设计了一种新的数据结构，其空间使用量能随图的可压缩性自动改进，并能高效支持导航操作。通过分析Barabási-Albert优先连接图模型，证明其空间使用量接近实例最优。该技术也适用于任意图，并保证渐近地不大于熵压缩边列表的大小。

**Result:** 所设计的数据结构的空间使用量随图的可压缩性自动优化，对于Barabási-Albert优先连接图模型，空间使用量接近实例最优。该数据结构技术也适用于任意图，并能保证其大小渐近地不大于熵压缩边列表。

**Conclusion:** 该研究成功设计了一种空间自适应的图数据结构，解决了现有图压缩数据结构在空间效率和通用性方面的局限性，为高效处理压缩图数据提供了新方法。

> **ai_Abstract:** 本文提出了一种新的图数据结构，旨在解决现有图压缩数据结构在空间效率和通用性方面的局限性。该结构能够根据图的可压缩性自动优化空间使用，同时高效支持导航操作。研究表明，在经典的Barabási-Albert优先连接图模型下，其空间使用量接近实例最优。此外，该技术也适用于任意图，并能保证空间复杂度渐近地不大于熵压缩边列表。一个关键贡献是对实例最优空间使用量的深入分析。

> **摘要翻译:** 对压缩数据进行计算将数据压缩的空间节省与直接在压缩表示上高效支持查询结合起来。此类数据结构广泛应用于文本索引，并已成功推广到树。对于图，对压缩数据进行计算的支持仍然零散；简洁数据结构领域的典型结果仅限于特定类别的图，并且对于此类中的任何图都使用相同的最坏情况空间量。
在这项工作中，我们设计了一种数据结构，其空间使用量随手头图的可压缩性自动改进，同时高效支持导航操作（模拟邻接列表访问）。具体来说，我们展示了当图根据经典的Barabási-Albert优先连接图模型绘制时，其空间使用量接近实例最优空间。我们的数据结构技术也适用于任意图，保证其大小渐近地不大于熵压缩边列表。一个关键的技术贡献是对实例最优空间使用量的仔细分析。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [40] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
> *生成式积木世界：在图像中移动物体*

*Vaibhav Vavilala, Seemandhar Jain, Rahul Vasanth, D. A. Forsyth, Anand Bhattad* | **Category: cs.GR, cs.CV**

**Keywords:** 生成式模型, 场景编辑, 3D图元, 纹理一致性, 图像生成

**Comment:** 23 pages, 16 figures, 2 tables

> **TL;DR:** 本文提出了一种名为“生成式积木世界”的方法，通过操作简单的几何抽象体来编辑生成图像中的场景。该方法将场景表示为凸3D图元组合，并利用基于深度和纹理提示的流式方法生成图像，显著提升了视觉保真度、可编辑性和组合泛化能力。

**AI_Comments:** 这篇论文的创新点在于其将场景分解为可编辑的3D图元，并结合了考虑3D修改的纹理提示，从而在图像编辑中实现了高水平的纹理一致性和对象身份保留。这种方法对于需要精细控制生成图像内容的应用程序具有重要意义，尤其是在虚拟现实、游戏开发和创意设计领域。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过操纵简单的几何抽象体来与生成图像的场景进行交互和编辑。

**Method:** 该方法将场景表示为凸3D图元的组合，同一个场景可以用不同数量的图元表示，允许编辑者移动整体结构或小细节。一旦场景几何体被编辑，图像将通过一种基于深度和纹理提示的流式方法生成。纹理提示考虑了修改后的3D图元，超越了现有键值缓存技术提供的纹理一致性。

**Result:** 纹理提示能够实现准确的物体和相机移动，并基本保留了所描绘物体的身份。定量和定性实验表明，该方法在视觉保真度、可编辑性和组合泛化方面优于现有工作。

**Conclusion:** 该方法通过创新的场景表示和图像生成机制，显著提升了生成图像的编辑能力和视觉质量，超越了现有技术。

> **ai_Abstract:** 本文提出了一种名为“生成式积木世界”的新方法，用于编辑生成图像中的场景。该方法通过将场景建模为可操作的凸3D图元集合，实现了对场景细节或整体结构的灵活编辑。图像生成采用了一种流式方法，结合了深度信息和创新的纹理提示，该纹理提示能有效处理修改后的3D图元，显著提升了纹理一致性。实验证明，该方法在视觉质量、编辑灵活性和泛化能力上均超越了现有技术。

> **摘要翻译:** 我们描述了“生成式积木世界”，通过操纵简单的几何抽象体来与生成图像的场景进行交互。我们的方法将场景表示为凸3D图元的组合，同一个场景可以用不同数量的图元表示，允许编辑者移动整个结构或小细节。一旦场景几何体被编辑，图像将通过一种基于深度和纹理提示的流式方法生成。我们的纹理提示考虑了修改后的3D图元，超越了现有键值缓存技术提供的纹理一致性。这些纹理提示（a）允许准确的物体和相机移动，并且（b）在很大程度上保留了所描绘物体的身份。定量和定性实验表明，我们的方法在视觉保真度、可编辑性和组合泛化方面优于现有工作。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [64] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
> *3DGH：可组合头发和面部的3D头部生成*

*Chengan He, Junxuan Li, Tobias Kirschstein, Artem Sevastopolsky, Shunsuke Saito, Qingyang Tan, Javier Romero, Chen Cao, Holly Rushmeier, Giljoo Nam* | **Category: cs.GR, cs.CV**

**Keywords:** 3D头部生成, 高斯泼溅, GAN, 可组合性, 发型编辑

**Comment:** Accepted to SIGGRAPH 2025. Project page:
  https://c-he.github.io/projects/3dgh/

> **TL;DR:** 3DGH是一种新的3D头部生成模型，通过分离头发和面部，实现了可组合的头部图像合成和发型编辑。

**AI_Comments:** 3DGH的创新之处在于其独特的数据表示和双生成器架构，成功解决了头发和面部建模的纠缠问题，从而实现了更精细的可组合性。这对于虚拟形象、游戏和动画等领域具有重要意义，因为它允许用户更灵活地编辑和生成3D头部资产。

<details>
  <summary>Details</summary>

**Motivation:** 以前的工作将头发和面部的建模纠缠在一起，限制了可组合性，而3DGH旨在解决这一问题。

**Method:** 提出了一种基于模板的3D高斯泼溅的新型数据表示，其中引入了可变形头发几何体以捕捉发型变化。在此数据表示基础上，设计了一个带有双生成器的3D GAN架构，并采用交叉注意力机制来建模头发和面部之间的内在关联。模型在合成渲染上训练，采用精心设计的优化目标以稳定训练并促进头发与面部的分离。

**Result:** 3DGH在无条件全头图像合成和可组合3D发型编辑方面表现出有效性。通过与现有最先进的3D GAN方法进行定性和定量比较，验证了其设计选择和性能。

**Conclusion:** 3DGH通过分离头发和面部，提出了一种有效且可组合的3D头部生成方法，成功实现了无条件全头图像合成和3D发型编辑。

> **ai_Abstract:** 3DGH是一种创新的无条件3D人头生成模型，其核心在于通过引入基于模板的3D高斯泼溅和可变形头发几何体，实现了头发和面部的独立建模。该模型采用双生成器3D GAN架构和交叉注意力机制来处理头发与面部的相关性，并通过精心设计的训练目标在合成数据上进行优化。实验证明，3DGH在无条件全头图像合成和可组合3D发型编辑方面均表现出色，超越了现有技术。

> **摘要翻译:** 我们提出了3DGH，一个用于生成具有可组合头发和面部组件的3D人头的无条件生成模型。与以往将头发和面部建模纠缠在一起的工作不同，我们提出使用一种基于模板的3D高斯泼溅的新型数据表示来分离它们，其中引入了可变形的头发几何体以捕捉不同发型之间的几何变化。基于这种数据表示，我们设计了一个带有双生成器的3D GAN架构，并采用交叉注意力机制来建模头发和面部之间的内在关联。该模型在合成渲染上训练，采用精心设计的优化目标以稳定训练并促进头发与面部的分离。我们进行了广泛的实验来验证3DGH的设计选择，并通过与几种最先进的3D GAN方法进行定性和定量比较来评估它，证明了其在无条件全头图像合成和可组合3D发型编辑方面的有效性。更多详细信息将在我们的项目页面上提供：https://c-he.github.io/projects/3dgh/。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [87] [Data Visualization for Improving Financial Literacy: A Systematic Review](https://arxiv.org/abs/2506.20901)
> *数据可视化对提高金融素养的作用：一项系统综述*

*Meng Du, Robert Amor, Kwan-Liu Ma, Burkhard C. Wünsche* | **Category: cs.GR**

**Keywords:** 数据可视化, 金融素养, 系统综述, 金融教育, 视觉分析

**Comment:** 

> **TL;DR:** 金融素养对个人至关重要但理解困难，数据可视化能简化概念。本系统综述分析了37篇论文，分类了数据可视化在金融教育中的应用，并提出了研究空白和实践建议。

**AI_Comments:** 这篇系统综述通过对现有文献的全面梳理和分类，为数据可视化在金融素养教育领域的应用提供了宝贵的结构化知识和实践指导，并指明了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 金融素养对个人财务福祉和安全至关重要，但许多人觉得金融概念难以理解，且只有一半的美国成年人具备金融素养。数据可视化可以简化这些概念，使其更易于理解和吸引人。

**Method:** 本文进行了一项系统综述，分析了37篇探讨数据可视化和视觉分析在金融教育和素养提升中应用的论文。研究将这些论文分为五个关键领域进行分类。

**Result:** 研究将文献分为五个关键领域：(1) 可视化使用在时间和空间上的演变，(2) 使用可视化工具的动机，(3) 所涉及的金融主题和教学方法，(4) 所应用的工具和技术类型，以及 (5) 如何评估教学干预的有效性。此外，研究还识别了研究空白并强调了推进金融素养的机会。

**Conclusion:** 本研究的发现为教育工作者和专业人士有效利用或设计可视化工具以提高金融素养提供了实用的见解。

> **ai_Abstract:** 本文通过对37篇研究论文的系统综述，探讨了数据可视化在金融教育和金融素养提升中的应用。研究将现有文献分类为可视化演变、使用动机、主题与教学方法、工具与技术类型以及效果评估五个方面。同时，该综述指出了研究空白，并为教育者和专业人士提供了利用可视化工具提高金融素养的实践指导。

> **摘要翻译:** 金融素养使个人能够做出明智有效的财务决策，从而提高他们的整体财务福祉和安全。然而，对许多人来说，理解金融概念可能令人生畏，而且只有一半的美国成年人被认为是具备金融素养的。数据可视化简化了这些概念，使其对所有年龄段的学习者来说都易于理解和引人入胜。本系统综述分析了37篇研究论文，探讨了数据可视化和视觉分析在金融教育和素养提升中的应用。我们将这些研究分为五个关键领域：(1) 可视化使用在时间和空间上的演变，(2) 使用可视化工具的动机，(3) 所涉及的金融主题和教学方法，(4) 所应用的工具和技术类型，以及 (5) 如何评估教学干预的有效性。此外，我们还识别了研究空白，并强调了推进金融素养的机会。我们的研究结果为教育工作者和专业人士有效利用或设计可视化工具以提高金融素养提供了实用的见解。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [110] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
> *使用几何感知扩散和时间视频模型进行一致的零样本3D纹理合成*

*Donggoo Kang, Jangyeong Kim, Dasol Jeong, Junyoung Choi, Jeonga Wi, Hyunmin Lee, Joonho Gwon, Joonki Paik* | **Category: cs.GR, cs.AI, cs.CV, 68T45, 68U05, I.3.7; I.4.10; I.2.10**

**Keywords:** 3D纹理合成, 视频生成模型, 几何感知, 扩散模型, 时间一致性

**Comment:** 

> **TL;DR:** VideoTex利用视频生成模型实现一致的3D纹理合成，解决了现有方法的空间和时间不一致性问题，并通过几何感知和结构化UV扩散策略提高了纹理质量和稳定性。

**AI_Comments:** 该论文的创新点在于将视频生成模型的优势引入到3D纹理合成中，有效地解决了传统方法在全局上下文和几何理解方面的不足，尤其是在处理空间和时间一致性问题上。几何感知和结构化UV扩散策略是其核心贡献，显著提升了纹理质量和跨帧稳定性，这对于实时3D应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的纹理合成方法由于缺乏全局上下文和几何理解，从固定视角生成纹理时存在不一致性。尽管视频生成模型在实现时间一致性视频方面取得了显著成功，但3D纹理合成仍面临挑战。

**Method:** 本文引入了VideoTex框架，该框架利用视频生成模型解决3D纹理中的空间和时间不一致性。它整合了几何感知条件以精确利用3D网格结构，并提出了一种结构化UV扩散策略，通过保留语义信息来增强遮挡区域的生成，从而产生更平滑、更连贯的纹理。

**Result:** VideoTex不仅实现了UV边界之间更平滑的过渡，而且确保了视频帧之间高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法。

**Conclusion:** VideoTex为需要视觉质量和时间连贯性的动态实时应用铺平了道路，通过其创新的几何感知扩散和时间视频模型方法，解决了3D纹理合成中的关键一致性问题。

> **ai_Abstract:** VideoTex是一个新颖的框架，利用视频生成模型解决3D纹理合成中的空间和时间不一致性问题。它通过引入几何感知条件和结构化UV扩散策略，精确利用3D网格结构并增强遮挡区域的生成，从而实现高质量、时间稳定的纹理。实验证明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法，为动态实时应用提供了可能。

> **摘要翻译:** 当前的纹理合成方法从固定视角生成纹理时，由于缺乏全局上下文和几何理解，存在不一致性。与此同时，视频生成模型的最新进展在实现时间一致性视频方面取得了显著成功。在本文中，我们引入了VideoTex，这是一个用于无缝纹理合成的新颖框架，它利用视频生成模型来解决3D纹理中的空间和时间不一致性。我们的方法结合了几何感知条件，能够精确利用3D网格结构。此外，我们提出了一种结构化UV扩散策略，通过保留语义信息来增强遮挡区域的生成，从而产生更平滑、更连贯的纹理。VideoTex不仅实现了UV边界之间更平滑的过渡，而且确保了视频帧之间高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法，为需要视觉质量和时间连贯性的动态实时应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [131] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
> *FairyGen: 从儿童手绘角色生成故事驱动的卡通视频*

*Jiayi Zheng, Xiaodong Cun* | **Category: cs.GR, cs.CV, cs.MM**

**Keywords:** 儿童手绘, 卡通视频生成, 故事驱动动画, 风格保持, 电影镜头设计

**Comment:** Project Page: https://jayleejia.github.io/FairyGen/ ; Code:
  https://github.com/GVCLab/FairyGen

> **TL;DR:** FairyGen是一个从单个儿童绘画自动生成故事驱动卡通视频的系统，它忠实保留了绘画的独特艺术风格，并通过解耦角色与背景、融入电影镜头设计等方式，实现富有表现力和连贯的动画。

**AI_Comments:** 该论文提出了一种创新方法，利用多模态大语言模型和扩散模型，实现了从儿童手绘角色生成故事驱动的卡通视频。其核心创新在于明确地将角色建模与风格化背景生成解耦，并巧妙地融入电影镜头设计，显著提升了叙事表现力和视觉质量。此外，两阶段运动定制适配器的设计也有效解决了动画中身份与运动的解耦问题，确保了动作的自然与合理。该系统在忠实保留原画艺术风格的同时，生成复杂、故事驱动的动画的能力，展现了其在个性化内容创作领域的巨大潜力，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有讲故事方法主要关注角色一致性和基本运动，而FairyGen旨在解决这些局限性，通过明确解耦角色建模与风格化背景生成，并融入电影镜头设计，以支持更具表现力和连贯性的故事讲述，从而实现个性化和引人入胜的故事动画。

**Method:** FairyGen系统首先使用MLLM从单个角色草图生成带有镜头级别描述的结构化故事板。然后，引入风格传播适配器将角色风格应用于背景以确保视觉一致性。接着，通过镜头设计模块（帧裁剪和多视角合成）增强视觉多样性和电影质量。为了动画化，系统重建角色的3D代理以获得物理上合理的运动序列，并用其微调基于MMDiT的图像到视频扩散模型。此外，提出了一个两阶段运动定制适配器：第一阶段从时间无序帧中学习外观特征以解耦身份与运动；第二阶段使用带有冻结身份权重的时步偏移策略建模时间动态。

**Result:** FairyGen系统能够生成与故事板对齐的多样且连贯的视频场景。实验证明，其生成的动画在风格上忠实于原始绘画，叙事结构清晰，且运动自然。

**Conclusion:** FairyGen系统通过从单个儿童绘画生成风格忠实、叙事结构化且运动自然的卡通视频，展示了其在个性化和引人入胜的故事动画方面的巨大潜力。

> **ai_Abstract:** FairyGen是一个创新的自动化系统，能将儿童手绘角色转化为故事驱动的卡通视频，并忠实保留其独特艺术风格。该系统通过使用MLLM生成详细故事板，引入风格传播适配器确保视觉一致性，利用镜头设计模块提升电影感，并通过3D代理重建和两阶段运动定制适配器（基于MMDiT扩散模型）实现逼真动画。它有效解决了传统方法的局限，通过解耦角色与背景、融入电影镜头设计，最终生成风格忠实、叙事连贯且动作自然的动画，为个性化故事动画开辟了新途径。

> **摘要翻译:** 我们提出了FairyGen，一个从单个儿童绘画中自动生成故事驱动卡通视频的系统，同时忠实地保留其独特的艺术风格。与之前主要关注角色一致性和基本运动的讲故事方法不同，FairyGen明确地将角色建模与风格化背景生成解耦，并融入电影镜头设计以支持富有表现力和连贯的讲故事。给定一个单一的角色草图，我们首先使用MLLM生成一个带有镜头级别描述的结构化故事板，指定环境设置、角色动作和摄像机视角。为了确保视觉一致性，我们引入了一个风格传播适配器，它捕获角色的视觉风格并将其应用于背景，忠实地保留角色的完整视觉特征，同时合成风格一致的场景。一个镜头设计模块通过基于故事板的帧裁剪和多视角合成进一步增强视觉多样性和电影质量。为了动画化故事，我们重建了角色的3D代理以导出物理上合理的运动序列，然后用于微调基于MMDiT的图像到视频扩散模型。我们进一步提出了一个两阶段运动定制适配器：第一阶段从时间无序的帧中学习外观特征，将身份与运动解耦；第二阶段使用带有冻结身份权重的时步偏移策略对时间动态进行建模。一旦训练完成，FairyGen直接渲染与故事板对齐的多样且连贯的视频场景。广泛的实验表明，我们的系统生成了风格忠实、叙事结构化、运动自然的动画，突出了其在个性化和引人入胜的故事动画方面的潜力。代码将在https://github.com/GVCLab/FairyGen提供。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [148] [IDGraphs: Intrusion Detection and Analysis Using Stream Compositing](https://arxiv.org/abs/2506.21425)
> *IDGraphs：使用流合成的入侵检测与分析*

*Pin Ren, Yan Gao, Zhichun Li, Yan Chen, Benjamin Watson* | **Category: cs.GR, cs.CR**

**Keywords:** 入侵检测, 可视化, 流合成, 网络安全, 异常检测

**Comment:** 

> **TL;DR:** IDGraphs是一个交互式可视化系统，用于通过流合成技术检测和分析网络入侵，解决了现有IDS在交互性、蠕虫传播分析和关联攻击发现方面的不足，并在真实数据集上成功检测多种攻击。

**AI_Comments:** IDGraphs的创新之处在于其将流合成和Histographs技术应用于入侵检测的可视化分析，提供了一种交互式的方法来处理大规模网络流量数据。其重要性体现在解决了现有IDS在处理复杂、分布式攻击和提供深入交互式分析方面的不足。它通过可视化手段，使得操作员能够更直观地发现和理解网络中的异常模式，尤其是在识别关联攻击和蠕虫传播方面。抽象中未明确提及限制，但可以推断其可能需要一定的可视化专业知识来有效利用，且对实时性要求极高的场景可能需要进一步优化。

<details>
  <summary>Details</summary>

**Motivation:** 现有入侵检测系统在交互式检查、分析蠕虫传播模式和发现关联攻击方面支持有限，且在高速网络流量增长下问题日益严重，快速准确地识别流量异常和攻击对大型网络运营商至关重要。

**Method:** IDGraphs是一个交互式可视化系统。它通过在水平轴上绘制时间、垂直轴上绘制聚合的未成功连接数来生成流级别的跟踪。系统使用Histographs技术将数万个此类跟踪堆栈汇总，将每个像素的数据频率映射到亮度。用户可以交互式查询汇总视图，通过突出显示跟踪子集进行分析，例如，刷选关联矩阵视图可突出显示具有相似模式的跟踪，从而揭示难以通过标准统计分析检测到的分布式攻击。

**Result:** 将IDGraphs系统应用于包含1.79亿流级别记录（总流量1.16TB）的真实网络路由器数据集。系统成功检测并分析了多种攻击和异常，包括端口扫描、蠕虫爆发、隐蔽的TCP SYN洪泛以及一些分布式攻击。

**Conclusion:** IDGraphs系统通过其创新的交互式可视化方法，有效解决了现有入侵检测系统在处理高速网络流量和复杂攻击模式方面的局限性，实现了对多种网络攻击和异常的成功检测与分析。

> **ai_Abstract:** 本文提出IDGraphs，一个交互式入侵检测可视化系统，旨在解决现有IDS在高速网络中对复杂攻击（如蠕虫传播和关联攻击）交互式分析的局限性。IDGraphs通过流级别跟踪和Histographs技术对大量数据进行可视化汇总，并允许用户交互式查询和分析。在真实网络数据集上的应用表明，IDGraphs能有效检测并分析包括端口扫描、蠕虫爆发和分布式攻击在内的多种流量异常。

> **摘要翻译:** 今天的网络中，流量异常和攻击司空见惯，对大型网络运营商而言，快速准确地识别它们至关重要。对于统计入侵检测系统（IDS）来说，在流级别进行检测对于准确的检测和缓解至关重要。然而，现有IDS系统仅提供有限的支持，用于：1) 交互式检查已检测到的入侵和异常，2) 分析蠕虫传播模式，3) 发现关联攻击。随着当今高速路由器上的流量持续增长，这些问题变得更加严峻。
IDGraphs是一个交互式可视化系统，用于入侵检测，旨在解决这些挑战。该系统的核心可视化是一个流级别的跟踪图，其中时间在水平轴上，聚合的未成功连接数在垂直轴上。然后，我们使用Histographs [RW05]技术总结了数万个此类跟踪的堆栈，该技术将每个像素的数据频率映射到亮度。用户可以交互式查询汇总视图，通过突出显示跟踪子集进行分析。例如，刷选链接的关联矩阵视图会突出显示具有相似模式的跟踪，从而揭示难以使用标准统计分析检测到的分布式攻击。
我们将IDGraphs系统应用于一个真实的网络路由器数据集，该数据集包含1.79亿条流级别记录，代表总流量1.16TB。该系统成功检测并分析了各种攻击和异常，包括端口扫描、蠕虫爆发、隐蔽的TCP SYN洪泛以及一些分布式攻击。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [41] [RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced Retrieval-Augmented Generation in Recommendation](https://arxiv.org/abs/2506.20817)
> *RAG-VisualRec：一个用于推荐系统中视觉和文本增强的检索增强生成开放资源*

*Ali Tourani, Fatemeh Nazary, Yashar Deldjoo* | **Category: cs.IR, cs.MM**

**Keywords:** 多模态推荐, 检索增强生成, 视觉嵌入, 冷启动, 电影推荐

**Comment:** 20 pages, 6 figures, 5 tables

> **TL;DR:** RAG-VisualRec是一个开放资源，它结合了LLM生成的剧情描述和预告片视觉嵌入，用于多模态电影推荐，并展示了召回率和NDCG的提升。

**AI_Comments:** 该论文提供了一个有价值的开放资源，解决了多模态推荐中常见的稀疏元数据挑战。它创新性地利用LLM生成的描述和预告片视觉嵌入，结合融合技术和重排序，为更鲁棒和细致的推荐系统（特别是冷启动场景）提供了有前景的方向。代码和数据的公开发布对未来的研究非常有益。

<details>
  <summary>Details</summary>

**Motivation:** 在电影领域，有限的元数据（例如，标题、类型）通常会阻碍鲁棒推荐的生成，因此需要开发多模态推荐系统来解决这一挑战。

**Method:** 该方法引入了一个资源，将LLM生成的剧情描述与预告片提取的视觉嵌入在一个统一的管道中结合起来，支持检索增强生成（RAG）和协同过滤。其核心是数据增强步骤，将稀疏元数据转换为更丰富的文本信号，并采用融合策略（如PCA、CCA）整合视觉线索。此外，还包含一个LLM驱动的重排序步骤。

**Result:** 实验评估表明，与单模态基线相比，基于CCA的融合显著提高了召回率，而LLM驱动的重排序步骤进一步改善了NDCG，尤其是在文本数据有限的情况下。

**Conclusion:** 该论文发布的框架鼓励进一步探索针对冷启动、注重新颖性和特定领域设置的多模态推荐技术。

> **ai_Abstract:** RAG-VisualRec是一个开放资源，旨在解决电影推荐中元数据有限的问题，通过整合LLM生成的剧情描述和预告片视觉嵌入来增强推荐。它采用数据增强、融合策略（如CCA、PCA）以及LLM驱动的重排序，以实现多模态推荐，并展示了召回率和NDCG的显著提升。

> **摘要翻译:** 本文旨在解决电影领域开发多模态推荐系统所面临的挑战，即有限的元数据（例如，标题、类型）常常阻碍生成鲁棒的推荐。我们引入了一个资源，它将LLM生成的剧情描述与预告片提取的视觉嵌入在一个统一的管道中结合起来，支持检索增强生成（RAG）和协同过滤。我们方法的核心是数据增强步骤，将稀疏元数据转换为更丰富的文本信号，以及整合视觉线索的融合策略（例如，PCA、CCA）。实验评估表明，与单模态基线相比，基于CCA的融合显著提高了召回率，而LLM驱动的重排序步骤进一步改善了NDCG，尤其是在文本数据有限的情况下。通过发布此框架，我们邀请对针对冷启动、注重新颖性和特定领域设置的多模态推荐技术进行进一步探索。所有代码、数据和详细文档均可在以下网址公开获取：https://github.com/RecSys-lab/RAG-VisualRec

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [65] [The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers](https://arxiv.org/abs/2506.20844)
> *科学事实核查的下一阶段：从复杂结构化学术论文中进行高级证据检索*

*Xingyu Deng, Xi Wang, Mark Stevenson* | **Category: cs.IR, H.3.3**

**Keywords:** 科学事实核查, 证据检索, 学术论文, 信息检索, 挑战

**Comment:** Accepted for ACM SIGIR Conference on Innovative Concepts and Theories
  in Information Retrieval (ICTIR'25)

> **TL;DR:** 现有科学事实核查系统无法处理完整的学术论文，本研究旨在通过识别挑战和潜在解决方案来改进专门的信息检索系统，以应对复杂科学文献的证据检索。

**AI_Comments:** 这篇论文的创新点在于它明确指出了现有科学事实核查系统在处理完整学术论文时的不足，并系统地列出了未来需要解决的关键挑战。它强调了将信息检索技术应用于复杂科学文本的重要性，特别是考虑到多模态信息和时间维度。这对于提高科学信息的可信度和自动化核查效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的科学事实核查方法主要基于小型数据集（如摘要），未能解决处理完整学术论文所带来的独特挑战，包括科学知识的演变性、学术文献的结构复杂性以及长篇、多模态科学表达的挑战。

**Method:** 本文审视了当前科学事实核查系统的局限性，揭示了可用于提升其性能的潜在特征和资源。它识别了证据检索中的关键研究挑战，并进行了初步实验来证实这些挑战并确定潜在解决方案。

**Result:** 论文识别了证据检索中的关键研究挑战，包括：解决语义限制和主题不平衡的证据驱动检索；利用引文跟踪缓解过时信息的时间感知证据检索；利用长程上下文的结构化文档解析；处理复杂科学表达（表格、图、领域特定术语）；以及评估科学文献的可信度。初步实验证实了这些挑战并确定了潜在解决方案。

**Conclusion:** 本视角论文旨在通过一个专门为实际应用定制的信息检索系统来推进科学事实核查。

> **ai_Abstract:** 本文探讨了科学事实核查的下一阶段，指出现有系统在处理完整、复杂结构化学术论文方面的局限性。研究识别了在证据检索中面临的关键挑战，包括语义、时间、结构化文档解析、复杂表达处理和可信度评估。通过初步实验证实这些挑战并提出潜在解决方案，旨在开发一个专门的信息检索系统以改进科学事实核查。

> **摘要翻译:** 科学事实核查旨在通过从研究文献中检索和分析证据来确定科学主张的真实性。这个问题本质上比一般事实核查更复杂，因为它必须适应科学知识的演变性质、学术文献的结构复杂性以及长篇、多模态科学表达所带来的挑战。然而，现有方法侧重于基于由摘要而非完整论文组成的小规模数据集的简化版本问题，从而避免了处理完整文档所带来的独特挑战。本文审视了当前科学事实核查系统的局限性，并揭示了可用于提升其性能的许多潜在特征和资源。它识别了证据检索中的关键研究挑战，包括：(1) 解决语义限制和主题不平衡的证据驱动检索；(2) 利用引文跟踪缓解过时信息的时间感知证据检索；(3) 利用长程上下文的结构化文档解析；(4) 处理复杂科学表达，包括表格、图和领域特定术语；以及(5) 评估科学文献的可信度。进行了初步实验以证实这些挑战并确定潜在解决方案。本视角论文旨在通过一个专门为实际应用定制的专业信息检索系统来推进科学事实核查。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [88] [Towards Two-Stage Counterfactual Learning to Rank](https://arxiv.org/abs/2506.20854)
> *迈向两阶段反事实学习排序*

*Shashank Gupta, Yiming Liao, Maarten de Rijke* | **Category: cs.IR**

**Keywords:** 反事实学习排序, 两阶段排序, 联合优化, 候选生成, 排序器

**Comment:** Accepted at ICTIR 2025 (co-located with SIGIR 2025)

> **TL;DR:** 本文提出了一种两阶段反事实学习排序（CLTR）方法，旨在联合训练候选生成器和排序器，以解决现有单阶段CLTR在大规模数据集上的不实用性以及现有两阶段CLTR方法的局限性。

**AI_Comments:** 该论文解决了CLTR研究中的一个关键空白，将其扩展到更符合实际应用的两阶段排序系统。其创新之处在于首次提出了针对两阶段排序的CLTR估计器和联合优化学习方法，这对于处理大规模文档集的真实世界系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有反事实学习排序（CLTR）方法多为单阶段，不适用于包含数百万文档的实际大规模排序系统。现有的针对两阶段系统的CLTR方法仅限于Top-1设置且只训练候选生成器而固定排序器，缺乏一种能联合训练排序器和候选生成器的CLTR方法。

**Method:** 本文提出了一种两阶段CLTR估计器，该估计器考虑了两个阶段之间的交互，并离线估计了两种策略的联合价值。此外，还提出了一种新颖的联合优化方法，分别训练候选生成器和排序器策略。

**Result:** 在半合成基准上的实验结果表明，所提出的联合CLTR方法优于基线方法。

**Conclusion:** 本文首次提出了针对两阶段排序系统的CLTR估计器和学习方法，实现了候选生成器和排序器策略的联合优化，并验证了其有效性。

> **ai_Abstract:** 本文针对现有反事实学习排序（CLTR）方法在处理大规模文档集时的局限性，提出了一种新颖的两阶段CLTR框架。该框架包含一个考虑两阶段交互并离线估计联合价值的CLTR估计器，以及一种用于联合训练候选生成器和排序器的新型优化方法。实验结果在一个半合成基准上验证了所提联合CLTR方法的有效性，填补了现有文献中缺乏两阶段CLTR联合训练方法的空白。

> **摘要翻译:** 反事实学习排序（CLTR）旨在从用户交互中学习排序策略，同时纠正交互数据中固有的偏差，例如位置偏差。现有的CLTR方法假设单一排序策略从整个文档候选集中选择Top-K排序。在实际应用中，候选文档集数量级达到数百万，使得单一阶段的排序策略不切实际。为了扩展到数百万文档，实际的排序系统设计为两阶段模式，即候选生成器后接一个排序器。现有针对两阶段离线排序系统的CLTR方法只考虑了Top-1排序设置，并且只专注于训练候选生成器，而排序器是固定的。现有文献中缺少一种用于联合训练排序器和候选生成器的CLTR方法。在本文中，我们提出了一种两阶段CLTR估计器，它考虑了两个阶段之间的交互，并离线估计了两种策略的联合价值。此外，我们提出了一种新颖的联合优化方法，分别训练候选生成器和排序器策略。据我们所知，我们是第一个提出两阶段排序的CLTR估计器和学习方法。在半合成基准上的实验结果证明了所提出的联合CLTR方法优于基线方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [111] [EraRAG: Efficient and Incremental Retrieval Augmented Generation for Growing Corpora](https://arxiv.org/abs/2506.20963)
> *EraRAG：面向增长型语料库的高效增量检索增强生成*

*Fangyuan Zhang, Zhengjun Huang, Yingli Zhou, Qintian Guo, Zhixun Li, Wensheng Luo, Di Jiang, Yixiang Fang, Xiaofang Zhou* | **Category: cs.IR, cs.LG**

**Keywords:** Retrieval Augmented Generation, Graph-RAG, Incremental Updates, Locality-Sensitive Hashing, Dynamic Corpora

**Comment:** Under review

> **TL;DR:** EraRAG 是一种新的图增强检索生成 (Graph-RAG) 框架，通过引入高效的增量更新机制，解决了现有系统在动态语料库中重建图的昂贵问题，显著提升了更新效率和准确性。

**AI_Comments:** 这篇论文的创新点在于提出了一个支持高效增量更新的 Graph-RAG 框架，通过引入 LSH 和分层图结构，解决了传统 Graph-RAG 在动态语料库中重建成本高昂的痛点。这对于需要处理持续增长数据的实际应用场景具有重要意义，极大地提升了 RAG 系统的实用性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图增强检索生成 (Graph-RAG) 方法通常假设语料库是静态的，当有新文档到来时，需要昂贵的完整图重建，这限制了它们在动态、不断演变环境中的可扩展性。

**Method:** 引入了一种名为 EraRAG 的新型多层图增强检索生成 (Graph-RAG) 框架。该方法利用基于超平面的局部敏感哈希 (LSH) 将原始语料库分区并组织成层次图结构，从而实现新数据的高效局部插入，而不会破坏现有拓扑结构，消除了再训练或昂贵重新计算的需求。

**Result:** 在大规模基准测试中，EraRAG 与现有 Graph-RAG 系统相比，更新时间与令牌消耗减少了一个数量级，同时提供了卓越的准确性性能。

**Conclusion:** 这项工作为必须在持续增长的语料库上运行的 RAG 系统提供了一条实用的前进道路，弥合了检索效率和适应性之间的差距。

> **ai_Abstract:** EraRAG 是一种创新的多层图增强检索生成 (Graph-RAG) 框架，旨在解决现有 Graph-RAG 系统在动态增长语料库中效率低下的问题。它通过利用基于超平面的局部敏感哈希 (LSH) 构建层次图结构，实现了新数据的局部高效插入，无需昂贵的图重建或再训练。实验证明，EraRAG 在更新效率、令牌消耗和检索准确性方面均显著优于现有系统，为在不断扩展的语料库上运行的 RAG 系统提供了实用的解决方案。

> **摘要翻译:** 图增强检索生成 (Graph-RAG) 通过对外部语料库进行结构化检索来增强大型语言模型 (LLM)。然而，现有方法通常假设语料库是静态的，当有新文档到来时，需要昂贵的完整图重建，这限制了它们在动态、不断演变环境中的可扩展性。为了解决这些限制，我们引入了 EraRAG，一种新型多层 Graph-RAG 框架，它支持高效和可扩展的动态更新。我们的方法利用基于超平面的局部敏感哈希 (LSH) 将原始语料库分区并组织成层次图结构，从而实现新数据的高效局部插入，而不会破坏现有拓扑结构。这种设计消除了再训练或昂贵重新计算的需求，同时保持了高检索准确性和低延迟。大规模基准测试的实验表明，与现有 Graph-RAG 系统相比，EraRAG 在更新时间与令牌消耗方面实现了高达一个数量级的减少，同时提供了卓越的准确性性能。这项工作为必须在持续增长的语料库上运行的 RAG 系统提供了一条实用的前进道路，弥合了检索效率和适应性之间的差距。我们的代码和数据可在 https://github.com/EverM0re/EraRAG-Official 获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [132] [Response Quality Assessment for Retrieval-Augmented Generation via Conditional Conformal Factuality](https://arxiv.org/abs/2506.20978)
> *通过条件共形事实性评估检索增强生成响应质量*

*Naihe Feng, Yi Sui, Shiyi Hou, Jesse C. Cresswell, Ga Wu* | **Category: cs.IR, H.3.3**

**Keywords:** 检索增强生成, 响应质量评估, 共形预测, 事实性, 统计保证

**Comment:** Accepted by SIGIR 2025 short paper, 5 pages, Code is available at
  https://github.com/n4feng/ResponseQualityAssessment

> **TL;DR:** Conformal-RAG利用共形预测为RAG响应子声明的质量提供统计保证，无需真实标签，并比直接应用CP效果更好。

**AI_Comments:** Conformal-RAG的创新之处在于将共形预测与RAG系统内部信息结合，为RAG响应的子声明质量提供统计层面的可靠性保证。这解决了RAG在实际应用中可信度评估的关键挑战，尤其是在无需真实标签的情况下提供概率保证，具有重要的实际意义和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有RAG研究主要关注整体问答准确性，忽视了生成响应中子声明的质量；此外，现有的RAG自动评估方法缺乏概率保证或需要真实答案。

**Method:** 本文提出了Conformal-RAG框架，该框架受共形预测（CP）在大型语言模型（LLM）上应用的启发。Conformal-RAG利用CP和RAG机制的内部信息，为响应质量提供统计保证，并确保跨多个子域的组条件覆盖，无需手动标记共形集。

**Result:** 与现有RAG自动评估方法相比，Conformal-RAG对精炼子声明的质量提供统计保证，确保响应可靠性而无需真实答案。实验表明，在保持相同可靠性保证的情况下，Conformal-RAG比直接将CP应用于LLM保留多达60%的高质量子声明。

**Conclusion:** Conformal-RAG通过利用RAG系统信息，为RAG响应的子声明质量提供可靠的统计保证，解决了现有评估方法缺乏概率保证和对真实标签依赖的局限性。

> **ai_Abstract:** 本文提出了Conformal-RAG框架，旨在解决检索增强生成（RAG）中子声明质量评估的不足。该框架利用共形预测（CP）和RAG机制的内部信息，为RAG生成响应的子声明质量提供统计保证，克服了现有评估方法缺乏概率保证和需要真实标签的限制。实验证明，Conformal-RAG在提供可靠性保证的同时，能比直接应用CP到LLM保留更多高质量子声明。

> **摘要翻译:** 现有关于检索增强生成（RAG）的研究主要侧重于提高整体问答准确性，往往忽视了生成响应中子声明的质量。最近旨在通过自动评估指标等方式提高RAG可信度的方法，缺乏概率保证或需要真实答案。为了解决这些局限性，我们提出了Conformal-RAG，一个受最近共形预测（CP）在大型语言模型（LLM）上应用启发的全新框架。Conformal-RAG利用CP和RAG机制的内部信息，为响应质量提供统计保证。它确保跨多个子域的组条件覆盖，而无需手动标记共形集，使其适用于复杂的RAG应用。与现有RAG自动评估方法相比，Conformal-RAG对精炼子声明的质量提供统计保证，确保响应可靠性而无需真实答案。此外，我们的实验表明，通过利用RAG系统的信息，Conformal-RAG在保持相同可靠性保证的情况下，比直接将CP应用于LLM保留多达60%的高质量子声明。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [149] [RecCoT: Enhancing Recommendation via Chain-of-Thought](https://arxiv.org/abs/2506.21032)
> *RecCoT：通过思维链增强推荐*

*Shuo Yang, Jiangxia Cao, Haipeng Li, Yuqi Mao, Shuchao Pang* | **Category: cs.IR**

**Keywords:** 推荐系统, 思维链, 可解释性, 用户偏好, 评论分析

**Comment:** Work in progress

> **TL;DR:** 现有推荐系统难以理解用户偏好背后的原因，因为它们侧重于行为共现而非内容语义。一些方法尝试利用评论内容，但未能提供人类可理解的解释。

**AI_Comments:** 该论文旨在解决现有推荐系统在理解用户偏好原因方面的不足，并指出现有基于评论的方法未能提供人类可理解的解释。其创新点在于提出“思维链”来增强推荐，这暗示了对推荐系统可解释性或推理能力的关注，是一个重要的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统主要通过隐式反馈学习用户-物品协作信号，但它们侧重于行为共现而非物品内容本身，导致难以理解用户喜欢或不喜欢某些物品的原因。尽管一些工作尝试利用基于内容的评论来捕获语义知识以增强推荐模型，但这些方法大多关注预测评论评分，未能提供人类可理解的解释。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文指出，当前推荐系统在理解用户偏好原因方面存在局限性，因为它们主要依赖于行为共现信号，而非物品内容。尽管有研究尝试利用评论内容来增强模型，但这些方法通常只预测评分，缺乏可解释性。

> **摘要翻译:** 在现实应用中，用户总是通过多个方面与物品互动，例如通过隐式二元反馈（如点击、不喜欢、长时间观看）和显式反馈（如评论、评价）。现代推荐系统（RecSys）从这些隐式反馈信号中学习用户-物品协作信号，作为大规模二元数据流，随后根据用户的个性化历史互动推荐其他高度相似的物品。然而，从这种协作连接的角度来看，推荐系统并不关注物品本身的实际内容，而是优先考虑物品之间行为共现的更高概率信号。因此，在这种二元学习范式下，推荐系统难以理解用户喜欢或不喜欢某些物品的原因。为了缓解这个问题，一些工作尝试利用基于内容的评论来捕获语义知识以增强推荐模型。然而，这些方法大多侧重于预测评论评分，但未能提供人类可理解的解释。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [169] [Real-time and personalized product recommendations for large e-commerce platforms](https://arxiv.org/abs/2506.21368)
> *针对大型电商平台的实时个性化商品推荐*

*Matteo Tolloso, Davide Bacciu, Shahab Mokarizadeh, Marco Varesi* | **Category: cs.IR, cs.AI**

**Keywords:** 实时推荐, 个性化推荐, 图神经网络, 电商平台, 简约学习

**Comment:** This paper has been accepted for publication at the International
  Conference on Artificial Neural Networks (ICANN) 2025. The final
  authenticated version will be available for purchase through the publisher's
  website. The conference proceedings will be published by Springer in the
  Lecture Notes in Computer Science (LNCS) series

> **TL;DR:** 提出一种利用图神经网络和简约学习方法为大型电商平台提供实时个性化商品推荐的新方法，实验证明其在预测购买序列和处理多交互场景方面的有效性。

**AI_Comments:** 这项研究的创新之处在于将图神经网络与简约学习相结合，以解决大型电商平台实时个性化推荐的挑战，特别是在时尚零售领域。其重要性体现在能够提供高效、准确且低延迟的推荐服务，这对于提升用户体验和平台收益至关重要。该方法在处理多交互场景和大规模数据集方面的表现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 为大型电商平台提供准确、可扩展、响应时间短的实时个性化商品推荐，以确保用户满意度。

**Method:** 采用图神经网络（Graph Neural Networks）和简约学习方法（parsimonious learning methodologies）。

**Result:** 在预测购买序列和处理多交互场景方面表现出有效性，并在真实世界约束下实现了高效的个性化推荐。

**Conclusion:** 该方法能够为大型电商平台提供高效的实时个性化商品推荐，有效处理复杂场景。

> **ai_Abstract:** 本文提出了一种针对大型电商平台（特别是时尚零售）的实时个性化商品推荐方法。该方法结合了图神经网络和简约学习，旨在实现高准确度、可扩展性及低响应时间。通过在大型电商平台数据集上的实验，证明了其在预测购买序列和处理多交互场景中的有效性，能够高效地提供个性化推荐。

> **摘要翻译:** 我们提出了一种为大型电商平台提供实时个性化商品推荐的方法，特别侧重于时尚零售。我们的方法旨在通过最小的响应时间实现准确和可扩展的推荐，确保用户满意度，并利用图神经网络和简约学习方法。对来自最大电商平台之一的数据集进行的广泛实验表明，我们的方法在预测购买序列和处理多交互场景方面是有效的，在真实世界约束下实现了高效的个性化推荐。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [8] [Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing](https://arxiv.org/abs/2506.20782)
> *脉冲神经网络用于SAR干涉相位解缠：一种节能处理的理论框架*

*Marc Bara* | **Category: cs.NE, cs.ET, cs.LG, eess.SP, 68T07, 94A08, I.2.6; G.1.6; B.7.1**

**Keywords:** 脉冲神经网络, SAR干涉相位解缠, 节能处理, 神经形态计算, 理论框架

**Comment:** 8 pages, 2 figures, patent pending

> **TL;DR:** 首次提出将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架，旨在实现节能高效的处理。

**AI_Comments:** 这项工作具有创新性，因为它首次将SNNs应用于SAR相位解缠，填补了现有研究空白。其重要性在于为未来大规模地球观测数据的节能处理提供了新的范式，尤其是在神经形态计算和SAR干涉测量交叉领域开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 地球观测数据量呈指数级增长，需要节能处理以实现可持续的数据中心运营。传统方法能耗高，而脉冲神经网络（SNNs）具有显著节能潜力（30-100倍）。

**Method:** 开发了专门用于缠绕相位数据的脉冲编码方案；提出了利用相位解缠空间传播特性的SNN架构；提供了计算复杂度和收敛特性的理论分析。

**Result:** 该框架展示了SNNs固有的时间动态如何自然地模拟相位解缠中基本的空间连续性约束。

**Conclusion:** 这项工作开辟了神经形态计算和SAR干涉测量交叉领域的新研究方向，为现有算法提供了一种补充方法，可能实现更可持续的大规模InSAR处理。

> **ai_Abstract:** 本文首次提出了将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架。针对地球观测数据量激增导致的能耗问题，SNNs因其事件驱动特性可实现显著节能。研究开发了专门的脉冲编码方案和SNN架构，并分析了其计算复杂度和收敛性，证明SNN的时间动态能有效模拟相位解缠的空间连续性约束，为大规模InSAR处理提供了节能新途径。

> **摘要翻译:** 我们首次提出了将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架。尽管这两个领域都有广泛的研究，但我们全面的文献综述证实，SNNs从未应用于相位解缠，这代表了当前方法论中的一个显著空白。随着地球观测数据量继续呈指数级增长（像NISAR这样的任务预计两年内将产生100PB数据），节能处理对于可持续的数据中心运营变得至关重要。SNNs以其事件驱动的计算模型，与传统方法相比，在保持相当准确性的同时，可提供30-100倍的潜在能源节省。我们开发了专门为缠绕相位数据设计的脉冲编码方案，提出了利用相位解缠空间传播性质的SNN架构，并提供了计算复杂度和收敛特性的理论分析。我们的框架展示了SNNs固有的时间动态如何自然地模拟相位解缠中基本的空间连续性约束。这项工作开辟了神经形态计算和SAR干涉测量交叉领域的新研究方向，为现有算法提供了一种补充方法，可能实现更可持续的大规模InSAR处理。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [24] [Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher](https://arxiv.org/abs/2506.20834)
> *脑到模型迁移：以人类神经活动为教师训练感觉和决策模型*

*Tomas Gallo Aquino, Victoria Liu, Habiba Azab, Raissa Mathura, Andrew J Watrous, Eleonora Bartoli, Benjamin Y Hayden, Paul Sajda, Sameer A Sheth, Nuttida Rungratsameetaweemana* | **Category: cs.NE, cs.ET, q-bio.NC**

**Keywords:** 脑到模型迁移, 神经活动, 迁移学习, 人工神经网络, 决策模型

**Comment:** 15 pages, 4 figures

> **TL;DR:** 引入Brain2Model Transfer (B2M) 框架，利用人类神经活动作为教师信号，更高效地训练人工神经网络，使其收敛更快、准确率更高。

**AI_Comments:** 这项研究通过将人类神经活动引入人工神经网络的训练过程，开辟了神经科学与人工智能结合的新途径。其创新之处在于将大脑视为一种高效的“教师模型”，从而克服了传统迁移学习中对大型预训练人工模型的依赖。该方法有望显著提高人工模型在学习复杂、高效表征方面的效率和准确性，尤其是在数据或计算资源有限的场景下，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的迁移学习依赖于大型预训练人工模型，而人类大脑能以更少的数据和计算资源学习高效的低维抽象表示。该研究的动机是利用人类大脑的这种高效学习能力来改进人工模型的训练。

**Method:** 提出Brain2Model Transfer Learning (B2M) 框架，将人类感觉和决策任务中的神经活动作为教师模型来训练人工神经网络。具体包括两种策略：1) 脑对比迁移（Brain Contrastive Transfer），通过对比目标对齐大脑活动和网络激活；2) 脑潜在迁移（Brain Latent Transfer），通过对脑源性特征进行监督回归，将相似认知任务的潜在动态投射到学生网络。在基于记忆的决策任务（使用循环神经网络）和自动驾驶的场景重建（使用变分自编码器）中验证了B2M。

**Result:** 接受脑基迁移的学生网络比单独训练的网络收敛更快，并获得更高的预测准确性。

**Conclusion:** 研究结果表明，大脑的表征对于人工学习器很有价值，为更有效地学习复杂的决策表征铺平了道路，而这些表征通过纯粹的人工训练可能成本高昂或速度缓慢。

> **ai_Abstract:** 本文提出了Brain2Model Transfer (B2M) 框架，旨在利用人类神经活动作为教师信号来训练人工神经网络。针对人类大脑在学习高效低维表示时所需数据和计算资源远少于人工模型的特点，B2M提供了两种策略：脑对比迁移和脑潜在迁移。实验结果表明，通过B2M训练的学生网络能够更快收敛并达到更高的预测精度，证明了大脑表征对于提升人工学习效率的价值，尤其是在复杂决策表征学习方面。

> **摘要翻译:** 迁移学习通过利用大型预训练教师模型丰富的特征表示，增强了新型感觉和决策模型的训练。认知神经科学表明，人脑为高效的感觉运动编码创建低维、抽象的表示。重要的是，与人工模型所需的数据点和计算能力相比，大脑能够以显著更少的数据点和更少的计算能力学习这些表示。我们引入了脑到模型迁移学习（B2M），这是一个框架，其中人类感觉和决策任务中的神经活动充当训练人工神经网络的教师模型。我们提出了两种B2M策略：（1）脑对比迁移，它通过对比目标对齐大脑活动和网络激活；（2）脑潜在迁移，它通过对脑源性特征进行监督回归，将相似认知任务的潜在动态投射到学生网络。我们在基于记忆的决策任务（使用循环神经网络）和自动驾驶的场景重建（使用变分自编码器）中验证了B2M。结果表明，受益于脑基迁移的学生网络比单独训练的网络收敛更快，并获得更高的预测准确性。我们的发现表明，大脑的表示对于人工学习器很有价值，为更有效地学习复杂的决策表示铺平了道路，而这些表示通过纯粹的人工训练可能成本高昂或速度缓慢。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [90] [Stochastic Quantum Spiking Neural Networks with Quantum Memory and Local Learning](https://arxiv.org/abs/2506.21324)
> *具有量子记忆和局部学习的随机量子脉冲神经网络*

*Jiechen Chen, Bipin Rajendran, Osvaldo Simeone* | **Category: cs.NE, cs.LG**

**Keywords:** 随机量子脉冲神经网络, 量子记忆, 局部学习, 神经形态计算, 量子计算

**Comment:** 

> **TL;DR:** 本文提出了一种随机量子脉冲（SQS）神经元模型及其网络（SQSNNs），通过利用多量子比特量子电路实现内部量子记忆和一次性概率脉冲生成，并采用硬件友好的局部学习规则进行训练，从而结合了神经形态计算的效率和量子计算的巨大状态空间，旨在实现模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络。

**AI_Comments:** 该论文提出了一种创新的混合方法，将量子计算原理与神经形态系统相结合。其主要创新包括使用多量子比特量子记忆实现脉冲神经元以及硬件友好的局部学习规则，这解决了现有量子脉冲模型的显著局限性。这可能是迈向实用、可扩展的量子神经网络的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 神经形态计算和量子计算是推动人工智能发展的有前景的范式，但现有量子脉冲模型存在局限性，例如依赖于单量子比特上的经典记忆机制（需要重复测量来估计放电概率）和使用经典模拟器上的传统反向传播进行训练。本文旨在解决这些挑战。

**Method:** 本文提出了一种随机量子脉冲（SQS）神经元模型。SQS神经元使用多量子比特量子电路实现具有内部量子记忆的脉冲单元，从而能够一次性实现事件驱动的概率脉冲生成。此外，SQS神经元网络（SQSNNs）可以通过硬件友好的局部学习规则进行训练，从而消除了对全局经典反向传播的需求。

**Result:** 所提出的SQSNN模型融合了神经形态计算的时间序列效率与量子计算的指数级大的内部状态空间，为模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络铺平了道路。

**Conclusion:** 本文提出了随机量子脉冲神经网络（SQSNN）模型，该模型结合了神经形态计算的效率和量子计算的强大能力，实现了模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络。

> **ai_Abstract:** 本文提出了一种随机量子脉冲（SQS）神经元模型及其网络（SQSNNs），旨在克服现有量子脉冲模型在经典记忆依赖和传统反向传播方面的局限性。SQS神经元利用多量子比特量子电路实现内部量子记忆，从而能够一次性进行事件驱动的概率脉冲生成。SQSNNs采用硬件友好的局部学习规则进行训练，无需全局经典反向传播。这种方法结合了神经形态计算的效率和量子计算的巨大状态空间，为开发模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络奠定了基础。

> **摘要翻译:** 神经形态计算和量子计算最近已成为推动人工智能发展的有前途的范式，各自提供互补的优势。基于脉冲神经元的神经形态系统通过稀疏、事件驱动的计算，在处理时间序列数据方面表现出色，仅在输入事件发生时才消耗能量。另一方面，量子计算利用叠加和纠缠来探索量子比特数量呈指数级增长的特征空间。结合这些范式的混合方法已开始显示出潜力，但现有的量子脉冲模型存在重要局限性。值得注意的是，先前的量子脉冲神经元实现依赖于单量子比特上的经典记忆机制，需要重复测量来估计放电概率，并且它们使用经典模拟器上的传统反向传播进行训练。本文提出了一种随机量子脉冲（SQS）神经元模型来解决这些挑战。SQS神经元使用多量子比特量子电路实现具有内部量子记忆的脉冲单元，从而能够一次性实现事件驱动的概率脉冲生成。此外，我们概述了如何通过硬件友好的局部学习规则训练SQS神经元网络——称为SQS神经网络（SQSNNs），从而消除了对全局经典反向传播的需求。所提出的SQSNN模型融合了神经形态计算的时间序列效率与量子计算的指数级大的内部状态空间，为模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络铺平了道路。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [113] [Assessing an evolutionary search engine for small language models, prompts, and evaluation metrics](https://arxiv.org/abs/2506.21512)
> *评估一种用于小型语言模型、提示和评估指标的进化搜索引擎*

*Cláudio Lúcio do Val Lopes, Lucca Machado* | **Category: cs.NE**

**Keywords:** 进化搜索, 小型语言模型, 提示优化, NSGA-II, 令牌效率

**Comment:** 14 pages, 1 figure, 1 table

> **TL;DR:** 本文介绍并评估了一个双目标进化搜索引擎，用于同时优化小型语言模型（SLMs）和提示，以提高任务准确性和令牌效率，并成功识别出高性能的模型-提示组合。

**AI_Comments:** 该论文的创新之处在于引入了双目标进化搜索引擎（使用NSGA-II算法和提示语法）来自动化优化小型语言模型和提示，以同时兼顾性能和效率。这为AI系统部署提供了一个更系统和高效的方法，避免了耗时的人工调优。其重要性在于为发现有效的人机交互模式提供了一个基础框架，并为决策者提供了实用的帕累托前沿，以适应不同的约束。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型和指令提示的同步优化在部署高效和有效的AI系统时面临重大挑战，尤其是在平衡性能与计算成本（如令牌使用）时。

**Method:** 本文引入并评估了一个双目标进化搜索引擎，专门针对小型语言模型（SLMs）。该研究采用NSGA-II算法和提示语法，在推理任务中同时优化任务准确性和令牌效率。

**Result:** 结果成功识别出多样化的高性能模型-提示组合，并定量揭示了两个目标之间的关键权衡。研究还强调了特定SLM与提示结构（例如指令、上下文、思维链）之间的任务特异性亲和力。生成的实用帕累托前沿为决策者提供了可根据其特定约束调整的优化解决方案组合。

**Conclusion:** 这种自动化方法超越了传统的手动调优，为发现有效的人机交互模式提供了一个基础框架。

> **ai_Abstract:** 本研究提出并评估了一种双目标进化搜索引擎，旨在解决小型语言模型（SLMs）和提示的同步优化难题，以平衡任务准确性和令牌效率。通过NSGA-II算法和提示语法，该引擎成功发现了多样化的高性能模型-提示组合，并揭示了性能与计算成本之间的权衡。该方法为决策者提供了优化的解决方案组合，并为自动化发现有效的人机交互模式奠定了基础，超越了传统的手动调优。

> **摘要翻译:** 语言模型和指令提示的同步优化在部署高效和有效的AI系统时面临重大挑战，尤其是在平衡性能与计算成本（如令牌使用）时。本文介绍并评估了一个双目标进化搜索引擎，旨在驾驭这一复杂空间，特别关注小型语言模型（SLMs）。我们采用NSGA-II算法和提示语法，在一些推理任务中同时优化任务准确性和令牌效率。我们的结果成功识别出多样化的高性能模型-提示组合，定量揭示了两个目标之间的关键权衡。这项研究强调了特定SLM与提示结构（例如指令、上下文、思维链）之间的任务特异性亲和力。生成的实用帕累度前沿为决策者提供了可根据其特定约束调整的优化解决方案组合。这种自动化方法超越了传统的手动调优，为发现有效的人机交互模式提供了一个基础框架。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [44] [Inverse initial data reconstruction for Maxwell's equations via time-dimensional reduction method](https://arxiv.org/abs/2506.20777)
> *麦克斯韦方程组初始数据逆向重构的时间维度约简方法*

*Thuy T. Le, Cong B. Van, Trong D. Dang, Loc H. Nguyen* | **Category: math.NA, cs.NA**

**Keywords:** 麦克斯韦方程组, 逆问题, 时间维度约简, 准可逆性, 初始电场重构

**Comment:** 

> **TL;DR:** 通过时间维度约简和准可逆性方法，从边界测量中重构非均匀各向异性介质中麦克斯韦方程组的初始电场，即使有噪声数据也表现出鲁棒性。

**AI_Comments:** 该论文的创新点在于引入了时间维度约简方法（基于Legendre多项式-指数基）将时空逆问题转化为一系列空间系统，并结合准可逆性方法有效处理了欠定设置下的非唯一性问题。其重要性体现在解决了在实际约束下（无需初始磁场和电荷密度）重构麦克斯韦方程组初始电场的难题，且在有噪声数据下仍表现出高准确性和鲁棒性，具有重要的实际应用价值。抽象中未提及具体限制，但可能需要进一步探讨基函数选择、计算成本或特定介质条件对方法性能的影响。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决非均匀和各向异性介质中时变麦克斯韦系统的一个逆问题，即利用有限时间间隔内电场及其法向导数的边界测量来恢复有界域内的初始电场。此方法还通过欠定公式避免了对初始磁场数据和电荷密度信息的需要，以适应实际约束。

**Method:** 1. 采用麦克斯韦方程组的欠定公式。2. 开发了一种时间维度约简方法，将电场投影到有限维勒让德多项式-指数基上，将原始时空问题转化为一系列空间系统。3. 使用准可逆性方法在最小范数框架内进行重构。4. 证明了收敛定理，确保准可逆性解的近似性。

**Result:** 1. 数值实验验证了该方法在完全三维设置下的性能。2. 即使数据中存在10%的噪声，重构的初始电场仍然准确。3. 证明了当噪声和正则化参数消失时，准可逆性解逼近真实解。

**Conclusion:** 提出的时间维度约简方法结合准可逆性方法，能够鲁棒且准确地从边界测量中重构非均匀各向异性介质中麦克斯韦方程组的初始电场，即使在有噪声数据的情况下也适用，对实际逆电磁问题具有重要意义。

> **ai_Abstract:** 本文研究了非均匀各向异性介质中麦克斯韦方程组的初始电场逆问题。通过采用欠定公式并引入时间维度约简方法，将原始时空问题转化为一系列空间系统。利用准可逆性方法在最小范数框架下进行重构，并证明了其收敛性。数值实验表明，该方法在存在噪声的情况下也能准确重构初始电场，具有良好的鲁棒性和实际应用潜力。

> **摘要翻译:** 我们研究了非均匀各向异性介质中时变麦克斯韦系统的一个逆问题。目标是利用有限时间间隔内电场及其法向导数的边界测量，恢复有界域 $\Omega \subset \mathbb{R}^3$ 中的初始电场 $\mathbf{E}_0$。根据实际约束，我们采用了麦克斯韦方程组的欠定公式，避免了对初始磁场数据和电荷密度信息的需要。为了解决这个逆问题，我们开发了一种时间维度约简方法，通过将电场投影到时间上的有限维勒让德多项式-指数基上。这使得原始时空问题被重构为一系列关于投影系数的空间系统。重构是使用准可逆性方法在最小范数框架内进行的，这适应了欠定设置固有的非唯一性。我们证明了一个收敛定理，确保当噪声和正则化参数消失时，准可逆性解逼近真实解。在完全三维环境中的数值实验验证了该方法的性能。即使数据中存在10%的噪声，重构的初始电场仍然准确，这表明所提出方法对实际逆电磁问题的鲁棒性和适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [68] [Boundary integral equation analysis for spheroidal suspensions](https://arxiv.org/abs/2506.20809)
> *扁球体悬浮液的边界积分方程分析*

*Leo Crowder, Tianyue Li, Eduardo Corona, Shravan Veerapaneni* | **Category: math.NA, cs.NA, physics.comp-ph, physics.flu-dyn**

**Keywords:** 边界积分方程, 扁球体, 快速多极方法, 拉普拉斯方程, 斯托克斯流

**Comment:** Submitted to Journal of Computational Physics, June 2025

> **TL;DR:** 该论文提出了一种快速、谱精确的边界积分方法，用于分析扁球体悬浮液，适用于拉普拉斯和斯托克斯问题，并能处理数百个粒子。

**AI_Comments:** 该论文的创新之处在于结合了扁球谐函数展开和实体谐函数来精确处理近场相互作用，并整合了快速多极方法来加速远场计算。其重要性在于为涉及非球形粒子的复杂流体动力学问题提供了一个高效且精确的工具。论文中提到在单个处理器上能处理“数百个粒子”，这可能暗示在处理更大规模系统时仍需考虑可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种快速、谱精确的方法，用于评估长椭球体和扁椭球体悬浮液上的边界积分算子（BIOs），并将其应用于颗粒悬浮流问题。

**Method:** 该方法首先推导了拉普拉斯方程的标准层势算子公式，该算子应用于适当的扁球谐函数基底中的积分密度展开。然后，这些公式引出实体谐函数中的解析表达式，用于谱精确评估近场粒子相互作用。远场相互作用则通过标准求积方案评估，并使用快速多极方法加速。此外，通过连接斯托克斯和拉普拉斯势的标准公式，该方案可应用于颗粒悬浮流问题。

**Result:** 通过数值测试，验证了该BIO评估框架在密集、多分散扁球体悬浮液中的准确性和效率。该方案可以轻松应用于涉及颗粒悬浮流的问题。对于拉普拉斯和斯托克斯问题，该方法允许在单个处理器上评估多达数百个粒子的悬浮液的BIOs。

**Conclusion:** 该论文开发的快速、谱精确的边界积分方法能有效分析拉普拉斯和斯托克斯问题中的扁球体悬浮液，并能高效处理数百个粒子。

> **ai_Abstract:** 该论文介绍了一种快速、谱精确的边界积分方法，用于分析长椭球体和扁椭球体悬浮液。它基于扁球谐函数和实体谐函数推导了近场相互作用的解析表达式，并结合快速多极方法处理远场相互作用。该方法在密集、多分散悬浮液中表现出高精度和效率，适用于拉普拉斯和斯托克斯问题，并能在单个处理器上处理数百个粒子。

> **摘要翻译:** 在这项工作中，我们提供了一种快速、谱精确的方法，用于评估长椭球体和扁椭球体悬浮液上的边界积分算子（BIOs）。我们首先推导了适用于拉普拉斯方程的标准层势算子的公式，这些算子应用于适当的扁球谐函数基底中的积分密度展开。然后，这些公式引出了实体谐函数中的解析表达式，从而能够对近场粒子相互作用进行谱精确评估。最后，使用标准求积方案评估平滑的远场相互作用；这些相互作用随后通过快速多极方法进行加速。
通过大量的数值测试案例，我们验证了我们BIO评估框架在密集、多分散扁球体悬浮液中的准确性和效率。通过使用连接斯托克斯和拉普拉斯势的标准公式，我们表明我们的方案可以很容易地应用于涉及颗粒悬浮流的问题。对于拉普拉斯和斯托克斯问题，我们的方法允许我们在单个处理器上评估多达数百个粒子的悬浮液的BIOs。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [92] [Multicontinuum Homogenization for Poroelasticity Model](https://arxiv.org/abs/2506.20890)
> *多连续介质均匀化孔隙弹性模型*

*Dmitry Ammosov, Mohammed Al-Kobaisi, Yalchin Efendiev* | **Category: math.NA, cs.CE, cs.NA, physics.comp-ph**

**Keywords:** 多连续介质, 孔隙弹性, 均匀化, 多孔介质, 高对比度

**Comment:** 

> **TL;DR:** 本文利用多连续介质均匀化方法，推导了多连续介质孔隙弹性模型，旨在解决高对比度多孔介质的计算挑战，并展示了其高精度。

**AI_Comments:** 该论文解决了高对比度多孔介质建模中的一个重要挑战，这对于许多工程和科学应用至关重要。利用多连续介质均匀化方法是克服标准方法局限性的一种创新途径，为复杂系统提供了更准确的描述。严格的推导和数值验证增强了所提出模型的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 孔隙弹性模型在描述多孔介质中的耦合流动和力学过程方面广泛应用，但在许多应用中，多孔介质的性质具有高对比度，导致严重的计算挑战。标准均匀化方法因缺乏宏观参数而无法提供准确解决方案。多连续介质方法通过定义多个平均状态（即连续介质）来解决这一问题。

**Method:** 本研究通过应用最近开发的多连续介质均匀化方法，推导了广义多连续介质孔隙弹性模型。方法包括在过采样区域中建立耦合约束单元问题以考虑不同的均匀化效应，获得细尺度场的多连续介质展开，并假设宏观变量平滑性来推导多连续介质模型。文中还提供了方程的最通用版本和简化版本。

**Result:** 数值结果表明，针对不同的非均匀介质情况，所提出的多连续介质模型具有高精度。

**Conclusion:** 通过严格的均匀化方法推导的多连续介质孔隙弹性模型，能够准确描述高对比度多孔介质中的耦合流动和力学过程。

> **ai_Abstract:** 本文利用严格的多连续介质均匀化方法，开发了广义多连续介质孔隙弹性模型。该模型旨在解决高对比度多孔介质所带来的计算难题，弥补了标准均匀化方法的不足。研究方法包括构建耦合约束单元问题并基于细尺度场展开推导多连续介质方程。数值实验验证了所提出模型在各种非均匀介质中的高精度表现。

> **摘要翻译:** 在本文中，我们使用多连续介质均匀化方法推导了多连续介质孔隙弹性模型。孔隙弹性模型广泛应用于科学和工程的许多领域，以描述多孔介质中的耦合流动和力学过程。然而，在许多应用中，孔隙弹性介质的性质具有高对比度，这带来了严重的计算挑战。众所周知，由于缺乏宏观参数，标准均匀化方法通常无法给出准确的解决方案。多连续介质方法通过定义几个称为连续介质的平均状态，允许我们考虑这种情况。在孔隙弹性领域，源自多孔介质理论的多网络模型是这些方法的代表。在这项工作中，我们通过推导广义多连续介质孔隙弹性模型来扩展以前的发现。我们应用最近开发的多连续介质均匀化方法，并提供了多连续介质方程的严格推导。为此，我们在过采样区域中制定了耦合约束单元问题，以考虑不同的均匀化效应。然后，我们获得了细尺度场的多连续介质展开，并假设宏观变量的平滑性推导了多连续介质模型。我们根据数值实验给出了方程的最通用版本和简化版本。对不同的非均匀介质情况进行了数值结果，并证明了我们提出的多连续介质模型具有高精度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [115] [Two-dimensional greedy randomized Kaczmarz methods for solving large-scale linear systems](https://arxiv.org/abs/2506.20940)
> *求解大规模线性系统的二维贪婪随机Kaczmarz方法*

*Tao Li, Meng-Long Xiao, Xin-Fang Zhang* | **Category: math.NA, cs.NA, 65F10, 65F20, 94A08**

**Keywords:** 二维Kaczmarz方法, 贪婪随机, 半随机, 大规模线性系统, 收敛性

**Comment:** arXiv admin note: text overlap with arXiv:2506.16106

> **TL;DR:** 本文提出并分析了多种二维Kaczmarz方法，包括贪婪随机和半随机版本，用于高效求解大规模线性系统，并证明了其收敛性及数值优越性。

**AI_Comments:** 本文的创新点在于将Kaczmarz方法扩展到二维选择策略，并结合了贪婪和半随机的思想，这对于加速大规模线性系统的求解具有重要意义。特别地，其对大数据问题的适用性提升了方法的实用价值。理论收敛性证明和数值优越性验证使得该研究成果具有坚实的理论基础和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了更有效地求解大规模线性系统，并改进现有Kaczmarz方法的性能，特别是针对大数据问题，本文提出了新的二维随机Kaczmarz方法及其改进版本。

**Method:** 本文提出了多种二维Kaczmarz方法：1. 二维随机Kaczmarz方法及其基于简单随机采样的改进版本，通过选择与交叉积常数平方成比例的概率选择两行。2. 二维贪婪随机Kaczmarz方法，通过在每次迭代中抓住残差向量的两个较大条目进行贪婪选择。3. 二维半随机Kaczmarz方法及其基于简单随机采样的修改版本，灵感来源于半随机Kaczmarz方法和切比雪夫大数定律。

**Result:** 理论上，所提出的方法被证明收敛到一致线性系统的唯一最小范数解。数值结果表明，在计算时间方面，所提出的方法优于一些现有方法，特别适用于实际应用。

**Conclusion:** 本文提出的二维贪婪随机Kaczmarz方法及其变体，通过理论分析和数值实验，证明了其在求解大规模线性系统方面的收敛性和计算效率优势，尤其适用于大数据问题。

> **ai_Abstract:** 本文提出并分析了一系列用于求解大规模线性系统的新型二维Kaczmarz方法。这些方法包括二维随机Kaczmarz、二维贪婪随机Kaczmarz和二维半随机Kaczmarz及其变体，它们通过选择两行或利用贪婪策略来加速收敛。理论上，论文证明了这些方法收敛到最小范数解。数值实验结果表明，与现有方法相比，这些新方法在计算时间上具有显著优势，特别适用于大数据问题。

> **摘要翻译:** 在本文中，我们考虑了一种新颖的二维随机Kaczmarz方法及其使用简单随机采样的改进版本，该方法以与其交叉积类常数平方成比例的概率选择两个活跃行，用于求解大规模线性系统。从每次迭代中抓住残差向量的两个较大条目的贪婪选择策略出发，我们随后设计了一种二维贪婪随机Kaczmarz方法。为了进一步改进上述方法，受半随机Kaczmarz方法和切比雪夫大数定律的启发，我们提出了一种二维半随机Kaczmarz方法及其使用简单随机采样的修改版本，这对于大数据问题尤其有利。理论上，我们证明了所提出的方法收敛到一致线性系统的唯一最小范数解。在一些实际应用上的数值结果表明，所提出的方法在计算时间方面优于一些现有方法。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [135] [An energy-stable parametric finite element method for the Willmore flow in three dimensions](https://arxiv.org/abs/2506.21025)
> *三维Willmore流的一种能量稳定参数有限元方法*

*Weizhu Bao, Yifei Li, Dongmin Wang* | **Category: math.NA, cs.NA, 65M60, 65M12, 35K55, 53C44**

**Keywords:** Willmore流, 参数有限元方法, 能量稳定, 几何梯度流, 网格质量

**Comment:** 

> **TL;DR:** 本文开发了一种新的能量稳定的参数有限元方法（ES-PFEM），用于三维Willmore流和曲率相关几何梯度流，通过引入新的几何恒等式和切向速度控制，实现了能量耗散并保持了良好的网格质量。

**AI_Comments:** 这项工作通过引入新颖的几何恒等式和切向速度控制机制，显著提升了参数有限元方法在处理Willmore流和曲率相关几何梯度流时的能量稳定性和网格质量，特别是在三维空间中。首次将PFEM应用于高斯曲率流，显示了其创新性。该方法对于模拟复杂曲面演化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 针对三维Willmore流和曲率相关几何梯度流，开发一种能量稳定的参数有限元方法，以保持能量耗散特性并提高网格质量，同时提供对ES-PFEM设计和网格质量改进的新理解。

**Method:** 该方法通过使用两个新的几何恒等式（法向速度场的重构变分形式和将平均曲率时间演化纳入控制方程）来推导新的变分公式。基于此，开发了一个隐式全离散参数有限元方案，确保能量耗散。此外，还首次开发了用于高斯曲率流的PFEM，并应用了切向速度控制以改善网格质量和增强鲁棒性。

**Result:** 所提出的ES-PFEM方法在全离散层面保持了能量耗散特性。在Willmore流下的曲面演化过程中，该方法能够维持良好的网格质量。数值实验广泛证实了该方法在能量耗散和网格质量方面的有效性，并且首次实现了高斯曲率流的PFEM。

**Conclusion:** 本文提出的能量稳定参数有限元方法（ES-PFEM）能够有效地模拟三维Willmore流和曲率相关几何梯度流，通过新颖的几何恒等式和切向速度控制，确保了能量耗散特性并保持了良好的网格质量，为相关领域提供了新的设计思路和理解。

> **ai_Abstract:** 本文提出了一种用于三维Willmore流和曲率相关几何梯度流的新型能量稳定参数有限元方法（ES-PFEM）。该方法通过引入两个新的几何恒等式，推导了新的变分公式，并开发了保持能量耗散特性的隐式全离散方案。研究还提供了ES-PFEM设计和PFEM网格质量改进的见解，首次实现了高斯曲率流的PFEM，并利用切向速度控制提高了网格质量和方法鲁棒性。数值实验验证了其在能量耗散和网格质量保持方面的有效性。

> **摘要翻译:** 这项工作开发了一种新颖的能量稳定参数有限元方法（ES-PFEM），用于三维曲面上的Willmore流和曲率相关几何梯度流。实现能量稳定性的关键在于使用了两个新颖的几何恒等式：(i) 法向速度场的重新表述变分形式，以及 (ii) 将平均曲率的时间演化纳入控制方程。这些恒等式使得能够推导出一个新的变分公式。通过使用参数有限元方法，随后开发了一个隐式全离散方案，该方案在全离散层面上保持了能量耗散特性。基于ES-PFEM，本文提供了关于通用曲率相关几何梯度流的ES-PFEM设计以及PFEM中网格质量改进的新理解的全面见解。特别是，我们首次开发了用于曲面高斯曲率流的PFEM。此外，应用了切向速度控制方法来改善网格质量并增强所提出数值方法的鲁棒性。大量的数值实验证实，所提出的方法在Willmore流下的曲面演化过程中保持了能量耗散特性并维持了良好的网格质量。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [152] [Entropy-stable in- and outflow boundary conditions for the compressible Navier-Stokes equations](https://arxiv.org/abs/2506.21065)
> *可压缩Navier-Stokes方程的熵稳定进出口边界条件*

*Magnus Svärd, Anita Gjesteland* | **Category: math.NA, cs.NA**

**Keywords:** 熵稳定, 边界条件, Navier-Stokes方程, 有限体积, 先验估计

**Comment:** 

> **TL;DR:** 本文提出并证明了可压缩Navier-Stokes方程的熵稳定进出口边界条件，并展示了其与熵稳定有限体积方案的结合应用及稳健性。

**AI_Comments:** 本文的核心创新在于提出了可压缩Navier-Stokes方程的熵稳定进出口边界条件，并从理论上证明了其能够保证物理量的先验估计。其重要性在于为计算流体力学中的边界处理提供了一种理论基础更强、稳定性更好的方法，尤其对于需要精确能量守恒和熵耗散控制的复杂流动问题具有重要意义。数值验证进一步证实了其在实际应用中的可行性和稳健性。

<details>
  <summary>Details</summary>

**Motivation:** 开发并证明可压缩Navier-Stokes方程的进出口边界条件，使其能够实现熵、质量和总能量的先验估计，并确保其稳定性。

**Method:** 提出进出口边界条件，并证明其允许熵、质量和总能量的先验估计。展示了如何将这些边界条件与熵稳定有限体积方案结合使用，并指出该方法也适用于其他类型的熵稳定方案。最后，通过有限体积方案进行数值计算以验证其稳健性。

**Result:** 所提出的边界条件允许对熵、质量和总能量进行先验估计。数值计算结果证明了这些边界条件的稳健性。

**Conclusion:** 所提出的进出口边界条件对于可压缩Navier-Stokes方程是熵稳定的，并且能够保证熵、质量和总能量的先验估计，同时在数值计算中表现出良好的稳健性。

> **ai_Abstract:** 本文针对可压缩Navier-Stokes方程，提出了一套熵稳定的进出口边界条件。研究证明这些条件能够实现熵、质量和总能量的先验估计。此外，文中详细阐述了如何将这些边界条件与熵稳定有限体积方案相结合，并指出其同样适用于其他熵稳定数值方法。通过数值模拟，验证了所提边界条件的稳健性。

> **摘要翻译:** 我们提出了可压缩Navier-Stokes方程的进出口边界条件，并证明它们允许对熵、质量和总能量进行先验估计。此外，我们展示了如何将这些边界条件与熵稳定有限体积方案结合起来近似处理。该方法也适用于其他类型的熵稳定方案。最后，我们使用有限体积方案进行了一些数值计算，并证明了它们的稳健性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [172] [Inverse source problem with a posteriori interior measurements for space-time fractional diffusion equations](https://arxiv.org/abs/2506.21070)
> *具有后验内部测量的时空分数阶扩散方程逆源问题*

*Kai Yu, Zhiyuan Li, Yikan Liu* | **Category: math.NA, cs.NA, 35R30, 35R11**

**Keywords:** 逆源问题, 分数阶扩散方程, Tikhonov正则化, Levenberg-Marquardt方法, 唯一性

**Comment:** 14 pages, 2 figures, 2 tables

> **TL;DR:** 本文研究了时空分数阶扩散方程的逆源问题，通过分数阶导数的记忆效应和唯一延拓性质证明了唯一性，并利用Tikhonov正则化和Levenberg-Marquardt方法进行了数值重建，数值示例验证了算法的有效性和准确性。

**AI_Comments:** 该研究在分数阶扩散方程的逆源问题上具有重要意义，其创新性在于结合了分数阶导数的特性、优化方法和正则化技术来解决这一挑战性问题。所提出的算法在数值上表现出良好的效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 本文研究了时空分数阶扩散方程的逆源问题，旨在从后验内部测量中识别未知源。

**Method:** 研究通过分数阶导数的记忆效应和唯一延拓性质建立了唯一性结果。数值重建方面，将逆问题重新表述为带有Tikhonov正则化的优化问题，并使用Levenberg-Marquardt方法识别未知源。

**Result:** 建立了逆源问题的唯一性结果。通过数值示例验证了所提出算法的效率和准确性。

**Conclusion:** 所提出的算法能够有效地、准确地从噪声测量中识别时空分数阶扩散方程的未知源。

> **ai_Abstract:** 本文探讨了时空分数阶扩散方程的逆源问题，利用分数阶导数的记忆效应和唯一延拓性质证明了唯一性。在数值重建方面，将该问题转化为一个Tikhonov正则化的优化问题，并采用Levenberg-Marquardt方法从噪声测量中识别未知源。数值实验结果证实了该算法的有效性和准确性。

> **摘要翻译:** 本文研究了基于后验内部测量的时空分数阶扩散方程的逆源问题。通过分数阶导数的记忆效应和唯一延拓性质建立了唯一性结果。对于数值重建，将逆问题重新表述为带有Tikhonov正则化的优化问题。我们使用Levenberg-Marquardt方法从噪声测量中识别未知源。最后，我们给出了一些数值示例，以说明所提出算法的效率和准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [187] [Robust space-time multiscale upscaling via multicontinuum homogenization for evolving perforated media](https://arxiv.org/abs/2506.21104)
> *演化穿孔介质中基于多连续体均匀化的鲁棒时空多尺度粗化*

*Wei Xie, Viet Ha Hoang, Yin Yang, Yunqing Huang* | **Category: math.NA, cs.NA**

**Keywords:** 多尺度粗化, 多连续体均匀化, 穿孔介质, 时空, 动态域

**Comment:** 

> **TL;DR:** 本文提出了一种基于多连续体均匀化的鲁棒多尺度建模框架，用于在收缩域中推导宏观有效方程，以解决动态细尺度几何形状带来的计算挑战。

**AI_Comments:** 该论文的创新点在于将多连续体均匀化方法应用于时间演化的穿孔介质，并考虑了域的动态演化和时间导数，这对于模拟复杂工程和地球科学问题具有重要意义。其提出的框架具有鲁棒性和泛化性，为处理动态细尺度几何问题提供了一个有效的计算工具。

<details>
  <summary>Details</summary>

**Motivation:** 由于多孔介质中反应传输、颗粒沉积和结构退化等应用中，时间演化的穿孔域具有动态的细尺度几何形状，准确捕捉其宏观行为存在显著的计算挑战。

**Method:** 本文开发了一种基于多连续体均匀化的鲁棒且可泛化的多尺度建模框架，用于在收缩域中推导有效的宏观方程。该方法根据物理特性（例如通道宽度）区分多个连续体，并通过在代表性体积单元上制定的时空局部单元问题将它们耦合。这些局部问题包含了时间导数和域演化，确保与底层细尺度动力学的一致性。

**Result:** 由此产生的粗化系统得到了可计算的宏观系数，并适用于大规模模拟。数值实验验证了该方法的准确性、效率以及在复杂瞬态工程问题中的潜在适用性。

**Conclusion:** 该方法成功地为时间演化的穿孔介质提供了鲁棒且高效的多尺度建模框架，能够准确捕捉宏观行为并适用于大规模模拟。

> **ai_Abstract:** 本文提出了一种基于多连续体均匀化的鲁棒时空多尺度建模框架，旨在解决时间演化穿孔介质中动态细尺度几何带来的计算挑战。该方法通过区分不同物理特性的连续体，并利用包含时间导数和域演化的时空局部单元问题进行耦合，从而在收缩域中推导出宏观有效方程。该框架产生的粗化系统具有可计算的宏观系数，适用于大规模模拟，并通过数值实验验证了其准确性、效率和广泛适用性。

> **摘要翻译:** 时间演化的穿孔域出现在许多工程和地球科学应用中，包括多孔介质中的反应传输、颗粒沉积和结构退化。由于动态的细尺度几何形状，准确捕捉此类系统的宏观行为带来了显著的计算挑战。在本文中，我们开发了一种基于多连续体均匀化的鲁棒且可泛化的多尺度建模框架，以在收缩域中推导有效的宏观方程。该方法根据物理特性（例如通道宽度）区分多个连续体，并通过在代表性体积单元上制定的时空局部单元问题将它们耦合。这些局部问题包含了时间导数和域演化，确保与底层细尺度动力学的一致性。由此产生的粗化系统得到了可计算的宏观系数，并适用于大规模模拟。本文展示了几个数值实验，以验证该方法的准确性、效率以及在复杂瞬态工程问题中的潜在适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [201] [Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation](https://arxiv.org/abs/2506.21206)
> *粒子方法中鲁棒高效的预处理技术，包括动态边界生成*

*Niklas S. Neher, Erik Faulhaber, Sven Berger, Christian Weißenfels, Gregor J. Gassner, Michael Schlottke-Lakemper* | **Category: math.NA, cs.NA**

**Keywords:** 粒子方法, 预处理, 有符号距离场, SPH, 粒子分布

**Comment:** 

> **TL;DR:** 本文介绍了一种针对2D和3D复杂几何体的鲁棒且高效的粒子预处理技术，旨在为SPH及其他粒子方法生成高质量的粒子分布。该方法能处理不完美的输入几何体，并确保粒子分布随分辨率提高而趋近精确几何体，从而支持稳定准确的粒子模拟。

**AI_Comments:** 本文的创新之处在于其全面的预处理流程，有效解决了粒子模拟中多个关键挑战，尤其体现在对不完善几何体的鲁棒性和无网格特性上。其重要性在于能够为基于粒子的模拟（特别是复杂形状）生成更稳定、更准确的初始粒子配置，极大地提升了模拟的质量和适用性。

<details>
  <summary>Details</summary>

**Motivation:** 为基于粒子的模拟（特别是复杂几何体）获取高质量的粒子分布以确保稳定性和准确性，带来了显著的挑战。

**Method:** 本文提出了一种预处理技术，其流程包括：首先，通过基于面的邻域搜索生成几何体表面附近的分辨率自适应点云；其次，该点云用于构建有符号距离场，以便在表面区域进行高效局部计算；接着，应用分层缠绕数方法进行快速准确的内外分割，以创建初始粒子配置；最后，使用受SPH启发的方案松弛粒子位置并填充边界粒子，确保完全核支持并促进各向同性分布，同时保留几何界面。该方法利用粒子方法的无网格特性，不需要连接信息，对不完善的输入几何体具有鲁棒性，并且内存效率高。

**Result:** 该技术能够生成确保完全核支持和各向同性分布的粒子配置，同时保留几何界面。它对不完善的输入几何体具有鲁棒性，并且内存效率高。实验表明，随着分辨率的提高，所得粒子分布会收敛到精确的几何体。

**Conclusion:** 本文提出了一种鲁棒且高效的预处理技术，能够为基于粒子的模拟生成高质量的粒子分布，克服了复杂几何体和不完善输入带来的挑战，从而实现了稳定和准确的模拟。

> **ai_Abstract:** 本文提出了一种鲁棒高效的预处理流程，用于为2D和3D几何体生成高质量的粒子分布，并针对SPH及其他粒子方法进行了优化。该方法通过生成分辨率自适应点云、构建有符号距离场、利用分层缠绕数方法进行内外分割，以及采用SPH启发式方案松弛和填充粒子位置。它不依赖网格连接信息，对不完善的输入几何体具有鲁棒性，且内存效率高。实验证明，随着分辨率的提高，生成的粒子分布能够收敛到精确的几何体，从而支持稳定准确的粒子模拟。

> **摘要翻译:** 为基于粒子的模拟（尤其是复杂几何体）获取高质量的粒子分布以确保稳定性和准确性，带来了显著的挑战。我们引入了一种针对2D和3D几何体的预处理技术，该技术针对光滑粒子流体动力学（SPH）及其他基于粒子的方法进行了优化。我们的流程始于在几何体表面附近通过基于面的邻域搜索生成分辨率自适应点云。该点云构成了有符号距离场的基础，从而能够在表面区域进行高效的局部计算。为了创建初始粒子配置，我们应用了分层缠绕数方法进行快速准确的内外分割。然后，使用受SPH启发的方案松弛粒子位置，该方案也用于填充边界粒子。这确保了完全核支持并促进了各向同性分布，同时保留了几何界面。通过利用基于粒子方法的无网格特性，我们的方法不需要连接信息，因此易于集成到现有的基于粒子框架中。它对不完善的输入几何体具有鲁棒性，并且在不影响性能的情况下具有内存效率。此外，我们的实验表明，随着分辨率的不断提高，所得粒子分布会收敛到精确的几何体。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [215] [On the coordinate system-dependence of the accuracy of symplectic numerical methods](https://arxiv.org/abs/2506.21241)
> *辛几何数值方法精度对坐标系的依赖性*

*Donát M. Takács, Tamás Fülöp* | **Category: math.NA, cs.NA, physics.class-ph, physics.comp-ph, 65P10, 70H15, 34A05**

**Keywords:** 辛几何方法, 坐标变换, 精度, 哈密顿系统, 修正哈密顿量

**Comment:** 24 pages, 7 figures

> **TL;DR:** 辛几何数值方法的精度受到坐标系选择的影响，本文系统探讨了其原因和影响，并提出了提高精度的方法。

**AI_Comments:** 这篇论文的创新点在于系统地揭示了辛几何数值方法精度对坐标系选择的实际依赖性，填补了现有研究的空白。它不仅从理论上推导了修正哈密顿量的非不变性和第一积分的非守恒性，还提出了通过“序补偿”坐标变换来提高精度的方法，具有重要的理论和实际意义，尤其对于需要高精度哈密顿系统模拟的领域。

<details>
  <summary>Details</summary>

**Motivation:** 辛几何方法在哈密顿系统模拟中广泛应用，但坐标系选择对其精度影响的实际方面研究不足，尽管其计算后果显著。本文旨在填补这一空白。

**Method:** 本文系统地概述了坐标变换如何影响辛几何方法的模拟结果。具体方法包括推导辛几何方法修正哈密顿量在坐标变换下的非不变性，以及给出辛欧拉方法对应循环坐标第一积分不守恒的充分条件。文章还考虑了寻找能提高数值方法精度阶数的序补偿坐标变换，并提供了各种数值示例。

**Result:** 推导了辛几何方法修正哈密顿量在坐标变换下的非不变性，并给出了辛欧拉方法对应循环坐标第一积分不守恒的充分条件。探讨了序补偿坐标变换提高精度阶数的可能性。

**Conclusion:** 辛几何方法的精度确实依赖于坐标系的选择，这种依赖性体现在修正哈密顿量的非不变性和第一积分的非守恒上，同时存在通过特定坐标变换提高精度的方法。

> **ai_Abstract:** 本文探讨了辛几何数值方法精度对坐标系的依赖性。研究发现，辛几何方法的修正哈密顿量在坐标变换下不具有不变性，并给出了辛欧拉方法中循环坐标对应第一积分不守恒的条件。文章还探讨了通过特定坐标变换提高数值方法精度阶数（序补偿）的可能性，并通过数值示例进行了验证，旨在弥补现有研究中对坐标选择实际影响关注不足的空白。

> **摘要翻译:** 辛几何数值方法已成为各领域（包括天体力学、分子动力学和机器人学）中精确模拟哈密顿系统的广泛选择。尽管它们的特性在数学上已得到充分理解，但通常很少关注坐标选择如何影响数值结果精度的实际方面，尽管其后果在计算上可能非常显著。本文旨在通过系统地概述坐标变换如何影响使用辛几何方法进行的模拟结果来填补这一空白。我们推导了辛几何方法修正哈密顿量在坐标变换下的非不变性，以及辛欧拉方法对应循环坐标第一积分不守恒的充分条件。我们还考虑了寻找能够提高数值方法精度阶数的序补偿坐标变换的可能性。文中提供了各种数值示例。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [227] [Runge--Kutta generalized Convolution Quadrature for sectorial problems](https://arxiv.org/abs/2506.21242)
> *龙格-库塔广义卷积积分法求解扇形问题*

*Jing Guo, Maria Lopez-Fernandez* | **Category: math.NA, cs.NA, 65R20, 65L06, 65M15, 26A33, 35R11**

**Keywords:** 广义卷积积分, 龙格-库塔方法, 扇形问题, 收敛性, 时间网格

**Comment:** 35 pages, 26 figures

> **TL;DR:** 本文研究了基于龙格-库塔方法的广义卷积积分法（gCQ）在求解一类重要扇形问题中的应用，证明了其在特定条件下能达到与原始卷积积分法相同的收敛阶，并提出了处理数据奇异性的优化时间网格策略，同时强调了其快速高效的实现优势。

**AI_Comments:** 本文的创新点在于证明了广义卷积积分法（gCQ）在特定扇形问题中能够克服其在一般设置下收敛性次优的限制，达到与原始卷积积分法（CQ）相同的最优收敛阶。特别是在处理数据奇异性时，通过设计最优分级时间网格来提高收敛阶，解决了原始CQ的阶数降低问题，这对于实际应用具有重要意义。此外，该方法还具有快速和内存高效的实现优势。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于龙格-库塔方法的广义卷积积分法（gCQ）在稳定性与收敛性方面，与均匀步长的原始卷积积分法（CQ）相比次优，尤其在收敛阶和数据正则性要求上存在不足。本文旨在解决这一问题，使其在特定应用中达到与原始CQ相同的性能。

**Method:** 本文研究了基于龙格-库塔方法的广义卷积积分法（gCQ）来近似求解扇形问题。特别地，针对具有代数类型奇异性的数据，提出了选择最优分级时间网格的方法。

**Result:** 对于一类特殊的扇形问题，本文证明了在相同的数据正则性假设下，基于Runge--Kutta的gCQ方法在非常通用的时间网格上可以达到与原始CQ相同的收敛阶。此外，对于具有代数类型奇异性的数据，通过选择最优分级时间网格，可以实现最大阶收敛，克服了原始CQ在此类情况下的阶数降低问题。该方法还具有快速和内存高效的实现优势。

**Conclusion:** 本文证明了基于龙格-库塔的广义卷积积分法（gCQ）在解决特定扇形问题时，可以达到与原始卷积积分法相同的收敛性能，并且能够通过优化时间网格来处理数据奇异性，实现最大阶收敛，同时具有高效的实现优势。

> **ai_Abstract:** 本文研究了基于龙格-库塔方法的广义卷积积分法（gCQ）在解决重要扇形问题中的应用。该方法是Lubich原始卷积积分法（CQ）的变步长泛化。针对现有gCQ在收敛阶和数据正则性方面次优的问题，本文证明了在特定扇形问题中，gCQ在相同数据正则性假设和通用时间网格下，能达到与原始CQ相同的收敛阶。对于具有代数奇异性的数据，本文还展示了如何选择最优分级时间网格以实现最大阶收敛，克服了原始CQ的阶数降低问题。此外，本文强调了gCQ方法快速且内存高效的实现优势，并通过数值实验验证了理论结果。

> **摘要翻译:** 我们研究了基于龙格-库塔方法的广义卷积积分法（gCQ）在近似求解一类重要扇形问题中的应用。gCQ将Lubich的原始卷积积分法（CQ）推广到变步长。在过去十年中，依赖于某些龙格-库塔方法，高阶版本的gCQ已经得到发展。迄今为止，基于龙格-库塔的gCQ已在一个相当通用的设置中进行了研究，其中包括应用于波问题的边界积分公式。与已知用于均匀步长CQ的结果相比，这些新方法的可用稳定性和收敛性结果是次优的，无论是在收敛阶还是数据正则性要求方面。在这里，我们专注于一类特殊的扇形问题，并证明在这些重要应用中，在相同的数据正则性假设下，并且对于非常通用的时间网格，可以实现与原始CQ相同的收敛阶。在数据具有某种已知代数类型奇异性的特殊情况下，我们还展示了如何选择最优分级时间网格以实现最大阶收敛，克服了原始CQ在这些情况下的众所周知的阶数降低问题。gCQ方法的一个重要优势是它允许快速和内存高效的实现。我们描述了如何实现基于龙格-库塔的快速且无感知的gCQ，并通过几个数值实验说明了我们的理论结果。本文中实现示例的代码可在[13]中获取。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [240] [On Uniform Weighted Deep Polynomial approximation](https://arxiv.org/abs/2506.21306)
> *关于均匀加权深度多项式逼近*

*Kingsley Yeon, Steven B. Damelin* | **Category: math.NA, cs.AI, cs.LG, cs.NA, stat.ML**

**Keywords:** 深度多项式逼近, 加权逼近, 非光滑函数, 不对称函数, 指数收敛

**Comment:** 

> **TL;DR:** 本文引入并分析了一种针对具有不对称行为函数的加权深度多项式逼近器，即使在参数数量相同的情况下，也显示出优于标准方法的性能。

**AI_Comments:** 本文通过将深度多项式与单侧权重相结合，提出了一种创新方法，有效解决了传统多项式逼近在处理具有不对称行为和非光滑性函数时的局限性。在相同参数数量下获得卓越性能的数值证据突显了其效率和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 经典多项式逼近对于非光滑或奇异函数仅能实现代数收敛，而有理函数可实现根指数收敛。虽然近期工作表明复合多项式架构可以恢复指数收敛率，但本文旨在高效逼近具有不对称行为（一侧无界增长，另一侧衰减）和局部非光滑性的函数。

**Method:** 作者引入并分析了一类加权深度多项式逼近器。通过将可学习的深度多项式乘以单侧权重，以捕获局部非光滑性和全局增长。此外，提出了一种稳定的基于图的参数化策略进行优化。

**Result:** 数值结果表明，即使在所有方法使用相同数量参数的情况下，该框架也优于泰勒、切比雪夫和标准深度多项式逼近器。

**Conclusion:** 所提出的加权深度多项式逼近器对于具有不对称行为的函数是有效的，并且比现有方法表现出更好的性能。

> **ai_Abstract:** 本文旨在解决非光滑或奇异函数逼近中传统多项式逼近仅能提供代数收敛的局限性。在深度多项式架构最近取得指数收敛率进展的基础上，作者提出了一类新颖的加权深度多项式逼近器。这些逼近器通过将可学习的深度多项式与单侧权重相结合，能够有效捕获局部非光滑性和全局不对称增长。数值实验表明，即使在参数数量相同的情况下，该新框架也超越了泰勒、切比雪夫和标准深度多项式逼近器的性能。此外，还引入了一种稳定的基于图的参数化策略以实现实际优化。

> **摘要翻译:** 在有理逼近理论中，有一个经典结果表明，某些非光滑或奇异函数，例如 $|x|$ 和 $x^{1/p}$，可以使用具有根指数收敛的有理函数在自由度方面进行有效逼近 
cite{Sta, GN}。相比之下，根据杰克逊定理 
cite{Lub2}，多项式逼近仅允许代数收敛。最近的工作表明，复合多项式架构即使在没有平滑性时也能恢复指数逼近率 
cite{KY}。在这项工作中，我们引入并分析了一类加权深度多项式逼近器，专为具有不对称行为（在一侧无界增长，在另一侧衰减）的函数量身定制。通过将可学习的深度多项式乘以单侧权重，我们捕获了局部非光滑性和全局增长。我们通过数值证明，即使所有方法使用相同数量的参数，该框架也优于泰勒、切比雪夫和标准深度多项式逼近器。为了在实践中优化这些逼近器，我们提出了一种基于 
cite{Jar} 的稳定图基参数化策略。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [250] [A Sampling-Based Adaptive Rank Approach to the Wigner-Poisson System](https://arxiv.org/abs/2506.21314)
> *一种基于采样的自适应秩方法求解Wigner-Poisson系统*

*Andrew Christlieb, Sining Gong, Jing-Mei Qiu, Nanyi Zheng* | **Category: math.NA, cs.NA**

**Keywords:** Wigner-Poisson系统, 自适应秩, 暖稠密等离子体, 阻止本领, 量子动力学模型

**Comment:** 

> **TL;DR:** 本文开发了一种用于一维一速Wigner-Poisson系统的质量守恒、自适应秩求解器，该求解器具有$O(N)$的复杂度和高精度，能够有效模拟暖稠密等离子体中的量子效应，并为高维Wigner-Poisson模拟奠定基础。

**AI_Comments:** 该论文引入了一种创新性的自适应秩方法来求解极具挑战性的Wigner-Poisson系统，这对暖稠密物质物理学至关重要。其核心创新在于利用观测到的解的低秩结构，开发出一种$O(N)$复杂度的求解器，显著提高了非局部量子动力学模型的计算效率。对结构保持性质的严格证明以及与全秩模拟在视觉上的无差别性，凸显了其鲁棒性和准确性，是迈向实用高维量子模拟的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个用于一维一速Wigner-Poisson系统的质量守恒、自适应秩求解器，其动机是应用于国家点火装置（NIF）中α粒子阻止本领的研究。在该体系下，电子处于暖稠密状态，需要考虑量子不确定性效应。此外，模拟中观察到解在特定普朗克常数下表现出低秩结构，这进一步促使了自适应秩求解器的开发。

**Method:** 该方法基于二阶Strang分裂法，首先设计了一个具有结构保持傅里叶更新的全秩求解器，以确保中间解的实值性。随后，针对观察到的低秩结构，开发了一个自适应秩求解器，该求解器结合了用于对流的半拉格朗日自适应秩（SLAR）方案和用于Wigner积分项的自适应秩、结构保持傅里叶更新。论文还提供了结构保持性质的严格证明。

**Result:** 所开发的全秩求解器通过确保中间解的实值性改进了现有方法。模拟结果表明，对于中等到高无量纲普朗克常数（$H 	ext{≥} 0.1$），解呈现出低秩结构。自适应秩求解器在存储和计算时间上均实现了$O(N)$的复杂度，同时保持了质量守恒和动量精度达到截断误差。自适应秩模拟在捕获解结构方面与全秩模拟在视觉上无法区分。

**Conclusion:** 自适应秩方法在高维Wigner-Poisson模拟中展现出巨大潜力，为在暖稠密等离子体中进行完全动力学阻止本领研究铺平了道路。

> **ai_Abstract:** 本文提出了一种新颖的、质量守恒的$O(N)$复杂度自适应秩求解器，用于解决一维一速Wigner-Poisson系统，该研究动机源于暖稠密等离子体中的应用。该求解器基于二阶Strang分裂法和结构保持的傅里叶更新。利用在特定普朗克常数下观察到的解的低秩结构，作者开发了一种结合SLAR和自适应傅里叶更新的自适应秩方案。该求解器能高效地保持质量和动量精度，其结果与全秩模拟视觉上无异，展现了其在高维量子动力学研究中的巨大潜力。

> **摘要翻译:** 我们开发了一种用于一维一速Wigner-Poisson系统的质量守恒、自适应秩求解器。我们的工作动机是应用于国家点火装置（NIF）中α粒子阻止本领的研究。在此状态下，电子处于暖稠密状态，需要超越标准动力学模型的描述。它们足够热以至于可以忽略泡利不相容原理，但又足够量子化以至于需要考虑不确定性。Wigner-Poisson系统能够捕捉这些效应，但由于其非局部性而带来挑战。基于二阶Strang分裂方法，我们首先设计了一个全秩求解器，其具有结构保持的傅里叶更新，确保中间解保持实值（达到机器精度），从而改进了以前的方法。模拟表明，对于中等到高无量纲普朗克常数（$H 	ext{≥} 0.1$），解表现出低秩结构。观察到的低秩结构促使我们开发了一种自适应秩求解器，该求解器基于用于对流的半拉格朗日自适应秩（SLAR）方案和用于Wigner积分项的自适应秩、结构保持傅里叶更新构建，并提供了严格的结构保持性质证明。我们的求解器在存储和计算时间上都实现了$O(N)$的复杂度，同时保持质量守恒并确保动量精度达到截断误差。自适应秩模拟在捕获解结构方面与全秩模拟在视觉上难以区分。这些结果凸显了自适应秩方法在高维Wigner-Poisson模拟中的潜力，为在暖稠密等离子体中进行完全动力学阻止本领研究铺平了道路。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [259] [A discontinuous in time Streamline Diffusion Virtual Element Method for Darcy-transport problem](https://arxiv.org/abs/2506.21326)
> *达西输运问题的时间不连续流线扩散虚单元法*

*R A Caraballo Diaz, F Dassi* | **Category: math.NA, cs.NA**

**Keywords:** 流线扩散, 虚单元法, 不连续伽辽金, 达西输运, 对流-扩散-反应

**Comment:** 

> **TL;DR:** 本文首次数值研究了达西输运问题中涉及化学反应物种的输运现象，提出并验证了一种时间不连续流线扩散虚单元法，实现了空间和时间上的任意阶精度。

**AI_Comments:** 本文的创新点在于将流线扩散法与虚单元法以及时间上的不连续伽辽金格式相结合，应用于复杂的达西输运问题。其抽象误差估计的推导以及数值实验验证的任意阶精度，突显了其在反应输运高精度模拟方面的理论严谨性和实际潜力。

<details>
  <summary>Details</summary>

**Motivation:** 研究涉及化学反应物种的输运现象，这些现象通过对流-扩散-反应系统建模，其流场由达西定律控制。

**Method:** 采用流线扩散法，结合虚单元法计算速度场和物种浓度，并使用时间上的不连续伽辽金格式。通过结合高斯-拉道插值和数值积分的特殊技术，推导了抽象误差估计。

**Result:** 理论上的抽象误差估计得到了数值实验的支持，实验结果显示在空间和时间上均达到了任意阶精度。

**Conclusion:** 所提出的时间不连续流线扩散虚单元法对于达西输运问题是有效的，并能实现任意阶精度。

> **ai_Abstract:** 本文首次对涉及化学反应物种的对流-扩散-反应系统在达西定律控制流场下的输运现象进行了数值研究。研究提出了一种时间不连续流线扩散虚单元法，用于计算速度场和物种浓度。通过利用高斯-拉道插值和数值积分，推导出了抽象误差估计，并通过数值实验验证了该方法在空间和时间上均能达到任意阶精度。

> **摘要翻译:** 我们首次对涉及化学反应物种的输运现象进行了数值研究，这些现象通过对流-扩散-反应系统建模，其流场由达西定律控制。在各种离散化方法中，我们考虑了流线扩散法。速度场和物种浓度都使用虚单元法计算，时间上采用不连续伽辽金格式。利用高斯-拉道插值结合数值积分的特殊技术，推导出了一个抽象误差估计。这些理论发现得到了数值实验的支持，实验显示在空间和时间上均达到了任意阶精度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [266] [Efficient parameter-robust preconditioners for linear poroelasticity and elasticity in the primal formulation](https://arxiv.org/abs/2506.21361)
> *原始公式中线性多孔弹性与弹性的高效参数鲁棒预条件子*

*Weizhang Huang, Zhuoran Wang* | **Category: math.NA, cs.NA, 65M60, 65F08, 65F10, 74F10**

**Keywords:** 多孔弹性, 预条件子, 鞍点系统, 参数鲁棒性, 弱Galerkin有限元

**Comment:** 27 pages

> **TL;DR:** 本文开发了一种高效的非奇异预条件子，用于解决多孔弹性问题中出现的鞍点系统，该预条件子在锁定情况下对参数变化具有鲁棒性，并能加速迭代求解。

**AI_Comments:** 这项研究的创新之处在于开发了一种非奇异预条件子，它在解决多孔弹性问题中的鞍点系统时，能够克服锁定问题，并且对关键参数具有鲁棒性。其重要性在于提供了一种高效的数值方法，能够显著加速此类复杂物理问题的模拟，对于工程、地球物理和生物领域具有实际应用价值。特别是其无需精确计算Schur补的特性降低了计算成本。

<details>
  <summary>Details</summary>

**Motivation:** 多孔弹性问题在工程、地球物理和生物应用中扮演重要角色。其完全离散化会导致大规模鞍点系统，在锁定情况下可能变得奇异，需要有效的预条件子来实现快速迭代求解。

**Method:** 本文开发了非奇异预条件子，使得预条件系统的特征值围绕1形成簇，并有一个阶为$1/\lambda$的离群值。研究了二场和三场块三角Schur补预条件子。所开发的预条件子无需计算Schur补，除了主对角块外也不需要精确求逆对角块。离散化采用了无锁定弱Galerkin有限元法和隐式Euler格式。

**Result:** 获得了特征值簇半径的上界，并表明其与inf-sup条件相关，但独立于网格尺寸、时间步长和锁定参数，这反映了预条件子对参数变化的鲁棒性。二维和三维数值结果均证实了所开发预条件子的有效性和参数鲁棒性。

**Conclusion:** 本文所开发的非奇异预条件子能够有效且参数鲁棒地解决多孔弹性问题中的大规模鞍点系统，尤其适用于锁定情况，从而加速了迭代求解过程。

> **ai_Abstract:** 本文针对多孔弹性问题离散化产生的大规模、在锁定情况下可能奇异的鞍点系统，提出了一种高效且参数鲁棒的非奇异预条件子。该预条件子使得预条件系统的特征值围绕1聚类，并通过理论分析和数值实验证明了其对网格尺寸、时间步长和锁定参数变化的鲁棒性。所提出的方法避免了Schur补的计算，并结合了无锁定弱Galerkin有限元法和隐式Euler格式，有效加速了迭代求解。

> **摘要翻译:** 多孔弹性问题在各种工程、地球物理和生物应用中扮演重要角色。它们的完全离散化在每个时间步都产生一个大规模鞍点系统，该系统在锁定情况下会变得奇异，需要有效的预条件子来进行快速迭代求解。本文没有构建谱等效的预条件子，而是开发了非奇异预条件子，使得预条件系统的特征值由围绕1的簇和一个阶为$1/\lambda$的离群值组成，其中$\lambda$是Lamé常数，在锁定情况下较大。已知GMRES的收敛因子受此类系统特征值簇半径的限制。本文研究了二场和三场块三角Schur补预条件子。获得了这些系统特征值簇半径的上界，并表明其与inf-sup条件相关，但独立于网格尺寸、时间步长和锁定参数，这反映了预条件子对参数变化的鲁棒性。此外，所开发的预条件子无需计算Schur补，除了主对角块外也不需要精确求逆对角块。离散化控制方程采用了无锁定弱Galerkin有限元法和隐式Euler格式。二维和三维数值结果均证实了所开发预条件子的有效性和参数鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [272] [Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes](https://arxiv.org/abs/2506.21395)
> *采用代数变分多尺度方法的最优解 第二部分：应用于纳维-斯托克斯方程*

*Suyash Shrestha, Marc Gerritsma, Gonzalo Rubio, Steven Hulshoff, Esteban Ferrer* | **Category: math.NA, cs.NA**

**Keywords:** 变分多尺度, 纳维-斯托克斯方程, 非线性问题, 高阶离散化, 数值模拟

**Comment:** 

> **TL;DR:** 本文将高阶变分多尺度(VMS)离散化框架非线性扩展，并应用于二维不可压缩纳维-斯托克斯方程，结果显示该方法鲁棒、准确且具有良好的守恒性。

**AI_Comments:** 该论文通过将变分多尺度方法扩展到非线性问题，特别是在纳维-斯托克斯方程上的应用，展示了其在流体力学数值模拟领域的创新性。其保持高阶精度和良好守恒性的能力，以及对复杂非线性多尺度问题的处理潜力，是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将之前针对稳态线性问题引入的基于变分多尺度（VMS）方法的高阶离散化框架扩展到非线性问题，特别是处理二维不可压缩纳维-斯托克斯方程。

**Method:** 本文提出了一种基于变分多尺度（VMS）方法的高阶离散化框架的非线性扩展。该方法基于通过控制算子的对称部分定义的“最优投影器”概念，将公式推广以处理二维不可压缩纳维-斯托克斯方程。它保持了已解析尺度和未解析尺度之间的清晰分离，并通过相关对称算子的近似精细尺度格林函数来近似精细尺度贡献。

**Result:** 该方法能够对非线性进行一致的变分处理，同时保持高阶精度。数值解能紧密近似连续/高分辨率解的最优投影，并继承了理想的守恒性。数值结果证实了该框架的鲁棒性、准确性及其在广泛的非线性多尺度问题中的应用潜力。

**Conclusion:** 所提出的高阶变分多尺度方法在处理非线性多尺度问题，特别是纳维-斯托克斯方程时，表现出优异的鲁棒性、准确性及守恒性，具有广泛的应用前景。

> **ai_Abstract:** 本文提出了一种高阶变分多尺度（VMS）方法的非线性扩展，用于求解二维不可压缩纳维-斯托克斯方程。该方法通过最优投影器概念，实现了已解析和未解析尺度间的清晰分离，并利用近似精细尺度格林函数处理精细尺度贡献，从而实现了高精度和一致的非线性变分处理。数值结果验证了其鲁棒性、准确性及良好的守恒特性，显示了其在非线性多尺度问题中的广泛应用潜力。

> **摘要翻译:** 这项工作提出了高阶离散化框架的非线性扩展，该框架基于先前为稳态线性问题引入的变分多尺度（VMS）方法。我们基于通过控制算子的对称部分定义的最优投影器的概念，将该公式推广以处理二维不可压缩纳维-斯托克斯方程。该方法在已解析尺度和未解析尺度之间保持清晰的分离，其中精细尺度贡献通过相关对称算子的近似精细尺度格林函数进行近似。这使得非线性能够得到一致的变分处理，同时保持高阶精度。我们表明，该方法产生的数值解能紧密近似连续/高分辨率解的最优投影，并继承了理想的守恒性。数值结果证实了该框架的鲁棒性、准确性及其在广泛的非线性多尺度问题中的应用潜力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [278] [An adaptive dynamical low-rank optimizer for solving kinetic parameter identification inverse problems](https://arxiv.org/abs/2506.21405)
> *一种用于解决动力学参数识别逆问题的自适应动态低秩优化器*

*Lena Baumann, Lukas Einkemmer, Christian Klingenberg, Jonas Kusch* | **Category: math.NA, cs.NA, 35Q49, 49M41, 65M22, 65M32**

**Keywords:** 参数识别, 逆问题, 动态低秩近似, 辐射传输方程, 计算效率

**Comment:** 

> **TL;DR:** 本文提出了一种自适应动态低秩近似（DLRA）方案，用于解决动力学参数识别逆问题，显著降低了计算和内存成本，并经验证具有高精度和效率。

**AI_Comments:** 本文的创新点在于将动态低秩近似（DLRA）与自适应策略结合，有效地解决了动力学参数识别逆问题中的计算和内存瓶颈。通过引入秩自适应基更新和线搜索机制，该方案在保证精度的前提下，实现了计算效率的显著提升，对于需要处理大规模动力学逆问题的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动力学方程参数识别逆问题的数值解计算和内存成本高昂。

**Method:** 本文提出了一种动态低秩方案，用于从宏观时间无关测量中重建辐射传输方程中的散射参数。首先在连续设置中通过PDE约束优化过程，并使用拉格朗日重构推导出伴随方程。对于散射系数，引入周期B样条近似并制定了更新其系数的梯度下降步骤。离散化后，应用动态低秩近似（DLRA），并利用秩自适应基更新和伽辽金积分器，以及线搜索方法来自适应细化梯度下降步长和DLRA容差。

**Result:** 所提出的方案显著降低了内存和计算成本。通过不同初始条件计算的数值结果验证了所提出的DLRA方案与使用完整求解器计算的解决方案相比的准确性和效率。

**Conclusion:** 本文提出的自适应动态低秩近似（DLRA）方案能够有效且高效地解决动力学参数识别逆问题，显著降低了计算和内存成本，并保持了高精度。

> **ai_Abstract:** 本文提出了一种自适应动态低秩近似（DLRA）方案，旨在解决动力学方程参数识别逆问题所面临的高计算和内存成本。该方法通过PDE约束优化过程，结合拉格朗日重构推导伴随方程，并利用周期B样条近似和梯度下降更新散射系数。离散化后，应用DLRA，并通过秩自适应基更新、伽辽金积分器和线搜索方法自适应调整步长和容差。研究结果表明，该方案显著降低了计算和内存成本，且数值实验验证了其相较于完整求解器的高准确性和效率。

> **摘要翻译:** 动力学方程参数识别逆问题的数值解可能表现出高计算和内存成本。在本文中，我们提出了一种动态低秩方案，用于从多个宏观时间无关测量中重建辐射传输方程中的散射参数。我们首先在连续设置中通过PDE约束优化过程，并使用拉格朗日重构推导出伴随方程。对于散射系数，引入了周期B样条近似，并制定了更新其系数的梯度下降步骤。在离散化之后，应用了动态低秩近似（DLRA）。我们利用秩自适应基更新和伽辽金积分器以及线搜索方法来对梯度下降步长和DLRA容差进行自适应细化。我们表明，所提出的方案显著降低了内存和计算成本。通过不同初始条件计算的数值结果验证了所提出的DLRA方案与使用完整求解器计算的解决方案相比的准确性和效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [281] [An Iterative Methodology for Unitary Quantum Channel Search](https://arxiv.org/abs/2506.21455)
> *单一量子信道搜索的迭代方法*

*Matthew M. Lin, Hao-Wei Huang, Bing-Ze Lu* | **Category: math.NA, cs.NA, quant-ph**

**Keywords:** 迭代算法, 极分解, 酉量子信道, 量子态对, 搜索空间缩减

**Comment:** 

> **TL;DR:** 本文提出了一种使用极分解的迭代算法，用于基于输入-输出量子态对来逼近单一酉矩阵表征的量子信道。该方法在有限数据下能显著减少搜索空间并被证明能收敛到局部最小值。

**AI_Comments:** 本文的创新之处在于利用极分解进行迭代搜索，并严格证明了在有限数据下搜索空间的显著减少和算法的收敛性。这对于实际的量子信道表征，尤其是在数据受限的情况下，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在有限数据下，基于输入-输出量子态对来近似由单个酉矩阵表征的量子信道。

**Method:** 提出了一种使用极分解的迭代算法。该方法利用一个具有特定结构的输入-输出量子态对来生成一个等价类，从而显著减小搜索空间的维度。

**Result:** 1. 在有限数据下，使用特定结构的输入-输出对，该方法获得的最佳解能生成一个等价类，显著减小搜索空间的维度。2. 描述相同信道的酉矩阵仅相差一个模为1的复数。3. 严格证明所提出的算法最终能够识别出一个临界点，该临界点也是所建立目标函数的局部最小值。

**Conclusion:** 本文提出的迭代算法能够有效地逼近单一酉矩阵表征的量子信道，并被严格证明在有限数据下能有效减少搜索空间并收敛到局部最小值。

> **ai_Abstract:** 本文提出了一种基于极分解的迭代算法，用于从输入-输出量子态对中近似单一酉矩阵表征的量子信道。研究证明，在有限数据条件下，通过使用特定结构的量子态对，该方法能够显著缩小搜索空间，并且算法能够收敛到目标函数的局部最小值，从而有效地识别量子信道。

> **摘要翻译:** 在本文中，我们提出了一种使用极分解的迭代算法，基于输入-输出量子态对来逼近由单个酉矩阵表征的信道。在有限数据下，我们阐述并证明，通过使用一个特定结构的输入-输出对，我们的方法获得的最佳解将生成一个等价类，从而显著减小搜索空间的维度。此外，我们证明了描述相同信道的酉矩阵仅相差一个模为1的复数。我们严格证明了我们提出的算法最终能够识别出一个临界点，该临界点也是所建立目标函数的局部最小值。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [43] [A Multi-Stage Framework for Multimodal Controllable Speech Synthesis](https://arxiv.org/abs/2506.20945)
> *多阶段多模态可控语音合成框架*

*Rui Niu, Weihao Wu, Jie Chen, Long Ma, Zhiyong Wu* | **Category: cs.SD, eess.AS**

**Keywords:** 多模态, 可控语音合成, 多阶段框架, 知识蒸馏, 语音多样性

**Comment:** Accepted by ICME2025

> **TL;DR:** 本文提出一个三阶段多模态可控语音合成框架，通过解决现有方法在鲁棒性、泛化性和多样性方面的挑战，生成高质量语音。

**AI_Comments:** 这篇论文的创新点在于提出了一个多阶段框架来整合多模态输入，并针对性地解决了现有方法的痛点，如数据质量导致的泛化性问题（通过知识蒸馏）以及文本提示的多样性不足（通过多源数据训练）。其多阶段设计和对不同模态编码器的优化，提升了可控语音合成的鲁棒性、泛化性和多样性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于面部的可控语音合成方法因数据质量受限于鲁棒性和泛化性，而文本提示方法在多样性和精细控制方面有限。多模态方法则受限于对完全匹配训练数据的依赖，影响其性能和适用性。

**Method:** 本文提出了一个三阶段多模态可控语音合成框架。针对人脸编码器，采用监督学习和知识蒸馏来解决泛化问题。此外，文本编码器在文本-人脸和文本-语音数据上进行训练，以增强生成语音的多样性。

**Result:** 实验结果表明，该方法在基于人脸和基于文本提示的语音合成方面均优于单模态基线方法，突出了其在生成高质量语音方面的有效性。

**Conclusion:** 所提出的多阶段多模态框架有效解决了现有可控语音合成方法的局限性，显著提升了生成语音的质量、鲁棒性和多样性。

> **ai_Abstract:** 本文提出了一种三阶段多模态可控语音合成框架，旨在克服现有面部和文本提示方法的局限性。该框架通过对人脸编码器采用监督学习和知识蒸馏提升泛化能力，并对文本编码器在多源数据上训练以增强语音多样性。实验证明，该方法在高质量语音生成方面优于单模态基线。

> **摘要翻译:** 可控语音合成旨在利用各种模态的参考输入来控制生成语音的风格。现有基于人部的方法由于数据质量限制，在鲁棒性和泛化性方面存在困难，而文本提示方法则提供有限的多样性和精细控制。尽管多模态方法旨在整合各种模态，但它们对完全匹配训练数据的依赖显著限制了其性能和适用性。本文提出了一个三阶段多模态可控语音合成框架来解决这些挑战。对于人脸编码器，我们使用监督学习和知识蒸馏来解决泛化问题。此外，文本编码器在文本-人脸和文本-语音数据上进行训练，以增强生成语音的多样性。实验结果表明，该方法在基于人脸和基于文本提示的语音合成方面均优于单模态基线方法，突出了其在生成高质量语音方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [67] [PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching](https://arxiv.org/abs/2506.21086)
> *PeakNetFP：基于峰值的神经网络音频指纹识别，对极端时间拉伸具有鲁棒性*

*Guillem Cortès-Sebastià, Benjamin Martin, Emilio Molina, Xavier Serra, Romain Hennequin* | **Category: cs.SD, cs.IR, eess.AS, H.3.1; H.3.3; H.3.4**

**Keywords:** 音频指纹识别, 神经网络, 时间拉伸, 频谱峰值, 效率

**Comment:** Accepted at ISMIR 2025

> **TL;DR:** PeakNetFP是一种新的基于峰值的神经网络音频指纹识别系统，它结合了传统峰值方法的轻量级和神经网络的适应性，在处理时间拉伸音频方面表现出色，同时比现有最先进的方法更高效。

**AI_Comments:** PeakNetFP的创新之处在于它成功地将传统基于峰值的音频指纹识别的轻量级特性与深度学习（神经网络）的强大适应性和模式识别能力融合。这种结合不仅解决了音频时间拉伸带来的挑战，还在效率上取得了显著突破，大幅减少了模型参数和输入数据量，使其在实际应用中更具吸引力。这为未来开发更高效、可扩展的音频处理技术指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的音频指纹识别系统在处理极端时间拉伸的音频数据时可能性能不佳，并且一些先进的深度学习方法（如NeuralFP）可能在效率上存在不足（参数多、输入数据大）。本文旨在开发一个既鲁棒又高效的解决方案。

**Method:** 本文提出了PeakNetFP，这是一个围绕频谱峰值设计的神经网络音频指纹识别系统。它利用稀疏频谱坐标，采用类似于计算机视觉模型PointNet++的分层点特征提取技术，并使用对比学习进行训练（类似于NeuralFP）。

**Result:** PeakNetFP在处理时间拉伸音频数据时，性能优于传统音频指纹识别系统，并与最先进的NeuralFP表现相当。它在50%到200%的时间拉伸因子下保持超过90%的Top-1命中率。此外，PeakNetFP具有显著的效率优势：与NeuralFP相比，其参数减少100倍，输入数据小11倍。

**Conclusion:** PeakNetFP为涉及时间拉伸的音频指纹识别任务提供了一个轻量且高效的解决方案。该系统成功地将基于峰值的音频指纹识别的轻量级特性与基于神经网络方法的适应性和模式识别能力相结合，为未来的音频指纹识别技术开辟了更具可扩展性和效率的解决方案。

> **ai_Abstract:** PeakNetFP是一种新型的神经网络音频指纹识别（AFP）系统，它创新性地结合了传统峰值方法的稀疏性与神经网络的强大模式识别能力。该系统采用分层点特征提取和对比学习，在处理极端时间拉伸音频数据时，表现出与最先进的NeuralFP相当的鲁棒性，并显著提高了效率，参数量减少100倍，输入数据量减少11倍，为音频指纹识别领域提供了轻量、高效且可扩展的解决方案。

> **摘要翻译:** 这项工作介绍了PeakNetFP，这是第一个专门围绕频谱峰值设计的神经网络音频指纹识别（AFP）系统。这个新颖的系统旨在利用传统基于峰值的AFP方法通常计算的稀疏频谱坐标。PeakNetFP执行类似于计算机视觉模型PointNet++的分层点特征提取技术，并像最先进的深度学习AFP系统NeuralFP一样使用对比学习进行训练。这种组合使得PeakNetFP在处理具有挑战性的时间拉伸音频数据时，能够超越传统的AFP系统，并实现与NeuralFP相当的性能。在广泛的评估中，PeakNetFP在50%到200%的时间拉伸因子范围内保持超过90%的Top-1命中率。此外，PeakNetFP提供了显著的效率优势：与NeuralFP相比，它的参数减少100倍，输入数据小11倍。这些特性使PeakNetFP成为涉及时间拉伸的AFP任务的轻量级高效解决方案。总的来说，该系统代表了未来AFP技术的一个有前景的方向，因为它成功地将基于峰值的AFP的轻量级特性与基于神经网络方法的适应性和模式识别能力相结合，为该领域更具可扩展性和效率的解决方案铺平了道路。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [91] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
> *一种用于少数乐器检测的层次深度学习方法*

*Dylan Sechet, Francesca Bugiotti, Matthieu Kowalski, Edouard d'Hérouville, Filip Langiewicz* | **Category: cs.SD, cs.AI, eess.AS**

**Keywords:** 层次深度学习, 乐器检测, 音乐信息检索, 霍恩博斯特尔-萨克斯分类, MedleyDB

**Comment:** International Conference on Digital Audio Effects (DAFx)

> **TL;DR:** 本文提出了一种层次深度学习方法，利用霍恩博斯特尔-萨克斯分类法，在MedleyDB数据集上评估并实现了更可靠的粗粒度乐器检测，尤其解决了少数乐器识别中的数据稀缺问题。

**AI_Comments:** 本文的创新之处在于提出了一种层次深度学习方法来解决音乐信息检索中少数乐器检测的数据稀缺问题。通过利用霍恩博斯特尔-萨克斯分类法，并将分层结构整合到模型中，有效地提高了粗粒度乐器检测的可靠性。这对于乐器编目和发现具有重要意义，尤其是在处理数据有限的乐器类别时。

<details>
  <summary>Details</summary>

**Motivation:** 在音乐信息检索中，识别音频片段中的乐器活动至乐器编目和发现至关重要。之前的深度学习方法主要侧重于数据量充足的乐器类别，而忽略了少数乐器。最近的研究表明，即使在乐器层面缺乏细粒度标注的情况下，分层分类在管弦乐器活动检测中也适用。

**Method:** 本研究基于霍恩博斯特尔-萨克斯分类法，使用MedleyDB数据集评估了分层分类系统。文中提出了多种策略将分层结构整合到模型中，并测试了一类新的用于分层音乐预测的模型。

**Result:** 研究结果表明，通过弥合详细乐器识别和组级识别之间的差距，实现了更可靠的粗粒度乐器检测。

**Conclusion:** 这项工作为该领域未来的进一步发展铺平了道路，尤其是在处理数据稀缺的少数乐器检测方面。

> **ai_Abstract:** 本文提出了一种层次深度学习方法，旨在解决音乐信息检索中少数乐器检测的数据稀缺问题。研究基于霍恩博斯特尔-萨克斯分类法，利用MedleyDB数据集评估了分层分类系统，并开发了新的模型来整合层次结构。实验结果表明，该方法能够实现更可靠的粗粒度乐器检测，有效连接了详细乐器识别与组级识别，为未来该领域的发展奠定了基础。

> **摘要翻译:** 在音乐信息检索中，识别音频片段中的乐器活动至关重要，对音乐编目和发现具有重要意义。先前的音乐乐器识别深度学习研究主要强调数据可用性充足的乐器类别。最近的研究表明，即使乐器层面缺乏细粒度标注，分层分类在管弦乐器活动检测中也适用。基于霍恩博斯特尔-萨克斯分类法，使用以其多样性和丰富性闻名的MedleyDB数据集，对这种分层分类系统进行了评估。这项工作提出了将分层结构整合到模型中的各种策略，并测试了一类新的用于分层音乐预测的模型。本研究通过弥合详细乐器识别和组级识别之间的差距，展示了更可靠的粗粒度乐器检测，为该领域未来的进一步发展铺平了道路。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [114] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
> *整合车辆声学数据以增强城市交通管理：以苏州为例的速度分类研究*

*Pengfei Fan, Yuli Zhang, Xinheng Wang, Ruiyuan Jiang, Hankang Gu, Dongyao Jia, Shangbo Wang* | **Category: cs.SD, cs.AI, eess.AS**

**Keywords:** 车辆声学数据, 速度分类, 深度学习, 交通管理, 苏州

**Comment:** 

> **TL;DR:** 本研究发布了苏州城市道路声学数据集，并提出了一种双模态特征融合深度卷积神经网络（BMCNN）用于车辆速度分类，旨在通过声学数据实现智能交通管理和噪声监测。

**AI_Comments:** 本文通过构建并公开新的数据集，为车辆声学研究提供了宝贵资源。所提出的BMCNN模型结合了多模态特征和注意力机制，有效提升了速度分类的准确性和鲁棒性，并在实际应用中展现了优化城市交通和环境的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了更好地理解车辆噪声与驾驶速度之间的关系，并利用声学数据优化交通流控制、减少路边噪声污染以及支持可持续城市规划，本研究旨在开发一种基于声学的车辆速度分类方法。

**Method:** 本研究公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一个双模态特征融合深度卷积神经网络（BMCNN）。在预处理阶段，应用了自适应去噪和归一化策略。在网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，并通过跨模态注意力机制在中间特征空间进行融合，以充分利用时频信息。

**Result:** BMCNN在SZUR-Acoustic数据集上实现了87.56%的分类准确率，在公共IDMT-Traffic数据集上达到了96.28%的准确率。消融研究和鲁棒性测试进一步验证了各模块对性能提升和过拟合缓解的贡献。

**Conclusion:** 所提出的基于声学的速度分类方法可集成到智慧城市交通管理系统中，用于实时噪声监测和速度估计，从而优化交通流控制，减少路边噪声污染，并支持可持续的城市规划。

> **ai_Abstract:** 本研究发布了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一种名为BMCNN的双模态特征融合深度卷积神经网络，用于基于车辆噪声的驾驶速度分类。BMCNN通过自适应去噪预处理，并结合MFCCs和小波包能量特征，利用跨模态注意力机制进行信息融合。实验证明，BMCNN在自建和公共数据集上均表现出高准确性，并通过消融研究验证了其模块的有效性。该方法有望应用于智慧城市交通管理，实现实时噪声监测和速度估计，从而优化交通流、减少噪声污染并支持城市可持续发展。

> **摘要翻译:** 本研究介绍并公开发布了苏州城市道路声学数据集（SZUR-Acoustic Dataset），该数据集附有全面的数据采集协议和注释指南，以确保实验工作流程的透明度和可复现性。为了模拟车辆噪声与驾驶速度之间的耦合关系，我们提出了一种双模态特征融合深度卷积神经网络（BMCNN）。在预处理阶段，应用了自适应去噪和归一化策略来抑制环境背景干扰；在网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，随后通过中间特征空间中的跨模态注意力机制进行融合，以充分利用时频信息。实验结果表明，BMCNN在SZUR-Acoustic数据集上实现了87.56%的分类准确率，在公共IDMT-Traffic数据集上达到了96.28%。对苏州数据集进行的消融研究和鲁棒性测试进一步验证了每个模块对性能改进和过拟合缓解的贡献。所提出的基于声学的速度分类方法可以集成到智慧城市交通管理系统中，用于实时噪声监测和速度估计，从而优化交通流控制，减少路边噪声污染，并支持可持续的城市规划。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [134] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
> *探索低资源音乐生成中的适配器设计权衡*

*Atharva Mehta, Shivam Chauhan, Monojit Choudhury* | **Category: cs.SD, cs.AI, cs.CL, cs.LG, cs.MM, eess.AS**

**Keywords:** 音乐生成, 适配器, 参数高效微调, MusicGen, Mustango

**Comment:** 9 pages, 5 figures

> **TL;DR:** 本研究探讨了针对低资源音乐生成的大型模型中不同适配器设计的权衡，发现卷积适配器擅长捕捉局部细节，而Transformer适配器更擅长处理长程依赖，并分析了计算效率和模型性能。

**AI_Comments:** 该论文通过对不同适配器设计在低资源音乐生成中的系统性研究，为参数高效微调（PEFT）在音乐领域的应用提供了宝贵的实践指导。其创新点在于细致地分析了不同适配器架构（卷积与Transformer）对音乐特征捕捉的差异，并量化了计算资源与模型性能的权衡。这对于资源受限的研究者和开发者而言具有重要意义，有助于他们在实际应用中做出更明智的设计选择。同时，对两种不同音乐生成模型（扩散与自回归）的比较也丰富了对各自优缺点的理解。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型音乐生成模型（如MusicGen和Mustango）计算成本高昂，需要大量硬件资源。参数高效微调（PEFT）技术，特别是基于适配器的方法，提供了一种有前景的替代方案。然而，适配器设计选择众多，在低资源音乐流派中，哪种组合能产生最佳适配器以及原因尚不清楚。

**Method:** 本文通过研究两种AI音乐模型（MusicGen和Mustango）在两种流派（印度斯坦古典音乐和土耳其马卡姆音乐）上的各种适配器配置，试图回答这个问题。

**Result:** 研究发现，卷积适配器擅长捕捉精细的局部音乐细节（如装饰音和短旋律），而Transformer适配器能更好地保持对结构化即兴创作至关重要的长程依赖。中等大小的适配器（40M参数）在表达能力和质量之间取得了最佳平衡。Mustango模型生成更多样化、更符合描述的输出，但缺乏音符稳定性、节奏对齐和美学，且计算密集型；MusicGen等自回归模型训练更快、效率更高，能产生更高质量的输出，但生成内容冗余度略高。

**Conclusion:** 本研究揭示了在低资源音乐生成背景下，不同适配器设计选择的独特权衡，并比较了不同模型架构的性能和计算效率，为优化PEFT策略提供了见解。

> **ai_Abstract:** 本研究探讨了在低资源音乐生成场景下，大型模型（MusicGen和Mustango）中适配器设计选择的权衡。论文评估了不同适配器配置（卷积和Transformer）对两种音乐流派（印度斯坦古典和土耳其马卡姆）的影响，并比较了其捕捉音乐细节、保持长程依赖的能力以及计算资源需求。研究发现，卷积适配器擅长局部细节，Transformer适配器擅长长程依赖，中等大小的适配器（40M参数）达到性能与效率的平衡。同时，论文对比了扩散模型Mustango和自回归模型MusicGen的优缺点。

> **摘要翻译:** 微调大型音乐生成模型，如MusicGen和Mustango，是一个计算成本高昂的过程，通常需要更新数十亿参数，因此需要大量硬件资源。参数高效微调（PEFT）技术，特别是基于适配器的方法，已成为一种有前景的替代方案，可以在最小化可训练参数的同时保持模型性能。然而，适配器的设计选择，包括其架构、放置和大小，数量众多，并且对于给定低资源音乐流派的案例，尚不清楚这些组合中的哪一种会产生最佳适配器以及原因。在本文中，我们试图通过研究两种AI音乐模型（MusicGen和Mustango）在两种流派：印度斯坦古典音乐和土耳其马卡姆音乐上的各种适配器配置来回答这个问题。
我们的研究结果揭示了明显的权衡：基于卷积的适配器擅长捕捉精细的局部音乐细节，如装饰音和短旋律，而基于Transformer的适配器能更好地保持对结构化即兴创作至关重要的长程依赖。此外，我们分析了不同适配器规模下的计算资源需求，展示了中等大小的适配器（40M参数）如何在表达能力和质量之间实现最佳平衡。此外，我们发现基于扩散模型的Mustango在生成更多样化、更符合输入提示描述的输出方面表现更好，但在音符稳定性、节奏对齐和美学方面有所欠缺。而且，它的计算量大，训练时间显著增加。相比之下，像MusicGen这样的自回归模型训练更快，效率更高，并且可以产生更高质量的输出，但其生成内容略有冗余。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [151] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
> *可学习自适应时频表示通过可微分短时傅里叶变换*

*Maxime Leiber, Yosra Marnissi, Axel Barrau, Sylvain Meignen, Laurent Massoulié* | **Category: cs.SD, cs.LG, eess.AS, eess.SP**

**Keywords:** 短时傅里叶变换, 可微分, 时频表示, 参数优化, 神经网络

**Comment:** DSTFT, STFT, spectrogram, time-frequency, IEEE Transactions on Signal
  Processing, 10 pages

> **TL;DR:** 提出了一种可微分的短时傅里叶变换(STFT)，解决了传统STFT参数调优困难的问题，实现了基于梯度的优化，并能与神经网络联合优化，有效提升了时频表示和下游任务性能。

**AI_Comments:** 这篇论文的创新点在于将短时傅里叶变换（STFT）参数调优问题转化为可微分的形式，从而能够利用梯度下降进行优化，极大地提高了效率和性能。它解决了传统STFT参数选择的痛点，并为信号处理与深度学习的结合提供了新的范式，特别是其与神经网络的无缝集成能力，有望在各种非平稳信号处理任务中发挥重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的短时傅里叶变换（STFT）在分析非平稳信号时广泛使用，但其性能对参数高度敏感，且手动或启发式调优常导致次优结果，现有方法依赖计算密集型离散搜索。

**Method:** 提出了一种统一的可微分STFT公式，通过梯度优化其参数，克服了传统离散搜索的局限性。该方法支持基于任意准则对时频表示（TFR）进行微调，并能与神经网络无缝集成，实现STFT参数和网络权重的联合优化。

**Result:** 实验证明，所提出的可微分STFT在增强时频表示（TFR）和改进下游任务性能方面是有效的，并在仿真数据和真实世界数据上都得到了验证。

**Conclusion:** 通过引入可微分的短时傅里叶变换，可以实现STFT参数的梯度优化，有效克服传统调优的局限性，提升时频表示的质量以及下游任务的性能，并能与深度学习模型结合。

> **ai_Abstract:** 本文提出了一种创新的可微分短时傅里叶变换（STFT）方法，旨在解决传统STFT参数调优困难且效率低下的问题。通过引入统一的可微分公式，该方法实现了STFT参数的梯度优化，避免了计算密集型离散搜索。它允许根据特定准则对时频表示（TFR）进行精细调整，并能与神经网络无缝结合，实现参数和网络权重的联合优化。实验结果表明，该可微分STFT能有效提升TFR质量，并改善下游任务的表现。

> **摘要翻译:** 短时傅里叶变换（STFT）广泛应用于非平稳信号分析。然而，其性能对其参数高度敏感，手动或启发式调优常导致次优结果。为了克服这一局限性，我们提出了一种统一的可微分STFT公式，该公式支持基于梯度的参数优化。这种方法解决了传统STFT参数调优方法的局限性，这些方法通常依赖于计算密集型的离散搜索。它能够根据任何期望的准则对时频表示（TFR）进行微调。此外，我们的方法与神经网络无缝集成，允许STFT参数和网络权重的联合优化。通过在模拟数据和真实世界数据上的实验，证明了所提出的可微分STFT在增强TFR和改进下游任务性能方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [171] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
> *SmoothSinger：一种具有多分辨率架构的歌唱语音合成条件扩散模型*

*Kehan Sui, Jinxu Xiang, Fang Jin* | **Category: cs.SD, cs.AI**

**Keywords:** 歌唱语音合成, 条件扩散模型, 多分辨率架构, 音频合成, 深度学习

**Comment:** 

> **TL;DR:** SmoothSinger是一种条件扩散模型，用于生成高质量和自然的歌唱语音，通过直接细化低质量音频并采用参考引导的双分支架构，实现了最先进的性能。

**AI_Comments:** SmoothSinger的创新之处在于其统一的框架，直接对低质量音频进行细化，避免了两阶段管道的失真。其参考引导的双分支架构和增强的U-Net（带有并行低频上采样路径）是关键的技术贡献，有助于提高合成语音的表达力和自然度。通过在训练中替换参考音频为降级的真实音频，有效解决了时序不匹配问题。该研究在SVS领域取得了显著进展，为高质量歌唱语音合成提供了新的SOTA解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 歌唱语音合成（SVS）需要精确建模音高、持续时间和发音。虽然基于扩散的模型在图像和视频生成方面取得了显著成功，但由于歌唱复杂的声学和音乐特性，将其应用于SVS仍然具有挑战性，经常导致降低自然度的伪影。现有的方法依赖于声码器作为最终阶段，通常会引入失真。

**Method:** 我们提出了SmoothSinger，一个条件扩散模型，旨在合成高质量和自然的歌唱语音。与依赖声码器的先前方法不同，SmoothSinger在一个统一的框架中直接细化低质量的合成音频，减轻了两阶段管道相关的降级。该模型采用参考引导的双分支架构，使用来自任何基线系统的低质量音频作为参考来引导去噪过程。此外，它通过并行低频上采样路径增强了传统的U-Net，使模型能够更好地捕捉音高轮廓和长期频谱依赖性。为了改善训练期间的对齐，我们用降级的真实音频替换参考音频，解决了参考信号和目标信号之间的时间不匹配。

**Result:** 在Opencpop数据集（一个大规模中文歌唱语料库）上的实验表明，SmoothSinger在客观和主观评估中都取得了最先进的结果。广泛的消融研究证实了其在减少伪影和提高合成语音自然度方面的有效性。

**Conclusion:** SmoothSinger是一种有效的条件扩散模型，能够合成高质量和自然的歌唱语音，通过其独特的架构和训练策略，克服了传统SVS扩散模型中的挑战，并取得了最先进的性能。

> **ai_Abstract:** SmoothSinger是一种用于歌唱语音合成的条件扩散模型。它通过直接细化低质量音频、采用参考引导的双分支架构以及增强U-Net以捕捉音高和长期依赖性，解决了传统扩散模型在SVS中产生的伪影和自然度问题。该模型在训练中通过使用降级的真实音频作为参考来改善对齐。实验证明，SmoothSinger在中文歌唱数据集Opencpop上达到了最先进的性能，显著减少了伪影并提高了合成语音的自然度。

> **摘要翻译:** 歌唱语音合成（SVS）旨在从乐谱中生成富有表现力的高质量人声，需要精确建模音高、持续时间和发音。虽然基于扩散的模型在图像和视频生成方面取得了显著成功，但由于歌唱复杂的声学和音乐特性，将其应用于SVS仍然具有挑战性，经常导致降低自然度的伪影。在这项工作中，我们提出了SmoothSinger，一个条件扩散模型，旨在合成高质量和自然的歌唱语音。与依赖声码器作为最终阶段并经常引入失真的先前方法不同，SmoothSinger在一个统一的框架中直接细化低质量的合成音频，减轻了两阶段管道相关的降级。该模型采用参考引导的双分支架构，使用来自任何基线系统的低质量音频作为参考来引导去噪过程，从而实现更具表现力和上下文感知的合成。此外，它通过并行低频上采样路径增强了传统的U-Net，使模型能够更好地捕捉音高轮廓和长期频谱依赖性。为了改善训练期间的对齐，我们用降级的真实音频替换参考音频，解决了参考信号和目标信号之间的时间不匹配。在Opencpop数据集（一个大规模中文歌唱语料库）上的实验表明，SmoothSinger在客观和主观评估中都取得了最先进的结果。广泛的消融研究证实了其在减少伪影和提高合成语音自然度方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [242] [DRAGON: Distributional Rewards Optimize Diffusion Generative Models](https://arxiv.org/abs/2504.15217)
> *DRAGON：分布奖励优化扩散生成模型*

*Yatong Bai, Jonah Casebeer, Somayeh Sojoudi, Nicholas J. Bryan* | **Category: cs.SD, cs.AI, cs.LG, cs.MM**

**Keywords:** 扩散模型, 生成优化, 分布奖励, 微调, 媒体生成

**Comment:** 

> **TL;DR:** DRAGON是一个灵活的框架，用于通过分布奖励微调媒体生成模型，其性能优于传统的RLHF/DPO，并在各种奖励函数下取得了高胜率，包括基于示范的奖励。

**AI_Comments:** DRAGON的创新之处在于其对“分布奖励”的概念，使其能够处理更广泛的奖励函数类型，包括跨模态和基于参考分布的奖励，这比传统的RLHF和DPO更具普适性。它在无需人类偏好标注的情况下，通过构建示范集和对比学习实现高质量生成，这对于数据标注成本高昂的媒体生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于人类反馈的强化学习（RLHF）或直接偏好优化（DPO）方法在优化媒体生成模型方面缺乏灵活性。当前需要一个更通用的框架，能够优化评估单个示例或其分布的奖励函数。

**Method:** DRAGON（Distributional RewArds for Generative OptimizatioN）框架被提出，它能够优化评估单个示例或其分布的奖励函数，兼容实例级、实例到分布和分布到分布的奖励。通过选择编码器（如CLAP）和参考示例来创建示范分布，构建新颖的奖励函数。DRAGON收集在线和策略内的生成，对其进行评分以构建正面和负面演示集，并利用两者的对比来最大化奖励。在评估中，该方法使用20种不同的奖励函数微调了一个音频领域的文本到音乐扩散模型，并比较了不同的FAD设置和消融实验。

**Result:** 在所有20个目标奖励中，DRAGON取得了81.45%的平均胜率。基于示范集的奖励函数能够增强生成效果，并与基于模型的奖励相当。在没有人类偏好注释训练的情况下，DRAGON通过适当的示范集实现了60.95%的人类投票音乐质量胜率。

**Conclusion:** DRAGON为设计和优化奖励函数以提高人类感知质量提供了一种新方法，尤其是在不需要显式人类偏好训练的情况下。

> **ai_Abstract:** DRAGON是一个多功能框架，用于微调媒体生成模型，通过优化评估单个示例或其分布的奖励函数，使其比RLHF或DPO更灵活。它能通过编码器和参考示例构建新颖的奖励函数，并通过对比正负生成集来最大化奖励。在对文本到音乐扩散模型的评估中，DRAGON在20种奖励函数上平均胜率达81.45%，且基于示范集的奖励函数能有效提升生成质量，在无需人类偏好训练的情况下，实现60.95%的人类投票音乐质量胜率。这为设计和优化奖励函数以提升人类感知质量提供了新途径。

> **摘要翻译:** 我们提出了DRAGON（Distributional RewArds for Generative OptimizatioN），这是一个用于微调媒体生成模型以达到预期结果的多功能框架。与传统的基于人类反馈的强化学习（RLHF）或成对偏好方法（如直接偏好优化（DPO））相比，DRAGON更加灵活。它能优化评估单个示例或其分布的奖励函数，使其兼容广泛的实例级、实例到分布和分布到分布奖励。利用这种多功能性，我们通过选择编码器和一组参考示例来创建示范分布，从而构建新颖的奖励函数。当使用跨模态编码器（如CLAP）时，参考示例可以是不同模态的（例如，文本与音频）。然后，DRAGON收集在线和策略内的生成，对它们进行评分以构建一个正面演示集和一个负面集，并利用这两个集合之间的对比来最大化奖励。为了进行评估，我们使用20种不同的奖励函数微调了一个音频领域的文本到音乐扩散模型，包括自定义音乐美学模型、CLAP分数、Vendi多样性和Frechet音频距离（FAD）。我们进一步比较了实例级（每首歌曲）和完整数据集FAD设置，同时消融了多个FAD编码器和参考集。在所有20个目标奖励中，DRAGON取得了81.45%的平均胜率。此外，基于示范集的奖励函数确实增强了生成效果，并且与基于模型的奖励相当。通过适当的示范集，DRAGON在未经人类偏好注释训练的情况下，实现了60.95%的人类投票音乐质量胜率。因此，DRAGON展示了一种设计和优化奖励函数以提高人类感知质量的新方法。声音示例可在https://ml-dragon.github.io/web 获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [48] [Metadata Enrichment of Long Text Documents using Large Language Models](https://arxiv.org/abs/2506.20918)
> *使用大型语言模型丰富长文本元数据*

*Manika Lamba, You Peng, Sophie Nikolov, Glen Layne-Worthey, J. Stephen Downie* | **Category: cs.DL, cs.ET, cs.IR**

**Keywords:** 元数据丰富, 大型语言模型, 数字图书馆, 长文本, HathiTrust

**Comment:** 

> **TL;DR:** 本项目利用人工和大型语言模型对HathiTrust数字图书馆的长文本（论文和学位论文）元数据进行了语义丰富和增强，该方法对数字存储库尤其有益，能改善搜索结果和可访问性。

**AI_Comments:** 该论文提出了一种利用大型语言模型和人工协同工作来丰富长文本元数据的方法，这在提升数字图书馆和存储库的数据可发现性与可访问性方面具有创新性。其重要性在于解决了传统元数据缺失和不足的问题，尤其对于大规模历史文献数据集，能显著改善用户体验和研究效率。该方法的普适性使其可能应用于其他类似的数据管理场景。

<details>
  <summary>Details</summary>

**Motivation:** 现有数字存储库的元数据可能存在大量缺失数据，且未预见到各种内容类型的访问点，导致搜索结果不佳和可访问性受限。

**Method:** 通过结合人工努力和大型语言模型，对从HathiTrust数字图书馆检索到的1920年至2020年间出版的英文长文本文档、论文和学位论文的元数据进行语义丰富和增强。

**Result:** 该方法为数字存储库引入了额外的元数据访问点，有效解决了现有元数据字段中数据大量缺失的问题。

**Conclusion:** 使用大型语言模型丰富元数据对数字存储库特别有益，能够增强搜索结果并提高数字存储库的可访问性。

> **ai_Abstract:** 本文介绍了一个项目，该项目通过结合人工和大型语言模型，对HathiTrust数字图书馆中1920年至2020年间的英文长文本（包括论文和学位论文）的元数据进行了语义丰富和增强。研究表明，利用大型语言模型进行元数据丰富，能为数字存储库提供更多访问点，尤其对元数据缺失严重的存储库而言，显著提升了搜索效率和可访问性，为计算社会科学、数字人文和信息科学等领域提供了宝贵资源。

> **摘要翻译:** 本项目结合人工努力和大型语言模型，对从HathiTrust数字图书馆检索到的1920年至2020年间出版的英文长文本文档、论文和学位论文的元数据进行了语义丰富和增强。该数据集为计算社会科学、数字人文和信息科学等领域的研究提供了宝贵的资源。我们的论文表明，使用大型语言模型丰富元数据对于数字存储库特别有益，因为它引入了可能最初未预见到的额外元数据访问点，以适应各种内容类型。这种方法对于现有元数据字段中存在大量缺失数据的存储库尤其有效，能增强搜索结果并提高数字存储库的可访问性。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

### [450] [Automatic Reviewers Assignment to a Research Paper Based on Allied References and Publications Weight](https://arxiv.org/abs/2506.21331)
> *基于相关参考文献和出版物权重的研究论文自动审稿人分配*

*Tamim Al Mahmud, B M Mainul Hossain, Dilshad Ara* | **Category: cs.DL, cs.CV**

**Keywords:** 自动审稿人分配, 同行评审, 研究论文, 文献计量学, 作者指标

**Comment:** IEEE Conference Proceedings (5 Pages)

> **TL;DR:** 本文提出并实现了一种程序，通过分析研究论文的参考文献、作者指标（h指数、i10指数、引用量）和附属关系，自动为研究论文分配审稿人。

**AI_Comments:** 该论文的创新点在于将参考文献分析与量化作者指标（如h指数、i10指数和引用量）以及在线信息（如主页、共同作者）相结合，以实现自动化审稿人选择。这种方法旨在提高分配审稿人的相关性和专业性。潜在的局限性可能包括对公开在线数据的依赖，这些数据可能不完整或过时，以及自动获取电子邮件地址可能涉及的伦理考量。

<details>
  <summary>Details</summary>

**Motivation:** 随着研究论文数量的急剧增加和新研究领域的不断涌现，高效且准确地为研究论文选择最佳专家审稿人成为一个重大挑战。当前的同行评审过程难以确保分配的审稿人是特定领域的真正专家。

**Method:** 该研究提出并实现了一个程序，用于自动选择研究论文的最佳审稿人。具体方法包括：首先收集论文末尾的参考文献；然后统计在参考文献中至少有一篇论文的作者；接着自动浏览网络提取研究主题关键词；之后搜索特定主题的顶尖研究人员，并统计前n位作者的h指数、i10指数和引用量；随后根据得分对这n位作者进行排名；最后自动浏览他们的主页以获取电子邮件地址，并检查并排除共同作者和同事，从而确定剩余的顶尖作者为最佳审稿人。

**Result:** 未在摘要中提及

**Conclusion:** 该研究提出的程序通过利用相关参考文献、作者指标和在线信息，为研究论文自动选择最佳审稿人提供了一种新策略，旨在解决高效准确分配审稿人的挑战。

> **ai_Abstract:** 本研究旨在解决为不断增长的研究论文量高效分配专家审稿人的挑战。论文提出并实现了一个程序，通过分析研究论文的参考文献、提取研究主题关键词，并识别顶尖研究人员，然后根据其h指数、i10指数和引用量等指标进行评估和排名，来自动选择最佳审稿人。该系统还会自动获取这些作者的电子邮件地址，并排除共同作者或同事，以确定最合适的审稿人。

> **摘要翻译:** 每天，大量的研究文档被提交给会议、文集、期刊、通讯、年度报告、日报和各种期刊。许多此类出版物使用独立的外部专家来评审投稿。这个过程被称为同行评审，审稿人被称为评审员。然而，并非总是能够为评审选择最佳评审员。此外，每个领域都在出现新的研究领域，研究论文的数量正在急剧增加。为了评审所有这些论文，每个期刊都分配一个由少数评审员组成的小团队，他们可能不是所有领域的专家。例如，一篇关于通信技术的研究论文应该由来自同一领域的专家进行评审。因此，高效选择研究论文的最佳评审员是一个巨大的挑战。
在这项研究中，我们提出并实现了一个程序，该程序使用一种新策略来自动选择研究论文的最佳审稿人。每篇研究论文末尾都包含参考文献，通常来自同一领域。首先，我们收集参考文献并统计在参考文献中至少有一篇论文的作者。然后，我们自动浏览网页以提取研究主题关键词。接下来，我们搜索特定主题的顶尖研究人员，并统计前n位作者的h指数、i10指数和引用量。之后，我们根据得分对前n位作者进行排名，并自动浏览他们的主页以获取电子邮件地址。我们还会在线检查他们的共同作者和同事，并将其从列表中排除。剩余的前n位作者，通常是教授，很可能是评审研究论文的最佳审稿人。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [51] [Rational Miner Behaviour, Protocol Stability, and Time Preference: An Austrian and Game-Theoretic Analysis of Bitcoin's Incentive Environment](https://arxiv.org/abs/2506.20965)
> *理性矿工行为、协议稳定性与时间偏好：比特币激励环境的奥地利学派与博弈论分析*

*Craig Steven Wright* | **Category: econ.GN, cs.CR, cs.GT, cs.NI, q-fin.EC, q-fin.GN, 91B42, 91A25, 91B50, K.4.4; J.4; C.2.4**

**Keywords:** 矿工行为, 协议稳定性, 时间偏好, 奥地利经济学, 博弈论, 比特币

**Comment:** Approximately 10,770 words, 0 figure, 0 table. Submitted to The
  Quarterly Journal of Austrian Economics

> **TL;DR:** 论文结合奥地利资本理论和重复博弈论，分析了可变协议如何提高矿工的时间偏好，导致寻租行为，并指出比特币协议的不可变性对网络稳定的重要性。

**AI_Comments:** 这篇论文创新性地将奥地利经济学派的时间偏好理论与博弈论相结合，为理解区块链协议设计中协议可变性对矿工激励和网络稳定性的影响提供了新的视角。其强调比特币协议不可变性的重要性，对区块链治理和长期发展具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨区块链系统中不同制度条件下战略矿工的行为，特别是协议可变性对矿工激励和长期规划的影响。

**Method:** 结合奥地利资本理论和重复博弈论，进行正式的博弈论分析。

**Result:** 当协议规则可变时，有效时间偏好会上升，从而破坏理性的长期规划和合作均衡，并将矿工的激励从生产性投资转向政治寻租和影响力博弈。

**Conclusion:** 协议的不可变性对于恢复战略连贯性、创业信心和可持续网络均衡至关重要。原始比特币协议被视为一个制度锚点，能够实现可计算性和低时间偏好。

> **ai_Abstract:** 本文结合奥地利资本理论和重复博弈论，分析了区块链系统中矿工的策略行为。研究发现，可变的协议规则会提高矿工的时间偏好，从而损害长期规划并促使矿工从生产性投资转向寻租活动。论文强调了原始比特币协议作为固定规则集的重要性，认为协议的不可变性对于维持网络稳定、促进创业信心至关重要。

> **摘要翻译:** 本文将奥地利资本理论与重复博弈论相结合，考察了区块链系统在不同制度条件下的战略矿工行为。研究表明，当协议规则可变时，有效时间偏好会上升，从而破坏理性的长期规划和合作均衡。本文运用正式的博弈论分析和奥地利经济学原理，论证了可变协议如何将矿工的激励从生产性投资转向政治寻租和影响力博弈。原始比特币协议被解释为一个制度锚点：一个固定的规则集，能够实现可计算性和低时间偏好。借鉴庞巴维克、米塞斯和哈耶克的工作，本文提出协议的不可变性对于恢复战略连贯性、创业信心和可持续网络均衡至关重要。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

### [98] [Institutional Noise, Strategic Deviation, and Intertemporal Collapse: A Formal Model of Miner Behaviour under Protocol Uncertainty](https://arxiv.org/abs/2506.20992)
> *制度噪音、策略偏差与跨期崩溃：协议不确定性下矿工行为的形式模型*

*Craig Steven Wright* | **Category: econ.GN, cs.CE, cs.CY, cs.GT, cs.SI, q-fin.EC, 91A05, 91B42, 68M14, 91B62, J.4; C.2.4; K.4.1; F.1.1**

**Keywords:** 区块链, 合作挖矿, 协议不确定性, 博弈论, 制度噪音

**Comment:** 40 pages, submitted to QJAE

> **TL;DR:** 论文通过博弈论模型分析区块链协议可变性如何破坏合作挖矿行为，指出规则不确定性导致短期主义和合作崩溃，强调协议设计需稳定。

**AI_Comments:** 这篇论文通过引入博弈论模型，为理解区块链协议设计中的“制度噪音”如何影响矿工行为提供了严谨的理论框架。其创新之处在于将随机规则冲击引入重复博弈，揭示了协议不确定性对长期合作和投资的负面影响，并从奥地利经济学角度强调了规则稳定性的重要性。这对于去中心化系统（如区块链）的协议设计具有重要的实践指导意义，提示设计者需重视规则的不可变性以促进可持续发展。

<details>
  <summary>Details</summary>

**Motivation:** 探讨协议可变性如何扰乱区块链系统中的合作挖矿行为。

**Method:** 采用形式化的博弈论模型，使用带有随机规则冲击的重复博弈框架。

**Result:** 即使是微小的制度规则不确定性也会增加时间偏好并导致策略偏差。固定规则环境支持长期投资和稳定均衡策略，而可变协议导致短期主义、高贴现和协调参与的崩溃。模拟结果识别出参数空间中的不稳定区域，其中理性挖矿让位于掠夺性或套利行为。

**Conclusion:** 协议设计必须被视为一种宪法经济约束，而不是一个可自由裁量的变量，这样才能在去中心化系统中实现可持续合作。

> **ai_Abstract:** 本文构建了一个形式化的博弈论模型，旨在分析区块链协议的可变性对合作挖矿行为的影响。研究发现，即使是轻微的规则不确定性也会导致矿工的时间偏好增加和策略偏离，进而引发短期主义和协作瓦解。相反，稳定的规则环境则有利于长期投资和均衡策略。模拟结果揭示了理性挖矿行为转向掠夺或套利的“不稳定区域”。论文强调，协议设计应被视为一种宪法经济学约束，而非可变因素，以确保去中心化系统的可持续合作。

> **摘要翻译:** 本文开发了一个形式化的博弈论模型，以检验协议可变性如何扰乱区块链系统中的合作挖矿行为。通过使用一个带有随机规则冲击的重复博弈框架，我们表明即使制度规则中存在微小的不确定性也会增加时间偏好并诱导策略偏差。固定规则环境支持长期投资和稳定的均衡策略；相比之下，可变协议导致短期主义、更高的贴现率和协调参与的崩溃。模拟结果确定了参数空间中的不稳定区域，其中理性的挖矿行为让位于掠夺性或套利行为。这些发现支持奥地利经济学的解释：可计算性需要规则稳定性。制度噪音破坏了生产性行动的信息基础。我们得出结论，如果要在去中心化系统中实现可持续合作，协议设计必须被视为一种宪法经济约束，而不是一个可自由裁量的变量。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='q-finpm'></a>
## q-fin.PM 

### [72] [From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting](https://arxiv.org/abs/2506.21246)
> *从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性*

*Giorgos Demosthenous, Chryssis Georgiou, Eliada Polydorou* | **Category: q-fin.PM, cs.AI, cs.ET, cs.LG, q-fin.ST**

**Keywords:** 加密货币预测, 数据源多样性, 链上指标, 宏观经济指标, 特征降维

**Comment:** 

> **TL;DR:** 本研究发现，整合链上、情感、传统市场和宏观经济等多源数据能显著提升加密货币市场预测模型的性能，尤其强调链上指标的重要性以及传统和宏观指标对长期预测的关联性。

**AI_Comments:** 该论文的创新之处在于系统性地评估了数据源多样性对加密货币预测的影响，特别是将宏观经济和传统市场数据与加密货币特有的链上指标相结合。其重要性在于提供了多方面数据方法价值的实证证据，这有助于在波动市场中开发更准确、更具韧性的模型。Crypto100指数的引入和新颖的特征降维算法也增加了方法论的价值。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过整合多种数据类别，探讨数据源多样性对加密货币预测模型性能的影响。

**Method:** 研究整合了技术指标、链上指标、情绪和兴趣指标、传统市场指数以及宏观经济指标等多种数据类别。引入了代表市值前100位加密货币的Crypto100指数，并提出了一种新颖的特征降维算法，以识别最具影响力且稳健的特征。通过全面的实验来评估模型性能。

**Result:** 数据源多样性显著提升了预测模型在不同时间范围内的预测性能。链上指标对短期和长期预测都至关重要。传统市场指数和宏观经济指标对长期预测的关联性日益增强。利用多样化数据源能显著提高模型准确性。

**Conclusion:** 这些见解有助于揭示加密货币市场的短期和长期驱动因素，并为开发更准确、更具韧性的预测模型奠定基础。

> **ai_Abstract:** 本研究探讨了数据源多样性（包括链上指标、情感、传统市场指数和宏观经济指标等）如何提升加密货币市场预测性能。研究引入了Crypto100指数和一种新的特征降维算法。实验结果表明，数据源多样性显著提高了模型的准确性，其中链上指标对所有时间范围的预测都至关重要，而宏观指标对长期预测的重要性日益增加，这有助于构建更稳健的预测模型。

> **摘要翻译:** 本研究通过整合包括技术指标、链上指标、情绪和兴趣指标、传统市场指数以及宏观经济指标在内的各种数据类别，探讨了数据源多样性对加密货币预测模型性能的影响。我们引入了代表市值前100位加密货币的Crypto100指数，并提出了一种新颖的特征降维算法，以从多样化的数据源中识别最具影响力且稳健的特征。我们全面的实验表明，数据源多样性显著提升了预测模型在不同时间范围内的预测性能。主要发现包括：链上指标对短期和长期预测都至关重要；传统市场指数和宏观经济指标对长期预测的关联性日益增强；以及利用多样化数据源能显著提高模型准确性。这些见解有助于揭示加密货币市场的短期和长期驱动因素，并为开发更准确、更具韧性的预测模型奠定基础。

</details>

[⬆️ 返回分类顶部](#q-finpm) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [96] [ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers](https://arxiv.org/abs/2506.21537)
> *ResQ：一种在模拟里德堡原子量子计算机上实现残差神经网络的新颖框架*

*Nicholas S. DiBrita, Jason Han, Tirthak Patel* | **Category: quant-ph, cs.CV, cs.ET**

**Keywords:** 量子机器学习, 残差神经网络, 里德堡原子量子计算机, 神经常微分方程, 量子神经ODE

**Comment:** ResQ will appear in the Proceedings of the IEEE International
  Conference on Computer Vision (ICCV), 2025

> **TL;DR:** 提出ResQ框架，在模拟里德堡原子量子计算机上利用量子神经ODE实现残差神经网络，解决机器学习分类问题。

**AI_Comments:** 这篇论文的创新点在于将残差神经网络（ResNets）这一机器学习模型与模拟里德堡原子量子计算机相结合，特别是引入了量子神经ODE的概念。它探索了量子计算在加速机器学习，特别是复杂网络结构方面的潜力，为量子机器学习领域开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算在加速机器学习方面的潜力巨大，但基于神经常微分方程（neural ODE）的残差神经网络（ResNets）尚未在量子计算机上探索。本研究旨在填补这一空白，并利用模拟里德堡原子量子计算机的优势实现ResNets。

**Method:** 作者提出了ResQ，一个新颖的框架，用于优化里德堡原子量子计算机的动力学，以利用模拟量子神经ODE解决机器学习中的分类问题。他们还阐述了模拟里德堡原子量子计算机特别适合ResNets的原因。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了ResQ，一个新颖的框架，旨在将基于神经常微分方程的残差神经网络（ResNets）应用于模拟里德堡原子量子计算机。研究指出量子计算在机器学习中的潜力，并阐述了模拟里德堡原子量子计算机为何特别适合ResNets。ResQ框架通过优化里德堡原子量子计算机的动力学，利用模拟量子神经ODE来解决机器学习中的分类问题。

> **摘要翻译:** 量子机器学习研究最近因量子计算加速机器学习的潜力而迅速发展。机器学习中一个尚未探索的领域是基于神经常微分方程（neural ODE）的残差神经网络（ResNets），其旨在利用常微分方程的原理提高神经网络的有效性。在这项工作中，我们提出了关于模拟里德堡原子量子计算机为何特别适合ResNets的见解。我们还介绍了ResQ，一个新颖的框架，用于优化里德堡原子量子计算机的动力学，以利用模拟量子神经ODE解决机器学习中的分类问题。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [288] [Quantum Adaptive Search: A Hybrid Quantum-Classical Algorithm for Global Optimization of Multivariate Functions](https://arxiv.org/abs/2506.21124)
> *量子自适应搜索：一种用于多元函数全局优化的混合量子-经典算法*

*G. Intoccia, U. Chirico, V. Schiano Di Cola, G. Pepe, S. Cuomo* | **Category: quant-ph, cs.NA, math.NA, math.OC**

**Keywords:** 量子自适应搜索, 全局优化, 混合量子-经典算法, 多元函数, 计算复杂度

**Comment:** 

> **TL;DR:** QAGS是一种混合量子-经典算法，通过量子估计概率分布自适应缩小搜索空间，实现多元函数全局优化，相较于经典方法具有更高的精度和更好的时间和空间复杂度。

**AI_Comments:** QAGS的创新之处在于其混合量子-经典架构和自适应搜索机制，通过量子方法指导经典优化，有效提升了全局优化的效率和精度。其在时间和空间复杂度上的优势表明了量子计算在解决复杂优化问题方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提出一种用于多元函数全局优化的混合量子-经典算法。

**Method:** 提出量子自适应搜索（QAGS），该算法采用自适应机制，根据目标函数的量子估计概率分布动态缩小搜索空间。量子态通过复数幅度映射编码解的质量信息，识别最有希望的区域并逐步收紧搜索边界；然后经典优化器对解进行局部优化。

**Result:** QAGS确保搜索空间向全局最优解收缩，并具有可控的计算复杂度。在基准函数上的数值结果表明，与经典方法相比，QAGS实现了更高的精度，并在时间和空间复杂度方面具有优势。

**Conclusion:** QAGS是一种有效的混合量子-经典算法，用于多元函数的全局优化，相比经典方法具有更高的精度和更好的计算复杂度。

> **ai_Abstract:** 本文介绍了一种名为量子自适应搜索（QAGS）的混合量子-经典算法，用于多元函数的全局优化。该算法利用量子估计的概率分布自适应地缩小搜索空间，通过量子态编码解的质量信息来识别有希望的区域并逐步收紧搜索范围，最后由经典优化器进行局部细化。研究表明，QAGS能有效收敛至全局最优解，并具有可控的计算复杂度。与传统方法相比，QAGS在基准测试中表现出更高的精度以及在时间和空间复杂度上的优势。

> **摘要翻译:** 这项工作提出了量子自适应搜索（QAGS），一种用于多元函数全局优化的混合量子-经典算法。该方法采用自适应机制，根据目标函数的量子估计概率分布动态缩小搜索空间。量子态通过适当的复数幅度映射编码解质量信息，从而能够识别最有希望的区域，并因此逐步收紧搜索边界；然后经典优化器对解进行局部细化。分析表明，QAGS确保搜索空间向全局最优解收缩，并具有可控的计算复杂度。基准函数上的数值结果表明，与经典方法相比，QAGS实现了更高的精度，同时在时间和空间复杂度方面都提供了优势。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [433] [Quantum Reinforcement Learning Trading Agent for Sector Rotation in the Taiwan Stock Market](https://arxiv.org/abs/2506.20930)
> *量子强化学习交易代理在台湾股市的行业轮动应用*

*Chi-Sheng Chen, Xinyu Zhang, Ya-Chuan Chen* | **Category: quant-ph, cs.LG, q-fin.CP**

**Keywords:** 量子强化学习, 行业轮动, 台湾股市, 金融应用, 奖励不匹配

**Comment:** 

> **TL;DR:** 本文提出了一个用于台湾股市行业轮动的混合量子-经典强化学习框架，发现量子增强模型在训练奖励上表现更好，但在实际投资指标（如累积回报和夏普比率）上不如经典模型，这揭示了强化学习在金融领域中代理奖励信号与真实投资目标不匹配的核心挑战。

**AI_Comments:** 本文创新性地将量子强化学习应用于股票市场行业轮动，并提供了量子增强模型与经典模型在实际金融应用中的对比基准。其重要性在于揭示了量子强化学习在金融领域应用时面临的核心挑战，即代理奖励与真实投资目标之间的不匹配问题，以及NISQ量子电路的局限性。研究指出了当前奖励设计可能导致过拟合短期波动的问题，为未来该领域的研究提供了明确的改进方向，如奖励塑形和正则化，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索量子强化学习在金融领域的应用，特别是台湾股市的行业轮动，并评估其性能。解决强化学习应用于金融领域时代理奖励信号与真实投资目标不匹配的问题。

**Method:** 提出一个混合量子-经典强化学习框架，以PPO为核心算法。结合经典架构（LSTM, Transformer）和量子增强模型（QNN, QRWKV, QASA）作为策略和价值网络。使用自动化特征工程从资本份额数据中提取金融指标。

**Result:** 经验回测显示，量子增强模型在训练奖励上始终更高，但在累积回报和夏普比率等实际投资指标上表现不如经典模型。这种差异突显了强化学习应用于金融领域时代理奖励信号与真实投资目标不匹配的核心挑战。分析表明，当前的奖励设计可能激励对短期波动过拟合，而非优化风险调整后的回报。

**Conclusion:** 量子增强模型在金融强化学习中面临奖励与性能差距的挑战，主要原因是代理奖励信号与真实投资目标不匹配，以及NISQ约束下量子电路的固有表达性和优化不稳定性。文章为部署量子强化学习提供了可复现的基准和关键见解，并提出了未来的改进方向。

> **ai_Abstract:** 本文提出了一个用于台湾股市行业轮动的混合量子-经典强化学习框架。该框架以PPO为基础，结合了经典（LSTM, Transformer）和量子增强（QNN, QRWKV, QASA）模型。研究发现，尽管量子模型在训练奖励上表现优异，但在实际投资指标（如回报和夏普比率）上却不及经典模型。这揭示了强化学习在金融应用中代理奖励与真实目标不匹配的挑战，并指出当前的奖励设计可能导致过拟合短期波动。文章讨论了这种性能差距，并提出了改进策略，为量子强化学习在金融领域的实际部署提供了重要见解和可复现的基准。

> **摘要翻译:** 我们提出了一个用于台湾股市行业轮动的混合量子-经典强化学习框架。我们的系统采用近端策略优化（PPO）作为核心算法，并集成了经典架构（LSTM、Transformer）和量子增强模型（QNN、QRWKV、QASA）作为策略和价值网络。自动化特征工程管道从资本份额数据中提取金融指标，以确保所有配置的模型输入一致。经验回测揭示了一个关键发现：尽管量子增强模型始终实现更高的训练奖励，但在累积回报和夏普比率等实际投资指标上，它们的表现不如经典模型。这种差异突显了将强化学习应用于金融领域的核心挑战——即代理奖励信号与真实投资目标之间的不匹配。我们的分析表明，当前的奖励设计可能激励对短期波动过拟合，而不是优化风险调整后的回报。这个问题因噪声中等规模量子（NISQ）约束下量子电路固有的表达性和优化不稳定性而加剧。我们讨论了这种奖励-性能差距的影响，并提出了未来改进的方向，包括奖励塑形、模型正则化和基于验证的早期停止。我们的工作提供了一个可复现的基准，并为在实际金融中部署量子强化学习的实际挑战提供了关键见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matsoft'></a>
## cond-mat.soft 

### [99] [Pull-off strength of mushroom-shaped fibrils adhered to rigid substrates](https://arxiv.org/abs/2506.20745)
> *蘑菇状纤维粘附于刚性基底的剥离强度*

*C. Betegón, C. Rodríguez, E. Martínez-Pañeda, R. M. McMeeking* | **Category: cond-mat.soft, cond-mat.mtrl-sci, cs.CE, physics.app-ph, physics.bio-ph**

**Keywords:** 蘑菇状纤维, 剥离强度, 粘附, Dugdale内聚区模型, 仿生粘合剂

**Comment:** 

> **TL;DR:** 研究利用计算方法分析蘑菇状纤维的剥离行为，发现分离过程在载荷控制下不稳定，宽薄的蘑菇帽能增强粘附，中心缺陷会显著降低剥离强度。

**AI_Comments:** 这项研究通过计算模拟深入分析了蘑菇状纤维的粘附机制，揭示了其剥离过程的不稳定性以及结构参数（如蘑菇帽形状）和缺陷对粘附性能的关键影响。这些发现对于设计和优化高性能仿生粘合剂和微结构表面具有重要的理论和实践指导意义，有助于推动相关工程应用的发展。

<details>
  <summary>Details</summary>

**Motivation:** 生物纤维结构（如壁虎）卓越的粘附性能启发了合成粘附表面的开发，其中蘑菇状纤维显示出优越的剥离强度，因此需要深入理解其脱离行为以优化设计。

**Method:** 本研究采用基于Dugdale内聚区模型的计算方法，分析了蘑菇状纤维粘附于刚性基底时的脱离行为。

**Result:** 1. 提供了完整的剥离曲线，显示分离过程在载荷控制下本质上是不稳定的，无论脱离是从纤维边缘还是中心开始。
2. 宽而薄的蘑菇帽能有效减少应力集中并促进中心脱离，从而增强粘附。
3. 并非所有几何形状都观察到中心脱离，但在所有情况下，边缘脱离在特定条件下都可能发生。
4. 纤维中心的粘附缺陷会显著降低剥离强度，特别是在无量纲参数\c{hi}较高时。

**Conclusion:** 这些研究结果有助于优化仿生粘合剂和微结构表面，应用于各种工程领域。

> **ai_Abstract:** 本文通过基于Dugdale内聚区模型的计算方法，深入分析了蘑菇状纤维与刚性基底的剥离行为。研究发现，脱离过程在载荷控制下不稳定，且宽薄的蘑菇帽能有效降低应力集中，促进中心脱离以增强粘附力。同时，揭示了中心粘附缺陷对剥离强度的显著负面影响。这些发现为优化仿生粘合剂和微结构表面提供了重要指导。

> **摘要翻译:** 生物纤维结构（如壁虎身上的）卓越的粘附性能启发了合成粘附表面的开发。其中，蘑菇状纤维与其他几何形状相比，表现出优越的剥离强度。在这项研究中，我们采用基于Dugdale内聚区模型的计算方法，分析了这些纤维粘附到刚性基底时的脱离行为。结果提供了完整的剥离曲线，揭示了分离过程在载荷控制下本质上是不稳定的，无论脱离是从纤维边缘还是中心开始。我们的发现表明，具有宽而薄的蘑菇帽的纤维能有效减少应力集中并促进中心脱离，从而增强粘附。然而，并非所有几何形状都观察到中心脱离，而在所有情况下，边缘脱离在特定条件下都可能发生。此外，我们研究了纤维中心粘附缺陷的影响，表明它们可以显著降低剥离强度，特别是在无量纲参数\c{hi}值较高时。这些见解有助于优化仿生粘合剂和微结构表面，应用于各种工程领域。

</details>

[⬆️ 返回分类顶部](#cond-matsoft) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [120] [Evolution and determinants of firm-level systemic risk in local production networks](https://arxiv.org/abs/2506.21426)
> *地方生产网络中企业层面系统性风险的演变与决定因素*

*Anna Mancini, Balázs Lengyel, Riccardo Di Clemente, Giulio Cimini* | **Category: physics.soc-ph, cs.SI, econ.GN, physics.data-an, q-fin.EC, q-fin.RM**

**Keywords:** 系统性风险, 生产网络, 供应链韧性, 企业适应性, COVID-19

**Comment:** 15 pages, 4 figures

> **TL;DR:** 本研究分析了匈牙利生产网络中企业层面的系统性风险及其决定因素，发现企业在危机中（如COVID-19）的适应性行为显著降低了系统性风险，提高了经济韧性，并指出国际贸易量是系统性风险的重要预测因子。

**AI_Comments:** 本研究的创新之处在于强调了企业在危机中通过重构供应链来适应环境的能力，并量化了这种适应性对系统性风险的影响。通过使用零模型作为基准，该研究能够突出实际生产网络中适应性行为的重要性，这对于理解和构建更具韧性的经济体系具有重要意义。同时，对国际贸易量作为预测因子的发现也为政策制定提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 近期危机（如COVID-19大流行和地缘政治紧张）暴露了供应链的脆弱性，导致产品短缺、成本增加和经济不稳定。这促使人们越来越努力评估系统性风险。然而，企业通过重新连接供应环节来应对危机的能力在很大程度上被忽视，限制了我们对生产网络韧性的理解。

**Method:** 本研究调查了2015年至2022年匈牙利生产网络中企业层面系统性风险的动态和决定因素。研究使用启发式最大熵零模型作为基准，该模型通过保留每个企业在部门层面的总投入（需求）和产出（供应）来生成一组处于均衡状态的生产网络。

**Result:** 研究发现，系统性风险最高的企业集合在COVID-19期间发生了结构性变化，促成经济交易的企业成为经济中的关键参与者，这一结果无法通过零模型重现。尽管经验系统性风险在疫情爆发前与零模型值吻合良好，但此后显著减小，因为企业的适应性行为导致了更具韧性的经济。此外，企业的国际贸易量（作为中断的对象）成为其系统性风险的重要预测因子。然而，国际联系不能为观察到的趋势提供明确的解释，因为进口和出口通过供需渠道对当地系统性风险产生相反的影响。

**Conclusion:** 企业在危机中的适应性行为可以显著降低系统性风险，提高经济韧性。国际贸易量是企业系统性风险的重要预测因子，但其对系统性风险的影响复杂，进口和出口的作用可能相反。

> **ai_Abstract:** 本研究探讨了在危机背景下（如COVID-19）地方生产网络中企业层面系统性风险的演变和决定因素。通过分析2015年至2022年匈牙利生产网络数据，并使用最大熵零模型进行对比，研究发现企业在疫情期间展现出结构性适应行为，使得具有高系统性风险的企业集合发生变化，并且这种适应性行为显著降低了整体系统性风险，增强了经济韧性。此外，研究揭示了企业的国际贸易量是其系统性风险的重要预测因子，尽管进出口通过不同渠道对局部系统性风险产生复杂且相反的影响。

> **摘要翻译:** 最近的危机，如COVID-19大流行和地缘政治紧张，暴露了供应链的脆弱性，并导致中断，从而引发产品短缺、成本增加和经济不稳定。这促使人们越来越努力评估系统性风险，即企业中断对整个经济体的影响。然而，企业通过重新连接供应环节来应对危机的能力在很大程度上被忽视，限制了我们对生产网络韧性的理解。本研究调查了2015年至2022年匈牙利生产网络中企业层面系统性风险的动态和决定因素。我们使用启发式最大熵零模型作为基准，该模型通过保留每个企业在部门层面的总投入（需求）和产出（供应）来生成一组处于均衡状态的生产网络。我们发现，系统性风险最高的、相对稳定的企业集合在COVID-19期间发生了结构性变化，因为那些促成经济交易的企业成为经济中的关键参与者——这一结果无法通过零模型重现。尽管经验系统性风险在疫情爆发前与零模型值吻合良好，但此后显著减小，因为企业的适应性行为导致了更具韧性的经济。此外，企业的国际贸易量（作为中断的对象）成为其系统性风险的重要预测因子。然而，国际联系不能为观察到的趋势提供明确的解释，因为进口和出口通过供需渠道对当地系统性风险产生相反的影响。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [162] [Linear codes arising from the point-hyperplane geometry-Part I: the Segre embedding](https://arxiv.org/abs/2506.21309)
> *线性码的产生源于点-超平面几何-第一部分：Segre嵌入*

*Ilaria Cardinali, Luca Giuzzi* | **Category: math.CO, cs.DM, cs.IT, math.IT, 51E22, 94B05, 14M12**

**Keywords:** 线性码, Segre嵌入, 射影几何, 极小码, 权重列表

**Comment:** 29 pages

> **TL;DR:** 本文研究了由Segre几何的特定子簇$\\Lambda_1$生成的线性码$\\mathcal{C}(\\Lambda_1)$，确定了其基本参数、权重列表和自同构群，并对其特殊权重码字进行了几何表征。

**AI_Comments:** 这篇论文通过将代数几何中的Segre嵌入与编码理论相结合，为构建和分析新型线性码提供了一个具体的例子。其创新之处在于利用几何结构$\\Lambda_1$来定义码，并深入分析其编码属性，这对于理解码的结构和设计具有重要意义。特别地，对码字进行几何表征是其亮点，有助于从几何直观上理解码的性质。

<details>
  <summary>Details</summary>

**Motivation:** 该论文研究了从Segre几何的特定子簇$\\Lambda_1$产生的线性码$\\mathcal{C}(\\Lambda_1)$，其动机在于深入理解这类特殊几何结构生成的线性码的性质和参数。

**Method:** 论文将$\\Lambda_1$视为射影系统，研究了由此产生的线性码$\\mathcal{C}(\\Lambda_1)$。具体方法包括确定其基本参数、完整的权重列表和线性自同构群，并对其最小、第二低权重码字以及部分最大权重码字进行了几何表征。

**Result:** 代码$\\mathcal{C}(\\Lambda_1)$被证明是极小码。论文确定了其基本参数、完整的权重列表和线性自同构群。此外，还对最小和第二低权重码字以及部分最大权重码字进行了几何表征。

**Conclusion:** 论文成功地研究了从Segre几何的特定子簇$\\Lambda_1$产生的线性码$\\mathcal{C}(\\Lambda_1)$，并全面描述了其编码特性和几何结构。

> **ai_Abstract:** 本文研究了从Segre几何的特定子簇$\\Lambda_1$（由满足$\\xi(x)=0$的纯张量$x\\\\otimes \\xi$构成）产生的线性码$\\mathcal{C}(\\Lambda_1)$。该码被证明是极小码。研究内容包括确定其基本编码参数、完整的权重分布以及线性自同构群。此外，论文还从几何角度对该码的最小、第二低以及部分最大权重码字进行了精确刻画。

> **摘要翻译:** 设$V$是有限域$\\mathbb{F}_q$上的一个向量空间，$\\Lambda$是Segre几何$\\mathrm{PG}(V)\\\\otimes\\\\mathrm{PG}(V^*)$在$\\mathrm{PG}(V\\\\otimes V^*)$中的像。考虑$\\Lambda$的一个子簇$\\Lambda_{1}$，它由纯张量$x\\\\otimes \\xi$表示，其中$x\\\\in V$和$\\xi\\\\in V^*$满足$\\xi(x)=0$。将$\\Lambda_1$视为$\\mathrm{PG}(V\\\\otimes V^*)$的一个射影系统，我们研究由此产生的线性码$\\mathcal{C}(\\Lambda_1)$。代码$\\mathcal{C}(\\Lambda_1)$是一个极小码，我们确定了它的基本参数、完整的权重列表和线性自同构群。我们还对其最小和第二低权重码字以及部分最大权重码字进行了几何表征。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [197] [Structural System Identification via Validation and Adaptation](https://arxiv.org/abs/2506.20799)
> *结构系统识别通过验证和适应*

*Cristian López, Keegan J. Moore* | **Category: math.DS, cs.LG, cs.SY, eess.SY**

**Keywords:** 结构系统识别, 生成建模, 神经网络, 参数估计, 模型验证

**Comment:** 

> **TL;DR:** 提出了一种基于生成模型和判别器网络的结构系统识别新方法，可直接从数据中估计参数并进行模型验证。

**AI_Comments:** 该论文创新性地将生成对抗网络（GAN）的思想应用于结构系统识别领域，通过引入判别器网络实现了参数学习与模型验证的同步进行，提升了系统识别的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 估计控制方程参数对于整合实验数据与科学理论以理解、验证和预测复杂系统的动态至关重要。

**Method:** 该方法受生成建模框架启发，使用一个神经网络将随机噪声映射到具有物理意义的参数。这些参数被用于已知的运动方程以生成“假”加速度，并通过均方误差损失与真实的训练数据进行比较。为了同时验证学习到的参数，引入了独立的验证数据集，由一个判别器网络评估生成的加速度是否真实或虚假，并指导参数生成器网络。

**Result:** 分析实验和真实实验结果表明了该方法在不同非线性结构系统上的参数估计准确性和模型验证能力。

**Conclusion:** 该方法能够准确估计结构系统参数并有效进行模型验证，为复杂系统的动力学理解和预测提供了新途径。

> **ai_Abstract:** 本文提出了一种新颖的结构系统识别方法，该方法融合了生成建模的思想，利用神经网络将噪声转化为物理参数，并通过运动方程生成预测值。通过结合均方误差损失和独立的判别器网络对验证数据集的评估，该方法不仅能估计系统参数，还能同时进行模型验证和不确定性量化。实验结果证实了其在非线性结构系统参数估计和模型验证方面的有效性。

> **摘要翻译:** 估算控制方程参数值对于将实验数据与科学理论相结合以理解、验证和预测复杂系统的动力学至关重要。在这项工作中，我们提出了一种直接从数据进行结构系统识别（SI）、不确定性量化和验证的新方法。受生成建模框架的启发，一个神经网络将随机噪声映射到具有物理意义的参数。然后，这些参数用于已知的运动方程中以获得伪加速度，并通过均方误差损失与真实的训练数据进行比较。为了同时验证学习到的参数，我们使用独立的验证数据集。来自这些数据集生成的加速度由一个判别器网络评估，该网络判断输出是真实的还是伪造的，并指导参数生成器网络。分析和真实实验表明了不同非线性结构系统的参数估计准确性和模型验证能力。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [208] [Detecting weighted hidden cliques](https://arxiv.org/abs/2506.21543)
> *加权隐藏团的检测*

*Urmisha Chatterjee, Karissa Huang, Ritabrata Karmakar, B. R. Vinay Kumar, Gábor Lugosi, Nandan Malhotra, Anirban Mandal, Maruf Alam Tarafdar* | **Category: math.ST, cs.IT, math.IT, math.PR, stat.TH, 62F03**

**Keywords:** 加权隐藏团, 假设检验, 谱测试, 统计极限, 图算法

**Comment:** 

> **TL;DR:** 本文研究了加权图中的隐藏团检测问题，将其建模为假设检验问题，并提出了在已知和部分已知分布情况下的统计界限和计算高效的谱测试方法。

**AI_Comments:** 这篇论文通过将经典的隐藏团问题推广到加权图，并采用假设检验的框架，为该领域带来了新的视角。其创新点在于考虑了边权信息，并区分了完全已知和部分已知分布的场景。提出计算高效的谱测试，并在k=\Omega(\sqrt{n})的条件下提供检测保证，具有重要的理论和实践意义。这为处理更复杂的图数据提供了工具。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在将经典的隐藏团问题推广到具有实值边权的图上，以解决在边权图上检测隐藏团的挑战。

**Method:** 研究方法是定义一个假设检验问题：零假设下边权来自分布P，备择假设下k个顶点间的边权来自分布Q，其余来自P。研究分为两种场景：P和Q完全已知，以及P和Q仅部分已知。在两种场景下，都提供了计算高效的谱测试方法来区分两种假设。

**Result:** 在第一种场景下，得到了两种假设可区分和不可区分时k的统计极限。在两种场景下，当Q不对P绝对连续时，提供了假设检验问题最小风险的界限。此外，在两种场景下，只要k=\Omega(\sqrt{n})，所提出的计算高效谱测试就能区分两种假设。

**Conclusion:** 论文成功地将经典隐藏团问题推广到加权图，并提出了在不同信息已知程度下有效的检测方法，特别是当隐藏团大小k达到\Omega(\sqrt{n})时，能够通过谱测试进行有效区分。

> **ai_Abstract:** 本文探讨了加权图中的隐藏团检测问题，将其形式化为一个假设检验框架。研究了两种情况：当边权分布P和Q完全已知时，以及当它们仅部分已知时。研究工作包括确定在不同条件下隐藏团大小k的统计可区分性极限，以及在特定分布条件下的最小风险界限。更重要的是，论文提出了一种计算高效的谱测试方法，该方法在两种场景下均能有效检测隐藏团，只要隐藏团的大小k至少为\Omega(\sqrt{n})。

> **摘要翻译:** 我们研究了经典隐藏团问题向具有实值边权的图的推广。形式上，我们定义了一个假设检验问题。在零假设下，一个n个顶点的完全图的边权与来自分布P的独立同分布边权相关联。在备择假设下，随机选择k个顶点，它们之间的边权来自分布Q，而其余边权从P中采样。目标是在观察到边权后，判断它们是由哪种假设生成的。我们在两种不同场景下研究了这个问题：(1) 当P和Q完全已知时，以及 (2) 当P和Q只有部分信息时。在第一种场景中，我们获得了当两种假设可区分和不可区分时k的统计极限。此外，在每种场景中，当Q不对P绝对连续时，我们提供了假设检验问题最小风险的界限。我们还提供了计算高效的谱测试，在两种场景下，只要k=\Omega(\sqrt{n})，这些测试就能区分两种假设。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [209] [Thinning to improve two-sample discrepancy](https://arxiv.org/abs/2506.20932)
> *稀疏化以改善两样本差异*

*Gleb Smirnov, Roman Vershynin* | **Category: math.PR, cs.DS**

**Keywords:** 两样本差异, 稀疏化, 在线算法, 复杂度降低, 统计学

**Comment:** 7 pages

> **TL;DR:** 通过丢弃少量点，一个简单的在线算法可以将两样本差异从$O(\sqrt{n})$降低到$O(\log^{2d} n)$。

**AI_Comments:** 这项工作提出了一种创新且高效的方法来处理两样本差异问题。其创新点在于使用“稀疏化”（丢弃点）的策略来达到显著的差异降低效果，并且算法是“在线”的，这可能意味着其在实时应用中具有潜力。将差异从多项式量级降低到对数多项式量级是一个显著的改进，对需要高精度样本匹配的应用非常有价值。

<details>
  <summary>Details</summary>

**Motivation:** 两独立样本之间的差异通常为$O(\sqrt{n})$量级，即使在简单的一维情况下也是如此，这表明在比较或分析样本时存在显著的变异性或不匹配问题。

**Method:** 提出了一种简单的在线算法，通过丢弃一小部分点来减少样本间的差异。

**Result:** 该算法成功将两样本差异从典型的$O(\sqrt{n})$降低到$O(\log^{2d} n)$的量级。

**Conclusion:** 通过对样本进行稀疏化处理（丢弃少量点），可以显著降低两独立样本之间的统计差异，从而提高样本间的匹配或比较质量。

> **ai_Abstract:** 本论文提出了一种简单的在线算法，旨在解决从相同分布中抽取的两独立样本之间通常存在的$O(\sqrt{n})$量级的差异问题。通过策略性地丢弃一小部分样本点，该算法能够显著地将样本差异降低到$O(\log^{2d} n)$的量级，从而提高了样本间的匹配和比较效率。

> **摘要翻译:** 从$\mathbb{R}^d$上的相同分布中抽取的两个独立样本$X_1,\dots,X_n$和$Y_1,\dots,Y_n$之间的差异，即使在一维情况下，通常也具有$O(\sqrt{n})$的量级。我们提供了一种简单的在线算法，通过丢弃一小部分点，将差异减少到$O(\log^{2d} n)$。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [212] [IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation](https://arxiv.org/abs/2506.20696)
> *IMC-PINN-FE：一种结合图像运动一致性和生物力学参数估计的患者特异性左心室有限元建模的物理信息神经网络*

*Siyu Mu, Wei Xuan Chan, Choon Hwai Yap* | **Category: physics.med-ph, cs.AI, eess.IV**

**Keywords:** 物理信息神经网络, 有限元建模, 心脏生物力学, 图像运动一致性, 患者特异性

**Comment:** 

> **TL;DR:** IMC-PINN-FE是一种结合图像运动一致性的物理信息神经网络，能快速、准确地进行患者特异性左心室有限元建模和生物力学参数估计。

**AI_Comments:** 该论文提出了一种创新的结合了图像运动一致性的物理信息神经网络（IMC-PINN-FE），显著提升了患者特异性心脏生物力学建模的效率和准确性。其创新点在于将图像运动数据整合到PINN框架中，实现了材料属性的反向计算和更好的运动保真度。该方法将计算时间从数小时缩短到数秒，大大提高了临床应用的潜力。此外，通过利用单个受试者的运动数据，减少了对大型数据集的依赖，增强了患者特异性，这对个性化医疗具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 阐明心肌生物力学行为对理解心脏生理学至关重要，但无法直接从临床影像中推断；传统的有限元方法计算成本高且难以重现观察到的心脏运动。

**Method:** 提出IMC-PINN-FE框架，将图像运动一致性（IMC）与有限元建模相结合。首先使用预训练的注意力网络或无监督循环正则化网络从MRI或超声心动图估计心脏运动并提取运动模式。然后，IMC-PINN-FE通过拟合临床压力测量值快速估计心肌刚度和主动张力，并将计算时间从数小时缩短到数秒。基于这些参数，它以75倍的速度进行整个心动周期的有限元建模。

**Result:** 计算速度从数小时缩短到数秒（逆向有限元建模）；有限元建模速度提高75倍；通过运动约束，与图像位移匹配更准确，平均Dice系数从0.849提高到0.927；同时保留了真实的压力-容积行为。

**Conclusion:** IMC-PINN-FE为快速、个性化和图像一致的心脏生物力学建模提供了一种稳健高效的方法，通过引入材料属性的反向计算和更好的运动保真度，改进了之前的PINN-FE模型。

> **ai_Abstract:** IMC-PINN-FE是一个创新的物理信息神经网络框架，旨在解决传统有限元方法在心脏生物力学建模中计算昂贵且运动匹配不准确的问题。它通过整合图像运动一致性，能够从临床影像中快速估计心脏运动模式，并结合压力测量值高效地反演出心肌力学参数。该方法显著加速了患者特异性左心室有限元建模过程，并显著提高了模型与实际图像运动的匹配度，同时减少了对大量数据集的依赖，提升了患者特异性。

> **摘要翻译:** 阐明心肌的生物力学行为对于理解心脏生理学至关重要，但无法直接从临床影像中推断，通常需要有限元（FE）模拟。然而，传统的有限元方法计算成本高，并且通常无法重现观察到的心脏运动。我们提出了IMC-PINN-FE，一个物理信息神经网络（PINN）框架，它将图像运动一致性（IMC）与有限元建模相结合，用于患者特异性左心室（LV）生物力学。心脏运动首先使用预训练的基于注意力网络或无监督循环正则化网络从MRI或超声心动图估计，然后提取运动模式。IMC-PINN-FE通过拟合临床压力测量值快速估计心肌刚度和主动张力，与传统逆向有限元相比，将计算时间从数小时加速到数秒。基于这些参数，它以75倍的速度在整个心动周期内执行有限元建模。通过运动约束，它更准确地匹配图像位移，将平均Dice系数从0.849提高到0.927，同时保持了真实的压力-容积行为。IMC-PINN-FE通过引入材料属性的反向计算和更好的运动保真度，改进了之前的PINN-FE模型。使用单个受试者的运动来重建形状模式也避免了对大型数据集的需求，并提高了患者特异性。IMC-PINN-FE为快速、个性化和图像一致的心脏生物力学建模提供了一种稳健高效的方法。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [222] [Guarding Offices with Maximum Dispersion](https://arxiv.org/abs/2506.21307)
> *以最大离散度守卫办公室*

*Sándor P. Fekete, Kai Kobbe, Dominik Krupke, Joseph S. B. Mitchell, Christian Rieck, Christian Scheffer* | **Category: cs.CG, cs.DS, F.2.2**

**Keywords:** 分散艺术画廊问题,正交多边形,NP完全性,算法,守卫问题

**Comment:** 40 pages, 29 figures, to appear in the proceedings 50th International
  Symposium on Mathematical Foundations of Computer Science (MFCS 2025)

> **TL;DR:** 本文研究了办公室状正交多边形上的分散艺术画廊问题，旨在最大化守卫之间的最小测地L1距离，并提供了复杂性结果和算法。

**AI_Comments:** 本文创新性地将分散艺术画廊问题应用于更贴近实际的办公室状多边形，并考虑了矩形可见性。其重要性在于不仅提供了理论上的复杂性分析（NP完全/难），还开发了实用的多项式时间算法，并证明了对于某些大规模实例，通过SAT求解器能够高效地找到最优解，这结合了理论深度与实践价值。解决了Rieck和Scheffer提出的开放问题也增加了其学术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究顶点守卫和矩形可见性（r-可见性）下分散艺术画廊问题，针对反映真实世界平面图特性的办公室状正交多边形，目标是最大化任意两个守卫之间的最小测地L1距离（称为分散距离），而非最小化守卫数量。

**Method:** 研究方法包括：证明了在某些条件下（如顶点为整数坐标）确定分散距离为4是NP完全的；提出了一种保证分散距离为3的多项式时间最坏情况最优算法；证明了当顶点坐标为有理数时，实现2+ε的分散距离是NP难的；提出了一种计算分散距离为2的最坏情况最优解的简单多项式时间算法；对于无孔独立办公室状多边形，提出了一种动态规划方法计算最优解；比较了基于SAT、CP和MIP公式的求解器，以评估实际可处理性。

**Result:** 主要结果包括：证明了在办公室状多边形中，当顶点坐标限制为整数时，确定顶点守卫集是否能实现4的分散距离是NP完全的；提出了一种能在多项式时间内保证3的分散距离的简单最坏情况最优算法；证明了当顶点坐标允许为有理数时，实现2+ε的分散距离对任何ε > 0都是NP难的；给出了一个计算分散距离为2的最坏情况最优解的直接多项式时间算法；对于无孔独立办公室状多边形，动态规划方法可以计算最优解；SAT求解器能够高效地计算随机生成实例的最优解，对于多达1600个顶点的实例，可在15秒内完成。

**Conclusion:** 本文全面分析了办公室状多边形上的分散艺术画廊问题，确立了其复杂性结果，并开发了高效算法，同时通过比较不同求解器证明了在某些情况下问题的实际可处理性。

> **ai_Abstract:** 本文研究了办公室状正交多边形中的分散艺术画廊问题，其目标是最大化顶点守卫之间的最小L1测地距离。研究证明了在特定条件下（如整数或有理坐标）实现某些分散距离（如4和2+ε）是NP完全或NP难的，并提出了能在多项式时间内保证分散距离为3和2的最坏情况最优算法。此外，对于更受限的无孔独立办公室状多边形，提出了动态规划方法，并通过实验证明了SAT求解器在处理大规模实例时的有效性。

> **摘要翻译:** 我们研究了顶点守卫和矩形可见性（r-可见性）下的分散艺术画廊问题，针对一类反映真实世界平面图特性的正交多边形：这些办公室状多边形由矩形房间和走廊组成。在分散艺术画廊问题中，目标不是最小化守卫的数量，而是最大化任意两个守卫之间的最小测地L1距离，这被称为分散距离。
我们的主要贡献如下。我们证明了在办公室状多边形中，当多边形的顶点限制为整数坐标时，确定顶点守卫集是否能实现4的分散距离是NP完全的。此外，我们提出了一种简单的最坏情况最优算法，该算法能在多项式时间内保证3的分散距离。我们的复杂性结果扩展到多连块，解决了Rieck和Scheffer（CGTA 2024）提出的一个开放问题。当顶点坐标允许为有理数时，我们建立了类似的结论，证明了对于任何ε > 0，实现2+ε的分散距离是NP难的，而对于这类多边形，经典的艺术画廊问题仍然可以在多项式时间内解决。此外，我们给出了一种直接的多项式时间算法，可以计算分散距离为2的最坏情况最优解。
另一方面，对于更受限制的无孔独立办公室状多边形，我们提出了一种动态规划方法来计算最优解。此外，我们证明了该问题对于任意正交多边形在实践中是可处理的。为此，我们比较了基于SAT、CP和MIP公式的求解器。值得注意的是，SAT求解器能够高效地计算随机生成实例的最优解，对于多达1600个顶点的实例，可在15秒内完成。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='physicsacc-ph'></a>
## physics.acc-ph 

### [223] [Estimation of superconducting cavity bandwidth and detuning using a Luenberger observer](https://arxiv.org/abs/2506.21207)
> *使用Luenberger观测器估计超导腔带宽和失谐*

*Bozo Richter, Andrea Bellandi, Julien Branlard, Leon Speidel, Annika Eichler* | **Category: physics.acc-ph, cs.SY, eess.SY**

**Keywords:** 超导腔, 带宽, 失谐, Luenberger观测器, 参数估计

**Comment:** 10 pages, 4 figures, to be published in APS Physical Review -
  Accelerator and Beams

> **TL;DR:** 本文提出使用Luenberger观测器估计超导腔的带宽和失谐，该方法无需显式滤波，并可直观控制误差收敛。

**AI_Comments:** 这篇论文的创新点在于引入Luenberger观测器来解决超导腔参数估计问题，其优势在于无需显式滤波和可控的误差收敛性，这对于实时控制系统来说非常重要。这种方法有望提高未来直线加速器的运行效率和稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 未来的连续波直线加速器需要精确跟踪超导腔的带宽和失谐参数，以了解超导状态并最小化运行功耗。

**Method:** 本文提出使用Luenberger观测器来计算超导腔的带宽和失谐。

**Result:** 该方法能够在控制系统原始采样率下提供估计值，无需显式滤波输入信号，并且可以通过调整增益参数直观地控制估计的误差收敛特性。论文中还介绍了实现考虑事项和测试结果。

**Conclusion:** Luenberger观测器为超导腔带宽和失谐的估计提供了一种有效且可控的新方法，优于传统方法，有望提高直线加速器的运行效率和稳定性。

> **ai_Abstract:** 本文介绍了一种利用Luenberger观测器估算超导腔带宽和失谐的新方法。该方法旨在满足未来连续波直线加速器对精确参数跟踪的需求，以优化腔体性能。与现有技术相比，Luenberger观测器无需对输入信号进行显式滤波，即可在控制系统的原始采样率下提供估计，并且其误差收敛特性可以通过增益参数直观地调整。论文中还讨论了该观测器的实现细节和测试结果。

> **摘要翻译:** 借助于超导技术的进步，未来十年预计将出现数个连续波直线加速器。对于这些机器来说，跟踪主要腔体参数，如谐振器带宽和失谐，至关重要。带宽提供了腔体超导状态的信息。失谐应最小化以限制操作腔体所需的功率。这些参数的估计通常在低电平射频控制系统的数字电子设备中实现，以最小化计算延迟。在本论文中，我们提出了一种使用Luenberger观测器计算带宽和失谐的方法。与以前的方法相比，状态观测器能够在原始控制系统采样率下提供估计，而无需显式滤波输入信号。此外，通过调整增益参数，可以直观地控制估计的误差收敛特性。手稿中介绍了派生观测器的实现考虑和测试结果。

</details>

[⬆️ 返回分类顶部](#physicsacc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [228] [E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs](https://arxiv.org/abs/2506.20944)
> *E-FreeM2：基于多模态大语言模型的训练无关多尺度跨模态新闻验证*

*Van-Hoang Phan, Long-Khanh Pham, Dang Vu, Anh-Duy Tran, Minh-Son Dao* | **Category: cs.MM, cs.CR**

**Keywords:** 多模态事实核查, 无需训练, 检索式, 虚假信息检测, MLLMs

**Comment:** Accepted to AsiaCCS 2025 @ SCID

> **TL;DR:** E-FreeM2是一个无需训练、基于检索的多模态事实核查系统，利用预训练视觉-语言模型和大型语言模型，有效检测虚假信息并抵御攻击，适用于移动和无线网络环境。

**AI_Comments:** E-FreeM2的创新之处在于其“无需训练”和“基于检索”的范式，这有效规避了传统训练模型易受对抗性攻击和数据投毒的固有缺陷。其轻量级设计也使其能够无缝集成到边缘设备，具有重要的实际应用价值。在当前虚假信息泛滥的背景下，这项研究为提升网络安全和信息可信度提供了新的、高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 移动和无线网络中虚假信息的快速传播带来了严峻的安全挑战，传统基于训练的模型存在对抗性攻击和数据投毒等漏洞。

**Method:** 本研究提出了一个名为E-FreeM2的无需训练、基于检索的多模态事实核查系统。它利用预训练的视觉-语言模型和大型语言模型进行可信度评估，通过动态检索和交叉引用可信数据源来缓解传统训练模型的漏洞。此外，其轻量级设计支持在边缘设备上无缝集成。

**Result:** 在两个事实核查基准测试上取得了SOTA（State-of-the-Art）结果，证实了其在虚假信息检测方面的有效性以及对各种攻击向量的鲁棒性。

**Conclusion:** E-FreeM2系统能够有效检测虚假信息并抵御攻击，有望增强移动和无线通信环境的安全性。

> **ai_Abstract:** 本研究提出E-FreeM2，一个无需训练、基于检索的多模态事实核查系统，旨在解决移动和无线网络中的虚假信息传播问题。该系统利用预训练的视觉-语言模型和大型语言模型，通过动态检索和交叉引用可信数据源来评估信息可信度，从而规避了传统训练模型面临的对抗性攻击和数据投毒等风险。E-FreeM2设计轻量化，易于在边缘设备上部署。实验结果表明，该系统在事实核查基准测试中取得了最先进的性能，并展现出对多种攻击的鲁棒性，有望显著提升移动和无线通信环境的安全性。

> **摘要翻译:** 移动和无线网络中虚假信息的快速传播带来了严峻的安全挑战。本研究引入了一种无需训练、基于检索的多模态事实核查系统，该系统利用预训练的视觉-语言模型和大型语言模型进行可信度评估。通过动态检索和交叉引用可信数据源，我们的方法减轻了传统基于训练模型的脆弱性，例如对抗性攻击和数据投毒。此外，其轻量级设计使得无需大量的设备端处理即可实现无缝的边缘设备集成。在两个事实核查基准测试上的实验取得了SOTA结果，证实了其在虚假信息检测方面的有效性以及对各种攻击向量的鲁棒性，突显了其在增强移动和无线通信环境安全性方面的潜力。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [232] [MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models](https://arxiv.org/abs/2506.20686)
> *MegaFold: 用于加速蛋白质结构预测模型的系统级优化*

*Hoa La, Ahan Gupta, Alex Morehead, Jianlin Cheng, Minjia Zhang* | **Category: q-bio.BM, cs.DC, cs.LG, cs.PF**

**Keywords:** 蛋白质结构预测, AlphaFold3, 系统优化, MegaFold, 训练加速

**Comment:** 13 pages, 12 figures

> **TL;DR:** MegaFold是一个跨平台系统，通过系统级优化显著加速了AlphaFold3等蛋白质结构预测模型的训练，减少了内存使用并提高了训练效率，同时支持更长的序列长度。

**AI_Comments:** MegaFold的创新之处在于其系统级的优化方法，针对当前最先进的蛋白质结构预测模型（如AlphaFold3）的训练瓶颈提出了多方面的解决方案。其结合了数据管道优化（提前缓存）、算子优化（Triton内核、深度融合）以及跨平台支持，有效提升了训练效率和内存利用率。这项工作对于推动AI在生物分子领域的应用，特别是加速蛋白质结构预测模型的研发和部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** AlphaFold3（AF3）等蛋白质结构预测模型虽然推动了生物分子建模的边界，但其训练成本高昂，存在计算和内存密集型操作、2D注意力机制以及检索增强数据管道等问题，这些都严重阻碍了AF3训练的可扩展性。

**Method:** MegaFold通过以下方法解决关键瓶颈：1. 提前缓存以消除检索增强数据管道中的GPU空闲时间。2. 基于Triton的内核，在异构设备上实现内存高效的EvoAttention。3. 对AF3中常见且关键的小型操作进行深度融合。

**Result:** 在NVIDIA H200和AMD MI250 GPU上的评估表明，MegaFold将AF3训练的峰值内存使用量降低了高达1.23倍，并将每次迭代的训练时间分别提高了高达1.73倍和1.62倍。更重要的是，MegaFold能够训练比PyTorch基线长1.35倍的序列长度而不会出现内存不足，显著提高了现代蛋白质折叠模型的可扩展性。

**Conclusion:** MegaFold通过系统级优化，有效解决了蛋白质结构预测模型（如AlphaFold3）训练中的计算和内存瓶颈，显著提升了训练效率和可扩展性，使其能够处理更长的蛋白质序列。

> **ai_Abstract:** 本研究介绍了MegaFold，一个旨在加速AlphaFold3（AF3）等蛋白质结构预测模型训练的跨平台系统。针对AF3训练中计算和内存密集、2D注意力以及检索增强数据管道等瓶颈，MegaFold采用了提前缓存、基于Triton的内存高效内核以及深度融合等优化技术。实验结果表明，MegaFold显著降低了AF3训练的峰值内存使用量，提高了训练速度，并使得模型能够处理更长的蛋白质序列，从而极大地提升了现代蛋白质折叠模型的可扩展性。

> **摘要翻译:** 蛋白质结构预测模型，如AlphaFold3 (AF3)，通过将科学信息架构变化融入Transformer架构，推动了生物分子建模的前沿。然而，这些进步带来了巨大的系统成本，引入了：计算和内存密集型操作、2D注意力机制以及检索增强数据管道，这些共同阻碍了AF3训练的可扩展性。在这项工作中，我们提出了MegaFold，一个用于加速AF3训练的跨平台系统。MegaFold通过提前缓存来消除检索增强数据管道中的GPU空闲时间、基于Triton的内核在异构设备上实现内存高效的EvoAttention，以及对AF3中常见和关键的小型操作进行深度融合，解决了关键瓶颈。在NVIDIA H200和AMD MI250 GPU上的评估表明，MegaFold将AF3训练的峰值内存使用量降低了高达1.23倍，并将每次迭代的训练时间分别提高了高达1.73倍和1.62倍。更重要的是，MegaFold能够训练比PyTorch基线长1.35倍的序列长度而不会出现内存不足，显著提高了现代蛋白质折叠模型的可扩展性。我们已将代码开源在https://github.com/Supercomputing-System-AI-Lab/MegaFold/。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

### [385] [CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions](https://arxiv.org/abs/2506.21085)
> *CovDocker：用任务、数据集和解决方案基准测试共价药物设计*

*Yangzhe Peng, Kaiyuan Gao, Liang He, Yuheng Cong, Haiguang Liu, Kun He, Lijun Wu* | **Category: q-bio.BM, cs.AI, cs.LG**

**Keywords:** 共价药物设计, 分子对接, 基准测试, 共价结合, CovDocker

**Comment:** Accepted to KDD 2025 Research Track

> **TL;DR:** CovDocker是一个用于共价对接的新基准，旨在解决现有方法在处理共价键方面的局限性，提供任务、数据集和解决方案以推进共价药物设计。

**AI_Comments:** CovDocker通过为共价对接提供一个结构化的基准，弥补了传统对接方法在该领域长期存在的不足，具有创新性。它将共价对接过程分解为具体任务，并利用先进模型建立基线，为未来的共价药物设计研究奠定了坚实基础，解决了药物发现中一个关键需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数分子对接方法和深度学习方法难以考虑共价键的形成和相关的结构变化，这限制了共价药物设计的发展。

**Method:** 将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过调整Uni-Mol和Chemformer等先进模型来建立基线性能。

**Result:** 建立了基线性能，并证明了该基准在准确预测相互作用位点和模拟共价结合中涉及的分子转化方面的有效性。

**Conclusion:** CovDocker基准为推进共价药物设计研究提供了一个严谨的框架，并强调了数据驱动方法在加速选择性共价抑制剂发现和解决治疗开发关键挑战方面的潜力。

> **ai_Abstract:** CovDocker通过引入一个全面的基准，解决了当前分子对接方法在处理共价键方面的局限性。它将共价对接分解为反应位点预测、共价反应预测和共价对接三个任务。通过调整先进模型，CovDocker证明了其在预测相互作用位点和模拟分子转化方面的有效性，为推进共价药物设计提供了一个严谨的框架，并加速了选择性共价抑制剂的发现。

> **摘要翻译:** 分子对接在预测配体与靶蛋白的结合模式中起着关键作用，而共价相互作用，即配体与靶点之间形成共价键，因其强效、持久的结合性质而特别有价值。然而，大多数现有的对接方法和深度学习方法很难考虑到共价键的形成和相关的结构变化。为了弥补这一空白，我们引入了一个全面的共价对接基准CovDocker，旨在更好地捕捉共价结合的复杂性。我们将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过调整Uni-Mol和Chemformer等先进模型，我们建立了基线性能，并证明了该基准在准确预测相互作用位点和模拟共价结合中涉及的分子转化方面的有效性。这些结果证实了该基准作为推进共价药物设计研究的严谨框架的作用。它强调了数据驱动方法在加速选择性共价抑制剂发现方面的潜力，并解决了治疗开发中的关键挑战。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [235] [Exact Time-Varying Turnpikes for Dynamic Operation of District Heating Networks](https://arxiv.org/abs/2506.21239)
> *区域供热网络动态运行的精确时变转轨*

*Max Rose, Hannes Gernandt, Timm Faulwasser, Johannes Schiffer* | **Category: math.OC, cs.SY, eess.SY**

**Keywords:** 区域供热网络, 时变转轨, 最优控制, 模型预测控制, 耗散性

**Comment:** 

> **TL;DR:** 本文研究了区域供热网络优化中的时变转轨现象，推导了唯一时变奇弧的存在条件和闭合形式表达式，并证明了精确时变转轨意味着最优控制问题的严格耗散性。

**AI_Comments:** 本文的创新点在于将转轨现象引入到区域供热网络的优化中，特别是在处理时变价格和需求方面。这为设计更精确、更鲁棒的模型预测控制提供了理论基础，有助于提高区域供热网络的运行效率和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 区域供热网络对供热部门脱碳至关重要，但其高效可靠运行需协调多个热源并考虑未来需求。现有预测和基于优化的控制方法未考虑时变问题。

**Method:** 通过分析具有时变价格和需求的最优控制问题，研究转轨现象在区域供热网络优化中的作用，并推导了唯一时变奇弧的存在条件及其闭合形式表达式，还提出了逆转轨结果。

**Result:** 推导了构成时变转轨的唯一时变奇弧的存在条件及其闭合形式表达式。展示了精确时变转轨情况意味着最优控制问题的严格耗散性。通过数值例子验证了发现。

**Conclusion:** 通过分析最优控制问题，证明了时变转轨现象在区域供热网络优化中的重要性，并为设计和分析模型预测控制提供了基础。

> **ai_Abstract:** 本文研究了区域供热网络优化中的时变转轨现象，以应对现有控制方法未能考虑时变问题的问题。作者通过分析具有时变价格和需求的最优控制问题，推导了构成时变转轨的唯一时变奇弧的存在条件及其闭合形式表达式。研究还提出了逆转轨结果，证明了精确时变转轨意味着最优控制问题的严格耗散性，并通过数值例子进行了说明。

> **摘要翻译:** 区域供热网络（DHN）对于供热部门的脱碳至关重要。然而，它们的有效和可靠运行需要协调多个热力生产商并考虑未来的需求。预测和基于优化的控制通常用于解决此任务，但现有针对DHN的结果并未考虑时变问题方面。由于转轨现象可以作为模型预测控制设计和分析的基础，本文通过分析具有时变价格和需求的基本最优控制问题，探讨其在DHN优化中的作用。也就是说，我们推导了唯一时变奇弧（构成时变转轨）的存在条件，并提供了其闭合形式表达式。此外，我们提出了逆转轨结果，表明精确时变情况意味着最优控制问题的严格耗散性。一个数值例子说明了我们的发现。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [415] [Control and optimization for Neural Partial Differential Equations in Supervised Learning](https://arxiv.org/abs/2506.20764)
> *监督学习中神经偏微分方程的控制与优化*

*Alain Bensoussan, Minh-Binh Tran, Bangjie Wang* | **Category: math.OC, cs.LG**

**Keywords:** 神经网络, 偏微分方程, 控制理论, 优化, 监督学习

**Comment:** 

> **TL;DR:** 本文提出将神经网络解释为偏微分方程（PDEs），并解决了PDE系数的控制与优化问题，证明了抛物线和双曲线方程情况下极小值/解的存在性。

**AI_Comments:** 本文通过将神经网络与偏微分方程控制理论相结合，提供了一个新颖的理论视角，特别关注了系数优化这一未充分探索的领域。其主要创新在于将监督学习问题重新构建在偏微分方程框架内，并提供了基础性的存在性证明，这对于开发新的神经网络优化算法至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管关于抛物线和双曲线系统的控制和优化问题已有大量文献，但在神经网络和监督学习背景下，控制和优化相关算子系数的具体问题尚未得到彻底探索。PDE控制理论中尚未系统地解决这一特定问题。

**Method:** 本文提出将神经网络解释为偏微分方程。将传统的常微分方程（ODE）控制问题重新表述为针对抛物线和双曲线算子系数优化的偏微分方程控制问题。对于抛物线PDEs，提出了对偶系统公式。对于双曲线PDEs，研究了相关控制问题并证明了近似控制问题解的存在性。

**Result:** 为抛物线PDEs的控制和优化问题提出了对偶系统公式，为未来开发高效数值方案奠定了基础。理论证明了抛物线PDEs的控制和优化问题存在极小值。证明了与双曲线PDEs相关的近似控制问题解的存在性。

**Conclusion:** 本文开创了在神经网络背景下控制和优化偏微分方程算子系数的研究方向，为抛物线和双曲线情况提供了极小值/解的理论存在性证明，为未来的数值方案奠定了基础。

> **ai_Abstract:** 本文提出将神经网络解释为偏微分方程（PDEs），以解决监督学习中偏微分方程算子系数控制和优化的未探索问题。它将传统的基于常微分方程的控制问题重新表述为偏微分方程控制问题。作者为抛物线PDEs开发了对偶系统公式，并证明了极小值的存在性，同时证明了双曲线PDEs近似控制问题解的存在性，为未来的数值方法奠定了理论基础。

> **摘要翻译:** 尽管关于抛物线和双曲线系统的控制和优化问题已有大量文献，但在此类系统中控制和优化相关算子系数的具体问题尚未得到彻底探索。在这项工作中，我们旨在开创控制理论中的一个研究方向，专注于优化和控制这些算子的系数——这个问题自然地出现在神经网络和监督学习的背景下。在监督学习中，主要目标是通过神经网络的层将初始数据传输到目标数据。我们提出了一种新颖的视角：神经网络可以被解释为偏微分方程（PDEs）。从这个角度来看，传统上在常微分方程（ODEs）背景下研究的控制问题被重新表述为偏微分方程的控制问题，特别是针对抛物线和双曲线算子中系数的优化和控制。据我们所知，PDE控制理论中尚未系统地解决这个具体问题。为此，我们为与抛物线PDE相关的控制和优化问题提出了一个对偶系统公式，为未来研究中开发高效数值方案奠定了基础。我们还提供了理论证明，表明抛物线PDE的控制和优化问题存在极小值。最后，我们研究了与双曲线PDE相关的控制问题，并证明了相应近似控制问题解的存在性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [428] [Faster Fixed-Point Methods for Multichain MDPs](https://arxiv.org/abs/2506.20910)
> *多链MDPs的更快不动点方法*

*Matthew Zurek, Yudong Chen* | **Category: math.OC, cs.LG, stat.ML**

**Keywords:** 多链MDPs, 值迭代, 平均奖励, 不动点方法, 收敛速度

**Comment:** 

> **TL;DR:** 本文研究了多链马尔可夫决策过程（MDPs）在平均奖励准则下的值迭代（VI）算法，并开发了能更快收敛的新算法，提高了收敛速度并扩展了VI方法的理论基础。

**AI_Comments:** 本文在解决多链马尔可夫决策过程（MDPs）的平均奖励问题方面取得了显著进展，通过开发新的算法有效提升了值迭代（VI）的收敛速度。其创新性在于提出了一种更好地解决导航子问题的方法，并建立了平均奖励问题与折扣问题之间的新颖联系，这对于理论研究和实际应用都具有重要意义。此外，将最优不动点方法扩展到一般巴纳赫空间，以及发现新的次线性收敛率和精细的次优分解，都进一步丰富了VI方法的理论基础。这些贡献有望为解决更复杂的决策问题提供更高效的工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究平均奖励准则下的多链马尔可夫决策过程（MDPs）是一个基础但理论上具有挑战性的问题。由于贝尔曼算子缺乏收缩性和解的非唯一性，以及多链设置中需要解决导航子问题，导致现有方法存在收敛速度慢等困难。

**Method:** 开发了新的算法，这些算法更好地解决了多链MDPs中的导航子问题，以实现更快的收敛速度。方法包括平均奖励问题与折扣问题之间的新颖联系，以及适用于一般巴纳赫空间的折扣VI最优不动点方法。

**Result:** 获得了相对于现有工作更高的收敛速度和更精确的复杂性度量。具体成果包括：平均奖励问题与折扣问题之间的新颖联系，适用于一般巴纳赫空间的折扣VI最优不动点方法，折扣值误差的新次线性收敛率，以及多链MDPs的精细次优分解。

**Conclusion:** 本研究的结果为折扣和平均奖励问题带来了更快的收敛速度，并扩展了值迭代（VI）方法的理论基础。

> **ai_Abstract:** 本文研究了平均奖励准则下多链马尔可夫决策过程（MDPs）的值迭代（VI）算法。针对该设置中贝尔曼算子缺乏收缩性、解非唯一性以及导航子问题带来的挑战，作者开发了新的算法，能够更好地解决导航子问题，从而实现更快的收敛。研究成果包括提高了收敛速度和复杂度度量，发现了平均奖励问题与折扣问题之间的新联系，提出了适用于一般巴纳赫空间的折扣VI最优不动点方法，得到了折扣值误差的新次线性收敛率，并对多链MDPs进行了精细的次优分解。总体而言，这些结果加快了折扣和平均奖励问题的收敛速度，并扩展了VI方法的理论基础。

> **摘要翻译:** 我们研究了在平均奖励准则下解决通用（又称多链）马尔可夫决策过程（MDPs）的值迭代（VI）算法，这是一个基础但理论上具有挑战性的设置。除了贝尔曼算子缺乏收缩性和解的非唯一性给所有平均奖励问题带来的固有困难之外，在多链设置中，最优策略除了优化每个组件内的长期性能外，还必须解决导航子问题，即转向最佳连接组件。我们开发了能够更好解决这一导航子问题的算法，以实现多链MDPs的更快收敛，从而相对于先前工作获得了更高的收敛速度和更精确的复杂性度量。我们结果中的许多关键组件都具有潜在的独立兴趣，包括平均奖励问题与折扣问题之间的新颖联系，适用于一般巴纳赫空间的折扣VI最优不动点方法，折扣值误差的新次线性收敛率，以及多链MDPs的精细次优分解。总的来说，我们的结果为折扣和平均奖励问题带来了更快的收敛速度，并扩展了VI方法的理论基础。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='physicsins-det'></a>
## physics.ins-det 

### [256] [Plasmonically Enhanced Flexural-Mode AlScN Nanoplate Resonator as Uncooled and Ultrafast IR Detector with High Responsivity](https://arxiv.org/abs/2506.21412)
> *等离子体增强弯曲模式AlScN纳米板谐振器作为非制冷超快高响应红外探测器*

*Aurelio Venditti, Walter Gubinelli, Enise F. Altin, Luca Colombo, Pietro Simeoni, Benyamin Davaji, Matteo Rinaldi* | **Category: physics.ins-det, cs.SY, eess.SY, physics.app-ph**

**Keywords:** AlScN纳米板, 红外探测器, 谐振器, 等离子体增强, 非制冷

**Comment:** This manuscript has been submitted to ACS Nano Letters for
  consideration

> **TL;DR:** 本文介绍了一种基于AlScN纳米板的新型小型化、非制冷、超快红外谐振热探测器，利用等离子体吸收和弯曲模式谐振实现了高响应度和快速响应，并有望用于创新的红外热成像。

**AI_Comments:** 该论文的创新点在于首次将等离子体吸收器与AlScN纳米板谐振器结合，用于红外探测，并且利用了AlScN的高机电耦合特性。其重要性在于提供了一种高性能、小型化、非制冷且响应速度快的红外探测方案，有望推动红外热成像技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 目前的红外谐振热探测器存在性能限制。本文旨在通过引入基于AlScN纳米板的新型探测器，利用其高机电耦合、良好热性能和增强的红外吸收，实现对现有技术的显著改进，以开发出具有紧凑尺寸、高光谱选择性、高响应度、低噪声和快速热响应的器件。

**Method:** 本文介绍了一种基于30%掺杂的AlScN纳米板的新型小型化、非制冷、超快红外谐振热探测器。该器件利用AlScN的高机电耦合、良好热性能和增强的红外选择性吸收。谐振模式的弯曲特性支持干涉光学读出，并且首次在谐振平台上实验性地集成了以AlScN作为介电层的等离子体吸收器。

**Result:** 该探测器实现了约130 ppt/pW的高红外响应度，约330 µs的热时间常数，以及大的面外位移。这些结果证明了其在紧凑尺寸、高光谱选择性和响应度、低噪声和快速热响应方面的能力。

**Conclusion:** 本文成功演示了基于等离子体增强弯曲模式AlScN纳米板谐振器作为非制冷超快红外探测器，其高性能（高响应度、快响应时间）和集成等离子体吸收器的创新性，为开发新型红外热成像仪奠定了基础，并有望实现极低的噪声等效功率。

> **ai_Abstract:** 本研究介绍了一种新型小型化、非制冷、超快红外谐振热探测器，其核心是30%掺杂的AlScN纳米板。该探测器利用AlScN优异的机电耦合、热性能和增强的红外吸收，结合等离子体吸收器和弯曲模式谐振，实现了高响应度（约130 ppt/pW）和快速热响应（约330 µs）。该器件具有紧凑尺寸、高光谱选择性和低噪声，为开发创新的多像素红外热成像仪和实现极低噪声等效功率提供了潜力。

> **摘要翻译:** 这封信介绍了一种基于30%掺杂的氮化铝钪（AlScN）纳米板的新型小型化、非制冷、超快红外（IR）谐振热探测器（RTDs）。该器件利用高机电耦合、良好的热性能以及增强和选择性的红外吸收，旨在展示对现有红外RTD技术的显著进步。这种单像素结合了紧凑的尺寸、高光谱选择性和响应度、降低的噪声和快速的热响应，从而有可能通过多像素集成开发创新的红外热成像仪。驱动谐振模式的弯曲性质最终实现了干涉光学读出，为实现极低的噪声等效功率水平铺平了道路。这些结果展示了约130 ppt/pW的高红外响应度、约330 µs的热时间常数和大的面外位移。这项工作代表了首次在谐振平台上实验性地集成了以AlScN作为介电层的等离子体吸收器。

</details>

[⬆️ 返回分类顶部](#physicsins-det) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [260] [Benchmarking and Parallelization of Electrostatic Particle-In-Cell for low-temperature Plasma Simulation by particle-thread Binding](https://arxiv.org/abs/2506.21524)
> *基于粒子-线程绑定的低温等离子体模拟静电粒子网格法基准测试与并行化*

*Libn Varghese, Bhaskar Chaudhury, Miral Shah, Mainak Bandyopadhyay* | **Category: physics.comp-ph, cs.DC, physics.plasm-ph**

**Keywords:** 粒子网格法, 并行化, 电荷沉积, 等离子体模拟, 扩展性

**Comment:** 

> **TL;DR:** 本文提出了一种基于粒子-线程绑定的新型并行化方法，用于解决粒子网格法（PIC）模拟中电荷沉积（CD）子例程的计算瓶颈和传统方法的扩展性问题，并在共享内存和分布式内存系统上展示了其良好的扩展性和性能。

**AI_Comments:** 该论文提出了一种新颖且高效的并行化策略，解决了粒子网格法（PIC）模拟中长期存在的电荷沉积（CD）计算瓶颈和传统并行化方法的扩展性问题。其创新点在于采用了粒子-线程绑定，并显著减少了私有网格的需求，从而在保持代码兼容性的同时实现了出色的扩展性和性能。这对于大规模等离子体模拟的计算效率提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 粒子网格法（PIC）在二维和三维设备尺度的等离子体模拟中计算成本很高，其中电荷沉积（CD）子例程由于频繁的粒子-网格交互而成为瓶颈。传统的并行化方法通过为每个核心生成私有网格来缓解依赖性，但这种方法面临扩展性问题。

**Method:** 提出了一种基于粒子-线程绑定策略的新方法。该方法在分布式内存系统中每个节点仅需四个私有网格，在共享内存系统中也只需四个私有网格，从而增强了CD的扩展性和性能，同时保持了传统的粒子网格数据结构，并对现有PIC代码的改动最小。该方法通过附加函数和标志确保并发线程对网格数据结构的完全可访问性，并避免了同一单元内粒子之间的同时访问。

**Result:** 在共享内存和分布式内存系统（1000个核心）上，使用低温部分磁化E x B放电模拟的PIC基准测试进行了性能评估，结果表明该方法具有良好的扩展性，并且硬件依赖性很小。

**Conclusion:** 所提出的基于粒子-线程绑定的方法显著增强了电荷沉积（CD）的扩展性和性能，同时对现有PIC代码的修改量很小。

> **ai_Abstract:** 本文针对粒子网格法（PIC）模拟中电荷沉积（CD）子例程的计算瓶颈和传统并行化方法的扩展性问题，提出了一种创新的粒子-线程绑定策略。该策略通过显著减少所需的私有网格数量（每个节点或系统仅四个）来提高CD的扩展性和性能，同时保持现有PIC代码的结构不变。通过在共享内存和分布式内存系统上对低温等离子体模拟进行基准测试，验证了该方法的有效性和低硬件依赖性。

> **摘要翻译:** 粒子网格法（PIC）用于等离子体模拟，通过粒子和网格数据结构跟踪粒子相空间信息。二维和三维设备尺度的PIC模拟计算成本高昂，因此需要并行化，其中电荷沉积（CD）子例程由于频繁的粒子-网格交互而常常成为瓶颈。传统方法通过为每个核心生成私有网格来缓解依赖性，但这种方法面临扩展性问题。我们提出了一种基于粒子-线程绑定策略的新方法，在分布式内存系统中每个节点仅需四个私有网格，或在共享内存系统中仅需四个私有网格，从而增强了CD的扩展性和性能，同时保持了传统的粒子网格数据结构，并对现有PIC代码的改动最小。该方法确保并发线程对网格数据结构的完全可访问性，并通过附加函数和标志避免了同一单元内粒子之间的同时访问。使用低温部分磁化E x B放电模拟的PIC基准测试在共享内存以及分布式内存系统（1000个核心）上进行了性能评估，结果表明该方法具有良好的扩展性，并且硬件依赖性很小。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [284] [Evaluating PDE discovery methods for multiscale modeling of biological signals](https://arxiv.org/abs/2506.20694)
> *评估用于生物信号多尺度建模的偏微分方程发现方法*

*Andréa Ducos, Audrey Denizot, Thomas Guyet, Hugues Berry* | **Category: q-bio.QM, cs.AI**

**Keywords:** PDE发现, 多尺度建模, 生物信号, 钙扩散, 星形胶质细胞

**Comment:** 

> **TL;DR:** 本文评估了五种先进的偏微分方程（PDE）发现方法，通过粒子模拟来从微观数据中推断生物系统的介观尺度动力学，结果表明这些方法能够准确恢复扩散项，展示了PDE发现从微观数据捕捉宏观动力学的潜力。

**AI_Comments:** 该论文提出了一种新颖的方法，通过结合粒子模拟和PDE发现来解决生物系统多尺度建模的挑战。其创新性在于利用PDE发现从微观数据中推断介观尺度动力学，这对于理解复杂生物过程至关重要。研究通过对钙扩散的模拟评估了多种SOTA方法，结果令人鼓舞，表明PDE发现有望成为连接不同尺度生物现象的有效工具。然而，目前仅限于初步实验和受控设置，未来的工作可能需要更复杂的生物系统和实验数据来验证其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 生物系统具有非线性、包含未观测变量且其动力学物理原理部分未知，这使得描述其行为极具挑战性。此外，生物活动发生在多个相互依赖的时空尺度上，需要跨尺度连接机制。为了解决跨尺度鸿沟的挑战，本研究利用偏微分方程（PDE）发现。

**Method:** 本文提出了一个结合粒子模拟和PDE发现的框架，并在受控环境下进行初步实验以评估方程发现能力。具体来说，研究评估了五种最先进的PDE发现方法，针对星形胶质细胞中钙扩散的粒子模拟数据进行测试。方法的性能通过发现方程的形式和钙浓度预测的时间变化进行评估。

**Result:** 研究结果表明，有几种方法能够准确地恢复扩散项。

**Conclusion:** 偏微分方程（PDE）发现方法在从微观数据中捕捉生物系统的宏观动力学方面具有巨大潜力。

> **ai_Abstract:** 本研究旨在评估偏微分方程（PDE）发现方法在生物信号多尺度建模中的应用。鉴于生物系统行为描述的挑战性（非线性、未观测变量、未知物理原理及多尺度活动），研究提出了一个结合粒子模拟与PDE发现的框架，旨在从微观数据中推断介观尺度的动力学。通过对星形胶质细胞中钙扩散的粒子模拟数据，评估了五种先进PDE发现方法的性能，评估指标包括发现方程的形式和钙浓度的时间预测。结果显示，多种方法能准确恢复扩散项，证实了PDE发现从微观数据捕捉生物系统宏观动力学的潜力。

> **摘要翻译:** 生物系统是非线性的，包含未观测变量，并且其动力学所遵循的物理原理部分未知。这使得描述其行为变得非常具有挑战性。值得注意的是，它们的活动发生在多个相互依赖的空间和时间尺度上，需要跨尺度连接机制。为了解决弥合尺度之间差距的挑战，我们利用偏微分方程（PDE）发现。PDE发现从微观数据中推断出介观尺度的动力学特征。在本文中，我们提出了一个结合粒子模拟和PDE发现的框架，并进行了初步实验以评估受控环境下的方程发现能力。我们评估了五种最先进的PDE发现方法，针对星形胶质细胞中钙扩散的粒子模拟数据。方法的性能通过发现方程的形式和钙浓度预测的时间变化进行评估。我们的结果表明，有几种方法能够准确地恢复扩散项，突出了PDE发现从微观数据中捕捉生物系统宏观动力学的潜力。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [291] [Surrogate normal-forms for the numerical bifurcation and stability analysis of navier-stokes flows via machine learning](https://arxiv.org/abs/2506.21275)
> *基于机器学习的纳维-斯托克斯流数值分岔和稳定性分析的代理范式*

*Alessandro Della Pia, Dimitrios G. Patsatzis, Gianluigi Rozza, Lucia Russo, Constantinos Siettos* | **Category: physics.flu-dyn, cs.NA, math.NA**

**Keywords:** 代理范式, 纳维-斯托克斯流, 数值分岔, 稳定性分析, 机器学习

**Comment:** 26 pages, 14 figures

> **TL;DR:** 本文提出了一种基于机器学习的“嵌入-学习-提升”框架，通过构建代理范式（极小维度降阶模型）来对高维纳维-斯托克斯流进行高效准确的数值分岔和稳定性分析。

**AI_Comments:** 这项工作创新性地将机器学习（特别是流形学习和高斯过程回归）与传统的数值分岔分析相结合，为高维复杂流体动力学系统的分析提供了一种计算效率高的新途径。其“嵌入-学习-提升”框架概念清晰，有效地克服了全空间分析的计算瓶颈，对于理解和预测复杂流动的行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 对高维纳维-斯托克斯流进行数值分岔和稳定性分析因计算成本高昂而难以在全空间中进行。

**Method:** 该框架分为四步：1. 流形学习揭示纳维-斯托克斯动力学的内在潜在维度；2. 利用高斯过程回归（GPR）在潜在空间中构建低维“范式”降阶模型；3. 使用这些模型，在潜在空间中应用数值分岔工具计算分岔图并进行稳定性分析；4. 解决原像问题以重建原始高维空间中的分岔结构。

**Result:** 该方法成功识别了潜在维度，并构建了基于GPR的代理范式，从而能够追踪和分析分岔解（包括极限环、其周期和稳定性），并在无限圆柱绕流和平面突扩通道流这两个典型流场上进行了验证，分别展示了Andronov-Hopf分岔和叉式分岔。

**Conclusion:** 基于机器学习的“嵌入-学习-提升”框架能够有效地构建代理范式，从而实现对高维纳维-斯托克斯流的计算效率高且准确的数值分岔和稳定性分析，解决了全空间分析计算成本过高的问题。

> **ai_Abstract:** 本文提出了一种名为“嵌入-学习-提升”的机器学习框架，用于从高保真纳维-斯托克斯模拟中构建代理范式（最小维度降阶模型）。该框架通过流形学习识别潜在维度，利用高斯过程回归构建低维模型，进而在潜在空间中高效执行数值分岔和稳定性分析（包括极限环），最后将结果重建回原始高维空间。该方法在两个典型流场中得到了验证，有效解决了高维流体动力学分析的计算难题。

> **摘要翻译:** 受无方程多尺度建模方法的启发，本文展示了“嵌入-学习-提升”框架如何能够从高保真纳维-斯托克斯模拟中构建代理范式，即最小维度的降阶模型（ROMs）。这些代理模型随后被用于高效准确的分岔和稳定性分析。该框架分为四个步骤。首先，流形学习揭示了跨参数空间的高维时空纳维-斯托克斯动力学的内在潜在维度。其次，我们利用高斯过程回归（GPR）在该潜在空间中构建了低维“范式”类降阶模型，捕捉了涌现的动力学。第三，利用这些模型，我们应用数值分岔工具来计算潜在空间中的分岔图并进行稳定性分析。这包括追踪由Andronov-Hopf分岔产生的极限环分支——这些任务在全空间中因计算成本高昂而难以处理。最后，解决原像问题允许在原始高维空间中重建分岔结构。我们在两个典型流场上演示了该方法：无限圆柱绕流和平面突扩通道流。随着雷诺数的增加，它们分别表现出Andronov-Hopf分岔和叉式分岔。我们的方法识别了潜在维度并构建了基于GPR的代理范式，从而能够追踪和分析分岔解，包括极限环、它们的周期以及通过Floquet乘数确定的稳定性。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [404] [Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation](https://arxiv.org/abs/2506.21154)
> *基于Transformer的时空反事实结果估计*

*He Li, Haoang Chi, Mingyu Liu, Wanrong Huang, Liyang Xu, Wenjing Yang* | **Category: stat.ME, cs.AI, cs.LG**

**Keywords:** 时空反事实估计, Transformer, 因果推断, 估计器, 森林损失

**Comment:** 24 pages, accepted at ICML 2025

> **TL;DR:** 本文提出了一种基于Transformer的新颖框架，用于估计具有时空属性的反事实结果，克服了传统方法的局限性，并在模拟和真实数据实验中展示了更强的估计能力，应用于分析哥伦比亚冲突对森林损失的因果效应。

**AI_Comments:** 该论文创新性地将Transformer模型引入时空反事实结果估计领域，解决了传统统计模型在性能和泛化方面的不足。其理论保证和在模拟及真实数据集上的优异表现，特别是应用于实际社会经济问题（如冲突对森林损失的影响），显示了其重要的应用价值和广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界具有时空维度，估计具有时空属性的反事实结果是一个关键问题。然而，现有基于经典统计模型的方法在性能和泛化能力上存在局限性。

**Method:** 本文提出了一种利用Transformer的新颖框架来估计具有时空属性的反事实结果。在该框架下，所提出的估计器在温和假设下具有一致性和渐近正态性。通过模拟实验和真实数据实验验证了其有效性。

**Result:** 模拟实验表明，所提出的估计器比基线方法具有更强的估计能力。真实数据实验为哥伦比亚冲突对森林损失的因果效应提供了有价值的结论。

**Conclusion:** 基于Transformer的方法能够有效且更准确地估计时空反事实结果，并在复杂现实世界问题中展现出强大的因果效应分析能力。

> **ai_Abstract:** 本文提出了一种新颖的基于Transformer的时空反事实结果估计框架，旨在克服传统统计模型在性能和泛化能力上的局限性。该框架下的估计器具有理论上的良好性质（一致性和渐近正态性），并通过模拟实验证明其优于现有基线方法。此外，真实世界数据实验成功应用于分析哥伦比亚冲突对森林损失的因果效应，验证了其在实际问题中的有效性。

> **摘要翻译:** 现实世界自然具有时间和空间的维度。因此，估计具有时空属性的反事实结果是一个关键问题。然而，以前的方法基于经典的统计模型，在性能和泛化方面仍然存在局限性。本文提出了一种利用Transformer估计具有时空属性的反事实结果的新颖框架，该框架展现出更强的估计能力。在温和的假设下，该框架内提出的估计器是一致且渐近正态的。为了验证我们方法的有效性，我们进行了模拟实验和真实数据实验。模拟实验表明我们的估计器比基线方法具有更强的估计能力。真实数据实验为哥伦比亚冲突对森林损失的因果效应提供了有价值的结论。源代码可在 https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master 获取。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [410] [The final solution of the Hitchhiker's problem #5](https://arxiv.org/abs/2506.20672)
> *《搭便车问题 #5》的最终解决方案*

*Matjaž Omladič, Martin Vuk, Aljaž Zalar* | **Category: stat.ML, cs.LG, math.OC, math.ST, stat.TH**

**Keywords:** 准联结函数, 依赖建模, 开放问题5, 解析方法, 极值

**Comment:** 20 pages

> **TL;DR:** 本文使用解析方法彻底解决了准联结函数中“搭便车指南”的开放问题5。

**AI_Comments:** 本文的创新之处在于，它通过纯粹的解析方法，为之前只能通过计算（如线性规划）或有限维度解决的复杂问题（开放问题5）提供了完整的、普遍适用的答案。这不仅解决了特定问题，也可能为准联结函数理论提供更深层次的理解和新的分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 尽管准联结函数缺乏统计解释，但近期一项名为“搭便车指南”的调查提高了准联结函数问题在依赖建模领域的评价。作者之前的研究解决了多元准联结函数相关质量分布的极值问题，并解决了“指南”中的开放问题5（维度d=17），但仍需一个完整的答案。

**Method:** 本文采用解析方法来提供对原始问题的完整答案。先前的研究（作者的旧作）曾使用线性规划方法。

**Result:** 本文使用解析方法，对“搭便车指南”中的开放问题5提供了一个完整的答案。先前的研究（作者的旧作）曾通过线性规划方法解决该问题至维度d=17，并驳斥了一个关于该问题解决方案的最新猜想。

**Conclusion:** 本文通过解析方法，最终提供了“搭便车指南”中开放问题5的完整解决方案。

> **ai_Abstract:** 本文针对准联结函数领域中“搭便车指南”提出的开放问题5，采用解析方法提供了一个完整的解决方案。该问题涉及多元准联结函数相关质量分布的极值。作者在先前的工作中曾使用线性规划方法解决了该问题至维度d=17，并驳斥了相关猜想，而本文则通过新的分析方法给出了最终且全面的答案。

> **摘要翻译:** 近期一项名为“搭便车指南”的调查（J.J. Arias-García, R. Mesiar, and B. De Baets, A hitchhiker's guide to quasi-copulas, Fuzzy Sets and Systems 393 (2020) 1-28）尽管准联结函数缺乏统计解释，但仍在依赖建模社区中提高了准联结函数问题的评价。在我们之前的工作中（arXiv:2410.19339，已在Fuzzy Sets and Systems接受），我们解决了与多元准联结函数相关的质量分布极值问题。通过线性规划方法，我们能够将“指南”中的开放问题5解决到维度d = 17，并驳斥了关于该问题解决方案的一个最新猜想。在本文中，我们使用解析方法来为原始问题提供一个完整的答案。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [417] [Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon](https://arxiv.org/abs/2506.20779)
> *ReLU神经网络的稳定最小值受维度灾难影响：神经破碎现象*

*Tongtong Liang, Dan Qiao, Yu-Xiang Wang, Rahul Parhi* | **Category: stat.ML, cs.LG**

**Keywords:** ReLU神经网络, 平坦最小值, 维度灾难, 神经破碎, 泛化

**Comment:** Comments Welcome!

> **TL;DR:** 本文研究发现，对于多变量输入的ReLU神经网络，平坦解（低损失曲率）虽然有助于泛化，但其收敛速度会随输入维度的增加呈指数级恶化，这揭示了“神经破碎”现象导致其在高维空间表现不佳。

**AI_Comments:** 本文创新性地揭示了ReLU神经网络中平坦最小值在高维空间下泛化性能不佳的深层原因，即“神经破碎”现象和维度灾难。它弥补了现有研究主要关注单变量输入或需要插值的不足，为理解深度学习模型的泛化行为提供了重要的理论见解。研究结果对优化算法和模型设计具有指导意义，尤其是在处理高维数据时，需要重新审视对平坦解的偏好。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作在研究ReLU神经网络中平坦度/低损失曲率的隐式偏差及其对泛化影响时，要么需要插值，要么只关注单变量输入。本文旨在研究多变量输入情况，这由梯度下降训练中的最小值稳定性和边缘稳定性现象充分激发。

**Method:** 本文通过理论分析，针对两种自然设置（1）平坦解的泛化差距，以及（2）稳定最小值在非参数函数估计中的均方误差（MSE），证明了上下界。通过一种基于边界局部化ReLU神经元的新颖填充论证，构建了极小极大下界。

**Result:** 研究发现，尽管平坦度确实能提升泛化能力，但其收敛速度必然随输入维度的增长呈指数级恶化。这导致平坦解与低范数解（例如权重衰减）之间存在指数级分离，后者已知不受维度灾难影响。特别是，神经破碎现象揭示了平坦解如何利用神经元极少激活但权重幅值较高的情况，导致在高维空间中性能不佳。理论发现得到了数值模拟的证实。

**Conclusion:** 本文首次系统地解释了为什么平坦最小值在高维空间中可能无法泛化，揭示了平坦解的泛化能力在高维情况下会遭遇维度灾难，并提出了“神经破碎”作为其根本原因。

> **ai_Abstract:** 本文研究了多变量输入下ReLU神经网络中平坦解的泛化能力。研究发现，尽管平坦度有助于泛化，但其收敛速度会随输入维度的增加呈指数级恶化，即遭遇维度灾难。这种现象被称为“神经破碎”，表现为神经元激活稀疏但权重幅值高，导致高维性能不佳。这与低范数解形成对比，后者不受维度灾难影响。本文首次系统地解释了平坦最小值在高维空间中泛化失败的原因，并通过理论分析和数值模拟进行了验证。

> **摘要翻译:** 我们研究了平坦度/低（损失）曲率的隐式偏差及其在具有多变量输入的双层过参数化ReLU网络中对泛化的影响——这个问题得到了梯度下降训练中最小值稳定性和边缘稳定性现象的充分启发。现有工作要么需要插值，要么只关注单变量输入。本文为多变量输入提供了新的、有些令人惊讶的理论结果。在两种自然设置下：（1）平坦解的泛化差距，以及（2）稳定最小值在非参数函数估计中的均方误差（MSE），我们证明了上下界，这些界限表明，虽然平坦度确实意味着泛化，但其导致的收敛速度必然随输入维度的增长呈指数级恶化。这导致平坦解与低范数解（即权重衰减）之间存在指数级分离，后者已知不受维度灾难影响。特别是，我们基于一种新的边界局部化ReLU神经元填充论证构建的极小极大下界，揭示了平坦解如何利用一种“神经破碎”现象，即神经元很少激活，但具有高权重幅值。这导致在高维空间中性能不佳。我们通过大量的数值模拟证实了这些理论发现。据我们所知，我们的分析首次系统地解释了为什么平坦最小值在高维空间中可能无法泛化。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [420] [Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution](https://arxiv.org/abs/2506.21278)
> *使用高效球面柯西分布的超球面变分自编码器*

*Lukas Sablica, Kurt Hornik* | **Category: stat.ML, cs.AI, cs.LG, math.ST, stat.TH**

**Keywords:** 超球面VAE, 球面柯西分布, 潜在空间, 重参数化技巧, 生成建模

**Comment:** 

> **TL;DR:** 本文提出了一种使用球面柯西（spCauchy）潜在分布的新型变分自编码器（VAE）架构，它提供了更自然的超球面表示，解决了现有方法（如vMF）的数值不稳定性，并实现了高效稳定的训练。

**AI_Comments:** 本文的创新之处在于将球面柯西（spCauchy）分布引入变分自编码器（VAE）的潜在空间，以解决现有方法（如高斯和vMF）在超球面数据建模中的局限性。其提出的重参数化技巧和KL散度计算方法显著提升了模型的数值稳定性和训练效率，对于处理方向性数据和高维生成建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的变分自编码器（VAE）在使用高斯潜在空间或von Mises-Fisher（vMF）分布时存在局限性：高斯分布不适合超球面数据，而vMF分布存在数值不稳定性，且两者都可能导致过度正则化。因此，需要一种更自然、稳定、富有表现力的潜在分布来改进超球面VAE。

**Method:** 本文提出了一种新颖的VAE架构，该架构采用球面柯西（spCauchy）潜在分布。它通过莫比乌斯变换实现了完全可微分且高效的重参数化技巧，并利用快速收敛的幂级数计算KL散度，从而避免了超几何函数比值评估中可能出现的下溢或溢出问题。

**Result:** 所提出的球面柯西（spCauchy）分布为潜在变量提供了更自然的超球面表示，能更好地捕获方向性数据，同时保持灵活性。其重尾特性防止了过度正则化，确保了高效的潜在空间利用和更具表现力的表示。此外，spCauchy规避了vMF固有的数值不稳定性，实现了稳定且可扩展的训练。

**Conclusion:** 球面柯西（spCauchy）分布是变分自编码器（VAE）的一个引人注目的替代方案，在高维生成建模中提供了理论优势和实际效率。

> **ai_Abstract:** 本文介绍了一种新颖的变分自编码器（VAE）架构，其核心是使用球面柯西（spCauchy）潜在分布。这种方法为潜在变量提供了更自然、更具表现力的超球面表示，能够有效地捕捉方向性数据。与传统的高斯或von Mises-Fisher（vMF）分布相比，spCauchy的重尾特性避免了过度正则化，从而实现了高效的潜在空间利用。同时，它通过莫比乌斯变换实现了完全可微分的重参数化技巧，并通过稳定的幂级数计算KL散度，成功解决了vMF分布的数值不稳定性问题。这些优势使spCauchy成为高维生成建模中一个理论上优越且实际高效的选择。

> **摘要翻译:** 我们提出了一种新颖的变分自编码器（VAE）架构，该架构采用球面柯西（spCauchy）潜在分布。与传统的欧几里得高斯潜在空间或广泛使用的von Mises-Fisher（vMF）分布不同，spCauchy为潜在变量提供了更自然的超球面表示，更好地捕获方向性数据，同时保持灵活性。其重尾特性防止了过度正则化，确保了高效的潜在空间利用，同时提供了更具表现力的表示。此外，spCauchy规避了vMF固有的数值不稳定性，这些不稳定性源于涉及贝塞尔函数的归一化常数计算。相反，它通过莫比乌斯变换实现了完全可微分且高效的重参数化技巧，从而实现稳定和可扩展的训练。KL散度可以通过快速收敛的幂级数计算，消除了与超几何函数比值评估相关的下溢或溢出问题。这些特性使spCauchy成为VAE的一个引人注目的替代方案，在高维生成建模中提供了理论优势和实际效率。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [431] [Active Learning for Manifold Gaussian Process Regression](https://arxiv.org/abs/2506.20928)
> *流形高斯过程回归的主动学习*

*Yuanxing Cheng, Lulu Kang, Yiwei Wang, Chun Liu* | **Category: stat.ML, cs.LG, 62, G.3**

**Keywords:** 主动学习, 流形高斯过程回归, 降维, 高维空间, 数据选择

**Comment:** 13 pages, 6 figures

> **TL;DR:** 提出一种结合流形学习和主动学习的框架，用于高维空间中的高斯过程回归，能有效提高精度并处理复杂函数。

**AI_Comments:** 该论文的创新点在于将主动学习与流形高斯过程回归相结合，通过联合优化神经网络降维和GP回归器，有效提升了高维空间中的预测精度。其处理复杂、不连续函数的能力以及计算可行性是其重要价值所在。未来的可扩展性和不确定性感知学习将是进一步提升该框架实用性的关键。

<details>
  <summary>Details</summary>

**Motivation:** 在处理高维数据时，通过结合流形学习和策略性数据选择来提高高斯过程回归的预测准确性。

**Method:** 本文引入了一个用于流形高斯过程（GP）回归的主动学习框架。该方法联合优化一个用于降维的神经网络和一个在潜在空间中的高斯过程回归器，并由一个最小化全局预测误差的主动学习准则进行监督。

**Result:** 在合成数据上的实验表明，该方法在性能上优于随机序贯学习。该框架能够高效处理复杂、不连续的函数，同时保持计算上的可行性。

**Conclusion:** 该主动学习框架在流形高斯过程回归中表现出色，能有效提高高维空间中的预测精度并处理复杂函数，具有实际应用价值。

> **ai_Abstract:** 本文提出了一种针对流形高斯过程回归的主动学习框架，旨在通过结合流形学习和智能数据选择来提升高维数据的预测精度。该框架通过一个主动学习准则，协同优化神经网络进行降维和高斯过程回归器在潜在空间中的表现。实验证明，该方法在处理复杂、不连续函数方面优于随机学习，并保持了计算效率，具有广泛的实际应用潜力。

> **摘要翻译:** 本文介绍了一种用于流形高斯过程（GP）回归的主动学习框架，该框架结合了流形学习和策略性数据选择，以提高高维空间中的精度。我们的方法联合优化了一个用于降维的神经网络和一个在潜在空间中的高斯过程回归器，并由一个最小化全局预测误差的主动学习准则进行监督。在合成数据上的实验表明，其性能优于随机序贯学习。该框架能够高效处理复杂、不连续的函数，同时保持计算上的可行性，为科学和工程应用提供了实际价值。未来的工作将侧重于可扩展性和不确定性感知流形学习。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [434] [Lower Bounds on the Size of Markov Equivalence Classes](https://arxiv.org/abs/2506.20933)
> *马尔可夫等价类大小的下界*

*Erik Jahn, Frederick Eberhardt, Leonard J. Schulman* | **Category: stat.ML, cs.LG, math.ST, stat.TH**

**Keywords:** 马尔可夫等价类, 因果发现, 下界, 有向无环图, 有向循环图

**Comment:** 

> **TL;DR:** 本文证明，当放宽无环性、因果充分性或均匀模型先验假设时，马尔可夫等价类的预期大小会呈指数级增长。

**AI_Comments:** 这篇论文对于理解因果发现算法的局限性具有重要意义。它挑战了在理想假设下马尔可夫等价类平均较小的传统观点，揭示了在更现实或更复杂的图模型中，因果识别的难度会显著增加。其结果对于指导因果推断实践和设计新的因果发现算法具有指导作用，特别是当无法满足某些严格假设时。

<details>
  <summary>Details</summary>

**Motivation:** 因果发现算法通常只能恢复到马尔可夫等价类，这些等价类的大小反映了从纯观测数据中学习底层因果图的局限性。现有研究发现，在特定假设下，这些等价类平均较小，但本文旨在探索放宽这些假设时的情况。

**Method:** 通过理论证明，在三种特定设置下（稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图），计算马尔可夫等价类预期大小的指数级下界。

**Result:** 证明了当放宽无环性、因果充分性或均匀模型先验中的任何一个假设时，马尔可夫等价类的预期大小不再是平均较小的，而是可以达到指数级下界。具体在稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图这三种图模型中得到了验证。

**Conclusion:** 放宽因果发现中的标准假设（无环性、因果充分性、均匀模型先验）会导致马尔可夫等价类的大小显著增加，这表明在这些更一般的设置下，从观测数据中进行因果推断的难度更大。

> **ai_Abstract:** 本文探讨了在放宽标准假设（无环性、因果充分性、均匀模型先验）时，因果发现中马尔可夫等价类大小的变化。研究发现，不同于在标准假设下平均较小的情况，当任何一个假设被放宽时，马尔可夫等价类的预期大小会呈指数级增长，并在稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图这三种特定设置中得到了指数级下界的证明。这揭示了在更复杂的因果模型中，从观测数据中识别因果结构所面临的挑战。

> **摘要翻译:** 因果发现算法通常只能恢复到它们的马尔可夫等价类，除非做出额外的参数假设。这些等价类的大小反映了仅从观测数据中可以学到关于底层因果图的局限性。在无环性、因果充分性和均匀模型先验的假设下，已知马尔可夫等价类平均较小。在本文中，我们表明当这些假设中的任何一个被放宽时，情况就不再如此。具体来说，我们证明了在三种设置下，马尔可夫等价类预期大小的指数级大下界：稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [436] [Forecasting Geopolitical Events with a Sparse Temporal Fusion Transformer and Gaussian Process Hybrid: A Case Study in Middle Eastern and U.S. Conflict Dynamics](https://arxiv.org/abs/2506.20935)
> *地缘政治事件预测：基于稀疏时间融合转换器和高斯过程混合模型在中东和美国冲突动态中的案例研究*

*Hsin-Hsiung Huang, Hayden Hampton* | **Category: stat.ML, cs.LG, stat.AP, stat.CO, 37M10, 62M10, 62P25, 65Y20**

**Keywords:** 地缘政治事件预测, 时间融合转换器, 高斯过程, 冲突动态, GDELT数据

**Comment:** 

> **TL;DR:** 本文提出了一种名为STFT-VNNGP的混合架构，结合了稀疏时间融合转换器（TFT）和变分最近邻高斯过程（VNNGP），旨在解决地缘政治事件数据（如GDELT）在长期预测中存在的稀疏性、突发性和过度分散性问题。该模型在预测中东和美国冲突动态的案例研究中表现出色，尤其是在长期预测突发事件时期的时机和规模方面，优于独立的TFT。

**AI_Comments:** 这项研究通过结合深度学习模型（TFT）和概率模型（VNNGP）的优势，创新性地解决了地缘政治事件数据预测中的核心挑战，特别是在处理稀疏、突发和过度分散数据方面。其重要性在于为国家安全领域提供了更可靠的长期预测工具。该模型在ATD竞赛中获胜证明了其有效性，而代码和工作流程的公开性进一步增强了其研究价值和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 从全球事件、语言和语调数据库（GDELT）等数据源预测地缘政治冲突对国家安全至关重要。然而，此类数据固有的稀疏性、突发性和过度分散性使得包括时间融合转换器（TFT）在内的标准深度学习模型难以产生可靠的长期预测，这构成了当前的挑战。

**Method:** 本文引入了STFT-VNNGP，这是一种混合架构，采用两阶段过程：首先，时间融合转换器（TFT）捕获复杂的时间动态以生成多分位数预测；其次，这些多分位数作为变分最近邻高斯过程（VNNGP）的有效输入，VNNGP执行原则性的时空平滑和不确定性量化。

**Result:** 在预测中东和美国冲突动态的案例研究中，STFT-VNNGP持续优于独立的TFT，在预测突发事件时期的时机和规模方面，尤其是在长期预测中表现出卓越的能力。该模型赢得了2023年威胁检测算法（ATD）竞赛。

**Conclusion:** 这项工作提供了一个强大的框架，可以从具有挑战性的地缘政治事件数据中生成更可靠、更具可操作性的情报。所有代码和工作流程均已公开，以确保可复现性。

> **ai_Abstract:** 本文提出了一种名为STFT-VNNGP的混合模型，它结合了时间融合转换器（TFT）和变分最近邻高斯过程（VNNGP），旨在解决地缘政治事件数据（如GDELT）在长期预测中面临的稀疏性、突发性和过度分散性挑战。该模型采用两阶段方法：TFT负责捕获时间动态并生成多分位数预测，VNNGP则利用这些预测进行时空平滑和不确定性量化。在预测中东和美国冲突动态的案例研究中，STFT-VNNGP在预测突发事件的时机和规模方面表现出卓越的长期预测能力，并持续优于独立的TFT，为生成更可靠和可操作的情报提供了鲁棒框架。

> **摘要翻译:** 从全球事件、语言和语调数据库（GDELT）等数据源预测地缘政治冲突是国家安全面临的关键挑战。此类数据固有的稀疏性、突发性和过度分散性导致包括时间融合转换器（TFT）在内的标准深度学习模型产生不可靠的长期预测。我们引入了STFT-VNNGP，这是一种混合架构，通过克服这些局限性赢得了2023年威胁检测算法（ATD）竞赛。我们的模型旨在弥补这一差距，采用两阶段过程：首先，TFT捕获复杂的时间动态以生成多分位数预测。然后，这些分位数作为变分最近邻高斯过程（VNNGP）的有效输入，VNNGP执行原则性的时空平滑和不确定性量化。在中东和美国冲突动态预测的案例研究中，STFT-VNNGP持续优于独立的TFT，在预测突发事件时期的时机和规模方面，尤其是在长期预测中表现出卓越的能力。这项工作为从具有挑战性的事件数据中生成更可靠、更具可操作性的情报提供了一个强大的框架，所有代码和工作流程均已公开，以确保可复现性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [443] [Homogenization of Multi-agent Learning Dynamics in Finite-state Markov Games](https://arxiv.org/abs/2506.21079)
> *有限状态马尔可夫博弈中多智能体学习动力学的均匀化*

*Yann Kerzreho* | **Category: stat.ML, cs.LG, math.PR**

**Keywords:** 多智能体学习, 马尔可夫博弈, 学习动力学, 常微分方程, 均匀化

**Comment:** 

> **TL;DR:** 通过重标度学习过程，将有限状态马尔可夫博弈中的多智能体学习动力学近似为常微分方程。

**AI_Comments:** 这项工作通过将复杂的离散多智能体学习动力学近似为连续的常微分方程，极大地简化了分析。这种“均匀化”方法在理论上具有重要意义，因为它提供了一个数学上更易处理的模型来理解和预测多智能体系统的行为，对于理解学习算法的收敛性和稳定性具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决多智能体强化学习在有限状态马尔可夫博弈中学习动力学复杂且难以分析的问题，提供一个可处理的近似方法。

**Method:** 该论文引入了一种新的方法，通过同时减小学习率和增加更新频率来重标度学习过程。这有效地将智能体的参数视为受快速混合博弈状态影响的慢演变变量。在状态过程遍历性和更新连续性的温和假设下，证明了这种重标度过程收敛到一个常微分方程（ODE）。

**Result:** 证明了重标度过程收敛到一个常微分方程（ODE）。该ODE为智能体的学习动力学提供了一个可处理的、确定性的近似。

**Conclusion:** 通过重标度学习过程，可以将多智能体学习动力学近似为一个可处理的、确定性的常微分方程，从而简化了对复杂系统行为的分析。

> **ai_Abstract:** 本文提出一种新方法，通过重标度学习过程（减小学习率、增加更新频率）来近似有限状态马尔可夫博弈中多智能体学习动力学。该方法将智能体参数视为慢演变变量，并证明在特定条件下，重标度过程收敛到一个常微分方程（ODE），从而为学习动力学提供可处理的确定性近似。

> **摘要翻译:** 本文介绍了一种新的方法，用于近似在有限状态马尔可夫博弈中交互的多个强化学习（RL）智能体的学习动力学。其思想是通过同时减小学习率和增加更新频率来重标度学习过程，有效地将智能体的参数视为受快速混合博弈状态影响的慢演变变量。在温和的假设下——状态过程的遍历性和更新的连续性——我们证明了这种重标度过程收敛到一个常微分方程（ODE）。这个ODE为智能体的学习动力学提供了一个可处理的、确定性的近似。该框架的实现可在以下网址获取：https://github.com/yannKerzreho/MarkovGameApproximation

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [448] [Wild refitting for black box prediction](https://arxiv.org/abs/2506.21460)
> *黑箱预测的野性再拟合*

*Martin J. Wainwright* | **Category: stat.ML, cs.LG, math.ST, stat.TH**

**Keywords:** 野性再拟合, 黑箱预测, 预测误差上限, 非参数估计, Rademacher对称化

**Comment:** 

> **TL;DR:** 本文提出了一种名为“野性再拟合”的计算高效程序，用于计算基于最小二乘法的惩罚非参数估计的实例级均方预测误差的高概率上限，仅需单个数据集和对预测方法的黑箱访问。

**AI_Comments:** 该论文的创新之处在于提出了一种计算高效的“野性再拟合”程序，能够为黑箱预测模型提供高概率的实例级均方预测误差上限。其重要性在于，它提供了一种在复杂模型中进行不确定性量化的方法，并且其理论分析为设计鲁棒的预测误差边界程序提供了清晰的指导。该方法仅依赖于黑箱访问和单个数据集，使其具有广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 需要为基于最小二乘法的惩罚非参数估计计算实例级均方预测误差的高概率上限，尤其是在只能进行黑箱访问的情况下。

**Method:** 该方法称为“野性再拟合”，仅需单个数据集和对预测方法的黑箱访问。它包含三个步骤：计算合适的残差，使用预因子$\rho$对其进行对称化和缩放，以及使用它们定义和解决以当前估计为中心修正的预测问题。它使用Rademacher残差对称化，类似于野性自举变体。

**Result:** 在允许噪声异质性的相对温和条件下，该方法在高概率下保证了其性能，表明经过适当选择的野性噪声尺度$\rho$的野性再拟合可以提供预测误差的上限。理论分析为此类程序的设计提供了指导，包括残差的形成方式、上限所需的野性子问题中噪声重缩放的量以及黑箱程序的局部稳定性特性。该程序适用于非刚性运动结构恢复、即插即用图像修复和核方法随机草图等问题。

**Conclusion:** 野性再拟合程序提供了一种计算高效且具有理论保证的方法，用于确定黑箱预测模型的预测误差上限，并为设计此类程序提供了有价值的指导。

> **ai_Abstract:** 本文介绍并分析了一种计算高效的“野性再拟合”程序，用于计算基于最小二乘法的惩罚非参数估计的实例级均方预测误差的高概率上限。该程序仅需单个数据集和对预测方法的黑箱访问，其核心步骤包括残差计算、残差对称化与缩放，以及解决修正的预测问题。通过理论分析，研究表明在温和条件下，该方法能提供预测误差的有效上限，并为程序设计提供指导。该方法已成功应用于非刚性运动结构恢复、即插即用图像修复和核方法随机草图等多个领域。

> **摘要翻译:** 我们描述并分析了一种计算高效的再拟合程序，用于计算基于最小二乘法惩罚非参数估计的实例级均方预测误差的高概率上限。该程序仅需单个数据集和对预测方法的黑箱访问，它包括三个步骤：计算合适的残差，使用预因子$\rho$对其进行对称化和缩放，以及使用它们定义和解决以当前估计为中心修正的预测问题。我们将其称为野性再拟合，因为它使用Rademacher残差对称化，类似于野性自举变体。在允许噪声异质性的相对温和条件下，我们建立了其性能的高概率保证，表明经过适当选择的野性噪声尺度$\rho$的野性再拟合可以提供预测误差的上限。这项理论分析为此类程序的设计提供了指导，包括残差的形成方式、上限所需的野性子问题中噪声重缩放的量以及黑箱程序的局部稳定性特性。我们举例说明了该程序在各种问题中的适用性，包括使用结构化矩阵惩罚的非刚性运动结构恢复；使用深度神经网络先验的即插即用图像修复；以及使用核方法的随机草图。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [449] [Gaussian Invariant Markov Chain Monte Carlo](https://arxiv.org/abs/2506.21511)
> *高斯不变马尔可夫链蒙特卡罗*

*Michalis K. Titsias, Angelos Alexopoulos, Siran Liu, Petros Dellaportas* | **Category: stat.ML, cs.LG, stat.ME**

**Keywords:** 马尔可夫链蒙特卡罗, 高斯不变性, 统计效率, 控制变量, 泊松方程

**Comment:** 29, 2 figures

> **TL;DR:** 开发了高斯不变的MCMC采样方法，提高了统计效率，并给出了理论和实践验证。

**AI_Comments:** 这项工作创新性地引入了高斯不变性到MCMC采样中，通过利用其独特的数学性质，实现了对泊松方程的精确求解，从而能够构建有效的方差削减技术。这对于提高MCMC方法的统计效率具有重要意义，尤其是在处理高维和复杂目标分布时。其理论分析和在实际应用中的优异表现，使其成为MCMC领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有标准随机游走 Metropolis (RWM) 和 Metropolis 调整 Langevin 算法 (MALA) 在统计效率上存在局限性，本研究旨在开发能够提高统计效率的新型采样方法。

**Method:** 开发了随机游走 Metropolis (RWM)、Metropolis 调整 Langevin 算法 (MALA) 和二阶 Hessian 或流形 MALA 的高斯不变版本。利用高斯不变性获得高斯目标的泊松方程精确解析解，并用这些解构建高效易用的控制变量，以减少任何难以处理目标下的估计器方差。

**Result:** 高斯不变采样方法能够产生具有改进统计效率的遍历估计器。新的采样器和估计器在多个示例中表现出色，包括高维潜在高斯模型，并与现有先进方法相比获得了最先进的结果。提供了关于几何遍历性的理论结果，以及显示最优接受率对目标高斯性依赖关系的最优尺度分析。

**Conclusion:** 高斯不变采样方法能够显著提高估计器的统计效率，通过利用高斯不变性获得的泊松方程精确解来构建有效的控制变量，从而实现方差减少。该方法在理论和实践中均表现出优越性。

> **ai_Abstract:** 本文提出了一系列高斯不变的马尔可夫链蒙特卡罗（MCMC）采样方法，包括RWM、MALA及其二阶变体。这些方法利用高斯不变性，能够获得泊松方程的精确解析解，进而构建高效的控制变量以显著提高估计器的统计效率并减少方差。通过在高维潜在高斯模型等多个示例中的验证，证明了其优于现有先进方法的性能，并提供了几何遍历性和最优尺度分析的理论支持。

> **摘要翻译:** 我们开发了采样方法，包括随机游走 Metropolis (RWM)、Metropolis 调整 Langevin 算法 (MALA) 和二阶 Hessian 或流形 MALA 的高斯不变版本。与标准 RWM 和 MALA 不同，我们展示了高斯不变采样可以产生具有改进统计效率的遍历估计器。这归因于高斯不变性的一种显著特性，该特性使我们能够获得高斯目标的泊松方程的精确解析解。这些解可用于构建高效且易于使用的控制变量，以减少任何难以处理的目标下的估计器方差。我们在几个示例中演示了新的采样器和估计器，包括潜在高斯模型中的高维目标，在这些模型中我们与几种先进方法进行了比较并获得了最先进的结果。我们还提供了关于几何遍历性的理论结果，以及显示最优接受率对目标高斯性依赖关系的最优尺度分析。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='q-biocb'></a>
## q-bio.CB 

### [414] [scMamba: A Scalable Foundation Model for Single-Cell Multi-Omics Integration Beyond Highly Variable Feature Selection](https://arxiv.org/abs/2506.20697)
> *scMamba：一种超越高变特征选择的可扩展单细胞多组学整合基础模型*

*Zhen Yuan, Shaoqing Jiao, Yihang Xiao, Jiajie Peng* | **Category: q-bio.CB, cs.LG**

**Keywords:** 单细胞多组学, 基础模型, 特征选择, 对比学习, scMamba

**Comment:** 

> **TL;DR:** scMamba是一种新的基础模型，能够无需预先特征选择地整合单细胞多组学数据，并显著优于现有方法。

**AI_Comments:** scMamba的创新之处在于其“超越高变特征选择”的能力，这解决了当前方法中可能丢失关键生物信息的痛点。其将基因组区域视为词、细胞视为句子的标记化策略，以及结合状态空间对偶性和对比学习的设计，使其能够有效处理高维稀疏的多组学数据。该模型的可扩展性使其有望应用于大规模单细胞图谱的分析，对于推动生物发现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的单细胞多组学整合方法通常依赖于选择高变基因或峰，这可能会无意中丢弃关键的生物学信息，导致数据整合的挑战。

**Method:** scMamba引入了一种基于补丁的细胞标记策略，将基因组区域视为词（tokens），细胞视为句子。它基于状态空间对偶性，从高维稀疏的单细胞多组学数据中提取生物学见解。此外，它采用了一种新颖的对比学习方法，并通过余弦相似度正则化进行增强，以实现更好的组学层对齐。

**Result:** 在多个数据集上的系统基准测试表明，scMamba在保留生物变异、对齐组学层以及增强下游任务（如聚类、细胞类型注释和轨迹推断）方面，显著优于现有最先进的方法。

**Conclusion:** scMamba被定位为一种强大的工具，用于大规模单细胞多组学整合，能够处理大型图谱并推动生物发现。

> **ai_Abstract:** scMamba是一个用于单细胞多组学整合的基础模型，其创新之处在于无需预先进行高变特征选择，同时保留了基因组位置信息。它采用独特的补丁式细胞标记策略和状态空间对偶性来处理高维稀疏数据，并通过增强的对比学习实现卓越的组学层对齐。基准测试表明，scMamba在保留生物变异和提升下游任务表现方面优于现有方法，使其成为大规模多组学整合的强大工具。

> **摘要翻译:** 单细胞多组学技术的出现使得在单个细胞内同时分析不同的组学层成为可能。整合此类多模态数据为细胞特性、调控过程和疾病机制提供了前所未有的见解。然而，这仍然具有挑战性，因为当前方法在预处理过程中通常依赖于选择高变基因或峰，这可能会无意中丢弃关键的生物学信息。在此，我们提出了scMamba，一个旨在整合单细胞多组学数据的基础模型，无需预先进行特征选择，同时保留基因组位置信息。scMamba引入了一种基于补丁的细胞标记策略，将基因组区域视为词（tokens），细胞视为句子。基于状态空间对偶性的概念，scMamba从高维、稀疏的单细胞多组学数据中提炼出丰富的生物学见解。此外，我们新颖的对比学习方法，通过余弦相似度正则化增强，与传统方法相比，能够实现卓越的组学层对齐。在多个数据集上的系统基准测试表明，scMamba在保留生物变异、对齐组学层和增强关键下游任务（如聚类、细胞类型注释和轨迹推断）方面，显著优于最先进的方法。我们的发现将scMamba定位为一种强大工具，用于大规模单细胞多组学整合，能够处理大型图谱并推动生物发现。

</details>

[⬆️ 返回分类顶部](#q-biocb) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [423] [Efficacy of Temporal Fusion Transformers for Runoff Simulation](https://arxiv.org/abs/2506.20831)
> *时间融合转换器在径流模拟中的效能*

*Sinan Rasiya Koya, Tirthankar Roy* | **Category: physics.geo-ph, cs.LG, stat.AP**

**Keywords:** 时间融合转换器, 径流模拟, LSTM, 水文建模, 可解释AI

**Comment:** 

> **TL;DR:** 本研究评估了时间融合转换器（TFT）在降雨径流模拟中相对于长短期记忆（LSTM）网络的性能，发现TFT略优于LSTM，尤其是在模拟径流曲线的中段和峰值方面，并且能处理更长的序列，提供可解释的科学见解。

**AI_Comments:** 该论文的创新之处在于将时间融合转换器（TFT）应用于水文径流模拟，并与传统的LSTM进行对比。TFT在处理长序列和提供可解释性方面的能力是其重要优势，这对于科学洞察和模型理解非常有价值。然而，论文也指出了在不同数据集上性能下降的问题，提示未来研究需要关注数据质量对模型泛化能力的影响。

<details>
  <summary>Details</summary>

**Motivation:** 结合注意力机制和循环网络在序列建模（包括水文预测）中已被证明很有价值。本研究旨在探索时间融合转换器（TFT）在降雨径流建模中相对于长短期记忆（LSTM）网络的优势。

**Method:** 研究训练了十个随机初始化的时间融合转换器（TFT）和长短期记忆（LSTM）模型，应用于美国531个CAMELS流域。实验还使用Caravan数据集的五个子集（分别代表美国、澳大利亚、巴西、英国和智利的流域）重复进行。随后，评估了模型的性能、其在流域属性方面的变异性以及不同数据集之间的差异。

**Result:** 研究发现，时间融合转换器（TFT）略微优于长短期记忆（LSTM）网络，尤其是在模拟径流曲线的中段和峰值。此外，TFT能够处理更长的序列，并且可能更适合更高或更大的流域。作为一种可解释的人工智能技术，TFT能识别关键的动态和静态变量。然而，TFT和LSTM在Caravan数据集上的性能均显著下降，这可能表明数据质量存在问题。

**Conclusion:** 这项研究总体上突出了时间融合转换器（TFT）在改进水文建模和理解方面的潜力。

> **ai_Abstract:** 本研究评估了时间融合转换器（TFT）在降雨径流模拟中的效能，并将其与长短期记忆（LSTM）网络进行比较。研究在美国CAMELS流域和全球Caravan数据集的子集上训练并测试了这两种模型。结果显示，TFT在性能上略优于LSTM，特别是在模拟水文曲线的中段和峰值，并且能够处理更长序列，提供可解释的变量洞察。尽管TFT具有优势，但两种模型在Caravan数据集上均表现出性能下降，可能与数据质量问题有关。总体而言，本研究强调了TFT在提升水文建模和理解方面的潜力。

> **摘要翻译:** 结合注意力机制与循环网络在序列建模（包括水文预测）中已显示出其价值。在此，我们探讨了时间融合转换器（TFTs）在降雨径流建模中相对于长短期记忆（LSTM）网络的优势。我们训练了十个随机初始化的模型，包括TFT和LSTM，应用于美国531个CAMELS流域。我们使用Caravan数据集的五个子集重复了实验，每个子集代表美国、澳大利亚、巴西、英国和智利的流域。然后，评估了模型的性能、其在流域属性方面的变异性以及根据数据集的不同而产生的差异。我们的研究结果表明，TFT略微优于LSTM，尤其是在模拟径流曲线的中段和峰值。此外，我们展示了TFT处理更长序列的能力，以及为什么它可能是更高或更大流域的更好选择。作为一种可解释的人工智能技术，TFT能够识别关键的动态和静态变量，提供有价值的科学见解。然而，TFT和LSTM在Caravan数据集上的性能都出现了显著下降，这表明可能存在数据质量问题。总的来说，这项研究强调了TFT在改进水文建模和理解方面的潜力。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [424] [Uncertainty-Aware Machine-Learning Framework for Predicting Dislocation Plasticity and Stress-Strain Response in FCC Alloys](https://arxiv.org/abs/2506.20839)
> *FCC合金中位错塑性与应力-应变响应预测的不确定性感知机器学习框架*

*Jing Luo, Yejun Gu, Yanfei Wang, Xiaolong Ma, Jaafar. A El-Awady* | **Category: cond-mat.mtrl-sci, cs.LG**

**Keywords:** 机器学习, 不确定性量化, 位错塑性, 应力-应变, FCC合金, 混合密度网络

**Comment:** 

> **TL;DR:** 本研究提出一种不确定性感知的机器学习框架，利用混合密度网络（MDN）模型预测FCC合金的位错塑性与应力-应变响应，并量化不确定性，以改进材料设计。

**AI_Comments:** 该论文的创新点在于利用混合密度网络（MDN）模型对位错密度和应力分布进行不确定性量化，并将其与位错介导的塑性模型相结合。这种明确的不确定性量化对于材料的可靠设计和开发至关重要，为材料科学领域的预测建模提供了更稳健的方法。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习在结构材料的理解和应用方面取得了显著进展，但越来越强调整合现有数据和量化预测模型中的不确定性。本研究旨在通过提高机械性能预测的准确性和可靠性，并优化合金设计来解决这一需求。

**Method:** 本研究提出了一种综合方法，利用在大量实验数据上训练的混合密度网络（MDN）模型。该方法独特地预测位错密度（推断为潜在变量）的分布以及晶粒水平上的应力分布。将这些预测分布的统计参数纳入位错介导的塑性模型中，从而实现了具有明确不确定性量化的精确应力-应变预测。

**Result:** 该策略不仅提高了机械性能预测的准确性和可靠性，而且在优化合金设计方面发挥了至关重要的作用，从而促进了快速发展行业中新材料的开发。

**Conclusion:** 所提出的不确定性感知机器学习框架显著提高了机械性能预测的准确性和可靠性，并在优化合金设计、促进新材料开发方面发挥关键作用。

> **ai_Abstract:** 本研究提出了一种新颖的机器学习框架，利用混合密度网络（MDN）模型预测FCC合金中的位错塑性与应力-应变响应。通过预测位错密度和应力分布，并将其统计参数整合到位错介导的塑性模型中，该框架实现了具有明确不确定性量化的精确应力-应变预测。这显著提高了机械性能预测的准确性和可靠性，并有助于优化合金设计和新材料开发。

> **摘要翻译:** 机器学习在结构材料的理解和应用方面取得了显著进展，对整合现有数据和量化预测模型中的不确定性越来越重视。本研究提出了一种综合方法，利用在大量实验数据上训练的混合密度网络（MDN）模型。该方法独特地预测位错密度（推断为潜在变量）的分布以及晶粒水平上的应力分布。将这些预测分布的统计参数纳入位错介导的塑性模型中，从而实现了具有明确不确定性量化的精确应力-应变预测。该策略不仅提高了机械性能预测的准确性和可靠性，而且在优化合金设计方面发挥了至关重要的作用，从而促进了快速发展行业中新材料的开发。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

