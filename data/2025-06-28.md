# AI-Enhanced arXiv Daily 2025-06-28

<a id='toc'></a>
## 今日总计: 450 篇论文
### 目录
- [cs.CR](#cscr) (12 篇)
- [cs.AI](#csai) (13 篇)
- [cs.LG](#cslg) (77 篇)
- [cs.RO](#csro) (18 篇)
- [cs.CV](#cscv) (113 篇)
- [cs.HC](#cshc) (11 篇)
- [cs.SE](#csse) (11 篇)
- [cs.SI](#cssi) (4 篇)
- [cs.NI](#csni) (2 篇)
- [cs.IT](#csit) (4 篇)
- [cs.AR](#csar) (3 篇)
- [cs.DC](#csdc) (11 篇)
- [cs.CY](#cscy) (2 篇)
- [cs.CE](#csce) (3 篇)
- [eess.SY](#eesssy) (8 篇)
- [eess.SP](#eesssp) (12 篇)
- [eess.IV](#eessiv) (9 篇)
- [eess.AS](#eessas) (5 篇)
- [cs.CL](#cscl) (39 篇)
- [cs.DS](#csds) (10 篇)
- [cs.GR](#csgr) (6 篇)
- [cs.IR](#csir) (7 篇)
- [cs.NE](#csne) (4 篇)
- [math.NA](#mathna) (18 篇)
- [cs.SD](#cssd) (8 篇)
- [cs.DL](#csdl) (2 篇)
- [econ.GN](#econgn) (2 篇)
- [q-fin.PM](#q-finpm) (1 篇)
- [quant-ph](#quant-ph) (3 篇)
- [cond-mat.soft](#cond-matsoft) (1 篇)
- [physics.soc-ph](#physicssoc-ph) (1 篇)
- [math.CO](#mathco) (1 篇)
- [math.DS](#mathds) (1 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [math.ST](#mathst) (1 篇)
- [physics.acc-ph](#physicsacc-ph) (1 篇)
- [math.PR](#mathpr) (1 篇)
- [math.OC](#mathoc) (3 篇)
- [cs.CG](#cscg) (1 篇)
- [cs.MM](#csmm) (1 篇)
- [q-bio.BM](#q-biobm) (2 篇)
- [physics.ins-det](#physicsins-det) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [q-bio.QM](#q-bioqm) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (1 篇)
- [stat.ME](#statme) (1 篇)
- [stat.ML](#statml) (9 篇)
- [q-bio.CB](#q-biocb) (1 篇)
- [physics.geo-ph](#physicsgeo-ph) (1 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [Perry: A High-level Framework for Accelerating Cyber Deception Experimentation](https://arxiv.org/abs/2506.20770)
> *Perry：一个加速网络欺骗实验的高级框架*

*Brian Singer, Yusuf Saquib, Lujo Bauer, Vyas Sekar* | **Category: cs.CR**

**Keywords:** 网络欺骗, 实验框架, 高级抽象, 安全评估, 蜜罐

**Comment:** 

> **TL;DR:** Perry是一个高级框架，旨在通过提供抽象层和实验模块来加速网络欺骗策略的设计和探索，解决了现有工具复杂且难以修改的问题。

**AI_Comments:** Perry框架通过引入高级抽象层和模块化设计，有效地解决了网络欺骗实验中工具复杂性和可扩展性差的问题。其创新点在于将欺骗策略的设计和实验过程进行了高级封装，使得安全操作员能够更专注于策略本身而非底层实现细节。这对于加速网络安全领域的研发和提升防御能力具有重要意义。该框架通过模拟大量假设情景来验证其价值，展现了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有网络欺骗工具和平台实现复杂且不可移植，难以修改和扩展，导致操作员难以实验、探索和评估欺骗方法。

**Method:** 论文引入了Perry框架，包含两个核心组件：一个高级抽象层用于安全操作员指定攻击者和欺骗策略，以及一个实验模块用于在真实的模拟网络中运行这些攻击者和防御者。为实现高级规范的转换，Perry设计了四个关键模块：动作规划器、可观察性模块、环境状态服务和攻击图服务。

**Result:** Perry的抽象层减少了探索各种欺骗防御、攻击者和环境的实现工作。通过模拟55个独特的欺骗假设情景，展示了Perry的价值，并揭示了这些实验如何帮助操作员理解微妙的权衡。

**Conclusion:** Perry框架通过提供高级抽象和实验能力，显著降低了网络欺骗实验的复杂性，使操作员能够更有效地设计、探索和评估欺骗策略，并理解其中的权衡。

> **ai_Abstract:** 本文介绍了Perry，一个高级框架，旨在简化和加速网络欺骗策略的实验与评估。针对现有工具复杂且难以修改的痛点，Perry提供了一个抽象层，允许安全操作员定义攻击者和欺骗策略，并包含一个实验模块用于在模拟网络中执行。通过动作规划、可观察性、环境状态和攻击图服务等四个关键模块，Perry能够将高级规范转换为具体实现。实验证明，Perry显著降低了欺骗防御探索的复杂性，并通过模拟55个场景揭示了策略权衡。

> **摘要翻译:** 网络欺骗旨在通过蜜罐、诱饵凭证或诱饵文件等虚假资产来分散、延迟和检测网络攻击者。然而，目前操作员难以实验、探索和评估欺骗方法。现有工具和平台实现复杂且不可移植，难以修改和扩展。我们通过引入Perry来解决这一痛点，Perry是一个高级框架，可加速欺骗假设情景的设计和探索。Perry包含两个组件：一个高级抽象层，供安全操作员指定攻击者和欺骗策略；以及一个实验模块，用于在真实的模拟网络中运行这些攻击者和防御者。为了转换这些高级规范，我们为Perry设计了四个关键模块：1）一个动作规划器，将高级动作转换为低级实现；2）一个可观察性模块，将低级遥测数据转换为高级观察结果；3）一个环境状态服务，支持环境无关的策略；以及4）一个攻击图服务，用于推断攻击者如何探索环境。我们证明了Perry的抽象层减少了探索各种欺骗防御、攻击者和环境的实现工作。我们通过模拟55个独特的欺骗假设情景来展示Perry的价值，并阐明这些实验如何使操作员能够揭示微妙的权衡。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [2] [SIMulator: SIM Tracing on a (Pico-)Budget](https://arxiv.org/abs/2506.20800)
> *SIMulator：低成本（Pico-）SIM卡追踪*

*Gabriel K. Gegenhuber, Philipp É. Frenzel, Adrian Dabrowski* | **Category: cs.CR**

**Keywords:** SIM卡追踪, 蜂窝网络, 低成本硬件, 树莓派Pico, APDU

**Comment:** Accepted Poster at WiSec 2025

> **TL;DR:** 研究人员开发了一种使用低成本、通用组件（如树莓派Pico）进行SIM卡追踪的方法，极大地降低了硬件复杂性和成本，使SIM追踪技术更易于获取。

**AI_Comments:** 本文的创新点在于提出了一个低成本、易于实现的SIM卡追踪解决方案，解决了传统方法中专用硬件昂贵且复杂的痛点。通过利用通用组件和巧妙的电气解耦设计，极大地降低了SIM卡追踪的门槛，对于推动蜂窝网络安全研究和开发具有重要意义。其重要性在于能够让更多资源有限的研究人员和业余爱好者参与到SIM卡相关的研究中，从而促进该领域的知识普及和技术创新。

<details>
  <summary>Details</summary>

**Motivation:** 传统的SIM卡追踪依赖于专业硬件，这给研究人员带来了财务和物流负担，特别是对于该领域的新手。

**Method:** 通过使用UART接口和GPIO端口等简单、广泛可用的组件，并将其移植到低成本微控制器上（如树莓派Pico，4美元）。通过电气解耦SIM卡和调制解调器，并仅在APDU级别传输数据，从而显著降低了硬件复杂性。

**Result:** 实现了完整的SIM卡追踪功能，仅使用简单、广泛可用的组件和低成本微控制器。

**Conclusion:** 通过显著降低硬件要求和相关成本，旨在使SIM卡追踪技术更广泛地应用于研究人员和爱好者社区，促进蜂窝网络研究中更广泛的探索和实验。

> **ai_Abstract:** 本文介绍了一种名为“SIMulator”的创新方法，旨在降低SIM卡追踪技术的门槛。传统SIM卡追踪需要昂贵的专用硬件，而SIMulator利用简单、通用组件（如UART和GPIO）以及低成本微控制器（如树莓派Pico）实现完整的SIM卡追踪功能。其关键在于通过电气解耦SIM卡和调制解调器，并在APDU级别进行数据传输，从而大幅简化了硬件设计。这项工作旨在使SIM卡追踪技术对更广泛的研究人员和爱好者群体更易于获取，从而推动蜂窝网络研究领域的进一步探索和实验。

> **摘要翻译:** SIM卡追踪——检查、修改和中继SIM卡与调制解调器之间通信的能力——已成为蜂窝网络研究中的一项重要技术。它支持重要的安全和开发相关应用，例如模糊测试通信接口、提取会话密钥、监控隐藏的SIM卡活动（例如主动SIM卡命令或空中更新），并通过SIM卡复用促进可扩展的分布式测量平台。传统上，实现这些功能依赖于专用硬件，这可能给研究人员，特别是该领域的新手带来财务和物流负担。在这项工作中，我们展示了仅使用简单、广泛可用的组件，如UART接口和GPIO端口，就可以实现完整的SIM卡追踪功能。我们将这些功能移植到低成本微控制器上，例如树莓派Pico（4美元）。与其他方法不同，它通过电气解耦SIM卡和调制解调器并仅在APDU级别传输，显著降低了硬件复杂性。通过显著降低硬件要求和相关成本，我们旨在使SIM卡追踪技术更广泛地应用于研究人员和爱好者社区，促进蜂窝网络研究中更广泛的探索和实验。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [3] [Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis](https://arxiv.org/abs/2506.20806)
> *海报：通过基于代理的分析增强GNN在网络入侵检测中的鲁棒性*

*Zhonghao Zhan, Huichi Zhou, Hamed Haddadi* | **Category: cs.CR, cs.AI**

**Keywords:** GNN, 网络入侵检测, LLM, 对抗性攻击, 鲁棒性

**Comment:** Poster accepted at the 10th IEEE European Symposium on Security and
  Privacy (Euro S&P 2025)

> **TL;DR:** 本研究提出了一种新颖的方法，利用大型语言模型（LLMs）作为代理，在GNN处理网络入侵检测数据之前，分析并缓解对抗性扰动，从而提高GNN的鲁棒性和泛化能力。

**AI_Comments:** 该论文的创新点在于将大型语言模型（LLMs）引入到GNN的预处理阶段，作为代理来增强其在网络入侵检测中的鲁棒性。这种方法通过在GNN处理数据之前识别并缓解对抗性扰动，有效地解决了现有GNN在现实攻击下性能下降的问题。其重要性在于为GNN在安全领域的应用提供了一种新的增强策略，特别是在面对日益复杂的网络威胁时。通过使用现实世界的对抗性攻击和物理测试台数据集进行评估，增加了研究结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）在网络入侵检测系统（NIDS）中显示出巨大潜力，特别是在IoT环境中，但它们面临着由于分布漂移导致的性能下降以及对现实对抗性攻击缺乏鲁棒性的问题。当前的鲁棒性评估通常依赖不切实际的合成扰动，并且缺乏对不同类型对抗性攻击（包括黑盒和白盒场景）进行系统分析的演示。

**Method:** 本研究提出了一种新颖的方法，通过在代理管道中利用大型语言模型（LLMs）作为模拟网络安全专家代理，来增强GNN的鲁棒性和泛化能力。这些代理在GNN处理之前，审查从网络流数据派生出的图结构，识别并可能缓解可疑或对抗性扰动的元素。

**Result:** 实验使用一个为现实评估设计的框架，并利用包括从物理测试台实验收集的数据集在内的各种对抗性攻击进行测试，结果表明集成LLM分析可以显著提高基于GNN的NIDS对抗挑战的弹性。

**Conclusion:** 本研究展示了LLM代理作为入侵检测架构中互补层的潜力，能够显著提高GNN在网络入侵检测中对抗现实世界挑战的鲁棒性。

> **ai_Abstract:** 本研究旨在解决图神经网络（GNNs）在网络入侵检测系统（NIDS）中面临的鲁棒性问题，尤其是在面对现实对抗性攻击和分布漂移时。为此，论文提出了一种新颖的方法，利用大型语言模型（LLMs）作为代理，在GNN处理网络流数据之前，对图结构进行分析，以识别并缓解可疑或对抗性扰动的元素。实验结果表明，这种集成LLM分析的方法显著提高了基于GNN的NIDS的弹性，证明了LLM代理在入侵检测架构中作为补充层的有效潜力。

> **摘要翻译:** 图神经网络（GNNs）在网络入侵检测系统（NIDS）中显示出巨大潜力，特别是在IoT环境中，但它们面临着由于分布漂移导致的性能下降以及对现实对抗性攻击缺乏鲁棒性的问题。当前的鲁棒性评估通常依赖不切实际的合成扰动，并且缺乏对不同类型对抗性攻击（包括黑盒和白盒场景）进行系统分析的演示。本研究提出了一种新颖的方法，通过在代理管道中利用大型语言模型（LLMs）作为模拟网络安全专家代理，来增强GNN的鲁棒性和泛化能力。这些代理在GNN处理之前，审查从网络流数据派生出的图结构，识别并可能缓解可疑或对抗性扰动的元素。我们的实验使用一个为现实评估设计的框架，并利用包括从物理测试台实验收集的数据集在内的各种对抗性攻击进行测试，结果表明集成LLM分析可以显著提高基于GNN的NIDS对抗挑战的弹性，展示了LLM代理作为入侵检测架构中互补层的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [4] [Empowering Digital Agriculture: A Privacy-Preserving Framework for Data Sharing and Collaborative Research](https://arxiv.org/abs/2506.20872)
> *赋能数字农业：一个用于数据共享和协作研究的隐私保护框架*

*Osama Zafar, Rosemarie Santa González, Mina Namazi, Alfonso Morales, Erman Ayday* | **Category: cs.CR, cs.LG**

**Keywords:** 数字农业, 隐私保护, 数据共享, 差分隐私, 联邦学习

**Comment:** arXiv admin note: text overlap with arXiv:2409.06069

> **TL;DR:** 本文提出了一个结合降维和差分隐私的框架，旨在解决数字农业中数据共享的隐私问题，从而实现安全协作和模型训练。该框架在真实数据集上得到了验证，证明了其强大的隐私保护能力和实用性能。

**AI_Comments:** 这项工作创新性地结合了降维技术和差分隐私来解决数字农业中数据共享的实际隐私问题，这对于推动农业数字化转型至关重要。其在真实数据集上的验证增强了方案的实用性和可信度。该框架不仅关注技术实现，还考虑了农民和研究人员的实际协作需求，具有重要的应用前景和政策指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 数据驱动的农业有潜力提高作物产量、疾病抵抗力和土壤健康。然而，隐私担忧，如不利定价、歧视和资源操纵，阻碍农民分享数据，因为这些数据可能被用来对付他们。

**Method:** 本文提出了一个隐私保护框架，旨在实现安全的数据共享和协作研究，同时减轻隐私风险。该框架结合了降维技术（如主成分分析PCA）和通过引入拉普拉斯噪声实现的差分隐私来保护敏感信息。它允许研究人员识别目标农民的潜在合作者，并通过联邦学习在已识别合作者的数据上或直接在聚合的隐私保护数据上训练个性化机器学习模型。此外，该框架还允许农民根据相似性识别潜在合作者。

**Result:** 该框架已在真实数据集上进行了验证，展示了对对抗性攻击的强大隐私保护能力，以及与中心化系统相当的实用性能。研究表明，该框架能够促进农民之间的协作，并帮助研究人员实现更广泛的研究目标。

**Conclusion:** 该框架的采用可以赋能研究人员和政策制定者负责任地利用农业数据，为数据驱动农业的变革性进步铺平道路。通过解决关键的隐私挑战，这项工作支持安全的数据集成，促进农业系统的创新和可持续性。

> **ai_Abstract:** 本文提出了一个隐私保护框架，旨在解决数字农业中数据共享的隐私障碍。该框架创新性地结合了降维技术（如PCA）和差分隐私（通过引入拉普拉斯噪声），以实现安全的数据共享和协作研究。它不仅支持研究人员识别潜在合作者并在此基础上训练个性化机器学习模型，也允许农民根据相似性寻找合作伙伴。该框架在真实数据集上的验证结果显示，其具备强大的隐私保护能力，同时保持了与中心化系统相当的实用性能。这项工作有望促进农业数据的负责任利用，从而推动数据驱动农业的创新和可持续发展。

> **摘要翻译:** 数据驱动的农业，将技术和数据整合到农业实践中，有潜力提高作物产量、疾病抵抗力和长期土壤健康。然而，隐私担忧，如不利定价、歧视和资源操纵，阻碍农民分享数据，因为这些数据可能被用来对付他们。为了解决这一障碍，我们提出了一个隐私保护框架，该框架能够实现安全的数据共享和研究开发协作，同时减轻隐私风险。该框架结合了降维技术（如主成分分析（PCA））和通过引入拉普拉斯噪声实现的差分隐私来保护敏感信息。所提出的框架允许研究人员识别目标农民的潜在合作者，并通过联邦学习在已识别合作者的数据上或直接在聚合的隐私保护数据上训练个性化机器学习模型。它还允许农民根据相似性识别潜在合作者。我们已在真实数据集上验证了这一点，展示了对对抗性攻击的强大隐私保护能力，以及与中心化系统相当的实用性能。我们展示了该框架如何促进农民之间的协作，并帮助研究人员追求更广泛的研究目标。该框架的采用可以赋能研究人员和政策制定者负责任地利用农业数据，为数据驱动农业的变革性进步铺平道路。通过解决关键的隐私挑战，这项工作支持安全的数据集成，促进农业系统的创新和可持续性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [30] [ZKPROV: A Zero-Knowledge Approach to Dataset Provenance for Large Language Models](https://arxiv.org/abs/2506.20915)
> *ZKPROV：一种用于大型语言模型数据集溯源的零知识方法*

*Mina Namazi, Alexander Nemecek, Erman Ayday* | **Category: cs.CR, cs.AI, cs.LG**

**Keywords:** 零知识证明, 数据集溯源, 大型语言模型, 隐私保护, 加密框架

**Comment:** 12 pages, 1 figure

> **TL;DR:** ZKPROV是一种零知识证明框架，用于验证大型语言模型是否在可靠数据集上训练，同时保护数据隐私和模型参数信息，且比现有方法更高效实用。

**AI_Comments:** ZKPROV的创新之处在于其在保护隐私和计算效率之间找到了一个独特的平衡点，解决了LLM在敏感领域部署的关键痛点。它避免了对整个训练过程进行昂贵的验证，而是专注于数据集与模型的绑定，这对于实际应用具有重要意义。形式化的安全保证也增加了其可信度。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）在敏感领域的部署，确保其计算溯源的完整性成为一个关键挑战，特别是在医疗保健等受监管部门，对数据集使用有严格要求。现有方法要么计算成本高昂（完全验证训练过程），要么依赖可信执行环境。

**Method:** ZKPROV通过零知识证明将训练好的模型与其授权训练数据集进行加密绑定，避免了对每个训练步骤的证明。它利用数据集签名的元数据和紧凑的模型参数承诺，提供可靠且保护隐私的保证，证明LLM的结果源自于在声明的授权相关数据集上训练的模型。

**Result:** 实验结果表明ZKPROV在生成和验证证明方面具有效率和可扩展性，为实际部署提供了实用的解决方案。该方法还提供了形式化的安全保证，证明其在确保可信数据集溯源的同时保留了数据集的机密性。

**Conclusion:** ZKPROV提供了一种实用、高效且保护隐私的零知识方法，用于验证大型语言模型的数据集溯源，解决了在敏感领域部署LLM时的数据完整性挑战。

> **ai_Abstract:** ZKPROV是一个新颖的零知识证明框架，旨在解决大型语言模型在敏感领域部署时的数据集溯源完整性挑战。它允许用户在不泄露敏感数据或模型参数的情况下，验证模型是否在授权数据集上训练。与现有高成本或依赖可信环境的方法不同，ZKPROV通过加密绑定模型与数据集，并利用数据集签名元数据和模型参数承诺，提供高效、可扩展且隐私保护的解决方案，确保LLM结果的可靠溯源。该方法已通过实验验证其效率和实用性，并提供了形式化的安全保证。

> **摘要翻译:** 随着大型语言模型（LLM）在敏感领域的部署日益增多，确保其计算溯源的完整性成为一个关键挑战，特别是在医疗保健等受监管部门，对数据集的使用有严格要求。我们引入了ZKPROV，一个新颖的加密框架，能够实现LLM溯源的零知识证明。它允许用户验证模型是否在可靠数据集上训练，而无需透露有关数据集或模型参数的敏感信息。与之前专注于训练过程的完整验证（导致显著的计算成本）或依赖可信执行环境的方法不同，ZKPROV提供了独特的平衡。我们的方法通过零知识证明将训练好的模型与其授权训练数据集加密绑定，同时避免证明每个训练步骤。通过利用数据集签名的元数据和紧凑的模型参数承诺，ZKPROV提供了可靠且保护隐私的保证，确保LLM的结果源自于在声明的授权和相关数据集上训练的模型。实验结果表明ZKPROV在生成和验证此证明方面具有效率和可扩展性，实现了实际部署的实用解决方案。我们还提供了形式化的安全保证，证明我们的方法在确保可信数据集溯源的同时保留了数据集的机密性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [54] [CodeGuard: A Generalized and Stealthy Backdoor Watermarking for Generative Code Models](https://arxiv.org/abs/2506.20926)
> *CodeGuard：一种用于生成式代码模型的通用且隐蔽的后门水印技术*

*Haoxuan Li, Jiale Zhang, Xiaobing Sun, Xiapu Luo* | **Category: cs.CR**

**Keywords:** 生成式代码模型, 后门水印, CodeGuard, 隐蔽性, 泛化性

**Comment:** 13 pages

> **TL;DR:** CodeGuard是一种新型后门水印技术，通过结合注意力机制和分布式触发器嵌入，解决了生成式代码模型水印在通用性和隐蔽性方面的挑战，实现了高验证率和低检测率。

**AI_Comments:** CodeGuard的创新点在于其结合注意力机制、同形字符替换和分布式触发器嵌入，有效提升了后门水印的通用性和隐蔽性，这对于保护生成式代码模型的知识产权具有重要意义。其在不影响模型核心性能的前提下，实现了高验证率和极低的检测率，展现了该方法的实用性和先进性。

<details>
  <summary>Details</summary>

**Motivation:** 生成式代码模型（GCMs）的训练成本高昂，需要有效的数字版权保护以防止未经授权的泄露和滥用。现有的后门水印技术存在两个主要挑战：一是跨任务和数据集的泛化能力有限，导致验证率波动；二是隐蔽性不足，水印容易被自动化方法检测和移除。

**Method:** 本文提出了CodeGuard，一种结合注意力机制和分布式触发器嵌入策略的新型水印方法。CodeGuard利用注意力机制识别水印嵌入位置以确保可验证性；通过同形字符替换避免人工检测；并通过分布式触发器嵌入降低自动化检测的可能性。

**Result:** 实验结果表明，CodeGuard在代码摘要和代码生成任务中均实现了高达100%的水印验证率，且不影响主要任务性能。在隐蔽性方面，CodeGuard表现出色，针对ONION检测方法的最高检测率仅为0.078，远低于基线方法。

**Conclusion:** CodeGuard成功解决了生成式代码模型后门水印在通用性和隐蔽性方面的挑战，实现了高验证率和低检测率，同时保持了模型的主要任务性能。

> **ai_Abstract:** 本文提出了一种名为CodeGuard的新型后门水印技术，旨在解决生成式代码模型版权保护中现有水印方法在泛化性和隐蔽性上的不足。CodeGuard结合了注意力机制以精确识别水印嵌入位置，并采用同形字符替换和分布式触发器嵌入策略来增强水印的隐蔽性，使其难以被人工或自动化方法检测。实验证明，CodeGuard在代码摘要和代码生成任务中均能达到近乎完美的水印验证率，同时对模型主要性能无影响，并且在隐蔽性方面显著优于现有基线方法。

> **摘要翻译:** 生成式代码模型（GCMs）通过自动化代码生成和代码摘要显著提升了开发效率。然而，构建和训练这些模型需要大量的计算资源和时间，因此需要有效的数字版权保护来防止未经授权的泄露和滥用。后门水印技术通过嵌入隐藏标识符，打破了模型的黑盒性质，从而简化了版权验证。当前后门水印技术面临两大挑战：首先，在不同任务和数据集上的泛化能力有限，导致验证率波动；其次，隐蔽性不足，水印容易被自动化方法检测和移除。为了解决这些问题，我们提出了CodeGuard，一种结合注意力机制和分布式触发器嵌入策略的新型水印方法。具体而言，CodeGuard采用注意力机制来识别水印嵌入位置，确保可验证性。此外，通过使用同形字符替换，它避免了人工检测，而分布式触发器嵌入则降低了自动化检测的可能性。实验结果表明，CodeGuard在代码摘要和代码生成任务中均实现了高达100%的水印验证率，且不影响主要任务性能。在隐蔽性方面，CodeGuard表现出色，针对ONION检测方法的最高检测率仅为0.078，显著低于基线方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [79] [SPA: Towards More Stealth and Persistent Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2506.20931)
> *SPA：迈向联邦学习中更隐蔽和持久的后门攻击*

*Chengcheng Zhu, Ye Li, Bosen Rao, Jiale Zhang, Yunlong Mao, Sheng Zhong* | **Category: cs.CR**

**Keywords:** 联邦学习, 后门攻击, 特征空间对齐, 隐蔽性, 持久性

**Comment:** 18 pages

> **TL;DR:** 本文提出了一种名为SPA的新型隐蔽后门攻击框架，通过特征空间对齐而非直接标签关联，实现联邦学习中更隐蔽、持久且对防御机制鲁棒的后门攻击。

**AI_Comments:** SPA通过引入特征空间对齐而非传统的标签关联，显著提升了联邦学习中后门攻击的隐蔽性和持久性，这是一种重要的创新。其对防御机制和非IID数据分布的鲁棒性也增强了其威胁性。这项工作的重要性在于它揭示了现有防御可能不足以应对更高级的特征级攻击，并强调了开发相应防御技术的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）面临后门攻击的独特安全挑战。现有后门策略主要依赖端到端标签监督，但这会导致可检测的特征解耦和有限的持久性。

**Method:** 本文提出了一种名为SPA的新型隐蔽后门攻击框架。它通过利用特征空间对齐而非直接触发器-标签关联来减少后门触发器特征与目标类特征之间的表征距离，从而使全局模型能够以高隐蔽性和持久性错误分类嵌入触发器的输入。此外，还引入了一种自适应的对抗性触发器优化机制，利用特征空间中的边界搜索来增强攻击的持久性和有效性，即使面对防御性FL场景和非IID数据分布也能奏效。

**Result:** 在各种FL基准上的大量实验表明，SPA始终以最小的模型效用影响实现高攻击成功率，在挑战性的参与和数据异构条件下保持鲁棒性，并展现出远超传统技术的持久后门效应。

**Conclusion:** 本文结果呼吁紧急关注FL中后门威胁日益增长的复杂性，并强调迫切需要先进的特征级防御技术。

> **ai_Abstract:** 本文提出了一种名为SPA的新型后门攻击框架，旨在解决联邦学习中现有后门攻击可检测性高和持久性差的问题。SPA通过在特征空间中对齐后门触发器和目标类别特征，而非依赖传统的触发器-标签关联，实现了更高的隐蔽性和持久性。它还引入了自适应对抗性触发器优化机制，以增强攻击在防御和非IID数据环境下的鲁棒性。实验证明，SPA在保持模型效用的同时，能达到高攻击成功率并展现出卓越的持久性，揭示了联邦学习中后门威胁的复杂演变。

> **摘要翻译:** 联邦学习（FL）已成为一种领先的保护隐私的分布式机器学习范式，然而FL的分布式特性带来了独特的安全挑战，特别是后门攻击的威胁。现有的后门策略主要依赖端到端标签监督，尽管它们有效，但通常会导致可检测的特征解耦和有限的持久性。在这项工作中，我们提出了一种新颖且隐蔽的后门攻击框架，名为SPA，它通过利用特征空间对齐而非直接触发器-标签关联，从根本上脱离了传统方法。具体来说，SPA减少了后门触发器特征和目标类特征之间的表征距离，使全局模型能够以高隐蔽性和持久性错误分类嵌入触发器的输入。我们进一步引入了一种自适应的对抗性触发器优化机制，利用特征空间中的边界搜索来增强攻击的持久性和有效性，即使面对防御性FL场景和非IID数据分布也能奏效。在各种FL基准上的大量实验表明，SPA始终以最小的模型效用影响实现高攻击成功率，在挑战性的参与和数据异构条件下保持鲁棒性，并展现出远超传统技术的持久后门效应。我们的结果呼吁紧急关注FL中后门威胁日益增长的复杂性，并强调迫切需要先进的特征级防御技术。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [85] [Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations](https://arxiv.org/abs/2506.21134)
> *内部工作：防御Kubernetes集群的网络错误配置*

*Jacopo Bufalino, Jose Luis Martin-Navarro, Mario Di Francesco, Tuomas Aura* | **Category: cs.CR, cs.NI**

**Keywords:** Kubernetes安全, 网络错误配置, 横向移动, 容器编排, 应用安全

**Comment:** 

> **TL;DR:** 研究发现Kubernetes集群中普遍存在网络错误配置，可能导致横向移动攻击，并提出了修复方案。

**AI_Comments:** 这篇论文通过对实际开源应用的广泛分析，揭示了Kubernetes网络配置中普遍存在的安全漏洞，这对于提升Kubernetes集群的实际安全性具有重要意义。其负责任的披露和推动修复的行动也值得肯定。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Kubernetes安全性研究广泛，但对网络配置对应用部署安全的影响关注不足，特别是横向移动方面。

**Method:** 对来自六个不同组织的287个开源应用程序进行了广泛评估，以分析Kubernetes集群中的网络错误配置。

**Result:** 识别出634个网络错误配置，远超现有解决方案的发现能力；向相关组织披露了发现，并已修复了30多个受影响应用的错误配置。

**Conclusion:** 通过分析和披露，证明了网络错误配置在Kubernetes集群中的普遍性和严重性，并成功推动了部分修复。

> **ai_Abstract:** 本文针对Kubernetes集群中网络配置对应用安全的影响这一研究空白，特别是横向移动风险，进行了全面分析。通过评估287个开源应用，发现了634个网络错误配置，并成功推动了其中30多个应用的修复，强调了网络配置在Kubernetes安全中的关键作用。

> **摘要翻译:** Kubernetes已成为容器编排的事实标准。不幸的是，其日益增长的普及也使其成为恶意行为者的诱人目标。尽管对保护Kubernetes进行了广泛研究，但很少关注网络配置对应用程序部署安全的影响。本文通过对Kubernetes集群中的网络错误配置进行全面分析，特别是针对横向移动，解决了这一空白。因此，我们对来自六个不同组织（从IT公司和公共实体到非营利组织）的287个开源应用程序进行了广泛评估。结果，我们识别出634个错误配置，远远超出了现有解决方案所能发现的范围。我们负责任地向相关组织披露了我们的发现，并进行了讨论以评估其严重性。截至目前，影响30多个应用程序的错误配置已通过我们提出的缓解措施得到修复。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [103] [PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection](https://arxiv.org/abs/2506.20981)
> *PrivacyGo：多维交集下的隐私保护广告测量*

*Jian Du, Haohao Qian, Shikun Zhang, Wen-jie Lu, Donghang Lu, Yongchuan Niu, Bo Jiang, Yongjun Zhao, Qiang Yan* | **Category: cs.CR**

**Keywords:** 隐私保护, 广告测量, OPRF, 差分隐私, 多标识符匹配

**Comment:** 

> **TL;DR:** PrivacyGo提出了一种结合反向不经意伪随机函数和盲密钥轮换技术，并加入差分隐私机制的加密框架，用于多标识符隐私保护广告测量，实现了高效且可扩展的解决方案。

**AI_Comments:** 该论文的创新点在于结合了反向不经意伪随机函数（OPRF）、盲密钥轮换技术和差分隐私，以实现多标识符下的隐私保护广告测量。其重要性在于解决了广告行业中用户数据匹配的隐私挑战，尤其是在大规模数据集下的实用性和可扩展性，这对于当前数据隐私日益受关注的环境至关重要。该框架为未来的隐私保护广告技术发展提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现代广告分析中，多标识符私有用户档案匹配是一个具有挑战性的实际问题，尤其是在隐私保护广告测量方面。当前的解决方案面临跨标识符链接和成员推断攻击的风险。

**Method:** 本文提出了一种全面的加密框架，利用反向不经意伪随机函数（OPRF）和新颖的盲密钥轮换技术，以支持多标识符之间的安全匹配。该设计能防止跨标识符链接，并包含一个差分隐私机制来混淆交集大小，从而减轻成员推断攻击等风险。

**Result:** 所提出的协议实现了强大的隐私保证和高效率，能够扩展到大型数据集，为安全广告转化跟踪等以隐私为中心的应用程序提供了一个实用且可扩展的解决方案。

**Conclusion:** 本文结合严格的密码学原理与差分隐私，解决了广告行业的一个关键需求，为隐私保护广告测量框架设定了新标准。

> **ai_Abstract:** PrivacyGo提出了一种创新的加密框架，用于解决多标识符隐私保护广告测量中的用户档案匹配问题。该框架结合了反向不经意伪随机函数（OPRF）和盲密钥轮换技术，确保了跨标识符的安全匹配，并利用差分隐私机制来保护交集大小，有效抵御了成员推断攻击。该方案不仅提供了强大的隐私保障，还具备高效率和可扩展性，为广告行业的安全转化跟踪等应用提供了实用且可行的解决方案，为隐私保护广告测量设立了新标准。

> **摘要翻译:** 本文解决了多标识符私有用户档案匹配这一具有挑战性且实际的问题，这是隐私保护广告测量（现代广告分析的基石）的核心。我们引入了一个全面的加密框架，利用反向不经意伪随机函数（OPRF）和新颖的盲密钥轮换技术，以支持跨多个标识符的安全匹配。我们的设计可防止跨标识符链接，并包含一个差分隐私机制来混淆交集大小，从而减轻成员推断攻击等风险。我们提出了一个具体的协议构建，实现了强大的隐私保证和高效率。它能够扩展到大型数据集，为安全广告转化跟踪等以隐私为中心的应用程序提供了一个实用且可扩展的解决方案。通过将严格的密码学原理与差分隐私相结合，我们的工作解决了广告行业的一个关键需求，为隐私保护广告测量框架设定了新标准。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [125] [TEMPEST-LoRa: Cross-Technology Covert Communication](https://arxiv.org/abs/2506.21069)
> *TEMPEST-LoRa: 跨技术秘密通信*

*Xieyang Sun, Yuanqing Zheng, Wei Xi, Zuhao Chen, Zhizhen Chen, Han Hao, Zhiping Jiang, Sheng Zhong* | **Category: cs.CR**

**Keywords:** 秘密通信, 电磁泄漏, LoRa, 气隙网络, 交叉技术通信

**Comment:** 15 pages, 19 figures, and this paper has been accepted to ACM CCS
  2025

> **TL;DR:** 本文介绍了一种名为TEMPEST-LoRa的新型电磁秘密信道，它利用交叉技术秘密通信（CTCC），允许攻击者将气隙网络中的秘密数据传输到远距离的LoRa接收器，并展示了通过操纵视频线缆实现远距离和高速数据传输的可行性。

**AI_Comments:** 本文提出了一种创新的秘密通信方法，通过利用现有设备的电磁泄漏与广泛部署的LoRa技术相结合，显著降低了攻击的门槛和可检测性。其创新之处在于利用了“交叉技术”的概念，使得无需专门接收设备即可进行远距离秘密通信。这对于气隙网络的安全防护提出了新的挑战，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 电磁（EM）秘密信道对气隙网络中的计算机和通信安全构成重大威胁。以往的方法需要攻击者在受害者附近部署高度专业化的接收器，这限制了其实际影响。本文旨在解决这一局限性，并揭示利用广泛部署的LoRa接收器进行秘密通信的潜在风险。

**Method:** 本文提出了一种名为TEMPEST-LoRa的新型电磁秘密信道，它基于交叉技术秘密通信（CTCC）。该方法通过操纵视频线缆来精确生成电磁泄漏，这些泄漏可以被第三方商用LoRa节点/网关接收。作者通过实验证明了CTCC的可行性，并展示了数据传输能力。

**Result:** 实验结果表明，攻击者可以可靠地解码来自视频线缆电磁泄漏调制下的秘密数据。最大传输距离达到87.5米，或最高传输速率达到21.6 kbps。此外，秘密数据传输可以在显示器关闭的情况下进行，从而实现隐蔽性。

**Conclusion:** 本文揭示了交叉技术秘密通信（CTCC）的潜在风险，并证明了利用视频线缆的电磁泄漏向远距离的商用LoRa接收器进行秘密数据传输的可行性，这表明了气隙网络安全面临的新威胁。

> **ai_Abstract:** 本文介绍了一种名为TEMPEST-LoRa的新型电磁秘密信道，旨在解决传统秘密通信方法对专用接收器依赖的局限性。通过利用交叉技术秘密通信（CTCC），该方法能够将气隙网络中的秘密数据，通过操纵视频线缆产生的电磁泄漏，传输到远距离的商用LoRa接收器。实验证明了这种方法的有效性，实现了87.5米的最大传输距离或21.6 kbps的最高传输速率，且可在显示器关闭时隐蔽进行，揭示了CTCC带来的新安全风险。

> **摘要翻译:** 电磁（EM）秘密信道对气隙网络中的计算机和通信安全构成重大威胁。以往的工作利用各种组件（如视频线缆、内存总线、CPU）的电磁辐射来秘密发送敏感信息。这些方法通常要求攻击者在受害者附近部署高度专业化的接收器，这限制了其实际影响。本文报告了一种新的电磁秘密信道——TEMPEST-LoRa，它建立在交叉技术秘密通信（CTCC）的基础上，可以允许攻击者将电磁调制的秘密数据从气隙网络秘密传输到远距离的广泛部署的LoRa接收器。我们揭示了CTCC的潜在风险，并通过解决操纵视频线缆以精确生成可被第三方商用LoRa节点/网关轻易接收的电磁泄漏所涉及的实际挑战，证明了其可行性。实验结果表明，攻击者可以可靠地解码由视频线缆的电磁泄漏调制的秘密数据，最大距离可达87.5米或速率可达21.6 kbps。我们注意到秘密数据传输可以在显示器关闭的情况下进行（因此是隐蔽的）。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [144] [PhishKey: A Novel Centroid-Based Approach for Enhanced Phishing Detection Using Adaptive HTML Component Extraction](https://arxiv.org/abs/2506.21106)
> *PhishKey：一种使用自适应HTML组件提取增强网络钓鱼检测的新型基于质心的方法*

*Felipe Castaño, Eduardo Fidalgo, Enrique Alegre, Rocio Alaiz-Rodríguez, Raul Orduna, Francesco Zola* | **Category: cs.CR, cs.AI**

**Keywords:** 网络钓鱼检测, 质心方法, HTML组件提取, 卷积神经网络, 软投票集成

**Comment:** 

> **TL;DR:** PhishKey是一种结合URL CNN分类和HTML质心提取的新型网络钓鱼检测方法，通过软投票集成提高准确性和鲁棒性，在多个数据集上表现出色。

**AI_Comments:** PhishKey的创新之处在于其混合方法，结合了URL的字符级CNN处理和HTML内容的词级质心提取，并通过软投票集成增强了性能。其对对抗性攻击的鲁棒性是其重要优势，这在当前复杂的网络安全环境中至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 网络钓鱼攻击构成重大网络安全威胁，且快速演变以规避检测机制并利用人类弱点。现有方法面临适应性、鲁棒性和效率方面的挑战。

**Method:** 本文引入PhishKey，这是一种新型网络钓鱼检测方法，通过从混合源进行自动特征提取。PhishKey结合了字符级处理与卷积神经网络 (CNN) 用于URL分类，以及一个基于质心的关键组件网络钓鱼提取器 (CAPE) 用于词级别的HTML内容处理。CAPE旨在减少噪声并确保完整样本处理，避免对输入数据进行裁剪操作。来自两个模块的预测通过软投票集成进行整合，以实现更准确和可靠的分类。

**Result:** 在四个先进数据集上进行的实验评估证明了PhishKey的有效性。它实现了高达98.70%的F1分数，并显示出对注入攻击等对抗性操纵的强大抵抗力，性能下降最小。

**Conclusion:** PhishKey通过结合URL和HTML内容分析，并采用集成学习，能够有效且鲁棒地检测网络钓鱼攻击，即使面对对抗性操纵也能保持高性能。

> **ai_Abstract:** PhishKey是一种新颖的网络钓鱼检测系统，旨在解决现有方法的适应性、鲁棒性和效率挑战。它通过结合基于CNN的URL字符级分类和基于质心的HTML内容词级提取（CAPE）来自动提取混合源特征。PhishKey利用软投票集成融合两个模块的预测结果，以提高检测的准确性和可靠性。实验结果表明，PhishKey在多个数据集上表现出色，F1分数高达98.70%，并对对抗性攻击具有强大的抵抗力。

> **摘要翻译:** 网络钓鱼攻击构成重大的网络安全威胁，它们快速演变以规避检测机制并利用人类的脆弱性。本文引入PhishKey以解决适应性、鲁棒性和效率方面的挑战。PhishKey是一种新颖的网络钓鱼检测方法，它利用从混合源自动提取特征。PhishKey结合了字符级处理与卷积神经网络（CNN）用于URL分类，以及一个基于质心的关键组件网络钓鱼提取器（CAPE）用于词级别的HTML内容。CAPE减少了噪声并确保了完整的样本处理，避免了对输入数据进行裁剪操作。来自两个模块的预测通过软投票集成进行整合，以实现更准确和可靠的分类。在四个最先进数据集上的实验评估证明了PhishKey的有效性。它实现了高达98.70%的F1分数，并显示出对注入攻击等对抗性操纵的强大抵抗力，性能下降最小。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [148] [Balancing Privacy and Utility in Correlated Data: A Study of Bayesian Differential Privacy](https://arxiv.org/abs/2506.21308)
> *关联数据中隐私与效用的平衡：一项关于贝叶斯差分隐私的研究*

*Martin Lange, Patricia Guerra-Balboa, Javier Parra-Arnau, Thorsten Strufe* | **Category: cs.CR, cs.IT, math.IT, 68P27**

**Keywords:** 贝叶斯差分隐私, 关联数据, 隐私保护, 效用

**Comment:** This is the extended version of the paper accepted in the Proceedings
  of the VLDB Endowment (PVLDB), 2025. The code used for our experiments is
  accessible in https://github.com/lange-martin/privacy-utility-bdp

> **TL;DR:** 解决了贝叶斯差分隐私在关联数据中应用时效用损失大的问题，通过新方法实现了在保持效用下对关联数据的隐私保护。

**AI_Comments:** 本文解决了贝叶斯差分隐私在实际应用中面临的效用损失这一关键挑战，其创新点在于提出了新颖的理论和方法，使得BDP能够在关联数据中实现高效用隐私保护。这对于提升差分隐私在复杂现实世界数据中的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准差分隐私在关联数据中隐私风险高，而贝叶斯差分隐私（BDP）虽能考虑关联性，但现有机制导致显著的效用损失，限制了其应用。本研究旨在探究BDP如何在不牺牲效用的情况下应用于常见数据结构。

**Method:** 通过分析任意和结构化的关联模型（包括高斯多元分布和马尔可夫链），推导了BDP的实用效用保证。贡献包括建立了DP和BDP之间的理论联系，并提出了一种新颖的方法来调整DP机制以满足BDP要求。

**Result:** 在真实世界数据库上的评估表明，他们的新定理能够设计出保持竞争性效用的BDP机制。

**Conclusion:** 这项工作为在关联数据环境中实现实用的隐私保护数据实践铺平了道路。

> **ai_Abstract:** 本文研究了在关联数据中应用贝叶斯差分隐私（BDP）时效用损失的问题。针对标准差分隐私在关联数据中隐私泄露评估不足的挑战，作者通过分析多种关联模型，推导了BDP的实用效用保证。研究提出了一种新方法，将标准差分隐私机制调整以满足BDP要求，并在真实世界数据上验证了其设计的BDP机制能够在保持竞争性效用的同时提供隐私保护，从而推动了关联数据中隐私保护实践的落地。

> **摘要翻译:** 差分隐私（DP）系统中，当数据存在关联时，隐私风险显著增加，因为标准的DP度量通常低估了由此产生的隐私泄露，使敏感信息容易受到攻击。鉴于现实世界数据库中依赖关系的普遍性，这种疏忽对隐私保护构成了严峻挑战。贝叶斯差分隐私（BDP）扩展了DP以考虑这些关联，但当前的BDP机制表现出显著的效用损失，限制了其采用。
在这项工作中，我们探讨了BDP是否可以在不牺牲效用的情况下在常见数据结构中实际实现——这是其适用性的一个关键因素。通过分析任意和结构化的关联模型，包括高斯多元分布和马尔可夫链，我们推导了BDP的实用效用保证。我们的贡献包括DP和BDP之间的理论联系，以及一种调整DP机制以满足BDP要求的新颖方法。通过对真实世界数据库的评估，我们证明了我们的新定理能够设计出保持竞争性效用的BDP机制，为在关联设置中实现实用的隐私保护数据实践铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [5] [Ad-Hoc Human-AI Coordination Challenge](https://arxiv.org/abs/2506.21490)
> *临时人机协作挑战*

*Tin Dizdarević, Ravi Hammond, Tobias Gessler, Anisoara Calinescu, Jonathan Cook, Matteo Gallici, Andrei Lupu, Jakob Nicolaus Foerster* | **Category: cs.AI, cs.HC, cs.MA**

**Keywords:** 人机协作, 人类代理, Hanabi, 评估, 数据集

**Comment:** Published at ICML 2025

> **TL;DR:** 引入AH2AC2挑战和人类代理，以解决人机协作中昂贵且难以复现的人类评估问题，并提供Hanabi游戏的基线结果和数据集。

**AI_Comments:** 这项工作创新性地提出了“人类代理”的概念和AH2AC2挑战，有效解决了人机协作研究中人类评估成本高、复现性差的关键瓶颈。通过提供可控的评估环境和受限数据集，它有望加速数据高效型人机协作AI的发展。其重要性在于为未来的人机协作研究提供了一个标准化的、可扩展的评估框架。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中实现AI代理和人类之间的无缝协作至关重要，但目前仍是一个重大的开放挑战。Hanabi作为人机协作的理想测试平台，其使用却因人类评估的成本高昂和难以复现而受到限制。

**Method:** 引入了临时人机协作挑战（AH2AC2），通过在大规模人类数据集上开发“人类代理”，使其成为AH2AC2中鲁棒、廉价且可复现的类人评估伙伴。同时，开源了一个包含3,079场游戏的受限人类游戏数据集，并提供了一个受控评估系统以确保公平评估。

**Result:** 提供了两人和三人Hanabi场景的基线结果。

**Conclusion:** 通过引入AH2AC2和人类代理，本研究为克服人机协作中昂贵且难以复现的人类评估问题提供了一个创新且可复现的解决方案，并促进了数据高效方法的发展。

> **ai_Abstract:** 这项工作提出了临时人机协作挑战（AH2AC2），旨在解决人机协作领域中昂贵且难以复现的人类评估问题。通过在大规模人类数据集上开发“人类代理”，AH2AC2提供了一种鲁棒、廉价且可复现的评估方法。研究者开源了一个受限的人类游戏数据集，并展示了Hanabi游戏的基线结果，以促进数据高效方法的开发。

> **摘要翻译:** 实现AI代理和人类之间的无缝协作对于实际应用至关重要，但这仍然是一个重大的开放挑战。花火（Hanabi）是一款具有不完美信息、受限通信、心智理论要求和协调行动的合作纸牌游戏——使其成为人机协作的理想测试平台。然而，由于人类评估的挑战，其在人机交互中的使用受到了限制。在这项工作中，我们引入了临时人机协作挑战（Ad-Hoc Human-AI Coordination Challenge, AH2AC2）来克服昂贵且难以复现的人类评估的限制。我们基于大规模人类数据集开发了“人类代理”（human proxy agents），它们在AH2AC2中作为鲁棒、廉价且可复现的类人评估伙伴。为了鼓励数据高效方法的发展，我们开源了一个包含3,079场游戏的数据集，并刻意限制了可用的人类游戏数据量。我们展示了两人和三人花火场景的基线结果。为确保公平评估，我们通过受控评估系统托管代理，而不是公开发布它们。代码可在https://github.com/FLAIROx/ah2ac2获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [19] [The Singapore Consensus on Global AI Safety Research Priorities](https://arxiv.org/abs/2506.20702)
> *新加坡全球人工智能安全研究优先事项共识*

*Yoshua Bengio, Tegan Maharaj, Luke Ong, Stuart Russell, Dawn Song, Max Tegmark, Lan Xue, Ya-Qin Zhang, Stephen Casper, Wan Sie Lee, Sören Mindermann, Vanessa Wilfred, Vidhisha Balachandran, Fazl Barez, Michael Belinsky, Imane Bello, Malo Bourgon, Mark Brakel, Siméon Campos, Duncan Cass-Beggs, Jiahao Chen, Rumman Chowdhury, Kuan Chua Seah, Jeff Clune, Juntao Dai, Agnes Delaborde, Nouha Dziri, Francisco Eiras, Joshua Engels, Jinyu Fan, Adam Gleave, Noah Goodman, Fynn Heide, Dan Hendrycks, Cyrus Hodes, Bryan Low Kian Hsiang, Minlie Huang, Sami Jawhar, Wang Jingyu, Adam Tauman Kalai, Meindert Kamphuis, Mohan Kankanhalli, Subhash Kantamneni, Mathias Bonde Kirk, Thomas Kwa, Jeffrey Ladish, Kwok-Yan Lam, Wan Lee Sie, Taewhi Lee, Xiaojian Li, Jiajun Liu, Chaochao Lu, Yifan Mai, Richard Mallah, Julian Michael, Nick Moës, Simon Möller, Kihyuk Nam, Kwan Yee Ng, Mark Nitzberg, Besmira Nushi, Seán O hÉigeartaigh, Alejandro Ortega, Pierre Peigné, James Petrie, Benjamin Prud'Homme, Reihaneh Rabbany, Nayat Sanchez-Pi, Sarah Schwettmann, Buck Shlegeris, Saad Siddiqui, Aradhana Sinha, Martín Soto, Cheston Tan, Dong Ting, Robert Trager, Brian Tse, Anthony Tung K. H., Vanessa Wilfred, John Willes, Denise Wong, Wei Xu, Rongwu Xu, Yi Zeng, HongJiang Zhang, Djordje Žikelić* | **Category: cs.AI, cs.CY**

**Keywords:** AI安全, 研究优先事项, 新加坡共识, 可信AI, 纵深防御模型

**Comment:** Final report from the "2025 Singapore Conference on AI (SCAI)" held
  April 26: https://www.scai.gov.sg/2025/scai2025-report

> **TL;DR:** 新加坡会议汇集全球AI科学家，旨在识别并整合AI安全研究重点，并将其分为开发、评估和控制三大领域，以构建可信赖的AI生态系统。

**AI_Comments:** 这份报告的重要性在于它提供了一个全球性的、结构化的AI安全研究框架，通过新加坡会议汇集了国际共识，并在此基础上将复杂的AI安全挑战划分为可操作的“开发、评估、控制”三大领域，这对于指导未来的AI安全研究和政策制定具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 确保AI安全（可信、可靠、安全）对于构建信任生态系统至关重要，这有助于人们自信地拥抱AI，最大化创新空间，同时避免负面影响。

**Method:** 通过举办“2025新加坡人工智能会议（SCAI）：国际人工智能安全科学交流”，汇集全球AI科学家，以识别和综合AI安全研究优先事项。该报告基于Yoshua Bengio主持的国际AI安全报告，并采纳了纵深防御模型。

**Result:** 形成了一份报告，将AI安全研究领域组织为三类：创建可信AI系统面临的挑战（开发）、评估其风险面临的挑战（评估）以及部署后监控和干预面临的挑战（控制）。

**Conclusion:** 报告通过对AI安全研究领域进行结构化分类（开发、评估、控制），为全球AI安全研究提供了优先事项和框架，旨在促进可信赖AI生态系统的构建。

> **ai_Abstract:** 这篇报告基于“2025新加坡人工智能会议”的成果，旨在应对AI能力快速发展带来的安全挑战。它通过汇集全球AI科学家，识别并综合了AI安全研究的优先事项，并将这些领域划分为开发、评估和控制三大类，以构建一个可信赖、可靠且安全的AI生态系统。

> **摘要翻译:** 快速发展的人工智能能力和自主性预示着巨大的变革前景，但也引发了关于如何确保人工智能安全，即值得信赖、可靠和安全的热烈讨论。因此，建立一个值得信赖的生态系统至关重要——它有助于人们自信地拥抱人工智能，为创新提供最大的空间，同时避免负面影响。“2025新加坡人工智能会议（SCAI）：人工智能安全国际科学交流”旨在通过汇集全球人工智能科学家，识别和综合人工智能安全研究优先事项，从而支持这一领域的研究。这份由此产生的报告以Yoshua Bengio主持并由33个政府支持的《国际人工智能安全报告》为基础。通过采用纵深防御模型，本报告将人工智能安全研究领域分为三类：创建可信赖人工智能系统面临的挑战（开发）、评估其风险面临的挑战（评估）以及部署后监控和干预面临的挑战（控制）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [43] [MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation](https://arxiv.org/abs/2506.20737)
> *MAGPIE：一个用于多智能体上下文隐私评估的数据集*

*Gurusha Juneja, Alon Albalak, Wenyue Hua, William Yang Wang* | **Category: cs.AI, cs.CL**

**Keywords:** 多智能体系统, 上下文隐私, LLM代理, 数据集, 隐私评估

**Comment:** 

> **TL;DR:** 本文提出了一个新数据集MAGPIE，用于评估大型语言模型（LLM）代理在多智能体协作中对上下文隐私的理解和维护能力，并发现当前SOTA模型在此方面表现不佳。

**AI_Comments:** 本文的创新之处在于提出了一个专门针对多智能体上下文隐私评估的高风险、真实场景数据集MAGPIE，填补了现有基准的空白。其重要性在于揭示了当前SOTA LLM在处理复杂隐私情境时的显著不足，对未来多智能体系统的设计和部署具有重要的指导意义。研究结果强调了在开发LLM代理时需要更深入地考虑隐私对齐，而不仅仅是任务完成。

<details>
  <summary>Details</summary>

**Motivation:** 随着基于LLM的智能体在协作任务中的广泛部署，隐私问题变得至关重要，因为这些智能体经常访问专有工具和机密数据库。现有的隐私评估基准不足以评估LLM智能体在复杂多轮对话中对上下文隐私的理解和维护能力。

**Method:** 本文首先提出了一个名为MAGPIE的新基准数据集，包含15个领域内的158个真实高风险场景，这些场景旨在权衡任务完成和隐私保护。然后，使用该数据集评估了包括GPT-4o和Claude-2.7-Sonnet在内的SOTA LLM，测试它们对上下文私有数据的理解以及在不侵犯用户隐私的情况下进行协作的能力。

**Result:** 实验表明，当前模型（包括GPT-4o和Claude-2.7-Sonnet）缺乏对上下文隐私的鲁棒理解，分别有25.2%和43.6%的时间将私有数据错误分类为可共享数据。在多轮对话中，即使有明确的隐私指示，这些模型仍在59.9%和50.5%的案例中泄露了私人信息。此外，多智能体系统在71%的场景中未能完成任务。

**Conclusion:** 当前模型未能同时实现上下文隐私保护和协作任务解决的目标。

> **ai_Abstract:** 本文针对LLM代理在多智能体协作中面临的上下文隐私挑战，提出了一个名为MAGPIE的新型高风险场景数据集，用于评估LLM代理对隐私的理解和保护能力。通过对GPT-4o和Claude-2.7-Sonnet等SOTA模型的评估发现，现有模型在识别和保护上下文隐私方面表现不佳，在多轮对话中频繁泄露信息，并且在需要隐私保护的协作任务中完成率较低，表明当前模型在隐私保护与任务协作之间存在不一致性。

> **摘要翻译:** 大型语言模型（LLM）代理的普及导致了代理间协作的日益增多，用于调度、谈判、资源分配等任务。在此类系统中，隐私至关重要，因为代理通常访问专有工具和需要严格保密的领域特定数据库。本文研究了基于LLM的代理是否表现出对上下文隐私的理解。并且，如果收到指示，这些系统是否在非对抗性多轮对话中保留推理时用户隐私。现有评估LLM代理上下文隐私的基准主要评估单轮、低复杂度的任务，其中私有信息可以很容易地被排除。我们首先提出了一个基准——MAGPIE，包含15个领域内的158个真实高风险场景。这些场景的设计使得完全排除私有数据会阻碍任务完成，但无限制的信息共享可能导致重大损失。然后，我们评估了当前最先进的LLM（a）它们对上下文私有数据的理解和（b）它们在不侵犯用户隐私的情况下进行协作的能力。实证实验表明，当前模型，包括GPT-4o和Claude-2.7-Sonnet，缺乏对上下文隐私的鲁棒理解，分别有25.2%和43.6%的时间将私有数据错误分类为可共享数据。在多轮对话中，即使在明确的隐私指示下，这些模型仍在59.9%和50.5%的案例中泄露了私人信息。此外，多智能体系统在71%的场景中未能完成任务。这些结果强调，当前模型并未同时实现上下文隐私保护和协作任务解决的目标。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [67] [Dynamic Context-Aware Prompt Recommendation for Domain-Specific AI Applications](https://arxiv.org/abs/2506.20815)
> *领域特定AI应用的动态上下文感知提示推荐*

*Xinye Tang, Haijun Zhai, Chaitanya Belwal, Vineeth Thayanithi, Philip Baumann, Yogesh K Roy* | **Category: cs.AI**

**Keywords:** 提示推荐, 动态上下文感知, 领域特定AI, LLM, 提示工程

**Comment:** 

> **TL;DR:** 本文提出一个动态上下文感知提示推荐系统，通过结合查询分析、知识增强、技能组织与排名，为领域特定AI应用生成高质量提示，并在真实世界数据上表现出高实用性和相关性。

**AI_Comments:** 本文提出了一种创新的方法来解决领域特定AI应用中提示工程的挑战。其创新点在于结合了多项技术，包括上下文感知、知识增强、分层技能管理和自适应学习，以实现动态和个性化的提示推荐。这对于提升LLM在垂直领域的应用效率和用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）驱动的应用对用户提示的质量高度敏感，但尤其对于领域特定应用而言，创建高质量提示常常具有挑战性。

**Method:** 本文提出了一个新颖的动态上下文感知提示推荐系统。该解决方案结合了上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排名来生成相关且可操作的提示建议。系统利用行为遥测和两阶段分层推理过程来动态选择和排序相关技能，并使用预定义和自适应模板（通过少样本学习增强）合成提示。

**Result:** 在真实世界数据集上的实验表明，该方法实现了高实用性和相关性，并通过自动化和专家评估得到验证。

**Conclusion:** 该研究成功开发了一个动态上下文感知提示推荐系统，有效解决了领域特定AI应用中高质量提示生成困难的问题，并通过实验证明了其有效性和实用性。

> **ai_Abstract:** 本文介绍了一个针对领域特定AI应用的动态上下文感知提示推荐系统。该系统通过整合上下文查询分析、检索增强知识、分层技能组织和自适应技能排名等技术，旨在解决大型语言模型应用中提示质量对性能影响大且难于创建的问题。它利用行为遥测和两阶段推理过程动态选择和排序技能，并结合少样本学习从预定义和自适应模板生成提示。实验结果表明，该系统在真实世界数据上表现出高实用性和相关性。

> **摘要翻译:** 大型语言模型（LLM）驱动的应用对用户提示的质量高度敏感，但尤其对于领域特定应用而言，创建高质量提示常常具有挑战性。本文提出了一个新颖的动态上下文感知提示推荐系统，用于领域特定AI应用。我们的解决方案结合了上下文查询分析、检索增强知识基础、分层技能组织和自适应技能排名，以生成相关且可操作的提示建议。该系统利用行为遥测和两阶段分层推理过程来动态选择和排序相关技能，并使用预定义和自适应模板（通过少样本学习增强）合成提示。在真实世界数据集上的实验表明，我们的方法实现了高实用性和相关性，并通过自动化和专家评估得到验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [92] [Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation](https://arxiv.org/abs/2506.20949)
> *超越反应式安全：通过长周期模拟实现风险感知型LLM对齐*

*Chenkai Sun, Denghui Zhang, ChengXiang Zhai, Heng Ji* | **Category: cs.AI, cs.CL**

**Keywords:** LLM对齐, 风险感知, 长期模拟, 安全, 间接危害

**Comment:** 

> **TL;DR:** 提出一个框架和数据集，用于通过长周期模拟评估和改进大型语言模型在社会决策中的长期安全对齐。

**AI_Comments:** 这项工作创新性地将LLM安全对齐的关注点从短期反应式安全扩展到长期、宏观层面的风险感知。通过引入长周期模拟框架和间接危害数据集，解决了现有安全评估的局限性，特别是在预见非显而易见的链式反应方面。其在性能上的显著提升表明了该方向的巨大潜力，对于构建更负责任和安全的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于语言模型代理对高风险社会决策日益增长的影响，确保其有益影响需要理解其建议的深远影响。现有安全方法可能仅限于反应式安全，未能预见间接和长期的危害。

**Method:** 提出一个概念验证框架，该框架能预测模型生成的建议如何在宏观层面随时间在社会系统中传播，从而实现更强大的对齐。引入一个包含100个间接危害场景的数据集，用于测试模型预见看似无害的用户提示带来的不利、不明显结果的能力。

**Result:** 在新的数据集上实现了超过20%的改进，并且在现有安全基准（AdvBench, SafeRLHF, WildGuardMix）上，相对于强基线，平均胜率超过70%。

**Conclusion:** 本研究提出的方法为构建更安全的代理提供了一个有前景的方向，通过长期模拟和风险感知对齐来超越反应式安全。

> **ai_Abstract:** 该研究提出了一个名为“超越反应式安全”的风险感知型LLM对齐框架，通过长周期模拟预测模型建议在社会系统中的长期影响。为评估模型长期安全意识，引入了包含100个间接危害场景的新数据集。该方法在新数据集上提升20%，并在现有安全基准上对强基线表现出超过70%的胜率，为开发更安全的AI代理提供了新方向。

> **摘要翻译:** 鉴于基于语言模型的代理对公共政策到医疗保健等高风险社会决策日益增长的影响，确保其有益影响需要理解其建议的深远影响。我们提出了一个概念验证框架，该框架能预测模型生成的建议如何在宏观层面随时间在社会系统中传播，从而实现更强大的对齐。为了评估语言模型的长期安全意识，我们还引入了一个包含100个间接危害场景的数据集，用于测试模型预见看似无害的用户提示带来的不利、不明显结果的能力。我们的方法不仅在新数据集上实现了超过20%的改进，而且在现有安全基准（AdvBench、SafeRLHF、WildGuardMix）上，相对于强基线，平均胜率超过70%，这表明了构建更安全代理的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [115] [Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?](https://arxiv.org/abs/2506.21215)
> *揭示大型语言模型中的因果推理：现实还是幻象？*

*Haoang Chi, He Li, Wenjing Yang, Feng Liu, Long Lan, Xiaoguang Ren, Tongliang Liu, Bo Han* | **Category: cs.AI, cs.CL, cs.LG**

**Keywords:** 因果推理, 大型语言模型, CausalProbe-2024, G^2-Reasoner, 二级因果推理

**Comment:** 24 pages, accepted at NeurIPS 2024

> **TL;DR:** 研究发现大型语言模型（LLMs）仅能进行浅层（一级）因果推理，缺乏真正的人类级（二级）推理能力。通过引入新的基准CausalProbe-2024和提出G^2-Reasoner方法，证明了LLMs的局限性并提供了一种增强其因果推理能力的新途径。

**AI_Comments:** 这项研究深入探讨了LLMs因果推理能力的本质局限性，区分了其现有的浅层（一级）能力与人类深层（二级）推理的差异，具有重要的理论意义。通过提出新的评估基准CausalProbe-2024和创新方法G^2-Reasoner，为量化和提升LLMs的因果推理能力提供了具体工具和方向。G^2-Reasoner的提出，特别是其结合通用知识和目标导向提示的思路，为未来LLMs向更高级智能发展提供了有益的启发。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的因果推理能力对于其迈向强人工智能至关重要。尽管LLMs似乎展示了理解上下文因果关系的能力，但仍不清楚它们是否进行真正类似人类的因果推理。

**Method:** 研究方法上，深入探讨了基于Transformer的LLMs的自回归机制，揭示其并非内在因果。实验上，引入了一个新的因果问答基准CausalProbe-2024，其语料库对于LLMs来说是新鲜且几乎未见的。为弥合与二级因果推理的差距，提出G^2-Reasoner方法，该方法将通用知识和目标导向提示融入LLMs的因果推理过程。

**Result:** LLMs仅能执行浅层（一级）因果推理，这主要归因于其参数中嵌入的因果知识，但缺乏真正类人（二级）因果推理的能力。LLMs在CausalProbe-2024上的表现与早期基准相比显著下降，表明它们主要进行一级因果推理。实验证明G^2-Reasoner显著增强了LLMs的因果推理能力，特别是在新鲜和反事实的上下文中。

**Conclusion:** 这项工作为LLMs超越一级、迈向二级、实现真正因果推理指明了一条新路径。

> **ai_Abstract:** 本研究旨在探究大型语言模型（LLMs）是否具备真正的因果推理能力。研究发现LLMs目前仅能进行浅层（一级）因果推理，这源于其参数中的嵌入知识，而非深层的人类级（二级）推理。通过分析Transformer的自回归机制，并引入新基准CausalProbe-2024，证实了LLMs在处理新颖因果情境时的性能下降。为提升LLMs的因果推理能力，论文提出了G^2-Reasoner方法，该方法通过整合通用知识和目标导向提示来模拟人类推理过程。实验结果表明，G^2-Reasoner显著增强了LLMs在新鲜和反事实语境下的因果推理能力，为LLMs向更高级别因果推理发展开辟了新途径。

> **摘要翻译:** 因果推理能力对于推动大型语言模型（LLMs）迈向强大的人工智能至关重要。尽管多功能LLMs似乎已经展示了理解上下文因果关系并提供符合因果律的响应的能力，但它们是否执行真正类似人类的因果推理仍不清楚。然而，目前的证据表明情况恰恰相反。具体来说，LLMs仅能执行浅层（一级）因果推理，这主要归因于其参数中嵌入的因果知识，但它们缺乏真正类人（二级）因果推理的能力。为了支持这一假设，在方法论上，我们深入探讨了基于Transformer的LLMs的自回归机制，揭示它并非内在因果。在经验上，我们引入了一个新的因果问答基准CausalProbe-2024，其语料库对于所研究的LLMs来说是新鲜且几乎未见的。LLMs在CausalProbe-2024上的表现与早期基准相比显著下降，这表明它们主要进行一级因果推理。为了弥合与二级因果推理的差距，我们从人类推理通常由通用知识和预期目标促进的事实中获得启发。我们提出了G^2-Reasoner，一种将通用知识和目标导向提示融入LLMs因果推理过程的方法。实验表明G^2-Reasoner显著增强了LLMs的因果推理能力，特别是在新鲜和反事实的上下文中。这项工作为LLMs超越一级、迈向二级、实现真正因果推理指明了一条新路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [135] [World-aware Planning Narratives Enhance Large Vision-Language Model Planner](https://arxiv.org/abs/2506.21230)
> *世界感知规划叙事增强大型视觉-语言模型规划器*

*Junhao Shi, Zhaoye Fei, Siyin Wang, Qipeng Guo, Jingjing Gong, Xipeng QIu* | **Category: cs.AI, cs.RO**

**Keywords:** 大型视觉-语言模型, 具身规划, 世界感知, 认知能力, 课程学习

**Comment:** 

> **TL;DR:** 大型视觉-语言模型（LVLMs）在复杂具身规划中表现不佳。本文提出WAP框架，通过注入环境理解能力和课程学习，显著提升LVLMs的任务成功率，并使其超越了GPT-4o等专有模型。

**AI_Comments:** 该研究通过引入“世界感知规划叙事增强”（WAP）框架，解决了LVLMs在具身规划中缺乏环境理解和视觉推理能力的核心问题。其创新点在于将四种认知能力（视觉外观建模、空间推理、功能抽象、句法基础）系统地融入LVLMs，并通过课程学习仅利用原始视觉观测进行训练。这一方法不仅显著提升了模型在复杂场景下的性能，还在开源模型上实现了超越专有SOTA模型的突破，为具身智能领域的发展提供了重要的方向和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在具身规划任务中面临挑战，尤其是在不熟悉的环境和多步骤目标下。现有方法依赖于环境无关的模仿学习，导致指令与环境脱节，模型难以处理上下文敏感指令，并过度依赖补充线索而非视觉推理。

**Method:** 本文提出了世界感知规划叙事增强（WAP）框架，通过四种认知能力（视觉外观建模、空间推理、功能抽象和句法基础）为LVLMs注入全面的环境理解。模型开发和评估仅使用原始视觉观测，并采用课程学习。

**Result:** 在EB-ALFRED基准测试中，Qwen2.5-VL的任务成功率绝对提高了60.7%，其中常识推理提高了60.0%，长距离规划提高了70.0%。增强后的开源模型在很大程度上优于GPT-4o和Claude-3.5-Sonnet等专有系统。

**Conclusion:** WAP框架通过注入全面的环境理解和采用课程学习，显著提升了LVLMs在具身规划任务上的性能，使其在复杂场景下表现更优，并超越了现有SOTA专有模型。

> **ai_Abstract:** 本文提出了世界感知规划叙事增强（WAP）框架，旨在解决大型视觉-语言模型（LVLMs）在复杂具身规划任务中环境理解和视觉推理不足的问题。WAP通过整合视觉外观建模、空间推理、功能抽象和句法基础四种认知能力，并结合课程学习，显著提升了LVLMs在未知环境和多步骤目标下的表现。在EB-ALFRED基准测试中，WAP使Qwen2.5-VL的任务成功率大幅提升，并使得开源模型超越了GPT-4o和Claude-3.5-Sonnet等专有系统。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在具身规划任务中显示出前景，但在涉及不熟悉环境和多步骤目标的复杂场景中表现不佳。当前方法依赖于环境无关的模仿学习，这使得指令与环境上下文脱节，导致模型难以处理上下文敏感指令，并在长时间交互过程中依赖补充线索而非视觉推理。在这项工作中，我们提出了世界感知规划叙事增强（WAP），这是一个通过四种认知能力（视觉外观建模、空间推理、功能抽象和句法基础）为LVLMs注入全面环境理解的框架，同时仅通过课程学习使用原始视觉观测来开发和评估模型。对EB-ALFRED基准的评估表明，任务成功率显著提高，Qwen2.5-VL的绝对成功率提高了60.7%，特别是在常识推理（+60.0）和长距离规划（+70.0）方面。值得注意的是，我们增强的开源模型在很大程度上优于GPT-4o和Claude-3.5-Sonnet等专有系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [152] [IXAII: An Interactive Explainable Artificial Intelligence Interface for Decision Support Systems](https://arxiv.org/abs/2506.21310)
> *IXAII：一个用于决策支持系统的交互式可解释人工智能界面*

*Pauline Speckmann, Mario Nadj, Christian Janiesch* | **Category: cs.AI, cs.SE, K.6.3 Software Management**

**Keywords:** 可解释AI, 交互式界面, 决策支持系统, LIME, SHAP

**Comment:** 9 pages, 2 figures, accepted to DESRIST 2025 Prototype Track

> **TL;DR:** IXAII是一个交互式可解释AI系统，它整合了多种解释方法，提供定制化视图和用户控制，旨在提高透明度并促进人机交互。

**AI_Comments:** 该论文的创新点在于其交互性设计和用户中心视角，这在当前静态可解释AI方法为主流的背景下显得尤为重要。通过整合多种解释方法并提供定制化视图，IXAII显著提升了可解释AI的实用性和用户体验，对于促进AI在决策支持系统中的透明度和信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的事后可解释AI方法大多是静态的，并且忽视了用户视角，这限制了它们对目标受众的有效性。

**Method:** 我们开发了一个名为IXAII的交互式可解释智能系统，它提供了来自LIME、SHAP、Anchors和DiCE四种可解释AI方法的解释。该原型为五种用户组提供了定制化视图，并赋予用户对解释内容和格式的控制权。我们通过专家和普通用户的访谈评估了IXAII。

**Result:** 我们的结果表明，IXAII通过提供具有多种可视化选项的不同解释，被认为有助于提高透明度。

**Conclusion:** 通过弥合可解释AI方法、交互性和实际实现之间的差距，我们为AI解释实践和人机交互提供了一个新颖的视角。

> **ai_Abstract:** 本文介绍了一个名为IXAII的交互式可解释人工智能界面，旨在解决现有可解释AI方法静态且忽视用户视角的问题。IXAII整合了LIME、SHAP、Anchors和DiCE等四种解释方法，为不同用户群体提供定制化的视图，并允许用户控制解释的内容和格式。通过专家和普通用户访谈评估，结果显示IXAII有助于提高AI系统的透明度。该研究为AI解释实践和人机交互提供了新颖的视角，弥合了可解释AI方法、交互性与实际应用之间的鸿沟。

> **摘要翻译:** 尽管已经开发了几种事后可解释AI方法，但大多数都是静态的，并且忽视了用户视角，这限制了它们对目标受众的有效性。为此，我们开发了一个名为IXAII的交互式可解释智能系统，它提供了来自LIME、SHAP、Anchors和DiCE四种可解释AI方法的解释。我们的原型为五种用户组提供了定制化视图，并赋予用户对解释内容和格式的控制权。我们通过专家和普通用户的访谈评估了IXAII。我们的结果表明，IXAII通过提供具有多种可视化选项的不同解释，被认为有助于提高透明度。通过弥合可解释AI方法、交互性和实际实现之间的差距，我们为AI解释实践和人机交互提供了一个新颖的视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [172] [Active Inference AI Systems for Scientific Discovery](https://arxiv.org/abs/2506.21329)
> *用于科学发现的主动推理人工智能系统*

*Karthik Duraisamy* | **Category: cs.AI, physics.soc-ph, 68, I.2**

**Keywords:** 主动推理, 科学发现, 人工智能系统, 因果模型, 知识图谱

**Comment:** 

> **TL;DR:** 本文提出了一种主动推理AI系统架构，旨在通过弥合抽象、推理和现实差距，克服当前AI在科学发现中的局限性，强调内部模型与外部验证的结合以及人类判断的不可或缺性。

**AI_Comments:** 该论文提出了一种创新且全面的AI架构，旨在克服当前AI在科学发现中的核心限制。其亮点在于强调了弥合“抽象、推理和现实”三大差距，并通过整合因果模型、神经符号方法、知识图谱和闭环实验反馈等多种先进AI范式，构建了一个自我完善的系统。特别值得注意的是，论文将人类判断提升为AI系统中的永久架构组件，而非临时辅助，这对于未来人机协作的科学研究具有重要指导意义，体现了对AI局限性的深刻理解和对复杂科学问题的务实态度。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工智能系统在科学发现方面受到其操作架构、脆弱的推理机制以及与实验现实脱节的根本性限制。作者认为，AI驱动的科学进步取决于弥合抽象、推理和现实这三个基本差距。

**Method:** 本文定义了用于科学发现的主动推理AI系统，其特点包括：(i) 维护基于因果自监督基础模型的长期研究记忆；(ii) 配备贝叶斯护栏的符号或神经符号规划器；(iii) 发展持久的知识图谱，通过思考生成新概念节点，推理建立因果边缘，并通过真实世界交互修正和强化连接；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来完善内部表示。核心在于内部模型（实现反事实推理）与外部验证（将假设根植于现实）的相互作用。

**Result:** Not mentioned in abstract

**Conclusion:** 科学发现源于使反事实推理成为可能内部模型与将假设建立在现实中的外部验证之间的相互作用。此外，模拟和实验反馈中固有的模糊性以及潜在的不确定性使得人类判断不可或缺，它不是一个临时支架，而是一个永久的架构组成部分。

> **ai_Abstract:** 本文提出了一种用于科学发现的主动推理AI系统架构，旨在解决当前AI在科学探索中面临的抽象、推理和现实差距。该系统整合了基于因果自监督模型的长期记忆、带贝叶斯约束的规划器、动态增长的知识图谱以及与模拟器和自动化实验室的闭环交互，强调通过内部反事实推理模型与外部真实验证的协同作用来促进发现。论文还特别指出，鉴于反馈的模糊性和不确定性，人类判断应作为AI系统不可或缺的永久组成部分。

> **摘要翻译:** 人工智能的快速发展引发了对变革性科学发现的期望，然而，当前的系统仍然受到其操作架构、脆弱的推理机制以及与实验现实脱节的根本性限制。在前人工作的基础上，我们认为，AI驱动的科学进步现在取决于弥合三个基本差距——抽象差距、推理差距和现实差距——而不是模型规模/数据/测试时间计算。科学推理需要支持行动和响应模拟的内部表示、区分相关性与机制的因果结构以及持续校准。我们将用于科学发现的主动推理人工智能系统定义为：(i) 维护基于因果自监督基础模型的长期研究记忆；(ii) 配备贝叶斯护栏的符号或神经符号规划器；(iii) 发展持久的知识图谱，其中思考生成新概念节点，推理建立因果边缘，真实世界交互修剪错误连接同时强化已验证的路径；(iv) 通过与高保真模拟器和自动化实验室的闭环交互来完善其内部表示——这是一个操作循环，其中心理模拟指导行动，经验惊喜重塑理解。本质上，我们概述了一种架构，其中发现产生于能够进行反事实推理的内部模型与将假设建立在现实中的外部验证之间的相互作用。文章还认为，模拟和实验反馈中固有的模糊性以及潜在的不确定性使得人类判断不可或缺，它不是一个临时支架，而是一个永久的架构组成部分。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [187] [TableMoE: Neuro-Symbolic Routing for Structured Expert Reasoning in Multimodal Table Understanding](https://arxiv.org/abs/2506.21393)
> *TableMoE：多模态表格理解中结构化专家推理的神经符号路由*

*Junwen Zhang, Pu Chen, Yin Zhang* | **Category: cs.AI, 68T07 (Primary), 68T50, 68T30, 68T45 (Secondary), F.2.2; I.2.7; I.2.10**

**Keywords:** 多模态表格理解, 神经符号推理, 专家混合, TableMoE, WildStruct

**Comment:** 43 pages and 11 figures

> **TL;DR:** TableMoE 是一种新型的神经符号 MLLM，用于鲁棒的多模态表格理解，它使用专家路由和大型预训练数据集，在具有挑战性的真实世界基准上超越了最先进的模型。

**AI_Comments:** 本文通过解决“野外”条件下多模态表格理解的实际挑战，做出了重大贡献，这些挑战经常困扰现有的大型多模态语言模型。核心创新在于神经符号路由机制，它巧妙地结合了神经网络能力和符号推理，以实现更鲁棒和可解释的表格处理。大规模 TableMoE-Align 数据集和具有挑战性的 WildStruct 基准的引入对于推动该领域的研究也至关重要，为未来的工作提供了宝贵的资源。对可解释性和鲁棒性的强调是一个强项，超越了单纯的性能指标。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型多模态语言模型（MLLMs）难以处理复杂、视觉退化的真实世界表格（WildStruct 条件），因为其结构复杂性、符号密度和视觉退化，导致性能有限和泛化能力差。

**Method:** 本文提出了 TableMoE，这是一种神经符号的连接专家混合（MoCE）架构，专门用于对多模态表格数据进行鲁棒、结构化推理。TableMoE 的核心是创新的神经符号路由机制，该机制预测潜在的语义标记角色（如标题、数据单元格、轴、公式），并利用由符号推理图指导的置信度感知门控策略，将表格元素动态路由到专门的专家（Table-to-HTML、Table-to-JSON、Table-to-Code）。为了促进有效的对齐驱动预训练，研究人员引入了大规模的 TableMoE-Align 数据集，包含 120 万个表格-HTML-JSON-代码四元组。为了评估模型，他们整理并发布了四个具有挑战性的 WildStruct 基准：WMMFinQA、WMMTatQA、WMMTabDialog 和 WMMFinanceMath。

**Result:** 实验结果表明，TableMoE 显著超越了现有的最先进模型。广泛的消融研究验证了每个核心组件，强调了神经符号路由和结构化专家对齐的关键作用。定性分析进一步展示了 TableMoE 的可解释性和增强的鲁棒性。

**Conclusion:** 将神经符号推理集成到多模态表格理解中是有效且鲁棒的，并且能够提高可解释性。

> **ai_Abstract:** 本文提出了 TableMoE，这是一种神经符号的连接专家混合（MoCE）架构，旨在解决复杂且退化的真实世界条件下（WildStruct）多模态表格理解的挑战。TableMoE 采用新颖的神经符号路由机制，该机制预测语义标记角色，并利用置信度感知门控策略将表格元素动态路由到专业专家。作者还提出了用于预训练的大规模 TableMoE-Align 数据集和四个具有挑战性的 WildStruct 基准用于评估。实验结果表明，TableMoE 显著优于现有最先进的模型，消融研究强调了其神经符号路由和专家对齐组件的重要性，展示了增强的鲁棒性和可解释性。

> **摘要翻译:** 多模态表格理解在现实世界中面临挑战，因为其结构复杂性、符号密度和视觉退化（模糊、倾斜、水印、不完整的结构或字体、多跨度或分层嵌套布局）。现有的多模态大型语言模型（MLLMs）在这些“野外结构”（WildStruct）条件下表现不佳，导致性能有限和泛化能力差。为了解决这些挑战，我们提出了TableMoE，这是一种神经符号的连接专家混合（MoCE）架构，专门用于对多模态表格数据进行鲁棒、结构化推理。TableMoE具有创新的神经符号路由机制，可以预测潜在的语义标记角色（例如，标题、数据单元格、轴、公式），并使用由符号推理图指导的置信度感知门控策略，将表格元素动态路由到专业专家（Table-to-HTML、Table-to-JSON、Table-to-Code）。为了促进有效的对齐驱动预训练，我们引入了大规模的TableMoE-Align数据集，该数据集包含来自金融、科学、生物医学和工业领域的120万个表格-HTML-JSON-代码四元组，专门用于模型预训练。为了进行评估，我们整理并发布了四个具有挑战性的WildStruct基准：WMMFinQA、WMMTatQA、WMMTabDialog和WMMFinanceMath，这些基准专门设计用于在现实世界的多模态退化和结构复杂性下对模型进行压力测试。实验结果表明，TableMoE显著超越了现有的最先进模型。广泛的消融研究验证了每个核心组件，强调了神经符号路由和结构化专家对齐的关键作用。通过定性分析，我们进一步展示了TableMoE的可解释性和增强的鲁棒性，强调了集成神经符号推理在多模态表格理解中的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [201] [Spatial Mental Modeling from Limited Views](https://arxiv.org/abs/2506.21458)
> *从有限视角进行空间心理建模*

*Baiqiao Yin, Qineng Wang, Pingyue Zhang, Jianshu Zhang, Kangrui Wang, Zihan Wang, Jieyu Zhang, Keshigeyan Chandrasegaran, Han Liu, Ranjay Krishna, Saining Xie, Manling Li, Jiajun Wu, Li Fei-Fei* | **Category: cs.AI, cs.CL, cs.CV**

**Keywords:** 视觉语言模型, 空间推理, 心理模型, 认知地图, MindCube

**Comment:** Preprint version

> **TL;DR:** 视觉语言模型（VLMs）在从有限视角进行空间推理方面表现不佳；本研究引入了MindCube基准测试，并提出“先映射后推理”的方法，通过构建内部空间模型显著提高了VLMs的性能。

**AI_Comments:** 本论文通过引入MindCube基准测试，量化了当前视觉语言模型在复杂空间推理方面的关键局限性，具有重要的诊断价值。其提出的“先映射后推理”方法，灵感来源于人类认知过程，通过强制模型构建内部空间表示，为提升AI的空间理解能力提供了一个创新且有效的路径。显著的性能提升证明了这种结合显式空间建模与高级训练技术（如强化学习）的潜力，对于推动视觉语言模型在更复杂、更接近人类的推理任务上的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉语言模型（VLMs）无法像人类一样仅凭少量视图想象完整的场景，在空间推理任务中表现出接近随机的性能。人类会形成空间心理模型来推断布局、透视和运动。本研究旨在揭示并解决VLMs在这方面的关键差距。

**Method:** 本研究引入了MindCube基准测试，包含21,154个问题和3,268张图像，用于系统评估VLMs构建稳健空间心理模型的能力，包括表示位置（认知映射）、方向（视角采纳）和动态（心理模拟“假设”运动）。研究探索了三种方法来帮助VLMs近似空间心理模型：未见的中间视图、自然语言推理链和认知地图。其中，“先映射后推理”的协同方法效果显著，该方法联合训练模型，使其首先生成认知地图，然后在此基础上进行推理。通过添加强化学习，性能得到进一步提升。

**Result:** 现有VLMs在MindCube基准测试中表现出接近随机的性能。通过“先映射后推理”的方法，准确率从37.8%提高到60.8%（+23.0%）。加入强化学习后，性能进一步提升至70.7%（+32.9%）。

**Conclusion:** 本研究的关键见解是，通过主动构建和利用具有灵活推理过程的内部结构化空间表示（即空间心理模型），能够显著提高视觉语言模型对不可观察空间的理解能力。

> **ai_Abstract:** 视觉语言模型（VLMs）在仅凭有限视图进行空间推理方面存在显著不足，无法像人类那样形成完整的空间心理模型。为解决此问题，本研究引入了MindCube，一个包含2万余问题的全新基准测试，揭示了现有VLMs在此任务上的低效表现。研究系统评估了VLMs构建空间心理模型的能力，并探索了多种改进方法。其中，“先映射后推理”的协同策略效果最佳，它通过联合训练模型生成内部认知地图并在此基础上进行推理，将准确率从37.8%提升至60.8%。进一步结合强化学习，性能可达70.7%。这表明，主动构建和利用内部结构化空间表示对于增强VLMs对不可观察空间的理解至关重要。

> **摘要翻译:** 视觉语言模型（VLMs）能否像人类一样，仅凭少量视图就能想象出完整的场景？人类会形成空间心理模型，即未见空间的内部表征，以便对布局、透视和运动进行推理。我们新的MindCube基准测试包含3,268张图像上的21,154个问题，揭示了这一关键差距，现有VLMs在此基准上表现出接近随机的性能。我们使用MindCube系统评估了VLMs通过表示位置（认知映射）、方向（视角采纳）和动态（“假设”运动的心理模拟）来构建稳健空间心理模型的能力。然后，我们探索了三种方法来帮助VLMs近似空间心理模型，包括未见的中间视图、自然语言推理链和认知地图。显著的改进来自于一种协同方法——“先映射后推理”，该方法联合训练模型，使其首先生成认知地图，然后在此基础上进行推理。通过训练模型对这些内部地图进行推理，我们将准确率从37.8%提高到60.8%（+23.0%）。添加强化学习将性能进一步推高到70.7%（+32.9%）。我们的关键见解是，这种空间心理模型的脚手架，即主动构建和利用具有灵活推理过程的内部结构化空间表示，显著提高了对不可观察空间的理解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [227] [Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge](https://arxiv.org/abs/2506.21506)
> *Mind2Web 2：使用代理作为评判者评估代理式搜索*

*Boyu Gou, Zanming Huang, Yuting Ning, Yu Gu, Michael Lin, Weijian Qi, Andrei Kopanev, Botao Yu, Bernal Jiménez Gutiérrez, Yiheng Shu, Chan Hee Song, Jiaman Wu, Shijie Chen, Hanane Nour Moussa, Tianshu Zhang, Jian Xie, Yifei Li, Tianci Xue, Zeyi Liao, Kai Zhang, Boyuan Zheng, Zhaowei Cai, Viktor Rozgic, Morteza Ziyadi, Huan Sun, Yu Su* | **Category: cs.AI, cs.CL**

**Keywords:** 代理式搜索, 评估基准, 代理作为评判者, 大型语言模型, Mind2Web 2

**Comment:** Project Homepage: https://osu-nlp-group.github.io/Mind2Web2/

> **TL;DR:** 本文介绍了Mind2Web 2，一个用于评估代理式搜索系统的新基准，以及一个新颖的“代理作为评判者”框架，以解决现有评估方法的不足。研究发现，最先进的系统已能达到人类性能的50-70%。

**AI_Comments:** Mind2Web 2的创新之处在于其构建了一个大规模、高质量、长周期任务的基准，并提出了“代理作为评判者”这一新颖的评估框架，有效解决了代理式搜索系统评估中答案时变性和复杂性的难题。这项工作对于推动下一代代理式搜索系统的发展和标准化评估具有重要意义，尤其是在强调自动化评估和真实世界任务复杂性方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估基准和方法已无法满足日益复杂的代理式搜索（如深度研究系统）的需求，这些系统涉及自主网络浏览和信息综合，且其答案是时变和开放式的，而当前方法多假设短搜索周期和静态答案。

**Method:** 论文引入了Mind2Web 2，一个包含130个真实、高质量、长周期任务的基准，这些任务需要实时网络浏览和大量信息综合。为评估时变和复杂答案，提出了一种新颖的“代理作为评判者”框架，该框架基于树状结构评分标准构建特定任务的判别代理，以自动评估答案的正确性和来源归属。研究对九个前沿代理式搜索系统和人类表现进行了综合评估，并进行了详细的错误分析。

**Result:** 最佳表现系统OpenAI Deep Research在花费一半时间的情况下，已能达到人类性能的50-70%。

**Conclusion:** Mind2Web 2为开发和评估下一代代理式搜索系统提供了坚实的基础。

> **ai_Abstract:** 本文针对现有评估方法无法适应复杂、开放式代理式搜索的挑战，提出了Mind2Web 2，这是一个包含130个真实、长周期任务的新基准。为有效评估时变和复杂答案，论文引入了“代理作为评判者”框架，利用基于树状评分标准的判别代理自动评估答案正确性和来源归属。通过对九个前沿系统和人类表现的综合评估，研究发现最佳系统OpenAI Deep Research已能以一半时间达到人类性能的50-70%，展示了代理式搜索的巨大潜力。Mind2Web 2旨在为未来代理式搜索系统的开发和评估提供严格的基础。

> **摘要翻译:** 代理式搜索，例如深度研究系统，其中大型语言模型自主浏览网页、综合信息并返回全面且有引文支持的答案，代表了用户与网络规模信息交互方式的重大转变。虽然有望提高效率和减轻认知负担，但代理式搜索日益增长的复杂性和开放性已超越了现有的评估基准和方法，这些方法大多假设短搜索周期和静态答案。在本文中，我们引入了Mind2Web 2，一个包含130个真实、高质量、长周期任务的基准，这些任务需要实时网络浏览和广泛的信息综合，耗费了超过1000小时的人工劳动构建。为了解决评估时变和复杂答案的挑战，我们提出了一种新颖的“代理作为评判者”框架。我们的方法基于树状结构评分标准构建特定任务的判别代理，以自动评估答案的正确性和来源归属。我们对九个前沿代理式搜索系统和人类表现进行了综合评估，并进行了详细的错误分析，以期为未来的发展提供见解。表现最佳的系统OpenAI Deep Research在花费一半时间的情况下，已能达到人类性能的50-70%，显示出巨大的潜力。总而言之，Mind2Web 2为开发和评估下一代代理式搜索系统提供了坚实的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [241] [PsyLite Technical Report](https://arxiv.org/abs/2506.21536)
> *PsyLite 技术报告*

*Fangjun Ding, Renyu Zhang, Xinyu Feng, Chengye Xie, Zheng Zhang, Yanting Zhang* | **Category: cs.AI, cs.HC**

**Keywords:** 心理咨询, 大语言模型, 轻量化部署, 对话安全, 条件RAG

**Comment:** 

> **TL;DR:** PsyLite是一个基于InternLM2.5-7B-chat的轻量级AI心理咨询大语言模型，通过两阶段训练和创新的条件RAG，显著提升了心理咨询能力、对话安全性和部署效率。

**AI_Comments:** PsyLite的创新之处在于其结合了两阶段训练策略和条件RAG，特别是在心理咨询中引入相声幽默元素以提升用户体验，同时兼顾对话安全。其轻量化部署（仅需5GB内存）是其重要优势，使得AI心理咨询能在资源受限环境中广泛应用。这对于推动AI心理健康服务普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI驱动心理咨询模型在对话安全、详细场景处理和轻量化部署方面存在不足。

**Method:** 本研究提出了PsyLite，一个基于InternLM2.5-7B-chat的轻量级心理咨询大语言模型代理。采用两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化）以增强模型深度推理、心理咨询和安全对话能力。部署时使用Ollama和Open WebUI创建自定义工作流，并设计了创新的条件RAG，以在心理咨询中适时引入相声幽默元素并拒绝危险请求。模型还利用量化技术（GGUF q4_k_m）实现低硬件部署。

**Result:** PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中均优于基线模型。尤其在CPsyCounE得分提升47.6%，对话安全（\safe{}得分提升2.4%）。模型仅需5GB内存即可运行。

**Conclusion:** PsyLite为资源受限环境下的心理咨询应用提供了可行的解决方案，并在专业性、安全性和轻量化部署方面表现出色。

> **ai_Abstract:** PsyLite是一个基于InternLM2.5-7B-chat开发的轻量级AI心理咨询大语言模型。它通过两阶段训练（混合蒸馏和ORPO优化）提升了深度推理、心理咨询和安全对话能力。其创新之处在于引入了条件RAG以在咨询中加入幽默元素并增强安全性。评估显示，PsyLite在专业性、安全性和通用评估方面均优于基线模型，且仅需5GB内存即可部署，为资源受限环境下的心理咨询提供了高效可行的方案。

> **摘要翻译:** 随着数字技术的飞速发展，AI驱动的心理咨询逐渐成为心理健康领域的重要研究方向。然而，现有模型在对话安全、详细场景处理和轻量化部署方面仍存在不足。为解决这些问题，本研究提出了PsyLite，一个基于InternLM2.5-7B-chat基础模型开发的轻量级心理咨询大语言模型代理。通过两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），PsyLite增强了模型的深度推理能力、心理咨询能力和安全对话能力。部署使用Ollama和Open WebUI后，通过Pipelines创建了自定义工作流。设计了一种创新的条件RAG，在心理咨询过程中适时引入相声幽默元素以增强用户体验，并拒绝危险请求以加强对话安全。评估结果显示，PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中均优于基线模型，尤其在心理咨询专业性（CPsyCounE得分提升47.6%）和对话安全（\safe{}得分提升2.4%）方面表现突出。此外，该模型利用量化技术（GGUF q4_k_m）实现了低硬件部署（5GB内存即可运行），为资源受限环境下的心理咨询应用提供了可行的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [15] [Progressive Size-Adaptive Federated Learning: A Comprehensive Framework for Heterogeneous Multi-Modal Data Systems](https://arxiv.org/abs/2506.20685)
> *渐进式规模自适应联邦学习：异构多模态数据系统的综合框架*

*Sajid Hussain, Muhammad Sohail, Nauman Ali Khan, Naima Iltaf, Ihtesham ul Islam* | **Category: cs.LG, cs.AI**

**Keywords:** 联邦学习, 数据集大小, 多模态数据, 自适应学习, 通信效率

**Comment:** 

> **TL;DR:** 本文提出了SAFL，一个基于数据集大小对联邦学习进行系统组织的新型渐进式训练框架，解决了现有联邦学习方法忽视数据集大小对训练动态影响的问题，并在多模态数据上取得了优异的性能和通信效率。

**AI_Comments:** 本文的创新点在于首次系统地研究了数据集大小对联邦学习性能和效率的影响，并提出了SAFL框架来解决这一问题。其重要性在于填补了联邦学习领域的一个关键空白，为未来的FL部署提供了基于数据特性的优化策略。特别是对最佳数据集大小范围的发现以及不同模态性能的揭示，具有重要的实践指导意义。该研究不仅提供了理论见解，还通过实时监控框架提供了实际操作层面的支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦学习方法主要关注模型异构性和聚合技术，但很大程度上忽略了数据集大小特性对联邦训练动态的根本性影响。

**Method:** 本文提出了基于大小的自适应联邦学习（SAFL），这是一个新颖的渐进式训练框架，它根据异构多模态数据的数据集大小特性系统地组织联邦学习。

**Result:** 实验结果显示：1) 联邦学习效果的最佳数据集大小范围为1000-1500样本；2) 结构化数据（时间序列、传感器）的性能明显优于非结构化数据（文本、多模态）；3) 超过2000样本的大数据集性能会系统性下降。SAFL在所有数据集上平均准确率达到87.68%，结构化数据模态达到99%+准确率，并将总数据传输量减少到7.38 GB（558次通信）。

**Conclusion:** 这项工作填补了理解数据特性如何驱动联邦学习策略的关键空白，为实际的联邦学习部署提供了理论见解和实践指导。

> **ai_Abstract:** 本文提出了一种名为“基于大小的自适应联邦学习”（SAFL）的新型渐进式训练框架，旨在解决现有联邦学习（FL）方法忽略数据集大小对训练动态影响的问题。SAFL根据数据集大小特性系统地组织联邦学习，并在13个数据集和7种模态上进行了全面评估。实验发现，1000-1500样本是联邦学习的最佳数据集大小范围，结构化数据性能优于非结构化数据，且大数据集性能会下降。SAFL实现了高准确率（平均87.68%），显著提高了通信效率，并提供了系统资源和训练动态的实时洞察，为实际FL部署提供了宝贵的理论和实践指导。

> **摘要翻译:** 联邦学习（FL）已成为一种在保护数据隐私的同时实现分布式机器学习的变革性范式。然而，现有方法主要关注模型异构性和聚合技术，很大程度上忽视了数据集大小特性对联邦训练动态的根本性影响。本文引入了基于大小的自适应联邦学习（SAFL），这是一个新颖的渐进式训练框架，它根据异构多模态数据的数据集大小特性系统地组织联邦学习。我们对跨越7种模态（视觉、文本、时间序列、音频、传感器、医学视觉和多模态）的13个不同数据集进行的综合实验评估揭示了关键见解：1) 联邦学习效果的最佳数据集大小范围为1000-1500样本；2) 存在清晰的模态性能层次结构，其中结构化数据（时间序列、传感器）的性能显著优于非结构化数据（文本、多模态）；3) 超过2000样本的大数据集性能会系统性下降。SAFL在所有数据集上平均准确率达到87.68%，其中结构化数据模态达到99%+的准确率。该框架展示了卓越的通信效率，在558次通信中将总数据传输量减少到7.38 GB，同时保持了高性能。我们的实时监控框架为系统资源利用率、网络效率和训练动态提供了前所未有的洞察。这项工作填补了理解数据特性应如何驱动联邦学习策略的关键空白，为神经网络和学习系统在实际联邦学习部署中提供了理论见解和实践指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [40] [E-ABIN: an Explainable module for Anomaly detection in BIological Networks](https://arxiv.org/abs/2506.20693)
> *E-ABIN：一种用于生物网络异常检测的可解释模块*

*Ugo Lomoio, Tommaso Mazza, Pierangelo Veltri, Pietro Hiram Guzzi* | **Category: cs.LG**

**Keywords:** 异常检测, 生物网络, 可解释AI, 基因表达, 组学数据

**Comment:** 

> **TL;DR:** E-ABIN是一个可解释的框架，结合了经典机器学习和图深度学习，用于在生物网络中检测和解释基因异常，解决了现有方法在多数据集和用户界面上的局限性，并在癌症和乳糜泻案例中展示了其有效性。

**AI_Comments:** E-ABIN的创新之处在于其结合了经典机器学习和图深度学习方法，并特别强调了结果的可解释性，这在生物医学领域至关重要。它还通过提供用户友好的平台解决了现有工具在可用性上的局限。该框架的通用性使其有望应用于更广泛的生物网络异常检测场景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基因异常检测方法通常局限于单一数据集，并且缺乏易于访问的图形界面，无法充分利用日益增长的大规模组学数据并提供可解释的结果。

**Method:** 本文引入了E-ABIN框架，它在一个统一、用户友好的平台中结合了经典机器学习（如支持向量机、随机森林）和基于图的深度学习技术（如图自编码器、图对抗属性网络），用于检测和解释基因表达或甲基化衍生网络中的异常。

**Result:** E-ABIN在膀胱癌和乳糜泻的案例研究中展示了其效用，有效地揭示了生物学相关的异常，并为疾病机制提供了见解，同时保持了高预测准确性和可解释性。

**Conclusion:** E-ABIN提供了一个通用、可解释且用户友好的框架，能够高效准确地在生物网络中进行异常检测和解释，从而为理解疾病机制提供了新的工具。

> **ai_Abstract:** E-ABIN是一个新颖的可解释框架，旨在解决现有基因异常检测方法在处理复杂组学数据时缺乏多数据集支持和用户界面的问题。该框架整合了经典机器学习（如SVM、RF）和图深度学习（如GAEs、GAANs）技术，在一个统一的平台中实现对生物网络中异常的高精度检测和解释。E-ABIN在膀胱癌和乳糜泻的案例研究中被证明能够有效识别生物学相关异常并提供疾病机制洞察。

> **摘要翻译:** 随着大规模组学数据可用性的增加，需要强大的分析框架来处理复杂的基因表达数据集，同时提供可解释的结果。人工智能的最新进展使得能够识别区分疾病状态与健康对照的异常分子模式。结合模型可解释性的改进，这些工具现在支持识别可能驱动疾病表型的基因。然而，当前的基因异常检测方法通常仍局限于单一数据集，并且缺乏易于访问的图形界面。在此，我们引入了E-ABIN，一个用于生物网络异常检测的通用、可解释框架。E-ABIN在一个统一、用户友好的平台中结合了经典机器学习和基于图的深度学习技术，能够检测和解释来自基因表达或甲基化衍生网络中的异常。通过整合支持向量机、随机森林、图自编码器（GAEs）和图对抗属性网络（GAANs）等算法，E-ABIN在保持可解释性的同时确保了高预测准确性。我们通过膀胱癌和乳糜泻的案例研究展示了E-ABIN的实用性，它有效地揭示了生物学相关的异常，并为疾病机制提供了见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [64] [On Context-Content Uncertainty Principle](https://arxiv.org/abs/2506.20699)
> *论语境-内容不确定性原理*

*Xin Li* | **Category: cs.LG**

**Keywords:** 语境-内容不确定性原理, 熵不对称性, 推理, 计算框架, 不确定性最小化

**Comment:** 

> **TL;DR:** 语境-内容不确定性原理（CCUP）提出了一种分层的计算框架，通过上下文和内容之间的熵不对称来解释不确定性下的推理，并展示了其在理解大脑和机器如何最小化不确定性方面的效率提升。

**AI_Comments:** 本文提出了一个新颖的语境-内容不确定性原理，并构建了一个分层的计算框架来解释不确定性下的推理。其创新之处在于将熵不对称性作为核心，并将其应用于大脑和机器的统一理论中，这对于理解智能系统的信息处理机制具有重要意义。提出的四层操作原则为未来的研究提供了详细的指导。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是提供一个统一的理论基础，以理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性。

**Method:** 本文开发了一个分层的计算框架，该框架从语境和内容之间的熵不对称性推导出操作原理。它将推理形式化为定向熵最小化，并识别了四个层次的操作原则：核心推理约束、资源分配原则、时间自举动力学和空间分层组合。研究还提出了形式等价定理、原则间的依赖格和计算模拟。

**Result:** 研究结果表明，通过计算模拟证明了与CCUP对齐的推理可以获得效率提升。

**Conclusion:** CCUP为理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了一个统一的理论基础。大脑不仅仅是一个推理机器，它还是一个循环一致的熵梯度解析器，通过路径依赖、内容播种的模拟来对齐结构和特异性。

> **ai_Abstract:** 本文提出了语境-内容不确定性原理（CCUP），一个基于语境与内容之间熵不对称性的计算框架，用于理解不确定性下的推理。CCUP将推理定义为定向熵最小化，并提出了四个层次的操作原则，涵盖了从核心推理机制到资源分配、时间学习和空间组合的各个方面。通过形式定理和计算模拟，该研究展示了CCUP对齐推理的效率优势，并为大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了一个统一的理论基础。

> **摘要翻译:** 语境-内容不确定性原理（CCUP）提出，不确定性下的推理受语境和内容之间熵不对称性的支配：高熵语境必须通过与低熵、结构化内容的对齐来解释。在本文中，我们开发了一个分层的计算框架，从这种基本不对称性中推导出操作原理。在基础层面，CCUP将推理形式化为定向熵最小化，建立了一个有利于内容优先结构的变分梯度。在此基础上，我们确定了四个层级的操作原则：（L1）核心推理约束，包括结构优先于特异性、不对称推理流、循环一致自举和条件压缩，所有这些都被证明可以相互归约；（L2）资源分配原则，如精度加权注意力、不对称学习率和基于吸引子的记忆编码；（L3）时间自举动力学，通过结构引导的课程随时间组织学习；以及（L4）空间分层组合，将这些机制整合到记忆、推理和规划的自组织循环中。我们提出了形式等价定理、原则间的依赖格以及计算模拟，展示了与CCUP对齐的推理所带来的效率提升。这项工作为理解大脑和机器如何通过递归的结构-特异性对齐来最小化不确定性提供了一个统一的理论基础。大脑不仅仅是一个推理机器。它是一个循环一致的熵梯度解析器，通过路径依赖、内容播种的模拟来对齐结构和特异性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [88] [A Survey of AI for Materials Science: Foundation Models, LLM Agents, Datasets, and Tools](https://arxiv.org/abs/2506.20743)
> *人工智能在材料科学中的应用综述：基础模型、LLM智能体、数据集和工具*

*Minh-Hao Van, Prateek Verma, Chen Zhao, Xintao Wu* | **Category: cs.LG, cs.CE**

**Keywords:** 材料科学, 人工智能, 基础模型, LLM智能体, 综述

**Comment:** 

> **TL;DR:** 本综述全面概述了基础模型、LLM智能体、数据集和工具如何推动材料科学领域的发展，并讨论了其应用、挑战和未来方向。

**AI_Comments:** 这篇综述及时地总结了AI，特别是基础模型和LLM在材料科学中的应用现状，为研究人员提供了全面的视角。其创新之处在于提出了任务驱动的分类法，有助于系统理解该领域的应用范围。重要性体现在它不仅指出了现有技术的潜力，也坦诚地揭示了当前面临的挑战和局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型正在通过实现可扩展、通用和多模态的AI系统，催化材料科学领域的变革。本综述旨在全面概述支持这一新兴领域的基础模型、智能体系统、数据集和计算工具。

**Method:** 本综述提供了一个全面的概述，引入了一个任务驱动的分类法，涵盖了六个广泛的应用领域，并讨论了单模态和多模态基础模型以及新兴的大型语言模型（LLM）智能体的最新进展。此外，还回顾了标准化数据集、开源工具和自主实验平台。

**Result:** 本综述评估了基础模型的早期成功，并指出了持续存在的局限性，包括泛化能力、可解释性、数据不平衡、安全问题和有限的多模态融合方面的挑战。

**Conclusion:** 未来研究方向将集中在可扩展的预训练、持续学习、数据治理和可信度上。

> **ai_Abstract:** 本综述全面探讨了人工智能，特别是基础模型和大型语言模型（LLM）智能体，在材料科学领域的应用与影响。文章首先阐述了基础模型在材料科学中实现可扩展、通用和多模态AI系统的变革潜力。随后，提出了一个任务驱动的分类法，将应用划分为六个核心领域。文中详细讨论了单模态和多模态基础模型以及LLM智能体的最新进展，并回顾了相关数据集、开源工具和自主实验平台。最后，评估了基础模型的初期成功，指出了泛化、可解释性、数据不平衡、安全和多模态融合等方面的局限性，并展望了未来在可扩展预训练、持续学习、数据治理和可信度等方向的研究。

> **摘要翻译:** 基础模型（FMs）正在通过实现可扩展、通用和多模态的AI系统，催化材料科学（MatSci）领域的变革。与传统上范围狭窄且需要针对特定任务进行工程设计的机器学习模型不同，基础模型提供跨领域泛化能力并展现出涌现能力。它们的通用性特别适合材料科学，因为该领域的研究挑战涵盖了多样化的数据类型和规模。本综述全面概述了支持这一新兴领域的基础模型、智能体系统、数据集和计算工具。我们引入了一个任务驱动的分类法，涵盖六个广泛的应用领域：数据提取、解释和问答；原子模拟；属性预测；材料结构、设计和发现；工艺规划、发现和优化；以及多尺度建模。我们讨论了单模态和多模态基础模型以及新兴的大型语言模型（LLM）智能体的最新进展。此外，我们回顾了标准化数据集、开源工具和自主实验平台，它们共同推动了基础模型在研究工作流程中的开发和集成。我们评估了基础模型的早期成功，并指出了持续存在的局限性，包括泛化能力、可解释性、数据不平衡、安全问题和有限的多模态融合方面的挑战。最后，我们阐明了以可扩展预训练、持续学习、数据治理和可信度为中心的未来研究方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [89] [Diffusion Tree Sampling: Scalable inference-time alignment of diffusion models](https://arxiv.org/abs/2506.20701)
> *扩散树采样：扩散模型推理时对齐的可扩展方法*

*Vineet Jain, Kusha Sareen, Mohammad Pedramfar, Siamak Ravanbakhsh* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 扩散模型, 推理时对齐, 蒙特卡罗树搜索, 生成建模, 计算效率

**Comment:** 

> **TL;DR:** 引入了扩散树采样（DTS），一种受蒙特卡罗树搜索启发的、用于扩散模型高效可扩展推理时对齐的方法，显著降低了计算成本，同时保持或提高了样本质量。

**AI_Comments:** 这篇论文通过借鉴蒙特卡罗树搜索（一种在强化学习和游戏AI中成熟的技术），为扩散模型引导提出了一种创新方法。其主要创新在于将推理时对齐构建为一个搜索问题，并利用树结构重用计算，这解决了现有方法中价值估计不准确和计算效率低下的常见问题。该方法“随时可用”的特性（即更多计算带来更好样本）是实现可扩展部署的一个重要实际优势。这项工作可能为更高效、更鲁棒地控制扩散模型输出铺平道路。

<details>
  <summary>Details</summary>

**Motivation:** 预训练扩散模型在推理时适应新目标时，现有引导方法存在价值估计不准确的问题，尤其是在高噪声水平下，这会使引导产生偏差。此外，过去运行的信息没有被重新利用来提高样本质量，导致计算资源使用效率低下。

**Method:** 受蒙特卡罗树搜索的启发，将推理时对齐视为一个重用过去计算的搜索问题。提出了扩散树采样（DTS），这是一种基于树的方法，通过将终端奖励通过扩散链传播回来，并随着每次额外的生成迭代地细化价值估计，从而从奖励对齐的目标密度中采样。其贪婪变体，扩散树搜索（DTS$^\star$），对高奖励样本进行全局搜索。

**Result:** 在MNIST和CIFAR-10的类条件生成任务中，DTS以高达10倍的更少计算量匹配了最佳基线的FID。在文本到图像生成和语言补全任务中，DTS$^\star$有效地搜索了高奖励样本，以高达5倍的更少计算量匹配了最佳N中选择的效果。通过重用信息，该算法可以随着额外计算的增加持续改进样本质量。

**Conclusion:** DTS通过重用前几代的信息，为扩散模型的推理时对齐提供了一种可扩展且高效的方法，使得额外的计算能够转化为持续更好的样本。

> **ai_Abstract:** 本文介绍了扩散树采样（DTS）及其贪婪变体DTS$^
star$，这是一种受蒙特卡罗树搜索启发的新方法，旨在解决预训练扩散模型在推理时高效对齐新目标的挑战。通过将对齐视为一个搜索问题并在树结构中重用过去的计算，DTS提供了渐近精确的样本，而DTS$^
star$则寻找高奖励样本。这些方法在各种生成任务中展示了显著的计算节省（DTS高达10倍，DTS$^
star$高达5倍），同时保持或提高了性能，为扩散模型引导提供了一种可扩展且随时可用的解决方案。

> **摘要翻译:** 预训练扩散模型在推理时适应新目标仍然是生成建模中的一个开放问题。现有的引导方法存在价值估计不准确的问题，尤其是在高噪声水平下，这会使引导产生偏差。此外，过去运行的信息没有被重新利用来提高样本质量，导致计算资源使用效率低下。受蒙特卡罗树搜索成功的启发，我们通过将推理时对齐视为一个重用过去计算的搜索问题来解决这些限制。我们引入了一种基于树的方法，通过将终端奖励通过扩散链传播回来，并随着每次额外的生成迭代地细化价值估计，从而从奖励对齐的目标密度中采样。我们提出的方法，扩散树采样（DTS），在无限次展开的极限下，从目标分布中产生渐近精确的样本；其贪婪变体，扩散树搜索（DTS$^
star$），对高奖励样本进行全局搜索。在MNIST和CIFAR-10的类条件生成任务中，DTS以高达10倍的更少计算量匹配了最佳基线的FID。在文本到图像生成和语言补全任务中，DTS$^
star$有效地搜索了高奖励样本，以高达5倍的更少计算量匹配了最佳N中选择的效果。通过重用前几代的信息，我们得到了一个随时可用的算法，它将额外的计算转化为持续更好的样本，为扩散模型的推理时对齐提供了一种可扩展的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [109] [Optimal Single-Policy Sample Complexity and Transient Coverage for Average-Reward Offline RL](https://arxiv.org/abs/2506.20904)
> *平均奖励离线强化学习中的最优单策略样本复杂度和瞬态覆盖*

*Matthew Zurek, Guy Zamir, Yudong Chen* | **Category: cs.LG, cs.IT, math.IT, math.OC, stat.ML**

**Keywords:** 离线强化学习, 平均奖励MDPs, 样本复杂性, 单策略, 偏差跨度

**Comment:** 

> **TL;DR:** 本文首次为平均奖励离线RL提供了单策略样本复杂性界限，解决了分布偏移和非均匀覆盖的挑战，并引入了一种新算法，无需先验参数知识。

**AI_Comments:** 本文在平均奖励离线强化学习领域取得了显著进展，首次提出了完全单策略样本复杂性界限，避免了以往工作中对所有策略统一的复杂性度量，更具实际意义。其引入的新颖理论工具（如策略命中半径）和算法（悲观折扣值迭代与分位数剪裁）具有创新性，且无需先验参数知识，提升了实用性。此外，对弱通信MDPs的处理也扩展了适用范围。

<details>
  <summary>Details</summary>

**Motivation:** 平均奖励MDPs中的离线强化学习在分布偏移和非均匀覆盖方面存在挑战，且从理论角度来看相对未被充分检验。现有工作在单策略数据覆盖下提供性能保证时，依赖于对所有策略统一的复杂性度量，而非仅针对目标策略。

**Method:** 本文提出了基于悲观折扣值迭代并辅以新颖分位数剪裁技术的算法，该技术实现了更尖锐的基于经验跨度的惩罚函数。该算法无需任何先验参数知识。研究通过目标策略的偏差跨度（bias span）和新颖的策略命中半径（policy hitting radius）来开发尖锐的保证。

**Result:** 本文首次获得了平均奖励离线RL的完全单策略样本复杂性界限。首次处理了通用的弱通信MDPs。通过困难示例证明在本文条件下学习需要超越目标策略平稳分布的覆盖假设。开发了几乎匹配主要结果的下界。

**Conclusion:** 本文为平均奖励离线RL提供了首个完全单策略样本复杂性界限，通过引入新颖的理论工具和算法，成功解决了分布偏移和非均匀覆盖的挑战，并证明了单策略复杂性度量与以往情况的区别，揭示了学习所需的更深层次覆盖假设。

> **ai_Abstract:** 本文针对平均奖励MDPs中的离线强化学习，解决了分布偏移和非均匀覆盖的理论挑战。通过引入基于目标策略的偏差跨度和新颖策略命中半径的尖锐保证，并提出一种结合悲观折扣值迭代与分位数剪裁的算法，首次实现了完全单策略样本复杂性界限，并能处理通用弱通信MDPs，且无需先验参数知识。研究还揭示了单策略复杂性需要超越目标策略平稳分布的覆盖假设，并提供了匹配的下界。

> **摘要翻译:** 我们研究平均奖励MDPs中的离线强化学习，这在分布偏移和非均匀覆盖方面提出了更大的挑战，并且从理论角度来看相对未被充分检验。虽然之前的工作在单策略数据覆盖假设下获得了性能保证，但这些保证利用了对所有策略统一的额外复杂性度量，例如统一混合时间。我们开发了仅取决于目标策略的尖锐保证，特别是偏差跨度（bias span）和新颖的策略命中半径（policy hitting radius），从而产生了平均奖励离线RL的第一个完全单策略样本复杂性界限。我们也是第一个处理通用弱通信MDPs的研究，这与先前工作中做出的限制性结构假设形成对比。为了实现这一点，我们引入了一种基于悲观折扣值迭代并辅以新颖分位数剪裁技术的算法，这使得能够使用更尖锐的基于经验跨度的惩罚函数。我们的算法在实施时也不需要任何先验参数知识。值得注意的是，我们通过困难示例表明，在我们条件下学习需要超越目标策略平稳分布的覆盖假设，从而将单策略复杂性度量与先前研究的情况区分开来。我们还开发了几乎匹配我们主要结果的下界。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [112] [On Convolutions, Intrinsic Dimension, and Diffusion Models](https://arxiv.org/abs/2506.20705)
> *关于卷积、内在维度和扩散模型*

*Kin Kwan Leung, Rasa Hosseinzadeh, Gabriel Loaiza-Ganem* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 卷积, 内在维度, 扩散模型, FLIPD, 流形假设

**Comment:** 

> **TL;DR:** 本文通过在更真实的假设下证明FLIPD估计器的正确性，弥补了扩散模型中局部内在维度（LID）估计的理论空白，并展示了均匀卷积的类似结果。

**AI_Comments:** 本文的创新之处在于它弥补了FLIPD这一先进LID估计器在理论基础上的重要空白，使其在更广泛、更真实的场景下具备了形式化的正确性证明。这对于依赖LID进行数据复杂性量化、异常检测和AI内容识别的应用具有重要意义，增强了FLIPD的可靠性和实用性。同时，对均匀卷积的扩展也展现了其理论的普适性。

<details>
  <summary>Details</summary>

**Motivation:** FLIPD在局部内在维度（LID）估计方面达到了最先进的性能，但其理论基础不完整，因为之前的研究仅在高度不现实的仿射子流形假设下证明了其正确性。本文旨在弥补这一理论空白，并在更现实的假设下形式化证明FLIPD的正确性。

**Method:** 本文通过形式化证明了FLIPD在现实假设下的正确性。此外，研究还展示了当高斯卷积被均匀卷积取代时，一个类似的结果仍然成立。

**Result:** 成功在现实假设下形式化证明了FLIPD（一种局部内在维度估计器）的正确性。同时，研究还发现当高斯卷积被均匀卷积替换时，一个类似的结果也成立。

**Conclusion:** 本文弥补了FLIPD局部内在维度估计器理论基础的空白，通过在现实假设下证明其正确性，并将其适用性扩展到均匀卷积，从而增强了其在量化数据复杂性、检测异常值和AI生成内容等应用中的可靠性。

> **ai_Abstract:** 本文解决了扩散模型中局部内在维度（LID）估计器FLIPD的理论基础不完整的问题。之前的研究仅在不现实的仿射子流形假设下证明了FLIPD的正确性。本工作通过在更现实的假设下形式化证明FLIPD的正确性来弥补这一理论空白。此外，研究还证明了当高斯卷积被均匀卷积取代时，一个类似的LID估计结果也成立，扩展了FLIPD的理论适用性。

> **摘要翻译:** 流形假设断言，高维环境空间中感兴趣的数据（例如图像数据）位于未知的低维子流形上。扩散模型（DMs）通过将数据与逐渐增大的高斯噪声进行卷积，然后学习逆转这一过程，已成为性能最佳的生成模型，并已知能够学习具有低维支持的分布。对于这些子流形中的给定数据，我们直观地期望DMs能够隐式学习其对应的局部内在维度（LID），即其所属子流形的维度。Kamkari 等人（2024b）最近通过将LID与DM的对数边际密度相对于添加噪声量的变化率联系起来，证明了确实如此，从而产生了名为FLIPD的LID估计器。FLIPD等LID估计器用途广泛，它们可以量化给定数据的复杂性，并可用于检测异常值、对抗性样本和AI生成文本。FLIPD在LID估计方面取得了最先进的性能，但其理论基础不完整，因为Kamkari 等人（2024b）仅在高度不现实的仿射子流形假设下证明了其正确性。在这项工作中，我们通过在现实假设下形式化证明FLIPD的正确性来弥补这一空白。此外，我们还表明，当高斯卷积被均匀卷积取代时，一个类似的结果仍然成立，并讨论了这一结果的相关性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [130] [Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection](https://arxiv.org/abs/2506.21093)
> *思维链增强的浅层Transformer用于无线符号检测*

*Li Fan, Peng Wang, Jing Yang, Cong Shen* | **Category: cs.LG, cs.IT, eess.SP, math.IT, stat.ML**

**Keywords:** 思维链, 浅层Transformer, 无线符号检测, 上下文学习, 资源受限设备

**Comment:** 

> **TL;DR:** 提出了一种名为CHOOSE的思维链增强浅层Transformer框架，用于无线符号检测，它在不增加模型深度的情况下显著提升了浅层模型的推理能力，使其在资源受限设备上也能实现与深层模型相当的性能。

**AI_Comments:** 这项工作的创新点在于将思维链（CoT）思想引入到浅层Transformer中，以增强其推理能力，从而在保持模型轻量化的同时，达到与深层模型相当的性能。这对于资源受限的移动设备部署Transformer模型具有重要意义，解决了传统深度Transformer计算成本高昂的问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于上下文学习（ICL）的Transformer模型需要深层架构才能达到满意性能，导致巨大的存储和计算成本，这限制了它们在资源受限设备上的部署。

**Method:** 本文提出CHOOSE（CHain Of thOught Symbol dEtection），一个思维链增强的浅层Transformer框架。通过在隐藏空间中引入自回归潜在推理步骤，CHOOSE显著提升了浅层模型（1-2层）的推理能力，而无需增加模型深度。

**Result:** 实验结果表明，CHOOSE优于传统的浅层Transformer，并且在保持存储和计算效率的同时，实现了与深层Transformer相当的检测性能。

**Conclusion:** 该方法为在计算资源有限的无线接收器中部署基于Transformer的算法提供了一个有前景的方向。

> **ai_Abstract:** 本文提出了一种名为CHOOSE的思维链增强浅层Transformer框架，用于无线符号检测。针对现有基于ICL的Transformer模型深度大、成本高的问题，CHOOSE通过在隐藏空间引入自回归潜在推理步骤，显著提升了浅层模型（1-2层）的推理能力，使其在不增加模型深度的情况下，能达到与深层模型相当的性能。实验证明，CHOOSE在保持高效的同时，性能优于传统浅层模型并媲美深层模型，为资源受限的无线设备部署Transformer算法提供了可行方案。

> **摘要翻译:** Transformer在解决无线通信问题，特别是在上下文学习（ICL）方面展现出潜力，其中模型通过提示适应新任务而无需更新模型。然而，先前的基于ICL的Transformer模型依赖于具有多层的深层架构才能实现令人满意的性能，导致巨大的存储和计算成本。在这项工作中，我们提出了CHain Of thOught Symbol dEtection（CHOOSE），一个思维链增强的浅层Transformer框架，用于无线符号检测。通过在隐藏空间中引入自回归潜在推理步骤，CHOOSE在不增加模型深度的情况下显著提升了浅层模型（1-2层）的推理能力。这种设计使得轻量级Transformer能够实现与更深层模型相当的检测性能，使其非常适合部署在资源受限的移动设备上。实验结果表明，我们的方法优于传统的浅层Transformer，并在保持存储和计算效率的同时，实现了与深层Transformer相当的性能。这代表了在计算资源有限的无线接收器中实现基于Transformer算法的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [132] [Test-time Scaling Techniques in Theoretical Physics -- A Comparison of Methods on the TPBench Dataset](https://arxiv.org/abs/2506.20729)
> *理论物理中的测试时缩放技术——TPBench数据集上的方法比较*

*Zhiqi Gao, Tianyi Li, Yurii Kvasiuk, Sai Chaitanya Tadepalli, Maja Rudolph, Daniel J. H. Chung, Frederic Sala, Moritz Münchmeyer* | **Category: cs.LG, astro-ph.CO, cs.AI, hep-ph, hep-th**

**Keywords:** 大型语言模型, 测试时缩放, 理论物理, TPBench, 符号验证

**Comment:** 23 pages, 6 figures

> **TL;DR:** 本文研究了大型语言模型（LLMs）在理论物理领域中的测试时缩放技术，并在TPBench数据集上比较了各种方法。作者提出了一种新颖的符号化弱验证器框架，该框架在TPBench上显著优于现有方法，并对AIME数据集也有效，强调了分步符号验证在解决复杂科学问题中的强大作用。

**AI_Comments:** 该论文的创新之处在于将通常用于数学问题的测试时缩放技术应用于理论物理领域。其开发了一种专门针对物理问题结构的新颖符号化弱验证器框架，并通过在TPBench新数据集上的实证验证，证明了其优于现有方法的性能，这是重要的贡献。它解决了LLM推理能力在不同领域泛化性的关键问题。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在复杂推理方面表现出色，测试时缩放技术能以低成本提升其性能。然而，许多此类方法主要在数学推理基准（如AIME）上开发和评估。本文旨在探究这些经验是否能推广到高级理论物理领域，并寻找在该领域有效的测试时缩放方法。

**Method:** 本文在TPBench物理数据集上评估了一系列常见的测试时缩放方法，并将其有效性与AIME上的结果进行比较。为了更好地利用物理问题的结构，研究开发了一种新颖的、符号化的弱验证器框架，以改进并行缩放结果。该新方法也R在AIME数据集上进行了评估。

**Result:** 所提出的新颖符号化弱验证器框架在TPBench数据集上显著优于现有的测试时缩放方法。该方法在AIME数据集上也证实了其在解决高级数学问题方面的有效性。

**Conclusion:** 分步符号验证对于解决复杂的科学问题具有强大的能力。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）的测试时缩放技术在理论物理领域的适用性，旨在将数学推理基准（如AIME）的经验推广到TPBench物理数据集。研究评估了现有方法，并引入了一种新颖的、利用物理问题结构的符号化弱验证器框架。实证结果表明，该新方法在TPBench上显著优于现有方法，并在AIME上同样有效，突出了分步符号验证在解决复杂科学问题中的强大作用。

> **摘要翻译:** 大型语言模型（LLMs）在复杂推理方面展现出强大的能力，而测试时缩放技术能以相对较低的成本提升其性能。许多此类方法已在AIME等数学推理基准上开发和评估。本文研究从这些基准中学到的经验是否能推广到高级理论物理领域。我们在TPBench物理数据集上评估了一系列常见的测试时缩放方法，并将其有效性与AIME上的结果进行比较。为了更好地利用物理问题的结构，我们开发了一种新颖的、符号化的弱验证器框架，以改进并行缩放结果。我们的实证结果表明，该方法在TPBench上显著优于现有的测试时缩放方法。我们还在AIME上评估了我们的方法，证实了其在解决高级数学问题方面的有效性。我们的发现强调了分步符号验证在解决复杂科学问题方面的强大能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [167] [LLM-guided Chemical Process Optimization with a Multi-Agent Approach](https://arxiv.org/abs/2506.20921)
> *LLM引导的多智能体化学过程优化*

*Tong Zeng, Srivathsan Badrinarayanan, Janghoon Ock, Cheng-Kai Lai, Amir Barati Farimani* | **Category: cs.LG, cs.AI, cs.CE**

**Keywords:** LLM, 多智能体, 化学过程优化, 约束推断, AutoGen

**Comment:** 16 pages (main manuscript without references), 2 figures

> **TL;DR:** 本文提出一个基于大型语言模型（LLM）的多智能体框架，用于在操作约束不明确或缺失的情况下自动推断约束并引导化学过程优化，该方法在计算效率和理解复杂过程方面表现出色。

**AI_Comments:** 这项研究通过引入LLM引导的多智能体方法来解决化学过程优化中长期存在的约束定义挑战，具有显著的创新性。其能够从少量信息中自主推断操作约束，并结合领域知识进行优化，这对于新兴和改造过程尤其重要。该方法在计算效率上的显著提升，以及对复杂过程的理解能力，预示着其在工业应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的化学过程优化方法（如梯度求解器、进化算法和参数网格搜索）在操作约束定义不清或缺失时变得不切实际，导致工程师需要依赖主观启发式方法来估计可行参数范围。本文旨在解决这一约束定义瓶颈。

**Method:** 本文提出了一个基于大型语言模型（LLM）的多智能体框架。该框架基于AutoGen，并使用OpenAI的o3模型，包含专门用于约束生成、参数验证、模拟执行和优化引导的智能体。该方法分两个阶段：首先是利用嵌入式领域知识自主生成约束，然后是迭代的多智能体优化。此框架无需预定义的操作界限。

**Result:** 该框架在加氢脱烷基过程的成本、产率和产率成本比指标上进行了验证，结果表明其性能与传统优化方法相当，同时计算效率更高，收敛所需的迭代次数更少。该方法在20分钟内收敛，比网格搜索快31倍。此外，该框架的推理引导搜索展现了复杂的流程理解能力，能够正确识别效用权衡并应用领域启发式方法。

**Conclusion:** 该方法在操作约束特征不明确或不可用的优化场景中，特别是对于新兴流程和改造应用，显示出巨大的潜力。

> **ai_Abstract:** 本文提出了一种LLM引导的多智能体框架，旨在解决化学过程优化中操作约束定义不清的问题。该框架利用LLM智能体自主推断约束，并通过多智能体协作引导优化。该方法在加氢脱烷基过程上进行了验证，结果显示其在计算效率和对复杂过程的理解方面均优于传统方法，尤其适用于约束条件缺失或不明确的场景。

> **摘要翻译:** 化学过程优化对于最大限度地提高生产效率和经济效益至关重要。传统的优化方法，包括基于梯度的求解器、进化算法和参数网格搜索，在操作约束定义不清或不可用时变得不切实际，需要工程师依赖主观启发式方法来估计可行的参数范围。为了解决这个约束定义瓶颈，我们提出了一个由大型语言模型（LLM）智能体组成的多智能体框架，该框架能够从最少的流程描述中自主推断操作约束，然后协同引导优化。我们基于AutoGen的智能体框架采用了OpenAI的o3模型，并设有专门用于约束生成、参数验证、模拟执行和优化引导的智能体。通过两个阶段——利用嵌入式领域知识自主生成约束，随后进行迭代的多智能体优化——该框架消除了对预定义操作边界的需求。在加氢脱烷基过程的成本、产率和产率成本比指标上进行验证后，该框架展示了与传统优化方法相当的性能，同时实现了更好的计算效率，所需的迭代次数更少。我们的方法在20分钟内收敛，比网格搜索快31倍。除了计算效率，该框架的推理引导搜索还展示了复杂的流程理解能力，能够正确识别效用权衡并应用领域启发式方法。这种方法在操作约束特征不明确或不可用的优化场景中，特别是对于新兴流程和改造应用，显示出巨大的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [168] [Multiple Streams of Relation Extraction: Enriching and Recalling in Transformers](https://arxiv.org/abs/2506.20746)
> *多重关系抽取流：Transformer中的丰富与回忆*

*Todd Nief, David Reber, Sean Richardson, Ari Holtzman* | **Category: cs.LG**

**Keywords:** 关系抽取, Transformer, 大型语言模型, 微调, 信息路径

**Comment:** 

> **TL;DR:** 本文通过动态权重嫁接方法研究了大型语言模型（LLM）在微调过程中学习到的关系信息如何在模型内部被提取和回忆，发现信息通过“丰富”和“回忆”两种路径传递。

**AI_Comments:** 本文通过提出创新的“动态权重嫁接”方法，弥补了现有信息定位方法在分析LLM内部信息流向方面的不足。这一方法不仅揭示了LLM在处理关系信息时存在“提取”和“回忆”两种路径，还详细分析了这些路径在模型中的具体作用机制和位置，对于理解Transformer模型如何存储和利用知识具有重要意义。其发现对于改进模型微调策略和提高模型可解释性具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有定位方法（如激活修补）不适用于分析大型语言模型（LLM）在微调过程中学习到的关系信息在模型内部的去向，因为它们可能会删除信息。为了填补这一空白，本文旨在探究关系信息在LLM中是如何被提取和回忆的。

**Method:** 本文提出了一种在微调模型和预训练模型之间进行动态权重嫁接的方法。通过这种方法，研究者分析了信息流的必要性和充分性，以及它们发生的层级、冗余程度和涉及的模型组件。

**Result:** 研究发现，微调后的语言模型在处理实体时会提取在微调过程中学到的关系信息，并在稍后的层中在生成预测时“回忆”这些信息。在某些情况下，模型需要这两种路径才能正确生成微调信息，而在其他情况下，单个“丰富”或“回忆”路径就足够了。“回忆”路径通过任务特定的注意力机制以及在预测前最终层中注意力输出和前馈网络的中的关系抽取步骤发生。

**Conclusion:** LLM在微调过程中学习到的关系信息通过“丰富”（提取）和“回忆”两种途径在模型内部传递，并且这两种路径在不同情况下可能单独或协同作用，以确保信息的正确生成。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）在微调期间学习到的关系信息如何在模型内部被处理。通过引入一种动态权重嫁接方法，作者发现LLM在处理实体时会“提取”关系信息，并在生成预测时“回忆”这些信息。研究表明，“丰富”（提取）和“回忆”这两种信息路径都对正确生成微调信息至关重要，并且在不同情境下可能单独或协同作用。论文进一步探讨了这些路径在模型层级中的发生位置、冗余性以及涉及的模型组件，揭示了“回忆”路径通过注意力机制和前馈网络在最终层发挥作用。

> **摘要翻译:** 当大型语言模型（LLM）在微调过程中学习到一种关系（例如，新电影上映、公司合并等）时，这些信息去向何处？是在模型处理实体时被提取，还是在预测前及时被回忆，或者存在多个独立的启发式方法？现有的定位方法（例如激活修补）不适合这种分析，因为它们倾向于替换残差流的一部分，可能会删除信息。为了填补这一空白，我们提出了微调和预训练语言模型之间的动态权重嫁接方法，以表明微调后的语言模型（1）在处理实体时提取在微调过程中学到的关系信息，并且（2）在生成预测时在后续层中“回忆”这些信息。在某些情况下，模型需要这两种途径才能正确生成微调信息，而在其他情况下，单个“丰富”或“回忆”途径就足够了。我们检查了这些信息途径的必要性和充分性，检查了它们发生的层级，它们表现出的冗余程度，以及涉及的模型组件——发现“回忆”途径通过任务特定的注意力机制以及在下一个词元预测前的最终层中注意力输出和前馈网络中的关系抽取步骤发生。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [169] [Artificial Delegates Resolve Fairness Issues in Perpetual Voting with Partial Turnout](https://arxiv.org/abs/2506.21186)
> *人工代理解决部分投票率下永久投票中的公平性问题*

*Apurva Shah, Axel Abels, Ann Nowé, Tom Lenaerts* | **Category: cs.LG, cs.CY**

**Keywords:** 永久投票, 公平性, 部分投票率, 人工代理, 偏好学习

**Comment:** The paper has been accepted at the ACM Collective Intelligence
  Conference (CI 2025), August 4 to 6, 2025, San Diego, CA, USA

> **TL;DR:** 本文研究了将人工代理（代表缺席选民的偏好学习智能体）整合到永久投票系统中，以解决部分投票率导致的公平性问题，结果表明人工代理能有效缓解缺席对公平性的影响并增强鲁棒性。

**AI_Comments:** 这项工作通过引入“人工代理”来解决现实世界中集体决策系统面临的实际问题，即部分投票率。其创新点在于利用机器学习代理来模拟缺席选民的偏好，从而提高投票系统的公平性和鲁棒性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的永久投票规则依赖于完全参与和完整的批准信息，这在实际中很少发生，因为部分投票率是常态，导致公平性问题。

**Method:** 作者研究了将人工代理（经过训练以代表缺席选民的偏好学习智能体）整合到永久投票系统中。他们检查了缺席对各种投票方法下的公平性和代表性的影响，并评估了人工代理在多大程度上可以弥补缺失的参与。

**Result:** 研究结果表明，虽然缺席显著影响公平性，但人工代理能可靠地缓解这些影响，并在不同场景下增强系统的鲁棒性。

**Conclusion:** 人工代理能够有效解决永久投票中因部分投票率引起的公平性问题，提高系统的鲁棒性。

> **ai_Abstract:** 本文研究了在永久投票系统中整合人工代理（代表缺席选民的偏好学习智能体），以解决实际中普遍存在的部分投票率导致的公平性问题。研究发现，缺席会对公平性产生显著影响，而人工代理能够有效地缓解这些负面影响，并在各种场景下增强系统的稳健性。

> **摘要翻译:** 永久投票通过评估随时间变化的代表性公平性来解决顺序集体决策中的公平性问题。然而，现有的永久投票规则依赖于完全参与和完整的批准信息，这些假设在实践中很少成立，因为部分投票率是常态。在这项工作中，我们研究了将人工代理（经过训练以代表缺席选民的偏好学习智能体）整合到永久投票系统中。我们检查了缺席对各种投票方法下的公平性和代表性的影响，并评估了人工代理在多大程度上可以弥补缺失的参与。我们的研究结果表明，虽然缺席显著影响公平性，但人工代理能可靠地缓解这些影响，并在不同场景下增强鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [182] [Lipschitz Bounds for Persistent Laplacian Eigenvalues under One-Simplex Insertions](https://arxiv.org/abs/2506.21352)
> *持久拉普拉斯特征值在单单纯形插入下的利普希茨界*

*Le Vu Anh, Mehmet Dik, Nguyen Viet Anh* | **Category: cs.LG, cs.IT, math.IT, math.MG**

**Keywords:** 持久拉普拉斯, 特征值, 利普希茨界, 单纯形插入, 拓扑数据分析

**Comment:** 16 pages, 4 figures

> **TL;DR:** 本文证明了在插入一个单纯形后，持久拉普拉斯特征值的变化有一个统一的利普希茨界，为谱拓扑数据分析提供了首次特征值层面的鲁棒性保证。

**AI_Comments:** 这项工作填补了持久拉普拉斯特征值在局部扰动下精确变化认知的空白，首次提供了特征值层面的鲁棒性保证。这对于依赖这些特征值的下游工具（如热核签名和谱神经网络）的可靠性至关重要，特别是在动态数据分析中具有重要的实际应用价值。其创新点在于建立了明确的利普希茨界，量化了特征值的稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管先前的研究已经确立了持久拉普拉斯算子的全局代数稳定性，但当插入一个顶点、边或三角形等单一单纯形时，单个特征值的精确变化仍是未知的。这很重要，因为热核签名和谱神经网络等下游工具直接依赖于这些特征值。

**Method:** 通过证明一个统一的利普希茨界来解决这个问题。

**Result:** 在插入一个单纯形后，每个向上持久拉普拉斯特征值的变化最大为其边界欧几里得范数的两倍，且与过滤尺度和复形大小无关。

**Conclusion:** 该结果为谱拓扑数据分析提供了首次特征值层面的鲁棒性保证。它确保了在局部更新下谱特征保持稳定，并能在动态数据设置中实现可靠的误差控制。

> **ai_Abstract:** 本文研究了持久拉普拉斯特征值在数据中插入单一单纯形时的变化情况。尽管持久拉普拉斯算子已被广泛应用于多个领域，但单个特征值在局部扰动下的精确变化一直不明确。研究通过证明一个统一的利普希茨界，揭示了插入一个单纯形后，持久拉普拉斯特征值的变化量受限于该单纯形边界欧几里得范数的两倍。这一发现首次为谱拓扑数据分析提供了特征值层面的鲁棒性保证，确保了谱特征在局部更新下的稳定性，并支持在动态数据环境中进行可靠的误差控制。

> **摘要翻译:** 持久拉普拉斯算子是矩阵算子，用于追踪数据形状和结构如何跨尺度转换，并广泛应用于生物学、物理学和机器学习。它们的特征值是过滤中几何和拓扑特征的简洁描述符。尽管早期的工作已经确立了这些算子的全局代数稳定性，但当插入一个顶点、边或三角形等单一单纯形时，单个特征值的精确变化仍然未知。这很重要，因为包括热核签名和谱神经网络在内的下游工具直接依赖于这些特征值。我们通过证明一个统一的利普希茨界来弥补这一空白：在插入一个单纯形后，每个向上持久拉普拉斯特征值的变化最大为其边界欧几里得范数的两倍，且与过滤尺度和复形大小无关。这一结果为谱拓扑数据分析提供了首次特征值层面的鲁棒性保证。它保证了谱特征在局部更新下保持稳定，并能在动态数据设置中实现可靠的误差控制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [184] [Characterization and Mitigation of Training Instabilities in Microscaling Formats](https://arxiv.org/abs/2506.20752)
> *微缩放格式中训练不稳定性的表征与缓解*

*Huangyuan Su, Mujin Kwun, Stephanie Gil, Sham Kakade, Nikhil Anand* | **Category: cs.LG, cs.AR**

**Keywords:** 微缩放, 训练不稳定性, 大型语言模型, 低精度, 量化

**Comment:** 14 pages + appendices

> **TL;DR:** 本文研究了在微缩放（MX）格式下训练大型语言模型时出现的训练不稳定性，发现这是由量化引入的梯度偏差引起的，并提出了通过混合精度配置来缓解这些不稳定性，使其性能接近全精度训练。

**AI_Comments:** 该论文的创新点在于系统性地表征了微缩放格式在训练大型语言模型时引入的不稳定性，并明确指出了其根本原因——量化引入的乘性梯度偏差。其重要性在于为未来低精度训练硬件和算法的设计提供了关键见解。通过提出并验证混合精度配置作为缓解策略，为实际应用提供了可行的解决方案。研究规模庞大，训练了近千个模型，增强了结论的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型训练成本高昂且计算密集，下一代硬件加速器支持低精度算术格式（如NVIDIA Blackwell架构中的微缩放MX格式）以提高效率。然而，在这些格式下训练模型可能面临挑战，需要对其进行表征和缓解。

**Method:** 研究人员训练了近一千个大型语言模型，涵盖不同计算预算和权重-激活精度组合，观察MX格式下的训练行为。为了解释不稳定现象，他们在一个较小的代理模型上进行了受控实验和消融研究，扫掠了架构设置、超参数和精度格式。通过原位干预实验，验证了修改训练中精度方案的有效性。

**Result:** 在MX格式下训练时，尤其是在较大的计算规模下，训练损失表现出尖锐、随机的不稳定性。实验表明，由层归一化仿射参数和少量激活的量化引入的乘性梯度偏差可以触发失控发散。通过原位干预，展示了通过在训练中修改精度方案可以避免或延迟不稳定性。在LLM设置中，某些混合配置能够恢复与全精度训练相当的性能。

**Conclusion:** 微缩放（MX）格式在大型语言模型训练中存在显著的不稳定性，这些不稳定性主要源于量化引入的乘性梯度偏差。然而，通过在训练中采用混合精度配置等策略，可以有效缓解这些不稳定性，使模型性能达到与全精度训练相当的水平。

> **ai_Abstract:** 本研究深入探讨了在NVIDIA Blackwell架构中引入的微缩放（MX）格式在大型语言模型（LLM）训练中出现的训练不稳定性。通过对大量LLM的广泛实验，作者发现MX格式训练会导致损失出现尖锐、随机的不稳定性。进一步的受控实验揭示，这种不稳定性源于量化层归一化仿射参数和部分激活时引入的乘性梯度偏差，该偏差可导致训练发散。为解决此问题，研究提出并通过实验验证了在训练中动态调整精度方案的有效性，特别是采用混合配置，能够显著缓解不稳定性并使模型性能恢复至与全精度训练相当的水平。

> **摘要翻译:** 训练大型语言模型是一个昂贵且计算密集的过程，随着模型规模的扩大、算法的改进和新数据的收集，这一过程需要重复进行。为了解决这个问题，下一代硬件加速器越来越多地支持低精度算术格式，例如NVIDIA Blackwell架构中引入的微缩放（MX）格式。这些格式在参数块内使用共享比例因子来扩展可表示范围，并以降低的精度执行前向/后向GEMM操作以提高效率。在这项工作中，我们调查了模型训练期间块缩放精度格式的挑战和可行性。在从头开始训练的近一千个语言模型中——计算预算从$2 \times 10^{17}$到$4.8 \times 10^{19}$ FLOPs，并涵盖了广泛的权重-激活精度组合——我们始终观察到MX格式的训练表现出尖锐、随机的损失不稳定性，尤其是在较大的计算规模下。为了解释这种现象，我们对一个表现出与语言模型相似行为的较小代理模型进行了受控实验和消融研究，扫掠了架构设置、超参数和精度格式。这些实验促使我们建立了一个简单的模型，其中层归一化仿射参数和少量激活的量化引入的乘性梯度偏差可以触发失控发散。通过对我们的代理模型进行原位干预实验，我们证明通过在训练中修改精度方案可以避免或延迟不稳定性。在这些发现的指导下，我们在LLM设置中评估了稳定策略，并表明某些混合配置可以恢复与全精度训练相当的性能。我们已在https://github.com/Hither1/systems-scaling发布了代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [193] [Universal and Efficient Detection of Adversarial Data through Nonuniform Impact on Network Layers](https://arxiv.org/abs/2506.20816)
> *神经网络层非均匀影响下的对抗性数据通用高效检测*

*Furkan Mumcu, Yasin Yilmaz* | **Category: cs.LG, cs.CR, cs.CV**

**Keywords:** 对抗性样本检测, 深度神经网络, 特征预测, 实时处理, 通用防御

**Comment:** arXiv admin note: substantial text overlap with arXiv:2410.17442

> **TL;DR:** 提出了一种通过分析对抗性攻击对DNN不同层的影响来高效检测对抗性样本的新方法。

**AI_Comments:** 本文提出了一种新颖的对抗性样本检测视角，即利用攻击对网络层非均匀影响的特性。其创新点在于通过轻量级回归模型预测层间特征并利用预测误差进行检测，避免了传统防御方法的局限性。该方法的通用性和高效性对于实际部署具有重要意义，尤其是在实时处理场景下。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）容易受到对抗性攻击，现有防御方法（提高DNN鲁棒性或使用辅助模型检测）要么对最新攻击无效，要么计算效率低下，无法进行实时处理。本研究旨在提供一种更实用、高效的攻击检测方法。

**Method:** 本文提出了一种新颖的通用高效方法来检测对抗性样本，通过分析攻击对不同DNN层产生的不同程度的影响。具体而言，该方法训练一个轻量级回归模型，该模型从早期层特征预测更深层特征，并利用预测误差来检测对抗性样本。

**Result:** 该检测方法被证明是高效的、计算效率高（适用于实时处理）、与任何DNN架构兼容，并且适用于图像、视频和音频等不同领域。

**Conclusion:** 本文提出了一种通用且高效的对抗性数据检测方法，通过分析对抗性攻击对网络层的非均匀影响，能够有效应对现有攻击并满足实时处理需求，具有广泛的应用前景。

> **ai_Abstract:** 本文提出了一种新颖、通用且高效的对抗性数据检测方法，旨在解决深度神经网络在对抗性攻击下的脆弱性问题。该方法通过分析对抗性攻击对深度神经网络不同层产生的非均匀影响来识别对抗性样本，具体实现为训练一个轻量级回归模型，利用早期层特征预测深层特征并基于预测误差进行检测。实验证明，该方法在效果和计算效率上均表现出色，适用于实时处理，并兼容多种DNN架构及跨模态数据。

> **摘要翻译:** 深度神经网络（DNN）对具有有限噪声预算的对抗性输入设计非常脆弱。虽然已经提出了许多对原始输入进行细微修改的成功攻击，但针对这些攻击的防御技术相对研究不足。现有的防御方法要么通过消除扰动的影响来提高DNN的鲁棒性，要么使用辅助模型来检测对抗性数据。尽管同样重要，但本研究中探讨的攻击检测方法与鲁棒性方法相比，提供了一种更实用的防御。我们发现，现有检测方法要么对最先进的攻击技术无效，要么计算效率低下，无法进行实时处理。我们提出了一种新颖的通用高效方法，通过分析攻击对不同DNN层产生的不同程度的影响来检测对抗性样本。我们的方法训练了一个轻量级回归模型，该模型从早期层特征预测更深层特征，并利用预测误差来检测对抗性样本。通过理论论证和大量实验，我们证明我们的检测方法高效、计算效率高（适用于实时处理）、与任何DNN架构兼容，并且适用于图像、视频和音频等不同领域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [198] [Stochastic and Non-local Closure Modeling for Nonlinear Dynamical Systems via Latent Score-based Generative Models](https://arxiv.org/abs/2506.20771)
> *基于潜在得分生成模型的非线性动力系统随机非局部闭合建模*

*Xinghao Dong, Huchen Yang, Jin-Long Wu* | **Category: cs.LG, math.DS, physics.comp-ph**

**Keywords:** 随机闭合模型, 潜在得分生成模型, 非线性动力系统, 扩散模型, 自编码器

**Comment:** 

> **TL;DR:** 提出了一种基于潜在得分生成AI框架，用于非线性动力系统的随机非局部闭合建模，通过在潜在空间中联合训练自编码器和扩散模型，显著降低计算成本，同时保持预测精度。

**AI_Comments:** 这项工作创新性地将自编码器与条件扩散模型结合，在潜在空间进行闭合建模，有效解决了多尺度动力系统建模中计算成本过高的问题。其重要性在于为工程湍流等复杂系统提供了更高效、更准确的数值模拟方法，有望推动计算力学领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在缺乏明确尺度分离的多尺度动力系统建模中存在局限性。经典闭合模型假设过于严格，而扩散模型的计算成本过高，限制了实际应用。

**Method:** 提出一个潜在得分生成AI框架，通过在潜在空间中联合训练卷积自编码器（convolutional autoencoders）和条件扩散模型（conditional diffusion models）。这种方法旨在显著降低采样过程的维度，同时保留物理特性。

**Result:** 联合训练方法成功发现了合适的潜在空间，确保了较小的重建误差和潜在空间中扩散模型的良好性能。当集成到数值模拟中时，该框架显著加速了计算，并保持了与物理空间中标准扩散模型相当的预测精度。

**Conclusion:** 通过在潜在空间中联合训练自编码器和条件扩散模型，可以有效地为非线性动力系统构建随机非局部闭合模型，克服了传统方法和现有扩散模型在计算效率上的限制，同时保持了高精度。

> **ai_Abstract:** 这篇论文提出了一种基于潜在得分生成AI的框架，用于非线性动力系统的随机非局部闭合建模。针对传统方法在多尺度系统建模中存在的局限性以及现有扩散模型计算成本高昂的问题，作者通过在潜在空间中联合训练卷积自编码器和条件扩散模型，有效降低了计算复杂度，同时保持了模型的预测精度。数值结果表明，该方法在计算效率和准确性方面均表现出色，为复杂多尺度动力系统建模提供了新的解决方案。

> **摘要翻译:** 我们提出了一种潜在得分生成AI框架，用于计算力学中非线性动力系统的随机、非局部闭合模型和本构定律的学习。这项工作解决了在没有明确尺度分离的情况下建模复杂多尺度动力系统的关键挑战，因为数值求解所有尺度是极其昂贵的，例如工程湍流。虽然经典闭合建模方法利用领域知识来近似亚网格尺度现象，但其确定性和局部假设在缺乏明确尺度分离的区域可能过于严格。扩散基随机模型的最新发展在闭合建模方面展现出前景，但其过高的计算推理成本限制了许多实际应用的落地。这项工作通过在潜在空间中联合训练卷积自编码器和条件扩散模型来解决这一限制，显著降低了采样过程的维度，同时保留了基本的物理特性。数值结果表明，联合训练方法有助于发现一个合适的潜在空间，该空间不仅保证了小的重建误差，而且确保了潜在空间中扩散模型的良好性能。当集成到数值模拟中时，所提出的通过潜在条件扩散模型实现的随机建模框架在保持与物理空间中标准扩散模型相当的预测精度的同时，实现了显著的计算加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [199] [Devising a solution to the problems of Cancer awareness in Telangana](https://arxiv.org/abs/2506.21500)
> *制定解决特伦甘纳邦癌症意识问题的方案*

*Priyanka Avhad, Vedanti Kshirsagar, Urvi Ranjan, Mahek Nakhua* | **Category: cs.LG, cs.CY, q-bio.QM**

**Keywords:** 癌症意识, 机器学习, 癌症筛查, 特伦甘纳邦, 易感性预测

**Comment:** 

> **TL;DR:** 针对特伦甘纳邦癌症意识和筛查率低的问题，本文开发了一个基于机器学习的系统，用于预测癌症易感性、提供医院建议并整合健康记录，以提高癌症意识和降低死亡率。

**AI_Comments:** 该论文提出了一种结合机器学习和信息系统来解决公共健康问题的创新方法。其重要性在于直接针对特伦甘纳邦癌症筛查率低和意识不足的实际痛点。通过预测易感性和提供个性化医院建议，有望提高早期诊断率。此外，整合健康卡和开展宣传活动的设计也体现了全面性。然而，抽象中未提及模型的具体性能指标（如准确率、召回率等），也未详细说明数据来源和规模，这可能是未来研究需要补充的方面。

<details>
  <summary>Details</summary>

**Motivation:** 特伦甘纳邦宫颈癌、乳腺癌和口腔癌的筛查率极低（2020年分别为3.3%、0.3%和2.3%）。尽管早期检测是降低发病率和死亡率的唯一途径，但当地民众对癌症症状和筛查实践的认识非常低。

**Method:** 开发了一个机器学习分类模型，根据人口统计学因素预测个人对乳腺癌或宫颈癌的易感性，分别使用了决策树分类和支持向量分类算法。同时，设计了一个系统，根据用户位置提供最近的医院或癌症治疗中心建议，并计划整合健康卡以维护个人医疗记录和开展癌症宣传活动。

**Result:** 开发了一个基于机器学习的癌症易感性预测模型，并设计了一个提供医院建议和整合医疗记录的综合系统。

**Conclusion:** 通过开发此解决方案，有助于传播癌症意识，从而降低癌症死亡率并提高特伦甘纳邦人民的癌症素养。

> **ai_Abstract:** 本文旨在解决印度特伦甘纳邦癌症筛查率低和公众癌症意识不足的问题。研究团队开发了一个机器学习分类模型，利用人口统计学因素预测个体对乳腺癌和宫颈癌的易感性，并分别采用了决策树和支持向量机算法。此外，还设计了一个系统，能够根据用户位置推荐最近的癌症治疗中心，并计划整合健康卡以管理医疗记录和组织癌症宣传活动。该解决方案旨在通过提高癌症意识来降低癌症死亡率并提升公众的癌症素养。

> **摘要翻译:** 根据数据显示，2020年特伦甘纳邦接受宫颈癌、乳腺癌和口腔癌筛查的女性比例分别为3.3%、0.3%和2.3%。尽管早期检测是降低发病率和死亡率的唯一途径，但人们对宫颈癌和乳腺癌的体征、症状以及筛查实践的认识非常低。我们开发了一个机器学习分类模型，根据人口统计学因素预测一个人是否易患乳腺癌或宫颈癌。我们设计了一个系统，根据用户的位置或地址提供最近的医院或癌症治疗中心的建议。除此之外，我们还可以整合健康卡来维护所有个体的医疗记录，并开展意识宣传活动。对于机器学习分类模型，我们分别使用决策树分类和支持向量分类算法来预测宫颈癌易感性和乳腺癌易感性。因此，通过设计这个解决方案，我们离实现我们的目标又近了一步，即传播癌症意识，从而降低癌症死亡率并提高特伦甘纳邦人民的癌症素养。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [212] [Stochastic Parameter Decomposition](https://arxiv.org/abs/2506.20790)
> *随机参数分解*

*Lucius Bushnaq, Dan Braun, Lee Sharkey* | **Category: cs.LG, cs.AI**

**Keywords:** 随机参数分解, 线性参数分解, 神经网络, 机械可解释性, 逆向工程

**Comment:** 

> **TL;DR:** 本文提出了一种名为随机参数分解（SPD）的新方法，旨在解决现有线性参数分解方法（如归因参数分解APD）在逆向工程神经网络时计算成本高和对超参数敏感的问题。SPD比APD更具可扩展性和鲁棒性，能分解更大更复杂的模型，并避免了参数收缩等问题，为机械可解释性研究开辟了新途径。

**AI_Comments:** SPD的创新之处在于其对现有线性参数分解方法的重大改进，特别是在解决可扩展性和鲁棒性方面的痛点。这使得机械可解释性研究能够扩展到更复杂、更大规模的神经网络模型，是该领域的一个重要进展。论文还提供了开源库，有助于研究的复现和进一步探索，体现了开放科学的精神。

<details>
  <summary>Details</summary>

**Motivation:** 逆向工程神经网络的关键一步是将其分解为更简单的部分。现有的线性参数分解框架中的主要方法，归因参数分解（APD），因其计算成本高和对超参数敏感而变得不实用。

**Method:** 本文引入了随机参数分解（SPD），这是一种比APD更具可扩展性且对超参数更鲁棒的方法。该方法通过连接因果中介分析和网络分解方法来实现。

**Result:** SPD能够分解比APD更大、更复杂的模型。它还避免了学习参数收缩等其他问题，并在玩具模型中更好地识别了真实机制。

**Conclusion:** SPD通过消除线性参数分解方法扩展到更大模型的障碍，为机械可解释性研究开辟了新的可能性。这通过连接因果中介分析和网络分解方法得以实现。

> **ai_Abstract:** 本文提出随机参数分解（SPD），旨在克服现有线性参数分解方法（如APD）在逆向工程神经网络时面临的计算成本高和超参数敏感性问题。SPD被证明比APD更具可扩展性和鲁棒性，能够有效分解更大、更复杂的神经网络模型，并避免了学习参数收缩等常见问题。通过将因果中介分析与网络分解相结合，SPD为将线性参数分解方法应用于大型模型提供了可行途径，从而为机械可解释性研究开辟了新的机遇。

> **摘要翻译:** 逆向工程神经网络的一个关键步骤是将其分解为可以相对独立研究的更简单部分。线性参数分解——一个已被提出的用于解决当前分解方法中若干问题的框架——将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，该框架中当前的主要方法，归因参数分解（APD），因其计算成本和对超参数的敏感性而变得不实用。在这项工作中，我们引入了随机参数分解（SPD），这是一种比APD更具可扩展性且对超参数更鲁棒的方法，我们通过分解比APD可能分解的模型略大且更复杂的模型来证明这一点。我们还表明，SPD避免了其他问题，例如学习参数的收缩，并且在玩具模型中更好地识别了真实机制。通过连接因果中介分析和网络分解方法，这一演示通过消除将线性参数分解方法扩展到更大模型的障碍，为机械可解释性开辟了新的研究可能性。我们发布了一个用于运行SPD和复现我们实验的库，地址为 https://github.com/goodfire-ai/spd。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [221] [Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)
> *精益训练，更低泄露：LoRA 下 LLM 微调中记忆化的再探讨*

*Fei Wang, Baochun Li* | **Category: cs.LG, cs.CL, cs.CR**

**Keywords:** LLM, LoRA, 微调, 记忆化, 数据泄露

**Comment:** 

> **TL;DR:** LoRA 微调显著降低了大型语言模型的记忆化风险，且不受模型规模和数据重复性的影响，同时保持了良好的任务性能。

**AI_Comments:** 这项工作揭示了 LoRA 微调在记忆化方面与传统微调和预训练的显著差异，强调了 LoRA 在降低数据泄露风险方面的潜力，这对于LLM的安全性和隐私性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）中的记忆化使其容易受到数据提取攻击。虽然预训练记忆化已被广泛研究，但在微调阶段，特别是 LoRA 微调中，其影响尚未得到充分探索。

**Method:** 本文重新审视了微调中的记忆化，并使用一种更宽松的基于相似度的记忆化度量方法，比较了 LoRA 微调与完全微调。

**Result:** 与预训练和完全微调不同，模型规模和数据重复等因素在 LoRA 微调中对记忆化的影响趋势不一致。LoRA 微调相比完全微调显著降低了记忆化风险，同时保持了强大的任务性能。

**Conclusion:** LoRA 是一种有效降低 LLM 微调中记忆化风险的方法，同时能维持性能。

> **ai_Abstract:** 本文重新审视了大型语言模型微调中的记忆化问题，特别关注了参数高效的 LoRA 方法。研究发现，与预训练和完全微调不同，LoRA 微调中的记忆化受模型规模和数据重复的影响较小，并且与完全微调相比，LoRA 能显著降低记忆化风险，同时保持优秀的任务性能。

> **摘要翻译:** 大型语言模型（LLM）中的记忆化使其容易受到数据提取攻击。虽然预训练记忆化已被广泛研究，但很少有工作探索其在微调中的影响，特别是对于 LoRA 微调这种广泛采用的参数高效方法。
在这项工作中，我们重新审视了微调中的记忆化，并发现了与不同微调策略先前研究结果的惊人差异。模型规模和数据重复等在预训练和完全微调中强烈影响记忆化的因素，在 LoRA 微调中并不遵循相同的趋势。使用一种更宽松的基于相似度的记忆化度量，我们证明 LoRA 相比完全微调显著降低了记忆化风险，同时仍保持了强大的任务性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [222] [GPU Kernel Scientist: An LLM-Driven Framework for Iterative Kernel Optimization](https://arxiv.org/abs/2506.20807)
> *GPU核科学家：一个由LLM驱动的迭代内核优化框架*

*Martin Andrews, Sam Witteveen* | **Category: cs.LG, cs.AI, cs.PF, cs.SE**

**Keywords:** GPU内核优化, LLM, 迭代优化, 自动化框架, 加速器内核

**Comment:** 4 page paper plus Appendices. Accepted to the ES-FoMo "Efficient
  Systems for Foundation Models" workshop at ICML 2025

> **TL;DR:** 本文介绍了一个名为“GPU核科学家”的LLM驱动框架，用于自动化迭代优化GPU内核，特别适用于新或文档较少的架构。

**AI_Comments:** 该论文创新性地将大型语言模型（LLM）应用于GPU内核优化这一高度专业化且传统上依赖人工的任务。其核心优势在于自动化迭代实验过程，并弥补了领域专业知识的不足，这对于新兴或文档较少的架构尤为重要。尽管缺乏具体的定量结果是一个限制，但所提出的框架设计和定性见解表明，它在民主化高性能计算方面具有显著潜力。

<details>
  <summary>Details</summary>

**Motivation:** 优化GPU内核以实现高性能是一项复杂任务，需要深入的架构知识和大量实验，尤其是在针对较新或文档较少的GPU架构时，挑战更大。现有传统开发辅助工具稀缺，因此需要一种自动化解决方案。

**Method:** “GPU核科学家”框架利用LLM进行多阶段进化过程：(a) 战略性选择有前景的现有代码版本；(b) 基于现有代码和GPU文献知识生成优化假设；(c) 通过代码修改并利用外部评估系统的时序数据反馈，自主执行实验。该方法旨在解决AMD MI300架构的挑战，并弥补领域专业知识的不足。

**Result:** 由于定量结果在论文提交时被禁止公开，本文主要展示了该架构的设计、操作工作流程和定性见解。研究强调了LLM驱动的代理在民主化和加速GPU内核优化方面的潜力，尤其是在资源受限或硬件快速发展的环境中。

**Conclusion:** LLM驱动的代理具有民主化和加速GPU内核优化的潜力，特别是在资源有限或硬件环境快速演进的情况下。

> **ai_Abstract:** 本文提出了一个名为“GPU核科学家”的LLM驱动自动化框架，旨在迭代优化GPU内核。该框架通过利用LLM选择代码版本、生成优化假设以及基于性能反馈自主执行实验，解决了GPU内核优化的复杂性，尤其是在面对新型架构时。尽管定量结果尚未公开，论文详细阐述了其架构设计和工作流程，强调了该框架在严苛硬件环境中民主化和加速GPU内核优化的巨大潜力。

> **摘要翻译:** 优化GPU内核以实现高性能是一项复杂的任务，通常需要深入的架构知识、广泛的性能分析和迭代实验。当针对较新或文档较少的GPU架构时，传统开发辅助工具稀缺，这一挑战尤为突出。本文介绍了一种由LLM驱动的“GPU核科学家”，这是一种用于迭代优化加速器内核的自动化方法。
我们的方法采用LLM进行多阶段、进化的过程：(a) 战略性地选择有前景的先前代码版本作为新迭代的基础；(b) 基于现有代码和从通用GPU文献中吸收的知识，生成优化实验的假设；(c) 通过代码修改并随后提交到外部评估系统，仅使用观察到的时间数据作为性能反馈，自主实施这些实验。我们详细介绍了该方法如何应对AMD MI300目标架构的挑战，并利用LLM弥补有限的领域特定人类专业知识。
由于在论文提交日期，正在进行的性能竞赛的定量结果被禁止公开，因此我们展示了架构设计、操作工作流程和定性见解，强调了LLM驱动的代理在民主化和加速GPU内核优化方面的潜力，特别是在资源受限或快速发展的硬件环境中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [238] [FINN-GL: Generalized Mixed-Precision Extensions for FPGA-Accelerated LSTMs](https://arxiv.org/abs/2506.20810)
> *FINN-GL：面向FPGA加速LSTM的广义混合精度扩展*

*Shashwat Khandelwal, Jakoba Petri-Koenig, Thomas B. Preußer, Michaela Blott, Shreejith Shanker* | **Category: cs.LG, cs.AI, cs.AR, eess.SP**

**Keywords:** FPGA, LSTM, 混合精度, FINN, RNN加速

**Comment:** 9 pages, 6 figures, 5 tables, Accepted for publication in IEEE
  FPL-2025 (https://2025.fpl.org/)

> **TL;DR:** 本文通过扩展FINN框架，为FPGA上的LSTM部署提供了广义的混合精度支持，实现了性能、资源和精度之间的良好平衡。

**AI_Comments:** 本文的创新点在于将FINN框架扩展到支持循环神经网络（RNNs），特别是LSTM的混合精度部署，这填补了现有FPGA加速工具主要针对前馈网络的空白。其提出的通用化流程，结合ONNX的Scan操作符和FINN编译器的定制转换，为在资源受限的FPGA上实现高效的LSTM加速提供了可行方案。这项工作对于推动边缘AI和嵌入式系统中时间序列任务的实时处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 循环神经网络（RNNs），特别是LSTM，在时间序列任务中表现出色，但其计算复杂性限制了在资源受限环境中进行实时部署。现有FPGA加速工具主要针对前馈网络，LSTM加速通常需要完全定制实现，因此存在一个空白。

**Method:** 作者利用开源且可扩展的FINN框架，通过ONNX的Scan操作符来建模LSTM的循环特性，并支持混合量化。此外，引入了FINN编译器中的自定义转换，将量化的ONNX计算图映射到FINN编译器HLS内核库和Vitis HLS的硬件块。

**Result:** 通过在股票预测任务上验证量化ConvLSTM模型，生成的硬件IP在性能（延迟）和资源消耗之间取得了平衡，同时在降低精度的前提下，其推理精度与现有最先进模型相当或更优。

**Conclusion:** 所提出的通用化流程将为FPGA上资源高效的RNN加速器设计铺平道路。

> **ai_Abstract:** 本文提出了一种基于FINN框架的通用混合精度扩展（FINN-GL），旨在解决LSTM在FPGA上部署的计算复杂性和现有工具不足的问题。通过利用ONNX的Scan操作符和FINN编译器的自定义转换，该方法支持LSTM的混合量化，并能将量化图映射到FPGA硬件。实验结果表明，该加速器在性能、资源利用和推理精度之间实现了高效平衡，并有望推动FPGA上资源高效RNN加速器的发展。

> **摘要翻译:** 循环神经网络（RNNs），特别是长短期记忆网络（LSTMs），对于情感分析和短期股票预测等时间序列任务非常有效。然而，其计算复杂性对资源受限环境中的实时部署构成了挑战。虽然FPGA为能源高效的AI加速提供了一个有前景的平台，但现有工具主要针对前馈网络，LSTM加速通常需要完全定制实现。本文通过利用开源且可扩展的FINN框架，弥补了这一空白，实现了LSTM在FPGA上的通用部署。具体而言，我们利用开放神经网络交换（ONNX）规范中的Scan操作符来建模LSTM计算的循环特性，从而支持其中的混合量化以及基于LSTM模型的功能验证。此外，我们在FINN编译器中引入了自定义转换，将量化的ONNX计算图映射到FINN编译器HLS内核库和Vitis HLS的硬件块。我们通过训练一个量化的ConvLSTM模型进行股票中间价预测任务（使用广泛使用的数据集），并使用我们的流程生成该模型的相应硬件IP（目标设备为XCZU7EV），从而验证了所提出的工具流程。结果表明，通过我们的流程生成的量化ConvLSTM加速器在性能（延迟）和资源消耗之间取得了平衡，同时在降低精度的前提下，其推理精度与现有最先进模型相当（或更优）。我们相信，所提出流程的通用性将为FPGA上资源高效的RNN加速器设计铺平道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [247] [An Information-Theoretic Analysis for Federated Learning under Concept Drift](https://arxiv.org/abs/2506.21036)
> *联邦学习在概念漂移下的信息论分析*

*Fu Peng, Meng Zhang, Ming Tang* | **Category: cs.LG, cs.DC**

**Keywords:** 联邦学习, 概念漂移, 信息论, KL散度, 互信息

**Comment:** 

> **TL;DR:** 本文使用信息论分析了联邦学习在概念漂移下的性能，并提出了一种基于KL散度和互信息的算法，该算法通过实验证明能有效提高长期性能并优于现有方法。

**AI_Comments:** 这篇论文通过引入信息论来分析联邦学习中的概念漂移问题，提供了一个新颖的理论视角。提出稳态泛化误差及其上界，并基于此设计正则化算法，具有理论和实践意义。使用树莓派搭建测试平台进行验证，增加了其实验的可信度。该研究在解决联邦学习在动态真实世界环境中适应性差的局限性方面迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦学习模型常在静态数据集上训练，但在真实世界中数据流分布会发生变化（概念漂移），导致模型性能下降。

**Method:** 本文利用信息论分析联邦学习在概念漂移下的性能，将概念漂移建模为马尔可夫链，并引入“稳态泛化误差”来评估模型捕获未来数据的能力，其上界通过KL散度和互信息推导。研究了周期性、渐进式和随机三种漂移模式。受此启发，提出了一种算法，通过KL散度和互信息对经验风险最小化方法进行正则化，以提高长期性能。还探讨了性能-成本权衡并构建了树莓派4联邦学习测试平台进行验证。

**Result:** 实验结果证实了理论发现，确认概念漂移模式显著影响联邦学习性能。所提出的方法在三种漂移模式下均持续优于现有方法。

**Conclusion:** 所提出的基于信息论的联邦学习概念漂移适应方法，通过对经验风险最小化进行正则化，能够有效提高长期性能并优于现有方法。

> **ai_Abstract:** 本文针对联邦学习在真实世界数据流中面临的概念漂移导致的性能下降问题，引入信息论进行分析。研究将概念漂移建模为马尔可夫链，并定义稳态泛化误差，利用KL散度和互信息推导其上界。在此基础上，提出了一种新的算法，通过KL散度和互信息正则化经验风险最小化，以提升长期性能。实验在树莓派4测试平台上进行，结果表明概念漂移模式对性能影响显著，且所提方法在多种漂移模式下均优于现有方案，证明了其在联邦学习中适应概念漂移的有效性。

> **摘要翻译:** 近期联邦学习（FL）研究通常在静态数据集上训练模型。然而，真实世界的数据常以流的形式到达，且分布不断变化，导致性能下降，这被称为概念漂移。本文利用信息论分析了联邦学习在概念漂移下的性能，并提出了一种缓解性能下降的算法。我们将概念漂移建模为马尔可夫链，并引入“稳态泛化误差”来评估模型捕获未来未知数据特征的能力。其上界通过KL散度和互信息推导得出。我们研究了三种漂移模式（周期性、渐进式和随机）及其对联邦学习性能的影响。受此启发，我们提出了一种算法，该算法利用KL散度和互信息对经验风险最小化方法进行正则化，从而提高长期性能。我们还通过识别帕累托前沿来探索性能-成本权衡。为了验证我们的方法，我们使用树莓派4设备构建了一个联邦学习测试平台。实验结果与理论发现相符，证实了漂移模式显著影响性能。我们的方法在这三种模式下始终优于现有方法，证明了其在联邦学习中适应概念漂移的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [248] [Divide, Specialize, and Route: A New Approach to Efficient Ensemble Learning](https://arxiv.org/abs/2506.20814)
> *分而治之、专业化与路由：一种高效集成学习的新方法*

*Jakub Piwko, Jędrzej Ruciński, Dawid Płudowski, Antoni Zajko, Patryzja Żak, Mateusz Zacharecki, Anna Kozak, Katarzyna Woźnica* | **Category: cs.LG**

**Keywords:** 集成学习, 二元分类, 实例难度, 模型专业化, 计算效率

**Comment:** 14 pages, 6 figures

> **TL;DR:** Hellsemble是一种新的集成学习框架，通过将数据集按难度划分并训练专业化模型，实现了高效且准确的二元分类，优于传统方法。

**AI_Comments:** Hellsemble 的创新之处在于其“分而治之”的策略，通过实例级难度划分和专业化模型训练，有效提升了集成学习的效率和对复杂数据的处理能力。其可解释性和路由机制是亮点。

<details>
  <summary>Details</summary>

**Motivation:** 传统集成学习方法（如 bagging, boosting, DES）存在计算成本高和对异构数据分布适应性有限的问题。

**Method:** 本文提出Hellsemble框架，用于二元分类。该框架通过迭代地将错误分类的实例从较简单的模型传递给后续模型，逐步将数据集划分为难度圈，形成一个由专业化基础学习器组成的委员会。每个模型都在难度递增的子集上进行训练，同时一个独立的路由模型学习根据推断的难度将新实例分配给最合适的基础模型。

**Result:** Hellsemble在保持计算效率和可解释性的同时，实现了强大的分类精度。在OpenML-CC18和Tabzilla基准测试上的实验结果表明，Hellsemble通常优于经典集成方法。

**Conclusion:** 拥抱实例级难度为构建高效、鲁棒的集成系统提供了有前景的方向。

> **ai_Abstract:** 本文提出了一种名为 Hellsemble 的新型可解释集成学习框架，旨在解决传统集成方法计算成本高和对异构数据适应性差的问题。Hellsemble 通过将数据集按难度递增地划分为子集，并训练一系列专业化的基础学习器，同时利用一个路由模型将新实例分配给最合适的模型。实验证明，Hellsemble 在保持计算效率和可解释性的同时，在分类精度上优于传统集成方法。

> **摘要翻译:** 集成学习已被证明在提高预测性能方面有效，但传统的袋装法、提升法和动态集成选择（DES）等方法存在计算成本高和对异构数据分布适应性有限的问题。为了解决这些限制，我们提出了 Hellsemble，一种新颖且可解释的二元分类集成框架，它在训练和推理过程中都利用了数据集的复杂性。Hellsemble 通过迭代地将错误分类的实例从较简单的模型传递给后续模型，从而将数据集逐步划分为难度圈，形成一个由专业化基础学习器组成的委员会。每个模型都在难度递增的子集上进行训练，同时一个独立的路由模型学习根据推断的难度将新实例分配给最合适的基础模型。Hellsemble 在保持计算效率和可解释性的同时，实现了强大的分类精度。在 OpenML-CC18 和 Tabzilla 基准测试上的实验结果表明，Hellsemble 通常优于经典的集成方法。我们的研究结果表明，拥抱实例级难度为构建高效且鲁棒的集成系统提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [257] [AGTCNet: A Graph-Temporal Approach for Principled Motor Imagery EEG Classification](https://arxiv.org/abs/2506.21338)
> *AGTCNet: 一种用于规范运动想象脑电图分类的图时域方法*

*Galvin Brice S. Lim, Brian Godwin S. Lim, Argel A. Bandala, John Anthony C. Jose, Timothy Scott C. Chu, Edwin Sybingco* | **Category: cs.LG, cs.HC**

**Keywords:** 运动想象, 脑电图分类, 图时域网络, 脑机接口, AGTCNet

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** AGTCNet是一种新颖的图时域模型，用于运动想象EEG分类，通过利用电极拓扑结构和图卷积注意力网络，实现了最先进的性能，同时具有更小的模型尺寸和更快的推理速度，解决了脑机接口系统中EEG信号时空依赖性捕获的挑战。

**AI_Comments:** AGTCNet的创新之处在于其将EEG电极的拓扑配置作为归纳偏置，并结合图卷积注意力网络来学习时空EEG表示，有效解决了传统方法难以捕捉复杂时空依赖性的问题。其重要性体现在不仅提升了分类准确率，还在模型紧凑性和推理效率上取得了显著进步，这对于实际的脑机接口系统部署具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 脑机接口（BCI）技术在帮助运动障碍人士方面具有巨大潜力，但开发与受试者和会话无关的BCI系统仍面临挑战，因为个体间和时间上神经网络活动的复杂性和变异性，以及EEG硬件的限制。现有方法在捕获多通道EEG信号中复杂的时空依赖性方面效率低下。

**Method:** 本研究引入了注意力图时域卷积网络（AGTCNet），这是一种新颖的图时域模型，用于运动想象EEG（MI-EEG）分类。AGTCNet利用EEG电极的拓扑配置作为归纳偏置，并集成了图卷积注意力网络（GCAT）来共同学习富有表现力的时空EEG表示。

**Result:** AGTCNet显著优于现有MI-EEG分类器，实现了最先进的性能，同时采用紧凑的架构。模型尺寸减少了49.87%，推理时间加快了64.65%，并且使用更短的输入EEG信号。在BCI Competition IV Dataset 2a上，AGTCNet在受试者独立分类中实现了66.82%的移动平均准确率，经受试者特定微调后提高到82.88%。在EEG Motor Movement/Imagery Dataset上，AGTCNet在4分类和2分类受试者独立分类中分别达到了64.14%和85.22%的移动平均准确率，受试者特定分类进一步提高到72.13%和90.54%。

**Conclusion:** AGTCNet通过有效捕获EEG信号的时空依赖性，并在紧凑的架构下实现卓越的性能，证明了其在BCI部署中的有效性和实用性。

> **ai_Abstract:** 本研究提出了一种名为AGTCNet的新型图时域卷积网络，用于运动想象EEG（MI-EEG）分类。该模型通过利用EEG电极的拓扑结构作为归纳偏置，并结合图卷积注意力网络，有效地捕获了多通道EEG信号中复杂的时空依赖性。实验结果表明，AGTCNet在保持紧凑架构的同时，显著超越了现有MI-EEG分类器，实现了最先进的性能，并且在模型尺寸、推理速度和所需输入信号长度方面均有显著优化，验证了其在脑机接口应用中的有效性和实用性。

> **摘要翻译:** 脑机接口（BCI）技术利用脑电图（EEG）标志着一项变革性创新，使运动障碍人士能够平等地参与环境。尽管其潜力巨大，但由于个体之间和随时间变化的神经活动固有的复杂性和变异性，以及EEG硬件限制，开发受试者不变和会话不变的BCI系统仍然是一个重大挑战。虽然先前的研究试图开发鲁棒的BCI系统，但现有方法在捕获多通道EEG信号中复杂的时空依赖性方面仍然无效。本研究通过引入注意力图时域卷积网络（AGTCNet）来解决这一差距，这是一种用于运动想象EEG（MI-EEG）分类的新型图时域模型。具体来说，AGTCNet利用EEG电极的拓扑配置作为归纳偏置，并集成了图卷积注意力网络（GCAT）来共同学习富有表现力的时空EEG表示。所提出的模型显著优于现有MI-EEG分类器，实现了最先进的性能，同时采用紧凑的架构，凸显了其在BCI部署中的有效性和实用性。模型尺寸减少了49.87%，推理时间加快了64.65%，并使用更短的输入EEG信号，AGTCNet在BCI Competition IV Dataset 2a上针对受试者独立分类实现了66.82%的移动平均准确率，当针对受试者特定分类进行微调时，准确率进一步提高到82.88%。在EEG Motor Movement/Imagery Dataset上，AGTCNet在4分类和2分类受试者独立分类中分别实现了64.14%和85.22%的移动平均准确率，受试者特定分类进一步提高到72.13%和90.54%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [258] [Towards an Optimal Control Perspective of ResNet Training](https://arxiv.org/abs/2506.21453)
> *面向ResNet训练的最优控制视角*

*Jens Püttschneider, Simon Heilig, Asja Fischer, Timm Faulwasser* | **Category: cs.LG, cs.SY, eess.SY, math.OC**

**Keywords:** ResNet训练, 最优控制, 层剪枝, 权重消失

**Comment:** Accepted for presentation at the High-dimensional Learning Dynamics
  (HiLD) workshop at ICML 2025

> **TL;DR:** 将ResNet训练构建为最优控制问题，通过惩罚中间输出使不必要的深层权重消失，为剪枝提供理论基础。

**AI_Comments:** 该研究通过将ResNet训练与最优控制理论相结合，提供了一个新颖的视角。其创新点在于引入了中间输出惩罚机制，并证明了其对层剪枝的潜在益处，这可能为神经网络压缩提供新的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为ResNet训练提供一种新的、基于最优控制的视角和公式，以解决标准架构和通用损失函数下的训练问题。

**Method:** 提出将ResNet训练表述为一个最优控制问题，通过惩罚隐藏状态的中间输出（对应于最优控制中的阶段成本项）来连接ResNet和最优控制。具体地，对于标准ResNet，通过后续的跳跃连接和输出层来获取中间输出。

**Result:** 训练动态导致不必要的更深残差层的权重趋于消失。

**Conclusion:** 这种训练方法为基于理论的层剪枝策略提供了潜力。

> **ai_Abstract:** 该论文提出将ResNet训练重新构建为一个最优控制问题，通过在训练过程中惩罚中间输出（作为阶段成本）来促使不必要的深层残差层权重趋于消失。这种方法为开发理论上更严谨的层剪枝策略提供了可能性。

> **摘要翻译:** 我们提出了一种ResNet训练公式，反映了一个适用于标准架构和通用损失函数的最优控制问题。我们建议通过惩罚对应于最优控制中阶段成本项的隐藏状态中间输出来连接这两个领域。对于标准ResNet，我们通过后续的跳跃连接和输出层传播状态来获取中间输出。我们证明了我们的训练动态会使不必要的更深残差层的权重消失。这表明了基于理论的层剪枝策略的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [265] [Demystifying Distributed Training of Graph Neural Networks for Link Prediction](https://arxiv.org/abs/2506.20818)
> *揭秘图神经网络在链接预测中的分布式训练*

*Xin Huang, Chul-Ho Lee* | **Category: cs.LG**

**Keywords:** 图神经网络, 分布式训练, 链接预测, 图稀疏化, 性能下降

**Comment:** Accepted by IEEE ICDCS 2025

> **TL;DR:** 本文揭示了图神经网络在链接预测中分布式训练的性能下降问题，并提出了一种名为SpLPG的方法，通过图稀疏化有效降低通信成本，同时保持预测精度。

**AI_Comments:** 这篇论文的创新点在于深入分析了分布式GNN在链接预测中性能下降的具体原因，并提出了一个实用的解决方案SpLPG。通过引入图稀疏化来优化分布式训练中的通信效率，SpLPG有效地平衡了性能与成本，对于推动GNN在实际大规模应用中的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管分布式图神经网络（GNNs）框架和系统提高了GNN的扩展性和训练速度，但大多数都针对节点分类进行了优化，其在链接预测上的性能尚未得到充分探索。当每个工作节点在没有访问整个图的情况下训练其分配的子图时，链接预测的性能会下降，这是本研究的动机。

**Method:** 本文通过调查每个工作节点在没有访问整个图的情况下训练其分配的子图时性能下降的问题，揭示了图神经网络在链接预测中分布式训练的奥秘。研究发现，问题的主要来源不仅是图划分导致的信息丢失，还包括模型训练过程中负样本的抽取方式。为了解决这个问题，论文提出了SpLPG，该方法有效利用图稀疏化来缓解性能下降问题，并降低了通信成本。

**Result:** 在多个公共真实世界数据集上的实验结果表明，SpLPG是有效的，它将通信开销降低了约80%，同时大部分保持了链接预测的准确性。

**Conclusion:** 本文揭示了分布式图神经网络在链接预测中性能下降的原因，并提出了一种名为SpLPG的有效解决方案，通过图稀疏化显著降低了通信成本，同时保持了预测精度，解决了在分布式训练中访问完整图信息导致的通信开销过高的问题。

> **ai_Abstract:** 本文研究了图神经网络在链接预测任务中进行分布式训练时遇到的性能下降问题。研究发现，性能下降主要源于图划分导致的信息丢失以及负样本抽取方式。虽然共享完整图信息可解决精度问题，但会带来高昂的通信成本。为此，论文提出了一种名为SpLPG的方法，通过图稀疏化有效缓解了性能下降，并显著降低了通信开销。实验证明，SpLPG在保持链接预测准确性的同时，能将通信开销降低高达80%。

> **摘要翻译:** 图神经网络（GNNs）是解决图相关问题的强大工具。分布式GNN框架和系统增强了GNN的可扩展性并加速了模型训练，但大多数都针对节点分类进行了优化。它们在链接预测上的性能仍未得到充分探索。本文通过调查每个工作节点在没有访问整个图的情况下训练其分配的子图时性能下降的问题，揭示了图神经网络在链接预测中分布式训练的奥秘。我们发现，问题的主要来源不仅是图划分导致的信息丢失，还包括模型训练过程中负样本的抽取方式。虽然与每个工作节点共享完整的图信息可以解决问题并保持链接预测的准确性，但这会产生很高的通信成本。我们提出了SpLPG，它有效利用图稀疏化来缓解性能下降问题，并降低了通信成本。在多个公共真实世界数据集上的实验结果表明了SpLPG的有效性，它将通信开销降低了约80%，同时大部分保持了链接预测的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [271] [Learning-Based Resource Management in Integrated Sensing and Communication Systems](https://arxiv.org/abs/2506.20849)
> *学习型综合传感与通信系统资源管理*

*Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney* | **Category: cs.LG**

**Keywords:** 集成传感与通信, 资源管理, 深度强化学习, 时间分配

**Comment:** 

> **TL;DR:** 本文提出了一种基于约束深度强化学习(CDRL)的方法，用于优化集成传感与通信系统中跟踪和通信之间的时间分配，以提高通信质量。

**AI_Comments:** 这篇论文的创新点在于将约束深度强化学习应用于集成传感与通信系统中的资源管理，解决了在有限时间预算下同时优化目标跟踪和数据传输的复杂问题。这种方法对于提高未来通信系统的效率和性能具有重要意义，尤其是在动态和资源受限的环境中。

<details>
  <summary>Details</summary>

**Motivation:** 在配备雷达和通信单元的集成传感与通信系统中，需要解决自适应时间分配任务，即在跟踪多个目标和向估计目标位置传输数据之间进行时间分配，以提高目标通信质量。

**Method:** 引入了一种新颖的约束深度强化学习（CDRL）方法，旨在优化在时间预算约束下跟踪和通信之间的资源分配。

**Result:** 数值结果表明，所提出的CDRL框架是高效的，并证实了其在高度动态环境中遵守时间约束的同时最大化通信质量的能力。

**Conclusion:** CDRL方法能够有效地优化集成传感与通信系统中的资源分配，从而在动态环境中提高通信质量。

> **ai_Abstract:** 本文研究了集成传感与通信系统中的自适应时间分配问题，该系统需在目标跟踪和数据传输之间进行资源分配。为解决此问题，作者提出了一种新颖的约束深度强化学习（CDRL）方法，旨在优化时间预算约束下的资源分配，以提高通信质量。数值结果验证了CDRL框架的有效性，表明其能在动态环境下最大化通信质量并遵守时间限制。

> **摘要翻译:** 本文旨在解决配备雷达和通信单元的集成传感与通信系统中自适应时间分配的任务。双功能雷达通信系统的任务涉及为跟踪多个目标分配驻留时间，并利用剩余时间向估计的目标位置传输数据。我们引入了一种新颖的约束深度强化学习（CDRL）方法，旨在优化在时间预算约束下跟踪和通信之间的资源分配，从而提高目标通信质量。我们的数值结果证明了我们提出的CDRL框架的效率，证实了其在高度动态环境中遵守时间约束的同时最大化通信质量的能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [273] [Multi-Objective Reinforcement Learning for Cognitive Radar Resource Management](https://arxiv.org/abs/2506.20853)
> *认知雷达资源管理中的多目标强化学习*

*Ziyang Lu, Subodh Kalia, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney* | **Category: cs.LG, eess.SP**

**Keywords:** 多目标强化学习, 认知雷达, 资源管理, 时间分配, 帕累托最优

**Comment:** 

> **TL;DR:** 本文利用多目标深度强化学习解决认知雷达的时间分配问题，通过比较DDPG和SAC算法，发现SAC在稳定性和样本效率上表现更优。

**AI_Comments:** 本文创新性地将多目标深度强化学习应用于关键的雷达资源管理问题，特别是时间分配。DDPG和SAC的比较提供了实际见解，SAC表现出明显的优势。使用NSGA-II提供帕累托前沿的上限也是一个很好的基准。这种方法可以显著提高未来认知雷达系统在复杂动态环境中的适应性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 多功能认知雷达系统中的时间分配问题需要在扫描新出现的目标和跟踪已检测到的目标之间进行权衡。

**Method:** 将问题表述为多目标优化问题；采用深度强化学习（DDPG和SAC）寻找帕累托最优解；并使用NSGA-II算法估计帕累托前沿的上限。

**Result:** DDPG和SAC两种算法在适应不同场景方面均有效；SAC在稳定性和样本效率方面优于DDPG。

**Conclusion:** 这项工作有助于开发更高效、更自适应的认知雷达系统，能够在动态环境中平衡多个相互竞争的目标。

> **ai_Abstract:** 本文解决了认知雷达中的多目标时间分配问题，平衡了新目标扫描和现有目标跟踪。它将此问题表述为多目标优化问题，并使用深度强化学习（DDPG和SAC）来寻找帕累托最优解。结果表明，两种算法均有效，其中SAC在稳定性和样本效率方面优于DDPG。文中还使用NSGA-II估计帕累托前沿的上限，有助于开发更具适应性的雷达系统。

> **摘要翻译:** 多功能认知雷达系统中的时间分配问题侧重于扫描新出现的目标和跟踪先前检测到的目标之间的权衡。我们将此问题表述为多目标优化问题，并采用深度强化学习来寻找帕累托最优解，比较了深度确定性策略梯度（DDPG）和软行动者-评论家（SAC）算法。我们的结果表明，这两种算法在适应各种场景方面均有效，其中SAC与DDPG相比，显示出更高的稳定性和样本效率。我们进一步采用NSGA-II算法来估计所考虑问题的帕累托前沿的上限。这项工作有助于开发更高效、更自适应的认知雷达系统，能够在动态环境中平衡动态环境中的多个竞争目标。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [282] [Omniwise: Predicting GPU Kernels Performance with LLMs](https://arxiv.org/abs/2506.20886)
> *Omniwise：使用大型语言模型预测GPU内核性能*

*Zixian Wang, Cole Ramos, Muhammad A. Awad, Keith Lowery* | **Category: cs.LG, cs.AI**

**Keywords:** GPU性能预测, 大型语言模型, 自监督学习, 性能分析, Omniwise

**Comment:** 

> **TL;DR:** Omniwise是一个端到端、自监督的微调流程，首次将大型语言模型（LLMs）应用于GPU内核性能预测，无需实际执行代码即可准确预测性能指标，并在AMD GPU上表现出色。

**AI_Comments:** 本文提出Omniwise，首次将大型语言模型（LLMs）应用于GPU内核性能预测，这是一个显著的创新点。其优势在于无需实际执行代码即可预测性能，大大节省了时间和资源。此外，该方法模型无关且轻量级，即使小型模型也能取得良好效果，并通过集成开发环境插件提升了实用性。这对于GPU性能优化和开发流程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）的快速发展彻底改变了人工智能，但其强大的架构需要高效的GPU性能。为了解决GPU内核性能预测的挑战，本研究旨在引入一种无需代码执行或分析工具的新方法。

**Method:** 本研究提出了Omniwise，一个端到端、自监督的微调流程，将大型语言模型（LLMs）应用于GPU内核性能预测。Omniwise是模型无关且轻量级的，可以直接从内核代码预测内存带宽、缓存命中率、GFLOPs和算术强度等关键性能指标，无需执行代码或使用分析工具。

**Result:** Omniwise在AMD MI250和MI300X架构上执行的GPU内核预测中，超过90%的预测结果在10%的相对误差范围内。它能够预测关键性能指标，包括内存带宽、缓存命中率、GFLOPs和算术强度。

**Conclusion:** Omniwise成功地将大型语言模型应用于GPU内核性能预测，提供了一种无需代码执行的、准确且轻量级的解决方案，并能无缝集成到开发者的工作流程中，极大地提升了性能分析的效率。

> **ai_Abstract:** Omniwise是首个将大型语言模型（LLMs）应用于GPU内核性能预测的端到端、自监督微调流程。它能够直接从内核代码预测内存带宽、缓存命中率、GFLOPs和算术强度等关键性能指标，无需实际执行代码或使用分析工具。该方法在AMD MI250和MI300X架构上的GPU内核上，超过90%的预测结果在10%的相对误差内。此外，Omniwise还提供了在线推理服务器和VS Code插件，便于开发者集成使用。

> **摘要翻译:** 近年来，深度神经网络（DNNs）的快速发展彻底改变了人工智能，使模型具备了前所未有的理解、生成和处理复杂数据的能力。这些强大的架构已经改变了广泛的下游应用，解决了人类力所不能及的任务。在本文中，我们介绍了Omniwise，这是第一个端到端、自监督的微调流程，将大型语言模型（LLMs）应用于GPU内核性能预测——这是性能分析中的一个新颖用例。Omniwise是模型无关且轻量级的，即使使用一个小型3B参数模型也能取得显著结果。它可以直接从内核代码预测关键性能指标，包括内存带宽、缓存命中率、GFLOPs和算术强度，而无需代码执行或分析工具。我们的方法在AMD MI250和MI300X架构上执行的GPU内核上，实现了超过90%的预测在10%的相对误差范围内。除了该流程，我们还开发了一个在线推理服务器和一个Visual Studio Code插件，将基于LLM的性能预测无缝集成到开发人员的工作流程中。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [286] [On the Necessity of Output Distribution Reweighting for Effective Class Unlearning](https://arxiv.org/abs/2506.20893)
> *论输出分布重加权对有效类别遗忘的必要性*

*Yian Wang, Ali Ebrahimpour-Boroojeny, Hari Sundaram* | **Category: cs.LG**

**Keywords:** 机器遗忘, 输出重加权, 类别遗忘, 成员推断攻击, 数据隐私

**Comment:** 

> **TL;DR:** 本文提出了一种名为RWFT的轻量级输出重加权遗忘方法，用于从训练好的分类器中擦除整个类别，无需完全重新训练，并能有效防止成员推断攻击，且在各项指标上表现优异。

**AI_Comments:** 本文创新性地提出了输出分布重加权的概念来解决机器遗忘中遗忘类别行为复制和成员推断攻击鲁棒性的问题。通过引入新的评估指标，进一步推动了该领域对遗忘效果量化的理解。其轻量级特性和优越的性能使其在实际应用中具有重要潜力，尤其是在数据隐私和模型伦理方面。

<details>
  <summary>Details</summary>

**Motivation:** 从训练模型中遗忘特定类别对于强制执行用户删除权和减轻有害或有偏见的预测至关重要。完全重新训练成本高昂，且现有遗忘方法在预测未遗忘类别样本时无法复制重新训练模型的行为，并且容易受到成员推断攻击。

**Method:** 引入了一种名为RWFT的输出重加权遗忘方法，这是一种轻量级技术，可在不完全重新训练的情况下从训练好的分类器中擦除整个类别。该方法通过对遗忘类别样本的预测概率质量进行简单的重新分配，使其对成员推断攻击MIA-NN具有鲁棒性。此外，还引入了一个基于总变差（TV）距离的预测概率新度量来量化残余泄漏。

**Result:** RWFT在现有评估指标和新提出的TV-based指标上都与完全重新训练的结果相匹配。与现有最佳方法相比，在之前使用的指标上提高了2.79%，在新提出的基于TV的指标上提高了111.45%。

**Conclusion:** 输出分布重加权对于实现有效的类别遗忘是必要的，它能够使遗忘模型更好地模拟完全重新训练的行为，并有效抵御成员推断攻击，同时提供了一种量化残余泄漏的新方法。

> **ai_Abstract:** 本文提出了一种名为RWFT的轻量级输出重加权遗忘方法，旨在无需完全重新训练即可从分类器中有效擦除特定类别。该方法通过重新分配遗忘类别的预测概率质量，提高了对成员推断攻击的鲁棒性。作者还引入了一个基于总变差距离的新度量来评估残余泄漏。实验结果表明，RWFT在各项指标上均能媲美完全重新训练，并且显著优于现有最先进的机器遗忘方法。

> **摘要翻译:** 在这项工作中，我们引入了一种输出重加权遗忘方法RWFT，这是一种轻量级技术，可以在不完全重新训练的情况下从训练好的分类器中擦除整个类别。从训练模型中遗忘特定类别对于强制执行用户删除权和减轻有害或有偏见的预测至关重要。完全重新训练成本高昂，而现有的遗忘方法在预测未遗忘类别样本时无法复制重新训练模型的行为。我们通过设计一种成员推断攻击的变体MIA-NN来证明这种失败，MIA-NN可以成功揭示任何这些方法的未遗忘类别。我们提出了一种对遗忘类别样本的预测概率质量进行简单重新分配的方法，该方法对MIA-NN具有鲁棒性。我们还引入了一个基于总变差（TV）距离的预测概率新度量，以量化残余泄漏，从而防止未来的方法容易受到新攻击的影响。通过对最先进的机器遗忘基线进行大量实验，我们表明我们的方法在先前工作使用的评估指标和我们在这项工作中提出的新指标上都与完全重新训练的结果相匹配。与最先进的方法相比，我们比现有最佳方法在先前使用的指标上提高了2.79%，在我们新的基于TV的指标上提高了111.45%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [290] [Graph-Structured Feedback Multimodel Ensemble Online Conformal Prediction](https://arxiv.org/abs/2506.20898)
> *图结构反馈多模型集成在线共形预测*

*Erfan Hajihashemi, Yanning Shen* | **Category: cs.LG**

**Keywords:** 在线共形预测, 多模型集成, 图结构反馈, 预测集, 分布漂移

**Comment:** 

> **TL;DR:** 提出一种新的多模型在线共形预测算法，通过图结构反馈动态选择有效模型子集，以降低计算复杂性并生成更小的预测集，同时保持覆盖率。

**AI_Comments:** 这篇论文通过引入图结构反馈机制，为多模型在线共形预测提供了一种新颖且高效的解决方案。其创新点在于动态选择有效模型子集，并利用预测集大小作为反馈，有效解决了计算复杂性和预测集过大的问题。这对于实际应用中需要处理大量候选模型和应对数据分布变化的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模型在线共形预测面临挑战：候选模型集过大导致计算复杂性增加，以及包含不相关或性能差的模型会负面影响性能并导致过大的预测集。

**Method:** 提出一种新的多模型在线共形预测算法。该算法通过收集来自二分图的反馈，在每个时间步识别一个有效的模型子集，并随新数据进行细化。然后从该子集中选择一个模型来构建预测集。此外，证明了使用预测集大小作为反馈（除了模型损失）可以显著提高效率。

**Result:** 提出的算法被证明能确保有效的覆盖率并实现次线性遗憾。在真实和合成数据集上的实验验证了所提出的方法能够构建更小的预测集，并优于现有的多模型在线共形预测方法。

**Conclusion:** 本文提出了一种创新的多模型在线共形预测算法，通过动态选择有效模型子集和利用预测集大小作为反馈，有效解决了现有方法的局限性，在保证覆盖率的同时显著提高了效率并减小了预测集。

> **ai_Abstract:** 本文提出了一种新颖的多模型在线共形预测算法，旨在解决现有方法中候选模型集过大导致的计算复杂性和无效模型影响预测集大小的问题。该算法通过基于二分图反馈动态识别并选择有效的模型子集来构建预测集，从而显著降低了计算成本并生成了更紧凑的预测集。研究还发现，将预测集大小作为反馈信号（除模型损失外）能进一步提升效率。理论分析和实验结果均表明，该方法在保证预测覆盖率的同时，实现了更优的性能和更小的预测集。

> **摘要翻译:** 在线共形预测已证明其有能力为每个传入数据点构建一个预测集，该预测集以预定概率覆盖真实标签。为了应对潜在的分布漂移，引入了多模型在线共形预测，从预选的候选集中选择和利用不同的模型。除了提高灵活性之外，预选集的选择也带来了挑战。包含大量模型的候选集可能会增加计算复杂性。此外，包含性能差的不相关模型可能会对性能产生负面影响，并导致不必要的大预测集。为了解决这些挑战，我们提出了一种新颖的多模型在线共形预测算法，该算法通过收集来自二分图的反馈，在每个时间步识别一个有效的模型子集，该二分图在接收新数据时得到完善。然后从该子集中选择一个模型来构建预测集，从而降低了计算复杂性并减小了预测集。此外，我们证明了使用预测集大小作为反馈，以及模型损失，可以通过构建更小的预测集来显著提高效率，同时仍满足所需的覆盖保证。所提出的算法被证明能确保有效的覆盖率并实现次线性遗憾。在真实和合成数据集上的实验验证了所提出的方法构建了更小的预测集，并优于现有的多模型在线共形预测方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [296] [Explainable AI for Radar Resource Management: Modified LIME in Deep Reinforcement Learning](https://arxiv.org/abs/2506.20916)
> *雷达资源管理中的可解释人工智能：深度强化学习中改进的 LIME*

*Ziyang Lu, M. Cenk Gursoy, Chilukuri K. Mohan, Pramod K. Varshney* | **Category: cs.LG**

**Keywords:** 可解释人工智能, 深度强化学习, 雷达资源管理, LIME, DL-LIME

**Comment:** 

> **TL;DR:** 本文提出了一种名为 DL-LIME 的改进 LIME 方法，它将深度学习集成到采样过程中，以解决传统 LIME 忽略特征相关性的问题。数值结果表明，DL-LIME 在雷达资源管理中，在保真度和任务性能方面均优于传统 LIME。

**AI_Comments:** 本文的创新点在于提出了 DL-LIME，通过将深度学习引入 LIME 的采样过程，解决了传统 LIME 忽略特征相关性的问题，从而提高了可解释性和性能。这对于将深度强化学习应用于关键决策领域（如雷达资源管理）具有重要意义，因为它能帮助理解模型决策，增强信任度。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习在雷达资源管理 (RRM) 等决策过程中表现出色，但其神经网络的“黑箱”性质限制了其可解释性。现有的可解释人工智能 (XAI) 方法如 LIME 在采样过程中忽略了特征间的相关性，需要一种改进的方法来提供更好的解释性。

**Method:** 本文提出了一种名为 DL-LIME 的改进 LIME 方法。DL-LIME 将深度学习 (DL) 集成到 LIME 的采样过程中，以解决传统 LIME 忽略特征相关性的问题。该方法应用于深度强化学习中的雷达资源管理。

**Result:** 数值结果表明，DL-LIME 在保真度和任务性能方面均优于传统 LIME。DL-LIME 在这两项指标上都表现出卓越的性能。此外，DL-LIME 还能揭示在雷达资源管理决策中哪些因素更重要。

**Conclusion:** DL-LIME 是一种改进的 LIME 方法，通过将深度学习集成到采样过程中，有效解决了传统 LIME 的局限性，并在雷达资源管理中实现了更好的解释性和性能。

> **ai_Abstract:** 本文针对深度强化学习在雷达资源管理中的“黑箱”问题，提出了一种改进的 LIME (局部可解释模型无关解释) 方法，命名为 DL-LIME。传统 LIME 在采样时忽略特征相关性，而 DL-LIME 通过将深度学习集成到采样过程中来解决这一问题。实验结果表明，DL-LIME 在保真度和任务性能上均优于传统 LIME，并且能有效揭示雷达资源管理决策中的关键因素。

> **摘要翻译:** 深度强化学习在决策过程中得到了广泛研究，并在包括雷达资源管理 (RRM) 在内的各个领域中表现出优于传统方法的性能。然而，神经网络的一个显著局限性是其“黑箱”性质，最近的研究工作越来越关注可解释人工智能 (XAI) 技术，以描述神经网络决策背后的原理。一种很有前景的 XAI 方法是局部可解释模型无关解释 (LIME)。然而，LIME 中的采样过程忽略了特征之间的相关性。在本文中，我们提出了一种改进的 LIME 方法，该方法将深度学习 (DL) 集成到采样过程中，我们称之为 DL-LIME。我们将 DL-LIME 应用于深度强化学习中的雷达资源管理。数值结果表明，DL-LIME 在保真度和任务性能方面均优于传统 LIME，在这两项指标上均表现出卓越的性能。DL-LIME 还提供了关于哪些因素在雷达资源管理决策中更重要的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [300] [Interpretable Representation Learning for Additive Rule Ensembles](https://arxiv.org/abs/2506.20927)
> *可解释的加性规则集成表示学习*

*Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley* | **Category: cs.LG, cs.AI**

**Keywords:** 加性规则集成, 可解释性, 稀疏线性变换, 倾斜决策边界, 模型复杂度

**Comment:** 

> **TL;DR:** 本文通过引入可学习的稀疏线性变换，扩展了传统规则集成，以在保持相同预测性能的同时显著降低模型复杂度。

**AI_Comments:** 本文的创新点在于将传统规则集成的轴平行决策边界扩展为倾斜边界，通过引入可学习的稀疏线性变换，使得模型能够在特征不理想的情况下依然保持较高的可解释性和预测性能。这种方法有效地平衡了模型的准确性与可解释性，对于实际应用中特征工程受限的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的加性规则集成模型使用基于单输入变量阈值（轴平行多面体）的规则条件，虽然可解释性高且学习效率高，但其性能高度依赖于预先准备好的富有表达力的输入特征。如果缺乏此类特征，为了达到足够的准确性，需要增加规则的数量和复杂性，从而降低模型的可解释性。

**Method:** 提出通过引入带有可学习稀疏线性变换的逻辑命题（形式为 $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$），来扩展经典的规则集成，从而实现具有倾斜面的决策区域。采用基于逻辑回归的迭代重加权公式的序贯贪婪优化方法进行学习。

**Result:** 实验结果表明，所提出的方法能够高效地构建规则集成，在十个基准数据集上与最先进的方法达到相同的测试风险，同时显著降低了模型复杂度。

**Conclusion:** 通过引入可学习的稀疏线性变换，本文提出的方法在保持高预测性能的同时，有效解决了传统规则集成在缺乏高质量特征时可解释性下降的问题，并显著降低了模型复杂度。

> **ai_Abstract:** 本文针对传统加性规则集成模型在缺乏高质量输入特征时解释性下降的问题，提出了一种新的方法。该方法通过引入带有可学习稀疏线性变换的逻辑命题，使得决策区域能够形成具有倾斜面的通用多面体，而非传统的轴平行多面体。文中采用基于迭代重加权逻辑回归的序贯贪婪优化算法进行模型学习。实验证明，新方法在保持与现有先进方法相同预测性能的同时，显著降低了模型复杂度，提升了模型的可解释性。

> **摘要翻译:** 符号规则的小型加性集成提供了可解释的预测模型。传统上，这些集成使用基于单个输入变量x和阈值t的简单阈值命题$x \geq t$的合取形式的规则条件，从而在几何上形成轴平行多面体作为决策区域。虽然这种形式确保了单个规则的高度可解释性，并且可以使用梯度提升方法有效地学习，但它依赖于拥有精心策划的一组富有表达力且理想独立的输入特征，以便少量的轴平行区域集成能够很好地描述目标变量。在缺乏此类特征的情况下，达到足够的准确性需要增加单个规则的数量和复杂性，这会降低模型的可解释性。在此，我们通过引入具有可学习的输入变量稀疏线性变换的逻辑命题，即形式为$\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$的命题来扩展经典规则集成，其中$\mathbf{w}$是可学习的稀疏权重向量，从而使决策区域成为具有倾斜面的通用多面体。我们提出了一种基于逻辑回归的迭代重加权公式的序贯贪婪优化学习方法。实验结果表明，所提出的方法能够高效地构建规则集成，在十个基准数据集上与最先进的方法具有相同的测试风险，同时显著降低了模型复杂度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [304] [Model State Arithmetic for Machine Unlearning](https://arxiv.org/abs/2506.20941)
> *模型状态算术用于机器遗忘*

*Keivan Rezaei, Mehrdad Saberi, Abhilasha Ravichander, Soheil Feizi* | **Category: cs.LG**

**Keywords:** 机器遗忘, 大型语言模型, 模型检查点, 数据擦除, MSA

**Comment:** Preprint. Work in progress

> **TL;DR:** 本文提出了一种名为MSA的新算法，通过利用模型检查点来有效估计和消除大型语言模型中特定数据点的影响，解决了传统重训练计算成本高的问题，并在多个基准测试中优于现有算法。

**AI_Comments:** 这项工作提出了一种新颖的方法，通过利用模型检查点来解决机器遗忘中的核心挑战——精确估计和消除数据点影响。其创新性在于将模型状态的演变融入到遗忘过程中，有效降低了计算成本并提高了遗忘效果。鉴于数据隐私和模型可控性的日益重要，这项研究对于开发负责任和可信赖的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在训练过程中可能包含私有、受版权保护、不准确或降低性能的数据。通过完全重训练来消除这些问题数据点的影响计算成本过高，因此需要低成本的遗忘算法。然而，精确估计和消除单个数据点的影响一直是一个挑战。

**Method:** 本文提出了一种名为MSA（Model State Arithmetic）的新算法，通过利用模型检查点（即捕获预训练不同阶段模型状态的工件）来估计和消除数据点的影响。

**Result:** 实验结果表明，MSA在多个基准测试、模型和评估指标上始终优于现有的机器遗忘算法。

**Conclusion:** MSA可以成为一种有效的方法，以实现更灵活的、能够进行数据擦除的大型语言模型。

> **ai_Abstract:** 本文提出了一种名为MSA（模型状态算术）的新型机器遗忘算法，旨在解决大型语言模型中移除特定数据点影响的计算成本问题。该算法通过利用模型预训练过程中的检查点来精确估计并消除有害数据的影响。实验结果表明，MSA在多个基准测试中表现优于现有遗忘算法，为实现更灵活、支持数据擦除的大型语言模型提供了有效途径。

> **摘要翻译:** 大型语言模型在海量网络数据语料库上进行训练，其中可能包括私有数据、受版权保护的材料、事实不准确的数据或降低模型性能的数据。通过完全重训练——即在排除这些特定实例的数据集上重复预训练模型——来消除此类问题数据点的影响，在计算上是 prohibitive 的。因此，出现了旨在消除特定数据点影响，同时以低计算成本保留模型其他部分的遗忘算法。然而，精确估计和撤销单个数据点的影响已被证明具有挑战性。在这项工作中，我们提出了一种新的算法，MSA，用于估计和撤销数据点的影响——通过利用模型检查点，即捕获预训练不同阶段模型状态的工件。我们的实验结果表明，MSA在多个基准测试、模型和评估指标上始终优于现有的机器遗忘算法，这表明MSA可能是一种有效的方法，可用于实现更灵活的、能够进行数据擦除的大型语言模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [306] [Antibody Design and Optimization with Multi-scale Equivariant Graph Diffusion Models for Accurate Complex Antigen Binding](https://arxiv.org/abs/2506.20957)
> *基于多尺度等变图扩散模型用于精确复杂抗原结合的抗体设计与优化*

*Jiameng Chen, Xiantao Cai, Jia Wu, Wenbin Hu* | **Category: cs.LG, cs.AI, I.2.6; I.2.1; J.3**

**Keywords:** 抗体设计, 等变图扩散, 序列-结构协同设计, 复杂抗原, 几何深度学习

**Comment:** 9 pages, 4 figures, accepted at IJCAI 2025

> **TL;DR:** AbMEGD是一个新的多尺度等变图扩散模型，用于抗体序列和结构协同设计，在复杂抗原结合方面表现优于现有方法。

**AI_Comments:** AbMEGD的创新点在于其结合了多尺度等变图扩散方法，实现了抗体序列和结构的协同设计，并利用E(3)等变性确保了几何精度和泛化能力。这对于处理复杂抗原的挑战尤其重要。其在关键CDR-H3区域的显著性能提升，表明该模型在平衡结构完整性和功能性方面取得了突破，为计算抗体设计领域设定了新的基准。

<details>
  <summary>Details</summary>

**Motivation:** 抗体设计在治疗和诊断开发中仍是关键挑战，特别是对于具有多样结合界面的复杂抗原。当前计算方法面临两大限制：(1) 在保留对称性的同时捕获几何特征，以及 (2) 泛化新型抗原界面。现有方法常未能准确捕获分子相互作用并维持结构完整性。

**Method:** 提出AbMEGD框架，一个端到端的多尺度等变图扩散（Multi-scale Equivariant Graph Diffusion）模型，用于抗体序列和结构协同设计。AbMEGD结合了原子级几何特征与残基级嵌入，捕获局部原子细节和全局序列-结构相互作用。其E(3)等变扩散方法确保了几何精度、计算效率和对复杂抗原的鲁棒泛化能力。

**Result:** 在SAbDab数据库上的实验表明，与领先的抗体设计模型DiffAb相比，AbMEGD在关键CDR-H3区域的氨基酸恢复率提高了10.13%，改进百分比提升了3.32%，均方根偏差降低了0.062Å。

**Conclusion:** AbMEGD能够平衡结构完整性与改进的功能性，为序列-结构协同设计和亲和力优化建立了新基准。

> **ai_Abstract:** 本研究提出了AbMEGD，一个端到端的多尺度等变图扩散模型，用于解决复杂抗原结合中的抗体序列和结构协同设计挑战。该模型结合了原子级和残基级特征，并采用E(3)等变扩散方法，以确保几何精度和泛化能力。实验结果显示，AbMEGD在氨基酸恢复率、改进百分比和均方根偏差方面优于现有领先模型，为抗体设计和亲和力优化设立了新标准。

> **摘要翻译:** 抗体设计在治疗和诊断开发中仍是一个关键挑战，特别是对于具有多样结合界面的复杂抗原。当前的计算方法面临两大主要限制：(1) 在保留对称性的同时捕获几何特征，以及 (2) 泛化新型抗原界面。尽管最近取得了进展，但这些方法往往未能准确捕获分子相互作用并维持结构完整性。为了解决这些挑战，我们提出了AbMEGD，一个端到端框架，它集成了多尺度等变图扩散（Multi-scale Equivariant Graph Diffusion）用于抗体序列和结构协同设计。AbMEGD利用先进的几何深度学习技术，将原子级几何特征与残基级嵌入相结合，从而捕获局部原子细节和全局序列-结构相互作用。其E(3)等变扩散方法确保了几何精度、计算效率以及对复杂抗原的鲁棒泛化能力。此外，使用SAbDab数据库进行的实验表明，与领先的抗体设计模型DiffAb相比，AbMEGD在关键的CDR-H3区域氨基酸恢复率提高了10.13%，改进百分比提升了3.32%，均方根偏差降低了0.062Å。这些结果突出了AbMEGD在平衡结构完整性与改进功能性方面的能力，为序列-结构协同设计和亲和力优化建立了新基准。代码可在：https://github.com/Patrick221215/AbMEGD 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [309] [SharpZO: Hybrid Sharpness-Aware Vision Language Model Prompt Tuning via Forward-Only Passes](https://arxiv.org/abs/2506.20990)
> *SharpZO：通过仅前向传播实现的混合锐度感知视觉语言模型提示调优*

*Yifan Yang, Zhen Zhang, Rupak Vignesh Swaminathan, Jing Liu, Nathan Susanj, Zheng Zhang* | **Category: cs.LG, cs.CL, cs.CV**

**Keywords:** 视觉语言模型, 提示调优, 零阶优化, 锐度感知, 仅前向传播

**Comment:** 

> **TL;DR:** SharpZO是一种混合锐度感知零阶优化方法，通过两阶段前向传播过程，显著提高了视觉语言模型在内存受限设备上的调优性能和收敛速度。

**AI_Comments:** SharpZO通过结合锐度感知和两阶段优化策略，为内存受限设备上的VLM微调提供了一个创新的解决方案。其“仅前向传播”的特性使其在实际应用中具有重要价值，尤其是在边缘计算场景。论文在理论分析和实验验证方面都做得很好，结果令人信服。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型（VLM）微调方法需要通过反向传播获取模型梯度，这使得它们不适用于内存受限的边缘设备。虽然已有一些无反向传播的微调方法，但它们通常依赖于高方差的进化策略或零阶优化，并且性能不佳。

**Method:** 本文提出了一种混合锐度感知零阶优化（SharpZO）方法。该方法包含一个两阶段优化过程：首先是锐度感知的进化策略（ES）阶段，用于全局探索和平滑损失景观以构建强大的初始化；随后是稀疏零阶优化进行的细粒度局部搜索。整个优化过程仅依赖于前向传播。

**Result:** SharpZO在CLIP模型上的实验表明，它显著提高了准确性和收敛速度，比最先进的仅前向传播方法平均提高了高达7%的性能。

**Conclusion:** SharpZO通过其混合锐度感知零阶优化方法，有效解决了在内存受限设备上微调视觉语言模型的挑战，并在仅前向传播的设置下取得了显著的性能提升和更快的收敛速度。

> **ai_Abstract:** 本文提出了一种名为SharpZO的混合锐度感知零阶优化方法，旨在解决视觉语言模型在内存受限边缘设备上进行微调时需要反向传播的问题。SharpZO采用两阶段优化：首先通过锐度感知进化策略进行全局探索和初始化，然后通过稀疏零阶优化进行局部搜索。该方法仅需前向传播，并在CLIP模型上展示出显著的准确性提升和更快的收敛速度，平均性能优于现有仅前向传播方法达7%。

> **摘要翻译:** 视觉语言模型（VLM）的微调在各种下游任务中取得了卓越的性能；然而，它需要通过反向传播（BP）访问模型梯度，这使得它们不适用于内存受限、仅推理的边缘设备。为了解决这一限制，先前的工作探索了各种无BP的微调方法。然而，这些方法通常依赖于高方差的进化策略（ES）或零阶（ZO）优化，并且往往未能达到令人满意的性能。在本文中，我们提出了一种混合锐度感知零阶优化（SharpZO）方法，专门设计用于通过锐度感知热身训练来增强ZO VLM微调的性能。SharpZO具有两阶段优化过程：一个锐度感知ES阶段，用于全局探索和平滑损失景观以构建强大的初始化，随后通过稀疏ZO优化进行细粒度的局部搜索。整个优化过程仅依赖于前向传播。详细的理论分析和对CLIP模型的广泛实验表明，SharpZO显著提高了准确性和收敛速度，比最先进的仅前向传播方法平均提高了高达7%的增益。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [313] [Distilling Normalizing Flows](https://arxiv.org/abs/2506.21003)
> *蒸馏归一化流*

*Steven Walton, Valeriy Klyukin, Maksim Artemev, Denis Derkach, Nikita Orlov, Humphrey Shi* | **Category: cs.LG**

**Keywords:** 归一化流, 知识蒸馏, 生成模型, 密度估计, 模型压缩

**Comment:** Published in eLVM @ CVPR
  (https://openaccess.thecvf.com/content/CVPR2025W/eLVM/html/Walton_Distilling_Normalizing_Flows_CVPRW_2025_paper)

> **TL;DR:** 本文提出了一种新的知识蒸馏技术，用于提高小型归一化流模型的采样质量和密度估计，使其在显著缩小模型尺寸的同时获得显著的性能提升。

**AI_Comments:** 该研究的创新之处在于探索了归一化流中非传统的知识转移形式，即在中间层进行知识蒸馏。这对于模型压缩和提高生成模型效率具有重要意义，能够使得更小、更快的模型达到与大型模型相当的性能。

<details>
  <summary>Details</summary>

**Motivation:** 显式密度学习器（如归一化流）在生成模型中越来越受欢迎，因为它们能够更好地建模概率分布，并且相对于生成对抗网络具有密度估计和精确潜在变量推断的优势。然而，这些模型通常训练难度更大，采样质量较低。

**Method:** 本文提出了新颖的知识蒸馏技术，以提高小型学生归一化流的采样质量和密度估计。研究了组合归一化流中知识蒸馏的能力，并利用归一化流的独特属性，允许在中间层进行非传统的知识转移。

**Result:** 通过知识蒸馏，可以显著缩小学生模型的尺寸，同时相对于未经蒸馏的学生模型获得实质性的性能提升。更小的模型会带来成比例的吞吐量增加，因为这取决于网络中双射器（即参数）的数量。

**Conclusion:** 知识蒸馏可以显著提高小型归一化流模型的性能和效率。

> **ai_Abstract:** 本文针对显式密度学习器（尤其是归一化流）训练困难和采样质量较低的问题，提出了一种新颖的知识蒸馏技术。研究发现，利用归一化流独特的中间层知识转移特性，可以将知识从大型教师模型蒸馏到小型学生模型。实验结果表明，通过这种蒸馏方法，学生模型在尺寸显著减小的同时，在性能上取得了实质性提升，并带来了更高的吞吐量。

> **摘要翻译:** 显式密度学习器正成为生成模型中越来越流行的技术，因为它们能够更好地建模概率分布。由于它们能够执行密度估计并具有精确的潜在变量推断，因此它们比生成对抗网络具有优势。这有许多优点，包括：能够简单地进行插值、计算样本似然和分析概率分布。这些模型的缺点是它们通常更难训练且采样质量较低。
归一化流是显式密度模型，它们使用可组合的双射函数将难以处理的概率函数转换为可处理的概率函数。在这项工作中，我们提出了新颖的知识蒸馏技术，以提高小型学生归一化流的采样质量和密度估计。我们旨在研究组合归一化流中知识蒸馏的能力，以了解这些架构提供的优点和缺点。归一化流具有独特的属性，允许非传统的知识转移形式，我们可以在中间层转移该知识。我们发现，通过这种蒸馏，我们可以使学生模型显著缩小，同时比未经蒸馏的学生模型获得实质性的性能提升。随着模型变小，吞吐量成比例增加，因为这取决于网络中双射器（即参数）的数量。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [315] [Flow-Based Single-Step Completion for Efficient and Expressive Policy Learning](https://arxiv.org/abs/2506.21427)
> *基于流的单步完成，实现高效且富有表现力的策略学习*

*Prajwal Koirala, Cody Fleming* | **Category: cs.LG, cs.RO**

**Keywords:** 强化学习, 生成模型, 流匹配, 单步完成, 策略学习

**Comment:** 

> **TL;DR:** 提出SSCP，一种基于流匹配的生成策略，实现单步动作生成，结合生成模型的表达能力与单峰策略的效率，适用于多种RL设置。

**AI_Comments:** SSCP的创新之处在于通过改进流匹配目标，实现了生成式策略的单步动作生成，有效解决了传统生成模型在强化学习中面临的效率和稳定性挑战。这使其能够同时拥有生成模型的表达能力和单峰策略的效率，显著提升了实际应用价值。其在多种RL设置下的普适性和对目标条件RL的扩展也增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成模型（如扩散和流匹配）在离线强化学习中虽然能捕捉多模态动作分布，但其迭代采样导致高推理成本和训练不稳定（梯度传播）。

**Method:** 提出“单步完成策略”（SSCP），这是一种生成策略，通过增强的流匹配目标进行训练，以从中间流样本预测直接完成向量，从而实现准确的单次动作生成。SSCP在异策略演员-评论家框架中结合了生成模型的表达能力与单峰策略的训练和推理效率，无需长反向传播链。

**Result:** 该方法有效地扩展到离线RL、离线到在线RL和在线RL设置，与基于扩散的基线相比，在速度和适应性方面提供了显著提升。进一步扩展到目标条件RL，使扁平策略能够利用子目标结构。在标准离线RL和行为克隆基准上取得了良好结果。

**Conclusion:** SSCP被定位为一个多功能、富有表现力且高效的深度RL和序列决策框架。

> **ai_Abstract:** 本文提出了单步完成策略（SSCP），一种基于增强流匹配目标的生成式策略，用于解决离线强化学习中现有生成模型（如扩散模型）因迭代采样导致的高推理成本和训练不稳定问题。SSCP能够从中间流样本直接预测完成向量，实现高效的单次动作生成。该方法在异策略演员-评论家框架下，结合了生成模型的表达能力与单峰策略的效率，并在离线、离线到在线及在线RL设置中展现出优越的速度和适应性。SSCP还在目标条件RL和各项基准测试中表现出色，被认为是一个多功能、高效的深度RL框架。

> **摘要翻译:** 生成模型，如扩散模型和流匹配模型，通过捕捉丰富、多模态的动作分布，为离线强化学习（RL）提供了富有表现力的策略。然而，它们的迭代采样引入了高昂的推理成本和由于跨采样步骤的梯度传播导致的训练不稳定。我们提出了“单步完成策略”（SSCP），这是一种生成策略，通过增强的流匹配目标进行训练，以从中间流样本预测直接完成向量，从而实现准确的单次动作生成。在异策略演员-评论家框架中，SSCP将生成模型的表达能力与单峰策略的训练和推理效率相结合，而无需冗长的反向传播链。我们的方法能有效地扩展到离线RL、离线到在线RL和在线RL设置，与基于扩散的基线相比，在速度和适应性方面提供了显著提升。我们进一步将SSCP扩展到目标条件RL，使扁平策略能够利用子目标结构，而无需显式的分层推理。SSCP在标准离线RL和行为克隆基准上取得了良好结果，将其定位为深度RL和序列决策的通用、富有表现力且高效的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [316] [TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence](https://arxiv.org/abs/2506.21028)
> *TRIDENT：结合分类学注释和局部对应关系的三模态分子表示学习*

*Feng Jiang, Mangal Prakash, Hehuan Ma, Jianyuan Deng, Yuzhi Guo, Amina Mollaysa, Tommaso Mansi, Rui Liao, Junzhou Huang* | **Category: cs.LG**

**Keywords:** 分子表示学习, 多模态学习, 分子性质预测, 分类学注释, 局部对应

**Comment:** 

> **TL;DR:** TRIDENT是一个三模态分子表示学习框架，通过整合SMILES、文本和分类学注释，并利用全局和局部对齐目标，在分子性质预测任务上实现了最先进的性能。

**AI_Comments:** TRIDENT的创新之处在于其整合了之前被忽视的文本和分类学信息，并引入了基于体积的全局对齐和局部对齐目标，以实现更精细和全面的分子表示学习。其动量平衡机制也提升了模型的学习能力。这项工作的重要性在于为分子性质预测提供了一个更全面、更强大的多模态学习范式，有望推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态分子表示学习方法忽略了分子的文本和分类学信息，而分子性质预测需要学习将化学结构映射到功能性质的表示。

**Method:** TRIDENT是一个新颖的框架，它整合了分子SMILES、文本描述和分类学功能注释来学习分子表示。它通过策划一个包含结构化、多级功能注释的分子-文本对数据集来实现。该框架采用基于体积的对齐目标进行全局三模态特征对齐，并引入了捕获分子子结构与其对应子文本描述之间关系的局部对齐目标。一个基于动量的机制动态平衡全局和局部对齐。

**Result:** TRIDENT在11项下游任务上实现了最先进的性能。

**Conclusion:** 结合SMILES、文本和分类学功能注释对于分子性质预测具有重要价值。

> **ai_Abstract:** TRIDENT是一个用于分子表示学习的新型三模态框架，它创新性地整合了分子SMILES、文本描述和分类学功能注释。该框架通过构建一个包含多级功能注释的分子-文本数据集，并采用基于体积的全局对齐目标以及新颖的局部对齐目标来捕捉细粒度关系。一个动量机制用于平衡不同层次的对齐。TRIDENT在多项下游任务中取得了最先进的性能，强调了多模态信息融合在分子性质预测中的重要性。

> **摘要翻译:** 分子性质预测旨在学习将化学结构映射到功能性质的表示。尽管多模态学习已成为学习分子表示的强大范式，但现有工作在很大程度上忽视了分子的文本和分类学信息用于表示学习。我们引入了TRIDENT，一个新颖的框架，它整合了分子SMILES、文本描述和分类学功能注释来学习丰富的分子表示。为此，我们策划了一个包含结构化、多级功能注释的分子-文本对的综合数据集。TRIDENT没有依赖传统的对比损失，而是采用基于体积的对齐目标来联合对齐全局级别的三模态特征，从而实现跨模态的软性、几何感知对齐。此外，TRIDENT引入了一种新颖的局部对齐目标，捕获分子子结构与其对应子文本描述之间的详细关系。一个基于动量的机制动态平衡全局和局部对齐，使模型能够学习广泛的功能语义和细粒度的结构-功能映射。TRIDENT在11项下游任务上实现了最先进的性能，证明了结合SMILES、文本和分类学功能注释对于分子性质预测的价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [319] [Little By Little: Continual Learning via Self-Activated Sparse Mixture-of-Rank Adaptive Learning](https://arxiv.org/abs/2506.21035)
> *循序渐进：通过自激活稀疏秩自适应学习实现持续学习*

*Haodong Lu, Chongyang Zhao, Jason Xue, Lina Yao, Kristen Moore, Dong Gong* | **Category: cs.LG**

**Keywords:** 持续学习, 预训练模型, 秩自适应, 专家混合, 灾难性遗忘

**Comment:** Preprint

> **TL;DR:** MoRA提出了一种新的持续学习方法，通过将低秩更新分解为稀疏激活的秩1专家来解决大预训练模型中灾难性遗忘和任务干扰的问题，并在CLIP和LLM上表现出显著效果。

**AI_Comments:** 该论文的创新点在于提出了MoRA，通过将低秩更新分解为更细粒度的秩-1专家，并引入自激活和稀疏选择机制，有效解决了现有LoRA-based MoE在持续学习中面临的干扰、冗余和路由歧义问题。这种细粒度的专家管理方式，以及通过中间激活推断专家相关性的设计，具有较高的创新性。MoRA在保持预训练模型性能的同时，显著缓解了灾难性遗忘，对于大模型在不断变化的环境中进行持续学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LoRA的专家混合（MoE）方法在处理大型预训练模型的持续学习时，面临灾难性遗忘和任务干扰的问题。具体而言，这些方法存在三个关键挑战：1）干扰：对每个输入激活完整的LoRA专家会导致子空间干扰，并阻碍跨任务选择性重用有用组件。2）冗余：由于不必要地激活不相关的秩和不充分地重用相关的秩，新添加的专家经常重复或与现有知识冲突。3）歧义：任务之间的重叠特征会混淆路由器，导致专家分配不稳定，随着专家数量的增加，早期任务路由会退化，加速遗忘。

**Method:** 我们提出了MoRA，一种具有自激活和稀疏秩激活的秩自适应学习方法，用于持续学习。与混合多个低秩矩阵不同，MoRA将每个秩-r更新分解为r个秩-1组件，每个组件被视为独立的专家，从而实现秩-1专家的细粒度混合利用，同时减轻干扰和冗余。为了避免模糊路由，我们提出每个秩-1专家可以通过中间激活推断其自身的相关性。结合我们提出的秩剪枝和激活预算，MoRA为每个输入自适应地选择稀疏的秩混合。

**Result:** MoRA在CLIP和大型语言模型（LLMs）的持续学习任务上得到了验证，分析了微调过程中的域内学习和域外遗忘/泛化。MoRA在增强预训练模型的持续学习、提高泛化能力和减轻遗忘方面显示出显著的有效性。

**Conclusion:** MoRA是一种有效的持续学习方法，能够显著增强预训练模型的持续学习能力，提高泛化性能并有效减轻遗忘，从而克服了现有方法面临的干扰、冗余和歧义等挑战。

> **ai_Abstract:** 该论文提出MoRA（Mixture-of-Rank Adaptive learning），一种针对大型预训练模型持续学习的新方法，旨在解决现有LoRA-based MoE方法面临的灾难性遗忘、任务干扰、冗余和路由歧义问题。MoRA将每个低秩更新分解为独立的秩-1专家，通过自激活和稀疏秩选择机制，实现细粒度的专家利用，并结合秩剪枝和激活预算来避免模糊路由。实验证明，MoRA在CLIP和LLM的持续学习任务中，显著提升了持续学习效果，改善了泛化能力并有效减轻了遗忘。

> **摘要翻译:** 带有大型预训练模型（PTMs）的持续学习（CL）面临着灾难性遗忘和任务干扰的挑战。现有的基于LoRA的专家混合（MoE）方法通过分配和冻结特定任务的适配器来减轻遗忘，但由于粗粒度的适配器级别选择，它们遭受干扰、冗余和模糊路由的问题。然而，这种设计引入了三个关键挑战：1）干扰：每次输入激活完整的LoRA专家会导致子空间干扰，并阻止跨任务选择性重用有用组件。2）冗余：由于不必要地激活不相关的秩和不充分地重用相关的秩，新添加的专家经常重复或与现有知识冲突。3）歧义：任务之间重叠的特征会混淆路由器，导致专家分配不稳定。随着更多专家的积累，早期任务的路由会退化，加速遗忘。我们提出了MoRA，一种具有自激活和稀疏秩激活的秩自适应学习方法，用于持续学习。与混合多个低秩矩阵不同，MoRA将每个秩-r更新分解为r个秩-1组件，每个组件被视为独立的专家，从而实现秩-1专家的细粒度混合利用，同时减轻干扰和冗余。为了避免模糊路由，我们提出每个秩-1专家可以通过中间激活推断其自身的相关性。结合我们提出的秩剪枝和激活预算，MoRA为每个输入自适应地选择稀疏的秩混合。我们在CLIP和大型语言模型（LLMs）的持续学习任务上验证了MoRA，分析了微调过程中的域内学习和域外遗忘/泛化。MoRA在增强预训练模型的持续学习、提高泛化能力和减轻遗忘方面显示出显著的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [325] [RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment](https://arxiv.org/abs/2506.21037)
> *RL-Selector：基于冗余评估的强化学习引导数据选择*

*Suorong Yang, Peijia Li, Furao Shen, Jian Zhao* | **Category: cs.LG, cs.CV**

**Keywords:** 数据选择, 强化学习, 冗余评估, epsilon-sample cover, 深度学习

**Comment:** ICCV 2025

> **TL;DR:** RL-Selector利用强化学习和epsilon-sample cover进行数据选择，以减少训练冗余并提高效率，同时增强模型泛化能力。

**AI_Comments:** 该论文的创新点在于引入了epsilon-sample cover来量化样本冗余，并巧妙地将数据选择问题转化为一个强化学习任务。这种动态的数据选择策略能够适应训练过程中数据集分布的变化，克服了传统静态方法的局限性，对于在大规模数据集上实现高效且高性能的深度学习模型训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代深度架构依赖大规模数据集，导致高计算和存储开销。真实世界数据集通常包含大量冗余，需要更数据高效的训练范式。现有数据选择方法通常依赖静态评分指标或预训练模型，忽视了所选样本的组合效应及其在训练过程中的演变动态。

**Method:** 引入了epsilon-sample cover的概念，通过量化样本间的关系来评估样本冗余，捕获数据集的内在结构。在此基础上，将数据选择重新定义为强化学习（RL）过程，并提出了RL-Selector。其中，一个轻量级RL代理利用从演变数据集分布中获得的epsilon-sample cover作为奖励信号，来优化选择策略。

**Result:** 在基准数据集和不同架构上的大量实验表明，该方法始终优于现有的最先进基线。使用我们选择的数据集训练的模型显示出增强的泛化性能和更高的训练效率。

**Conclusion:** RL-Selector通过强化学习引导的数据选择，有效解决了大规模数据集训练中的冗余问题，提高了训练效率和模型泛化能力。

> **ai_Abstract:** RL-Selector是一种通过强化学习引导的数据选择方法，旨在解决大规模数据集训练中的冗余问题。该方法引入了epsilon-sample cover来量化样本冗余并捕捉数据集的内在结构，将数据选择建模为强化学习过程。一个轻量级RL代理利用epsilon-sample cover作为奖励信号来动态优化数据选择策略。实验结果表明，RL-Selector在提高训练效率和模型泛化性能方面优于现有最先进的方法。

> **摘要翻译:** 现代深度架构通常依赖于大规模数据集，但在此类数据集上进行训练会导致高昂的计算和存储开销。真实世界数据集通常包含大量冗余，这促使人们需要更数据高效的训练范式。数据选择已显示出通过识别最具代表性的样本来减轻冗余的潜力，从而在不损害性能的情况下降低训练成本。现有方法通常依赖静态评分指标或预训练模型，忽视了所选样本的组合效应及其在训练过程中的演变动态。我们引入了epsilon-sample cover的概念，它基于样本间关系量化样本冗余，捕捉数据集的内在结构。在此基础上，我们将数据选择重新表述为强化学习（RL）过程，并提出了RL-Selector，其中一个轻量级RL代理通过利用从演变数据集分布中获得的epsilon-sample cover作为奖励信号来优化选择策略。在基准数据集和不同架构上的大量实验表明，我们的方法始终优于现有最先进的基线。使用我们选择的数据集训练的模型显示出增强的泛化性能和更高的训练效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.21039)
> *严格子目标执行：分层强化学习中可靠的长周期规划*

*Jaebak Hwang, Sanghyeon Lee, Jeongmo Kim, Seungyul Han* | **Category: cs.LG, cs.AI**

**Keywords:** 分层强化学习, 子目标执行, 长周期规划, 图基方法, 稀疏奖励

**Comment:** 9 technical page followed by references and appendix

> **TL;DR:** 本文提出了严格子目标执行（SSE），一个基于图的分层强化学习框架，通过结构化约束高层决策来确保单步子目标可达性，并结合了解耦探索策略和故障感知路径优化，以解决长周期任务中的子目标不可行性和规划效率低下问题，实验证明其在效率和成功率上均优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了“严格子目标执行”的概念，通过结构化约束强制保证子目标的可达性，并结合了新颖的解耦探索策略和故障感知路径优化，有效提升了分层强化学习在长周期稀疏奖励任务中的性能和可靠性。这对于实际应用中需要稳定长周期规划的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 长周期目标条件任务对强化学习（RL）提出了根本性挑战，尤其是在目标距离遥远且奖励稀疏的情况下。现有的分层和基于图的方法虽然提供部分解决方案，但通常存在子目标不可行性和规划效率低下的问题。

**Method:** 本文引入了严格子目标执行（SSE），一个基于图的分层RL框架。SSE通过结构化约束高层决策来强制执行单步子目标可达性。为增强探索，SSE采用解耦探索策略，系统地遍历目标空间中探索不足的区域。此外，它还包含一个故障感知路径优化机制，通过根据观察到的低层成功率动态调整边缘成本来改进基于图的规划，从而提高子目标的可靠性。

**Result:** 在各种长周期基准测试中的实验结果表明，SSE在效率和成功率方面均持续优于现有的目标条件RL和分层RL方法。

**Conclusion:** 严格子目标执行（SSE）框架通过强制执行单步子目标可达性、采用解耦探索策略和故障感知路径优化，有效解决了长周期任务中子目标不可行性和规划效率低下的问题，显著提高了分层强化学习的性能。

> **ai_Abstract:** 本文提出了一种名为严格子目标执行（SSE）的基于图的分层强化学习框架，旨在解决长周期目标条件任务中子目标不可行性和规划效率低下的问题。SSE通过结构化约束确保单步子目标可达性，并结合了解耦探索策略以促进对未探索区域的遍历，以及故障感知路径优化机制以根据低层成功率动态调整规划。实验证明，SSE在效率和成功率方面均优于现有方法。

> **摘要翻译:** 长周期目标条件任务对强化学习（RL）提出了根本性挑战，尤其是在目标距离遥远且奖励稀疏的情况下。尽管分层和基于图的方法提供部分解决方案，但它们常常面临子目标不可行性和规划效率低下的问题。我们引入了严格子目标执行（SSE），一个基于图的分层RL框架，它通过结构化约束高层决策来强制执行单步子目标可达性。为了增强探索，SSE采用了一种解耦探索策略，系统地遍历目标空间中探索不足的区域。此外，故障感知路径优化通过根据观察到的低层成功率动态调整边缘成本来改进基于图的规划，从而提高了子目标的可靠性。在各种长周期基准测试中的实验结果表明，SSE在效率和成功率方面均持续优于现有的目标条件RL和分层RL方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [330] [Efficient Skill Discovery via Regret-Aware Optimization](https://arxiv.org/abs/2506.21044)
> *通过后悔感知优化实现高效技能发现*

*He Zhang, Ming Zhou, Shaopeng Zhai, Ying Sun, Hui Xiong* | **Category: cs.LG, cs.AI**

**Keywords:** 技能发现, 后悔感知, 极小极大博弈, 强化学习, 高效探索

**Comment:** 

> **TL;DR:** 本文提出了一种名为“后悔感知优化”的新型无监督技能发现方法，将技能发现框架化为技能生成和策略学习的极小极大博弈，以提高高维环境下的效率和多样性。

**AI_Comments:** 这篇论文通过将技能发现问题转化为一个极小极大博弈，并引入“后悔感知”机制来动态调整探索强度，为无监督技能发现提供了一个新颖且高效的视角。其创新点在于利用策略强度的收敛程度（通过后悔衡量）来指导技能生成，从而避免了无效探索并提高了效率，尤其在高维环境中的零样本改进显示了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有无监督技能发现方法在探索方面表现良好，但在效率上仍有限制，尤其是在高维情况下。

**Method:** 将技能发现框架化为技能生成和策略学习的极小极大博弈，并提出一种基于时间表征学习的后悔感知方法。该方法根据策略强度收敛程度（通过后悔衡量）调整探索方向，对强度较弱的技能进行更多探索。通过可学习的技能生成器指导技能发现，并利用可升级的技能生成器群体避免退化。

**Result:** 实验结果表明，该方法在效率和多样性方面均优于现有基线方法。在高维环境中，该方法比现有方法实现了15%的零样本改进。

**Conclusion:** 该研究提出了一种高效且多样化的无监督技能发现方法，通过后悔感知优化和极小极大博弈框架，显著提升了高维环境下的性能和探索效率。

> **ai_Abstract:** 本文提出了一种名为“后悔感知优化”的高效无监督技能发现方法，旨在解决现有方法在效率上的局限性，尤其是在高维环境中。该方法将技能发现建模为技能生成与策略学习的极小极大博弈，并利用后悔机制指导技能探索，优先发现强度较弱但有潜力的技能。实验证明，该方法在效率和多样性上均优于现有基线，并在高维环境中取得了显著的零样本性能提升。

> **摘要翻译:** 无监督技能发现旨在在开放式强化学习中学习多样且可区分的行为。现有方法侧重于通过纯粹探索、互信息优化和学习时间表征来提高多样性。尽管它们在探索方面表现良好，但在效率方面仍有限制，尤其是在高维情况下。在这项工作中，我们将技能发现框定为技能生成和策略学习的极小极大博弈，提出了一种基于时间表征学习的后悔感知方法，该方法沿着可升级策略强度的方向扩展发现的技能空间。该方法背后的关键见解是技能发现与策略学习是对抗性的，即对强度较弱的技能应进行更多探索，而对强度收敛的技能则进行较少探索。作为一种实现，我们用后悔来衡量强度收敛的程度，并用一个可学习的技能生成器来指导技能发现。为避免退化，技能生成来自一个可升级的技能生成器群体。我们在不同复杂度和维度大小的环境中进行了实验。经验结果表明，我们的方法在效率和多样性方面均优于基线。此外，与现有方法相比，我们的方法在高维环境中实现了15%的零样本改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [333] [FedDAA: Dynamic Client Clustering for Concept Drift Adaptation in Federated Learning](https://arxiv.org/abs/2506.21054)
> *FedDAA：联邦学习中概念漂移适应的动态客户端聚类*

*Fu Peng, Ming Tang* | **Category: cs.LG**

**Keywords:** 联邦学习, 概念漂移, 动态聚类, 数据异质性, 灾难性遗忘

**Comment:** 

> **TL;DR:** FedDAA通过动态客户端聚类和多源漂移检测，解决了联邦学习中由于概念漂移导致的历史知识遗忘问题，并显著提升了性能。

**AI_Comments:** FedDAA的创新点在于其能够区分联邦学习中不同类型的概念漂移（真实、虚拟、标签），并针对性地采取不同的适应策略，从而有效避免了灾难性遗忘，并更好地保留了历史知识。这种细致的漂移处理方式是现有方法所欠缺的，对于提升联邦学习在动态数据环境下的鲁棒性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在联邦学习中，客户端数据分布随时间变化导致概念漂移，引入时空数据异质性。现有方法主要关注真实漂移，忽视虚拟漂移和标签漂移，导致灾难性遗忘，且无法区分不同漂移源以采取恰当的适应策略。

**Method:** 提出FedDAA，一个动态聚类联邦学习框架，旨在适应多源概念漂移并保留历史知识。它包含三个模块：集群数量确定模块（寻找最优集群数）、真实漂移检测模块（区分真实漂移与虚拟/标签漂移）和概念漂移适应模块（适应新数据同时保留有用历史信息）。

**Result:** FedDAA在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上比现有最先进方法提高了7.84%到8.52%的准确率，并提供了理论收敛保证。

**Conclusion:** FedDAA通过有效区分和适应多源概念漂移，并在保留有用历史知识的同时，显著提升了联邦学习在数据漂移环境下的性能。

> **ai_Abstract:** 本文提出了FedDAA，一个针对联邦学习中多源概念漂移的动态聚类框架。它通过区分真实漂移、虚拟漂移和标签漂移，并采用不同的适应策略（丢弃或保留历史数据），有效解决了现有方法在处理非真实漂移时灾难性遗忘的问题。FedDAA包含集群数量确定、真实漂移检测和概念漂移适应三个模块，并在多个数据集上取得了显著的准确率提升。

> **摘要翻译:** 在联邦学习（FL）中，每个客户端的数据分布可能随时间变化，引入了时间和空间上的数据异质性，这被称为概念漂移。数据异质性源于三种漂移来源：真实漂移（条件分布P(y|x)的变化）、虚拟漂移（输入分布P(x)的变化）和标签漂移（标签分布P(y)的变化）。然而，大多数现有解决概念漂移的联邦学习方法主要关注真实漂移。当客户端经历虚拟漂移或标签漂移时，这些方法往往无法选择性地保留有用的历史知识，导致灾难性遗忘。一个关键挑战在于区分不同来源的漂移，因为它们需要不同的适应策略：真实漂移需要丢弃过时数据，而虚拟漂移或标签漂移则受益于保留历史数据。如果不明确识别漂移来源，通用的适应策略将是次优的，并可能损害泛化能力。为了解决这一挑战，我们提出了FedDAA，一个动态聚类联邦学习框架，旨在适应多源概念漂移，同时保留有价值的历史知识。具体而言，FedDAA集成了三个模块：一个集群数量确定模块来寻找最优集群数量；一个真实漂移检测模块来区分真实漂移与虚拟/标签漂移；以及一个概念漂移适应模块来适应新数据同时保留有用的历史信息。我们提供了理论收敛保证，实验表明FedDAA在Fashion-MNIST、CIFAR-10和CIFAR-100数据集上比现有最先进方法提高了7.84%到8.52%的准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [335] [Enhancing LLM Tool Use with High-quality Instruction Data from Knowledge Graph](https://arxiv.org/abs/2506.21071)
> *利用知识图谱的高质量指令数据增强大型语言模型工具使用能力*

*Jingwei Wang, Zai Zhang, Hao Qian, Chunjing Gan, Binbin Hu, Ziqi Liu, Zhiqiang Zhang, Jun Zhou, Bin Shi, Bo Dong* | **Category: cs.LG, cs.CL**

**Keywords:** 大型语言模型, 工具使用, 指令数据, 知识图谱, 微调

**Comment:** 20 pages, 12 figures

> **TL;DR:** 本文提出了一种利用知识图谱生成高质量指令数据的方法，以显著提升大型语言模型（LLMs）的工具使用能力。

**AI_Comments:** 该论文的创新点在于利用知识图谱这一高质量、人工整理的语义信息源来生成LLM的工具使用指令数据，而非依赖LLM自身生成，从而解决了传统方法数据质量不足的问题。其重要性在于为提升LLM的实际应用能力提供了一条有效途径，特别是在需要精确理解工具功能和用户意图的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 教导大型语言模型（LLMs）使用工具对于提升其解决问题的能力和扩展应用至关重要。然而，有效使用工具具有挑战性，因为它需要深入理解工具功能和用户意图。以往的方法主要依赖LLMs生成指令数据，但这些数据的质量往往不足。

**Method:** 本文提出了一种利用知识图谱生成高质量指令数据的新方法。首先，从知识图谱中提取各种查询路径，并将其转化为广泛的用户查询。然后，将实体之间的关系转化为可操作的工具，并将每个查询的路径解析为详细的解决方案步骤，从而创建高质量的指令数据。

**Result:** 实验表明，仅用一小部分这种合成数据进行微调，就能显著提高LLMs的工具利用率和整体能力。

**Conclusion:** 通过利用知识图谱生成高质量指令数据，可以有效提升大型语言模型的工具使用和整体能力。

> **ai_Abstract:** 本文提出了一种新颖的方法，通过利用知识图谱生成高质量的指令数据来增强大型语言模型（LLMs）的工具使用能力。该方法通过从知识图谱中提取查询路径并将其转化为用户查询，再将实体关系转化为工具，并将查询路径解析为详细的解决方案步骤，从而创建出高质量的训练数据。实验证明，即使使用少量这种合成数据进行微调，也能显著提升LLMs的工具利用率和整体性能。

> **摘要翻译:** 教导大型语言模型（LLMs）使用工具对于提升其解决问题的能力和扩展应用至关重要。然而，有效使用工具具有挑战性，因为它需要深入理解工具功能和用户意图。以往的方法主要依赖LLMs生成指令数据，但这些数据的质量往往不足。在本文中，我们提出了一种利用知识图谱生成高质量指令数据的新方法。知识图谱是人工整理的、富含语义信息的数据集。我们首先从给定的知识图谱中提取各种查询路径，这些路径被转化为广泛的用户查询。然后，我们将实体之间的关系转化为可操作的工具，并将每个查询的路径解析为详细的解决方案步骤，从而创建高质量的指令数据。我们的实验表明，仅用一小部分这种合成数据进行微调，就能显著提高LLMs的工具利用率和整体能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [339] [FeDa4Fair: Client-Level Federated Datasets for Fairness Evaluation](https://arxiv.org/abs/2506.21095)
> *FeDa4Fair：用于公平性评估的客户端级联邦数据集*

*Xenia Heilmann, Luca Corbucci, Mattia Cerrato, Anna Monreale* | **Category: cs.LG, cs.AI**

**Keywords:** 联邦学习, 公平性评估, 数据集, 客户端偏差, FeDa4Fair

**Comment:** 

> **TL;DR:** FeDa4Fair是一个库，用于生成表格数据集，以评估异构客户端偏差下的联邦学习公平性方法，并发布了四个偏置异构数据集和相应的基准。

**AI_Comments:** 该论文通过引入FeDa4Fair库和相关数据集，为联邦学习中的公平性研究提供了一个重要工具和基准。其创新之处在于关注客户端级别的异构偏差，这在现有研究中常被忽视。通过提供受控环境和即用型函数，该工作有助于提升联邦学习公平性研究的严谨性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中的公平性是一个关键问题，因为本地客户端数据集中的偏差会影响整个联邦系统。现有公平性增强解决方案大多只关注单一敏感属性的偏差缓解，忽略了不同客户端多样且有时冲突的公平性需求，这限制了干预措施的有效性。为了支持更稳健和可复现的联邦学习公平性研究，需要一致地基准测试全局和客户端级别的公平性感知联邦学习方法。

**Method:** 该论文通过以下三方面做出贡献：1) 引入FeDa4Fair库，用于生成表格数据集，以评估异构客户端偏差下的公平联邦学习方法；2) 发布了四个偏置异构数据集和相应的基准，用于在受控环境中比较公平性缓解方法；3) 提供了用于评估这些数据集公平性结果的即用型函数。

**Result:** 该研究发布了四个偏置异构数据集和相应的基准，以在受控环境中比较公平性缓解方法，并提供了用于评估公平性结果的即用型函数。

**Conclusion:** 该论文通过提供FeDa4Fair库、偏置异构数据集和评估函数，旨在支持联邦学习中更稳健和可复现的公平性研究，并实现公平性感知联邦学习方法在全球和客户端级别的一致基准测试。

> **ai_Abstract:** 该论文提出了FeDa4Fair，一个用于评估联邦学习（FL）中公平性的库，旨在解决现有公平性研究未能充分考虑客户端间异构偏差的问题。FeDa4Fair通过生成专门的表格数据集来模拟异构客户端偏差，并发布了四个偏置异构数据集及其基准，以支持在受控环境中对公平性缓解方法进行鲁棒且可复现的评估。此外，该工作还提供了用于评估这些数据集公平性结果的即用型函数。

> **摘要翻译:** 联邦学习（FL）能够在不共享客户端私有数据的情况下，实现多个客户端之间的协作模型训练。然而，公平性仍然是一个关键问题，因为本地客户端数据集中的偏差可能会影响整个联邦系统。客户端之间异构的数据分布可能导致模型对某些客户端比对其他客户端更公平。尽管文献中存在几种增强公平性的解决方案，但大多数都集中于缓解单一敏感属性（通常是二元）的偏差，而忽略了不同客户端多样化且有时相互冲突的公平性需求。这种有限的视角可能会限制公平性干预措施对不同客户端的有效性。为了支持联邦学习中更稳健和可重现的公平性研究，我们的目标是在全局和客户端级别实现对公平性感知FL方法的一致基准测试。在本文中，我们以三种方式做出贡献：(1) 我们引入了FeDa4Fair，一个用于生成表格数据集的库，专门用于评估异构客户端偏差下的公平FL方法；(2) 我们发布了四个偏置异构数据集和相应的基准，用于在受控环境中比较公平性缓解方法；(3) 我们提供了用于评估这些数据集公平性结果的即用型函数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [341] [Interpretable Hierarchical Concept Reasoning through Attention-Guided Graph Learning](https://arxiv.org/abs/2506.21102)
> *通过注意力引导图学习的可解释分层概念推理*

*David Debot, Pietro Barbiero, Gabriele Dominici, Giuseppe Marra* | **Category: cs.LG, cs.AI**

**Keywords:** 概念基础模型, 可解释性, 分层推理, 注意力机制, 图学习

**Comment:** 

> **TL;DR:** 本文提出H-CMR，一种新的概念基础模型，通过学习有向无环图和注意力机制，为概念和任务预测提供可解释性，并达到SOTA性能，支持人机交互。

**AI_Comments:** H-CMR的创新点在于将可解释性扩展到概念预测层面，而非仅限于最终任务预测。通过引入注意力引导的图学习来建模概念间的层次关系，它提供了一种透明的推理路径。其支持人机交互的特性，尤其是在推理时通过概念干预提升准确性和训练时通过模型干预提升数据效率的潜力，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有概念基础模型（CBMs）仅对最终任务预测提供可解释性，而概念本身的预测通常由黑盒神经网络完成，缺乏透明度。

**Method:** 本文提出分层概念记忆推理器（H-CMR），这是一种新的CBM。H-CMR通过学习一个有向无环图来建模概念之间的关系，其中边表示定义概念的逻辑规则。在推理过程中，H-CMR利用神经网络注意力机制选择这些规则的一个子集，然后分层应用这些规则来预测所有概念和最终任务。

**Result:** 实验结果表明，H-CMR在性能上与最先进的模型相当。它还通过概念和模型干预实现了强大的人机交互，前者可以显著提高推理时的准确性，后者可以在背景知识可用时提高训练期间的数据效率。

**Conclusion:** H-CMR通过提供对概念和任务预测的可解释性，并保持高性能，解决了现有CBMs的局限性，同时通过人机交互增强了模型的实用性和效率。

> **ai_Abstract:** 本文提出H-CMR，一种新型概念基础模型，旨在解决现有CBMs在概念预测层面缺乏可解释性的问题。H-CMR通过学习一个有向无环图来表示概念间的逻辑关系，并利用注意力机制选择相关规则进行分层推理，从而同时为概念和最终任务预测提供可解释性。实验证明H-CMR性能与SOTA相当，并能通过人机交互（概念/模型干预）提升推理准确性和训练数据效率。

> **摘要翻译:** 概念基础模型（CBMs）是一类深度学习模型，通过高级概念解释预测来提供可解释性。这些模型首先预测概念，然后利用它们执行下游任务。然而，当前的CBMs仅为最终任务预测提供可解释性，而概念预测本身通常通过黑盒神经网络进行。为了解决这一局限性，我们提出了分层概念记忆推理器（H-CMR），这是一种新的CBM，它为概念和任务预测都提供了可解释性。H-CMR使用学习到的有向无环图来建模概念之间的关系，其中边表示定义其他概念的逻辑规则。在推理过程中，H-CMR采用神经注意力机制来选择这些规则的一个子集，然后分层应用这些规则来预测所有概念和最终任务。实验结果表明，H-CMR的性能与最先进的技术相匹配，同时通过概念和模型干预实现了强大的人机交互。前者可以在推理时显著提高准确性，而后者可以在背景知识可用时提高训练期间的数据效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [343] [Learning to Skip the Middle Layers of Transformers](https://arxiv.org/abs/2506.21103)
> *学习跳过Transformer的中间层*

*Tim Lawson, Laurence Aitchison* | **Category: cs.LG, cs.CL**

**Keywords:** Transformer, 条件计算, 层跳过, 模型效率, 门控机制

**Comment:** 11 pages, 2 figures

> **TL;DR:** 提出一种动态跳过Transformer中间层的新架构，但实验结果显示与基线模型相比，计算效率和性能权衡没有提升。

**AI_Comments:** 该论文提出了一种创新的、基于可解释性研究的Transformer层跳过策略，即从中间向外跳层，这与以往独立跳层或针对特定模块的方法不同。然而，其主要局限在于实验结果未能证明在计算效率和性能上优于现有基线，这可能限制了其在实际应用中的直接价值，但也为未来研究提供了宝贵的负面结果和设计方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有条件计算方法效率不高，且可解释性研究表明Transformer中间层冗余度更高，早期层聚合信息。因此，目标是减少“简单”token的计算需求并可能促进多级表示层次。

**Method:** 提出一种新颖的架构，动态地从中间向外跳过可变数量的层。一个学习到的门控机制根据输入决定是否绕过对称的中心块，一个门控注意力机制阻止后续token关注跳过的token位置。残差范数通过“三明治”或“perilayernorm”方案控制，门控稀疏性通过自适应正则化损失控制。

**Result:** 在所研究的规模下，与层数较少的密集基线模型相比，该方法在验证交叉熵和估计FLOPs之间的权衡方面没有实现改进。

**Conclusion:** 尽管提出了新颖的跳层策略，但在当前实验规模下，该方法未能提升Transformer的计算效率与性能的权衡。

> **ai_Abstract:** 这篇论文提出了一种新的Transformer架构，旨在通过动态跳过其中间层来提高计算效率。受中间层冗余和早期层信息聚合的启发，该方法利用学习到的门控机制决定跳过中心块，并使用门控注意力防止对跳过位置的关注。尽管目标是减少计算和促进层次化表示，但实验结果表明，在所测试的规模下，该方法并未在计算量和模型性能之间实现比密集基线模型更好的权衡。

> **摘要翻译:** 条件计算是提高Transformer效率的流行策略。现有方法通常针对单个模块（例如，专家混合层）或独立地跳过层。然而，可解释性研究表明Transformer的中间层表现出更大的冗余性，并且早期层将信息聚合到token位置。受这些见解的启发，我们提出了一种新颖的架构，该架构动态地从中间向外跳过可变数量的层。特别是，一个学习到的门控机制根据输入决定是否绕过对称的中心块，一个门控注意力机制阻止后续token关注跳过的token位置。残差范数通过“三明治”或“perilayernorm”方案控制，门控稀疏性通过自适应正则化损失控制。我们旨在减少“简单”token的计算需求并可能促进新兴的多级表示层次结构，但在所研究的规模下，与层数较少的密集基线模型相比，我们的方法在验证交叉熵和估计FLOPs之间的权衡方面没有实现改进。我们已在https://github.com/tim-lawson/skip-middle 发布了代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [345] [Unlasting: Unpaired Single-Cell Multi-Perturbation Estimation by Dual Conditional Diffusion Implicit Bridges](https://arxiv.org/abs/2506.21107)
> *Unlasting: 基于双条件扩散隐式桥接的无配对单细胞多扰动估计*

*Changxi Chi, Jun Xia, Yufei Huang, Jingbo Zhou, Siyuan Li, Yunfan Liu, Chang Yu, Stan Z. Li* | **Category: cs.LG, q-bio.MN**

**Keywords:** 单细胞, 扰动, 扩散模型, 无配对数据, 基因调控网络

**Comment:** 

> **TL;DR:** Unlasting提出了一种基于双条件扩散隐式桥接的模型，用于解决无配对单细胞多扰动数据的估计问题，并通过整合基因调控网络和掩码机制来提高生成质量，并引入新的评估指标。

**AI_Comments:** Unlasting的创新之处在于其利用双条件扩散隐式桥接（DDIB）来处理单细胞扰动数据中普遍存在的无配对问题，这在生物学数据分析中是一个重大挑战。通过整合基因调控网络（GRN）信息，该模型能够以生物学上更合理的方式理解和传播扰动信号，增强了模型的生物学解释性。引入掩码机制预测沉默基因以及针对异质性设计新的评估指标，都体现了对单细胞数据复杂性的深入理解和细致处理。这项工作有望显著提升单细胞扰动分析的准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 估计单细胞对各种扰动的反应对于识别关键基因和增强药物筛选至关重要，能显著提高实验效率。然而，单细胞测序是破坏性的，无法捕获同一细胞扰动前后的表型，导致数据固有的无配对性。现有方法要么强制配对，要么忽略细胞间的固有关系。

**Method:** 本文提出了Unlasting框架，基于双扩散隐式桥接（DDIB）来学习不同数据分布之间的映射，有效处理无配对数据。该框架被解释为一种数据增强形式。它整合了基因调控网络（GRN）信息以生物学上有意义的方式传播扰动信号，并结合掩码机制预测沉默基因以提高生成质量。此外，引入了一个更合适的评估指标来捕获细胞间在相同扰动下基因表达的固有异质性（双峰分布）。

**Result:** Not mentioned in abstract

**Conclusion:** Unlasting是一种双条件扩散模型，它克服了无配对单细胞扰动数据的问题，并在基因调控网络的指导下增强了模型对扰动的洞察力，通过专门设计的掩码模型预测沉默基因以提高生成质量。此外，它引入了一个生物学基础的评估指标，能更好地反映单细胞反应中固有的异质性。

> **ai_Abstract:** Unlasting是一种创新的双条件扩散模型，旨在解决单细胞多扰动数据固有的无配对问题。通过利用双扩散隐式桥接（DDIB），该模型能够学习不同数据分布之间的映射，并将其视为一种数据增强策略。为了提高估计的生物学相关性和生成质量，Unlasting整合了基因调控网络（GRN）信息以传播扰动信号，并引入了掩码机制来预测沉默基因。此外，为了准确捕捉单细胞反应的内在异质性，该研究还提出了一种新的、更合适的评估指标。

> **摘要翻译:** 估计单细胞对各种扰动的反应有助于识别关键基因并增强药物筛选，显著提高实验效率。然而，单细胞测序是一个破坏性的过程，使得捕获同一细胞扰动前后的表型成为不可能。因此，在扰动和未扰动条件下收集的数据是固有的无配对的。现有方法要么尝试使用随机采样强制配对无配对数据，要么在建模过程中忽略未扰动和扰动细胞之间的固有关系。在这项工作中，我们提出了一个基于双扩散隐式桥接（DDIB）的框架来学习不同数据分布之间的映射，有效地解决了无配对数据的挑战。我们进一步将此框架解释为一种数据增强形式。我们整合了基因调控网络（GRN）信息，以生物学上有意义的方式传播扰动信号，并进一步结合掩码机制来预测沉默基因，提高生成谱的质量。此外，相同扰动下的基因表达在不同细胞之间通常差异显著，经常表现出反映内在异质性的双峰分布。为了捕捉这一点，我们引入了一个更合适的评估指标。我们提出了Unlasting，一种双条件扩散模型，它克服了无配对单细胞扰动数据的问题，并在GRN的指导下加强了模型对扰动的洞察力，其专门设计的掩码模型旨在通过预测沉默基因来提高生成质量。此外，我们引入了一个具有生物学基础的评估指标，可以更好地反映单细胞反应中固有的异质性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [347] [Robust Policy Switching for Antifragile Reinforcement Learning for UAV Deconfliction in Adversarial Environments](https://arxiv.org/abs/2506.21127)
> *对抗环境下无人机冲突避免的鲁棒策略切换抗脆弱强化学习*

*Deepak Kumar Panda, Weisi Guo* | **Category: cs.LG, cs.AI**

**Keywords:** 抗脆弱强化学习, 策略切换, 无人机冲突避免, 对抗环境, 折扣汤普森采样

**Comment:** 

> **TL;DR:** 本文提出了一种基于折扣汤普森采样（DTS）的抗脆弱强化学习框架，通过动态切换多个鲁棒策略来应对无人机在对抗环境中面临的广义分布偏移和未见过的攻击，显著提高了导航性能。

**AI_Comments:** 该论文的创新点在于将抗脆弱性概念引入强化学习，并利用折扣汤普森采样实现策略的动态切换，以应对非固定和不断演变的对抗性攻击。这种方法超越了传统鲁棒RL仅处理固定扰动的局限性，在无人机等关键应用领域具有重要意义。通过将策略选择建模为MAB问题，并提供理论保障，提升了方法的严谨性。其在复杂环境下的优越性能也验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的鲁棒强化学习方法在处理固定扰动方面有效，但对于来自最优价值分布的分布外偏移，其泛化能力有限，无法有效应对由传感器操纵引起的对抗性攻击对无人机导航自动化造成的漏洞。

**Method:** 本文引入了一个抗脆弱强化学习框架，通过结合基于折扣汤普森采样（DTS）的切换机制来增强对更广泛分布偏移的适应性。该机制动态地从多个鲁棒策略中选择，以最小化对抗引起的S-A-V分布偏移。首先，通过考虑策略空间中的一系列扰动，推导出一组多样化的动作鲁棒策略。然后，将这些策略建模为多臂赌博机（MAB）问题，其中DTS根据非平稳伯努利奖励进行最优策略选择，从而有效地适应不断演变的对抗策略。还提供了理论框架，通过优化DTS来最小化由于分布偏移引起的总遗憾，从而实现对未见过的对抗攻击的有效适应。

**Result:** 广泛的数值模拟验证了所提出的框架在具有多个动态三维障碍物和更强的PGD及欺骗攻击的复杂导航环境中的有效性。与传统的鲁棒、非自适应强化学习方法相比，该抗脆弱方法表现出卓越的性能，具有更短的导航路径长度和更高的无冲突导航轨迹率。

**Conclusion:** 本文提出的抗脆弱强化学习框架通过策略切换机制，能够有效应对无人机在对抗环境中面临的广义分布偏移和未见过的攻击，显著提高了其鲁棒性和导航性能。

> **ai_Abstract:** 本文针对无人机在对抗环境中因传感器操纵导致的强化学习漏洞，提出了一种抗脆弱强化学习框架。该框架引入基于折扣汤普森采样（DTS）的策略切换机制，动态选择多组鲁棒策略，以应对广义的分布偏移和未见过的对抗攻击。通过将策略选择建模为多臂赌博机问题并优化DTS，该方法显著提升了无人机在复杂导航环境中的鲁棒性和冲突避免能力，表现出比现有鲁棒RL方法更优的性能。

> **摘要翻译:** 无人机（UAV）导航自动化程度的提高使其面临对抗性攻击，这些攻击通过传感器操纵利用强化学习（RL）中的漏洞。尽管现有的鲁棒RL方法旨在减轻此类威胁，但它们的有效性在泛化到来自最优价值分布的分布外偏移时受到限制，因为它们主要设计用于处理固定扰动。为了解决这一限制，本文引入了一个抗脆弱RL框架，通过结合基于折扣汤普森采样（DTS）的切换机制，增强了对更广泛分布偏移的适应性。该机制动态地在多个鲁棒策略中选择，以最小化对抗性引起的S-A-V（状态-动作-价值）分布偏移。所提出的方法首先通过考虑策略空间中的一系列扰动，推导出一组多样化的动作鲁棒策略。然后，将这些策略建模为多臂赌博机（MAB）问题，其中DTS根据非平稳伯努利奖励进行最优策略选择，从而有效地适应不断演变的对抗策略。还提供了理论框架，通过优化DTS以最小化由于分布偏移引起的总遗憾，从而实现对未见过的对抗攻击的有效适应，进而引入抗脆弱性。广泛的数值模拟验证了所提出的框架在具有多个动态三维障碍物和更强的PGD（投影梯度下降）和欺骗攻击的复杂导航环境中的有效性。与传统的鲁棒、非自适应RL方法相比，该抗脆弱方法实现了卓越的性能，与现有鲁棒RL技术相比，展示了更短的导航路径长度和更高的无冲突导航轨迹率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [348] [Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks](https://arxiv.org/abs/2506.21129)
> *课程引导的反脆弱强化学习，用于观测空间攻击下无人机安全避碰*

*Deepak Kumar Panda, Adolfo Perrusquia, Weisi Guo* | **Category: cs.LG, cs.AI**

**Keywords:** 反脆弱强化学习, 无人机避碰, 对抗性攻击, 观测空间, 课程学习

**Comment:** 

> **TL;DR:** 本文提出了一种反脆弱强化学习框架，通过模拟攻击者逐步增加扰动，使RL智能体能够适应观测空间攻击，从而在安全关键系统中实现更安全、更有弹性的决策。

**AI_Comments:** 该论文的创新点在于提出了“反脆弱强化学习”的概念，旨在使RL策略不仅能抵抗攻击，还能在面对递增的对抗性扰动时变得更强。通过引入模拟攻击者和理论上对脆弱性与反脆弱性的定义，并结合Wasserstein距离最小化进行评论家对齐，提供了一种新颖且有效的方法来提升RL在安全关键系统中的鲁棒性和弹性。尤其是在无人机避碰场景中的出色表现，凸显了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）策略在安全关键系统（如无人机导航）中容易受到观测空间中的分布外（OOD）对抗性攻击。这些攻击会导致分布偏移，显著降低价值估计，从而导致不安全或次优的决策，使现有策略变得脆弱。

**Method:** 提出了一种反脆弱强化学习框架，旨在适应递增的对抗性扰动课程。该框架引入了一个模拟攻击者，逐步增加观测空间扰动的强度，使RL智能体能够适应并泛化到更广泛的OOD观测，并预测以前未见的攻击。理论上，将脆弱性定义为随着扰动强度增加，价值函数分布的单调发散（灾难性遗忘），并将反脆弱性定义为这种价值偏移的有界性，并推导出稳定遗忘的适应条件。通过使用Wasserstein距离最小化，在逐步扰动的观测上进行迭代的专家引导评论家对齐来强制执行这些界限。该方法在涉及动态3D障碍的无人机避碰场景中进行了实证评估。

**Result:** 反脆弱策略在经受投影梯度下降（PGD）和GPS欺骗攻击时，始终优于标准和鲁棒RL基线，实现了高达15%的累积奖励提升和超过30%的冲突事件减少。

**Conclusion:** 这些发现证明了反脆弱强化学习在具有不断演变威胁场景的环境中实现安全和弹性决策的实践和理论可行性。

> **ai_Abstract:** 本文提出了一种课程引导的反脆弱强化学习框架，以解决安全关键系统中强化学习策略对观测空间对抗性攻击的脆弱性。该框架引入一个模拟攻击者，逐步增加扰动强度，使RL智能体能够适应并泛化到新的攻击。研究者对脆弱性进行了理论表征，将其定义为价值函数分布的灾难性遗忘，并定义了反脆弱性为价值偏移的有界性。该方法通过迭代专家引导的评论家对齐，利用Wasserstein距离最小化来强制执行这些界限。在无人机避碰场景中的实验结果表明，该反脆弱策略在面对PGD和GPS欺骗攻击时，显著优于现有基线，实现了更高的累积奖励和更少的冲突事件，从而证明了其在安全弹性决策中的实用性和理论可行性。

> **摘要翻译:** 强化学习（RL）策略部署在安全关键系统，如动态空域中的无人机（UAV）导航，容易受到观测空间中的分布外（OOD）对抗性攻击。这些攻击会导致分布偏移，显著降低价值估计，从而导致不安全或次优的决策，使现有策略变得脆弱。为了解决这种脆弱性，我们提出了一种反脆弱RL框架，旨在适应递增的对抗性扰动课程。该框架引入了一个模拟攻击者，逐步增加观测空间扰动的强度，这使得RL智能体能够适应并泛化到更广泛的OOD观测，并预测以前未见的攻击。我们首先对脆弱性进行了理论表征，正式将灾难性遗忘定义为随着扰动强度增加，价值函数分布的单调发散。在此基础上，我们将反脆弱性定义为这种价值偏移的有界性，并推导出稳定遗忘的适应条件。我们的方法通过使用Wasserstein距离最小化，在逐步扰动的观测上进行迭代的专家引导评论家对齐来强制执行这些界限。我们在涉及动态3D障碍的无人机避碰场景中对该方法进行了实证评估。结果表明，在经受投影梯度下降（PGD）和GPS欺骗攻击时，反脆弱策略始终优于标准和鲁棒RL基线，实现了高达15%的累积奖励提升和超过30%的冲突事件减少。这些发现证明了反脆弱强化学习在具有不断演变威胁场景的环境中实现安全和弹性决策的实践和理论可行性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [350] [NaLaFormer: Norm-Aware Linear Attention for Transformer Models](https://arxiv.org/abs/2506.21137)
> *NaLaFormer：面向Transformer模型的范数感知线性注意力*

*Weikang Meng, Yadan Luo, Liangyu Huo, Yaowei Wang, Xin Li, Zheng Zhang* | **Category: cs.LG**

**Keywords:** 线性注意力, Transformer, 范数感知, 熵减, NaLaFormer

**Comment:** 

> **TL;DR:** 现有的线性注意力机制忽略了查询范数，导致熵间隙和内积交互缺失。NaLaFormer提出了一种范数感知线性注意力机制，通过解耦查询和键矩阵、引入范数感知核函数和范数保留映射来解决这些问题，从而在视觉和语言任务上提高了性能和效率。

**AI_Comments:** NaLaFormer的创新点在于其对线性注意力中范数问题的深入洞察和解决方案。通过解耦、范数感知核函数和范数保留映射，它不仅解决了现有方法的局限性，还提升了模型的表达能力和效率，为Transformer模型的优化提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的线性注意力机制通过L1范数归一化忽略了查询范数，导致熵间隙。同时，现有方法抑制了查询和键向量的负值，导致映射后内积交互缺失。本文旨在恢复范数引导的动态尖峰性和恢复核扰动的范数分布。

**Method:** 我们提出了一种范数感知线性注意力（NaLaFormer）机制。具体地，首先将查询和键矩阵解耦为范数和方向两个分量，分别实现范数感知的尖峰性控制和范数一致性。其次，引入了一种查询范数感知的核函数，以动态控制熵减。此外，采用范数保留映射将角度矩阵的所有元素投影为正值，并利用余弦相似度抑制方向相反的维度，以确保范数一致性并强制执行非负性约束。

**Result:** NaLaFormer在视觉和语言任务上提高了性能，表达能力和效率均提升高达4.2%。

**Conclusion:** NaLaFormer通过解决线性注意力中查询范数被忽略和负值抑制的问题，有效提升了Transformer模型在视觉和语言任务上的性能和效率。

> **ai_Abstract:** 本文提出了一种名为NaLaFormer的范数感知线性注意力机制，旨在解决现有线性注意力中查询范数被忽略导致的熵间隙以及负值抑制导致的内积交互缺失问题。NaLaFormer通过将查询和键矩阵解耦为范数和方向分量，引入查询范数感知的核函数以动态控制熵减，并采用范数保留映射确保范数一致性和非负性。实验证明，NaLaFormer在视觉和语言任务上提高了性能、表达能力和效率，提升高达4.2%。

> **摘要翻译:** 线性注意力已成为softmax注意力的可行替代方案，将复杂度从序列长度的二次方降低到线性。为了保持softmax的两个基本特性：非负性和熵减，当前工作采用各种线性可分离核函数和L1范数归一化而非softmax操作。然而，线性注意力中的归一化操作忽略了查询范数，这种退化严重导致了熵间隙。同时，现有工作抑制了查询和键向量的负值，导致映射后缺少内积交互。为了解决这些双重挑战，我们提出了一种新颖的范数感知线性注意力机制，旨在恢复范数引导的动态尖峰性并恢复核扰动的范数分布。具体地，我们首先将查询和键矩阵解耦为范数和方向两个分量，分别实现范数感知的尖峰性控制和范数一致性。我们从数学上揭示了熵减的程度随softmax归一化中查询范数的变化而变化，这促使我们设计了一个查询范数感知的核函数，用于动态控制熵减。此外，为了确保范数一致性并强制执行非负性约束，我们采用范数保留映射将角度矩阵的所有元素投影为正值，利用余弦相似度抑制方向相反的维度。我们进行了广泛的实验，证明NaLaFormer在视觉和语言任务上提高了性能，表达能力和效率均提升高达4.2%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [352] [Complexity-aware fine-tuning](https://arxiv.org/abs/2506.21220)
> *复杂度感知微调*

*Andrey Goncharov, Daniil Vyazhev, Petr Sychev, Edvard Khalafyan, Alexey Zaytsev* | **Category: cs.LG, cs.CL**

**Keywords:** LLM微调, 复杂度感知, 熵, 数据效率, 知识蒸馏

**Comment:** 

> **TL;DR:** 提出一种新的高效微调LLM的方法，通过熵识别复杂数据，并仅对复杂数据进行推理，从而在显著减少数据量的情况下达到与蒸馏相当的性能，并优于标准SFT。

**AI_Comments:** 该论文的创新点在于引入了“复杂度感知”的概念，通过熵来智能地选择性应用推理，从而显著提高了LLM微调的效率。这对于资源受限或需要快速部署LLM的场景具有重要意义，因为它在保持性能的同时大幅减少了数据和计算开销。

<details>
  <summary>Details</summary>

**Motivation:** 通用大型语言模型（LLMs）通过监督微调（SFT）来提高特定领域性能，但通过蒸馏大型模型的思维链虽然能获得更好结果，却需要大量的昂贵调用和更多的数据，效率低下。

**Method:** 本文提出了一种高效微调的新蓝图，该蓝图仅对通过熵识别的复杂数据使用推理。具体方法是在两个小型开源模型（约3B）上，通过单令牌答案熵（ROC AUC 0.73）将训练数据分为复杂性类别，并通过SFT和蒸馏对LLMs进行微调。

**Result:** 我们的方法显著优于标准SFT方法（平均准确率0.55 对 0.43），并且在数据量减少62%的情况下，提供了与蒸馏相当的性能（两者平均准确率均为0.55）。

**Conclusion:** 该研究提出了一种高效的LLM微调方法，通过选择性地对复杂数据进行处理，实现了与数据密集型蒸馏方法相当的性能，同时显著降低了数据需求，并优于标准SFT。

> **ai_Abstract:** 本文提出了一种新颖的“复杂度感知微调”方法，旨在提高大型语言模型（LLMs）的微调效率。该方法通过熵值识别训练数据中的复杂样本，并仅对这些复杂数据应用推理，从而避免了传统蒸馏方法所需的大量计算和数据。实验结果表明，该方法在显著减少62%数据量的情况下，其性能优于标准监督微调（SFT），并能达到与完整蒸馏方法相当的准确率。

> **摘要翻译:** 通用大型语言模型（LLMs）经常通过监督微调（SFT）进行微调，以提高在特定领域的性能。通过蒸馏更大模型的思维链可以获得更好的结果，但代价是大量的昂贵调用和更多的数据。我们提出了一种高效微调的新颖蓝图，该蓝图仅对通过熵识别的复杂数据使用推理。具体来说，在两个小型开源模型（约3B）上，我们通过单令牌答案熵（ROC AUC 0.73）将训练数据分为复杂性类别，通过SFT和蒸馏对大型语言模型（LLMs）进行微调，并表明我们的管道显著优于标准SFT方法（平均准确率0.55对0.43），并且在数据量减少62%的情况下，提供了与蒸馏相当的性能（两者平均准确率均为0.55）。我们发布了代码和数据，以促进该方向的进一步研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [353] [DBConformer: Dual-Branch Convolutional Transformer for EEG Decoding](https://arxiv.org/abs/2506.21140)
> *DBConformer：用于脑电图解码的双分支卷积Transformer*

*Ziwei Wang, Hongbin Wang, Tianwang Jia, Xingyi He, Siyang Li, Dongrui Wu* | **Category: cs.LG, cs.AI**

**Keywords:** 脑电图解码, 卷积Transformer, 双分支网络, 时间依赖性, 空间交互

**Comment:** 12 pages, 6 figures

> **TL;DR:** DBConformer是一种双分支卷积Transformer网络，用于脑电图解码，通过集成时间Conformer和空间Conformer来捕获长程时间依赖性和通道间交互，并在多个数据集上表现出优越的性能和可解释性。

**AI_Comments:** DBConformer的创新点在于其双分支结构，能够并行处理时间依赖性和空间交互，并结合轻量级通道注意力，有效解决了传统CNN和串行Conformer在EEG解码中遇到的挑战。其在保持高性能的同时显著减少参数量，并提供可解释的特征，这对于脑机接口的应用至关重要，提高了模型的实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的卷积神经网络（CNNs）在脑电图（EEG）解码中难以捕获长程时间依赖性和全局通道间关系，因为其感受野较短。而目前的CNN-Transformer混合模型（Conformers）大多采用串行设计，导致局部和全局特征的整合不理想，并且常常忽略显式的通道建模。

**Method:** 本文提出了DBConformer，一种专为脑电图解码设计的双分支卷积Transformer网络。它集成了一个时间Conformer来建模长程时间依赖性，以及一个空间Conformer来提取通道间交互，从而捕获脑电信号中的时间动态和空间模式。一个轻量级通道注意力模块通过为脑电图通道分配数据驱动的重要性来进一步优化空间表示。

**Result:** 在五个运动想象（MI）数据集和两个癫痫检测数据集上的广泛实验表明，DBConformer在三种评估设置下始终优于10个有竞争力的基线模型，且参数量比高容量的EEG Conformer基线少八倍以上。此外，可视化结果证实DBConformer提取的特征具有生理可解释性，并与运动想象中的感觉运动先验一致。

**Conclusion:** DBConformer的卓越性能和可解释性使其在稳健和可解释的脑电图解码中具有可靠性。

> **ai_Abstract:** 该论文提出了DBConformer，一种用于脑电图（EEG）解码的双分支卷积Transformer网络。针对现有CNN和Conformer模型在捕获长程时间依赖性、全局通道关系以及特征整合方面的不足，DBConformer通过并行的时间Conformer和空间Conformer分别处理EEG信号的时间动态和空间模式，并结合通道注意力模块优化空间表示。实验结果表明，DBConformer在多个运动想象和癫痫检测数据集上表现出优于现有基线模型的性能，且参数量显著减少，同时提取的特征具有良好的生理可解释性。

> **摘要翻译:** 基于脑电图（EEG）的脑机接口（BCIs）将自发/诱发的神经活动转化为外部通信的控制命令。虽然卷积神经网络（CNNs）仍然是脑电图解码的主流骨干网络，但其固有的短感受野使其难以捕获长程时间依赖性和全局通道间关系。最近的CNN-Transformer混合模型（Conformers）部分解决了这个问题，但大多数采用串行设计，导致局部和全局特征的整合不理想，并且常常忽略显式的通道建模。为了解决这些限制，我们提出了DBConformer，一种专为脑电图解码设计的双分支卷积Transformer网络。它集成了一个时间Conformer来建模长程时间依赖性，以及一个空间Conformer来提取通道间交互，从而捕获脑电信号中的时间动态和空间模式。一个轻量级通道注意力模块通过为脑电图通道分配数据驱动的重要性来进一步优化空间表示。在五个运动想象（MI）数据集和两个癫痫检测数据集上的广泛实验表明，DBConformer在三种评估设置下始终优于10个有竞争力的基线模型，且参数量比高容量的EEG Conformer基线少八倍以上。此外，可视化结果证实DBConformer提取的特征具有生理可解释性，并与运动想象中的感觉运动先验一致。DBConformer的卓越性能和可解释性使其在稳健和可解释的脑电图解码中具有可靠性。代码已在https://github.com/wzwvv/DBConformer上公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [355] [DiLoCoX: A Low-Communication Large-Scale Training Framework for Decentralized Cluster](https://arxiv.org/abs/2506.21263)
> *DiLoCoX：一种用于去中心化集群的低通信大规模训练框架*

*Ji Qi, WenPeng Zhu, Li Li, Ming Wu, YingJun Wu, Wu He, Xun Gao, Jason Zeng, Michael Heinrich* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 去中心化训练, 低通信, 大规模模型, 流水线并行, 梯度压缩

**Comment:** 

> **TL;DR:** DiLoCoX是一个低通信、大规模的去中心化集群训练框架，它结合了多种策略，使得在慢速网络上对千亿参数级模型进行分布式训练成为可能，并实现了显著的加速。

**AI_Comments:** DiLoCoX的创新性在于其整合多种优化策略，以实现在低带宽去中心化网络上对超大规模模型进行高效训练。其理论分析和显著的经验加速（357x）证明了其在解决分布式训练通信瓶颈方面的巨大潜力。这项工作为未来在资源受限环境下部署和训练巨型模型开辟了新途径，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型（特别是大型语言模型）的分布式训练需要高水平的通信，高度依赖于具有快速可靠互连的中心化集群。当前面临的挑战是如何在慢速网络上对超过千亿参数的模型进行训练，以释放去中心化集群的潜力。

**Method:** 本文提出了DiLoCoX，一个低通信大规模去中心化集群训练框架。它结合了流水线并行（Pipeline Parallelism）、双优化器策略（Dual Optimizer Policy）、通信与本地训练的一步延迟重叠（One-Step-Delay Overlap of Communication and Local Training）以及自适应梯度压缩方案（Adaptive Gradient Compression Scheme）。同时，通过收敛性理论分析证明了一步延迟重叠和自适应梯度压缩方案的有效性。

**Result:** DiLoCoX能够在1Gbps的网络上预训练一个107B的基础模型。与传统的AllReduce相比，DiLoCoX在分布式训练中实现了357倍的速度提升，同时模型的收敛性退化可以忽略不计。

**Conclusion:** DiLoCoX是首个成功应用于万亿参数级以上模型的去中心化训练框架，它极大地提高了参数规模和模型预训练速度，使得在慢速网络上进行大规模模型训练成为可能。

> **ai_Abstract:** DiLoCoX是一种创新的低通信大规模去中心化集群训练框架，旨在解决大型语言模型在慢速网络上进行分布式训练的挑战。该框架通过结合流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案，显著提高了模型预训练的参数规模和速度。理论分析证明了其核心组件的收敛性，并通过实验证明DiLoCoX能在1Gbps网络上高效预训练107B模型，实现357倍于AllReduce的加速，同时保持良好收敛性。这是首个成功应用于千亿参数级以上模型的去中心化训练框架。

> **摘要翻译:** 基础模型，特别是大型语言模型（LLMs）的分布式训练需要高水平的通信。因此，它高度依赖于具有快速可靠互连的中心化集群。我们能否在慢速网络上进行训练，从而在处理超过千亿参数的模型时释放去中心化集群的潜力？在本文中，我们提出了DiLoCoX，一个低通信大规模去中心化集群训练框架。它结合了流水线并行、双优化器策略、通信与本地训练的一步延迟重叠以及自适应梯度压缩方案。这种组合显著提高了参数规模和模型预训练的速度。我们通过收敛性理论分析证明了通信与本地训练的一步延迟重叠以及自适应梯度压缩方案的益处。经验上，我们证明了DiLoCoX能够在1Gbps的网络上预训练一个107B的基础模型。与传统的AllReduce相比，DiLoCoX在分布式训练中实现了357倍的速度提升，同时模型的收敛性退化可以忽略不计。据我们所知，这是第一个成功应用于超过千亿参数模型的去中心化训练框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [356] [Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks](https://arxiv.org/abs/2506.21142)
> *无人机网络攻击的生成对抗规避与域外检测*

*Deepak Kumar Panda, Weisi Guo* | **Category: cs.LG**

**Keywords:** 无人机网络攻击, 生成对抗网络, 域外检测, 入侵检测系统, 条件变分自编码器

**Comment:** 

> **TL;DR:** 本文提出一种基于cGAN生成无人机网络对抗攻击并利用CVAE进行检测的框架，旨在增强入侵检测系统（IDS）抵御新型隐蔽威胁的能力。

**AI_Comments:** 该论文创新性地结合了生成对抗网络（cGAN）来制造隐蔽的无人机网络攻击样本，并引入条件变分自编码器（CVAE）来检测这些高级对抗性威胁，解决了传统IDS和OOD检测器的局限性。其重要性在于提升了无人机IDS对新型、自适应网络攻击的鲁棒性，为未来网络安全防御提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的入侵检测系统（IDS）和域外（OOD）检测器在识别新型、隐蔽的无人机网络攻击时面临挑战，难以区分隐蔽的对抗性攻击与真实的OOD事件，导致系统易受攻击。

**Method:** 本文提出一个基于条件生成对抗网络（cGAN）的框架来生成隐蔽的对抗性攻击，以规避IDS机制。首先设计一个鲁棒的多类别IDS分类器，在良性无人机遥测数据和已知网络攻击上进行训练。然后，cGAN利用该分类器扰动已知攻击，生成被误分类为良性但统计上仍类似于OOD分布的对抗性样本，并进行迭代优化。为检测这些扰动，引入一个条件变分自编码器（CVAE），利用负对数似然将对抗性输入与真实的OOD样本分离。

**Result:** 比较评估表明，基于CVAE的悔恨分数在识别隐蔽对抗性威胁方面显著优于传统的基于马哈拉诺比斯距离的检测器。

**Conclusion:** 研究强调了先进概率建模对于增强IDS抵御自适应、基于生成模型的网络入侵的重要性。

> **ai_Abstract:** 本文针对无人机网络攻击中传统入侵检测系统和域外检测器无法有效识别新型隐蔽威胁的问题，提出了一种基于cGAN生成对抗性攻击样本并利用CVAE进行检测的框架。该框架首先训练一个IDS分类器，然后利用cGAN生成能规避IDS且统计上类似OOD的隐蔽对抗样本。为检测这些样本，引入CVAE，并通过负对数似然区分对抗性输入与真实OOD样本。实验证明，CVAE在检测隐蔽对抗性威胁方面优于传统方法，强调了先进概率建模在增强IDS能力中的重要性。

> **摘要翻译:** 无人机日益融入民用空域，凸显了对弹性智能入侵检测系统（IDS）的需求，因为传统的异常检测方法往往无法识别新型威胁。一种常见的方法是将不熟悉的攻击视为域外（OOD）样本；然而，当缓解措施不足时，这会使系统容易受到攻击。此外，传统的OOD检测器难以区分隐蔽的对抗性攻击和真实的OOD事件。本文介绍了一种基于条件生成对抗网络（cGAN）的框架，用于制作规避IDS机制的隐蔽对抗性攻击。我们首先设计了一个鲁棒的多类别IDS分类器，该分类器在良性无人机遥测数据和已知网络攻击（包括拒绝服务（DoS）、虚假数据注入（FDI）、中间人（MiTM）和重放攻击）上进行训练。使用该分类器，我们的cGAN扰动已知攻击以生成对抗性样本，这些样本被错误地分类为良性，同时保留了与OOD分布的统计相似性。这些对抗性样本经过迭代细化以实现高隐蔽性和成功率。为了检测此类扰动，我们实现了一个条件变分自编码器（CVAE），利用负对数似然将对抗性输入与真实的OOD样本分离。比较评估表明，基于CVAE的悔恨分数在识别隐蔽对抗性威胁方面显著优于传统的基于马哈拉诺比斯距离的检测器。我们的发现强调了先进概率建模对于增强IDS抵御自适应、基于生成模型的网络入侵的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [359] [Personalized Federated Learning via Dual-Prompt Optimization and Cross Fusion](https://arxiv.org/abs/2506.21144)
> *通过双提示优化和交叉融合的个性化联邦学习*

*Yuguang Zhang, Kuangpu Guo, Zhihe Lu, Yunbo Wang, Jian Liang* | **Category: cs.LG, cs.CV**

**Keywords:** 联邦学习, 个性化, 提示学习, 异构性, 视觉-语言模型

**Comment:** 

> **TL;DR:** pFedDC 是一种个性化联邦学习框架，通过双提示学习和交叉融合解决了联邦学习中的数据异构性问题。

**AI_Comments:** 该论文的创新点在于结合了预训练视觉-语言模型的提示学习能力，并引入了双提示（全局和局部）以及交叉融合机制来处理联邦学习中的客户端异构性，特别是考虑了联合标签域分布漂移。这种方法为联邦学习的个性化和鲁棒性提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习面临数据、计算和通信异构性挑战。现有联邦提示学习方法仅依赖文本提示，且忽略联合标签域分布漂移。

**Method:** 本文提出了 pFedDC 框架，该框架基于双提示学习和交叉融合。每个客户端维护视觉和语言模态的全局和局部提示，其中全局提示捕获通用知识，局部提示编码客户端特定语义和域特征。此外，还设计了一个交叉融合模块，用于自适应整合不同级别的提示，以生成与每个客户端独特数据分布对齐的个性化表示。

**Result:** 在九个具有各种类型异构性的数据集上进行的广泛实验表明，pFedDC 始终优于最先进的方法。

**Conclusion:** pFedDC 通过双提示优化和交叉融合，有效解决了联邦学习中的异构性问题，并实现了优越的个性化性能。

> **ai_Abstract:** 本文提出了 pFedDC，一个基于双提示优化和交叉融合的个性化联邦学习框架，旨在解决联邦学习中的数据异构性问题。该框架允许每个客户端维护视觉和语言模态的全局和局部提示，并通过交叉融合模块自适应整合这些提示，生成个性化表示。实验证明 pFedDC 在多种异构数据集上优于现有SOTA方法。

> **摘要翻译:** 联邦学习（FL）允许在去中心化客户端之间进行协作模型训练，而无需共享本地数据，但面临数据、计算和通信异构性的挑战。预训练视觉-语言模型（VLMs）凭借其强大的泛化能力和通过提示进行的轻量级调优，提供了一种有前景的解决方案。然而，现有的联邦提示学习方法仅依赖于文本提示，并且忽略了联合标签域分布漂移。在本文中，我们提出了一种基于双提示学习和交叉融合的个性化联邦学习框架，称之为 pFedDC。具体而言，每个客户端在视觉和语言模态中维护全局和局部提示：全局提示捕获联邦中共享的通用知识，而局部提示编码客户端特定的语义和域特征。同时，设计了一个交叉融合模块，以自适应地整合来自不同级别的提示，使模型能够生成与每个客户端独特数据分布对齐的个性化表示。在九个具有各种类型异构性的数据集上进行的广泛实验表明，pFedDC 始终优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [361] [Linearity-based neural network compression](https://arxiv.org/abs/2506.21146)
> *基于线性度的神经网络压缩*

*Silas Dobler, Florian Lemmerich* | **Category: cs.LG, cs.AI, stat.ML**

**Keywords:** 神经网络压缩, 线性度, 模型剪枝, ReLU, 模型合并

**Comment:** 

> **TL;DR:** 本文提出一种新的基于线性度的神经网络压缩方法，可以在不损失性能的情况下将模型大小压缩到原始的1/4，并且可以与现有压缩技术结合使用。

**AI_Comments:** 这项工作提出了一种创新的神经网络压缩视角，即利用神经元的线性行为进行层合并，这与传统的基于重要性/冗余度的剪枝方法不同。其创新点在于从神经元激活的内在特性出发，提供了一种新的压缩机制。该方法实现了显著的无损压缩比例，并且能够与其他压缩技术兼容，这极大地增强了其在实际应用中的潜力。它为未来神经网络模型的小型化和效率提升提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强已高度优化的现有神经网络压缩解决方案，本文提出了一种新颖的基于线性度的方法来减少神经网络权重。

**Method:** 本文提出了一种基于线性度的神经网络压缩方法。该方法基于ReLU类激活函数中几乎总是激活的神经元表现出线性的直觉，从而允许合并后续层。论文介绍了其理论基础并进行了实验评估。

**Result:** 该新方法在大多数测试模型上实现了无损压缩，将模型大小减少到原始的1/4。将该方法应用于已通过基于重要性剪枝的模型时，显示出与其他压缩类型之间很少的干扰，表明可以成功组合多种技术。

**Conclusion:** 这项工作为一种新型的压缩方法奠定了基础，该方法能够实现更小、最终更高效的神经网络模型。

> **ai_Abstract:** 本文提出一种新颖的基于线性度的神经网络压缩方法，旨在通过利用ReLU类激活函数中几乎总是激活的神经元的线性特性来合并后续层，从而有效减少模型权重。实验证明，该方法在大多数模型上能实现高达1/4的无损压缩，并且可以与现有的基于重要性的剪枝方法兼容并成功结合，为构建更小、更高效的神经网络模型提供了新途径。

> **摘要翻译:** 在神经网络压缩领域，当前大多数方法通过衡量重要性和冗余度来减少不必要的参数。为了增强已高度优化的现有解决方案，我们提出了一种基于线性度的压缩方法，作为减少神经网络权重的创新方式。它基于这样一种直觉：对于ReLU类激活函数，几乎总是激活的神经元表现出线性，从而允许合并后续层。我们介绍了这种压缩背后的理论，并对我们的方法进行了实验评估。我们这种新颖的方法在大多数测试模型中实现了无损压缩，将模型大小减小到原始的1/4。将我们的方法应用于已通过基于重要性剪枝的模型时，显示出不同类型的压缩之间干扰很小，这表明成功结合多种技术的可能性。总的来说，我们的工作为一种新型的压缩方法奠定了基础，该方法能够实现更小、最终更高效的神经网络模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [363] [Latent Prototype Routing: Achieving Near-Perfect Load Balancing in Mixture-of-Experts](https://arxiv.org/abs/2506.21328)
> *潜在原型路由：在专家混合模型中实现近乎完美的负载均衡*

*Jiajie Yang* | **Category: cs.LG, cs.CL**

**Keywords:** 专家混合, 负载均衡, 路由, 潜在原型, 大型语言模型

**Comment:** 15 pages,4 figures

> **TL;DR:** 本文提出潜在原型路由（LPR）框架，通过集群视角解决专家混合（MoE）模型中严重的专家负载不平衡问题，实现了近乎完美的负载均衡，同时不影响性能。

**AI_Comments:** 该论文通过引入潜在原型路由（LPR），为MoE模型中的负载均衡问题提供了一个创新且有效的解决方案。其将专家路由与聚类思想相结合的视角是新颖的，并且通过量化指标（Gini系数和最小-最大比率）证明了其方法的显著优势，对提高大型语言模型训练和推理的效率具有重要意义。该方法在不损害性能的前提下，极大地提升了资源利用率，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前专家混合（MoE）系统存在严重的负载不平衡问题，导致模型容量和计算资源大量未被利用。只有一小部分专家在训练和推理过程中持续被激活。

**Method:** 我们从聚类视角重新审视专家路由，并提出了潜在原型路由（LPR），这是一个新颖的路由框架，它在推广现有方法的同时，促进了平衡的专家利用，且不损害下游性能。

**Result:** 在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上的广泛实验表明，LPR将专家负载的Gini系数平均从0.70降低到0.035，将最小-最大专家负载比从1e-6提高到0.70，实现了近乎完美的负载均衡。

**Conclusion:** 潜在原型路由（LPR）通过从聚类视角重新设计专家路由，显著解决了MoE模型中的负载不平衡问题，实现了卓越的资源利用率，同时保持了模型性能。

> **ai_Abstract:** 本文提出了一种名为潜在原型路由（LPR）的新型专家混合（MoE）模型路由框架，旨在解决现有MoE架构中严重的专家负载不平衡问题。LPR从聚类视角出发，通过推广现有方法，有效地促进了专家资源的平衡利用，同时不影响模型性能。实验结果表明，LPR在多种MoE模型上显著降低了专家负载的Gini系数，并大幅提升了最小-最大专家负载比，实现了近乎完美的负载均衡，从而提高了计算资源的利用率。

> **摘要翻译:** 专家混合（MoE）架构已成为高效扩展大型语言模型（LLMs）的关键策略。然而，当前的MoE系统面临严重的负载不平衡问题，即在训练和推理过程中，只有一小部分专家持续被激活，导致模型容量和计算资源的大量未被充分利用。在这项工作中，我们从聚类的角度重新审视了专家路由，并提出了潜在原型路由（LPR），这是一种新颖的路由框架，它概括了现有方法，同时促进了平衡的专家利用，而不会损害下游性能。在多个开源MoE模型（包括DeepSeek-V3、Qwen3-MoE和Mixtral）上的大量实验表明，LPR平均将专家负载的Gini系数从0.70降低到0.035，并将最小-最大专家负载比从1e-6提高到0.70，实现了近乎完美的负载均衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [364] [Diverse Mini-Batch Selection in Reinforcement Learning for Efficient Chemical Exploration in de novo Drug Design](https://arxiv.org/abs/2506.21158)
> *强化学习中用于从头药物设计中高效化学探索的多样化小批量选择*

*Hampus Gummesson Svensson, Ola Engkvist, Jon Paul Janet, Christian Tyrchan, Morteza Haghir Chehreghani* | **Category: cs.LG**

**Keywords:** 强化学习, 多样化小批量选择, 行列式点过程, 从头药物设计, 化学探索

**Comment:** 

> **TL;DR:** 本文提出了一种在强化学习中使用行列式点过程进行多样化小批量选择的方法，以提高从头药物设计中的化学探索效率，实验证明能显著提升解决方案的多样性并保持高质量。

**AI_Comments:** 这项工作通过引入行列式点过程进行多样化小批量选择，为强化学习中的高效探索提供了一个新颖的视角，尤其是在高成本评估领域如药物设计中。其创新性在于将多样性纳入学习过程，有效缓解了模式崩溃问题，并有望加速新药的发现。该方法在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 在许多实际应用中，评估实例的质量通常成本高昂且耗时，特别是在强化学习中，新的环境交互需要被评估以提供奖励信号。为了有效探索并缓解模式崩溃，从多样化的小批量中学习至关重要。

**Method:** 本文引入了用于强化学习的多样化小批量选择，并提出使用行列式点过程来完成此任务。该框架在药物发现的真实世界问题中进行了研究。

**Result:** 实验结果表明，所提出的多样化小批量选择框架可以显著提高解决方案的多样性，同时仍能获得高质量的解决方案。

**Conclusion:** 我们的多样化小批量选择框架能够显著提高解决方案的多样性，同时保持高品质。在药物发现中，这样的结果可能潜在地更快地满足未满足的药物需求。

> **ai_Abstract:** 本研究提出了一种在强化学习中进行多样化小批量选择的新框架，旨在解决实例评估成本高昂和模式崩溃的问题。该方法利用行列式点过程来确保小批量的多样性，并将其应用于从头药物设计中的化学探索。通过与现有分子生成模型的广泛实验表明，该框架能显著提高生成解决方案的多样性，同时保持高质量，从而加速药物发现过程。

> **摘要翻译:** 在许多实际应用中，评估实例的质量通常成本高昂且耗时，例如人工反馈和物理模拟，这与提出新实例形成对比。特别是，这在强化学习中更为关键，因为需要评估与环境的新交互（即新实例）以提供学习所需的奖励信号。由于充分探索至关重要，从多样化的小批量中学习可以产生巨大影响并有助于缓解模式崩溃。在本文中，我们引入了用于强化学习的多样化小批量选择，并提出使用行列式点过程来完成此任务。我们在真实世界问题（即药物发现）的背景下研究了这个框架。我们通过实验研究了我们提出的框架如何提高从头药物设计中化学探索的有效性，其中找到多样化和高质量的解决方案至关重要。我们使用三个成熟的分子生成预言机进行了全面的评估，涉及大量的生成步骤。我们的实验得出结论，我们的多样化小批量选择框架可以显著提高解决方案的多样性，同时仍能获得高质量的解决方案。在药物发现中，这样的结果可能潜在地更快地满足未满足的药物需求。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [367] [Scalable Bayesian Low-Rank Adaptation of Large Language Models via Stochastic Variational Subspace Inference](https://arxiv.org/abs/2506.21408)
> *通过随机变分子空间推理实现大规模语言模型的可扩展贝叶斯低秩适应*

*Colin Samplawski, Adam D. Cobb, Manoj Acharya, Ramneet Kaur, Susmit Jha* | **Category: cs.LG, cs.AI, cs.CL**

**Keywords:** 贝叶斯深度学习, 大型语言模型, 不确定性量化, 低秩适应, 随机变分推理

**Comment:** Accepted at UAI 2025

> **TL;DR:** 本文提出了ScalaBL，一种新的可扩展贝叶斯低秩适应方法，通过在低维子空间中进行推理，显著减少了大型语言模型不确定性量化所需的额外参数，同时保持了竞争力并提高了可扩展性。

**AI_Comments:** 这项工作的创新之处在于，它通过在低维子空间中进行推理，并重新利用LoRA参数作为投影，有效地解决了贝叶斯LLM在不确定性量化方面面临的参数扩展性问题。其重要性在于，它使得LLMs在需要高置信度和不确定性量化的高风险应用中（如自动驾驶和医疗）更具实用性。通过显著减少额外参数的需求，ScalaBL为构建更大、更实用的贝叶斯LLM铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）普遍存在幻觉和校准不良问题，使得在自动驾驶和医疗保健等高风险领域中，对这些模型进行不确定性量化变得至关重要。然而，现有基于贝叶斯深度学习的方法，尽管通过低秩适应（LoRA）参数使问题更易处理，但由于需要额外的参数，难以扩展到更大的LLMs。

**Method:** 本文提出了可扩展贝叶斯低秩适应（ScalaBL），通过随机变分子空间推理（Stochastic Variational Subspace Inference）在LoRA秩r的r维子空间中执行贝叶斯推理。该方法通过将LoRA参数重新用作投影矩阵，能够将子空间中的样本映射到LLM的完整权重空间，并利用随机变分推理学习所有参数。

**Result:** 尽管子空间维度较低，但ScalaBL与最先进的方法实现了竞争性的性能，并且仅需要大约1000个额外的参数。此外，它还能够扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

**Conclusion:** ScalaBL通过在低维子空间中进行贝叶斯推理，有效地解决了现有贝叶斯LLM方法在扩展性方面的参数限制问题，显著提高了贝叶斯LLM的可扩展性，同时保持了高性能。

> **ai_Abstract:** 本文提出了可扩展贝叶斯低秩适应（ScalaBL），一种针对大型语言模型（LLMs）不确定性量化的新方法。针对现有贝叶斯LLM方法扩展性差的问题，ScalaBL通过在低维子空间中进行贝叶斯推理，并巧妙地利用LoRA参数作为投影矩阵，实现了将子空间样本映射到LLM的全权重空间。实验证明，ScalaBL仅需少量额外参数即可达到与现有先进方法相当的性能，并成功扩展到比以往更大的贝叶斯LLM。

> **摘要翻译:** 尽管大型语言模型（LLMs）被广泛使用，但它们已知会产生错误信息并校准不良。这使得这些模型的不确定性量化变得至关重要，尤其是在自主和医疗保健等高风险领域。先前的工作通过对微调模型的低秩适应（LoRA）参数进行推理，使基于贝叶斯深度学习的方法更具可行性。然而，这些方法虽然有效，但由于与LoRA相比需要额外的参数，因此难以扩展到更大的LLMs。在这项工作中，我们提出了通过随机变分子空间推理实现的可扩展贝叶斯低秩适应（ScalaBL）。我们对LoRA秩r的r维子空间进行贝叶斯推理。通过将LoRA参数重新用作投影矩阵，我们能够将该子空间中的样本映射到LLM的完整权重空间。这使我们能够使用随机变分推理学习我们方法的所有参数。尽管我们的子空间维度较低，但我们能够与最先进的方法达到具有竞争力的性能，同时仅需要约1000个额外参数。此外，它使我们能够扩展到迄今为止最大的贝叶斯LLM，其基础参数是先前工作的四倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [369] [Zero-Shot Learning for Obsolescence Risk Forecasting](https://arxiv.org/abs/2506.21240)
> *零样本学习用于过时风险预测*

*Elie Saad, Aya Mrabah, Mariem Besbes, Marc Zolghadri, Victor Czmil, Claude Baron, Vincent Bourgeois* | **Category: cs.LG**

**Keywords:** 过时风险, 零样本学习, 大型语言模型, 预测, 数据限制

**Comment:** 

> **TL;DR:** 本文提出一种利用零样本学习（ZSL）和大型语言模型（LLMs）预测电子元件过时风险的方法，以解决数据稀缺问题，并在真实数据集上验证了其有效性。

**AI_Comments:** 该研究的创新点在于将零样本学习和大型语言模型应用于过时风险预测这一数据稀缺的领域，提供了一种解决实际工业挑战的新途径。其重要性在于能够帮助企业降低成本、保障系统安全与可用性。

<details>
  <summary>Details</summary>

**Motivation:** 电子元件过时给相关产业带来成本增加和系统中断等挑战，准确的过时风险预测至关重要，但现有方法受限于可靠数据的缺乏。

**Method:** 本文提出一种新颖的方法，利用零样本学习（ZSL）和大型语言模型（LLMs）来预测过时风险。该方法通过从表格数据集中利用领域特定知识来解决数据限制。

**Result:** 该方法在两个真实世界数据集中展示了有效的风险预测能力。对四种LLM的比较评估强调了为特定预测任务选择正确模型的重要性。

**Conclusion:** 零样本学习结合大型语言模型能够有效预测电子元件过时风险，并且针对具体预测任务选择合适的LLM对模型性能至关重要。

> **ai_Abstract:** 本文提出一种新颖的零样本学习（ZSL）结合大型语言模型（LLMs）的方法，用于预测电子元件的过时风险。该方法通过利用表格数据中的领域特定知识来克服数据不足的挑战，并在两个真实世界数据集中验证了其有效性。研究还指出，针对特定预测任务选择合适的LLM至关重要。

> **摘要翻译:** 电子元件过时给依赖电子元件的行业带来了严峻挑战，导致成本增加并扰乱了系统的安全性与可用性。准确的过时风险预测至关重要，但由于缺乏可靠数据而受到阻碍。本文提出了一种利用零样本学习（ZSL）与大型语言模型（LLMs）预测过时风险的新方法，旨在通过利用表格数据集中的领域特定知识来解决数据限制问题。该方法应用于两个真实世界数据集，展示了有效的风险预测能力。对四种LLM的比较评估强调了为特定预测任务选择正确模型的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [372] [Improved seeding strategies for k-means and k-GMM](https://arxiv.org/abs/2506.21291)
> *k-means和k-GMM改进的种子点初始化策略*

*Guillaume Carrière, Frédéric Cazals* | **Category: cs.LG, F.2; G.3**

**Keywords:** k-means, k-GMM, 种子点初始化, 聚类, 前瞻性原则

**Comment:** 13 pages

> **TL;DR:** 本文提出并实验验证了k-means和k-GMM新的初始化方法，通过前瞻性原则和多通道策略，在最终度量指标上优于现有方法。

**AI_Comments:** 本文通过对k-means和k-GMM随机种子点初始化技术的深入分析和形式化，提出了具有创新性的“前瞻性原则”和“多通道策略”。其创新点在于将种子点选择与最终评估指标更紧密地结合，并有效降低了随机性影响。实验结果表明其在性能上的显著提升，尤其是在k-means领域首次超越了k-means++和multi-swap等先进方法，这具有重要的实践意义。此外，对k-means特性的深入洞察也为后续研究提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 现有k-means和k-GMM随机初始化技术存在改进空间，需要更有效的种子点初始化方法来提高聚类性能。

**Method:** 重新审视了随机种子点初始化技术，形式化了其三个关键要素：种子采样使用的度量、候选种子点数量和种子点选择使用的度量。在此基础上，提出了利用“前瞻性原则”（根据评估算法的最终度量来调整种子点选择）和“多通道策略”（减少随机性影响）的新型初始化方法。

**Result:** 实验表明，在最终度量指标（k-means的SSE，k-GMM的对数似然）上，相对于经典竞争者有持续的常数因子改进，开销适中。特别是对于k-means，该方法优于最近设计的multi-swap策略，后者是第一个超越贪婪k-means++初始化的方法。实验分析还揭示了k-means的一些细微特性，包括种子点初始化时的SSE与最终SSE之间的相关性（或缺乏）、迭代种子点方法中观察到的方差减少现象，以及最终SSE对贪婪方法池大小的敏感性。

**Conclusion:** 作者提出的最有效的种子点初始化方法有望成为标准技术。从理论角度看，种子点初始化的形式化为新的分析方法打开了大门。

> **ai_Abstract:** 本文重新审视了k-means和k-GMM的随机种子点初始化技术，并形式化了其关键要素。在此基础上，提出了基于“前瞻性原则”和“多通道策略”的新型初始化方法。实验证明，这些方法在最终聚类质量上显著优于现有技术，并揭示了k-means的一些深层特性。这些方法有望成为新的标准初始化策略，并为理论分析奠定基础。

> **摘要翻译:** 我们重新审视了k-means聚类和k-GMM（使用期望最大化进行高斯混合模型拟合）的随机种子点初始化技术，并形式化了它们的三个关键要素：用于种子采样的度量、候选种子点的数量以及用于种子点选择的度量。这项分析产生了利用前瞻性原则——使种子点选择与用于评估算法的最终度量保持更高的一致性——和多通道策略来驯服随机性影响的新型初始化方法。
实验表明，在最终度量指标（k-means的SSE，k-GMM的对数似然）上，相对于经典竞争者，以适度的开销实现了持续的常数因子改进。特别是对于k-means，我们的方法改进了最近设计的multi-swap策略，这是第一个在性能上超越贪婪k-means++初始化的方法。
我们的实验分析还揭示了k-means经常被忽视的一些细微特性，包括种子点初始化时的SSE与最终SSE之间的相关性（或缺乏）、在迭代种子点方法中观察到的方差减少现象，以及最终SSE对贪婪方法池大小的敏感性。
实际上，我们最有效的种子点初始化方法是成为标准技术之一（如果不是唯一）的有力候选。从理论角度来看，我们对种子点初始化的形式化为新的分析方法开辟了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [377] [DynamicBench: Evaluating Real-Time Report Generation in Large Language Models](https://arxiv.org/abs/2506.21343)
> *DynamicBench：评估大型语言模型中的实时报告生成*

*Jingyao Li, Hao Sun, Zile Qiao, Yong Jiang, Pengjun Xie, Fei Huang, Hong Xu, Jiaya Jia* | **Category: cs.LG**

**Keywords:** DynamicBench, 大型语言模型, 实时报告生成, 基准测试, 信息处理

**Comment:** 

> **TL;DR:** DynamicBench是一个新的基准测试，用于评估LLM处理实时信息和生成报告的能力，其方法在文档有无的情况下均超越GPT4o。

**AI_Comments:** 该论文通过引入DynamicBench，创新性地解决了现有LLM基准测试未能有效评估实时信息处理能力的痛点。其双路径检索管道和对领域特定知识的要求，使其能够更真实地模拟实际应用场景。超越GPT4o的性能表明了该方法的有效性和重要性，对于推动LLM在动态信息处理领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的大型语言模型（LLM）基准测试依赖于静态评估，无法捕捉当代应用中实时信息处理的动态需求。为了解决这一限制，本文提出了DynamicBench。

**Method:** DynamicBench采用双路径检索管道，整合了网络搜索和本地报告数据库。它需要领域特定知识，并在提供或不提供外部文档的场景中评估模型处理最新信息或利用上下文增强的能力。此外，本文还引入了一个先进的报告生成系统，能够管理动态信息合成。

**Result:** 实验结果证实了该方法的有效性，其方法在无文档和文档辅助场景中分别超越GPT4o 7.0%和5.8%，达到了最先进的性能。

**Conclusion:** 本文提出的DynamicBench及其相关方法有效解决了大型语言模型在实时报告生成方面的评估空白，并在实验中展现出卓越的性能。

> **ai_Abstract:** 本文介绍了DynamicBench，一个旨在评估大型语言模型（LLM）实时报告生成能力的新型基准测试。针对传统静态评估的局限性，DynamicBench采用双路径检索管道，结合网络搜索和本地报告数据库，并要求领域特定知识。它在有无外部文档的场景下评估LLM处理最新信息的能力。实验结果表明，该方法实现了最先进的性能，在无文档和文档辅助场景中分别超越GPT4o 7.0%和5.8%。

> **摘要翻译:** 大型语言模型（LLM）的传统基准测试通常依赖于通过讲故事或表达意见进行的静态评估，这未能捕捉当代应用中实时信息处理的动态需求。为了解决这一限制，我们提出了DynamicBench，一个旨在评估LLM存储和处理最新数据熟练程度的基准测试。DynamicBench利用双路径检索管道，整合了网络搜索和本地报告数据库。它需要领域特定知识，以确保在专业领域内准确生成报告。通过在提供或不提供外部文档的场景中评估模型，DynamicBench有效地衡量了它们独立处理最新信息或利用上下文增强的能力。此外，我们引入了一个先进的报告生成系统，擅长管理动态信息合成。我们的实验结果证实了我们方法的有效性，我们的方法在无文档和文档辅助场景中分别超越GPT4o 7.0%和5.8%，达到了最先进的性能。代码和数据将公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [380] [SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning](https://arxiv.org/abs/2506.21355)
> *SMMILE：一个专家驱动的多模态医学上下文学习基准*

*Melanie Rieff, Maya Varma, Ossian Rabow, Subathra Adithan, Julie Kim, Ken Chang, Hannah Lee, Nidhi Rohatgi, Christian Bluethgen, Mohamed S. Muneer, Jean-Benoit Delbrouck, Michael Moor* | **Category: cs.LG**

**Keywords:** 多模态上下文学习, 医学人工智能, 基准测试, 多模态大语言模型, 近因偏差

**Comment:** 

> **TL;DR:** 引入SMMILE，首个专家驱动的医学多模态上下文学习基准，评估发现当前多模态大语言模型在此任务上表现不佳，且易受无关示例和示例顺序影响。

**AI_Comments:** 本文的创新之处在于构建了首个专家驱动的医学多模态上下文学习基准SMMILE，填补了该领域评估工具的空白。其重要性在于揭示了当前多模态大语言模型在医学上下文学习中存在的关键局限性，特别是在处理无关示例和示例顺序方面，为未来模型改进提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态上下文学习（ICL）在医学等领域潜力巨大，但其探索不足，特别是多模态大语言模型在医学任务中从上下文中学习的能力尚不明确。

**Method:** 引入了SMMILE，一个由11位医学专家策划的医学多模态上下文学习基准，包含111个问题（517个问答-图像三元组），涵盖6个医学专业和13种成像模式。还推出了增强版SMMILE++。对15个多模态大语言模型进行了全面评估。

**Result:** 大多数模型在医学多模态上下文学习能力上表现中等或较差。上下文学习对零样本的平均提升仅为SMMILE上的8%和SMMILE++上的9.4%。无关上下文示例会降低性能，单个噪声或无关示例可使性能下降高达9.5%。示例排序存在近因偏差，即将最相关的示例放在最后可使性能大幅提升高达71%。

**Conclusion:** 当前多模态大语言模型在从上下文学习多模态医学任务时存在严重的局限性和偏差。

> **ai_Abstract:** 本文引入了SMMILE，首个由专家驱动的医学多模态上下文学习基准，旨在评估多模态大语言模型在医学领域从上下文学习的能力。该基准包含由医学专家精心策划的问题和示例，并推出了增强版SMMILE++。通过对15个MLLM的广泛评估，研究发现当前模型在医学多模态上下文学习方面表现不佳，且易受不相关示例干扰，同时示例排序存在近因偏差，提示了当前模型在此任务上的显著局限性。

> **摘要翻译:** 尽管多模态上下文学习（ICL）在医学等领域具有巨大潜力，但其探索不足。临床医生日常会遇到需要从有限示例中适应的各种专业任务，例如从少量相关既往病例中获取见解或考虑一组受限的鉴别诊断。虽然多模态大语言模型（MLLMs）在医学视觉问答（VQA）方面取得了进展，但它们从上下文中学习多模态任务的能力在很大程度上是未知的。
我们介绍了SMMILE，这是第一个专家驱动的医学任务多模态ICL基准。十一位医学专家策划了问题，每个问题都包含一个多模态查询和多模态上下文示例作为任务演示。SMMILE包含111个问题（517个问答-图像三元组），涵盖6个医学专业和13种成像模式。我们进一步介绍了SMMILE++，这是一个包含1038个排列问题的增强变体。对15个MLLM的全面评估表明，大多数模型在医学任务中的多模态ICL能力表现中等或较差。在开放式评估中，ICL在SMMILE上比零样本平均仅提升8%，在SMMILE++上提升9.4%。我们观察到对不相关上下文示例的敏感性：即使是单个噪声或不相关的示例也能使性能下降高达9.5%。此外，示例排序表现出近因偏差，即将最相关的示例放在最后可以使性能大幅提升高达71%。我们的发现强调了当前MLLM在从上下文中学习多模态医学任务时存在的关键局限性和偏差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [382] [rQdia: Regularizing Q-Value Distributions With Image Augmentation](https://arxiv.org/abs/2506.21367)
> *rQdia：使用图像增强正则化Q值分布*

*Sam Lerman, Jing Bi* | **Category: cs.LG, cs.AI**

**Keywords:** rQdia, Q值分布, 图像增强, 深度强化学习, 像素级控制

**Comment:** 

> **TL;DR:** rQdia通过图像增强和简单的辅助损失来正则化Q值分布，显著提升了像素级深度强化学习算法（如DrQ、SAC和Data-Efficient Rainbow）在MuJoCo和Atari环境中的表现，并使无模型连续控制超越了状态编码基线。

**AI_Comments:** 本文的创新点在于提出了一个简单而有效的辅助损失，通过正则化Q值分布来利用图像增强，从而显著提升了像素级深度强化学习的性能。其重要性在于，它不仅在多个基准测试中取得了优异成绩，更重要的是，它推动了无模型像素级连续控制超越了传统的基于状态编码的基线，为该领域的发展开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 在像素级深度强化学习中，为了提升现有算法的性能和样本效率，并使无模型的连续控制能够超越基于状态编码的基线，作者提出了正则化Q值分布的方法。

**Method:** rQdia通过使用增强图像和引入一个简单的辅助损失来正则化Q值分布，该损失通过均方误差（MSE）来均衡这些分布。

**Result:** rQdia在MuJoCo连续控制套件中，分别将DrQ和SAC在像素级任务上的表现提升了9/12和10/12；在Atari街机环境中，将Data-Efficient Rainbow的表现提升了18/26。这些提升体现在样本效率和长期训练中。此外，rQdia的加入最终使得无模型的像素级连续控制超越了状态编码基线。

**Conclusion:** rQdia通过正则化Q值分布，显著提升了多种像素级深度强化学习算法的性能和效率，并成功使无模型的像素级连续控制超越了传统的状态编码基线。

> **ai_Abstract:** rQdia是一种用于像素级深度强化学习的方法，它利用图像增强技术通过简单的均方误差辅助损失来正则化Q值分布。该方法显著提升了DrQ和SAC在MuJoCo连续控制任务上的表现，并改善了Data-Efficient Rainbow在Atari环境中的性能。rQdia不仅提高了算法的样本效率和长期训练效果，还首次使无模型像素级连续控制超越了状态编码基线。

> **摘要翻译:** rQdia通过增强图像在基于像素的深度强化学习中正则化Q值分布。通过一个简单的辅助损失，即通过均方误差（MSE）均衡这些分布，rQdia在MuJoCo连续控制套件中，分别将DrQ和SAC在像素级任务上的表现提升了9/12和10/12，并在26个Atari街机环境中提升了Data-Efficient Rainbow的表现18个。性能提升体现在样本效率和长期训练中。此外，rQdia的加入最终使得无模型的像素级连续控制超越了状态编码基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [383] [MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN Hardware Accelerators](https://arxiv.org/abs/2506.21371)
> *MAx-DNN：用于节能DNN硬件加速器的多级算术近似*

*Vasileios Leon, Georgios Makris, Sotirios Xydis, Kiamal Pekmestzi, Dimitrios Soudris* | **Category: cs.LG, cs.AR**

**Keywords:** 深度神经网络, 硬件加速器, 算术近似, 能效, ROUP乘法器

**Comment:** Presented at the 13th IEEE LASCAS Conference

> **TL;DR:** MAx-DNN提出了一种多级算术近似方法，通过在层、滤波器和核级别分布近似乘法器，显著提高深度神经网络硬件加速器的能效，同时保持可接受的精度。

**AI_Comments:** 本文的创新点在于提出了多级（层、滤波器、核）的细粒度近似方法，这比传统的粗粒度近似更精细和灵活。通过在不同粒度级别上应用近似乘法器，可以更好地平衡精度和能效之间的权衡。其重要性在于为未来节能型AI硬件设计提供了新的思路，尤其是在资源受限的边缘设备上部署DNN时具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）架构的快速增长使其成为提供高级机器学习任务的事实方法，但其计算需求高。本文旨在通过利用DNN工作负载的细粒度错误弹性与硬件近似技术相结合，实现更高级别的能效，从而解决低功耗DNN计算的需求。

**Method:** 本文利用最先进的ROUP近似乘法器，系统地探索其在网络中的细粒度分布，采用层级、滤波器级和核级方法。通过在CIFAR-10数据集上使用ResNet-8模型评估了这些近似的影响。

**Result:** 所提出的解决方案相比于基线量化模型，在牺牲高达4%的精度损失的情况下，实现了高达54%的能量增益；与最先进的DNN近似方法相比，则提供了2倍的能量增益和更好的精度。

**Conclusion:** MAx-DNN通过多级算术近似，有效地提高了深度神经网络硬件加速器的能效，并在保持可接受的精度损失的同时，优于现有的先进近似方法。

> **ai_Abstract:** 本文提出MAx-DNN，一种利用多级算术近似来提高深度神经网络（DNN）硬件加速器能效的方法。通过系统地在层、滤波器和核级别分布ROUP近似乘法器，研究了其对精度和能耗的影响。在ResNet-8和CIFAR-10数据集上的评估表明，该方法在可接受的精度损失下显著降低了能耗，并且在能效方面优于现有先进的DNN近似技术。

> **摘要翻译:** 如今，深度神经网络（DNN）架构的快速增长已使其成为提供高精度高级机器学习任务的事实方法。针对低功耗DNN计算，本文研究了DNN工作负载的细粒度错误弹性与硬件近似技术之间的相互作用，以实现更高水平的能效。我们利用最先进的ROUP近似乘法器，系统地探索了它们在网络中根据我们的层级、滤波器级和核级方法的细粒度分布，并检查了它们对精度和能耗的影响。我们使用CIFAR-10数据集上的ResNet-8模型来评估我们的近似。所提出的解决方案与基线量化模型相比，以高达4%的精度损失换取了高达54%的能量增益，同时与最先进的DNN近似方法相比，提供了2倍的能量增益和更好的精度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [385] [Pay Attention to Small Weights](https://arxiv.org/abs/2506.21374)
> *关注小权重*

*Chao Zhou, Tom Jacobs, Advait Gadhikar, Rebekka Burkholz* | **Category: cs.LG, cs.AI**

**Keywords:** 模型微调, 小权重, NANOADAM, 资源效率, 灾难性遗忘

**Comment:** 

> **TL;DR:** 针对大型预训练模型微调的资源密集问题，本文提出NANOADAM，通过动态更新小权重来降低成本，同时提高泛化性能并减少灾难性遗忘。

**AI_Comments:** 这篇论文通过一个简洁而新颖的观察（大梯度与小权重相关）提出了一种高效的微调策略。其创新点在于利用这一观察来设计一个无梯度且能有效减少灾难性遗忘的方法，显著降低了微调的资源消耗，同时提升了模型性能。这对于大型模型在资源受限环境下的部署和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型预训练神经网络存在内存和计算成本高的资源密集问题。通过分析微调过程中梯度和权重的关系，发现大梯度常与小权重相关，尤其在微调设置中更为显著，这促使作者提出一种新的微调策略。

**Method:** 提出NANOADAM方法，该方法在微调过程中动态地仅更新小幅度的权重。其优点包括：参数子集确定无需梯度计算（无梯度准则），保留大幅度权重以减少灾难性遗忘，允许使用更大的学习率。

**Result:** NANOADAM在实验中持续获得更好的泛化性能，并在NLP和视觉任务中得到了验证。

**Conclusion:** NANOADAM通过关注并动态更新小权重，有效解决了大型模型微调的资源密集问题，同时提高了性能并减少了灾难性遗忘，提供了一种高效且实用的微调策略。

> **ai_Abstract:** 本文针对大型预训练模型微调中存在的资源密集问题，通过观察到微调时大梯度常与小权重相关这一现象，提出了一种名为NANOADAM的新方法。NANOADAM在微调时仅动态更新小幅度的权重，无需梯度计算即可确定更新参数，有效保留了预训练学到的关键特征以减少灾难性遗忘，并支持更大的学习率，从而在NLP和视觉任务中展现出更优的泛化性能。

> **摘要翻译:** 微调大型预训练神经网络在内存和计算成本方面都是资源密集型的。为了缓解这种情况，一种常见的方法是将训练限制在模型参数的一个子集上。通过分析微调过程中梯度和权重之间的关系，我们观察到一个显著的模式：大梯度通常与小幅度的权重相关。这种相关性在微调设置中比从头开始训练时更为明显。受此观察启发，我们提出了NANOADAM，它在微调过程中动态地仅更新小幅度的权重，并提供了几个实际优势：首先，这个标准是无梯度的——可以在不计算梯度的情况下确定参数子集；其次，它保留了大幅度的权重，这些权重可能编码了预训练期间学到的关键特征，从而降低了灾难性遗忘的风险；第三，它允许使用更大的学习率，并在实验中持续带来更好的泛化性能。我们在NLP和视觉任务中都证明了这一点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [387] [Temporal-Aware Graph Attention Network for Cryptocurrency Transaction Fraud Detection](https://arxiv.org/abs/2506.21382)
> *用于加密货币交易欺诈检测的时间感知图注意力网络*

*Zhi Zheng, Bochuan Zhou, Yuping Song* | **Category: cs.LG, cs.AI**

**Keywords:** Cryptocurrency fraud detection, Graph Attention Network, Temporal awareness, Class imbalance, Anomaly detection

**Comment:** 

> **TL;DR:** 提出了一种名为ATGAT的时间感知图注意力网络，通过融合多尺度时间特征和三重注意力机制，有效提升了加密货币交易欺诈检测的性能，并在Elliptic++数据集上取得了显著优于传统方法和GNN的成果。

**AI_Comments:** 该论文通过引入时间感知和三重注意力机制，显著提升了图神经网络在加密货币欺诈检测中的性能，解决了传统方法难以处理的时间和结构依赖性问题，并有效应对了类别不平衡。其模块化设计和在其他时间图异常检测任务中的推广潜力是其重要创新点。

<details>
  <summary>Details</summary>

**Motivation:** 加密货币交易欺诈检测面临日益复杂的交易模式和严重的类别不平衡挑战。传统方法依赖手动特征工程，难以捕获交易网络中的时间和结构依赖性。

**Method:** 本文提出了一种增强型时间感知图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 设计先进的时间嵌入模块，融合多尺度时间差特征与周期性位置编码；(2) 构建时间感知三重注意力机制，联合优化结构、时间及全局上下文注意力；(3) 采用加权BCE损失解决类别不平衡问题。

**Result:** 在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到0.9130，比最佳传统方法XGBoost提高了9.2%，比GCN提高了12.0%，比标准GAT提高了10.0%。

**Conclusion:** 该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广到其他时间图异常检测任务。

> **ai_Abstract:** 本文提出了一种名为增强型时间感知图注意力网络（ATGAT）的新方法，旨在解决加密货币交易欺诈检测中复杂的交易模式和类别不平衡问题。ATGAT通过一个先进的时间嵌入模块、一个时间感知三重注意力机制和一个加权BCE损失来提升性能。实验结果显示，ATGAT在Elliptic++数据集上取得了0.9130的AUC，显著优于传统方法和现有图神经网络模型，证明了其在欺诈检测中的有效性和普适性。

> **摘要翻译:** 加密货币交易欺诈检测面临着日益复杂的交易模式和严重的类别不平衡的双重挑战。传统方法依赖于手动特征工程，并且难以捕获交易网络中的时间和结构依赖关系。本文提出了一种增强型时间感知图注意力网络（ATGAT），通过三个模块提升检测性能：(1) 设计了一个先进的时间嵌入模块，融合了多尺度时间差特征和周期性位置编码；(2) 构建了一个时间感知三重注意力机制，联合优化了结构、时间以及全局上下文注意力；(3) 采用加权BCE损失来解决类别不平衡问题。在Elliptic++加密货币数据集上的实验表明，ATGAT的AUC达到了0.9130，比最佳传统方法XGBoost提高了9.2%，比GCN提高了12.0%，比标准GAT提高了10.0%。该方法不仅验证了时间感知和三重注意力机制对图神经网络的增强效果，还为金融机构提供了更可靠的欺诈检测工具，其设计原则可推广到其他时间图异常检测任务。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [388] [Early Stopping Tabular In-Context Learning](https://arxiv.org/abs/2506.21387)
> *早期停止表格上下文学习*

*Jaris Küken, Lennart Purucker, Frank Hutter* | **Category: cs.LG**

**Keywords:** 表格基础模型, 上下文学习, 早期停止, 推理效率, Transformer

**Comment:** ICML Workshop Paper

> **TL;DR:** 针对表格基础模型在上下文学习中推理成本高的问题，提出了一种早期停止策略，通过动态评估在每个Transformer编码器层后是否停止，显著加速了推理，同时保持了性能。

**AI_Comments:** 这项工作通过引入早期停止策略，有效地解决了表格基础模型在推理时的高成本问题，尤其是在处理大型数据集时。其创新点在于动态评估和逐层解码器的结合，实现了效率与性能的良好平衡。这对于实际应用中部署大规模表格上下文学习模型具有重要意义，因为它能显著降低计算资源消耗。

<details>
  <summary>Details</summary>

**Motivation:** 表格基础模型通过上下文学习在各种表格学习任务中表现出强大的性能，无需任何下游微调即可提供强大的泛化能力。然而，它们的推理时间成本仍然很高，特别是对于更大的数据集。

**Method:** 提出了一种早期停止上下文学习过程的方法。通过在每个Transformer编码器层之后动态评估是否停止上下文学习来实现。一旦停止，使用预训练的逐层解码器解码嵌入。

**Result:** 在34个小型分类任务上的实验表明，早期停止上下文学习可以将推理速度提高高达1.3倍，而预测性能的下降可以忽略不计。在5个大型分类任务上，实现了高达2.2倍的加速。

**Conclusion:** 早期退出是一种有效且实用的策略，可以提高表格上下文学习的效率。

> **ai_Abstract:** 本文提出了一种早期停止表格上下文学习的方法，旨在解决表格基础模型推理成本高的问题。该方法通过在每个Transformer编码器层后动态判断是否停止，并使用预训练解码器解码，从而显著加速了推理过程。实验证明，在小型数据集上可提速1.3倍且性能无明显下降，在大型数据集上可提速高达2.2倍，显示了其作为提高表格上下文学习效率的有效性。

> **摘要翻译:** 表格基础模型通过上下文学习在各种表格学习任务中表现出强大的性能，无需任何下游微调即可提供强大的泛化能力。然而，它们的推理时间成本仍然很高，特别是对于更大的数据集。为了解决这个问题，我们提出了早期停止上下文学习过程。我们通过在每个Transformer编码器层之后动态评估是否停止上下文学习来实现这一点。一旦停止，我们使用预训练的逐层解码器解码嵌入。在34个小型分类任务上的实验表明，早期停止上下文学习可以将推理速度提高高达1.3倍，而预测性能的下降可以忽略不计。为了评估可扩展性，我们进一步在五个大型分类任务上评估了我们的方法，实现了高达2.2倍的加速。我们的结果证明了早期退出作为一种有效且实用的策略，在提高表格上下文学习效率方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [391] [Distributed Cross-Channel Hierarchical Aggregation for Foundation Models](https://arxiv.org/abs/2506.21411)
> *分布式跨通道分层聚合用于基础模型*

*Aristeidis Tsaris, Isaac Lyngaas, John Lagregren, Mohamed Wahib, Larry York, Prasanna Balaprakash, Dan Lu, Feiyi Wang, Xiao Wang* | **Category: cs.LG**

**Keywords:** 分布式聚合, 基础模型, 视觉Transformer, 计算效率, 超光谱成像

**Comment:** 

> **TL;DR:** 本文提出D-CHAG，一种分布式跨通道分层聚合方法，旨在解决视觉基础模型中图像标记化和聚合的计算密集问题，显著提高计算效率，减少内存使用，并提高吞吐量。

**AI_Comments:** 该论文提出了一种创新的分布式聚合方法D-CHAG，有效解决了视觉基础模型在处理多通道图像数据时面临的计算效率和内存瓶颈问题。其兼容性强，可与现有并行策略和Transformer架构结合，并在超大规模GPU集群上展现出显著的性能提升，对推动大规模视觉基础模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉科学基础模型在科学发现和创新中潜力巨大，但当前分布式方法未能充分解决图像标记化和聚合带来的计算密集挑战。

**Method:** 本文引入分布式跨通道分层聚合（D-CHAG）方法，专为具有大量通道的图像模态数据集设计。该方法兼容任何模型并行策略和任何类型的视觉Transformer架构，并可与张量并行和模型分片集成。

**Result:** D-CHAG在超光谱成像和天气预报任务上进行了评估。当与张量并行和模型分片集成时，在Frontier超级计算机上使用多达1024个AMD GPU时，内存使用量减少高达75%，持续吞吐量增加一倍以上。

**Conclusion:** D-CHAG通过提高计算效率、减少内存使用和增加吞吐量，有效解决了视觉基础模型中图像聚合的计算密集挑战，从而推动科学发现和创新。

> **ai_Abstract:** 本文提出了一种名为分布式跨通道分层聚合（D-CHAG）的新方法，旨在解决视觉基础模型在处理多通道图像数据时面临的计算密集问题。D-CHAG兼容多种模型并行策略和视觉Transformer架构，并通过实验证明其能显著提高计算效率、减少内存使用，并在大规模GPU集群上提升吞吐量，特别适用于高光谱成像和天气预报等任务。

> **摘要翻译:** 基于视觉的科学基础模型在推动科学发现和创新方面具有巨大潜力。这种潜力源于它们能够聚合来自不同来源（如不同物理基础或数据采集系统）的图像，并使用Transformer架构学习时空相关性。然而，对图像进行标记化和聚合可能计算密集，这是当前分布式方法尚未完全解决的挑战。在这项工作中，我们引入了分布式跨通道分层聚合（D-CHAG）方法，该方法专为具有大量图像模态通道的数据集设计。我们的方法兼容任何模型并行策略和任何类型的视觉Transformer架构，显著提高了计算效率。我们在高光谱成像和天气预报任务上评估了D-CHAG。当与张量并行和模型分片集成时，我们的方法在Frontier超级计算机上使用多达1024个AMD GPU时，内存使用量减少高达75%，持续吞吐量增加了一倍以上。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [393] [Deception Detection in Dyadic Exchanges Using Multimodal Machine Learning: A Study on a Swedish Cohort](https://arxiv.org/abs/2506.21429)
> *使用多模态机器学习在两人交流中检测欺骗：一项针对瑞典人群的研究*

*Franco Rugolon, Thomas Jack Samuels, Stephan Hau, Lennart Högman* | **Category: cs.LG**

**Keywords:** 欺骗检测, 多模态机器学习, 两人互动, 音视频分析, 晚期融合

**Comment:** 40 pages, 2 figures, 2 tables. To be submitted in Behavior Research
  Methods

> **TL;DR:** 本研究使用多模态机器学习（音频、视频、动作单元、凝视）在瑞典两人互动中检测欺骗，发现结合欺骗者和被欺骗者的数据以及多模态（特别是晚期融合）显著提高了检测准确性。

**AI_Comments:** 该论文具有创新性，因为它首次在斯堪的纳维亚人群中研究多模态欺骗检测，并强调了在两人交流中整合双方参与者数据的重要性，这是一种细致入微的方法。该任务达到了71%的准确率，是一个很好的基准。其在心理治疗环境中的潜在应用尤其值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查使用多模态机器学习技术在两人互动中检测欺骗的有效性，重点是整合来自欺骗者和被欺骗者的数据。

**Method:** 研究采用多模态机器学习方法，比较了早期和晚期融合策略。数据来源包括音频和视频信息（特别是动作单元和凝视信息），并结合了欺骗者和被欺骗者双方的数据。数据集是新收集的，来自参与情感相关话题的真实或谎言情景的瑞典母语使用者。

**Result:** 结果表明，结合语音和面部信息比单一模态方法表现更优。此外，包含来自两位参与者的数据显著提高了欺骗检测准确性，最佳性能（71%）是通过对两种模态和参与者应用晚期融合策略实现的。

**Conclusion:** 这些发现与心理学理论一致，表明在初次互动中面部和声音表达的差异控制。作为针对斯堪的纳维亚人群的首次同类研究，这项研究为未来对两人互动（特别是在心理治疗环境中）的调查奠定了基础。

> **ai_Abstract:** 本研究探索了在两人互动中应用多模态机器学习进行欺骗检测，整合了来自欺骗者和被欺骗者双方的音频（语音）和视频（动作单元、凝视）数据。研究使用了新的瑞典数据集，并比较了早期和晚期融合方法。结果表明，结合语音和面部信息以及两位参与者的数据显著提高了检测准确性，其中晚期融合方法达到了71%的最佳性能。这些发现支持了关于表达控制的心理学理论，并为未来在两人互动（特别是心理治疗）背景下的研究奠定了基础。

> **摘要翻译:** 这项研究调查了使用多模态机器学习技术在两人互动中检测欺骗的有效性，重点是整合来自欺骗者和被欺骗者的数据。我们比较了早期和晚期融合方法，利用音频和视频数据——特别是动作单元和凝视信息——跨所有可能的模态和参与者组合。我们的数据集是新收集的，来自参与情感相关话题的真实或谎言情景的瑞典母语使用者，作为我们分析的基础。结果表明，与单模态方法相比，结合语音和面部信息能产生更优越的性能。此外，包含来自两位参与者的数据显著提高了欺骗检测的准确性，最佳性能（71%）是通过对两种模态和参与者应用晚期融合策略实现的。这些发现与心理学理论一致，这些理论表明在初次互动中面部和声音表达的差异控制。作为针对斯堪的纳维亚人群的首次同类研究，这项研究为未来对两人互动（特别是在心理治疗环境中）的调查奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [396] [A Keyword-Based Technique to Evaluate Broad Question Answer Script](https://arxiv.org/abs/2506.21461)
> *评估开放式问题答案的基于关键词的技术*

*Tamim Al Mahmud, Md Gulzar Hussain, Sumaiya Kabir, Hasnain Ahmad, Mahmudus Sobhan* | **Category: cs.LG**

**Keywords:** 关键词评估, 主观题, 电子评估, 自动评分, 答卷分析

**Comment:** ACM Conference Proceedings (9 Pages)

> **TL;DR:** 本文提出了一种基于关键词的电子系统，用于自动评估主观题的答案，并检查语法和拼写错误，在100份答卷上取得了0.91的准确率。

**AI_Comments:** 该研究提出了一种实用的方法来自动化主观题的评估，这在传统教育评估中是一个挑战。其创新点在于结合了关键词匹配和语法拼写检查，提高了评估的效率和准确性。然而，该方法可能在处理语义复杂或表达方式多样的答案时面临局限性，且0.91的准确率虽高，但仍需考虑其在不同学科和问题类型上的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供一种高效的电子解决方案，用于评估主观题的答卷，以改进教育系统的评估方法。

**Method:** 提出并实现了一个集成系统，通过从答卷中提取关键词，并与从开放和封闭领域解析的关键词进行比较来评估书面答卷。该系统还检查答卷中的语法和拼写错误。

**Result:** 该系统在100名学生的答卷上进行了测试，并获得了0.91的准确率。

**Conclusion:** 该系统能够有效且高精度地评估主观题答卷。

> **ai_Abstract:** 本文提出了一种基于关键词的电子系统，旨在高效评估主观题的答卷。该系统通过提取答卷中的关键词并与预设关键词进行比较来评分，同时还检查语法和拼写错误。实验结果显示，该系统在处理100份学生答卷时达到了0.91的准确率，证明了其在自动化评估方面的有效性。

> **摘要翻译:** 评估是通过各种技术（如口头或口试、主观或客观书面测试）评估和确定教育系统的方法。本文提出了一种高效的电子评估主观答卷的解决方案。在本文中，我们提出并实现了一个检查和评估书面答卷的集成系统。本文重点关注从答卷中查找关键词，然后将其与从开放域和封闭域解析的关键词进行比较。该系统还检查答卷中的语法和拼写错误。我们提出的系统在100名学生的答卷上进行了测试，并给出了0.91的准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [398] [Optimising 4th-Order Runge-Kutta Methods: A Dynamic Heuristic Approach for Efficiency and Low Storage](https://arxiv.org/abs/2506.21465)
> *优化四阶龙格-库塔方法：一种提高效率和降低存储的动态启发式方法*

*Gavin Lee Goodship, Luis Miralles-Pechuan, Stephen O'Sullivan* | **Category: cs.LG, cs.AI**

**Keywords:** 龙格-库塔方法, 启发式优化, 遗传算法, 强化学习, 计算效率

**Comment:** 

> **TL;DR:** 本研究提出一种结合遗传算法和强化学习的混合方法，用于自动发现启发式规则，以优化低存储的四阶Runge-Kutta方法，显著提高计算效率并保持精度，超越了传统方法。

**AI_Comments:** 这项研究通过结合遗传算法和强化学习，为数值方法的启发式优化提供了一个创新的自动化范式。它克服了传统手动设计或穷举搜索的局限性，在提高计算效率的同时保持了高精度，对于大规模科学和工程模拟具有重要意义。该方法在资源效率方面的提升，特别是25%的运行时减少，展示了其在实际应用中的巨大潜力。此外，它为未来结合深度强化学习和AutoML的启发式搜索奠定了基础，具有前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 扩展稳定性龙格-库塔（ESRK）方法在解决大规模计算问题中至关重要，但平衡精度、稳定性和计算效率，特别是对于高阶、低存储方案，仍然是一个挑战。传统方法依赖于手动设计的启发式或穷举数值搜索，效率低下。

**Method:** 本研究引入了一种混合遗传算法（GA）和强化学习（RL）的方法，用于自动化启发式发现，以优化低存储的ESRK方法。该方法利用GA驱动的变异进行搜索空间探索，并采用受RL启发的状态转换机制动态改进启发式选择，从而实现系统性地减少参数，同时保持四阶精度。

**Result:** 最佳启发式方法在IPOPT运行时方面比传统ESRK优化过程减少了25%，同时保持了数值稳定性和精度。

**Conclusion:** 自适应启发式发现能够显著提高高精度模拟的资源效率，并扩大低存储Runge-Kutta方法在实际应用中的适用性。这项工作为数值方法的启发式优化建立了新范式，并为未来探索开辟了途径。

> **ai_Abstract:** 本文提出一种新颖的混合遗传算法（GA）和强化学习（RL）方法，用于优化低存储的四阶Runge-Kutta（ESRK）方法，以解决大规模计算中平衡精度、稳定性与效率的挑战。该方法通过GA进行搜索空间探索，并利用RL动态优化启发式规则，实现了参数的系统性减少，同时保持四阶精度。实验结果表明，该方法使计算运行时减少了25%，显著提高了效率，并为数值方法的启发式优化开辟了新途径。

> **摘要翻译:** 扩展稳定性龙格-库塔（ESRK）方法对于解决科学和工程中的大规模计算问题至关重要，包括天气预报、气动分析和复杂的生物建模。然而，平衡精度、稳定性与计算效率仍然是一个挑战，特别是对于高阶、低存储方案。本研究引入了一种混合遗传算法（GA）和强化学习（RL）方法，用于自动化启发式发现，以优化低存储的ESRK方法。与依赖手动设计启发式或穷举数值搜索的传统方法不同，我们的方法利用GA驱动的变异进行搜索空间探索，并采用受RL启发的状态转换机制动态改进启发式选择。这使得系统性地减少参数成为可能，同时保持四阶精度并显著提高计算效率。所提出的GA-RL启发式优化框架通过对基准问题进行严格测试得到验证，包括一维和二维Brusselator系统以及稳态Navier-Stokes方程。与传统ESRK优化过程相比，性能最佳的启发式方法在IPOPT运行时减少了25%，同时保持了数值稳定性和精度。这些发现证明了自适应启发式发现提高高保真模拟资源效率的潜力，并拓宽了低存储龙格-库塔方法在实际计算流体动力学、物理模拟和其他高要求领域的适用性。这项工作为数值方法的启发式优化建立了新范式，为使用深度强化学习和基于AutoML的启发式搜索开辟了进一步探索的途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [400] [Process mining-driven modeling and simulation to enhance fault diagnosis in cyber-physical systems](https://arxiv.org/abs/2506.21502)
> *基于过程挖掘的建模与仿真以增强信息物理系统故障诊断*

*Francesco Vitale, Nicola Dall'Ora, Sebastiano Gaiardelli, Enrico Fraccaroli, Nicola Mazzocca, Franco Fummi* | **Category: cs.LG, cs.AI**

**Keywords:** 故障诊断, 过程挖掘, 随机仿真, 信息物理系统, 异常检测

**Comment:** 

> **TL;DR:** 本文提出了一种无监督故障诊断方法，结合多元时间序列异常检测、过程挖掘和随机仿真，以解决信息物理系统故障行为手动建模的复杂性，并在机械臂数据集上验证了其有效性。

**AI_Comments:** 该论文提出了一种创新的无监督故障诊断框架，通过结合数据驱动的异常检测、过程挖掘和随机仿真，有效解决了传统手动建模的局限性。其亮点在于将低级传感器数据转化为高层过程模型，并支持动态仿真，这对于理解复杂系统的故障机制具有重要意义。在智能制造和工业物联网背景下，该方法为实现预测性维护和数字孪生提供了有力的技术支持。局限性可能在于对数据质量和事件日志构建的依赖性，以及Petri网模型在极端复杂系统中的可伸缩性。

<details>
  <summary>Details</summary>

**Motivation:** 信息物理系统 (CPS) 中的故障诊断对于确保系统可靠性和运行效率至关重要。然而，手动建模故障行为通常需要大量领域专业知识，并且生成的模型复杂、容易出错且难以解释。本文旨在解决这一挑战。

**Method:** 该方法是一种新颖的无监督故障诊断方法，集成了多元时间序列中的集体异常检测、过程挖掘和随机仿真。首先，利用多元时间序列分析从低级传感器数据中检测集体异常。然后，将这些异常转换为结构化事件日志，通过过程挖掘发现可解释的过程模型。通过将时间分布纳入提取的Petri网，该方法支持故障行为的随机仿真，从而增强了根本原因分析和行为理解。

**Result:** 该方法在机器人臂数据集 (RoAD) 上进行了验证。实验结果表明，该方法在信息物理系统故障行为的建模、仿真和分类方面是有效的。这有助于创建全面的故障字典，支持预测性维护和工业环境数字孪生的开发。

**Conclusion:** 本文提出了一种基于过程挖掘的无监督故障诊断方法，通过集成异常检测、过程挖掘和随机仿真，有效解决了信息物理系统故障行为建模的挑战，并为预测性维护和数字孪生提供了支持。

> **ai_Abstract:** 本文提出了一种新颖的无监督故障诊断方法，旨在解决信息物理系统（CPS）中手动建模故障行为的复杂性。该方法整合了多元时间序列的集体异常检测、过程挖掘和随机仿真。它首先从传感器数据中识别异常，将其转换为事件日志，然后通过过程挖掘发现可解释的Petri网模型，并进行随机仿真以增强根本原因分析。该方法在机器人臂数据集上得到验证，结果显示其在建模、仿真和分类CPS故障行为方面的有效性，支持预测性维护和数字孪生开发。

> **摘要翻译:** 信息物理系统（CPS）中的故障诊断对于通过准确检测异常和识别其根本原因来确保系统可靠性和运行效率至关重要。然而，手动建模故障行为通常需要广泛的领域专业知识，并且产生的模型复杂、容易出错且难以解释。为了解决这一挑战，我们提出了一种新颖的无监督故障诊断方法，该方法集成了多元时间序列中的集体异常检测、过程挖掘和随机仿真。最初，利用多元时间序列分析从低级传感器数据中检测集体异常。然后，将这些异常转换为结构化事件日志，通过过程挖掘发现可解释的过程模型。通过将时间分布纳入提取的Petri网，该方法支持故障行为的随机仿真，从而增强了根本原因分析和行为理解。该方法使用机器人臂数据集（RoAD）（智能制造领域广泛认可的基准）进行了验证。实验结果表明，该方法在信息物理系统故障行为的建模、仿真和分类方面是有效的。这使得能够创建全面的故障字典，支持预测性维护和工业环境数字孪生的开发。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [402] [mTSBench: Benchmarking Multivariate Time Series Anomaly Detection and Model Selection at Scale](https://arxiv.org/abs/2506.21550)
> *mTSBench：大规模多元时间序列异常检测和模型选择基准测试*

*Xiaona Zhou, Constantin Brif, Ismini Lourentzou* | **Category: cs.LG, cs.AI**

**Keywords:** 多元时间序列异常检测, 模型选择, 基准测试, 大型语言模型, 无监督学习

**Comment:** 

> **TL;DR:** mTSBench是一个大规模多元时间序列异常检测和模型选择基准，发现没有单一检测器表现最佳，且现有模型选择方法仍有不足。

**AI_Comments:** mTSBench的创新之处在于其作为迄今为止最大的多元时间序列异常检测基准，并首次将基于大型语言模型的检测器纳入评估范围，这对于推动该领域的发展具有重要意义。该工作揭示了当前异常检测和模型选择方法的局限性，特别是没有“一刀切”的解决方案，且现有模型选择技术仍不理想，为未来的研究指明了方向。其提供的统一评估套件将有助于领域内研究的严谨性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 多元时间序列异常检测在医疗、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖、时间动态和稀疏的异常标签而极具挑战性。

**Method:** 本文引入了mTSBench，这是迄今为止最大的多元时间序列异常检测（MTS-AD）和无监督模型选择基准，涵盖19个数据集和12个不同应用领域的344个带标签时间序列。mTSBench评估了24种异常检测方法，包括基于大型语言模型（LLM）的检测器，并在标准化条件下系统地基准测试了无监督模型选择技术。

**Result:** 研究结果证实没有单一检测器在所有数据集上表现出色，强调了模型选择的重要性。然而，即使是最先进的选择方法也远未达到最优，揭示了关键的不足。

**Conclusion:** mTSBench提供了一个统一的评估套件，旨在实现严谨、可复现的比较，并促进自适应异常检测和鲁棒模型选择的未来发展。

> **ai_Abstract:** 本文介绍了mTSBench，一个迄今为止最大的多元时间序列异常检测（MTS-AD）和无监督模型选择基准。它包含了344个时间序列、19个数据集和12个应用领域，并评估了24种检测方法（包括LLM-based）。研究发现没有单一检测器能普遍表现最佳，且当前的模型选择方法仍有显著提升空间。mTSBench旨在为MTS-AD提供统一、可复现的评估平台，以推动该领域的未来研究。

> **摘要翻译:** 多元时间序列异常检测（MTS-AD）在医疗保健、网络安全和工业监控等领域至关重要，但由于复杂的变量间依赖、时间动态和稀疏的异常标签，仍然极具挑战性。我们引入了mTSBench，这是迄今为止最大的MTS-AD和无监督模型选择基准，涵盖19个数据集和12个不同应用领域的344个带标签时间序列。mTSBench评估了24种异常检测方法，包括基于大型语言模型（LLM）的多元时间序列检测器，并在标准化条件下系统地基准测试了无监督模型选择技术。与先前的研究结果一致，我们的结果证实没有单一检测器在所有数据集上表现出色，强调了模型选择的重要性。然而，即使是最先进的选择方法也远未达到最优，揭示了关键的不足。mTSBench提供了一个统一的评估套件，旨在实现严谨、可复现的比较，并促进自适应异常检测和鲁棒模型选择的未来发展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [404] [Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test](https://arxiv.org/abs/2506.21551)
> *在LLM预训练中何处寻找Grokking？无需测试即可监控从记忆到泛化*

*Ziyue Li, Chenrui Fan, Tianyi Zhou* | **Category: cs.LG**

**Keywords:** Grokking, 大型语言模型, 预训练, 泛化, 通路分析

**Comment:** 

> **TL;DR:** Grokking现象在大型语言模型预训练中存在，且与内部通路结构化和复杂性降低有关，可以通过新指标无需测试进行监控。

**AI_Comments:** 这篇论文的创新之处在于将Grokking现象的研究从小型模型和玩具任务扩展到大规模LLM的预训练阶段，并首次证实了其存在。更重要的是，它深入探讨了Grokking的内部机制，通过分析模型内部的“通路”演变，提供了从记忆到泛化转换的机械性解释。提出的新指标具有重要的实践价值，为LLM预训练提供了一种无需额外测试即可监控泛化能力的方法，这对于优化大型模型训练过程具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** Grokking现象（训练损失收敛后测试性能仍持续提升）在神经网络训练中被发现，使得泛化和推理等新兴能力的机制变得神秘。之前的研究多集中于小型模型和特定任务，缺乏对大型语言模型预训练中Grokking现象的深入研究。

**Method:** 本研究首次在7B大型语言模型（LLM），即OLMoE的一次性预训练检查点上进行Grokking研究。研究计算训练损失并在多种基准任务上评估泛化能力。通过调查LLM内部动态，特别是训练样本的通路（跨层专家选择）演变，来揭示Grokking的机制。此外，开发了两种新颖的指标来量化通路距离和单个通路的复杂性，并验证了它们预测泛化改进的能力。理论上，还证明了更结构化的通路能降低模型复杂性并改善泛化界限。

**Result:** 本研究首次验证了Grokking现象在大规模基础模型预训练中仍然存在，尽管不同数据可能异步进入Grokking阶段。研究发现训练样本的通路从随机、实例特定演变为更结构化和样本间可共享，且样本通路的复杂性在损失收敛后降低，这表明了从记忆到泛化的转换。开发的新指标能够高效、简单地预测不同下游任务上的泛化改进，且仅依赖于训练数据，因此具有在不进行微调和测试的情况下监控泛化性能的实用价值。理论上，更结构化的通路能降低模型复杂性并改善泛化界限。

**Conclusion:** Grokking现象在大型语言模型预训练中普遍存在，其机制在于内部通路从记忆到泛化的转换，表现为通路结构化和复杂性降低。通过新开发的内部指标，可以在不依赖测试的情况下有效监控模型的泛化性能。

> **ai_Abstract:** 本文首次在7B大型语言模型（OLMoE）的预训练过程中研究了Grokking现象，发现它确实存在于大规模基础模型中。研究揭示了Grokking的内部机制：训练样本的通路（专家选择）从随机变为结构化和可共享，且通路复杂性降低，这标志着从记忆到泛化的转变。为监控这一过程，作者提出了两种基于训练数据的新指标，能够有效预测泛化性能，从而实现在不进行微调和测试的情况下监控预训练模型的泛化能力。理论分析也支持了通路结构化对泛化能力的提升作用。

> **摘要翻译:** Grokking，即训练损失收敛后测试性能仍持续提升的现象，最近在神经网络训练中被观察到，这使得泛化以及推理等新兴能力的机制变得神秘。虽然之前的研究通常在少量玩具或高度特定的任务上训练小型模型数千个周期，但我们首次对7B大型语言模型（LLM），即OLMoE，在一次性预训练过程中的检查点上进行了Grokking研究。我们计算了训练损失，并在包括数学推理、代码生成以及常识/领域特定知识检索任务在内的多种基准任务上评估了泛化能力。
我们的研究首次验证了Grokking现象在大规模基础模型预训练中依然发生，尽管不同数据可能异步进入Grokking阶段。我们通过调查LLM的内部动态，进一步揭示了Grokking的“泛化涌现”机制。具体来说，我们发现训练样本的通路（即跨层的专家选择）在Grokking过程中从随机、实例特定演变为更结构化且样本间可共享。此外，尽管损失已收敛，样本通路的复杂性却降低了。这些迹象表明了从记忆到泛化（memorization-to-generalization）的转换，为延迟泛化提供了机制解释。在本研究中，我们开发了两种新颖的指标来量化通路距离和单个通路的复杂性。我们展示了它们预测不同下游任务泛化改进的能力。它们高效、计算简单，且仅依赖于训练数据。因此，它们对预训练具有实用价值，使我们能够在不进行微调和测试的情况下监控泛化性能。理论上，我们证明了更结构化的通路能降低模型复杂性并改善泛化界限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [9] [IMA-Catcher: An IMpact-Aware Nonprehensile Catching Framework based on Combined Optimization and Learning](https://arxiv.org/abs/2506.20801)
> *IMA-Catcher: 基于组合优化与学习的冲击感知非抓取式捕获框架*

*Francesco Tassi, Jianzhuang Zhao, Gustavo J. G. Lahr, Luna Gava, Marco Monforte, Arren Glover, Chiara Bartolozzi, Arash Ajoudani* | **Category: cs.RO**

**Keywords:** 机器人捕获, 冲击感知, 优化, 学习, 非抓取式

**Comment:** 25 pages, 17 figures, accepted by International Journal of Robotics
  Research (IJRR)

> **TL;DR:** 本文提出了IMA-Catcher，一个冲击感知的机器人捕获框架，通过优化和学习在捕获前减少冲击力，并在捕获后平稳耗散能量，以应对高速捕获中产生的高冲击问题。

**AI_Comments:** 该论文创新性地结合了优化和学习方法来解决机器人高速捕获中的核心问题——冲击力。通过在捕获前阶段进行速度匹配优化和在捕获后阶段引入反射质量最小化，有效降低了冲击并提高了系统稳定性。其分层控制器的设计也考虑了实际机器人约束，增强了实用性。该研究对于开发更鲁棒、更安全的机器人捕获系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人捕获飞行物体时会产生高冲击力，可能导致任务失败和潜在的硬件损坏，尤其是在物体质量与机器人有效载荷比增加时。

**Method:** 本文提出了一个隐式冲击感知框架，分为捕获前和捕获后两个阶段。在捕获前阶段，一个实时最优规划器生成末端执行器轨迹，旨在最小化机器人与物体之间的速度差以减少冲击力。在捕获后阶段，基于人类演示生成机器人的位置、速度和刚度轨迹，用于捕获未知质量的自由落体物体。同时，使用一个分层二次规划控制器来强制执行机器人的关节和扭矩限制，并将最小化末端执行器反射质量作为次要目标。实验首先在一维环境中进行，以研究各贡献的影响，然后通过增加捕获高度来评估方法的鲁棒性，最后扩展到多维笛卡尔轴捕获，以证明其泛化能力。

**Result:** 实验结果表明，在没有速度匹配的情况下，任务会因冲击导致的关节扭矩过大而不可行。该方法通过加入反射质量最小化，并在增加捕获高度的情况下，证明了其鲁棒性。最终，该设置扩展到多维笛卡尔轴捕获，证明了其在空间中的泛化能力。

**Conclusion:** 本文提出的IMA-Catcher框架通过结合优化和学习，有效解决了机器人捕获中的高冲击力问题，提高了捕获任务的成功率和安全性。

> **ai_Abstract:** 本文提出IMA-Catcher，一个基于优化与学习的冲击感知非抓取式机器人捕获框架，旨在解决高速捕获中高冲击力导致的任务失败和硬件损坏问题。该框架在捕获前通过优化速度匹配来减少冲击力，在捕获后利用人类演示和分层二次规划控制器平稳耗散能量并最小化反射质量。实验证明，该方法有效降低了冲击，提高了捕获的鲁棒性和泛化性。

> **摘要翻译:** 机器人捕获飞行物体通常会产生高冲击力，这可能导致任务失败和潜在的硬件损坏。当物体质量与机器人有效载荷之比增加时，考虑到表征此任务的强大惯性分量，这一点尤为突出。本文旨在通过提出一种隐式冲击感知框架来解决这个问题，该框架在捕获前和捕获后阶段都能完成捕获任务。在第一阶段，运动规划器生成最小化捕获力的最优轨迹，而在第二阶段，物体的能量被平稳耗散，从而最大程度地减少反弹。特别是在捕获前阶段，实时最优规划器负责生成末端执行器的轨迹，该轨迹最小化机器人与物体之间的速度差，以减少捕获期间的冲击力。在捕获后阶段，机器人的位置、速度和刚度轨迹是根据人类演示生成的，用于捕获一系列未知质量的自由落体物体。分层二次规划控制器用于强制执行机器人的约束（即关节和扭矩限制），并创建一系列任务，将末端执行器的反射质量最小化作为次要目标。初步实验将问题隔离到一维，以准确研究每个贡献对所提出指标的影响。我们展示了在没有速度匹配的情况下，由于冲击导致的关节扭矩过大，同一任务将变得不可行。然后研究了反射质量最小化的加入，并增加了捕获高度以评估方法的鲁棒性。最后，设置扩展到沿多个笛卡尔轴的捕获，以证明其在空间中的泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [34] [Online Planning for Cooperative Air-Ground Robot Systems with Unknown Fuel Requirements](https://arxiv.org/abs/2506.20804)
> *具有未知燃料需求的空地机器人协同系统在线规划*

*Ritvik Agarwal, Behnoushsadat Hatami, Alvika Gautam, Parikshit Maini* | **Category: cs.RO**

**Keywords:** 在线规划, 空地机器人系统, 燃料受限无人机, 移动加油站, 动态调整

**Comment:** Submitted to RSS (MRS Workshop)

> **TL;DR:** 提出一种在线规划方法，用于解决空地机器人协同系统中，无人机在未知燃料成本下进行任务，并通过地面移动加油站补给的问题，通过两阶段方案和在线算法动态调整加油点，仿真验证了可行性。

**AI_Comments:** 该研究的创新点在于提出了一个两阶段的在线规划方法，特别是在线算法能够根据实时燃料消耗动态调整汇合点，有效应对了未知燃料成本的挑战。这种动态调整能力对于实际应用中的鲁棒性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 解决燃料受限的无人机路径规划问题，特别是当目标燃料成本未知时，需要一个在线规划方案来动态调整空中无人机和地面加油站的汇合点。

**Method:** 采用两阶段解决方案：首先，一个离线启发式规划器计算初始无人机（UAV）和地面车辆（UGV）路径；其次，一个新颖的在线规划算法根据目标处理期间的实时燃料消耗动态调整汇合点。

**Result:** 初步的Gazebo仿真结果表明，所提出的方法在保持无人机-地面车辆路径有效性、确保任务完成方面是可行的。

**Conclusion:** 该研究成功开发并验证了一种在线规划方法，能够有效解决具有未知燃料需求的空地机器人协同系统的燃料补给和任务完成问题。

> **ai_Abstract:** 本文提出了一种针对空地机器人协同系统的在线规划方法，以解决燃料受限无人机路由问题中目标燃料成本未知的情况。该方法包含一个离线启发式规划器用于初始路径规划，以及一个新颖的在线算法根据实时燃料消耗动态调整无人机与地面加油站的汇合点。初步的Gazebo仿真验证了该方法在维持路径有效性和确保任务完成方面的可行性。

> **摘要翻译:** 我们考虑了燃料受限无人机路径规划问题（FCURP-MRS）的一个在线变体，其中包含一个地面移动加油站，且目标会产生未知的燃料成本。我们开发了一个两阶段解决方案：一个离线启发式规划器计算初始无人机和地面车辆路径，以及一个新颖的在线规划算法，根据目标处理期间的实时燃料消耗动态调整汇合点。初步的Gazebo仿真演示了我们方法在保持无人机-地面车辆路径有效性、确保任务完成方面的可行性。视频链接：https://youtu.be/EmpVj-fjqNY

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [58] [Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection](https://arxiv.org/abs/2506.20812)
> *基于模型的使用激光雷达进行无人机输电线路姿态和弧垂实时估计*

*Alexandre Girard, Steven A. Parkison, Philippe Hamelin* | **Category: cs.RO, cs.CV**

**Keywords:** 激光雷达, 无人机检测, 输电线路, 姿态估计, 弧垂估计

**Comment:** Submitted to IEEE case 2025

> **TL;DR:** 提出一种基于模型的激光雷达估计方法，用于无人机输电线路的实时姿态和弧垂估计，解决了传统方法中对单个导线跟踪的挑战，实现快速准确的定位。

**AI_Comments:** 这篇论文通过引入一个单一的几何模型来表示整个导线阵列，而不是单独跟踪每根导线，提供了一种创新的方法来解决无人机激光雷达输电线路检测中的关键挑战。这种模型驱动的方法提高了在稀疏和噪声数据下的鲁棒性和效率，对于实时应用至关重要。其在处理异常值方面的能力也显著增强了实际部署的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 使用无人机载激光雷达传感器定位输电线路面临多项挑战：导线反射面小导致点云数据有限；并非所有导线都能被稳定检测；以及难以区分导线与其他物体（如树木和电线杆）的激光雷达点。

**Method:** 提出一种估计方法，通过最小化激光雷达测量值与代表整个导线阵列的单一几何模型之间的误差，而不是单独跟踪每根导线。

**Result:** 该方法实现了准确的跟踪，求解器在每帧50毫秒内收敛，即使在存在部分观测、噪声和异常值的情况下也能表现良好。敏感性分析表明，该估计方法可以容忍多达两倍于有效导线测量值的异常点。

**Conclusion:** 该研究提出了一种新颖的基于模型的估计方法，有效解决了无人机激光雷达输电线路检测中的挑战，实现了实时、准确和鲁棒的姿态和弧垂估计。

> **ai_Abstract:** 本文提出一种新颖的基于模型的估计方法，旨在解决使用无人机载激光雷达传感器进行输电线路姿态和弧垂估计时的挑战。该方法通过将激光雷达测量值与表示整个导线阵列的单一几何模型进行匹配来最小化误差，从而避免了对单根导线的独立跟踪。实验结果表明，该方法能够实现准确且实时的跟踪，即使在存在噪声、异常值和不完整数据的情况下，求解器也能快速收敛，并且对异常点具有很高的容忍度。

> **摘要翻译:** 无人机可以在输电线路带电时进行检查，大大简化了检查过程。然而，使用机载激光雷达传感器相对于所有导线定位无人机存在几个挑战：（1）导线为激光雷达光束提供的表面很小，限制了扫描中导线点的数量；（2）并非所有导线都能被持续检测到；（3）难以区分对应于导线的激光雷达点与其他物体（如树木和电线杆）的激光雷达点。本文提出了一种估计方法，通过最小化激光雷达测量值与代表整个导线阵列的单一几何模型之间的误差，而不是单独跟踪每根导线。使用输电线路无人机检查数据进行的实验结果表明，该方法实现了准确的跟踪，求解器在每帧50毫秒内收敛，即使在存在部分观测、噪声和异常值的情况下也能表现良好。敏感性分析表明，该估计方法可以容忍多达两倍于有效导线测量值的异常点。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [83] [Cooperative Circumnavigation for Multi-Quadrotor Systems via Onboard Sensing](https://arxiv.org/abs/2506.20954)
> *多旋翼系统基于机载感知的协同环绕飞行*

*Xueming Liu, Lin Li, Xiang Zhou, Qingrui Zhang, Tianjiang Hu* | **Category: cs.RO**

**Keywords:** 多旋翼系统, 协同环绕, 机载感知, 卡尔曼滤波, 容错性

**Comment:** 8 Pages, 7 figures. Accepted by RA-L

> **TL;DR:** 本文提出了一种多旋翼系统协同环绕框架，利用机载感知技术实现对移动目标的跟踪和包围，无需外部定位系统，并在遮挡环境下表现出鲁棒性和容错性。

**AI_Comments:** 本文的创新之处在于提出了一种不依赖外部定位的协同环绕框架，并在遮挡环境下验证了其鲁棒性。特别是在状态估计方面，结合了改进的卡尔曼滤波和事件触发的分布式卡尔曼滤波，有效处理了相对定位和目标估计问题。此外，其展示的容错性增加了实际部署的可靠性，对于搜救等应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决多旋翼系统在不依赖外部定位系统的情况下，对移动目标进行协同环绕跟踪的挑战，特别是在视觉遮挡和系统部分故障的复杂环境中。

**Method:** 采用异构感知策略评估旋翼-旋翼和旋翼-目标交互关系；开发改进的卡尔曼滤波器融合视觉-惯性里程计和距离测量以提高旋翼间相对定位精度；设计事件触发的分布式卡尔曼滤波器结合邻居测量和估计的相对位置，在视觉遮挡下实现鲁棒的目标状态估计；构建基于振荡器自主编队飞行策略的协同环绕控制器。

**Result:** 通过广泛的室内外实验验证了所提出环绕框架在遮挡环境中的高效性；通过旋翼故障实验，突出显示了该框架固有的容错特性。

**Conclusion:** 所提出的协同环绕框架能够使多旋翼系统在不依赖外部定位系统的情况下，有效且鲁棒地包围和跟踪移动目标，即使在视觉遮挡和部分系统故障的情况下也能保持性能，展现了在搜救行动中的潜在应用价值。

> **ai_Abstract:** 本文提出了一种创新的多旋翼系统协同环绕框架，该框架不依赖外部定位系统，通过异构感知、改进的卡尔曼滤波器和事件触发的分布式卡尔曼滤波器实现对移动目标的鲁棒跟踪和包围。它利用基于振荡器的编队策略进行控制，并通过实验证明了其在遮挡环境下的高效性和固有的容错性，预示了其在搜救等领域的应用前景。

> **摘要翻译:** 本文提出了一种多旋翼系统协同环绕框架，用于包围和跟踪移动目标，无需依赖外部定位系统。利用异构感知策略和相应的状态估计算法，评估了旋翼-旋翼和旋翼-目标交互之间的独特关系。开发了一种改进的卡尔曼滤波器，融合视觉-惯性里程计与距离测量，以提高旋翼间相对定位的精度。设计了一种事件触发的分布式卡尔曼滤波器，通过结合邻居测量和估计的旋翼间相对位置，在视觉遮挡下实现鲁棒的目标状态估计。利用估计结果，构建了一个协同环绕控制器，利用基于振荡器的自主编队飞行策略。我们进行了广泛的室内外实验，以验证所提出的环绕框架在遮挡环境中的效率。此外，一项旋翼故障实验突出了所提出框架固有的容错特性，强调了其在搜救行动中的部署潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [107] [Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends](https://arxiv.org/abs/2506.20966)
> *VLA模型后训练与人类运动学习的并行：进展、挑战与趋势*

*Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duan, Fu-Chao Xie, Wen-Kai Wang, Si-Cheng Wang, Ling-Yun Li, Tian Tu, Zeng-Guang Hou* | **Category: cs.RO, cs.AI**

**Keywords:** VLA模型, 后训练, 人类运动学习, 机器人操作, 分类法

**Comment:** 

> **TL;DR:** 本文从人类运动学习的角度综述了VLA模型后训练策略，并提出了一个分类法，以指导未来研究。

**AI_Comments:** 本文的创新之处在于将VLA模型的后训练与人类运动学习进行类比，提供了一个新颖且直观的视角来理解和分类VLA模型的适应性策略。这种跨领域的方法有助于系统化地分析现有方法，并为未来的研究指明方向。其提出的分类法具有很强的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** VLA模型在复杂操作任务中展现出泛化能力，但在需要高精度和准确性的应用中存在性能差距。后训练对于使基础模型与下游应用对齐至关重要，这类似于人类运动技能习得的过程。

**Method:** 本文从人类运动学习的角度，通过环境、具身和任务三个维度，回顾了VLA模型的后训练策略。引入了一个与人类学习机制对齐的结构化分类法，包括：(1) 增强环境感知，(2) 提高具身意识，(3) 深化任务理解，以及 (4) 多组件集成。

**Result:** 本文识别了VLA模型后训练中的关键挑战和趋势，并建立了一个概念框架以指导未来的研究。

**Conclusion:** 这项工作提供了从人类运动学习视角对当前VLA模型后训练方法的全面概述，以及对VLA模型开发的实用见解。

> **ai_Abstract:** 本文综述了视觉-语言-动作 (VLA) 模型的后训练策略，旨在弥补其在精度方面的不足。作者从人类运动学习的角度，通过环境、具身和任务三个维度进行分析，并提出了一个结构化分类法。该研究识别了VLA后训练的挑战和趋势，为未来研究提供了概念框架和实用见解。

> **摘要翻译:** 视觉-语言-动作 (VLA) 模型通过整合用于机器人操作的动作生成模块，扩展了视觉-语言模型 (VLM)。VLA 模型利用 VLM 在视觉感知和指令理解方面的优势，在各种操作任务中展现出有前景的泛化能力。然而，需要高精度和准确性的应用在没有进一步适应的情况下会暴露出性能差距。来自多个领域的证据强调了后训练在使基础模型与下游应用对齐方面的关键作用，这促进了对后训练 VLA 模型的广泛研究。VLA 模型后训练旨在解决如何提高具身对给定任务与环境交互能力的问题，这类似于人类运动技能习得的过程。因此，本文从人类运动学习的角度，通过环境、具身和任务三个维度，回顾了 VLA 模型的后训练策略。引入了一个与人类学习机制对齐的结构化分类法：(1) 增强环境感知，(2) 提高具身意识，(3) 深化任务理解，以及 (4) 多组件集成。最后，识别了 VLA 模型后训练中的关键挑战和趋势，建立了一个概念框架以指导未来的研究。这项工作提供了从人类运动学习视角对当前 VLA 模型后训练方法的全面概述，以及对 VLA 模型开发的实用见解。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [128] [ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation](https://arxiv.org/abs/2506.20969)
> *ThermalDiffusion：用于自主导航的视觉到热图像到图像转换*

*Shruti Bansal, Wenshan Wang, Yifei Liu, Parv Maheshwari* | **Category: cs.RO, cs.CV**

**Keywords:** ThermalDiffusion, 图像到图像转换, 热图像, 自主导航, 扩散模型

**Comment:** Accepted at Thermal Infrared in Robotics (TIRO) Workshop, ICRA 2025

> **TL;DR:** 该论文提出了一种使用条件扩散模型将RGB图像转换为热图像的方法，以解决自主系统中热图像数据不足的问题，从而增强多模态数据集。

**AI_Comments:** 该论文的创新点在于利用条件扩散模型进行视觉到热图像的转换，以解决热图像数据稀缺的痛点。这对于推动热像仪在全天候自主导航中的应用具有重要意义，尤其是在数据驱动的深度学习时代。其方法通过合成数据来增强现有数据集，提供了一个实用的解决方案，有望加速相关技术的发展和部署。

<details>
  <summary>Details</summary>

**Motivation:** 自主系统依赖传感器感知环境，但现有相机、激光雷达和雷达在夜间或恶劣环境下存在局限性。热像仪能提供有价值的信息，但机器人和自动化领域缺乏足够的热图像数据。现有针对自动驾驶的多模态数据集也缺乏热图像，这阻碍了热像仪的广泛应用。

**Method:** 本文提出使用条件扩散模型，利用自注意力机制学习真实世界物体的热特性，将现有RGB图像转换为热图像，从而合成热数据来扩充数据集。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本论文提出“ThermalDiffusion”方法，旨在解决自主导航系统中热图像数据不足的问题。针对现有传感器在恶劣环境下的局限性以及多模态数据集中热图像的缺乏，研究者利用条件扩散模型，结合自注意力机制，将RGB图像转换为合成热图像，以扩充现有数据集，从而促进热像仪在机器人和自动化领域的广泛应用。

> **摘要翻译:** 自主系统依赖传感器来估计周围环境。然而，相机、激光雷达和雷达都有其自身的局限性。在夜间或恶劣环境，如雾、薄雾或灰尘中，热像仪由于物体的热特征，可以提供关于感兴趣物体存在的宝贵信息。它们使得识别通常比周围环境温度更高的人类和车辆变得容易。在本文中，我们专注于热像仪在机器人和自动化领域的应用，其中最大的障碍是数据的缺乏。有几个多模态数据集可用于自动驾驶机器人研究，涉及场景分割、目标检测和深度估计等任务，这些是自主系统的基石。然而，这些数据集被发现缺乏热图像。我们的论文提出了一种解决方案，通过合成热数据来增强这些数据集，以实现热像仪的广泛和快速适应。我们探索了使用条件扩散模型，利用自注意力机制学习真实世界物体的热特性，将现有RGB图像转换为热图像。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [146] [Fault-Tolerant Spacecraft Attitude Determination using State Estimation Techniques](https://arxiv.org/abs/2506.21016)
> *容错航天器姿态确定中的状态估计算法*

*B. Chidambaram, A. Hilbert, M. Silva* | **Category: cs.RO, cs.SY, eess.SY**

**Keywords:** 姿态确定, 容错, 卡尔曼滤波, 粒子滤波, 故障检测

**Comment:** 8 pages, 19 figures

> **TL;DR:** 本文探讨了扩展卡尔曼滤波、无迹卡尔曼滤波和粒子滤波在航天器容错姿态估计中的性能，并分析了基于这些滤波器的故障检测、隔离和恢复技术。

**AI_Comments:** 该研究通过评估多种状态估计算法在容错航天器姿态确定中的表现，并结合故障检测、隔离和恢复技术，为航天器在复杂故障环境下的可靠运行提供了重要的技术分析。其创新点在于将成熟的滤波技术应用于航天器故障容错场景，并详细分析了其在不同故障模式下的性能。

<details>
  <summary>Details</summary>

**Motivation:** 为航天器提供一个鲁棒的容错姿态估计框架。

**Method:** 采用扩展卡尔曼滤波 (EKF)、无迹卡尔曼滤波 (UKF) 和粒子滤波 (PF) 进行姿态估计，并在此基础上分析了用于故障检测、隔离和恢复的各种技术。

**Result:** 分析的关键结果包括各种故障模式下滤波器的性能。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了扩展卡尔曼滤波、无迹卡尔曼滤波和粒子滤波在大型低轨卫星容错姿态估计中的应用。研究分析了这些滤波器在不同故障模式下的性能，并探讨了基于这些滤波器实现的故障检测、隔离和恢复技术。

> **摘要翻译:** 扩展卡尔曼滤波、无迹卡尔曼滤波和粒子滤波为航天器容错姿态估计提供了一个鲁棒的框架。本文探讨了每种滤波器在低地球轨道大型卫星上的性能。此外，还分析了基于这些滤波器构建的各种用于从错误传感器测量中进行故障检测、隔离和恢复的技术。此分析的关键结果包括各种故障模式下滤波器的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [163] [STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner](https://arxiv.org/abs/2506.21030)
> *STEP Planner：构建跨层级子目标树作为具身长周期任务规划器*

*Zhou Tianxing, Wang Zhirui, Ao Haojia, Chen Guangyan, Xing Boyang, Cheng Jingwen, Yang Yi, Yue Yufeng* | **Category: cs.RO**

**Keywords:** 长周期任务规划, 具身智能, 子目标树, 大型语言模型, 机器人规划

**Comment:** 

> **TL;DR:** STEP Planner通过构建跨层级子目标树，解决了LLM在长周期具身任务规划中成功率低的问题，并在虚拟和真实机器人实验中取得了优于SOTA的性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合LLM和实时反馈的闭环系统，通过构建层级子目标树来应对具身长周期任务规划的挑战。其通过子目标分解和叶节点终止的协同作用，有效地弥补了LLM在复杂推理上的不足，并实现了可观的性能提升，对于具身AI领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在现实世界环境中部署机器人需要可靠的长周期任务规划能力。然而，直接使用大型语言模型（LLMs）作为动作序列生成器，由于其对长周期具身任务推理能力的限制，通常导致成功率较低。

**Method:** STEP框架通过一对闭环模型构建子目标树：一个子目标分解模型和一个叶节点终止模型。该框架开发了一个从粗到细的层级树结构。子目标分解模型利用基础LLM将复杂目标分解为可管理的子目标，从而扩展子目标树。叶节点终止模型根据环境状态提供实时反馈，决定何时终止树的扩展，并确保每个叶节点可以直接转换为原始动作。

**Result:** 在VirtualHome WAH-NL基准测试和真实机器人上进行的实验表明，STEP在长周期具身任务完成方面取得了高达34%（WAH-NL）和25%（真实机器人）的成功率，优于现有最先进（SOTA）的方法。

**Conclusion:** STEP Planner通过构建跨层级子目标树，有效提升了机器人在长周期具身任务中的规划成功率，解决了LLM在该领域应用中的局限性，并展现出超越现有方法的性能。

> **ai_Abstract:** STEP Planner提出了一种用于具身长周期任务规划的新方法，通过构建一个跨层级子目标树来解决传统LLM在处理此类任务时成功率低的问题。该框架包含一个利用LLM进行子目标分解的模型和一个基于环境反馈的叶节点终止模型，形成闭环控制，确保子目标可执行。实验结果表明，STEP在虚拟和真实机器人环境中均显著提高了长周期任务的完成成功率，超越了现有最先进的方法。

> **摘要翻译:** 可靠的长周期任务规划能力对于在现实世界环境中部署机器人至关重要。然而，直接使用大型语言模型（LLMs）作为动作序列生成器，由于其对长周期具身任务推理能力的限制，通常导致成功率较低。在STEP框架中，我们通过一对闭环模型构建子目标树：一个子目标分解模型和一个叶节点终止模型。在此框架内，我们开发了一个从粗到细的层级树结构。子目标分解模型利用基础LLM将复杂目标分解为可管理的子目标，从而扩展子目标树。叶节点终止模型根据环境状态提供实时反馈，决定何时终止树的扩展，并确保每个叶节点可以直接转换为原始动作。在VirtualHome WAH-NL基准测试和真实机器人上进行的实验表明，STEP在长周期具身任务完成方面取得了高达34%（WAH-NL）和25%（真实机器人）的成功率，优于现有最先进（SOTA）的方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [180] [V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](https://arxiv.org/abs/2506.21041)
> *V2X-REALM：基于视觉语言模型的鲁棒端到端协同自动驾驶与自适应长尾建模*

*Junwei You, Pei Li, Zhuoyu Jiang, Zilin Huang, Rui Gan, Haotian Shi, Bin Ran* | **Category: cs.RO, cs.AI, cs.CV**

**Keywords:** 协同自动驾驶, 长尾场景, 视觉语言模型, 鲁棒性, 端到端

**Comment:** 

> **TL;DR:** V2X-REALM是一个基于视觉语言模型的框架，通过引入场景生成、自适应注意力模块和对比学习，显著提升了协同自动驾驶在长尾复杂场景下的鲁棒性和性能。

**AI_Comments:** V2X-REALM的创新性在于其结合了视觉语言模型，并针对长尾场景提出了多方面的解决方案，包括利用基础模型进行场景生成，以及通过自适应注意力和对比学习来增强特征处理和对齐。这对于提高自动驾驶在复杂和不常见条件下的性能和安全性具有重要意义，尤其是在协同自动驾驶领域。

<details>
  <summary>Details</summary>

**Motivation:** 在城市环境中，自动驾驶车辆在稀有、多样且视觉退化的长尾场景下，确保鲁棒的规划和决策仍然是一个基本挑战。在协同设置中，车辆和基础设施共同感知和推理复杂环境时，这个问题变得更加关键。

**Method:** 本文提出了V2X-REALM，一个基于视觉语言模型（VLM）的框架，该框架采用自适应多模态学习，以实现长尾场景下鲁棒的协同自动驾驶。V2X-REALM引入了三个核心创新点：1) 一个提示驱动的长尾场景生成和评估流程，利用基础模型合成真实的（如雪、雾）长尾条件，以丰富训练多样性；2) 一个门控多场景自适应注意力模块，利用场景先验调节视觉流以重新校准模糊或损坏的特征；3) 一个多任务场景感知对比学习目标，以改善多模态对齐并促进跨场景特征可分离性。

**Result:** 大量实验表明，V2X-REALM在复杂、具有挑战性的驾驶条件下，在鲁棒性、语义推理、安全性以及规划精度方面显著优于现有基线。

**Conclusion:** V2X-REALM提升了端到端协同自动驾驶的可扩展性。

> **ai_Abstract:** V2X-REALM是一个针对协同自动驾驶中长尾场景挑战提出的视觉语言模型（VLM）框架。它通过提示驱动的场景生成、门控多场景自适应注意力模块和多任务场景感知对比学习这三大创新，有效解决了稀有和视觉退化场景下的鲁棒性问题。实验证明，V2X-REALM在鲁棒性、语义推理、安全性和规划精度方面均显著优于现有方法，提升了端到端协同自动驾驶的可扩展性。

> **摘要翻译:** 确保在稀有、多样和视觉退化的长尾场景下鲁棒的规划和决策，仍然是城市环境中自动驾驶面临的一个基本挑战。在协同设置中，当车辆和基础设施在复杂环境中共同感知和推理时，这个问题变得更加关键。为了解决这一挑战，我们提出了V2X-REALM，一个基于视觉语言模型（VLM）的框架，该框架采用自适应多模态学习，以实现长尾场景下鲁棒的协同自动驾驶。V2X-REALM引入了三个核心创新点：(i) 一个提示驱动的长尾场景生成和评估流程，该流程利用基础模型合成真实的（如雪和雾）长尾条件，涵盖车辆端和基础设施端视图，从而有效丰富训练多样性；(ii) 一个门控多场景自适应注意力模块，该模块利用场景先验来调节视觉流，以重新校准模糊或损坏的特征；(iii) 一个多任务场景感知对比学习目标，该目标改善了多模态对齐并促进了跨场景特征的可分离性。大量实验表明，V2X-REALM在复杂、具有挑战性的驾驶条件下，在鲁棒性、语义推理、安全性以及规划精度方面显著优于现有基线，从而提升了端到端协同自动驾驶的可扩展性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [195] [Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions](https://arxiv.org/abs/2506.21057)
> *知识驱动的模仿学习：实现跨多样化条件的泛化*

*Zhuochen Miao, Jun Lv, Hongjie Fang, Yang Jin, Cewu Lu* | **Category: cs.RO**

**Keywords:** 模仿学习, 知识驱动, 泛化, 机器人操作, 语义关键点图

**Comment:** IROS 2025

> **TL;DR:** 本文提出了一种知识驱动的模仿学习框架，通过利用外部结构化语义知识来提高机器人操作的泛化能力和数据效率。

**AI_Comments:** 这项工作通过引入外部语义知识和创新的语义关键点图，有效解决了模仿学习中泛化能力和数据效率的挑战。其在仅需少量专家演示的情况下超越了现有方法，并在多样化条件下表现出鲁棒性，这对于实际机器人部署具有重要意义。该研究为知识驱动的机器人学习奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 模仿学习在机器人操作中表现强大，但其泛化能力受限于有限专家演示中对特定对象的依赖。

**Method:** 本文提出了知识驱动的模仿学习框架，该框架利用外部结构化语义知识来抽象同一类别内的对象表示。具体地，引入了一种新颖的语义关键点图作为知识模板，并开发了一种粗到细的模板匹配算法，该算法优化了结构一致性和语义相似性。

**Result:** 在三项真实世界机器人操作任务中，该方法取得了卓越的性能，仅用四分之一的专家演示就超越了基于图像的扩散策略。广泛的实验进一步证明了其在新型对象、背景和光照条件下的鲁棒性。

**Conclusion:** 这项工作开创了一种知识驱动的方法，用于在真实世界环境中实现数据高效的机器人学习。

> **ai_Abstract:** 本文提出了一种名为“知识驱动的模仿学习”的新框架，旨在解决传统模仿学习在机器人操作中泛化能力受限的问题。该方法利用外部结构化语义知识，通过引入语义关键点图作为知识模板和开发粗到细的模板匹配算法，实现了对同一类别内对象表示的抽象。实验证明，该方法在真实世界机器人任务中表现优越，显著减少了所需的专家演示数量，并展现出对新对象、背景和光照条件的强大鲁棒性，为数据高效的机器人学习开辟了新途径。

> **摘要翻译:** 模仿学习已成为机器人操作中一种强大的范式，但其泛化能力仍受限于有限专家演示中的对象特定依赖。为了解决这一挑战，我们提出了知识驱动的模仿学习，一个利用外部结构化语义知识来抽象同一类别内对象表示的框架。我们引入了一种新颖的语义关键点图作为知识模板，并开发了一种粗到细的模板匹配算法，该算法优化了结构一致性和语义相似性。在三项真实世界机器人操作任务中进行评估，我们的方法取得了卓越的性能，仅用四分之一的专家演示就超越了基于图像的扩散策略。广泛的实验进一步证明了其在新型对象、背景和光照条件下的鲁棒性。这项工作开创了一种知识驱动的方法，用于在真实世界环境中实现数据高效的机器人学习。代码和更多材料可在 https://knowledge-driven.github.io/ 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [209] [Control of Marine Robots in the Era of Data-Driven Intelligence](https://arxiv.org/abs/2506.21063)
> *数据驱动智能时代海洋机器人的控制*

*Lin Hong, Lu Liu, Zhouhua Peng, Fumin Zhang* | **Category: cs.RO**

**Keywords:** 海洋机器人, 数据驱动控制, 机器学习, 控制策略, 自主性

**Comment:** 

> **TL;DR:** 本文回顾了数据驱动智能时代海洋机器人控制的最新进展，旨在为下一代控制框架提供路线图，以克服传统方法的局限性。

**AI_Comments:** 这篇论文通过系统回顾数据驱动智能在海洋机器人控制中的应用，填补了传统控制方法在复杂海洋环境下的局限性，具有重要的指导意义。其创新之处在于将机器学习范式引入海洋机器人控制，并提供了全面的现状分析和未来展望，对该领域的研究具有重要的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于模型的海洋机器人控制方法因机器人动力学的非线性、不确定性以及海洋环境的复杂性而暴露出局限性。机器学习的快速发展为将数据驱动智能融入控制策略提供了新途径，促使海洋机器人控制范式转变。

**Method:** 本文通过回顾数据驱动智能这一新兴范式，综述了海洋机器人控制的最新进展。内容涵盖个体和协同海洋机器人系统，并总结了支持高级控制方法开发和验证的开源资源。

**Result:** 综述了数据驱动智能在海洋机器人控制方面的显著成就，涵盖个体和协同系统，并总结了相关开源资源。提出了未来展望，以指导实现海洋机器人在实际应用中的高级自主性。

**Conclusion:** 本文旨在为数据驱动智能时代海洋机器人的下一代控制框架提供一份路线图，以期实现海洋机器人在实际应用中的高水平自主性。

> **ai_Abstract:** 本文回顾了数据驱动智能在海洋机器人控制领域的最新进展，旨在应对传统基于模型方法在处理非线性、不确定性和复杂海洋环境方面的局限性。该综述涵盖了数据驱动控制在个体和协同海洋机器人系统中的显著成就，并总结了相关开源资源。文章还提出了未来研究方向，旨在为实现海洋机器人在实际应用中的高水平自主性提供路线图。

> **摘要翻译:** 海洋机器人的控制长期以来一直依赖于基于模型的方法，这些方法以经典和现代控制理论为基础。然而，机器人动力学固有的非线性和不确定性，加上海洋环境的复杂性，已经揭示了传统控制方法的局限性。机器学习的快速发展为将数据驱动智能融入控制策略开辟了新途径，促使海洋机器人控制发生范式转变。本文回顾了在这一新兴范式下海洋机器人控制的最新进展。综述涵盖了个体和协同海洋机器人系统，强调了数据驱动型海洋机器人控制方面的显著成就，并总结了支持高级控制方法开发和验证的开源资源。最后，概述了几个未来展望，以指导研究实现海洋机器人在实际应用中的高水平自主性。本文旨在为数据驱动智能时代海洋机器人的下一代控制框架提供一份路线图。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [223] [CURL-SLAM: Continuous and Compact LiDAR Mapping](https://arxiv.org/abs/2506.21077)
> *CURL-SLAM：连续紧凑激光雷达建图*

*Kaicheng Zhang, Shida Xu, Yining Ding, Xianwen Kong, Sen Wang* | **Category: cs.RO**

**Keywords:** 激光雷达SLAM, CURL, 紧凑地图, 连续重建, 球谐函数

**Comment:** 

> **TL;DR:** CURL-SLAM提出了一种基于CURL的激光雷达建图新范式，实现了连续、紧凑、一致的三维地图，并在CPU上达到实时性能。

**AI_Comments:** 该论文的创新点在于引入CURL作为激光雷达地图的表示方式，显著提升了地图的紧凑性和连续性，并克服了传统点云地图存储大的缺点。其提出的针对CURL的姿态优化和局部束调整策略也具有独特性。在CPU上实现实时性能，表明其具有较好的实用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统激光雷达SLAM系统通常依赖于三维点云地图，这需要大量的存储空间来保留大规模环境中的结构细节，导致地图不够紧凑。

**Method:** CURL-SLAM利用激光雷达连续超紧凑表示（CURL）的球谐函数隐式编码，生成紧凑且可变密度连续重建的三维地图，并在闭环后实现全局地图一致性。它将激光雷达姿态估计公式化为针对CURL的独特优化问题，并扩展到局部束调整（BA），实现姿态细化和地图校正。

**Result:** CURL-SLAM实现了最先进的三维建图质量和有竞争力的激光雷达轨迹精度，并在CPU上达到了传感器速率实时性能（10 Hz）。

**Conclusion:** CURL-SLAM通过引入基于CURL的新范式，有效解决了传统激光雷达SLAM在地图存储、连续性和一致性方面的挑战，并展现出卓越的性能和实时处理能力。

> **ai_Abstract:** CURL-SLAM提出一种新颖的激光雷达SLAM范式，通过利用CURL（Continuous and Ultra-compact Representation of LiDAR）的球谐函数隐式编码，解决了传统点云地图存储量大和连续性差的问题。该方法能够生成紧凑、可变密度连续重建的三维地图，并在闭环后实现全局一致性。CURL-SLAM还将激光雷达姿态估计设计为针对CURL的优化问题，并结合局部束调整实现姿态和地图的同步校正。实验结果表明，CURL-SLAM在三维建图质量、轨迹精度和CPU实时性能方面均达到先进水平。

> **摘要翻译:** 这篇论文研究了三维激光雷达建图，重点在于开发一种可更新、可定位的地图表示，以实现三维地图的连续性、紧凑性和一致性。传统的激光雷达同时定位与建图（SLAM）系统通常依赖于三维点云地图，这通常需要大量的存储空间来保留大规模环境中的结构细节。在这篇论文中，我们通过利用[1]中介绍的激光雷达连续超紧凑表示（CURL），提出了一种新颖的激光雷达SLAM范式。我们提出的激光雷达建图方法，CURL-SLAM，利用CURL的球谐函数隐式编码，生成能够以可变密度连续重建的紧凑三维地图，并在闭环后实现全局地图一致性。与流行的基于迭代最近点（ICP）的激光雷达里程计技术不同，CURL-SLAM将激光雷达姿态估计公式化为针对CURL量身定制的独特优化问题，并将其扩展到局部束调整（BA），从而实现同步姿态细化和地图校正。实验结果表明，CURL-SLAM实现了最先进的三维建图质量和有竞争力的激光雷达轨迹精度，并在CPU上提供了传感器速率的实时性能（10 Hz）。我们将向社区发布CURL-SLAM的实现。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [236] [UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research](https://arxiv.org/abs/2506.21178)
> *UAIbot: 适用于交互式机器人学习和研究的初学者友好型网络模拟器*

*Johnata Brayan, Armando Alves Neto, Pavel Petrovič, Gustavo M Freitas, Vinicius Mariano Gonçalves* | **Category: cs.RO, 68T40, I.2.9; I.6.3**

**Keywords:** 机器人模拟器, 网络平台, 交互式学习, 开源, 机器人教育

**Comment:** 12 pages, 8 figures, submitted to Springer proceedings

> **TL;DR:** UAIbot是一个免费开源的网络机器人模拟器，旨在简化机器人学习和研究，通过Python和JavaScript接口提供无需安装的交互式实践体验。

**AI_Comments:** UAIbot的创新之处在于其“初学者友好”和“网络化”的特性，大大降低了机器人模拟学习和研究的门槛。其免费开源的模式也促进了知识的普及和社区协作。这种基于Web的无需安装的解决方案对于教育和快速原型开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的机器人模拟平台面临教育和研究挑战，安装繁琐且不易上手，限制了学生和研究人员的实践学习和快速实验。

**Method:** UAIbot通过提供基于Python和JavaScript的Web接口，实现无需复杂安装即可访问的实践学习体验。它允许用户交互式地探索从机械臂运动学到行人流动力学等基础数学和物理原理。

**Result:** UAIbot为学生提供了深化理解的有效工具，促进了快速实验，并增强了研究成果的传播。它使交互式学习成为可能，并帮助用户探索基础原理。

**Conclusion:** UAIbot通过其免费、开源和易于访问的Web平台，成功解决了传统机器人模拟器的痛点，为机器人学习和研究提供了一个有效且用户友好的工具。

> **ai_Abstract:** 本文介绍了UAIbot，一个免费开源的Web机器人模拟器。它通过提供Python和JavaScript接口，解决了传统模拟器安装复杂的问题，使初学者能够轻松进行交互式机器人学习和研究。UAIbot旨在通过实践操作，帮助用户深入理解机器人学中的基本原理，促进快速实验，并提升研究成果的普及性。

> **摘要翻译:** 本文介绍了UAIbot，一个免费开源的网络机器人模拟器，旨在解决传统模拟平台普遍面临的教育和研究挑战。UAIbot的Python和JavaScript接口使得无需繁琐安装即可获得便捷的实践学习体验。通过允许用户交互式探索从机械臂运动学到行人流动力学等基础数学和物理原理，UAIbot为深化学生理解、促进快速实验和增强研究传播提供了一个有效的工具。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [239] [Active Disturbance Rejection Control for Trajectory Tracking of a Seagoing USV: Design, Simulation, and Field Experiments](https://arxiv.org/abs/2506.21265)
> *远洋USV轨迹跟踪的主动抗扰控制：设计、仿真与实地实验*

*Jelmer van der Saag, Elia Trevisan, Wouter Falkena, Javier Alonso-Mora* | **Category: cs.RO, cs.SY, eess.SY**

**Keywords:** 主动抗扰控制, 轨迹跟踪, 无人水面艇, 环境扰动, 实地实验

**Comment:** Accepted for presentation at IROS 2025. Submitted version

> **TL;DR:** 本文提出了一种基于主动抗扰控制（ADRC）的无人水面艇（USV）轨迹跟踪控制器，并通过定制仿真和实地实验验证了其在减少横向跟踪误差方面的有效性，但代价是更高的能量消耗。

**AI_Comments:** 这篇论文通过结合仿真和实地实验，验证了ADRC在复杂海洋环境下对USV轨迹跟踪的有效性，其创新性在于将ADRC应用于实际USV并量化了其性能提升及代价。这项工作对于未来USV在复杂环境下的自主导航和控制具有重要意义，同时也指出了高能耗是ADRC在实际应用中需要解决的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 无人水面艇（USV）在波浪和水流等不确定环境扰动下，其控制面临巨大挑战，因此需要一种能有效应对这些扰动的轨迹跟踪控制器。

**Method:** 本文提出了一种基于主动抗扰控制（ADRC）的轨迹跟踪控制器，并将其应用于DUS V2500无人艇。通过开发包含真实波浪和水流扰动的定制仿真模型来验证控制器性能，并通过在荷兰斯赫弗宁根港和海上进行的实地测试进一步验证。

**Result:** 仿真结果表明，在所有测试条件下，ADRC相比基线PID控制器显著降低了横向跟踪误差，但增加了控制工作量和能量消耗。实地试验证实了这些发现，并揭示了海上试验期间能量消耗相比基线进一步增加。

**Conclusion:** ADRC控制器能有效减少无人水面艇在环境扰动下的轨迹跟踪误差，但其代价是更高的能量消耗。

> **ai_Abstract:** 本文针对无人水面艇在不确定环境扰动下的轨迹跟踪难题，提出了一种基于主动抗扰控制（ADRC）的解决方案。通过定制仿真和实地实验（包括港口和海上测试），研究验证了ADRC控制器在显著降低横向跟踪误差方面的有效性。然而，研究也指出，ADRC的应用会导致控制工作量和能量消耗的增加，尤其是在海上环境中。

> **摘要翻译:** 无人水面艇（USV）由于波浪和水流等不确定环境扰动而面临严峻的控制挑战。本文提出了一种基于主动抗扰控制（ADRC）的轨迹跟踪控制器，并在DUS V2500上实现。开发了一个包含真实波浪和水流扰动的定制仿真系统来验证控制器的性能，并通过在荷兰斯赫弗宁根港和海上进行的实地测试进一步验证。仿真结果表明，与基线PID控制器相比，ADRC在所有测试条件下显著减少了横向跟踪误差，但增加了控制工作量和能量消耗。实地试验证实了这些发现，同时揭示了海上试验期间能量消耗相比基线进一步增加。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [246] [Dynamic Risk-Aware MPPI for Mobile Robots in Crowds via Efficient Monte Carlo Approximations](https://arxiv.org/abs/2506.21205)
> *拥挤环境中移动机器人的动态风险感知MPPI：通过高效蒙特卡洛近似*

*Elia Trevisan, Khaled A. Mustafa, Godert Notten, Xinwei Wang, Javier Alonso-Mora* | **Category: cs.RO**

**Keywords:** 移动机器人, 风险感知, MPPI, 蒙特卡洛近似, 碰撞概率

**Comment:** Accepted for presentation at IROS 2025. Submitted Version

> **TL;DR:** 本文提出DRA-MPPI，一种新的运动规划器，利用高效蒙特卡洛近似实时处理人群中机器人运动的不确定性，提高安全性并避免“机器人冻结”问题。

**AI_Comments:** 该论文提出了一种创新的风险感知运动规划方法DRA-MPPI，通过高效的蒙特卡洛近似解决了传统方法在处理非高斯不确定性预测和实时约束方面的难题。其核心贡献在于将碰撞概率有效地融入到MPPI框架中，从而显著提高了机器人在拥挤环境中的安全性并避免了保守行为（“机器人冻结”）。该方法的实时性和与现有方法的对比优势，使其在实际应用中具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在人群中安全部署移动机器人，需要运动规划器考虑其他代理预测轨迹中的不确定性。传统方法在处理任意形状的预测和实时约束时面临挑战。

**Method:** 本文提出动态风险感知模型预测路径积分控制（DRA-MPPI）。该方法利用MPPI的无梯度特性，通过蒙特卡洛（MC）方法高效近似多个动态障碍物之间的联合碰撞概率（CP），实时处理数百条采样轨迹。这使得可以拒绝超过预定义CP阈值的样本，或将CP作为导航成本函数中的加权目标。

**Result:** DRA-MPPI缓解了“机器人冻结”问题，同时提高了安全性。在真实世界和模拟实验中，DRA-MPPI与现有最先进方法（包括基于场景的模型预测控制（S-MPC）、Frenet规划器和普通MPPI）相比，表现出卓越的性能。

**Conclusion:** DRA-MPPI通过有效处理不确定性预测和实时约束，显著提升了移动机器人在拥挤环境中的安全性和导航能力，优于现有方法。

> **ai_Abstract:** 本文提出了一种名为动态风险感知模型预测路径积分控制（DRA-MPPI）的运动规划器，旨在解决移动机器人在人群中导航时处理不确定性预测和实时约束的挑战。DRA-MPPI利用蒙特卡洛方法高效近似联合碰撞概率，从而能够拒绝高风险轨迹或将其纳入导航成本，有效避免了“机器人冻结”问题并提高了安全性。实验结果表明，DRA-MPPI在复杂动态环境中表现优于现有先进方法。

> **摘要翻译:** 在人类环境中安全部署移动机器人，需要运动规划器考虑其他代理预测轨迹中的不确定性。这在传统方法中仍然具有挑战性，特别是在任意形状的预测和实时约束下。为了解决这些挑战，我们提出了一种动态风险感知模型预测路径积分控制（DRA-MPPI），这是一种运动规划器，它结合了可能具有非高斯随机预测模型的不确定未来运动。通过利用MPPI的无梯度特性，我们提出了一种方法，可以通过蒙特卡洛（MC）方法实时有效地近似多个动态障碍物之间的联合碰撞概率（CP），针对数百条采样轨迹进行计算。这使得可以拒绝超过预定义CP阈值的样本，或将CP作为导航成本函数中的加权目标。因此，DRA-MPPI缓解了机器人冻结问题，同时增强了安全性。与最先进的方法（包括基于场景的模型预测控制（S-MPC）、Frenet规划器和普通MPPI）相比，DRA-MPPI在多个动态障碍物下的真实世界和模拟实验中表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [256] [ACTLLM: Action Consistency Tuned Large Language Model](https://arxiv.org/abs/2506.21250)
> *ACTLLM：动作一致性调优的大型语言模型*

*Jing Bi, Lianggong Bruce Wen, Zhang Liu, Chenliang Xu* | **Category: cs.RO**

**Keywords:** 机器人操作, 大型语言模型, 动作一致性, 视觉机器人, 动态环境

**Comment:** 

> **TL;DR:** ACTLLM是一种新型机器人操作方法，利用语言和动作一致性在动态环境中实现高效视觉机器人操作。

**AI_Comments:** 这篇论文的创新点在于结合了大型语言模型与机器人操作，特别是通过引入“动作一致性约束”来优化视觉表示的学习，以及将MDP重构为“多轮视觉对话”以处理长期任务。这种方法有效地弥补了传统视觉系统在动态环境适应性和空间推理上的不足，为机器人操作提供了一个更灵活、更具上下文感知能力的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于视觉的系统难以学习在任务执行和空间推理方面都表现出色的视觉表示，从而限制了它们在动态环境中的适应性。

**Method:** 引入ACTLLM，通过语言生成结构化的场景描述符，为空间理解和任务性能提供统一接口。引入新的动作一致性约束，使视觉感知与相应动作对齐，以增强可操作视觉表示的学习。将操作任务的马尔可夫决策过程重新构建为多轮视觉对话框架，以建模长期任务执行。

**Result:** ACTLLM在各种场景中表现出色，证明了其在具有挑战性的基于视觉的机器人操作任务中的有效性。

**Conclusion:** ACTLLM通过结合语言指导和动作一致性，有效解决了动态环境中机器人操作的挑战，提升了视觉机器人的任务执行和空间推理能力。

> **ai_Abstract:** ACTLLM是一种创新的大型语言模型，专为动态环境中的机器人操作设计。它通过利用语言生成结构化场景描述符，并引入动作一致性约束来对齐视觉感知与动作，从而克服了传统视觉系统在学习有效视觉表示上的局限性。该方法还将马尔可夫决策过程重构为多轮视觉对话，以增强长期任务执行的上下文关联性。实验证明ACTLLM在复杂的视觉机器人操作任务中表现卓越。

> **摘要翻译:** 本文介绍了ACTLLM（动作一致性调优的大型语言模型），这是一种在动态环境中进行机器人操作的新颖方法。传统的基于视觉的系统通常难以学习在任务执行和空间推理方面都表现出色的视觉表示，从而限制了它们在动态环境中的适应性。ACTLLM通过利用语言来创建结构化的场景描述符来解决这些挑战，为空间理解和通过灵活的语言指令执行任务提供统一的接口。此外，我们引入了一种新颖的动作一致性约束，使视觉感知与相应的动作对齐，从而增强了可操作视觉表示的学习。此外，我们还将操作任务的马尔可夫决策过程重新构建为多轮视觉对话框架。这种方法能够通过从任务执行历史中获得增强的上下文相关性来建模长期任务执行。在我们的评估中，ACTLLM在各种场景中表现出色，证明了其在具有挑战性的基于视觉的机器人操作任务中的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [270] [Real-time Terrain Analysis for Off-road Autonomous Vehicles](https://arxiv.org/abs/2506.21347)
> *越野自动驾驶汽车的实时地形分析*

*Edwina Lewis, Aditya Parameshwaran, Laura Redmond, Yue Wang* | **Category: cs.RO**

**Keywords:** 实时地形分析, 自动驾驶车辆, 路面粗糙度, 贝叶斯校准, Simplex控制器

**Comment:** 

> **TL;DR:** 本研究提出了一种新颖的实时路面粗糙度估计系统，利用贝叶斯校准方法处理车轴加速度，以提高自动驾驶车辆在崎岖路面上的安全性和效率。

**AI_Comments:** 该论文的创新点在于提出了一个将贝叶斯校准与高斯过程和半车辆模型相结合的实时路面粗糙度估计框架。这种方法不仅能够预测粗糙度，还能量化预测的不确定性，这对于自动驾驶车辆的风险管理至关重要。与Simplex控制器的集成展示了其实用性，为提高越野自动驾驶车辆的安全性提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决自动驾驶车辆在路面粗糙度变化时面临的控制挑战，这些变化可能导致转向操作期间的行驶偏差和潜在的失控。

**Method:** 该研究提出了一个实时路面粗糙度估计系统，采用贝叶斯校准方法处理车轴加速度来预测地形粗糙度。技术框架集成了高斯过程替代模型和模拟半车辆模型，系统地处理车辆速度和路面粗糙度参数以生成车轴加速度响应。贝叶斯校准程序通过观测到的加速度和速度逆向估计路面粗糙度，生成量化预测不确定性的后验分布。训练数据通过拉丁超立方采样生成，校准后的模型与Simplex控制器架构无缝集成，根据实时粗糙度预测动态调整速度限制。

**Result:** 在随机生成的不同粗糙度区域的路面上进行的实验验证表明，该系统具有强大的实时表征能力。集成Simplex控制策略通过主动响应路面状况，有效增强了自动驾驶车辆的运行安全性。

**Conclusion:** 该创新的贝叶斯框架为减轻与粗糙度相关的操作风险奠定了全面基础，同时提高了自动驾驶系统的效率和安全裕度。

> **ai_Abstract:** 本研究提出了一种用于越野自动驾驶车辆的实时路面粗糙度估计系统，以解决因路面粗糙度变化导致的控制挑战。该系统采用贝叶斯校准方法，结合高斯过程模型和半车辆模型，通过分析车轴加速度来预测地形粗糙度并量化不确定性。实验证明，该方法能有效增强自动驾驶车辆在崎岖路面上的操作安全性和效率。

> **摘要翻译:** 本研究旨在解决路面粗糙度变化引起的自动驾驶车辆关键控制挑战，这些变化会导致转向操作期间的行驶偏差和潜在的失控。我们提出了一种新颖的实时路面粗糙度估计系统，该系统采用贝叶斯校准方法，处理车轴加速度以可量化的置信度预测地形粗糙度。该技术框架将高斯过程替代模型与模拟半车辆模型相结合，系统地处理车辆速度和路面粗糙度参数以生成相应的车轴加速度响应。贝叶斯校准程序根据观测到的加速度和速度进行路面粗糙度的逆向估计，生成量化预测不确定性的后验分布，用于自适应风险管理。训练数据的生成利用拉丁超立方采样在全面的速度和粗糙度参数空间中进行，而校准后的模型与Simplex控制器架构无缝集成，根据实时粗糙度预测动态调整速度限制。在具有不同粗糙度区域的随机生成路面上进行的实验验证表明，该系统具有鲁棒的实时表征能力，集成Simplex控制策略通过主动响应路面状况，有效增强了自动驾驶车辆的运行安全性。这种创新的贝叶斯框架为减轻与粗糙度相关的操作风险奠定了全面基础，同时提高了自动驾驶系统中的效率和安全裕度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [277] [WorldVLA: Towards Autoregressive Action World Model](https://arxiv.org/abs/2506.21539)
> *世界VLA：迈向自回归动作世界模型*

*Jun Cen, Chaohui Yu, Hangjie Yuan, Yuming Jiang, Siteng Huang, Jiayan Guo, Xin Li, Yibing Song, Hao Luo, Fan Wang, Deli Zhao, Hao Chen* | **Category: cs.RO, cs.AI**

**Keywords:** 自回归动作世界模型, WorldVLA, 视觉-语言-动作模型, 注意力掩码, 动作生成

**Comment:** Code: https://github.com/alibaba-damo-academy/WorldVLA

> **TL;DR:** WorldVLA是一个统一动作和图像理解与生成的自回归动作世界模型，它整合了VLA模型和世界模型，并通过注意力掩码策略解决了自回归动作生成中的性能下降问题。

**AI_Comments:** 这篇论文通过提出WorldVLA，有效地将VLA模型与世界模型融合，实现了动作和图像理解与生成的统一，这是一个重要的创新点。模型内部的世界模型和动作模型之间的相互增强机制是其性能优越的关键。更值得注意的是，论文识别并成功解决了自回归动作生成中常见的误差累积问题，通过提出新颖的注意力掩码策略，显著提升了模型的实用性和鲁棒性，对未来的自回归模型设计具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有模型可能无法有效统一动作和图像的理解与生成，且自回归动作生成存在误差传播导致性能下降的问题，需要一个能同时解决这些问题并提升性能的框架。

**Method:** 提出了WorldVLA，一个自回归动作世界模型，它将视觉-语言-动作（VLA）模型和世界模型集成在一个框架中。世界模型通过利用动作和图像理解来预测未来图像，以学习环境的潜在物理特性并改进动作生成。动作模型根据图像观察生成后续动作，辅助视觉理解并反过来帮助世界模型的视觉生成。为了解决自回归动作序列生成性能下降的问题，提出了一种注意力掩码策略，在生成当前动作时选择性地掩盖先前的动作。

**Result:** WorldVLA在性能上优于独立的动作模型和世界模型，这表明世界模型和动作模型之间存在相互增强。然而，发现自回归生成动作序列时动作模型性能会下降，这归因于模型动作预测泛化能力有限导致误差传播。提出的注意力掩码策略在动作块生成任务中显示出显著的性能提升。

**Conclusion:** WorldVLA成功地将动作和图像理解与生成统一起来，并通过世界模型和动作模型之间的相互增强取得了优越的性能。同时，通过引入注意力掩码策略，有效解决了自回归动作生成中的误差传播问题，提升了模型的泛化能力和性能。

> **ai_Abstract:** WorldVLA是一个创新的自回归动作世界模型，它在一个统一的框架中结合了视觉-语言-动作（VLA）模型和世界模型。该模型旨在通过世界模型预测未来图像来学习环境物理特性以改进动作生成，并通过动作模型生成后续动作来辅助视觉理解。研究表明，WorldVLA性能优于独立模型，且其内部的世界模型和动作模型相互促进。针对自回归动作生成中存在的误差传播导致的性能下降问题，研究提出了一种注意力掩码策略，显著提升了动作块生成任务的性能。

> **摘要翻译:** 我们提出了WorldVLA，一个自回归动作世界模型，它统一了动作和图像的理解与生成。我们的WorldVLA将视觉-语言-动作（VLA）模型和世界模型集成在一个单一的框架中。世界模型通过利用动作和图像理解来预测未来图像，目的是学习环境的潜在物理特性以改进动作生成。同时，动作模型根据图像观察生成后续动作，辅助视觉理解并反过来帮助世界模型的视觉生成。我们证明了WorldVLA优于独立的动作模型和世界模型，突出了世界模型和动作模型之间的相互增强。此外，我们发现当以自回归方式生成动作序列时，动作模型的性能会下降。这种现象可归因于模型对动作预测的泛化能力有限，导致误差从早期动作传播到后续动作。为了解决这个问题，我们提出了一种注意力掩码策略，在生成当前动作时选择性地掩盖先前的动作，这在动作块生成任务中显示出显著的性能提升。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [18] [OTSurv: A Novel Multiple Instance Learning Framework for Survival Prediction with Heterogeneity-aware Optimal Transport](https://arxiv.org/abs/2506.20741)
> *OTSurv：一种用于生存预测的异质性感知最优传输多实例学习框架*

*Qin Ren, Yifan Wang, Ruogu Fang, Haibin Ling, Chenyu You* | **Category: cs.CV**

**Keywords:** 多实例学习, 生存预测, 最优传输, 病理异质性, 全玻片图像

**Comment:** 

> **TL;DR:** OTSurv是一个新的多实例学习（MIL）框架，它利用最优传输（OT）来解决全玻片图像（WSIs）生存预测中存在的病理异质性问题，通过引入全局长尾和局部不确定性感知约束，实现了最先进的性能和高可解释性。

**AI_Comments:** OTSurv的创新之处在于将最优传输理论引入多实例学习框架，以解决全玻片图像中复杂的病理异质性问题。通过引入全局长尾和局部不确定性感知约束，它不仅提高了预测精度，还增强了模型的可解释性，这对于临床应用具有重要价值。其在多个基准测试中取得的最先进结果证明了其有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多实例学习（MIL）方法在利用全玻片图像（WSIs）进行生存预测时，未能明确捕捉病理异质性，包括全局的长尾形态分布和局部的瓦片级预测不确定性。

**Method:** 提出OTSurv框架，将生存预测表述为一个异质性感知最优传输问题。该问题包含两个核心约束：1）全局长尾约束，通过调节传输质量分配来建模先验形态分布，以避免模式崩溃和过度均匀性；2）局部不确定性感知约束，通过逐步增加总传输质量来优先处理高置信度补丁并抑制噪声。该框架将初始OT问题重铸为非平衡OT形式，并使用高效且硬件友好的矩阵缩放算法求解。

**Result:** OTSurv在六个流行的基准测试中取得了新的最先进结果，平均C-index绝对提高了3.6%。此外，OTSurv在对数秩检验中达到了统计显著性。

**Conclusion:** OTSurv提供高可解释性，使其成为数字病理学中生存预测的强大工具。

> **ai_Abstract:** OTSurv是一种新颖的多实例学习框架，用于利用全玻片图像进行生存预测。它通过异质性感知最优传输方法，解决了现有MIL方法未能捕捉病理异质性的问题。该框架引入了全局长尾约束和局部不确定性感知约束，有效建模了形态分布并处理了预测不确定性。实验结果表明，OTSurv在多个基准测试中显著提升了生存预测的性能和可解释性。

> **摘要翻译:** 使用全玻片图像（WSIs）进行生存预测可以被表述为一个多实例学习（MIL）问题。然而，现有的MIL方法往往未能明确捕捉WSI内的病理异质性，无论是全局的（通过长尾形态分布），还是局部的（通过瓦片级预测不确定性）。最优传输（OT）通过结合边缘分布约束，提供了一种建模这种异质性的原则性方法。基于这一见解，我们提出了OTSurv，一个从最优传输角度出发的新型MIL框架。具体来说，OTSurv将生存预测表述为一个异质性感知的OT问题，并带有两个约束：（1）全局长尾约束，通过调节传输质量分配来建模先验形态分布，以避免模式崩溃和过度均匀性；（2）局部不确定性感知约束，通过逐步提高总传输质量来优先处理高置信度补丁并抑制噪声。然后，我们将最初的OT问题，通过这些约束进行增强，重铸为一种非平衡OT形式，可以使用高效且硬件友好的矩阵缩放算法求解。经验上，OTSurv在六个流行的基准测试中取得了新的最先进结果，平均C-index绝对提高了3.6%。此外，OTSurv在对数秩检验中达到了统计显著性，并提供了高可解释性，使其成为数字病理学中生存预测的强大工具。我们的代码可在https://github.com/Y-Research-SBU/OTSurv获得。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [42] [StereoDiff: Stereo-Diffusion Synergy for Video Depth Estimation](https://arxiv.org/abs/2506.20756)
> *StereoDiff：立体与扩散协同用于视频深度估计*

*Haodong Li, Chen Wang, Jiahui Lei, Kostas Daniilidis, Lingjie Liu* | **Category: cs.CV**

**Keywords:** 视频深度估计, 立体匹配, 扩散模型, 时间一致性, StereoDiff

**Comment:** Work done in Nov. 2024. Project page: https://stereodiff.github.io/

> **TL;DR:** StereoDiff结合立体匹配和视频扩散模型，解决了视频深度估计中动静态区域的不同一致性要求，实现了SOTA性能。

**AI_Comments:** 该论文的创新点在于认识到视频深度估计中动静态区域一致性要求的差异，并提出了一个结合立体匹配和视频扩散的两阶段协同框架。这种方法有效利用了立体匹配的全局3D线索和扩散模型在动态区域平滑过渡上的优势，解决了传统方法的局限性。通过数学分析和SOTA性能验证，该工作为视频深度估计提供了一个新颖且高效的解决方案，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频深度估计方法是图像深度估计的简单扩展，未能有效处理视频中动态和静态区域根本不同的时间一致性要求。静态区域可从立体匹配中获得全局3D线索，而动态区域则需从大规模数据中学习以确保平滑过渡。

**Method:** StereoDiff是一种两阶段视频深度估计器。它将主要用于静态区域的立体匹配与用于动态区域保持深度平滑过渡的视频深度扩散相结合。通过频域分析数学地证明了立体匹配和视频深度扩散的互补优势。

**Result:** StereoDiff在零样本、真实世界、动态视频深度基准（包括室内和室外）上取得了最先进（SoTA）的性能，显示出其在视频深度估计中卓越的一致性和准确性。

**Conclusion:** StereoDiff通过协同立体匹配和视频深度扩散，有效解决了视频中静态和动态区域不同的深度一致性要求，从而显著提高了视频深度估计的性能。

> **ai_Abstract:** StereoDiff是一种新型的两阶段视频深度估计器，旨在解决现有方法在处理视频中动静态区域不同深度一致性要求时的不足。它创新性地结合了立体匹配（用于静态区域提供全局3D线索）和视频深度扩散（用于动态区域确保平滑过渡），并通过频域分析证明了其互补优势。实验结果表明，StereoDiff在零样本、真实世界的动态视频深度基准上实现了最先进的性能，显著提高了视频深度估计的一致性和准确性。

> **摘要翻译:** 最近的视频深度估计方法通过遵循图像深度估计的范式，即通常使用海量数据微调预训练的视频扩散模型，取得了很好的性能。然而，我们认为视频深度估计并非图像深度估计的简单扩展。视频中动态和静态区域的时间一致性要求根本不同。静态区域（通常是背景）的一致视频深度可以通过跨所有帧的立体匹配更有效地实现，这提供了更强的全局3D线索。而动态区域的一致性由于违反三角测量约束，仍然需要从大规模视频深度数据中学习以确保平滑过渡。基于这些见解，我们引入了StereoDiff，这是一种两阶段视频深度估计器，它将主要用于静态区域的立体匹配与用于保持动态区域深度平滑过渡的视频深度扩散相结合。我们通过频域分析数学地证明了立体匹配和视频深度扩散如何通过频域分析提供互补优势，突出了它们协同作用在捕捉两者优势方面的有效性。在零样本、真实世界、动态视频深度基准（包括室内和室外）上的实验结果表明，StereoDiff的性能达到了SoTA，展示了其在视频深度估计中卓越的一致性和准确性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [66] [ConViTac: Aligning Visual-Tactile Fusion with Contrastive Representations](https://arxiv.org/abs/2506.20757)
> *ConViTac：使用对比表示对齐视觉-触觉融合*

*Zhiyuan Wu, Yongqiang Zhao, Shan Luo* | **Category: cs.CV, cs.RO**

**Keywords:** 视觉-触觉融合, 对比学习, 表示学习, 跨模态注意力, 机器人感知

**Comment:** 

> **TL;DR:** ConViTac通过对比学习和跨模态注意力，提高了视觉-触觉融合的特征对齐，在材料分类和抓取预测任务中表现优于现有技术。

**AI_Comments:** 该论文的创新点在于引入了对比学习来增强视觉和触觉模态之间的特征对齐，克服了传统直接融合方法的局限性。CEC机制通过统一的潜在嵌入空间和跨模态注意力，有效地提升了多模态融合的质量和下游任务的性能。这对于提升机器人感知和操作能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人视觉和触觉是互补的感知模态，但现有方法在融合视觉-触觉表示时，直接组合（如特征加法和拼接）导致特征集成不佳。

**Method:** 本文提出了ConViTac，一个视觉-触觉表示学习网络。其核心是对比嵌入条件（CEC）机制，该机制利用通过自监督对比学习预训练的对比编码器，将视觉和触觉输入投射到统一的潜在嵌入中。这些嵌入通过跨模态注意力耦合视觉-触觉特征融合，以对齐统一表示并增强下游任务性能。

**Result:** ConViTac在实际应用中优于当前最先进的方法。所提出的CEC机制有效，在材料分类和抓取预测任务中将准确率提高了高达12.0%。

**Conclusion:** ConViTac及其提出的对比嵌入条件（CEC）机制能够有效对齐视觉-触觉特征并提高下游任务的性能，超越了现有技术。

> **ai_Abstract:** 本文提出了ConViTac，一个用于视觉-触觉表示学习的网络，旨在通过引入对比嵌入条件（CEC）机制来解决现有融合方法中特征集成不佳的问题。CEC利用自监督对比学习预训练的编码器将视觉和触觉输入映射到统一的潜在空间，并通过跨模态注意力实现特征对齐。实验证明ConViTac在材料分类和抓取预测等下游任务上优于现有技术，并显著提升了性能。

> **摘要翻译:** 视觉和触觉是机器人最基本的两种感觉模态，它们提供互补信息，增强感知和操作任务。以往的研究试图共同学习视觉-触觉表示以提取更有意义的信息。然而，这些方法通常依赖直接组合，例如特征加法和拼接，进行模态融合，这往往导致特征集成不佳。在本文中，我们提出了ConViTac，一个视觉-触觉表示学习网络，旨在利用对比表示增强融合过程中的特征对齐。我们的主要贡献是对比嵌入条件（CEC）机制，该机制利用通过自监督对比学习预训练的对比编码器，将视觉和触觉输入投射到统一的潜在嵌入中。这些嵌入通过跨模态注意力耦合视觉-触觉特征融合，旨在对齐统一表示并提高下游任务的性能。我们进行了广泛的实验，证明了ConViTac在实际应用中优于当前最先进的方法，并验证了我们提出的CEC机制的有效性，该机制在材料分类和抓取预测任务中将准确率提高了高达12.0%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [91] [AI-Driven MRI-based Brain Tumour Segmentation Benchmarking](https://arxiv.org/abs/2506.20786)
> *AI驱动的MRI脑肿瘤分割基准测试*

*Connor Ludwig, Khashayar Namdar, Farzad Khalvati* | **Category: cs.CV**

**Keywords:** 脑肿瘤分割, 提示模型, nnU-Net, SAM, 性能基准

**Comment:** 

> **TL;DR:** 本研究对多种基于提示的医学图像分割模型在脑肿瘤数据集上进行了基准测试，发现虽然在理想提示下部分模型表现优异，但由于实际操作的限制，nnU-Net仍是实际应用中的主导。

**AI_Comments:** 本文对新兴的通用可提示模型在医学图像分割领域的实际应用潜力进行了有价值的评估。其创新点在于系统性地比较了不同提示质量对模型性能的影响。研究揭示了虽然这些模型在理想条件下表现出色，但在实际临床场景中，如何高效获取高质量提示仍是一个挑战。这强调了nnU-Net等无需精细提示的模型在当前实践中的重要性，并为未来可提示模型的研究方向（如提升点提示鲁棒性和实用性）提供了见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究缺乏对新兴通用可提示模型（如SAM系列）及其医学变体在通用医学数据集上，针对不同提示质量的评估和比较。

**Method:** 研究使用Segment Anything Model (SAM)、Segment Anything Model 2 (SAM 2)、MedSAM、SAM-Med-3D和nnU-Net在BraTS 2023成人胶质瘤和儿科数据集上进行零样本推理，评估点和边界框两种提示类型在多种提示质量下的表现。此外，还在儿科数据集上对SAM、SAM 2、MedSAM和SAM-Med-3D进行了微调，以扩展模型和提示评估。

**Result:** 在提供极其准确的边界框提示时，SAM和SAM 2的Dice分数分别高达0.894和0.893，超过了nnU-Net的分割性能。然而，由于提供高度准确提示的不切实际性，nnU-Net仍然是主要的医学图像分割网络。微调后点提示的性能显著提高，但仍未能实现比边界框或nnU-Net更好的分割效果。

**Conclusion:** 尽管在理想的高精度边界框提示下，部分基于提示的模型（如SAM和SAM 2）在脑肿瘤分割上能超越nnU-Net，但由于实际应用中难以提供此类高精度提示，nnU-Net仍是当前医学图像分割的主导模型。微调可以显著改善点提示性能，但要达到最优分割效果仍需进一步研究。

> **ai_Abstract:** 本研究对AI驱动的MRI脑肿瘤分割模型进行了基准测试，比较了包括SAM系列模型和nnU-Net在内的多种模型在BraTS 2023数据集上的表现。结果表明，尽管SAM和SAM 2在获得极高精度边界框提示时能超越nnU-Net，但由于实际应用中的限制，nnU-Net仍是主流选择。微调能显著提升点提示性能，但尚未超越边界框或nnU-Net。

> **摘要翻译:** 医学图像分割极大地辅助了医学诊断，其中基于U-Net的架构和nnU-Net提供了最先进的性能。近年来，出现了许多通用的可提示模型及其医学变体，但目前在通用医学数据集上，针对不同提示质量对这些模型进行评估和比较的工作尚缺乏。本研究使用Segment Anything Model (SAM)、Segment Anything Model 2 (SAM 2)、MedSAM、SAM-Med-3D和nnU-Net，在BraTS 2023成人胶质瘤和儿科数据集上，针对点和边界框两种提示类型，在多种提示质量下进行零样本推理。其中几个模型表现出有前景的Dice分数，特别是SAM和SAM 2在给定极其准确的边界框提示时，分别取得了高达0.894和0.893的分数，这超出了nnU-Net的分割性能。然而，由于提供高度准确提示给模型的不切实际性，nnU-Net仍然是主要的医学图像分割网络。通过在儿科数据集上对SAM、SAM 2、MedSAM和SAM-Med-3D进行微调，扩展了模型和提示的评估和比较。微调后点提示性能的提升是显著的，并显示出未来研究的潜力，但仍未能实现比边界框或nnU-Net更好的分割效果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [114] [How do Foundation Models Compare to Skeleton-Based Approaches for Gesture Recognition in Human-Robot Interaction?](https://arxiv.org/abs/2506.20795)
> *基础模型与基于骨架的方法在人机交互手势识别中的比较如何？*

*Stephanie Käs, Anton Burenko, Louis Markert, Onur Alp Culha, Dennis Mack, Timm Linder, Bastian Leibe* | **Category: cs.CV, cs.HC, cs.RO, I.2.10; I.2.9; I.5.4; I.4.8; I.4.9; H.1.2**

**Keywords:** 手势识别, 基础模型, 人机交互, 骨架方法, 多模态模型

**Comment:** 

> **TL;DR:** 本研究比较了基础模型（V-JEPA、Gemini Flash 2.0）与基于骨架的方法（HD-GCN）在人机交互手势识别中的表现，并引入了NUGGET数据集。结果显示HD-GCN性能最佳，但V-JEPA表现接近，预示着基础模型可能简化系统。Gemini在零样本设置下表现不佳。

**AI_Comments:** 本论文对新兴的基础模型与现有基于骨架的方法在人机交互手势识别中的应用进行了及时比较。V-JEPA虽非最先进，但仅通过简单分类头便取得接近的竞争力，这一发现具有重要意义，预示着未来人机交互系统可能实现更通用、更低复杂度的发展。Gemini Flash 2.0在零样本文本描述下的识别困境，揭示了当前视觉语言模型在手势理解方面的一个关键局限，并强调了更精细的多模态整合或专用手势表示的必要性。此外，NUGGET数据集的引入也是对该领域的一项宝贵贡献。

<details>
  <summary>Details</summary>

**Motivation:** 手势是人机非语言交流的关键，尤其在嘈杂环境中。传统的深度学习手势识别依赖于复杂的、针对特定任务的架构。本研究的动机在于探究视觉基础模型（VFMs）和视觉语言模型（VLMs）是否能凭借其强大的泛化能力，通过取代专用任务模块来降低系统复杂性。

**Method:** 本研究调查了如何将VFM（V-JEPA）和VLM（Gemini Flash 2.0）应用于动态全身手势识别，并将其与表现顶尖的基于骨架的方法（HD-GCN）进行了比较。为评估这些手势识别方法，研究引入了一个专为内部物流环境中人机通信定制的数据集NUGGET。

**Result:** 实验结果显示，HD-GCN取得了最佳性能。然而，V-JEPA通过一个简单的、针对特定任务的分类头也取得了接近的性能。相比之下，Gemini Flash 2.0在零样本设置下，仅凭文本描述难以区分手势。

**Conclusion:** 尽管传统的基于骨架的方法（HD-GCN）目前表现最佳，但V-JEPA等基础模型在手势识别方面显示出降低系统复杂性的潜力，尤其作为共享多任务模型。对于Gemini这类模型，需要进一步研究适合手势的输入表示形式。

> **ai_Abstract:** 本研究评估了基础模型（V-JEPA、Gemini Flash 2.0）与基于骨架的方法（HD-GCN）在人机交互中动态全身手势识别方面的性能。研究引入了NUGGET数据集进行评估。结果显示，HD-GCN表现最佳，但V-JEPA通过简单的分类头也取得了接近的性能，表明其在简化系统复杂性方面的潜力。Gemini Flash 2.0在零样本设置下，仅依赖文本描述时识别手势表现不佳，这强调了对手势合适输入表示进行进一步研究的必要性。

> **摘要翻译:** 手势使非语言人机通信成为可能，尤其是在敏捷生产等嘈杂环境中。传统的基于深度学习的手势识别依赖于使用图像、视频或骨架姿态估计作为输入的特定任务架构。与此同时，视觉基础模型（VFMs）和视觉语言模型（VLMs）凭借其强大的泛化能力，有望通过取代专用任务模块来降低系统复杂性。本研究调查了这些模型在动态全身手势识别中的应用，比较了V-JEPA（最先进的VFM）、Gemini Flash 2.0（多模态VLM）和HD-GCN（表现顶尖的基于骨架的方法）。我们引入了NUGGET数据集，该数据集专为内部物流环境中的人机通信而定制，用于评估不同的手势识别方法。在我们的实验中，HD-GCN取得了最佳性能，但V-JEPA通过一个简单的、针对特定任务的分类头也取得了接近的性能——从而为通过将其用作共享多任务模型来降低系统复杂性铺平了可能的道路。相比之下，Gemini在零样本设置下，仅凭文本描述难以区分手势，这突出表明需要进一步研究适合手势的输入表示形式。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [134] [Leveraging Vision-Language Models to Select Trustworthy Super-Resolution Samples Generated by Diffusion Models](https://arxiv.org/abs/2506.20832)
> *利用视觉-语言模型选择扩散模型生成的可靠超分辨率样本*

*Cansu Korkmaz, Ahmet Murat Tekalp, Zafer Dogan* | **Category: cs.CV, cs.AI**

**Keywords:** 超分辨率, 扩散模型, 视觉-语言模型, 可信度分数, 样本选择

**Comment:** 14 pages, 9 figures, 5 tables, accepted to IEEE Transactions on
  Circuits and Systems for Video Technology

> **TL;DR:** 本文提出一个利用视觉-语言模型从扩散模型生成的超分辨率图像中选择最可靠样本的框架，并通过新的可信度分数（TWS）进行评估，该方法比传统指标更能反映信息保真度。

**AI_Comments:** 创新点：首次将视觉-语言模型应用于扩散模型生成的超分辨率图像的选择和评估，解决了生成多样性但缺乏可靠性选择的痛点。重要性：提出了一个衡量超分辨率图像“可信度”的新颖混合指标TWS，弥补了传统指标在评估信息保真度上的不足，为生成式SR的评估和选择提供了更符合人类感知的标准。

<details>
  <summary>Details</summary>

**Motivation:** 超分辨率是一个病态逆问题，存在多种可行解。回归式SR模型难以平衡保真度和感知质量，常引入伪影，在关键信息应用中造成歧义。扩散模型能生成多样化的SR图像，但从中选择最可靠的解决方案仍是挑战。

**Method:** 本文引入一个鲁棒、自动化的框架，利用视觉-语言模型（VLM，如BLIP-2, GPT-4o）的语义推理能力，通过结构化查询评估语义正确性、视觉质量和伪影存在，从而从扩散模型生成的SR图像集中识别最可靠的样本。排名靠前的SR候选样本将被集成以获得单一可靠输出。为评估VLM选择的有效性，作者提出了一种新颖的混合度量“可信度分数”（TWS），该分数基于CLIP嵌入的语义相似性、边缘图SSIM的结构完整性和多级小波分解的伪影敏感性三个互补组件来量化SR可靠性。

**Result:** 实验证明，TWS在模糊图像和自然图像中都与人类偏好高度相关，并且VLM引导的选择始终产生高TWS值。与PSNR、LPIPS等未能反映信息保真度的传统指标相比，该方法提供了一种原则性、可扩展和可推广的解决方案，能更好地反映信息保真度，以应对扩散SR空间的不确定性。

**Conclusion:** 本工作通过将输出与人类期望和语义正确性对齐，为生成式SR中的可信度设定了新基准，提供了一种克服扩散SR不确定性的有效方法。

> **ai_Abstract:** 本文提出一个利用视觉-语言模型（VLM）从扩散模型生成的超分辨率（SR）图像集中选择最可靠样本的新框架。该框架通过VLM评估SR样本的语义正确性、视觉质量和伪影，并将高排名样本集成。为验证VLM选择的有效性，作者引入了一种新颖的混合度量“可信度分数”（TWS），该分数综合考虑语义相似性、结构完整性和伪影敏感性。实验证明，TWS与人类偏好高度相关，且VLM引导的选择能持续获得高TWS值，表明该方法在信息保真度方面优于传统SR评估指标。

> **摘要翻译:** 超分辨率（SR）是一个病态的逆问题，对于给定的低分辨率图像，存在许多可行的解决方案。一方面，回归式SR模型旨在平衡保真度和感知质量以产生单一解决方案，但这种权衡常常引入伪影，在识别数字或字母等信息关键应用中造成歧义。另一方面，扩散模型生成多样化的SR图像，但从这组图像中选择最可靠的解决方案仍然是一个挑战。本文引入了一个鲁棒、自动化的框架，通过利用视觉-语言模型（VLM）的语义推理能力，从扩散模型生成的图像集中识别最可靠的SR样本。具体而言，BLIP-2、GPT-4o及其变体等VLM通过结构化查询来评估语义正确性、视觉质量和伪影存在。然后将排名靠前的SR候选样本进行集成，以经济高效的方式获得单一的可靠输出。为了严格评估VLM选择样本的有效性，我们提出了一种新颖的“可信度分数”（TWS），这是一个混合度量，它基于三个互补组件量化SR可靠性：通过CLIP嵌入的语义相似性、使用边缘图SSIM的结构完整性，以及通过多级小波分解的伪影敏感性。我们通过实验证明，TWS在模糊图像和自然图像中都与人类偏好高度相关，并且VLM引导的选择始终产生高TWS值。与PSNR、LPIPS等未能反映信息保真度的传统指标相比，我们的方法为解决扩散SR空间的不确定性提供了一种原则性、可扩展和可推广的解决方案。通过将输出与人类期望和语义正确性对齐，这项工作为生成式SR中的可信度设定了新基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [151] [FixCLR: Negative-Class Contrastive Learning for Semi-Supervised Domain Generalization](https://arxiv.org/abs/2506.20841)
> *FixCLR：半监督域泛化的负类对比学习*

*Ha Min Son, Shahbaz Rezaei, Xin Liu* | **Category: cs.CV, cs.AI**

**Keywords:** 半监督域泛化, 对比学习, 域不变性, 伪标签, FixCLR

**Comment:** 

> **TL;DR:** FixCLR引入负类对比学习，通过显式域不变性正则化来改进半监督域泛化（SSDG），尤其是在标签稀缺的情况下。

**AI_Comments:** FixCLR的创新之处在于将负类对比学习引入半监督域泛化，并通过显式正则化来学习域不变表示，解决了传统SSDG方法在标签稀缺下的性能瓶颈。其模块化设计允许与现有方法结合，增强了其实用性和影响力。该研究还通过广泛且新颖的实验设置，对SSDG领域进行了深入探索。

<details>
  <summary>Details</summary>

**Motivation:** 半监督域泛化（SSDG）在数据分布外泛化时，由于标签稀缺，现有方法往往表现不佳。这些方法未能明确地正则化以学习跨所有域的域不变表示，而这正是域泛化的关键目标。

**Method:** 本文引入了FixCLR。受自监督学习的启发，FixCLR修改了对比学习的两个关键组件，以实现显式的域不变性正则化：利用伪标签的类别信息和仅使用排斥项。FixCLR还可以与大多数现有的SSDG和半监督方法结合使用，以获得互补的性能改进。

**Result:** 研究包括了SSDG研究中以前未曾探索过的广泛实验，包括对半监督方法不同改进的基准测试、预训练模型与非预训练模型性能的评估，以及在多域数据集上的测试。FixCLR被证明是一种有效的SSDG方法，特别是与其他半监督方法结合使用时。

**Conclusion:** FixCLR被证明是一种有效的半监督域泛化（SSDG）方法，尤其是在与其他半监督方法结合使用时，它通过显式的域不变性正则化解决了现有方法的不足。

> **ai_Abstract:** 本文提出FixCLR，一种针对半监督域泛化（SSDG）的新方法，旨在解决现有方法在标签稀缺下无法有效学习域不变表示的问题。FixCLR通过修改对比学习的组件，即利用伪标签的类别信息和仅使用排斥项，实现显式的域不变性正则化。实验证明，FixCLR是一种有效的SSDG方法，并且可以与现有半监督方法结合使用以进一步提升性能，尤其适用于多域数据集和评估预训练模型。

> **摘要翻译:** 半监督域泛化（SSDG）旨在解决当只有少量标签可用时，泛化到分布外数据的问题。由于标签稀缺，应用域泛化方法通常表现不佳。因此，现有的SSDG方法将半监督学习方法与各种正则化项结合起来。然而，这些方法没有明确地正则化以学习跨所有域的域不变表示，而这正是域泛化的一个关键目标。为了解决这个问题，我们引入了FixCLR。受自监督学习成功的启发，我们改变了两个关键组件，以使对比学习适应显式的域不变性正则化：利用伪标签的类别信息和仅使用排斥项。FixCLR还可以添加到大多数现有的SSDG和半监督方法之上，以实现互补的性能改进。我们的研究包括了SSDG研究中以前未曾探索过的广泛实验。这些实验包括对半监督方法不同改进的基准测试、评估预训练模型与非预训练模型的性能，以及在多域数据集上进行多域数据集的测试。总的来说，FixCLR被证明是一种有效的SSDG方法，特别是当与其它半监督方法结合使用时。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [156] [Step-by-Step Video-to-Audio Synthesis via Negative Audio Guidance](https://arxiv.org/abs/2506.20995)
> *负面音频引导的逐步视频到音频合成*

*Akio Hayakawa, Masato Ishii, Takashi Shibuya, Yuki Mitsufuji* | **Category: cs.CV, cs.LG, cs.SD, eess.AS**

**Keywords:** 视频到音频合成, 拟音, 负面音频引导, 音频生成, 分步生成

**Comment:** 

> **TL;DR:** 提出一种受拟音启发的分步视频到音频合成方法，通过负面音频引导生成高质量的独立音轨。

**AI_Comments:** 这篇论文的创新点在于其分步生成独立音轨的方法，这与传统的拟音工作流程相呼应，提高了合成音频的精细度和质量。特别值得注意的是，它利用概念否定思想进行引导式生成，并且能够利用预训练模型并在无需专门配对数据集的情况下进行训练，这大大降低了数据门槛，使其方法更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在全面捕捉视频中由特定声音事件引起的所有音效，并克服对专用配对数据集的需求。

**Method:** 提出一种新颖的逐步视频到音频生成方法，按顺序生成与视频中特定声音事件对应的独立音轨。每个生成步骤都被表述为引导式视频到音频合成任务，以目标文本提示和先前生成的音轨为条件。该设计受概念否定思想的启发，并引入了一个训练框架，利用预训练的视频到音频模型，无需专门的配对数据集。

**Result:** 该方法为单个输入视频生成了多个语义上不同的音轨，并产生了比现有基线更高质量的复合音频合成。

**Conclusion:** 该研究成功开发了一种分步视频到音频合成方法，能够生成高质量、语义独立的音轨，从而在无需专用配对数据集的情况下实现卓越的复合音频合成。

> **ai_Abstract:** 本文提出一种新颖的分步视频到音频合成方法，通过模仿传统拟音工作流程，顺序生成与视频中声音事件对应的独立音轨。该方法将每个步骤视为引导式合成任务，并利用受概念否定启发的训练框架，在无需专用配对数据集的情况下，利用预训练模型进行训练。实验证明，该方法能为单个视频生成多个语义独立的音轨，并产生优于现有基线的复合音频质量。

> **摘要翻译:** 我们提出了一种新颖的逐步视频到音频生成方法，该方法按顺序生成独立的音轨，每个音轨对应视频中的特定声音事件。我们的方法模仿传统的拟音工作流程，旨在全面捕捉给定视频引起的所有声音事件。每个生成步骤都被表述为引导式视频到音频合成任务，以目标文本提示和先前生成的音轨为条件。这种设计灵感来源于先前组合生成框架中的概念否定思想。为了实现这种引导式生成，我们引入了一个训练框架，该框架利用预训练的视频到音频模型，并消除了对专用配对数据集的需求，从而允许在更易获取的数据上进行训练。实验结果表明，我们的方法为单个输入视频生成了多个语义上不同的音轨，从而产生了比现有基线更高质量的复合音频合成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [171] [Vector Contrastive Learning For Pixel-Wise Pretraining In Medical Vision](https://arxiv.org/abs/2506.20850)
> *用于医学视觉中像素级预训练的向量对比学习*

*Yuting He, Shuo Li* | **Category: cs.CV**

**Keywords:** 对比学习, 像素级预训练, 医学视觉, 自监督预训练, 向量回归

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 向量对比学习（COVER）通过解决标准对比学习中的过度分散问题，显著改进了医学视觉中的像素级预训练。

**AI_Comments:** 该论文的创新点在于将对比学习重新表述为向量回归问题，并提出了COVER框架来解决标准对比学习中像素级表示的过度分散问题。这对于医学视觉中像素级预训练至关重要，有助于推动可泛化的医学视觉基础模型的发展。

<details>
  <summary>Details</summary>

**Motivation:** 将对比学习扩展到像素级表示对于医学视觉至关重要，但仍然是一个开放问题。标准对比学习存在过度分散问题，破坏了像素级特征相关性并扰乱了类内分布。

**Method:** 该研究将对比学习重新表述为向量回归问题，通过建模位移向量中的特征距离来实现像素级预训练中的分散量化。为此，提出了COntrast in VEctor Regression (COVER)框架。COVER建立可扩展的基于向量的自学习，强制从向量回归到距离建模的一致优化流，并利用向量金字塔架构进行粒度适应，从而在自监督预训练中保留像素级特征相关性。

**Result:** 在涵盖2个维度和4种模态的8项任务中进行的广泛实验表明，COVER显著改进了像素级自监督预训练，推动了可泛化的医学视觉基础模型发展。

**Conclusion:** COVER显著改进了像素级自监督预训练，并推动了可泛化的医学视觉基础模型的发展。

> **ai_Abstract:** 标准对比学习在医学视觉的像素级预训练中存在过度分散问题。该研究提出向量对比学习，将其重构为向量回归问题，并引入COVER框架，通过建立向量自学习、优化流和向量金字塔架构来保留像素级特征相关性。实验证明COVER在多任务和多模态上显著提升了像素级自监督预训练效果。

> **摘要翻译:** 对比学习（CL）已成为基础模型中自监督预训练（SSP）的基石，然而，将CL扩展到像素级表示（这对医学视觉至关重要）仍然是一个开放问题。标准CL将SSP表述为二元优化问题（二元CL），其中过度追求特征分散导致过度分散问题，破坏了像素级特征相关性，从而扰乱了类内分布。我们的向量CL将CL重新表述为向量回归问题，通过在回归位移向量中建模特征距离，从而实现像素级预训练中的分散量化。为了实现这一新范式，我们提出了COntrast in VEctor Regression (COVER)框架。COVER建立了可扩展的基于向量的自学习，强制从向量回归到距离建模的一致优化流，并利用向量金字塔架构进行粒度适应，从而在SSP中保留像素级特征相关性。在涵盖2个维度和4种模态的8项任务中进行的广泛实验表明，COVER显著改进了像素级SSP，推动了可泛化的医学视觉基础模型发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [186] [Enhancing Ambiguous Dynamic Facial Expression Recognition with Soft Label-based Data Augmentation](https://arxiv.org/abs/2506.20867)
> *增强基于软标签的数据增强的模糊动态面部表情识别*

*Ryosuke Kawamura, Hideaki Hayashi, Shunsuke Otake, Noriko Takemura, Hajime Nagahara* | **Category: cs.CV**

**Keywords:** 动态面部表情识别, 数据增强, 软标签, 模糊表情, mixup

**Comment:** 

> **TL;DR:** 提出MIDAS，一种基于软标签数据增强方法，旨在提高模糊动态面部表情识别（DFER）性能。

**AI_Comments:** 该论文提出了一种新颖的数据增强方法MIDAS，通过引入软标签和扩展mixup机制，有效解决了动态面部表情识别中模糊表情的挑战。其创新性在于将软标签与数据增强结合，为处理情感模糊性提供了一个简洁而高效的方案。文中提及构建新的FERV39k-Plus数据集也值得关注，为该领域研究提供了新的资源。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，准确识别野外数据中常见的模糊面部表情对于动态面部表情识别（DFER）至关重要。

**Method:** 本研究提出MIDAS，一种数据增强方法。该方法通过凸组合视频帧对及其对应的软标签（代表多个情感类别的概率）来扩充训练数据，从而将mixup扩展到软标签视频数据，以增强模糊面部表情数据的DFER性能。

**Result:** 实验结果表明，使用MIDAS增强数据训练的模型在DFEW数据集和新构建的FERV39k-Plus数据集上，比在原始数据集上训练的现有最先进方法表现出更优越的性能。

**Conclusion:** MIDAS是一种简单而高效的方法，能够有效处理动态面部表情识别中的模糊性，并显著提升模型性能。

> **ai_Abstract:** 本研究提出MIDAS，一种基于软标签的数据增强方法，旨在提升动态面部表情识别（DFER）中对模糊表情的识别能力。MIDAS通过凸组合视频帧及其软标签来扩展mixup，以有效处理模糊性。实验结果表明，在DFEW和FERV39k-Plus数据集上，使用MIDAS增强数据训练的模型性能优于现有最先进方法。

> **摘要翻译:** 动态面部表情识别（DFER）是一项从面部表情视频序列中估计情感的任务。对于实际应用而言，准确识别野外数据中频繁遇到的模糊面部表情至关重要。在本研究中，我们提出了MIDAS，一种旨在通过使用表示多个情感类别概率的软标签来增强模糊面部表情数据的DFER性能的数据增强方法。MIDAS通过凸组合视频帧对及其对应的情感类别标签来扩充训练数据。这种方法将mixup扩展到软标签视频数据，为处理DFER中的模糊性提供了一种简单而高效的方法。为了评估MIDAS，我们在DFEW数据集和FERV39k-Plus（一个将软标签分配给现有DFER数据集的新构建数据集）上进行了实验。结果表明，使用MIDAS增强数据训练的模型比在原始数据集上训练的现有最先进方法取得了更优越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [200] [THIRDEYE: Cue-Aware Monocular Depth Estimation via Brain-Inspired Multi-Stage Fusion](https://arxiv.org/abs/2506.20877)
> *THIRDEYE：基于脑启发式多阶段融合的线索感知单目深度估计*

*Calin Teodor Ioan* | **Category: cs.CV, cs.AI, I.4.8; I.2.10**

**Keywords:** 单目深度估计, 线索感知, 脑启发, 多阶段融合, ThirdEye

**Comment:** 

> **TL;DR:** ThirdEye是一个利用预训练网络提供的显式单目线索，并通过脑启发式多阶段融合来估计深度的系统，解决了传统方法忽视人类视觉系统依赖的线索问题。

**AI_Comments:** 该论文的创新点在于其脑启发式的多阶段融合架构和显式线索感知的方法，这与传统深度学习的隐式学习形成对比。通过利用预训练的线索专家网络并将其冻结，该系统能够继承大量外部监督，从而减少了自身训练的需求，这在效率和性能上可能具有重要意义。然而，抽象中明确指出定量结果将在未来版本中提供，这意味着目前尚无法评估其实际性能。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单目深度估计方法通过隐式学习从RGB像素推断深度，常常忽略了人类视觉系统所依赖的显式单目线索（如遮挡边界、阴影和透视）。本文的动机是设计一个能够主动利用这些显式线索的深度估计系统。

**Method:** ThirdEye是一个线索感知的流水线，通过专门的、预训练且冻结的网络提供显式线索。这些线索在一个三阶段皮层层级（V1->V2->V3）中融合，该层级配备了键值工作记忆模块，根据可靠性对线索进行加权。然后，一个自适应分箱Transformer头部生成高分辨率视差图。由于线索专家网络是冻结的，ThirdEye继承了大量的外部监督，同时只需要适度的微调。

**Result:** 定量结果将在未来的修订版中提供。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** ThirdEye是一种新型的单目深度估计算法，旨在解决传统方法忽视人类视觉系统所利用的显式线索的问题。它通过预训练且冻结的专家网络主动提供遮挡边界、阴影和透视等线索，并在一个受大脑启发的V1->V2->V3三阶段皮层层级中融合这些线索，其中包含一个基于可靠性加权的键值工作记忆模块。最后，一个自适应分箱Transformer头部生成高分辨率视差图。该方法通过利用外部监督减少了微调需求。

> **摘要翻译:** 单目深度估计方法传统上训练深度模型直接从RGB像素推断深度。这种隐式学习常常忽略了人类视觉系统所依赖的显式单目线索，例如遮挡边界、阴影和透视。我们没有期望网络在没有帮助的情况下发现这些线索，而是提出了ThirdEye，一个线索感知的流水线，通过专门的、预训练且冻结的网络主动提供每种线索。这些线索在一个三阶段皮层层级（V1->V2->V3）中融合，该层级配备了键值工作记忆模块，根据可靠性对它们进行加权。然后，一个自适应分箱Transformer头部生成高分辨率视差图。由于线索专家网络是冻结的，ThirdEye继承了大量的外部监督，同时只需要适度的微调。这个扩展版本提供了额外的架构细节、神经科学动机和扩展的实验协议；定量结果将在未来的修订版中出现。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [215] [MultiHuman-Testbench: Benchmarking Image Generation for Multiple Humans](https://arxiv.org/abs/2506.20879)
> *MultiHuman-Testbench：多人物图像生成基准测试*

*Shubhankar Borse, Seokeon Choi, Sunghyun Park, Jeongho Kim, Shreya Kadambi, Risheek Garrepalli, Sungrack Yun, Munawar Hayat, Fatih Porikli* | **Category: cs.CV**

**Keywords:** 多人物生成, 图像生成, 基准测试, 面部身份, 评估指标

**Comment:** 

> **TL;DR:** 本文提出了MultiHuman-Testbench，一个用于评估多人物图像生成模型的新型基准，解决了现有缺乏专用基准的问题，并提出了新的评估方法和技术以提高身份相似性。

**AI_Comments:** 本文的创新之处在于提出了首个专门用于多人物图像生成的基准测试MultiHuman-Testbench，填补了该领域评估工具的空白。其重要性在于提供了一个标准化的评估框架和数据集，这将极大地促进多人物图像生成技术的发展和比较。同时，提出的结合人体分割和匈牙利匹配的新技术也为提高生成图像中人物身份的保持性提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 生成包含多个执行复杂动作且保留面部身份的人物的图像是一个重大挑战。造成这一挑战的主要原因是缺乏一个专用的基准测试。

**Method:** 引入了MultiHuman-Testbench，一个包含1800个样本（包括文本提示和5,550个独特人脸图像）以及人工选择的姿态条件图像的新型基准。提出了一个多方面的评估套件，采用面部计数、ID相似性、提示对齐和动作检测四项关键指标。此外，还提出了利用人体分割和匈牙利匹配来整合图像和区域隔离的新技术。

**Result:** 对包括零样本方法和基于训练的方法在内的多种模型进行了彻底评估。提出的新技术显著提高了ID相似性。

**Conclusion:** 提出的基准和关键发现为推进多人物图像生成研究提供了宝贵的见解和标准化工具。

> **ai_Abstract:** 本文介绍了MultiHuman-Testbench，这是一个专门针对多人物图像生成任务的新型基准测试。该基准包含1800个多样化样本，包括文本提示和大量人脸图像，并辅以人工选择的姿态条件图像。研究者提出了一个包含四项关键指标的多方面评估框架，并开发了结合人体分割和匈牙利匹配的新技术，以提高生成图像中人物身份的相似性。通过对多种模型进行评估，该研究为多人物图像生成领域提供了一个标准化的评估工具和有价值的见解。

> **摘要翻译:** 生成包含多个执行复杂动作且保留面部身份的人物的图像是一个重大挑战。造成这一挑战的主要原因是缺乏一个专用的基准测试。为了解决这个问题，我们引入了MultiHuman-Testbench，一个用于严格评估多人物生成模型的生成模型的新型基准。该基准包含1800个样本，包括精心策划的文本提示，描述了从简单到复杂的人类动作。这些提示与总共5,550张独特的人脸图像匹配，这些图像经过均匀采样，以确保年龄、种族背景和性别多样性。除了说明文字，我们还提供了人工选择的姿态条件图像，这些图像准确匹配提示。我们提出了一个多方面的评估套件，采用面部计数、ID相似性、提示对齐和动作检测四项关键指标。我们对包括零样本方法和基于训练的方法在内的多种模型进行了彻底评估，无论是否包含区域先验。我们还提出了利用人体分割和匈牙利匹配来整合图像和区域隔离的新技术，显著提高了ID相似性。我们提出的基准和关键发现为推进多人物图像生成研究提供了宝贵的见解和标准化工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [216] [Out-of-Distribution Semantic Occupancy Prediction](https://arxiv.org/abs/2506.21185)
> *分布外语义占据预测*

*Yuheng Zhang, Mengfei Duan, Kunyu Peng, Yuhang Wang, Ruiping Liu, Fei Teng, Kai Luo, Zhiyong Li, Kailun Yang* | **Category: cs.CV, cs.RO, eess.IV**

**Keywords:** 分布外, 语义占据预测, 自动驾驶, 异常检测, 3D体素

**Comment:** The established datasets and source code will be made publicly
  available at https://github.com/7uHeng/OccOoD

> **TL;DR:** 现有3D语义占据预测方法在分布外（OoD）物体上表现不佳。本文提出了OccOoD框架和VAA-KITTI、VAA-KITTI-360数据集，以解决此问题，实现了最先进的OoD检测性能，同时保持了竞争力占据预测能力。

**AI_Comments:** 该论文通过解决自动驾驶中经常被忽视的分布外场景，为提高自动驾驶安全性指明了一个关键方向。合成异常数据集的创建对于解决该领域数据稀缺性问题具有创新性，而所提出的OccOoD框架及其VBPF和基于RWKV的分支为集成OoD检测提供了一种新颖的架构设计。同时关注OoD检测和保持占据预测性能是其一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D语义占据预测方法主要关注分布内场景，容易受到分布外（OoD）物体和长尾分布的影响，这增加了未检测到的异常和误判的风险，从而对自动驾驶构成安全隐患。

**Method:** 本文提出了“分布外语义占据预测”的概念。为弥补数据集空白，引入了“合成异常集成管道”来创建VAA-KITTI和VAA-KITTI-360两个数据集，通过注入合成异常同时保留真实的几何和遮挡模式。此外，还提出了一个名为“OccOoD”的新型框架，将OoD检测集成到3D语义占据预测中，其中包含“体素-BEV渐进融合（VBPF）”模块，该模块利用基于RWKV的分支通过几何-语义融合来增强OoD检测。

**Result:** 实验结果表明，OccOoD在1.2米区域内实现了最先进的OoD检测，AuROC为67.34%，AuPRCr为29.21%，同时保持了有竞争力的占据预测性能。

**Conclusion:** 本文成功引入了一个新颖的框架（OccOoD）和数据集（VAA-KITTI、VAA-KITTI-360），实现了分布外语义占据预测，显著提高了自动驾驶的OoD检测性能，增强了安全性。

> **ai_Abstract:** 本文旨在解决自动驾驶中3D语义占据预测对分布外（OoD）物体识别不足的挑战。为此，研究提出了一种“合成异常集成管道”以构建VAA-KITTI和VAA-KITTI-360两个新数据集，其中注入了合成异常。核心贡献是“OccOoD”框架，它将OoD检测集成到3D语义占据预测中，并利用包含RWKV分支的“体素-BEV渐进融合（VBPF）”模块来增强OoD检测。实验证明，OccOoD在保持占据预测性能的同时，实现了最先进的OoD检测。

> **摘要翻译:** 3D语义占据预测对于自动驾驶至关重要，它提供了密集、语义丰富的环境表示。然而，现有方法侧重于分布内场景，使其容易受到分布外（OoD）物体和长尾分布的影响，这增加了未检测到的异常和误解的风险，从而构成安全隐患。为了解决这些挑战，我们引入了分布外语义占据预测，旨在3D体素空间中进行OoD检测。为了填补数据集的空白，我们提出了一种合成异常集成管道，该管道在保留真实空间和遮挡模式的同时注入合成异常，从而能够创建两个数据集：VAA-KITTI和VAA-KITTI-360。我们引入了OccOoD，一个将OoD检测集成到3D语义占据预测中的新型框架，其中Voxel-BEV渐进融合（VBPF）利用基于RWKV的分支通过几何-语义融合来增强OoD检测。实验结果表明，OccOoD在1.2米区域内实现了最先进的OoD检测，AuROC为67.34%，AuPRCr为29.21%，同时保持了有竞争力的占据预测性能。已建立的数据集和源代码将在https://github.com/7uHeng/OccOoD 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [226] [The Role of Cyclopean-Eye in Stereo Vision](https://arxiv.org/abs/2506.20900)
> *独眼巨人眼在立体视觉中的作用*

*Sherlon Almeida da Silva, Davi Geiger, Luiz Velho, Moacir Antonelli Ponti* | **Category: cs.CV**

**Keywords:** 立体视觉, 独眼巨人眼, 深度重建, 几何先验, 深度学习

**Comment:** arXiv admin note: text overlap with arXiv:2502.21280

> **TL;DR:** 本文探讨了独眼巨人眼模型在现代立体视觉系统中的几何基础，并结合深度学习和注意力机制，证明了几何先验与学习特征结合能有效提升深度重建。

**AI_Comments:** 这篇论文通过重新审视经典的独眼巨人眼模型，并将其与现代深度学习技术（如深度学习特征匹配和注意力机制）相结合，为立体视觉的深度重建提供了新的视角。其创新点在于强调了几何先验在数据驱动方法中的重要性，揭示了将传统几何理论与现代AI技术融合的潜力，可能为更鲁棒和准确的立体视觉系统奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 探讨现代立体视觉系统中的几何基础，特别是3D结构和受人类启发的感知如何促进准确的深度重建。

**Method:** 重新审视独眼巨人眼模型，提出新的几何约束以处理遮挡和深度不连续性。评估深度学习模型导出的立体特征匹配质量，以及注意力机制在恢复有意义的3D表面中的作用。通过理论分析和真实数据集的实证研究。

**Result:** 结合强大的几何先验与学习特征为理解立体视觉系统提供了内部抽象。

**Conclusion:** 结合强大的几何先验与学习特征为理解立体视觉系统提供了内部抽象。

> **ai_Abstract:** 本文深入研究了现代立体视觉系统的几何原理，并重新审视了独眼巨人眼模型。研究引入了新的几何约束来处理遮挡和深度不连续性，并评估了深度学习模型产生的立体特征匹配质量以及注意力机制在3D表面恢复中的作用。通过理论和实验，论文指出结合强几何先验和学习特征能有效提升对立体视觉系统的理解和深度重建。

> **摘要翻译:** 这项工作研究了现代立体视觉系统的几何基础，重点关注3D结构和受人类启发的感知如何有助于准确的深度重建。我们重新审视了独眼巨人眼模型，并提出了新的几何约束，以解释遮挡和深度不连续性。我们的分析包括评估来自深度学习模型的立体特征匹配质量，以及注意力机制在恢复有意义的3D表面中的作用。通过理论见解和真实数据集的实证研究，我们证明了将强大的几何先验与学习特征相结合，为理解立体视觉系统提供了内部抽象。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [228] [Unlocking Constraints: Source-Free Occlusion-Aware Seamless Segmentation](https://arxiv.org/abs/2506.21198)
> *解锁约束：无源遮挡感知无缝分割*

*Yihong Cao, Jiaming Zhang, Xu Zheng, Hao Shi, Kunyu Peng, Hang Liu, Kailun Yang, Hui Zhang* | **Category: cs.CV, cs.RO, eess.IV**

**Keywords:** 无源分割, 全景图像, 遮挡感知, 域适应, 无监督学习

**Comment:** Accepted to ICCV 2025. All data and code will be made publicly
  available at https://github.com/yihong-97/UNLOCK

> **TL;DR:** 本文提出了一种名为SFOASS的无源遮挡感知无缝分割任务及其首个解决方案UNLOCK，该方案无需源数据或目标标签，即可在全景图像上实现与有源方法相当的分割性能，并具有遮挡感知能力。

**AI_Comments:** 该论文的创新点在于提出了无源遮挡感知无缝分割这一更实用的任务，并提供了首个解决方案UNLOCK。其核心优势在于无需访问源数据和目标标签即可实现高性能的全景图像分割，这大大降低了实际应用的门槛。通过集成全方位伪标签学习和非模态驱动上下文学习，UNLOCK有效地解决了全景图像中的扭曲、遮挡和视角覆盖问题，为全景感知领域提供了一个重要且实用的进展。

<details>
  <summary>Details</summary>

**Motivation:** 全景图像处理在全方位感知中至关重要，但面临扭曲、透视遮挡和标注受限等挑战。现有的无监督域适应方法需要访问源针孔数据，这在实际应用中是一种限制。

**Method:** 本文引入了无源遮挡感知无缝分割（SFOASS）任务，并提出了第一个解决方案UNconstrained Learning Omni-Context Knowledge (UNLOCK)。UNLOCK框架包括两个关键模块：全方位伪标签学习（Omni Pseudo-Labeling Learning）和非模态驱动上下文学习（Amodal-Driven Context Learning）。该方法无需依赖源数据或目标标签，即可使模型实现360度视角覆盖和遮挡感知推理的分割。

**Result:** 实验结果表明，所提出的无源方法实现了与依赖源数据方法相当的性能，在mAAP上达到10.9，mAP上达到11.6，均为最先进水平，并且相对于仅使用源数据的方法，mAPQ有+4.3的绝对提升。

**Conclusion:** 本文提出的无源遮挡感知无缝分割方法UNLOCK在全景图像处理中表现出色，实现了与有源方法相当的性能，并在没有源数据或目标标签的情况下，有效解决了全景图像分割中的遮挡和视角覆盖问题。

> **ai_Abstract:** 本文针对全景图像处理中存在的扭曲、遮挡和标注限制以及现有域适应方法对源数据的依赖问题，提出了无源遮挡感知无缝分割（SFOASS）任务及其首个解决方案UNLOCK。UNLOCK包含全方位伪标签学习和非模态驱动上下文学习模块，使其能够在不依赖源数据或目标标签的情况下，实现360度视角覆盖和遮挡感知分割。实验证明，UNLOCK在性能上可与依赖源数据的方法媲美，并取得了最先进的结果。

> **摘要翻译:** 全景图像处理对于全方位感知至关重要，但面临扭曲、透视遮挡和标注受限等约束。以前的无监督域适应方法将知识从带标签的针孔数据转移到无标签的全景图像，但它们需要访问源针孔数据。为了解决这些问题，我们引入了一个更实用的任务，即无源遮挡感知无缝分割（Source-Free Occlusion-Aware Seamless Segmentation, SFOASS），并提出了其第一个解决方案，名为无约束学习全方位知识（UNconstrained Learning Omni-Context Knowledge, UNLOCK）。具体而言，UNLOCK包括两个关键模块：全方位伪标签学习（Omni Pseudo-Labeling Learning）和非模态驱动上下文学习（Amodal-Driven Context Learning）。在不依赖源数据或目标标签的情况下进行适应，该框架增强了模型，以实现360度视角覆盖和遮挡感知推理的分割。此外，我们通过真实到真实和合成到真实两种适应设置，对所提出的SFOASS任务进行了基准测试。实验结果表明，我们的无源方法实现了与依赖源数据方法相当的性能，在mAAP上达到10.9，mAP上达到11.6，均为最先进水平，并且相对于仅使用源数据的方法，mAPQ有+4.3的绝对提升。所有数据和代码将公开在https://github.com/yihong-97/UNLOCK。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [240] [FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing](https://arxiv.org/abs/2506.20911)
> *FaSTA*: 结合子程序挖掘的快慢工具路径智能体，用于高效多轮图像编辑*

*Advait Gupta, Rishie Raj, Dang Nguyen, Tianyi Zhou* | **Category: cs.CV**

**Keywords:** 多轮图像编辑, 神经符号智能体, 大型语言模型, A*搜索, 子程序挖掘

**Comment:** 

> **TL;DR:** FaSTA*是一个高效的神经符号智能体，通过结合LLM的快速规划和A*的慢速搜索，并挖掘可重用子程序，实现高效的多轮图像编辑，同时显著提高计算效率。

**AI_Comments:** FaSTA*的创新性在于其结合了LLM的高级规划能力和A*的精确搜索，并通过子程序挖掘和重用机制实现了显著的效率提升。这种快慢结合的神经符号方法，模拟了人类解决问题的过程，即先尝试已知或高层策略，失败后再进行细致探索，这在复杂多步骤任务中具有很高的应用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决复杂的多轮图像编辑任务，并开发一个成本高效的神经符号智能体。

**Method:** 本文提出FaSTA*，一个成本高效的神经符号智能体，用于处理多轮图像编辑任务。它结合大型语言模型（LLMs）进行快速的高级子任务规划，以及每子任务的慢速、精确的工具使用和局部A*搜索，以找到成本高效的工具路径。为了节省A*搜索在相似子任务上的成本，FaSTA*通过LLMs对先前成功的工具路径进行归纳推理，持续提取和优化常用子程序，并将其作为新工具在未来的任务中重用，实现自适应的快慢规划。

**Result:** FaSTA*在计算效率上显著优于现有图像编辑方法，同时在成功率方面与最先进的基线保持竞争力。

**Conclusion:** 该研究成功开发并验证了FaSTA*，一个在多轮图像编辑任务中既高效又具有竞争力的神经符号智能体，其通过结合LLM规划和A*搜索，并引入子程序挖掘和重用机制，显著提升了性能。

> **ai_Abstract:** 本文提出了一种名为FaSTA*的成本高效神经符号智能体，用于处理复杂的多轮图像编辑任务。FaSTA*结合了大型语言模型进行快速高层子任务规划和A*搜索进行精确的底层工具使用。其核心创新在于通过LLM对成功工具路径进行子程序挖掘，将常用操作封装并重用，从而显著降低了重复任务的探索成本。实验结果表明，FaSTA*在计算效率上远超现有方法，同时在成功率上与最先进的基线持平。

> **摘要翻译:** 我们开发了一种成本高效的神经符号智能体，以解决“检测图像中的长凳并将其重新着色为粉红色。此外，删除猫以获得更清晰的视图并将墙壁重新着色为黄色”等具有挑战性的多轮图像编辑任务。它结合了大型语言模型（LLMs）的快速、高级子任务规划与每个子任务的慢速、精确的工具使用和局部A*搜索，以找到一个成本高效的工具路径——一系列对AI工具的调用。为了节省A*在相似子任务上的成本，我们通过LLMs对先前成功的工具路径进行归纳推理，持续提取/优化常用子程序，并将其作为新工具在未来的任务中重用，实现自适应的快慢规划。在这种规划中，首先探索更高级别的子程序，只有当它们失败时，才会激活低级别的A*搜索。可重用的符号子程序显著节省了应用于相似图像的相同类型子任务的探索成本，从而产生了一个类人化的快慢工具路径智能体“FaSTA*”：首先由LLMs尝试快速子任务规划，然后是基于规则的每子任务子程序选择，预计这可以覆盖大多数任务，而慢速A*搜索仅针对新颖和具有挑战性的子任务触发。通过与最近的图像编辑方法进行比较，我们证明FaSTA*在计算效率上显著更高，同时在成功率方面与最先进的基线保持竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [242] [Generalizable Neural Electromagnetic Inverse Scattering](https://arxiv.org/abs/2506.21349)
> *可泛化神经电磁逆散射*

*Yizhe Cheng, Chunxun Tian, Haoru Wang, Wentao Zhu, Xiaoxuan Ma, Yizhou Wang* | **Category: cs.CV, eess.IV**

**Keywords:** 电磁逆散射, 泛化能力, 物理驱动, 感应电流, 稀疏发射器

**Comment:** 

> **TL;DR:** 本文提出一种可泛化的物理驱动神经框架，用于解决电磁逆散射问题（EISP）。该框架利用感应电流作为中间表示，有效克服了现有方法在泛化能力和稀疏发射器设置下的局限性，并在重建精度、泛化能力和鲁棒性方面优于现有技术。

**AI_Comments:** 该论文通过引入物理驱动的感应电流作为中间表示，巧妙地解耦了电磁逆散射问题中的非线性和病态性，从而显著提升了模型的泛化能力和对稀疏数据设置的鲁棒性。这种结合物理洞察与深度学习的方法是解决复杂逆问题的创新范式。

<details>
  <summary>Details</summary>

**Motivation:** 解决电磁逆散射问题（EISP）固有的病态性和高度非线性挑战，特别是针对现有机器学习方法（如Img-Interiors）存在的需要案例特定优化、缺乏对未知数据的泛化能力以及在稀疏发射器设置（例如只有一个发射器）下失效的局限性。

**Method:** 本文从物理信息角度重新审视EISP，将其重新表述为两阶段逆透射-散射过程，并发现感应电流是可泛化的中间表示。在此基础上，提出首个可泛化的物理驱动EISP框架，包含一个电流估计器和一个介电常数求解器。电流估计器学习感应电流作为入射场和散射场之间的物理桥梁，介电常数求解器直接从估计的感应电流计算相对介电常数。

**Result:** 实验表明，本文方法在重建精度、泛化能力和鲁棒性方面均优于现有最先进的方法，并且对发射器稀疏性保持强大的鲁棒性。

**Conclusion:** 该工作为电磁逆散射提供了一个全新的视角，代表着向实现成本效益高的电磁成像实用解决方案迈出了重要一步。

> **ai_Abstract:** 本文提出一种可泛化的神经电磁逆散射框架，旨在克服现有机器学习方法在电磁逆散射问题（EISP）中泛化能力差和对稀疏发射器设置不鲁棒的局限性。通过将EISP重新构想为两阶段过程，并利用感应电流作为可泛化的中间表示，该框架通过电流估计器和介电常数求解器实现了端到端的介电常数预测。实验证明，该方法在重建精度、泛化能力和鲁棒性方面均优于现有技术。

> **摘要翻译:** 解决电磁逆散射问题（EISP）在医学成像等应用中至关重要，其目标是从散射电磁场中重建相对介电常数。这个逆过程本质上是病态且高度非线性的，这使得它特别具有挑战性。最近一种基于机器学习的方法Img-Interiors通过利用连续隐函数显示出有希望的结果。然而，它需要针对特定案例进行优化，缺乏对未知数据的泛化能力，并且在稀疏发射器设置下（例如只有一个发射器）会失效。为了解决这些局限性，我们从物理信息的角度重新审视EISP，将其重新表述为两阶段逆透射-散射过程。这种表述揭示了感应电流作为一种可泛化的中间表示，有效地将非线性散射过程与病态逆问题解耦。基于这一见解，我们提出了第一个可泛化的物理驱动EISP框架，它包括一个电流估计器和一个介电常数求解器，以端到端的方式工作。电流估计器明确地学习感应电流作为入射场和散射场之间的物理桥梁，而介电常数求解器直接从估计的感应电流计算相对介电常数。这种设计使得对未知数据进行数据驱动训练和可泛化的前向预测相对介电常数成为可能，同时对发射器稀疏性保持强大的鲁棒性。大量的实验表明，我们的方法在重建精度、泛化能力和鲁棒性方面均优于现有最先进的方法。这项工作为电磁逆散射提供了一个全新的视角，代表着向实现经济高效的电磁成像实用解决方案迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [250] [M2SFormer: Multi-Spectral and Multi-Scale Attention with Edge-Aware Difficulty Guidance for Image Forgery Localization](https://arxiv.org/abs/2506.20922)
> *M2SFormer：结合边缘感知难度指导的多光谱多尺度注意力图像伪造定位*

*Ju-Hyeon Nam, Dong-Hyun Moon, Sang-Chul Lee* | **Category: cs.CV**

**Keywords:** 图像伪造定位, Transformer, 多尺度注意力, 多频注意力, 难度引导

**Comment:** Accepted in International Conference on Computer Vision (ICCV) 2025

> **TL;DR:** M2SFormer是一个基于Transformer的框架，通过统一多频和多尺度注意力以及引入难度引导的注意力模块来解决图像伪造定位中的计算开销和表示能力限制，在基准数据集上表现优于现有SOTA模型。

**AI_Comments:** M2SFormer的创新之处在于其将多频和多尺度注意力统一在跳跃连接中，以及引入了基于曲率度量的难度引导注意力模块。这种结合使得模型能够更全面地捕获伪造痕迹，并有效保留细微细节，从而提高了对复杂和未见伪造的定位能力和泛化性。这是一个重要的进步，对于数字图像取证领域具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习图像伪造定位方法存在计算开销大、表示能力有限的问题，尤其对于细微或复杂的篡改效果不佳。

**Method:** 本文提出了M2SFormer，一个基于Transformer编码器的新框架。它在跳跃连接中统一了多频和多尺度注意力，并利用一个全局先验图（曲率度量）来指示伪造定位的难度，然后引导一个难度引导的注意力模块以更有效地保留细微操作。

**Result:** M2SFormer在多个基准数据集上超越了现有的最先进模型，在检测和定位未见领域伪造方面提供了卓越的泛化能力。

**Conclusion:** M2SFormer通过其新颖的架构和注意力机制，有效解决了图像伪造定位的挑战，并在泛化能力和性能上超越了现有SOTA方法。

> **ai_Abstract:** M2SFormer是一个新颖的基于Transformer编码器的框架，旨在解决现有深度学习方法在图像伪造定位中面临的计算开销和表示能力有限的挑战。它通过在跳跃连接中统一多频和多尺度注意力来捕获多样的伪造痕迹，并利用一个难度引导的注意力模块来保留细微细节，该模块由指示伪造定位难度的全局先验图指导。实验证明M2SFormer在多个基准数据集上超越了现有SOTA模型，并提供了卓越的泛化能力。

> **摘要翻译:** 图像编辑技术发展迅速，既促进了创新应用，也导致了数字图像的恶意篡改。基于深度学习的方法最近在像素级伪造定位方面取得了高精度，但它们经常面临计算开销大和表示能力有限的问题，特别是对于细微或复杂的篡改。在本文中，我们提出了M2SFormer，一个新颖的基于Transformer编码器的框架，旨在克服这些挑战。与单独处理空间和频率线索的方法不同，M2SFormer在跳跃连接中统一了多频和多尺度注意力，利用全局上下文更好地捕获不同的伪造痕迹。此外，我们的框架通过利用全局先验图（一个指示伪造定位难度的曲率度量）来解决上采样过程中精细细节的丢失问题，该先验图随后引导一个难度引导的注意力模块，以更有效地保留细微操作。在多个基准数据集上的大量实验表明，M2SFormer优于现有的最先进模型，在检测和定位未见领域伪造方面提供了卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features](https://arxiv.org/abs/2506.21046)
> *提升生成式对抗迁移性与自监督视觉Transformer特征*

*Shangbo Wu, Yu-an Tan, Ruinan Ma, Wencong Ma, Dehua Zhu, Yuanzhang Li* | **Category: cs.CV, cs.CR**

**Keywords:** 对抗攻击, 黑盒迁移性, 自监督学习, Vision Transformer, 生成式对抗网络

**Comment:** 14 pages, 9 figures, to appear in ICCV 2025

> **TL;DR:** 本文提出dSVA，一种利用自监督ViT（结合对比学习和掩蔽图像建模）提取的全局和局部特征来生成对抗样本的方法，显著提升了黑盒对抗迁移性，超越了现有技术。

**AI_Comments:** 这篇论文的创新点在于首次将自监督学习（特别是ViT的CL和MIM双范式）应用于提升生成式对抗攻击的黑盒迁移性。通过利用ViT提取的更丰富、更具鲁棒性的特征，成功克服了传统方法对硬标签或监督特征的依赖，极大地提升了对抗样本的泛化能力。其方法dSVA为未来对抗攻击和防御的研究开辟了新途径，特别是在自监督模型日益普及的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 之前的对抗样本生成方法主要依赖监督学习的特征。受自监督学习和Transformer架构之间协同作用的启发，本文旨在探索利用自监督Vision Transformer (ViT) 表示能否改善对抗迁移性。

**Method:** 本文提出dSVA，一种生成式双自监督ViT特征攻击方法。它利用ViT的对比学习（CL）的全局结构特征和掩蔽图像建模（MIM）的局部纹理特征。设计了一个新的生成式训练框架，包含一个生成器来创建黑盒对抗样本，并通过利用自监督ViT的联合特征和注意力机制来训练生成器。

**Result:** 研究发现，CL和MIM使ViT能够关注不同的特征倾向，当两者结合利用时，能显著提升对抗泛化能力。通过扰动自监督ViT提取的双重深度特征，实现了对各种架构模型的卓越黑盒迁移性，性能优于现有技术。

**Conclusion:** 结合自监督ViT的全局（CL）和局部（MIM）特征能够显著提升对抗样本的黑盒迁移性，证明了自监督学习在对抗攻击领域的潜力。

> **ai_Abstract:** 本文提出dSVA，一种新颖的生成式对抗攻击方法，旨在提升黑盒对抗迁移性。该方法创新性地利用自监督Vision Transformer (ViT) 的双重特征：来自对比学习的全局结构特征和来自掩蔽图像建模的局部纹理特征。通过设计一个生成器训练框架，dSVA能够生成高度泛化的对抗样本。实验证明，结合这两种自监督ViT特征能显著提高对抗攻击的迁移性，超越了现有最佳方法，展示了自监督学习在对抗攻击中的巨大潜力。

> **摘要翻译:** 深度神经网络（DNNs）的能力源于从提供的数据中提取和解释特征。通过利用DNN中的中间特征而非依赖硬标签，我们能够生成更有效泛化的对抗性扰动，从而提升黑盒迁移性。在之前的工作中，这些特征普遍来自于监督学习。受自监督学习和Transformer架构之间卓越协同作用的启发，本文探讨了利用自监督视觉Transformer（ViT）表示是否能改善对抗迁移性。我们提出了dSVA——一种生成式双自监督ViT特征攻击，它利用了来自对比学习（CL）的全局结构特征和来自掩蔽图像建模（MIM）的局部纹理特征，这是ViT的自监督学习范式组合。我们设计了一个新颖的生成式训练框架，该框架包含一个生成器来创建黑盒对抗样本，以及通过利用自监督ViT的联合特征和注意力机制来训练生成器的策略。我们的研究结果表明，CL和MIM使ViT能够关注不同的特征倾向，当两者结合利用时，能够显著提升对抗泛化能力。通过扰动自监督ViT提取的双重深度特征，我们获得了对各种架构模型的卓越黑盒迁移性，其性能优于现有技术。代码可在https://github.com/spencerwooo/dSVA 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [259] [PhysRig: Differentiable Physics-Based Skinning and Rigging Framework for Realistic Articulated Object Modeling](https://arxiv.org/abs/2506.20936)
> *PhysRig：基于可微分物理的蒙皮和绑定框架，用于逼真关节对象建模*

*Hao Zhang, Haolan Xu, Chun Feng, Varun Jampani, Narendra Ahuja* | **Category: cs.CV**

**Keywords:** 蒙皮, 绑定, 可微分物理, 软体模拟, 关节对象建模

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出了PhysRig，一个可微分的基于物理的蒙皮和绑定框架，通过将骨架嵌入到可变形软体结构中，克服了传统线性混合蒙皮（LBS）的局限性，生成更逼真、物理上更合理的结果。

**AI_Comments:** PhysRig的创新之处在于将可微分物理模拟引入蒙皮和绑定过程，克服了传统LBS在处理复杂变形和弹性材料方面的固有局限性。通过嵌入骨架到体积软体中并利用连续介质力学，它能够生成更物理逼真的效果。该方法的可微分性对于优化和学习非常重要。其在多种数据集上的优越表现和在姿态迁移中的应用前景，使其在动画、VR/AR和数字人建模等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有蒙皮和绑定方法（如线性混合蒙皮LBS）存在体积损失、不自然变形等伪影，且无法有效建模软组织、毛发等弹性材料。

**Method:** 提出PhysRig框架，将刚性骨架嵌入体积表示（如四面体网格），并模拟为由动画骨架驱动的可变形软体结构。该方法利用连续介质力学，将对象离散化为嵌入欧拉背景网格中的粒子，以确保对材料属性和骨骼运动都可微分。此外，引入材料原型以减少学习空间。

**Result:** PhysRig在综合合成数据集上持续优于传统的基于LBS的方法，生成更逼真且物理上更合理的结果。该框架在姿态迁移任务中也展现了其适用性。

**Conclusion:** PhysRig提供了一个有效且通用的解决方案，解决了传统蒙皮和绑定方法在处理弹性材料和生成物理逼真变形方面的局限性，尤其适用于关节对象建模。

> **ai_Abstract:** 本文介绍了PhysRig，一个创新的可微分物理蒙皮和绑定框架，旨在克服传统线性混合蒙皮（LBS）在处理弹性材料和生成逼真变形方面的局限性。PhysRig通过将骨架嵌入可变形软体结构并利用连续介质力学进行物理模拟，实现了对材料属性和骨骼运动的可微分性，同时通过引入材料原型优化了学习空间。实验证明，PhysRig在生成更逼真、物理上更合理的结果方面显著优于LBS，并在姿态迁移等任务中展现了广泛的适用性，为关节对象建模提供了新的解决方案。

> **摘要翻译:** 蒙皮和绑定是动画、关节对象重建、运动迁移和4D生成中的基本组成部分。现有方法主要依赖线性混合蒙皮（LBS），因为它简单且可微分。然而，LBS引入了体积损失和不自然变形等伪影，并且无法建模弹性材料，如软组织、毛发和柔性附肢（例如，象鼻、耳朵和脂肪组织）。在这项工作中，我们提出了PhysRig：一个可微分的基于物理的蒙皮和绑定框架，通过将刚性骨架嵌入到体积表示（例如，四面体网格）中来克服这些限制，该体积表示被模拟为由动画骨架驱动的可变形软体结构。我们的方法利用连续介质力学，将对象离散化为嵌入欧拉背景网格中的粒子，以确保对材料属性和骨骼运动都可微分。此外，我们引入了材料原型，显著减少了学习空间，同时保持了高表达性。为了评估我们的框架，我们使用来自Objaverse、The Amazing Animals Zoo和MixaMo的网格构建了一个全面的合成数据集，涵盖了不同的对象类别和运动模式。我们的方法始终优于传统的基于LBS的方法，生成更逼真且物理上更合理的结果。此外，我们展示了我们框架在姿态迁移任务中的适用性，突出了其在关节对象建模方面的多功能性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [266] [AIR-VIEW: The Aviation Image Repository for Visibility Estimation of Weather, A Dataset and Benchmark](https://arxiv.org/abs/2506.20939)
> *AIR-VIEW：用于天气能见度估计的航空图像库，一个数据集和基准*

*Chad Mourning, Zhewei Wang, Justin Murray* | **Category: cs.CV**

**Keywords:** 航空天气, 能见度估计, 数据集, 机器学习, 基准

**Comment:** 5 pages, meant as citation for dataset

> **TL;DR:** 本文介绍了AIR-VIEW，一个用于航空天气能见度估计的新型大型数据集和基准，旨在解决现有公开数据集的不足。

**AI_Comments:** 该论文通过创建并公开一个大规模、高质量的航空图像数据集AIR-VIEW，显著解决了航空天气能见度估计领域长期存在的数据稀缺问题，这是推动该领域机器学习应用的关键一步。同时，提供的基准有助于标准化模型评估，促进后续研究的进展和比较。这项工作对于开发低成本的替代方案，以取代昂贵的传统天气传感器具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为航空天气提供低成本的机器学习替代方案是研究热点，但在大气能见度估计领域，缺乏适用于监督学习的、足够大、多样化且标注了能见度估计的公开数据集。

**Method:** 本文通过为期一年的数据收集活动，从FAA天气摄像头网络中收集图像，构建了AIR-VIEW数据集。同时，在AIR-VIEW和三个公开数据集上，应用了三种常用方法和一个通用基线模型进行训练和测试，并与近期批准的ASTM标准进行了比较，建立了基准。

**Result:** 本文成功引入了一个新的航空图像数据集AIR-VIEW，该数据集是为期一年的数据收集活动的成果，旨在用于天气能见度估计。此外，还提供了一个基准，该基准在AIR-VIEW和三个公开数据集上，应用了三种常用方法和一个通用基线，并与ASTM标准进行了比较。

**Conclusion:** 本文通过引入AIR-VIEW数据集和相关基准，为航空天气能见度估计的机器学习研究提供了急需的公共资源和评估框架，有助于推动该领域低成本解决方案的发展。

> **ai_Abstract:** 本文针对航空大气能见度估计领域缺乏适用于机器学习的公开数据集的问题，引入了AIR-VIEW数据集。该数据集通过一年期的FAA天气摄像头网络图像收集而成，旨在满足监督学习的需求。此外，论文还提出了一个基准，利用AIR-VIEW和三个现有公开数据集，评估了三种常用机器学习方法和一个通用基线，并将结果与近期批准的ASTM标准进行了比较，为该领域提供了重要的资源和评估工具。

> **摘要翻译:** 机器学习在航空天气领域是一个不断发展的研究方向，旨在为传统的昂贵天气传感器提供低成本替代方案；然而，在大气能见度估计领域，缺乏适用于监督学习的、标注了航空相关距离能见度估计的、地点多样化且规模足够的公开数据集。本文介绍了一个新数据集，该数据集代表了为期一年的FAA天气摄像头网络图像数据收集活动的成果，适用于此目的。我们还提出了一个基准，该基准在训练和测试时，除了我们自己的数据集外，还在三个公开数据集上应用了三种常用方法和一个通用基线，并与近期批准的ASTM标准进行了比较。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [Hierarchical Sub-action Tree for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.20947)
> *连续手语识别的分层子动作树*

*Dejie Yang, Zhu Xu, Xinjie Gao, Yang Liu* | **Category: cs.CV, cs.MM**

**Keywords:** 连续手语识别, 分层子动作树, 手语词汇知识, 跨模态对齐, 大语言模型

**Comment:** 

> **TL;DR:** 提出分层子动作树(HST-CSLR)模型，结合大语言模型中的手语词汇知识，通过分层对齐和对比增强，有效提升连续手语识别性能。

**AI_Comments:** 本文的创新点在于提出了分层子动作树(HST)结构，并首次有效地将大型语言模型中的手语词汇知识引入到连续手语识别中，从而克服了传统方法对词汇知识利用不足的缺陷。树结构的应用也有效地降低了计算复杂度，提升了效率。

<details>
  <summary>Details</summary>

**Motivation:** 连续手语识别(CSLR)面临大数据集和精确标注不足的瓶颈，现有跨模态方案未能充分利用手语词汇的知识。

**Method:** 提出分层子动作树(HST)，称为HST-CSLR，旨在有效地将手语词汇知识与视觉表示学习相结合。通过整合来自大型语言模型的手语词汇特有知识，构建HST进行文本信息表示，并逐步对齐视觉和文本模态，同时利用树结构降低计算复杂度。此外，还引入对比对齐增强来弥合两种模态之间的差距。

**Result:** 在PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture四个数据集上的实验证明了HST-CSLR的有效性。

**Conclusion:** 本文提出的HST-CSLR模型，通过有效结合大语言模型中的手语词汇知识和分层对齐策略，显著提升了连续手语识别的性能，并解决了数据不足和知识利用不充分的问题。

> **ai_Abstract:** 本文针对连续手语识别(CSLR)中数据集不足和手语词汇知识利用不充分的问题，提出了一种名为分层子动作树(HST-CSLR)的新方法。该方法通过整合来自大语言模型的手语词汇特有知识，构建HST进行文本表示，并逐步对齐视觉与文本模态，同时利用树结构降低计算复杂度。此外，引入对比对齐增强以弥合模态间隙。实验结果表明，HST-CSLR在多个数据集上表现出有效性。

> **摘要翻译:** 连续手语识别（CSLR）旨在将未剪辑的视频转录为通常是文本词汇的手语词（glosses）。最近的研究表明，由于训练数据不足，大型数据集和精确标注的缺乏已成为CSLR的瓶颈。为了解决这个问题，一些工作开发了跨模态解决方案来对齐视觉和文本模态。然而，它们通常从手语词汇中提取文本特征，但没有充分利用其知识。在本文中，我们提出了分层子动作树（Hierarchical Sub-action Tree，HST），称为HST-CSLR，以有效地将手语词汇知识与视觉表示学习结合起来。通过整合来自大型语言模型的手语词汇特有知识，我们的方法更有效地利用了文本信息。具体来说，我们构建了一个HST用于文本信息表示，逐步对齐视觉和文本模态，并受益于树结构以降低计算复杂度。此外，我们施加了对比对齐增强以弥合两种模态之间的差距。在四个数据集（PHOENIX-2014、PHOENIX-2014T、CSL-Daily和Sign Language Gesture）上的实验证明了我们的HST-CSLR的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [274] [Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval](https://arxiv.org/abs/2506.21538)
> *最大匹配至关重要：防止表示坍塌以实现鲁棒的跨模态检索*

*Hani Alomari, Anushka Sivakumar, Andrew Zhang, Chris Thomas* | **Category: cs.CV, cs.IR, cs.LG**

**Keywords:** 跨模态检索, 表示坍塌, 基于集合的嵌入, 最大匹配, 损失函数

**Comment:** Accepted at the 63rd Annual Meeting of the Association for
  Computational Linguistics (ACL 2025 Main)

> **TL;DR:** 该论文提出了一种新的方法，通过最大对分配相似性和两种损失函数来防止基于集合的跨模态检索中的表示坍塌，并在MS-COCO和Flickr30k数据集上取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于针对基于集合的跨模态表示中特有的稀疏监督和表示坍塌问题，提出了新颖的解决方案。通过引入最大对分配相似性以及专门设计的两种损失函数，它有效地提升了跨模态检索的鲁棒性和精确性，对该领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单向量嵌入难以捕捉跨模态间细致和多样化的关系。尽管基于集合的方法很有前景，但它们面临稀疏监督和集合坍塌等问题，限制了其有效性。

**Method:** 提出了“最大对分配相似性”来优化嵌入集合之间的一对一匹配，以保持集合内的语义多样性。引入了两种损失函数：全局判别损失（Global Discriminative Loss）以增强嵌入之间的区别，以及集合内散度损失（Intra-Set Divergence Loss）以防止集合内部的坍塌。

**Result:** 该方法在MS-COCO和Flickr30k数据集上取得了最先进的性能，且不依赖外部数据。

**Conclusion:** 通过引入最大对分配相似性以及全局判别损失和集合内散度损失，该方法成功解决了基于集合的跨模态检索中表示坍塌的问题，并显著提升了检索性能。

> **ai_Abstract:** 该论文通过引入最大对分配相似性来优化嵌入集合之间的一对一匹配，并提出两种新的损失函数（全局判别损失和集合内散度损失），解决了基于集合的跨模态检索中表示坍塌和稀疏监督的问题。这些创新旨在保持和增强语义多样性，最终在MS-COCO和Flickr30k数据集上实现了最先进的性能。

> **摘要翻译:** 跨模态图像-文本检索具有挑战性，因为不同模态内容之间可能存在多种关联。传统方法学习单一向量嵌入来表示每个样本的语义，但难以捕捉跨模态间细致和多样化的关系。基于集合的方法将每个样本表示为多个嵌入，提供了一种有前景的替代方案，因为它们可以捕捉更丰富、更多样的关系。在本文中，我们表明，尽管基于集合的表示很有前景，但它们仍然面临稀疏监督和集合坍塌等问题，这限制了它们的有效性。为了解决这些挑战，我们提出了最大对分配相似性（Maximal Pair Assignment Similarity）来优化嵌入集合之间的一对一匹配，从而保持集合内的语义多样性。我们还引入了两种损失函数来进一步增强表示：全局判别损失（Global Discriminative Loss）以增强嵌入之间的区别，以及集合内散度损失（Intra-Set Divergence Loss）以防止每个集合内部的坍塌。我们的方法在MS-COCO和Flickr30k数据集上取得了最先进的性能，且不依赖外部数据。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [278] [OmniEval: A Benchmark for Evaluating Omni-modal Models with Visual, Auditory, and Textual Inputs](https://arxiv.org/abs/2506.20960)
> *OmniEval：一个用于评估视觉、听觉和文本输入的全模态模型的基准*

*Yiman Zhang, Ziheng Luo, Qiangyu Yan, Wei He, Borui Jiang, Xinghao Chen, Kai Han* | **Category: cs.CV, cs.AI**

**Keywords:** 全模态模型, 评估基准, 视觉, 听觉, 文本

**Comment:** 

> **TL;DR:** OmniEval是一个新的基准，用于评估处理视觉、听觉和文本输入的全模态模型，具有全模态协作、视频多样性和任务多样性等特点。

**AI_Comments:** 该论文的创新点在于提出了一个更全面的全模态评估基准OmniEval，特别强调了音频与视频之间的强耦合，并引入了更细粒度的任务类型，弥补了现有基准在评估全模态模型协同感知能力方面的不足。其包含中英文视频和多样化任务的设计，使其具有较高的实用性和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准可能无法有效评估需要视觉、听觉和文本输入协同的全模态模型，因此需要一个能突出模态间强耦合的评估平台。

**Method:** 本文介绍了OmniEval基准，其特点包括：(i) 全模态协作：设计强调音视频强耦合的任务，要求模型有效利用所有模态的协作感知；(ii) 视频多样性：包含810个音视频同步视频（285个中文，525个英文）；(iii) 任务多样性和粒度：包含2617个问答对（1412个开放式问题，1205个多项选择问题），分为3大类12子类任务，并引入了更细粒度的视频定位任务Grounding。

**Result:** 在OmniEval上对几种全模态模型进行了实验。具体实验结果细节未在摘要中提及。

**Conclusion:** 作者希望OmniEval能为评估模型构建和理解所有模态上下文连贯性的能力提供一个平台。

> **ai_Abstract:** 本文提出了OmniEval，一个专为评估全模态模型（涵盖视觉、听觉、文本输入）设计的基准。它通过强调全模态协作、提供多样化的音视频数据（包括中英文）以及细致多样的任务类型（如视频定位Grounding），旨在全面评估模型在多模态上下文理解和连贯性构建方面的能力。作者在OmniEval上对多种全模态模型进行了实验。

> **摘要翻译:** 在本文中，我们介绍了 OmniEval，这是一个用于评估 MiniCPM-O 2.6 等全模态模型的基准，该基准包含视觉、听觉和文本输入。与现有基准相比，我们的 OmniEval 具有几个显著特点：(i) 全模态协作：我们设计的评估任务突出了音频和视频之间的强耦合，要求模型有效利用所有模态的协作感知；(ii) 视频多样性：OmniEval 包含 810 个音视频同步视频，其中 285 个中文视频和 525 个英文视频；(iii) 任务多样性和粒度：OmniEval 包含 2617 个问答对，其中包括 1412 个开放式问题和 1205 个多项选择问题。这些问题分为 3 种主要任务类型和 12 种子任务类型，以实现全面评估。其中，我们引入了一个更细粒度的视频定位任务，名为 Grounding。然后，我们使用几种全模态模型在 OmniEval 上进行了实验。我们希望我们的 OmniEval 能够为评估从所有模态上下文中构建和理解连贯性的能力提供一个平台。代码和数据可在 https://omnieval.github.io/ 找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [281] [Evidence-based diagnostic reasoning with multi-agent copilot for human pathology](https://arxiv.org/abs/2506.20964)
> *基于证据的病理诊断推理与多智能体副驾驶*

*Chengkuan Chen, Luca L. Weishaupt, Drew F. K. Williamson, Richard J. Chen, Tong Ding, Bowen Chen, Anurag Vaidya, Long Phi Le, Guillaume Jaume, Ming Y. Lu, Faisal Mahmood* | **Category: cs.CV, cs.AI**

**Keywords:** 病理学, 人工智能, 多模态大语言模型, 诊断推理, 全玻片图像

**Comment:** 

> **TL;DR:** 本文介绍了PathChat+，一种新型多模态大语言模型（MLLM），专为人类病理学设计，解决了现有模型在整合语言指令、处理多图像理解和自主诊断推理方面的局限性。在此基础上，提出了SlideSeek，一个多智能体AI系统，能够通过迭代、分层的诊断推理自主评估全玻片图像（WSIs），并在具有挑战性的诊断基准测试中表现出色。

**AI_Comments:** 该论文在计算病理学领域取得了重要进展，通过引入PathChat+解决了当前MLLMs在病理学数据和多模态理解方面的核心痛点。更具创新性的是，SlideSeek多智能体系统的提出，使其能够进行迭代、分层的诊断推理，这模仿了人类病理学家的思考过程，是AI从图像识别走向复杂诊断推理的关键一步。生成可解释报告的能力也极大地增强了AI在临床应用中的可信度和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的计算病理学模型主要侧重于图像分析，但缺乏整合自然语言指令或丰富的文本上下文的能力。当前多模态大语言模型（MLLMs）在计算病理学领域面临训练数据不足、对多图像理解支持和评估不足以及缺乏自主诊断推理能力的限制。为了解决这些问题，本研究旨在开发一种能够进行基于证据的诊断推理并具备自主诊断能力的AI系统。

**Method:** 本研究引入了PathChat+，一种新型多模态大语言模型（MLLM），专为人类病理学设计，通过超过100万个多样化的病理学特定指令样本和近550万个问答回合进行训练。此外，还提出了SlideSeek，一个推理驱动的多智能体AI系统，它利用PathChat+通过迭代、分层的诊断推理自主评估千兆像素的全玻片图像（WSIs）。

**Result:** PathChat+在多项病理学基准测试中显著优于先前的PathChat副驾驶以及最先进的通用模型和其他病理学专用模型。SlideSeek在具有挑战性的开放式鉴别诊断基准DDxBench上达到了高准确率，并且能够生成视觉化、人类可解释的摘要报告。

**Conclusion:** PathChat+和SlideSeek的开发和成功验证表明，结合大规模病理学特定数据训练的多模态大语言模型和多智能体推理系统，能够显著提升计算病理学在诊断推理方面的能力，并为病理学家提供有效的辅助诊断工具。

> **ai_Abstract:** 本研究针对计算病理学中传统模型缺乏语言整合和现有多模态大语言模型（MLLMs）在数据、多图像理解及自主推理方面的不足，提出了两项创新。首先，开发了PathChat+，一个在海量病理学专用数据上训练的新型MLLM，其在多项基准测试中表现优异。其次，构建了SlideSeek，一个基于PathChat+的多智能体AI系统，能够自主进行迭代、分层的全玻片图像诊断推理，并在鉴别诊断任务中取得高准确率，同时生成可解释的报告，显著提升了病理学诊断的AI辅助能力。

> **摘要翻译:** 病理学正在经历由全玻片成像和人工智能（AI）驱动的快速数字化转型。尽管基于深度学习的计算病理学取得了显著成功，但传统模型主要专注于图像分析，而没有整合自然语言指令或丰富的文本上下文。当前计算病理学中的多模态大语言模型（MLLMs）面临局限性，包括训练数据不足、对多图像理解的支持和评估不足，以及缺乏自主诊断推理能力。为了解决这些局限性，我们引入了PathChat+，一种专为人类病理学设计的新型MLLM，它在超过100万个多样化的病理学特定指令样本和近550万个问答回合上进行训练。在各种病理学基准测试中的广泛评估表明，PathChat+显著优于先前的PathChat副驾驶以及最先进的通用模型和其他病理学专用模型。此外，我们提出了SlideSeek，一个推理驱动的多智能体AI系统，它利用PathChat+通过迭代、分层的诊断推理自主评估千兆像素的全玻片图像（WSIs），在具有挑战性的开放式鉴别诊断基准DDxBench上达到了高准确率，同时还能生成视觉化、人类可解释的摘要报告。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [283] [DFVEdit: Conditional Delta Flow Vector for Zero-shot Video Editing](https://arxiv.org/abs/2506.20967)
> *DFVEdit：零样本视频编辑的条件增量流向量*

*Lingling Cai, Kang Zhao, Hangjie Yuan, Xiang Wang, Yingya Zhang, Kejie Huang* | **Category: cs.CV, cs.AI**

**Keywords:** 视频编辑, 零样本, 视频扩散Transformer, 流向量, 计算效率

**Comment:** Zero-shot video editing

> **TL;DR:** DFVEdit是一种高效的零样本视频编辑方法，专为Video DiTs设计，通过流变换直接操作潜在空间，无需注意力修改或微调，显著提升了编辑速度和内存效率。

**AI_Comments:** 这篇论文通过提出DFVEdit，为Video DiTs的视频编辑提供了一种创新且高效的解决方案。其核心创新在于将编辑和采样统一在连续流视角下，并引入条件增量流向量，从而避免了传统方法中计算量大的注意力修改和微调。这极大地提升了推理速度和内存效率，解决了Video DiTs在实际应用中的主要瓶颈。该方法的零样本特性和对现有Video DiTs的无缝兼容性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频编辑方法直接应用于Video Diffusion Transformers (Video DiTs) 会产生巨大的计算开销，因为它们需要资源密集型的注意力修改或微调。

**Method:** 提出了DFVEdit，一种高效的零样本视频编辑方法。它通过流变换直接操作干净的潜在空间，无需注意力修改和微调。该方法基于编辑和采样可以统一在连续流的视角下，并提出了条件增量流向量 (CDFV) 作为DFV的理论无偏估计。此外，还集成了隐式交叉注意力 (ICA) 指导和嵌入强化 (ER) 以提高编辑质量。

**Result:** DFVEdit在实用效率方面表现出色，与基于注意力工程的编辑方法相比，在Video DiTs上实现了至少20倍的推理加速和85%的内存减少。在结构保真度、时空一致性和编辑质量方面达到了最先进的性能，并可无缝应用于流行的Video DiTs (如CogVideoX和Wan2.1)。

**Conclusion:** DFVEdit是一种高效、高性能的零样本视频编辑方法，通过创新的流变换方法解决了Video DiTs的计算开销问题，并在多个方面实现了最先进的性能。

> **ai_Abstract:** DFVEdit是一种专为Video Diffusion Transformers (Video DiTs) 设计的高效零样本视频编辑方法。它通过引入条件增量流向量 (CDFV) 和直接在潜在空间进行流变换，避免了传统方法所需的注意力修改和微调，显著降低了计算开销。该方法集成了隐式交叉注意力指导和嵌入强化以提升编辑质量，并在推理速度和内存效率上取得了显著提升，实现了20倍加速和85%内存减少，同时在多个Video DiTs上达到了最先进的编辑性能。

> **摘要翻译:** 视频扩散Transformer (Video DiTs) 的出现标志着视频生成领域的一个里程碑。然而，将现有视频编辑方法直接应用于Video DiTs通常会产生巨大的计算开销，因为它们需要资源密集型的注意力修改或微调。为了缓解这个问题，我们提出了DFVEdit，一种专为Video DiTs量身定制的高效零样本视频编辑方法。DFVEdit通过流变换直接操作干净的潜在空间，从而无需注意力修改和微调。更具体地说，我们观察到编辑和采样可以在连续流的视角下统一。在此基础上，我们提出了条件增量流向量 (CDFV)——DFV的理论无偏估计——并集成了隐式交叉注意力 (ICA) 指导以及嵌入强化 (ER) 以进一步提高编辑质量。DFVEdit在实用效率方面表现出色，与基于注意力工程的编辑方法相比，在Video DiTs上实现了至少20倍的推理加速和85%的内存减少。广泛的定量和定性实验表明，DFVEdit可以无缝应用于流行的Video DiTs（例如CogVideoX和Wan2.1），在结构保真度、时空一致性和编辑质量方面达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [284] [MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification](https://arxiv.org/abs/2506.21199)
> *MedPrompt：用于医学图像分割和分类的LLM-CNN融合与权重路由*

*Shadman Sobhan, Kazi Abrar Mahmud, Abduz Zami* | **Category: cs.CV, eess.SP**

**Keywords:** 医学图像分析, LLM, CNN, 图像分割, 图像分类

**Comment:** 40 pages, 8 Tables, 9 Figures

> **TL;DR:** MedPrompt是一个统一的框架，结合LLM进行高级任务规划和CNN进行低级图像处理，通过权重路由实现可扩展的医学图像分割和分类，避免了为新任务重新训练整个框架，并在19个数据集上表现出色。

**AI_Comments:** MedPrompt的创新点在于其LLM-CNN融合架构和权重路由机制，这显著提高了医学图像分析系统的灵活性和可扩展性，解决了传统方法需要为每个任务单独训练模型的痛点。其支持用户定义工作流的能力也为实际应用带来了便利。该方法有望推动医学影像诊断的自动化和个性化发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的医学图像分析系统通常是任务特定的，需要独立的模型进行分类和分割，并且缺乏支持用户定义工作流的灵活性。

**Method:** MedPrompt是一个统一的框架，它将一个少样本提示的大型语言模型（Llama-4-17B）用于高级任务规划，并与一个模块化卷积神经网络（DeepFusionLab）用于低级图像处理相结合。LLM解释用户指令并生成结构化输出以动态路由任务特定的预训练权重，这种权重路由方法避免了在添加新任务时重新训练整个框架，只需任务特定权重。

**Result:** MedPrompt在19个公共数据集上进行了评估，涵盖5种成像模式的12项任务。系统在解释和执行提示驱动指令方面达到了97%的端到端正确性，平均推理延迟为2.5秒。DeepFusionLab在肺部分割方面达到了0.9856的Dice系数，在结核病分类方面达到了0.9744的F1分数。

**Conclusion:** MedPrompt通过结合LLM的可解释性和模块化CNN的效率，实现了可扩展的、提示驱动的医学成像。

> **ai_Abstract:** MedPrompt是一个创新的统一框架，旨在解决现有医学图像分析系统任务特定和缺乏灵活性的问题。它通过融合大型语言模型（LLM）进行高级任务规划和卷积神经网络（CNN）DeepFusionLab进行低级图像处理，并引入了权重路由机制，实现了动态任务适应而无需整体重新训练。该系统在多达19个数据集、12项任务和5种成像模式上进行了广泛评估，展示了97%的指令执行正确率和2.5秒的低延迟，同时在分割和分类任务上取得了有竞争力的性能，为可扩展、提示驱动的医学图像分析提供了有效方案。

> **摘要翻译:** 当前的医学图像分析系统通常是任务特定的，需要独立的模型进行分类和分割，并且缺乏支持用户定义工作流的灵活性。为了解决这些挑战，我们引入了MedPrompt，一个统一的框架，它结合了一个少样本提示的大型语言模型（Llama-4-17B）用于高级任务规划，并与一个模块化卷积神经网络（DeepFusionLab）用于低级图像处理。LLM解释用户指令并生成结构化输出以动态路由任务特定的预训练权重。这种权重路由方法避免了在添加新任务时重新训练整个框架——只需要任务特定的权重，从而增强了可扩展性和部署便利性。我们在19个公共数据集上评估了MedPrompt，涵盖了5种成像模式的12项任务。该系统在解释和执行提示驱动指令方面达到了97%的端到端正确性，平均推理延迟为2.5秒，使其适用于近实时应用。DeepFusionLab实现了具有竞争力的分割精度（例如，肺部Dice系数0.9856）和强大的分类性能（结核病F1分数0.9744）。总的来说，MedPrompt通过结合LLM的可解释性与模块化CNN的效率，实现了可扩展的、提示驱动的医学成像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [287] [From Cradle to Cane: A Two-Pass Framework for High-Fidelity Lifespan Face Aging](https://arxiv.org/abs/2506.20977)
> *从摇篮到拐杖：一种用于高保真度全生命周期人脸老化的两阶段框架*

*Tao Liu, Dafeng Zhang, Gengchen Li, Shizhuo Liu, Yongqi Song, Senmao Li, Shiqi Yang, Boqian Li, Kai Wang, Yaxing Wang* | **Category: cs.CV, cs.AI**

**Keywords:** 人脸老化, 扩散模型, 身份保留, 年龄准确性, 两阶段框架

**Comment:** 30 pages, 12 figures

> **TL;DR:** 现有的人脸老化方法难以实现逼真和身份保留，尤其是在大年龄差距下。本文提出了Cradle2Cane，一个基于两阶段扩散模型的框架，通过自适应噪声注入和身份感知嵌入来平衡年龄准确性和身份保留，并优于现有方法。

**AI_Comments:** 这项工作通过引入一个创新的两阶段框架来解决人脸老化中的核心挑战——年龄准确性与身份保留之间的权衡。其亮点在于结合了T2I扩散模型，并设计了独特的AdaNI机制和身份感知嵌入，有效地实现了平衡。这种分阶段处理复杂任务的方法值得借鉴，并且其在处理大年龄差距和极端姿势方面的潜力是重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 人脸老化是计算机视觉中的一项关键任务，但现有方法在整个生命周期内实现逼真和无缝转换时面临挑战，尤其是在处理大年龄差距或极端头部姿势时。核心挑战在于平衡年龄准确性和身份保留（即“年龄-身份权衡”），大多数现有方法在此方面存在偏颇。

**Method:** 本文提出了一个名为Cradle2Cane的两阶段人脸老化框架，基于少步文本到图像（T2I）扩散模型。第一阶段通过引入自适应噪声注入（AdaNI）机制解决年龄准确性问题，该机制由年龄和性别提示作为文本条件引导，并允许通过调整噪声水平控制老化强度。此阶段弱化身份保留以促进更强的年龄转换。第二阶段通过将模型条件化于SVR-ArcFace和Rotate-CLIP两种身份感知嵌入（IDEmb），增强身份保留并保持年龄特定特征，同时对第一阶段的图像进行去噪。两个阶段以端到端方式联合训练。

**Result:** 在CelebA-HQ测试数据集上进行的广泛实验，通过Face++和Qwen-VL协议评估，表明Cradle2Cane在年龄准确性和身份一致性方面均优于现有的人脸老化方法。

**Conclusion:** Cradle2Cane框架成功地解决了人脸老化中的年龄-身份权衡问题，通过两阶段方法实现了卓越的年龄准确性和身份一致性。

> **ai_Abstract:** 本研究提出了一种名为Cradle2Cane的两阶段人脸老化框架，旨在解决现有方法在全生命周期人脸老化中面临的“年龄-身份权衡”挑战。该框架基于文本到图像扩散模型，并通过两个阶段实现平衡。第一阶段利用自适应噪声注入（AdaNI）机制，结合年龄和性别提示，优先实现年龄准确性。第二阶段则通过引入SVR-ArcFace和Rotate-CLIP两种身份感知嵌入，增强图像的身份保留，同时维持年龄特征。两个阶段联合训练，实验结果表明Cradle2Cane在年龄准确性和身份一致性方面均优于现有方法，为高保真度人脸老化提供了有效解决方案。

> **摘要翻译:** 人脸老化已成为计算机视觉中的一项关键任务，其应用范围从娱乐到医疗保健。然而，现有方法难以在整个生命周期内实现逼真和无缝的转换，尤其是在处理大年龄差距或极端头部姿势时。核心挑战在于平衡年龄准确性和身份保留——我们称之为年龄-身份权衡。大多数现有方法要么以牺牲身份一致性为代价优先进行年龄转换，要么反之。在这项工作中，我们通过提出一个名为Cradle2Cane的两阶段人脸老化框架来解决这个问题，该框架基于少步文本到图像（T2I）扩散模型。第一阶段通过引入自适应噪声注入（AdaNI）机制来解决年龄准确性问题。该机制通过包含给定人物的年龄和性别提示描述作为文本条件进行引导。此外，通过调整噪声水平，我们可以控制老化强度，同时在人脸转换中提供更大的灵活性。然而，在此阶段身份保留被弱化，以促进更强的年龄转换。在第二阶段，我们通过将模型条件化于两个身份感知嵌入（IDEmb）：SVR-ArcFace和Rotate-CLIP，来增强身份保留，同时保持年龄特定特征。此阶段允许对第一阶段转换后的图像进行去噪，确保更强的身份保留而不损害老化准确性。两个阶段都以端到端方式联合训练。在CelebA-HQ测试数据集上进行的广泛实验，通过Face++和Qwen-VL协议进行评估，表明我们的Cradle2Cane在年龄准确性和身份一致性方面优于现有的人脸老化方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [291] [3D Scene-Camera Representation with Joint Camera Photometric Optimization](https://arxiv.org/abs/2506.20979)
> *具有联合相机光度优化的三维场景-相机表示*

*Weichen Dai, Kangcheng Ma, Jiaxin Wang, Kecen Pan, Yuhang Ming, Hua Zhang, Wanzeng Kong* | **Category: cs.CV**

**Keywords:** 三维场景表示, 相机光度优化, 图像畸变, 深度正则化, 多视图图像

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的三维场景-相机表示方法，通过联合优化相机光度模型来有效去除图像畸变带来的场景无关信息，从而在存在图像退化的情况下也能获得高质量的三维场景表示。

**AI_Comments:** 该论文创新性地将相机光度模型纳入三维场景表示的映射过程中，并通过联合优化和深度正则化有效解决了图像畸变对场景重建质量的影响。这对于实际应用中，尤其是在复杂或受损成像条件下获取高质量三维数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从多视图图像表示场景是计算机视觉中的关键任务，但相机成像固有的光度畸变会显著降低图像质量，导致三维场景表示包含错误信息，从而降低表示质量。

**Method:** 提出了一种新颖的三维场景-相机表示，通过联合相机光度优化。引入内部和外部光度模型，构建了一个完整的光度模型和相应的相机表示。通过同时优化相机表示参数，有效分离了场景无关信息。此外，在光度参数优化过程中引入深度正则化，以防止三维场景表示拟合场景无关信息。该方法将相机模型作为映射过程的一部分，构建了一个包含场景辐射场和相机光度模型的完整映射。

**Result:** 实验结果表明，即使在渐晕和污垢等成像退化条件下，所提出的方法也能实现高质量的三维场景表示。

**Conclusion:** 通过联合相机光度优化和深度正则化，该方法能够有效处理相机光度畸变，从而在存在图像退化的情况下也能获得高质量的三维场景表示。

> **ai_Abstract:** 本文提出了一种新颖的三维场景-相机表示方法，旨在解决相机光度畸变对三维场景表示质量的影响。该方法通过引入内部和外部光度模型，并进行联合相机光度优化，能够有效分离图像中的场景无关信息。此外，通过引入深度正则化，进一步防止三维场景表示拟合错误信息。实验证明，该方法即使在成像退化条件下也能获得高质量的三维场景表示。

> **摘要翻译:** 从多视图图像表示场景是计算机视觉中的一项关键任务，具有广泛的应用。然而，相机成像中固有的光度畸变会显著降低图像质量。如果不考虑这些畸变，三维场景表示可能会无意中包含与场景无关的错误信息，从而降低表示质量。在本文中，我们提出了一种具有联合相机光度优化的新型三维场景-相机表示方法。通过引入内部和外部光度模型，我们提出了一个完整的光度模型和相应的相机表示。通过同时优化相机表示的参数，所提出的方法有效地将与场景无关的信息从三维场景表示中分离出来。此外，在光度参数优化过程中，我们引入了深度正则化，以防止三维场景表示拟合与场景无关的信息。通过将相机模型作为映射过程的一部分，所提出的方法构建了一个包含场景辐射场和相机光度模型的完整映射。实验结果表明，即使在渐晕和污垢等成像退化条件下，所提出的方法也能实现高质量的三维场景表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [293] [GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction](https://arxiv.org/abs/2506.21121)
> *GoIRL：面向图的逆强化学习用于多模态轨迹预测*

*Muleilan Pei, Shaoshuai Shi, Lu Zhang, Peiliang Li, Shaojie Shen* | **Category: cs.CV, cs.RO**

**Keywords:** 轨迹预测, 逆强化学习, 图神经网络, 自动驾驶, 多模态

**Comment:** Accepted by ICML 2025

> **TL;DR:** 本文提出了一种名为GoIRL的图导向逆强化学习框架，用于自动驾驶中的多模态轨迹预测，并在大型基准测试中取得了最先进的性能和更好的泛化能力。

**AI_Comments:** 本文的创新之处在于将逆强化学习（IRL）与图神经网络相结合，用于解决自动驾驶中的多模态轨迹预测问题。与传统的监督学习方法不同，GoIRL通过IRL推断奖励函数，从而更好地捕捉潜在的驾驶意图和多样的行为模式。其分层轨迹生成器和概率融合策略也有效提升了预测的准确性和置信度，展现了IRL在复杂动态环境预测中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中周围代理的轨迹预测由于其固有的不确定性和潜在的多模态性而具有挑战性。

**Method:** 本文提出了一种新颖的GoIRL（Graph-oriented Inverse Reinforcement Learning）框架，这是一种基于IRL的预测器，配备矢量化上下文表示。开发了一个特征适配器，将车道图特征有效地聚合到网格空间中，并与最大熵IRL范式集成，以推断奖励分布并获得可以采样以诱导多个合理计划的策略。此外，以采样的计划为条件，实现了一个分层参数化轨迹生成器，带有细化模块以提高预测精度，并采用概率融合策略以提高预测置信度。

**Result:** 该方法在大型Argoverse和nuScenes运动预测基准测试中不仅取得了最先进的性能，而且与现有监督模型相比，展现出卓越的泛化能力。

**Conclusion:** GoIRL框架通过结合逆强化学习和图导向特征表示，有效解决了自动驾驶中的多模态轨迹预测难题，并在性能和泛化能力上超越了现有方法。

> **ai_Abstract:** 本文提出GoIRL，一个面向图的逆强化学习框架，用于自动驾驶中的多模态轨迹预测。该框架利用特征适配器将车道图特征整合到网格空间，并通过最大熵IRL推断奖励分布以生成多模态计划。在此基础上，通过分层轨迹生成器和概率融合策略提升预测精度和置信度。实验证明，GoIRL在Argoverse和nuScenes基准测试中表现出最先进的性能和优越的泛化能力。

> **摘要翻译:** 周围代理的轨迹预测由于其固有的不确定性和潜在的多模态性，在自动驾驶中是一项具有挑战性的任务。与主要依赖监督学习的现有数据驱动方法不同，在本文中，我们引入了一种新颖的图导向逆强化学习（GoIRL）框架，这是一种基于IRL的预测器，配备了矢量化上下文表示。我们开发了一个特征适配器，以有效地将车道图特征聚合到网格空间中，从而实现与最大熵IRL范式的无缝集成，以推断奖励分布并获得可以采样以诱导多个合理计划的策略。此外，以采样的计划为条件，我们实现了一个分层参数化轨迹生成器，带有细化模块以提高预测精度，并采用概率融合策略以提高预测置信度。广泛的实验结果表明，我们的方法不仅在大型Argoverse和nuScenes运动预测基准测试中取得了最先进的性能，而且与现有监督模型相比，展现出卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [294] [Rethink Sparse Signals for Pose-guided Text-to-image Generation](https://arxiv.org/abs/2506.20983)
> *重新思考用于姿态引导文本到图像生成的稀疏信号*

*Wenjie Xuan, Jing Zhang, Juhua Liu, Bo Du, Dacheng Tao* | **Category: cs.CV**

**Keywords:** 稀疏信号, 姿态引导生成, 文本到图像, ControlNet, 关键点学习

**Comment:** accepted by ICCV 2025

> **TL;DR:** 本文提出SP-Ctrl，一个基于稀疏信号（如OpenPose）的ControlNet，解决了密集信号在姿态引导文本到图像生成中的问题，实现了与密集信号相当甚至超越现有稀疏信号方法的性能，并支持多样化和跨物种生成。

**AI_Comments:** 这篇论文通过重新思考并有效利用稀疏信号，为姿态引导的文本到图像生成领域提供了一个创新且实用的解决方案。其创新点在于克服了传统密集信号的缺点，并证明了稀疏信号在特定场景下可以达到甚至超越密集信号的性能。SP-Ctrl的设计，特别是可学习的OpenPose扩展和关键点概念学习，是提升稀疏信号表达力和控制力的关键。这项工作对于推动T2I生成在更广泛应用场景中的发展具有重要意义，尤其是在需要灵活编辑和多样化生成的场景。

<details>
  <summary>Details</summary>

**Motivation:** 现有姿态引导文本到图像生成方法多采用密集信号（如深度、DensePose），但存在编辑困难和与文本提示不一致的问题。稀疏信号（如OpenPose）因其简单性和形状无关性而未被充分探索，这促使作者重新审视并利用稀疏信号。

**Method:** 本文提出了一种新颖的空间姿态控制网络（Spatial-Pose ControlNet, SP-Ctrl）。具体而言，SP-Ctrl将OpenPose扩展为可学习的空间表示，使关键点嵌入更具判别性和表达性。此外，SP-Ctrl引入了关键点概念学习，鼓励关键点令牌关注每个关键点的空间位置，从而改善姿态对齐。

**Result:** 在以动物和人类为中心的图像生成任务上的实验表明，所提出的方法在稀疏姿态引导下优于近期空间可控的T2I生成方法，甚至能与基于密集信号的方法性能相匹配。此外，SP-Ctrl通过稀疏信号在多样化和跨物种生成方面显示出前景广阔的能力。

**Conclusion:** 本文成功地重新利用了稀疏信号进行姿态引导的文本到图像生成，通过提出的SP-Ctrl，不仅解决了密集信号的挑战，还在性能上达到了甚至超越了现有方法，并在多样性和跨物种生成方面展现了巨大潜力。

> **ai_Abstract:** 本文针对姿态引导文本到图像生成中密集信号存在的编辑困难和文本不一致问题，提出重新审视并利用稀疏信号。为此，作者开发了Spatial-Pose ControlNet (SP-Ctrl)，它通过将OpenPose扩展为可学习的空间表示并引入关键点概念学习，显著提升了稀疏信号的可控性和姿态对齐能力。实验证明，SP-Ctrl在稀疏姿态引导下表现优异，甚至能与密集信号方法媲美，并展现了在多样化和跨物种生成方面的强大潜力。

> **摘要翻译:** 最近的工作倾向于使用密集信号（例如，深度、DensePose）作为稀疏信号（例如，OpenPose）的替代品，为姿态引导的文本到图像生成提供详细的空间指导。然而，密集表示带来了新的挑战，包括编辑困难和与文本提示潜在的不一致性。这一事实促使我们重新审视用于姿态引导的稀疏信号，因为它们具有简单性和形状无关的特性，而这仍然未被充分探索。本文提出了一种新颖的空间姿态控制网络（Spatial-Pose ControlNet, SP-Ctrl），为稀疏信号赋予了强大的可控性，用于姿态引导的图像生成。具体而言，我们将OpenPose扩展为可学习的空间表示，使关键点嵌入具有判别性和表达性。此外，我们引入了关键点概念学习，这鼓励关键点令牌关注每个关键点的空间位置，从而改善姿态对齐。在以动物和人类为中心的图像生成任务上的实验表明，我们的方法在稀疏姿态引导下优于近期空间可控的T2I生成方法，甚至能与基于密集信号的方法性能相匹配。此外，SP-Ctrl通过稀疏信号在多样化和跨物种生成方面显示出前景广阔的能力。代码将在https://github.com/DREAMXFAR/SP-Ctrl 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [297] [EVA: Mixture-of-Experts Semantic Variant Alignment for Compositional Zero-Shot Learning](https://arxiv.org/abs/2506.20986)
> *EVA：用于组合零样本学习的专家混合语义变体对齐*

*Xiao Zhang, Yongqiang Ma, Haodong Jing, Nanning Zheng* | **Category: cs.CV**

**Keywords:** 组合零样本学习, 专家混合, 语义变体对齐, 域专家适应, 零样本学习

**Comment:** 

> **TL;DR:** EVA提出了一种专家混合语义变体对齐框架，通过域专家适应和语义变体对齐，显著提高了组合零样本学习的性能。

**AI_Comments:** 该论文通过引入“专家混合”和“语义变体对齐”的概念，为组合零样本学习提供了创新的解决方案。特别是，域专家适应能够更好地处理不同语义子集，而语义变体对齐则解决了细粒度图像-组合对齐的问题，这些都是现有方法面临的关键挑战。其在多个基准测试上的显著性能提升，凸显了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的组合零样本学习方法通常通过简单的组合原型映射来获取原始特征，这对于可分为不同语义子集的个体来说是次优的。此外，一对多的跨模态原始匹配忽略了相同状态或对象内的组合差异，限制了细粒度的图像-组合对齐。

**Method:** 本文提出EVA，一个用于组合零样本学习的专家混合语义变体对齐框架。具体而言，引入了域专家适应，利用多个专家实现令牌感知学习和建模高质量的原始表示。为了实现准确的组合泛化，进一步提出了语义变体对齐，以选择语义相关的表示进行图像-原始匹配。

**Result:** EVA在三种流行的基准测试中，在封闭世界和开放世界设置下，均显著优于其他最先进的组合零样本学习方法。

**Conclusion:** 所提出的EVA框架通过其域专家适应和语义变体对齐机制，有效解决了现有组合零样本学习方法的局限性，并显著提高了性能。

> **ai_Abstract:** 本文针对组合零样本学习（CZSL）中现有方法在处理语义子集和组合差异方面的不足，提出了一种名为EVA的专家混合语义变体对齐框架。EVA通过引入域专家适应来实现令牌感知学习和高质量的原始表示，并利用语义变体对齐来选择语义相关的表示进行图像-原始匹配，从而实现准确的组合泛化。实验结果表明，EVA在多个基准测试中显著优于现有最先进的CZSL方法。

> **摘要翻译:** 组合零样本学习（CZSL）研究了基于学习到的原始概念识别未知状态-对象对的组合泛化能力。现有CZSL方法通常通过简单的组合原型映射来获取原始特征，这对于可分为不同语义子集的个体来说是次优的。此外，一对多的跨模态原始匹配忽略了相同状态或对象内的组合差异，限制了细粒度的图像-组合对齐。在本研究中，我们提出了EVA，一个用于CZSL的专家混合语义变体对齐框架。具体而言，我们引入了域专家适应，利用多个专家实现令牌感知学习和建模高质量的原始表示。为了实现准确的组合泛化，我们进一步提出了语义变体对齐，以选择语义相关的表示进行图像-原始匹配。我们的方法在三种流行的基准测试中，在封闭世界和开放世界设置下，均显著优于其他最先进的CZSL方法，证明了所提出见解的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [299] [Segment Anything in Pathology Images with Natural Language](https://arxiv.org/abs/2506.20988)
> *使用自然语言在病理图像中分割一切*

*Zhixuan Chen, Junlin Hou, Liqi Lin, Yihui Wang, Yequan Bie, Xi Wang, Yanning Zhou, Ronald Cheong Kin Chan, Hao Chen* | **Category: cs.CV, cs.AI**

**Keywords:** 病理图像分割, 自然语言处理, 基础模型, PathSegmentor, 可解释AI

**Comment:** 

> **TL;DR:** PathSegmentor是一个基于自然语言提示的病理图像分割基础模型，解决了数据标注和类别定义限制，并在PathSeg数据集上表现优异，提升了诊断可解释性。

**AI_Comments:** 这项工作通过引入首个文本提示的病理图像分割基础模型PathSegmentor和迄今最大的病理分割数据集PathSeg，显著推动了计算病理学领域的发展。其创新之处在于利用自然语言提示进行分割，极大地降低了对繁琐空间输入的依赖，解决了标注数据稀缺和类别定义受限的痛点。此外，该模型在提升诊断模型可解释性方面的潜力，对于临床决策支持和精准肿瘤学具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前病理图像分割方法在临床应用中面临标注数据有限和类别定义受限的挑战。

**Method:** 提出了PathSegmentor，首个针对病理图像的文本提示分割基础模型。同时构建了PathSeg数据集，包含17个公共来源的27.5万个图像-掩膜-标签三元组，涵盖160个类别。PathSegmentor允许用户使用自然语言提示进行语义分割，无需繁琐的空间输入，例如点或框。

**Result:** PathSegmentor在准确性和适用性方面优于专用模型，并保持紧凑架构。在整体Dice分数上，它分别比现有空间提示模型和文本提示模型高出0.145和0.429。在分割复杂结构和泛化到外部数据集方面表现出强大的鲁棒性。其输出通过特征重要性估计和成像生物标志物发现，增强了诊断模型的可解释性。

**Conclusion:** 这项工作推动了精准肿瘤学中可解释AI的发展，为病理学家提供了循证支持。

> **ai_Abstract:** PathSegmentor是一个开创性的文本提示分割基础模型，专为病理图像分析设计，旨在克服现有方法在标注数据和类别定义上的局限。该模型结合了大规模的PathSeg数据集（包含27.5万个图像-掩膜-标签三元组和160个类别），允许用户通过自然语言提示进行精确的语义分割。实验证明，PathSegmentor在准确性、适用性和泛化能力上均显著优于现有模型，并能增强诊断模型的可解释性，为精准肿瘤学中的可解释AI发展做出贡献。

> **摘要翻译:** 病理图像分割在计算病理学中至关重要，用于分析与癌症诊断和预后相关的组织学特征。然而，当前方法在临床应用中面临标注数据有限和类别定义受限的重大挑战。为了解决这些局限性，我们提出了PathSegmentor，这是首个专为病理图像设计的文本提示分割基础模型。我们还引入了PathSeg，这是迄今为止最大、最全面的病理分割数据集，由17个公共来源构建，包含160个不同类别的27.5万个图像-掩膜-标签三元组。通过PathSegmentor，用户可以使用自然语言提示执行语义分割，无需繁琐的空间输入，例如点或框。大量实验表明，PathSegmentor以更高的准确性和更广泛的适用性优于专用模型，同时保持紧凑的架构。在整体Dice分数上，它分别显著超越现有空间提示模型和文本提示模型0.145和0.429，在分割复杂结构和泛化到外部数据集方面显示出强大的鲁棒性。此外，PathSegmentor的输出通过特征重要性估计和成像生物标志物发现，增强了诊断模型的可解释性，为病理学家提供循证支持以辅助临床决策。这项工作推动了精准肿瘤学中可解释AI的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [301] [TSDASeg: A Two-Stage Model with Direct Alignment for Interactive Point Cloud Segmentation](https://arxiv.org/abs/2506.20991)
> *TSDASeg: 一种用于交互式点云分割的直接对齐两阶段模型*

*Chade Li, Pengju Zhang, Yihong Wu* | **Category: cs.CV**

**Keywords:** 交互式点云分割, 三维-文本对齐, 两阶段模型, 记忆模块, 跨模态

**Comment:** 

> **TL;DR:** 现有交互式点云分割方法因缺乏直接三维-文本对齐而表现不佳。本文提出TSDASeg，一个带有直接跨模态对齐模块和记忆模块的两阶段模型，解决了这一问题，并在多个数据集上取得了最先进的性能。

**AI_Comments:** 该论文通过引入直接三维-文本对齐，解决了交互式点云分割中的一个关键局限性，这是一项重要的创新。利用专用记忆模块来处理跨模态特征并确保场景之间的一致性也是一个巧妙的设计。所提出的TSDASeg模型似乎是解决实际三维视觉-语言应用的强大方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的交互式点云处理方法，特别是针对分割等点级别任务，由于缺少直接的三维-文本对齐，无法有效地将局部三维特征与文本语境关联，导致性能不佳。

**Method:** 本文提出了TSDASeg，一个结合了直接跨模态对齐模块和记忆模块的两阶段模型，用于交互式点云分割。直接跨模态对齐模块用于在三维点云和文本/二维图像数据之间建立显式对齐。记忆模块内包含多个专用记忆库，分别存储文本特征、视觉特征及其跨模态对应映射，并通过自注意力机制和交叉注意力机制动态利用这些记忆库来更新场景特定特征，从而解决不同场景下交互式分割结果的不一致性。

**Result:** 在多个三维指令、参考和语义分割数据集上进行的实验表明，所提出的TSDASeg方法实现了最先进的性能。

**Conclusion:** TSDASeg通过引入直接的三维-文本对齐和记忆模块，有效解决了交互式点云分割中现有方法的局限性，并在多个数据集上取得了最先进的性能，证明了其在实际应用中的有效性。

> **ai_Abstract:** TSDASeg是一种新颖的两阶段模型，专为交互式点云分割设计。它通过引入一个直接跨模态对齐模块和一个记忆模块，解决了现有方法缺乏直接三维-文本对齐的局限性。对齐模块显式地将三维点云与文本/二维图像关联起来，而记忆模块动态地存储和更新跨模态特征，以确保在不同场景下的一致性。实验结果表明，TSDASeg在各种三维分割数据集上实现了最先进的性能。

> **摘要翻译:** 三维视觉-语言模型（VLMs）的快速发展激发了人们对交互式点云处理任务的极大兴趣，尤其是在实际应用中。然而，现有方法在点级别任务（如分割）中往往表现不佳，因为缺少直接的三维-文本对齐，这限制了它们将局部三维特征与文本语境关联起来的能力。为了解决这个问题，我们提出了TSDASeg，这是一个两阶段模型，结合了直接跨模态对齐模块和记忆模块，用于交互式点云分割。我们引入了直接跨模态对齐模块，以在三维点云和文本/二维图像数据之间建立显式对齐。在记忆模块中，我们采用了多个专用记忆库来分别存储文本特征、视觉特征及其跨模态对应映射。这些记忆库通过自注意力机制和交叉注意力机制动态利用，根据预先存储的数据更新场景特定特征，有效地解决了不同场景下交互式分割结果的不一致性。在多个三维指令、参考和语义分割数据集上进行的实验表明，所提出的方法实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [303] [Real-Time ESFP: Estimating, Smoothing, Filtering, and Pose-Mapping](https://arxiv.org/abs/2506.21234)
> *实时ESFP：估计、平滑、滤波和姿态映射*

*Qifei Cui, Yuang Zhou, Ruichen Deng* | **Category: cs.CV, cs.RO**

**Keywords:** ESFP, 实时, 姿态估计, 机械臂控制, 运动平滑

**Comment:** 

> **TL;DR:** 本文提出了ESFP，一个端到端管道，能将单目RGB视频转换为低成本四自由度桌面机械臂的可执行关节轨迹。

**AI_Comments:** 该论文的创新点在于提出了一个完整的端到端管道ESFP，用于将人体运动视频实时转换为机械臂的控制指令。特别是HPSTM模块，通过结合Transformer和可微分正向运动学解码器，在平滑轨迹的同时保持了生物力学约束，这一点非常有意义。整个系统旨在实现低成本机械臂的视频控制，具有潜在的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在将单目RGB视频转换为低成本四自由度桌面机械臂的可执行关节轨迹。

**Method:** 本文提出了ESFP，一个包含四个顺序模块的端到端管道：1) 估计：ROMP将每帧提升为24个关节的3D骨架。2) 平滑：提出的HPSTM（一个带有自注意力机制的序列到序列Transformer）结合了长距离时间上下文和可微分正向运动学解码器，强制保持骨骼长度不变和解剖学合理性，同时联合预测关节均值和完整协方差。3) 滤波：根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，以抑制残余噪声。4) 姿态映射：一个几何重定向层将肩-肘-腕三元组转换为uArm的极坐标工作空间，同时保持腕部方向。

**Result:** 本文成功提出了ESFP，一个能够将单目RGB视频转换为低成本四自由度桌面机械臂可执行关节轨迹的端到端管道，并详细描述了其四个组成模块及其功能。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一个名为ESFP的实时端到端管道，旨在将单目RGB视频转换为低成本四自由度桌面机械臂的可执行关节轨迹。ESFP由四个模块组成：首先，ROMP模块将视频帧转换为3D骨架；其次，HPSTM（一个序列到序列Transformer）负责平滑关节轨迹并预测均值和协方差，同时确保解剖学合理性；接着，滤波模块根据不确定性估计抑制噪声；最后，姿态映射层将处理后的骨架姿态转换为机械臂在极坐标工作空间内的动作，并保持腕部方向。

> **摘要翻译:** 本文提出了ESFP，一个端到端管道，能将单目RGB视频转换为低成本四自由度桌面机械臂的可执行关节轨迹。ESFP包含四个顺序模块。(1) 估计：ROMP将每帧提升为24个关节的3D骨架。(2) 平滑：提出的HPSTM——一个带有自注意力机制的序列到序列Transformer——结合了长距离时间上下文和可微分正向运动学解码器，强制保持骨骼长度不变和解剖学合理性，同时联合预测关节均值和完整协方差。(3) 滤波：根据HPSTM的不确定性估计对根归一化轨迹进行方差加权，以抑制残余噪声。(4) 姿态映射：一个几何重定向层将肩-肘-腕三元组转换为uArm的极坐标工作空间，同时保持腕部方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [307] [DBMovi-GS: Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting](https://arxiv.org/abs/2506.20998)
> *DBMovi-GS：通过稀疏控制高斯泼溅从模糊单目视频进行动态视图合成*

*Yeon-Ji Song, Jaein Kim, Byung-Ju Kim, Byoung-Tak Zhang* | **Category: cs.CV**

**Keywords:** 动态视图合成, 模糊单目视频, 高斯泼溅, 3D重建, 运动恢复

**Comment:** CVPRW 2025, Neural Fields Beyond Conventional Cameras

> **TL;DR:** DBMovi-GS提出了一种新方法，通过生成密集的3D高斯并恢复清晰度，解决了从模糊单目视频进行动态场景新视图合成的挑战。

**AI_Comments:** DBMovi-GS的创新之处在于其能够直接从模糊的单目视频中进行动态视图合成，这对于现有方法来说是一个未解决的挑战。通过利用稀疏控制的高斯泼溅技术生成密集的3D高斯并恢复清晰度，该方法显著提升了在复杂真实世界环境中的鲁棒性和视觉保真度，为动态场景的新视图合成带来了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的新视图合成方法受限于对高分辨率图像的依赖或对静态几何和刚性场景的强假设，导致在动态物体和相机运动的真实世界环境中缺乏鲁棒性，表现不稳定且视觉保真度下降。

**Method:** 我们提出了Motion-aware Dynamic View Synthesis from Blurry Monocular Video via Sparse-Controlled Gaussian Splatting (DBMovi-GS)。我们的模型生成密集的3D高斯，从模糊视频中恢复清晰度，并重建受动态运动变化影响的场景的详细3D几何。

**Result:** 我们的模型在动态模糊场景下的新视图合成中实现了鲁棒性能，并为模糊单目视频输入设置了真实新视图合成的新基准。

**Conclusion:** DBMovi-GS有效地解决了从模糊单目视频进行动态视图合成的挑战，通过生成密集的3D高斯并恢复清晰度，重建详细的3D几何，从而在动态模糊场景中实现鲁棒性能并设定了新的基准。

> **ai_Abstract:** DBMovi-GS是一种针对从模糊单目视频进行动态视图合成的新方法，旨在解决现有技术在动态模糊场景中鲁棒性差的问题。该模型通过生成密集的3D高斯来恢复视频清晰度并重建受动态运动影响的详细3D几何，从而在动态模糊场景的新视图合成中表现出强大的性能，并为该领域设立了新的基准。

> **摘要翻译:** 新视图合成是一项从未知视角生成场景的任务；然而，从模糊单目视频合成动态场景仍然是一个尚未有效解决的挑战。现有新视图合成方法通常受限于对高分辨率图像的依赖或对静态几何和刚性场景的强假设。因此，它们的方法在具有动态物体和相机运动的真实世界环境中缺乏鲁棒性，导致不稳定和视觉保真度下降。为了解决这个问题，我们提出了通过稀疏控制高斯泼溅从模糊单目视频进行运动感知动态视图合成（DBMovi-GS），这是一种专为从模糊单目视频进行动态视图合成而设计的方法。我们的模型生成密集的3D高斯，从模糊视频中恢复清晰度，并重建受动态运动变化影响的场景的详细3D几何。我们的模型在动态模糊场景下的新视图合成中取得了鲁棒性能，并为模糊单目视频输入设置了真实新视图合成的新基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [308] [ToosiCubix: Monocular 3D Cuboid Labeling via Vehicle Part Annotations](https://arxiv.org/abs/2506.21358)
> *ToosiCubix: 基于车辆部件标注的单目3D长方体标注*

*Behrooz Nasihatkon, Hossein Resani, Amirreza Mehrzadian* | **Category: cs.CV, cs.RO**

**Keywords:** 3D长方体标注, 单目, 车辆, 数据标注, 优化

**Comment:** 

> **TL;DR:** ToosiCubix 是一种仅使用单目图像和少量用户点击即可进行车辆3D长方体标注的方法，比现有方法更经济且可扩展。

**AI_Comments:** 本文的主要创新在于提出了一种仅使用单目图像和少量用户点击即可进行3D长方体标注的方法，极大地降低了数据采集的成本和复杂性。这使得大规模3D数据标注变得更加可行和普及。该方法通过将问题转化为优化并结合先验知识来解决尺度模糊性，显示了其在实际应用中的潜力。其重要性在于为自动驾驶和计算机视觉领域的数据集构建提供了更经济、更高效的解决方案。虽然需要用户点击，但数量极少，使其具有很高的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 许多现有的车辆3D长方体标注方法依赖于昂贵且经过仔细校准的相机-激光雷达或立体设置，这限制了它们进行大规模数据采集的可及性。

**Method:** ToosiCubix 是一种仅使用单目图像和相机内参进行真值长方体标注的方法。它通过用户对车辆特定特征（如车轮、车标、对称性）的大约10次点击来估计车辆的位置、方向和尺寸（8自由度）。几何约束被表述为一个优化问题，通过坐标下降策略（在PnP和最小二乘子问题之间交替）解决。为了处理尺度和未观测尺寸等常见歧义，该方法结合了概率尺寸先验，从而实现了9自由度的长方体放置。

**Result:** 该方法能够准确估计车辆的位置、方向和尺寸（8自由度，加入先验后9自由度）。它在KITTI和Cityscapes3D数据集上进行了验证，结果表明该方法为高质量3D长方体标注提供了一种经济高效且可扩展的解决方案。

**Conclusion:** ToosiCubix 提供了一种实用、经济高效且可扩展的解决方案，仅使用单目图像即可实现高质量的3D长方体标注，克服了以往方法的局限性。

> **ai_Abstract:** ToosiCubix 是一种新颖的车辆3D长方体标注方法，它仅使用单目图像和最少的用户输入（每辆车约10次点击）。该方法通过将几何约束表述为优化问题，并利用坐标下降策略（交替进行PnP和最小二乘子问题）来解决，从而克服了昂贵多传感器设置的局限性。通过整合概率尺寸先验，ToosiCubix 实现了9自由度的长方体放置。该方法在KITTI和Cityscapes3D数据集上进行了验证，证明了其在高质量3D标注方面的成本效益和可扩展性。

> **摘要翻译:** 许多现有的车辆3D长方体标注方法依赖于昂贵且经过仔细校准的相机-激光雷达或立体设置，这限制了它们进行大规模数据采集的可及性。我们引入了 ToosiCubix，这是一种简单而强大的方法，仅使用单目图像和相机内参即可标注真值长方体。我们的方法每辆车只需约10次用户点击，这使得它对于向最初未配备专用设备收集的现有数据集添加3D标注非常实用。通过对不同车辆部件上的特定特征（例如车轮、车标、对称性）进行标注，我们能够准确估计每辆车的位置、方向和尺寸，但存在尺度模糊性（8自由度）。几何约束被表述为一个优化问题，我们使用坐标下降策略解决，在透视-n-点（PnP）和最小二乘子问题之间交替。为了处理尺度和未观测尺寸等常见歧义，我们引入了概率尺寸先验，从而实现了9自由度的长方体放置。我们在KITTI和Cityscapes3D数据集上验证了我们的标注，结果表明我们的方法为高质量3D长方体标注提供了一种经济高效且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [310] [Style-Aligned Image Composition for Robust Detection of Abnormal Cells in Cytopathology](https://arxiv.org/abs/2506.21001)
> *细胞病理学中用于异常细胞鲁棒检测的风格对齐图像合成*

*Qiuyi Qi, Xin Li, Ming Kong, Zikang Xu, Bingdi Chen, Qiang Zhu, S Kevin Zhou* | **Category: cs.CV**

**Keywords:** 异常细胞检测, 细胞病理学, 图像合成, 风格对齐, 鲁棒性

**Comment:** MIDL 2025 Oral

> **TL;DR:** 提出SAIC方法，通过合成风格对齐的病理图像，提高异常细胞检测的鲁棒性和整体性能。

**AI_Comments:** SAIC的创新之处在于其通过合成高保真、风格对齐的病理图像来解决细胞病理学中异常细胞检测面临的数据稀缺和风格不一致问题。该方法巧妙地结合了属性指导、高频特征重建以及大型视觉-语言模型进行质量控制，为医疗图像分析领域提供了新的思路。其重要性体现在能有效提升医疗诊断的准确性和鲁棒性，尤其是在处理罕见病变或多样化样本时。

<details>
  <summary>Details</summary>

**Motivation:** 高质量标注的缺乏、长尾数据分布以及不一致的染色风格对训练神经网络鲁棒地检测细胞病理学中的异常细胞构成了重大障碍。

**Method:** 本文提出了一种风格对齐图像合成（SAIC）方法。该方法无需额外训练，首先根据属性指导从异常细胞库中选择合适的候选细胞；然后，采用高频特征重建技术实现异常细胞与病理背景的风格对齐和高保真合成；最后，引入大型视觉-语言模型来过滤高质量的合成图像。

**Result:** 实验结果表明，结合SAIC合成的图像能有效增强针对长尾类别和不同风格的异常细胞检测性能和鲁棒性，从而提升整体检测效果。全面的质量评估进一步证实了SAIC在临床应用场景中的通用性和实用性。

**Conclusion:** SAIC方法通过合成高保真和风格对齐的病理图像，有效提升了细胞病理学中异常细胞检测的性能和鲁棒性，并具有良好的临床实用性。

> **ai_Abstract:** 针对细胞病理学中异常细胞检测面临的标注稀缺、数据长尾和染色风格不一致等挑战，本文提出了一种风格对齐图像合成（SAIC）方法。SAIC通过结合属性指导下的细胞选择、高频特征重建进行风格对齐的高保真合成，以及大型视觉-语言模型进行质量过滤，生成高质量的合成病理图像。实验证明，SAIC合成的图像显著提升了异常细胞检测模型对长尾类别和不同风格的性能与鲁棒性，展现了其在临床应用中的普适性和实用价值。

> **摘要翻译:** 细胞病理学中高质量标注的缺乏、长尾数据分布以及不一致的染色风格等挑战，对训练神经网络鲁棒地检测异常细胞构成了重大障碍。本文提出了一种风格对齐图像合成（SAIC）方法，该方法合成高保真且风格保留的病理图像，以增强检测模型的有效性和鲁棒性。SAIC无需额外训练，首先根据属性指导从异常细胞库中选择合适的候选细胞。然后，它采用高频特征重建技术实现异常细胞与病理背景的风格对齐和高保真合成。最后，它引入大型视觉-语言模型来过滤高质量的合成图像。实验结果表明，结合SAIC合成的图像能有效增强针对长尾类别和不同风格的异常细胞检测性能和鲁棒性，从而提升整体检测效果。全面的质量评估进一步证实了SAIC在临床应用场景中的通用性和实用性。我们的代码将在https://github.com/Joey-Qi/SAIC 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [312] [EndoFlow-SLAM: Real-Time Endoscopic SLAM with Flow-Constrained Gaussian Splatting](https://arxiv.org/abs/2506.21420)
> *EndoFlow-SLAM：基于流约束高斯泼溅的实时内窥镜SLAM*

*Taoyu Wu, Yiyi Miao, Zhuoxiao Li, Haocheng Zhao, Kang Dang, Jionglong Su, Limin Yu, Haoang Li* | **Category: cs.CV, cs.RO**

**Keywords:** 内窥镜SLAM, 3D高斯泼溅, 光流, 实时, 姿态估计

**Comment:** 

> **TL;DR:** EndoFlow-SLAM引入光流损失和深度正则化策略，改进3D高斯泼溅(3DGS)以克服内窥镜SLAM中的光度不一致和动态运动问题，在实时三维重建和位姿估计方面优于现有方法。

**AI_Comments:** 该论文的创新点在于将光流损失和深度正则化策略引入到基于3DGS的SLAM系统中，以应对内窥镜手术中特有的光度不一致和动态运动问题。这对于提升内窥镜实时三维重建和导航的准确性和鲁棒性具有重要意义。其在动态场景下的优越表现也突显了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在内窥镜等手术场景中，高效的三维重建和实时可视化至关重要。现有的基于3D高斯泼溅（3DGS）的同步定位与建图（SLAM）方法主要依赖外观约束，但在内窥镜场景中，非朗伯表面引起的光度不一致和呼吸引起的动态运动会影响SLAM系统性能。

**Method:** 该方法引入光流损失作为几何约束，有效约束场景的三维结构和相机运动。此外，提出了一种深度正则化策略来缓解光度不一致问题，并确保3DGS深度渲染在内窥镜场景中的有效性。为了改善SLAM系统中的场景表示，该研究还改进了3DGS细化策略，关注渲染质量欠佳的关键帧视角，以获得更好的渲染结果。

**Result:** 在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，该方法在新视角合成和位姿估计方面优于现有最先进的方法，在静态和动态手术场景中均表现出高性能。

**Conclusion:** EndoFlow-SLAM通过引入光流约束和深度正则化等策略，有效解决了内窥镜SLAM中光度不一致和动态运动的挑战，实现了高效的实时三维重建和精准的位姿估计，为手术场景提供了优越的SLAM解决方案。

> **ai_Abstract:** EndoFlow-SLAM是一种为内窥镜手术场景设计的实时SLAM系统，旨在解决现有3DGS-based SLAM方法在内窥镜中面临的光度不一致和动态运动挑战。该方法通过引入光流损失作为几何约束，以及提出深度正则化策略来优化3D结构和相机运动，并改进3DGS细化策略以增强场景表示。实验结果表明，EndoFlow-SLAM在静态和动态手术场景中，其新视角合成和位姿估计性能均优于现有先进方法。

> **摘要翻译:** 高效的三维重建和实时可视化在内窥镜等手术场景中至关重要。近年来，三维高斯泼溅（3DGS）在高效三维重建和渲染方面表现出卓越的性能。大多数基于3DGS的同步定位与建图（SLAM）方法仅依赖外观约束来优化3DGS和相机姿态。然而，在内窥镜场景中，挑战包括由非朗伯表面引起的光度不一致和呼吸导致的动态运动影响SLAM系统的性能。为了解决这些问题，我们额外引入了光流损失作为几何约束，有效约束了场景的三维结构和相机运动。此外，我们提出了一种深度正则化策略，以缓解光度不一致问题并确保3DGS深度渲染在内窥镜场景中的有效性。另外，为了改善SLAM系统中的场景表示，我们通过关注对应于渲染质量欠佳关键帧的视角来改进3DGS细化策略，从而获得更好的渲染结果。在C3VD静态数据集和StereoMIS动态数据集上的大量实验表明，我们的方法在新视角合成和位姿估计方面优于现有最先进的方法，在静态和动态手术场景中均表现出高性能。源代码将在论文接受后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [314] [Inverse Scene Text Removal](https://arxiv.org/abs/2506.21002)
> *逆向场景文本移除*

*Takumi Yoshimatsu, Shumpei Takezaki, Seiichi Uchida* | **Category: cs.CV**

**Keywords:** 逆向场景文本移除, 场景文本移除, 文本检测, 图像修复, 滥用检测

**Comment:** 17 pages

> **TL;DR:** 本文研究逆向场景文本移除（ISTR），旨在检测图像是否经过场景文本移除（STR）处理，定位被移除的文本区域，并尝试恢复移除的文本内容。

**AI_Comments:** 这项工作具有重要的实际意义，因为它直接解决了文本移除技术可能带来的伦理和滥用问题。通过提出逆向检测和定位的方法，为图像取证和内容真实性验证提供了新的视角。尝试恢复文本内容虽然具有挑战性，但为未来的研究指明了方向。其创新性在于从“移除”的对立面“检测移除”进行研究，填补了该领域的空白。

<details>
  <summary>Details</summary>

**Motivation:** 场景文本移除（STR）技术虽然有所进步，但也带来了滥用风险。为了检测潜在的滥用并改进STR技术，需要一种能够分析STR处理过的图像，并识别是否经过STR处理以及移除文本区域的方法。

**Method:** 本文研究逆向场景文本移除（ISTR）。方法包括两个主要任务：1) 二分类：检测图像是否经过STR处理。2) 定位：定位被移除的文本区域。此外，还尝试训练一个文本识别器来恢复被移除的文本内容，以评估其难度。

**Result:** 实验表明，检测图像是否经过STR处理和定位被移除文本区域的任务可以高精度实现。恢复被移除文本内容的尝试也揭示了其难度。

**Conclusion:** 逆向场景文本移除（ISTR）任务，包括检测图像是否经过STR处理和定位被移除文本区域，是可行的且能达到高精度，这有助于检测潜在的滥用并改进STR技术。恢复被移除的文本内容具有挑战性。

> **ai_Abstract:** 本文提出并研究了逆向场景文本移除（ISTR）任务，旨在应对场景文本移除（STR）技术可能带来的滥用风险。ISTR主要包括检测图像是否经过STR处理的二分类任务，以及定位被移除文本区域的任务。实验证明，这些任务可以高精度完成，有助于识别STR的潜在滥用并改进现有STR方法。此外，研究还尝试恢复被移除的文本内容，并评估了该任务的难度。

> **摘要翻译:** 场景文本移除（STR）旨在从图像中擦除文本元素。它最初是为了从自然场景图像中移除隐私敏感或不需要的文本，但现在也应用于版式图像。STR通常检测文本区域然后进行修复。尽管STR通过神经网络和合成数据取得了进展，但滥用风险也随之增加。本文研究逆向STR（ISTR），它分析经过STR处理的图像，并专注于二分类（检测图像是否经过STR处理）和定位被移除的文本区域。我们在实验中证明这些任务可以高精度实现，从而能够检测潜在的滥用并改进STR。我们还尝试通过训练一个文本识别器来恢复被移除的文本内容，以了解其难度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [VisionGuard: Synergistic Framework for Helmet Violation Detection](https://arxiv.org/abs/2506.21005)
> *VisionGuard：头盔违规检测的协同框架*

*Lam-Huy Nguyen, Thinh-Phuc Nguyen, Thanh-Hai Nguyen, Gia-Huy Dinh, Minh-Triet Tran, Trung-Nghia Le* | **Category: cs.CV**

**Keywords:** 头盔违规检测, 交通安全, 目标检测, 跟踪, 数据不平衡

**Comment:** 

> **TL;DR:** VisionGuard是一个多阶段框架，通过自适应标注和上下文扩展模块，解决了头盔违规自动检测中数据不一致和类别不平衡的挑战，将mAP提高了3.1%。

**AI_Comments:** 这篇论文通过提出VisionGuard框架，有效解决了头盔违规自动检测中长期存在的分类一致性差和数据不平衡问题。其创新点在于结合了跟踪算法进行标签细化（自适应标注模块）和生成虚拟边界框以增强稀有类别召回率（上下文扩展模块）。这使得检测系统在复杂多变的环境下更鲁棒、更准确。该框架对于提升交通监控的自动化水平和道路安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 摩托车手头盔法规的执行对道路安全至关重要，但自动检测面临环境多变性、摄像机角度和数据不一致等挑战，这些因素阻碍了摩托车和骑手的可靠检测，并干扰了对象分类的一致性。现有的逐帧检测器在类别不平衡和标注不一致的情况下存在局限性。

**Method:** 提出VisionGuard，一个协同的多阶段框架，旨在克服逐帧检测器的局限性。它集成了两个关键组件：自适应标注模块和上下文扩展模块。自适应标注模块是一种基于跟踪的细化技术，通过利用跟踪算法在帧之间分配持久标签并纠正错误分类来增强分类一致性。上下文扩展模块通过生成具有适当置信度分数的虚拟边界框来提高代表性不足类别的召回率，有效解决了数据不平衡的影响。

**Result:** 实验结果表明，与基线检测器相比，VisionGuard将整体mAP提高了3.1%。

**Conclusion:** VisionGuard证明了其在交通监控系统中实际部署的有效性和潜力，最终促进了安全和法规遵守。

> **ai_Abstract:** VisionGuard是一个用于头盔违规检测的协同多阶段框架，旨在解决自动检测中环境变异性、数据不一致性和类别不平衡等挑战。该框架包含自适应标注模块（通过跟踪提高分类一致性）和上下文扩展模块（通过生成虚拟边界框改善稀有类别召回率）。实验证明，VisionGuard将整体mAP提高了3.1%，显示出其在实际交通监控系统中的应用潜力，有助于提升道路安全和法规遵守。

> **摘要翻译:** 强制执行摩托车手头盔法规对于提高道路安全和确保交通管理系统的有效性至关重要。然而，由于环境多变性、摄像机角度和数据不一致等因素，头盔违规的自动检测面临重大挑战。这些因素阻碍了摩托车和骑手的可靠检测，并干扰了对象分类的一致性。为了应对这些挑战，我们提出了VisionGuard，一个协同的多阶段框架，旨在克服逐帧检测器的局限性，特别是在类别不平衡和标注不一致的场景中。VisionGuard集成了两个关键组件：自适应标注和上下文扩展模块。自适应标注模块是一种基于跟踪的细化技术，通过利用跟踪算法在帧之间分配持久标签并纠正错误分类来增强分类一致性。上下文扩展模块通过生成具有适当置信度分数的虚拟边界框来提高代表性不足类别的召回率，有效解决了数据不平衡的影响。实验结果表明，与基线检测器相比，VisionGuard将整体mAP提高了3.1%，证明了其在交通监控系统中实际部署的有效性和潜力，最终促进了安全和法规遵守。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [318] [SAM4D: Segment Anything in Camera and LiDAR Streams](https://arxiv.org/abs/2506.21547)
> *SAM4D：在相机和激光雷达流中分割一切*

*Jianyun Xu, Song Wang, Ziqian Ni, Chunyong Hu, Sheng Yang, Jianke Zhu, Qiang Li* | **Category: cs.CV, cs.RO**

**Keywords:** 多模态分割, 激光雷达, 相机, 基础模型, 伪标签生成

**Comment:** Accepted by ICCV2025, Project Page: https://SAM4D-Project.github.io

> **TL;DR:** SAM4D是一个多模态时间基础模型，用于相机和激光雷达流的可提示分割，通过统一位置编码和运动感知注意力增强跨模态和时间一致性，并提出自动化数据引擎加速伪标签生成。

**AI_Comments:** SAM4D的创新点在于其多模态（相机+LiDAR）融合策略和时间一致性处理，特别是UMPE和MCMA的设计。更重要的是，它提出了一个自动化数据引擎，显著加速了高质量伪标签的生成，这对于解决自动驾驶领域昂贵且耗时的数据标注问题具有重要意义。该模型在基础模型框架下，结合了分割和数据生成能力，具有很高的实用价值和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有分割模型在多模态数据对齐和时间一致性方面存在挑战，尤其是在动态自动驾驶场景中。此外，数据标注是瓶颈，需要更高效的标注方法。

**Method:** 该论文引入了统一多模态位置编码（UMPE）以对齐相机和激光雷达特征到共享3D空间，实现跨模态提示和交互。提出了运动感知跨模态记忆注意力（MCMA）以利用自我运动补偿增强时间一致性和长距离特征检索。此外，开发了一个多模态自动化数据引擎，通过协同VFM驱动的视频masklets、时空4D重建和跨模态masklet融合来生成相机-激光雷达对齐的伪标签。

**Result:** 在构建的Waymo-4DSeg数据集上进行了广泛实验，结果表明SAM4D具有强大的跨模态分割能力和在数据标注方面的巨大潜力。其自动化数据引擎生成伪标签的速度比人工标注快几个数量级，同时保持了语义保真度。

**Conclusion:** SAM4D通过其创新的多模态和时间处理机制，显著提升了相机和激光雷达流的分割能力，并为解决数据标注瓶颈提供了一个高效的解决方案。

> **ai_Abstract:** SAM4D是一个针对相机和激光雷达流的可提示分割的多模态时间基础模型。它通过统一多模态位置编码（UMPE）实现特征对齐和跨模态交互，并利用运动感知跨模态记忆注意力（MCMA）增强时间一致性。为了解决标注瓶颈，SAM4D还引入了一个多模态自动化数据引擎，能够高效生成高质量的相机-激光雷达对齐伪标签。在Waymo-4DSeg数据集上的实验表明，SAM4D在跨模态分割和数据标注方面表现出强大的能力和巨大潜力。

> **摘要翻译:** 我们提出了SAM4D，一个多模态和时间基础模型，旨在实现相机和激光雷达流的可提示分割。引入了统一多模态位置编码（UMPE），以在共享的3D空间中对齐相机和激光雷达特征，从而实现无缝的跨模态提示和交互。此外，我们提出了运动感知跨模态记忆注意力（MCMA），它利用自我运动补偿来增强时间一致性和长距离特征检索，确保在动态变化的自动驾驶场景中实现鲁棒的分割。为了避免标注瓶颈，我们开发了一个多模态自动化数据引擎，该引擎协同VFM驱动的视频masklets、时空4D重建和跨模态masklet融合。该框架生成的相机-激光雷达对齐伪标签的速度比人工标注快几个数量级，同时在点云表示中保留了VFM衍生的语义保真度。我们在构建的Waymo-4DSeg数据集上进行了广泛实验，这些实验证明了所提出的SAM4D强大的跨模态分割能力和在数据标注方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [320] [Detection of Breast Cancer Lumpectomy Margin with SAM-incorporated Forward-Forward Contrastive Learning](https://arxiv.org/abs/2506.21006)
> *乳腺癌保乳术切缘的SAM融合前向-前向对比学习检测*

*Tyler Ward, Xiaoqin Wang, Braxton McFarland, Md Atik Ahamed, Sahar Nozad, Talal Arshad, Hafsa Nebbache, Jin Chen, Abdullah Imran* | **Category: cs.CV**

**Keywords:** 乳腺癌, 保乳术, 切缘检测, 对比学习, SAM, 深度学习

**Comment:** 19 pages, 7 figures, 3 tables

> **TL;DR:** 该研究提出了一种结合SAM和前向-前向对比学习的深度学习框架FFCL-SAM，用于提高乳腺癌保乳术中切缘评估的速度和准确性，以减少再次手术率。

**AI_Comments:** 这篇论文的创新点在于将前向-前向对比学习（FFCL）与强大的通用分割模型SAM相结合，以解决乳腺癌保乳术中切缘评估的实际临床难题。FFCL的预训练策略能够有效利用局部和全局信息进行补丁级分类，而SAM的引入则能提供高精度的分割能力。该方法不仅在准确性上取得了显著提升（AUC 0.8455，Dice相似度提高27.4%），还在推理速度上实现了突破（47毫秒/图像），这对于术中快速决策至关重要。其潜在的临床影响是巨大的，有望显著降低患者的再次手术率，减轻患者负担并优化医疗资源。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于评估乳腺癌保乳术中切缘状态的二维标本X射线摄影（SR）准确性有限，导致近四分之一的患者需要再次手术，因此需要更准确、快速的方法来评估切缘。

**Method:** 提出了一种结合Segment Anything Model (SAM) 和 Forward-Forward Contrastive Learning (FFCL) 的新型深度学习框架。该方法首先对SR图像进行标注，然后使用FFCL预训练ResNet-18骨干网络进行切缘状态分类，最后通过重建粗略的二值掩码来提示SAM进行精细的肿瘤切缘分割。

**Result:** 该方法在切缘分类方面实现了0.8455的AUC；在切缘分割方面，Dice相似度比基线模型提高了27.4%；同时，每张图像的推理时间减少到47毫秒。

**Conclusion:** FFCL-SAM显著提高了术中切缘评估的速度和准确性，具有降低再次切除率和改善乳腺癌治疗手术结果的巨大潜力。

> **ai_Abstract:** 该论文提出了一种名为FFCL-SAM的深度学习框架，旨在提高乳腺癌保乳术中切缘评估的准确性和效率。该框架结合了前向-前向对比学习（FFCL）进行图像补丁分类预训练，并利用Segment Anything Model (SAM) 进行精细的肿瘤切缘分割。实验结果表明，FFCL-SAM在切缘分类和分割性能上均显著优于基线模型，并大幅缩短了推理时间，有望减少患者的再次手术率并改善治疗效果。

> **摘要翻译:** **标题：** 融合SAM的前向-前向对比学习在乳腺癌保乳术切缘检测中的应用

**摘要：** 在保乳术中完整切除肿瘤并获得阴性标本切缘对于降低乳腺癌复发至关重要。然而，二维标本X射线摄影（SR）作为目前用于评估术中标本切缘状态的方法，其准确性有限，导致近四分之一的患者需要再次手术。为解决此问题，我们提出了一种新颖的深度学习框架，将Segment Anything Model (SAM) 与前向-前向对比学习 (FFCL) 相结合。FFCL是一种预训练策略，利用局部和全局对比学习对SR图像进行补丁级分类。在对已知恶性、非恶性组织和病理证实切缘的SR图像进行标注后，我们使用FFCL预训练一个ResNet-18骨干网络来分类切缘状态，然后重建粗略的二值掩码以提示SAM进行精细的肿瘤切缘分割。我们的方法在切缘分类方面实现了0.8455的AUC，在切缘分割方面的Dice相似度比基线模型提高了27.4%，同时将每张图像的推理时间减少到47毫秒。这些结果表明，FFCL-SAM显著提高了术中切缘评估的速度和准确性，具有降低再次切除率和改善乳腺癌治疗手术结果的巨大潜力。我们的代码可在https://github.com/tbwa233/FFCL-SAM/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [322] [Whole-Body Conditioned Egocentric Video Prediction](https://arxiv.org/abs/2506.21552)
> *全身条件下的自我中心视频预测*

*Yutong Bai, Danny Tran, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik* | **Category: cs.CV, cs.AI, cs.LG, cs.MM, cs.RO**

**Keywords:** 自我中心视频预测, 身体姿态, 扩散模型, 具身智能体, 视频生成

**Comment:** Project Page: https://dannytran123.github.io/PEVA

> **TL;DR:** 该论文训练了一个模型（PEVA），通过以人体姿态为条件，预测第一人称视角视频，并使用了一个新的评估协议来分析其能力。

**AI_Comments:** 这项工作的创新在于将全身姿态作为条件来预测自我中心视频，这为模拟具身智能体在复杂环境中的行为提供了新的视角。通过使用扩散模型和大规模真实世界数据集，该研究为未来更高级的具身AI系统奠定了基础。分层评估协议的设计也值得称赞，它允许对模型的不同能力进行细致分析。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在从人类视角出发，通过视频预测来模拟复杂的真实世界环境和具身智能体的行为。

**Method:** 作者训练了一个自回归条件扩散变换器（PEVA），通过过去视频和相对3D身体姿态表示的动作进行条件化，以预测自我中心视频。模型在大型真实世界自我中心视频和身体姿态捕获数据集Nymeria上进行训练。他们还设计了一个分层评估协议。

**Result:** 该模型学会了模拟物理人体动作如何从第一人称视角塑造环境。他们设计的分层评估协议能够全面分析模型的具身预测和控制能力。

**Conclusion:** 这项工作代表了从人类视角出发，通过视频预测来建模复杂真实世界环境和具身智能体行为挑战的初步尝试。

> **ai_Abstract:** 该论文介绍了一种名为PEVA的模型，旨在通过以人体动作（表示为相对3D身体姿态）为条件，预测自我中心视频。该模型利用运动姿态轨迹来模拟人类行为如何影响环境。PEVA是一个自回归条件扩散变换器，在大型数据集Nymeria上进行训练。为了全面评估模型的具身预测和控制能力，研究者还开发了一个分层评估协议。这项工作是解决从人类视角建模复杂真实世界环境和具身智能体行为的初步探索。

> **摘要翻译:** 我们训练模型（PEVA）根据过去的视频和由相对3D身体姿态表示的动作来预测自我中心视频。通过以身体关节层次结构化的运动姿态轨迹为条件，我们的模型学会了从第一人称视角模拟物理人体动作如何塑造环境。我们在Nymeria（一个包含大量真实世界自我中心视频和身体姿态捕捉数据的大规模数据集）上训练了一个自回归条件扩散变换器。我们进一步设计了一个具有逐渐增加挑战性任务的分层评估协议，从而能够全面分析模型的具身预测和控制能力。我们的工作代表了从人类视角出发，通过视频预测来解决建模复杂真实世界环境和具身智能体行为挑战的初步尝试。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [323] [The Aging Multiverse: Generating Condition-Aware Facial Aging Tree via Training-Free Diffusion](https://arxiv.org/abs/2506.21008)
> *衰老多重宇宙：通过免训练扩散生成条件感知面部衰老树*

*Bang Gong, Luchao Qi, Jiaye Wu, Zhicheng Fu, Chunbo Song, David W. Jacobs, John Nicholson, Roni Sengupta* | **Category: cs.CV**

**Keywords:** 面部衰老, 扩散模型, 条件感知, 衰老树, 免训练

**Comment:** 

> **TL;DR:** 提出“衰老多重宇宙”框架，通过免训练扩散方法，从单张图像生成多条受外部因素影响的 plausible 面部衰老轨迹，形成“衰老树”，优于现有确定性方法。

**AI_Comments:** 本文提出了“衰老树”这一新颖概念，通过整合外部因素，超越了传统的确定性衰老模型，提供了一种更真实、更多功能的衰老模拟方法。“免训练扩散”方法的提出尤具创新性，降低了计算成本，使模型更具实用性。该研究强调平衡身份保留、年龄准确性和条件控制，并结合注意力混合和模拟衰老正则化等特定技术，展现了其方法论的稳健性。其在数字故事讲述和健康教育方面的应用潜力巨大，凸显了这项研究的实际影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法将衰老建模为单一确定性路径，而本文旨在生成受环境、健康和生活方式等外部因素影响的多种 plausible 面部衰老轨迹。

**Method:** 提出一种免训练的基于扩散的方法，以平衡身份保留、年龄准确性和条件控制。主要贡献包括用于调节编辑强度的注意力混合（attention mixing）和用于稳定编辑的模拟衰老正则化（Simulated Aging Regularization）策略。

**Result:** 在身份保留、衰老真实感和条件对齐方面表现出最先进的性能，优于现有编辑和年龄进展模型，这些模型通常未能考虑一个或多个编辑标准。

**Conclusion:** 将衰老转化为一个多维度、可控且可解释的过程，为数字故事讲述、健康教育和个性化可视化开辟了新的创意和实用途径。

> **ai_Abstract:** 本文提出“衰老多重宇宙”框架，利用免训练扩散方法，从单张图像生成多条受外部因素（如环境、健康、生活方式）影响的 plausible 面部衰老轨迹，形成“衰老树”，以可视化多样化的未来。该方法通过注意力混合和模拟衰老正则化策略，平衡身份保留、年龄准确性和条件控制。实验和用户研究表明，在身份保留、衰老真实感和条件对齐方面，其性能优于现有模型。该方法将衰老转化为多维度、可控且可解释的过程，为数字故事讲述、健康教育和个性化可视化等领域开辟了新途径。

> **摘要翻译:** 我们引入了衰老多重宇宙（Aging Multiverse），这是一个从单张图像生成多条 plausible 面部衰老轨迹的框架，每条轨迹都以环境、健康和生活方式等外部因素为条件。与将衰老建模为单一确定性路径的现有方法不同，我们的方法创建了一个可视化多样化未来的衰老树。为了实现这一点，我们提出了一种免训练的基于扩散的方法，该方法平衡了身份保留、年龄准确性和条件控制。我们的主要贡献包括用于调节编辑强度的注意力混合（attention mixing）和用于稳定编辑的模拟衰老正则化（Simulated Aging Regularization）策略。广泛的实验和用户研究表明，在身份保留、衰老真实感和条件对齐方面，该方法表现出最先进的性能，优于现有编辑和年龄进展模型，这些模型通常未能考虑一个或多个编辑标准。通过将衰老转化为一个多维度、可控且可解释的过程，我们的方法为数字故事讲述、健康教育和个性化可视化开辟了新的创意和实用途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [326] [User-in-the-Loop View Sampling with Error Peaking Visualization](https://arxiv.org/abs/2506.21009)
> *用户在环的视图采样与误差峰值可视化*

*Ayaka Yasunaga, Hideo Saito, Shohei Mori* | **Category: cs.CV**

**Keywords:** 视图采样, 增强现实, 新视图合成, 误差可视化, 光场, 3D高斯泼溅

**Comment:** Accepted at IEEE ICIP 2025, Project Page:
  https://mediated-reality.github.io/projects/yasunaga_icip25/

> **TL;DR:** 该论文提出了一种新的AR中新视图合成的视图采样方法，通过可视化误差来指导用户，使数据收集过程更轻松高效，并适用于大场景。

**AI_Comments:** 这篇论文通过将数据收集从显式3D注释转变为直观的误差可视化，解决了AR中新视图合成数据收集的实际挑战。这一创新显著改善了用户体验和效率，使过程更易于访问并可扩展到更大的场景，这对于实际的AR应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有的增强现实（AR）视图采样方法对用户心理要求高，需要3D注释，并且由于采样理论的限制，捕获区域小。本文的动机是让用户摆脱这些限制，实现更轻松高效的新视图合成数据收集。

**Method:** 本文提出利用局部重建的光场，并通过“误差峰值可视化”来指导用户插入新的视图以消除误差，从而进行视图采样。

**Result:** 误差峰值可视化侵入性更小，减少了最终结果的失望，并且在移动视图合成系统中用更少的视图样本就能达到满意效果。此外，该方法还可用于更大场景的辐射场重建，如3D高斯泼溅。

**Conclusion:** 所提出的误差峰值可视化方法提高了新视图合成中视图采样的用户体验和效率，使其更省力并适用于更大场景。

> **ai_Abstract:** 本文介绍了一种用于增强现实中新视图合成的用户在环视图采样方法。为克服当前依赖3D注释且对用户要求高、限制性强的方法，作者提出利用局部重建的光场和“误差峰值可视化”来引导用户。研究表明，该方法侵入性更小，提高了用户满意度，所需样本量更少，并且适用于3D高斯泼溅等更大场景的重建技术。

> **摘要翻译:** 增强现实（AR）提供了可视化缺失视图样本以进行新视图合成的方法。现有方法为新视图样本提供3D注释，并要求用户通过对齐AR显示器来拍摄图像。众所周知，这种数据收集任务对精神要求很高，并且由于理想但限制性的底层采样理论，将捕获区域限制在预定义的小区域。为了将用户从3D注释和有限的场景探索中解放出来，我们建议使用局部重建的光场并可视化通过插入新视图要消除的误差。我们的结果表明，误差峰值可视化侵入性更小，减少了最终结果的失望，并且在我们的移动视图合成系统中，使用更少的视图样本就令人满意。我们还表明，我们的方法可以为更大场景的最新辐射场重建做出贡献，例如3D高斯泼溅。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [329] [Bridging Video Quality Scoring and Justification via Large Multimodal Models](https://arxiv.org/abs/2506.21011)
> *通过大型多模态模型连接视频质量评分与解释*

*Qizhi Xie, Kun Yuan, Yunpeng Qu, Jiachao Gong, Mingda Wu, Ming Sun, Chao Zhou, Jihong Zhu* | **Category: cs.CV**

**Keywords:** 视频质量评估, 大型多模态模型, 指令调优, 数据生成, 思维链

**Comment:** 15 pages, 4 figures, 8 tables

> **TL;DR:** 本文提出了一种名为SIG的管道，用于自动生成视频质量评估的指令数据（Score2Instruct数据集），并开发了一种渐进式调优策略和S2I-Bench基准，以提升大型多模态模型在视频质量评分和解释方面的能力。

**AI_Comments:** 本文的创新点在于提出了一个自动化的数据生成管道SIG，解决了视频质量评估领域高质量指令数据稀缺的问题，并摆脱了对人工标注和专有系统的依赖，极大地提升了数据生成的可扩展性和效率。通过引入分层思维链（CoT），模型能够更好地模拟人类的推理过程，从而提供更具解释性的视频质量评估。这项工作对于推动大型多模态模型在视频理解和评价方面的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的视频质量评估（VQA）方法仅生成数值分数，无法描述视频复杂的质量维度，限制了其适用性。现有的指令数据生成方法主要集中在图像领域，且高度依赖人工标注和专有系统，导致数据可扩展性和效率受限。

**Method:** 本文提出了基于分数的指令生成（Score-based Instruction Generation, SIG）管道。SIG首先对未标注视频的多个质量维度进行评分，并将其映射到文本定义的级别。然后，它明确地结合了分层思维链（Chain-of-Thought, CoT）来模拟人类视觉系统，建模特定维度与整体质量之间的关联。该自动化管道消除了对专家编写质量描述和专有系统的依赖。在此基础上，生成了包含超过320K个指令-响应对的Score2Instruct (S2I) 数据集。此外，为同时提升视频大型多模态模型（LMMs）的质量评分和解释能力，本文设计了一种渐进式调优策略。基于SIG，进一步构建了一个包含400个开放式问题的S2I-Bench基准，以更好地评估视频LMMs的质量解释能力。

**Result:** 在S2I-Bench和现有基准上的实验结果表明，该方法持续改进了多个视频大型多模态模型的质量评分和解释能力。

**Conclusion:** 本文提出的SIG管道及其生成的S2I数据集和S2I-Bench基准，有效提升了大型多模态模型在视频质量评估中的评分和解释能力，解决了传统方法和现有数据生成方法的局限性。

> **ai_Abstract:** 本文针对传统视频质量评估（VQA）仅提供数值分数而缺乏解释性的问题，提出了一种基于分数的指令生成（SIG）管道。该管道能够自动化生成大规模视频质量评估指令数据（Score2Instruct数据集），并结合分层思维链（CoT）来模拟人类推理过程。此外，本文还设计了渐进式调优策略和S2I-Bench基准，以提升大型多模态模型（LMMs）在视频质量评分和解释方面的能力。实验证明，该方法显著改善了多个视频LMMs的性能。

> **摘要翻译:** 经典的视频质量评估（VQA）方法生成一个数值分数来判断视频感知的视觉保真度和清晰度。然而，一个分数无法描述视频复杂的质量维度，限制了其适用性。受益于语言输出，通过指令调优将视频大型多模态模型（LMMs）应用于VQA，有潜力解决这个问题。该方法的核心在于以视频质量为中心的指令数据。之前的探索主要集中在图像领域，其数据生成过程高度依赖人工质量标注和专有系统，限制了数据的可扩展性和有效性。为了解决这些挑战，我们提出了基于分数的指令生成（SIG）管道。具体来说，SIG首先对未标注视频的多个质量维度进行评分，并将分数映射到文本定义的级别。然后，它明确地结合了分层思维链（CoT）来建模特定维度与整体质量之间的关联，模仿人类视觉系统的推理过程。该自动化管道消除了对专家编写质量描述和专有系统的依赖，确保了数据的可扩展性和生成效率。为此，生成的Score2Instruct (S2I) 数据集包含超过320K个多样化的指令-响应对，为指令调优奠定了基础。此外，为了同时提升视频LMMs的质量评分和解释能力，我们设计了一种渐进式调优策略以充分释放S2I的潜力。在SIG的基础上，我们进一步策划了一个名为S2I-Bench的基准，包含400个开放式问题，以更好地评估视频LMMs的质量解释能力。S2I-Bench和现有基准上的实验结果表明，我们的方法持续改进了多个视频LMMs的质量评分和解释能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [331] [FedSC: Federated Learning with Semantic-Aware Collaboration](https://arxiv.org/abs/2506.21012)
> *FedSC：语义感知协作的联邦学习*

*Huan Wang, Haoran Li, Huaming Chen, Jun Yan, Jiahua Shi, Jun Shen* | **Category: cs.CV**

**Keywords:** 联邦学习, 数据异质性, 语义感知, 原型学习, 协作训练

**Comment:** 12 pages, KDD 2025

> **TL;DR:** FedSC通过构建语义级关系原型和一致原型来解决联邦学习中的数据异质性问题，从而在保护隐私的同时实现有效的协作训练。

**AI_Comments:** 该论文创新性地将语义信息融入联邦学习框架，通过语义级原型来解决数据异质性问题，这为联邦学习的进一步发展提供了新的视角。其提出的跨对比学习和一致原型设计具有新颖性，并提供了理论收敛性保证，增强了方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在保护隐私方面存在数据异质性挑战，现有方法常忽略客户端固有的语义信息。本文旨在探索利用客户端内部语义信息来处理数据异质性问题。

**Method:** 本文提出了FedSC（Federated Learning with Semantic-Aware Collaboration）方法。其核心思想是在语义层面构建关系原型（relational prototypes）和一致原型（consistent prototypes）。具体地，FedSC引入了一种跨对比学习策略，使实例级嵌入与相同语义的关系原型更接近，并远离不同类别。此外，FedSC通过差异聚合方式设计了一致原型，作为正则化惩罚来约束局部模型的优化区域。文章还提供了FedSC的理论收敛性分析。

**Result:** 在各种具有挑战性的场景下进行的实验结果表明，FedSC的有效性以及其关键组件的效率。

**Conclusion:** FedSC通过引入语义感知协作，有效地解决了联邦学习中的数据异质性问题，并通过构建关系原型和一致原型，提供了丰富的类别底层知识和稳定的收敛信号，并得到了理论收敛性保证。

> **ai_Abstract:** 本文提出了FedSC（Federated Learning with Semantic-Aware Collaboration），旨在解决联邦学习中的数据异质性问题。FedSC通过在语义层面构建关系原型和一致原型，利用客户端内部的语义信息。它引入了跨对比学习策略来优化实例嵌入，并利用一致原型作为正则化项。理论分析和实验结果均验证了FedSC在处理数据异质性方面的有效性和收敛性。

> **摘要翻译:** 联邦学习（FL）旨在跨客户端协同训练模型，同时不共享数据以保护隐私。然而，一个主要的挑战是数据异质性问题，这指的是多个客户端的标签偏好存在偏差。许多现有的FL方法尝试在本地（例如，正则化局部模型）或全局（例如，微调全局模型）解决数据异质性问题，但往往忽略了每个客户端中固有的语义信息。为了探索利用客户端内部语义有意义的知识来处理数据异质性的可能性，本文提出了语义感知协作的联邦学习（FedSC），以捕获异构客户端的客户端特定和类别相关知识。FedSC的核心思想是在语义层面构建关系原型和一致原型，旨在以原型协作的方式提供丰富的类别底层知识和稳定的收敛信号。一方面，FedSC引入了一种跨对比学习策略，使实例级嵌入更接近具有相同语义的关系原型，并远离不同的类别。另一方面，FedSC通过差异聚合方式设计了一致原型，作为正则化惩罚来约束局部模型的优化区域。此外，本文提供了FedSC的理论分析以确保收敛性。在各种具有挑战性场景下的实验结果证明了FedSC的有效性和关键组件的效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [334] [HybridQ: Hybrid Classical-Quantum Generative Adversarial Network for Skin Disease Image Generation](https://arxiv.org/abs/2506.21015)
> *HybridQ：用于皮肤病图像生成的混合经典-量子生成对抗网络*

*Qingyue Jiao, Kangyu Zheng, Yiyu Shi, Zhiding Liang* | **Category: cs.CV, cs.LG, quant-ph**

**Keywords:** 生成对抗网络, 量子计算, 皮肤病图像, 数据增强, 混合模型

**Comment:** 

> **TL;DR:** HybridQ是一种混合经典-量子生成对抗网络，通过新的潜在空间融合技术生成彩色皮肤病图像，在性能上优于现有模型，且参数和训练时间更少，显示了量子图像生成的潜力。

**AI_Comments:** 本文的创新点在于首次将经典与量子计算有效融合，通过独特的潜在空间融合技术实现了彩色医学图像的生成，克服了现有量子图像生成方法的局限性。其重要性在于为医学图像数据增强提供了一种高效且资源需求更低的替代方案，尤其是在量子硬件仍在发展初期的背景下，其性能表现令人鼓舞。该研究为量子图像生成领域的发展开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 皮肤病诊断的机器学习模型需要大量高质量数据，但现有数据集存在类别不平衡、隐私和对象偏差问题。经典生成模型计算资源消耗大、训练时间长。现有量子图像生成方法只能产生低质量灰度图像。

**Method:** 本文提出了一种新颖的经典-量子潜在空间融合技术，并在此基础上构建了首个能够生成彩色医学图像的混合经典-量子生成对抗网络 (HybridQ)。

**Result:** HybridQ在图像生成质量和作为数据增强时的分类性能提升方面均优于经典的深度卷积GAN和现有混合经典-量子GAN。其性能提升与最先进的经典生成模型相当，但参数量减少了25倍以上，训练周期减少了10倍。该模型在真实IBM量子机器上也能表现出稳健的性能。

**Conclusion:** 研究结果表明，随着量子硬件的进步，量子图像生成具有广阔的前景。

> **ai_Abstract:** 本文提出了HybridQ，这是一种新颖的混合经典-量子生成对抗网络，利用经典-量子潜在空间融合技术生成彩色医学图像，以解决皮肤病数据集的数据稀缺问题。该模型在图像生成质量和分类性能提升方面超越了传统和现有混合GAN，且显著减少了参数和训练时间，展现了量子图像生成在医学领域的巨大潜力，并在真实量子硬件上验证了其鲁棒性。

> **摘要翻译:** 机器学习辅助诊断在皮肤病检测中越来越受到关注，但训练有效的模型需要大量高质量数据。皮肤病数据集常面临类别不平衡、隐私问题和对象偏差，使得数据增强变得至关重要。虽然经典生成模型被广泛使用，但它们需要大量的计算资源和漫长的训练时间。量子计算提供了一个有前景的替代方案，但现有的基于量子的图像生成方法只能产生灰度低质量图像。通过一种新颖的经典-量子潜在空间融合技术，我们的工作克服了这一限制，并引入了第一个能够生成彩色医学图像的经典-量子生成对抗网络（GAN）。我们的模型在图像生成质量和作为数据增强时的分类性能提升方面均优于经典的深度卷积GAN和现有混合经典-量子GAN。此外，性能提升与使用最先进的经典生成模型所达到的效果相当，但参数量减少了25倍以上，训练周期减少了10倍。这些结果预示着随着量子硬件的进步，量子图像生成将拥有光明的前景。最后，我们展示了我们的模型在真实IBM量子机器上带硬件噪声的稳健性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [336] [Multimodal Prompt Alignment for Facial Expression Recognition](https://arxiv.org/abs/2506.21017)
> *多模态提示对齐用于面部表情识别*

*Fuyan Ma, Yiran He, Bin Sun, Shutao Li* | **Category: cs.CV, cs.AI**

**Keywords:** 面部表情识别, 提示学习, 多模态对齐, 视觉-语言模型, 大型语言模型

**Comment:** To appear in ICCV2025

> **TL;DR:** 提出MPA-FER框架，通过多粒度硬提示生成、LLM知识注入、原型引导视觉特征对齐和跨模态全局-局部对齐，提升VLM在面部表情识别中的性能，超越SOTA方法。

**AI_Comments:** 该论文创新性地将LLM生成的细粒度语义信息融入VLM的提示学习中，并通过多重对齐机制（硬提示-软提示、视觉特征-原型、全局-局部跨模态）解决了现有VLM在FER中难以捕捉细微表情差异的问题。其方法不仅提升了性能，还保持了预训练模型的泛化能力和计算效率，为VLM在细粒度识别任务中的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于VLM的面部表情识别（FER）方法难以捕捉细粒度的文本-视觉关系，这对于区分面部表情的细微差异至关重要。

**Method:** 提出MPA-FER多模态提示对齐框架，为提示视觉特征学习提供细粒度语义指导。具体包括：1. 多粒度硬提示生成策略，利用LLM（如ChatGPT）为每个面部表情生成详细描述。2. 通过最小化软提示与硬提示之间的特征差异，将LLM外部知识注入软提示。3. 引入原型引导的视觉特征对齐，确保提示视觉特征与类别特定原型对齐，以保留预训练CLIP模型的泛化能力。4. 提出跨模态全局-局部对齐模块，关注表情相关的面部特征，进一步改善文本和视觉特征的对齐。

**Result:** 该框架在三个FER基准数据集上优于最先进的方法，同时保留了预训练模型的优势并最小化了计算成本。

**Conclusion:** MPA-FER通过多模态提示对齐，有效解决了VLM在面部表情识别中难以捕捉细粒度文本-视觉关系的问题，实现了更精确和可解释的表示，并在性能上超越了现有SOTA方法。

> **ai_Abstract:** 本文提出MPA-FER，一个用于面部表情识别的多模态提示对齐框架。它通过LLM生成细粒度硬提示来指导软提示学习，并结合原型引导的视觉特征对齐和跨模态全局-局部对齐模块，以增强VLM捕获细微表情差异的能力。实验证明，MPA-FER在多个基准数据集上超越现有SOTA方法，同时保持高效性。

> **摘要翻译:** 提示学习已被广泛采用，以有效地将CLIP等视觉-语言模型（VLMs）应用于各种下游任务。尽管取得了成功，但当前基于VLM的面部表情识别（FER）方法难以捕捉细粒度的文本-视觉关系，这对于区分面部表情的细微差异至关重要。为了解决这一挑战，我们提出了一种用于FER的多模态提示对齐框架，称为MPA-FER，它为提示视觉特征的学习过程提供了细粒度的语义指导，从而产生更精确和可解释的表示。具体来说，我们引入了一种多粒度硬提示生成策略，该策略利用大型语言模型（LLM）如ChatGPT为每个面部表情生成详细描述。通过最小化软提示与硬提示之间的特征差异，将基于LLM的外部知识注入软提示中。为了保留预训练CLIP模型的泛化能力，我们的方法结合了原型引导的视觉特征对齐，确保来自冻结图像编码器的提示视觉特征与类别特定原型紧密对齐。此外，我们提出了一种跨模态全局-局部对齐模块，该模块专注于表情相关的面部特征，进一步改善了文本和视觉特征之间的对齐。广泛的实验表明，我们的框架在三个FER基准数据集上优于最先进的方法，同时保留了预训练模型的优势并最小化了计算成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [338] [LASFNet: A Lightweight Attention-Guided Self-Modulation Feature Fusion Network for Multimodal Object Detection](https://arxiv.org/abs/2506.21018)
> *LASFNet：一种用于多模态目标检测的轻量级注意力引导自调制特征融合网络*

*Lei Hao, Lina Xu, Chang Liu, Yanni Dong* | **Category: cs.CV**

**Keywords:** 多模态目标检测, 特征融合, 轻量级网络, 注意力机制, 自调制

**Comment:** 

> **TL;DR:** LASFNet提出了一种轻量级注意力引导自调制特征融合网络，通过单一融合单元显著减少计算开销，同时提高多模态目标检测的精度。

**AI_Comments:** LASFNet的创新之处在于提出了单一特征级融合单元的基线，以及引入了ASFF模块和FATM模块，显著降低了多模态目标检测的计算复杂性，同时保持或提高了检测精度。其轻量化设计对于资源受限的应用场景具有重要意义，展现了在效率和性能之间取得良好平衡的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态目标检测中，通过特征级融合进行深度特征提取至关重要，但现有方法常涉及复杂的训练过程，通过堆叠多个特征级融合单元集成模态特定特征，导致显著的计算开销。

**Method:** 本研究提出了一种新的融合检测基线，其使用单一特征级融合单元实现高性能检测，从而简化训练过程。在此基础上，提出了轻量级注意力引导自调制特征融合网络（LASFNet），引入了新颖的注意力引导自调制特征融合（ASFF）模块，该模块根据来自不同模态的注意力信息，在全局和局部层面自适应调整融合特征的响应。此外，在LASFNet的颈部设计了一个轻量级特征注意力转换模块（FATM），以增强对融合特征的关注并最小化信息损失。

**Result:** 在三个代表性数据集上的广泛实验表明，与最先进的方法相比，LASFNet实现了有利的效率-精度权衡，参数数量和计算成本分别减少了90%和85%，同时检测精度（mAP）提高了1%-3%。

**Conclusion:** LASFNet通过其轻量级设计和创新的融合策略，显著提升了多模态目标检测的效率和精度，为该领域提供了一个高性能且计算友好的解决方案。

> **ai_Abstract:** 本论文提出LASFNet，一种轻量级注意力引导自调制特征融合网络，旨在解决多模态目标检测中现有方法计算开销大的问题。LASFNet通过一个单一的特征级融合单元，结合注意力引导自调制特征融合（ASFF）模块和轻量级特征注意力转换模块（FATM），显著简化了训练过程，并提高了特征融合的效率和质量。实验结果表明，该方法在保持甚至提升检测精度的同时，大幅减少了参数量和计算成本，实现了卓越的效率-精度平衡。

> **摘要翻译:** 通过特征级融合进行有效的深度特征提取对于多模态目标检测至关重要。然而，以往的研究通常涉及复杂的训练过程，通过堆叠多个特征级融合单元来整合模态特定特征，导致显著的计算开销。为了解决这个问题，我们提出了一种新的融合检测基线，其使用单一特征级融合单元来实现高性能检测，从而简化训练过程。在此基础上，我们提出了一种轻量级注意力引导自调制特征融合网络（LASFNet），它引入了一种新颖的注意力引导自调制特征融合（ASFF）模块，该模块根据来自不同模态的注意力信息，在全局和局部层面自适应调整融合特征的响应，从而促进全面和丰富的特征生成。此外，在LASFNet的颈部设计了一个轻量级特征注意力转换模块（FATM），以增强对融合特征的关注并最小化信息损失。在三个代表性数据集上的广泛实验表明，与最先进的方法相比，我们的方法实现了有利的效率-精度权衡，参数数量和计算成本分别减少了90%和85%，同时检测精度（mAP）提高了1%-3%。代码将开源于https://github.com/leileilei2000/LASFNet。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [340] [Instella-T2I: Pushing the Limits of 1D Discrete Latent Space Image Generation](https://arxiv.org/abs/2506.21022)
> *Instella-T2I：突破一维离散潜在空间图像生成的极限*

*Ze Wang, Hao Chen, Benran Hu, Jiang Liu, Ximeng Sun, Jialian Wu, Yusheng Su, Xiaodong Yu, Emad Barsoum, Zicheng Liu* | **Category: cs.CV**

**Keywords:** 图像生成, 离散潜在空间, 一维二值表示, Token化, 文本到图像

**Comment:** 

> **TL;DR:** Instella-T2I引入一维二值图像潜在表示，显著减少了文本到图像生成所需的离散token数量（低至128个），同时保持高分辨率细节和竞争力，大幅提升了训练和推理效率。

**AI_Comments:** Instella-T2I的创新点在于引入了一维二值图像潜在空间，这是一种非常激进且有效的token化方法。它成功地将高分辨率图像的表示压缩到极低的128个离散token，这在计算效率上是一个巨大的飞跃，尤其是在训练和推理速度方面。其无需私有数据和后期优化即可达到竞争性性能的特点，表明了其方法的鲁棒性和普适性。这对于推动大规模图像生成模型的发展具有重要意义，降低了资源需求，使其更易于部署和研究。

<details>
  <summary>Details</summary>

**Motivation:** 图像token化对于降低高分辨率图像建模的计算需求至关重要，能显著提高图像和多模态理解及生成的效率。近期一维潜在空间通过消除二维网格结构减少了所需token数量，但仍有提升空间，尤其是在保持高分辨率细节和进一步压缩token数量方面。

**Method:** 本论文通过引入一维二值图像潜在表示，进一步推进了紧凑离散图像表示。该方法将每张图像表示为一系列二值向量，而非传统的独热码本token。这种方法在保持一维潜在空间紧凑性的同时，保留了高分辨率细节。

**Result:** Instella-T2I的文本到图像模型是首个在使用128个离散token（适用于高达1024x1024的图像）的情况下，在扩散和自回归生成方面均达到竞争性性能的模型。与标准VQ-VAE相比，token数量减少了高达32倍。所提出的一维二值潜在空间与简单的模型架构相结合，显著提高了训练和推理速度。模型允许在单个GPU节点（配备8个AMD MI300X GPU）上实现4096的全局批处理大小，训练可在200个GPU日内完成。模型在没有内部私有训练数据或后期训练优化的情况下，实现了与现代图像生成模型相当的性能。

**Conclusion:** Instella-T2I提供了一种可扩展且高效的替代传统token化方法，通过引入一维二值图像潜在表示，极大地减少了文本到图像生成所需的token数量，同时保持了高分辨率细节和竞争性性能，并在训练和推理速度上取得了显著提升。

> **ai_Abstract:** Instella-T2I提出了一种新颖的一维二值图像潜在表示方法，旨在大幅减少文本到图像生成所需的离散token数量，同时保持高分辨率细节。该方法将图像编码为二值向量序列，而非传统的独热码本token。实验表明，Instella-T2I模型仅用128个token即可在1024x1024图像上实现与现有扩散和自回归模型相当的性能，相较于标准VQ-VAE，token数量减少了32倍。此外，该模型显著提升了训练和推理速度，并在不依赖私有数据或后期优化的前提下展现出强大竞争力，提供了一种高效且可扩展的图像token化替代方案。

> **摘要翻译:** 图像token化在降低高分辨率图像建模的计算需求方面起着关键作用，显著提高了图像和多模态理解与生成的效率。一维潜在空间的最新进展通过消除对二维网格结构的需求，减少了所需的token数量。在本文中，我们通过引入一维二值图像潜在表示，进一步推动了紧凑离散图像表示。通过将每张图像表示为一系列二值向量，而不是使用传统的独热码本token，我们的方法在保持一维潜在空间紧凑性的同时保留了高分辨率细节。据我们所知，我们的文本到图像模型是第一个仅使用128个离散token（适用于高达1024x1024的图像）就能在扩散和自回归生成方面实现竞争性性能的模型，与标准VQ-VAE相比，token数量减少了高达32倍。所提出的一维二值潜在空间，结合简单的模型架构，显著提高了训练和推理速度。我们的文本到图像模型允许在单个配备8个AMD MI300X GPU的GPU节点上实现4096的全局批处理大小，并且训练可以在200个GPU日内完成。我们的模型在没有任何内部私有训练数据或后期训练优化的情况下，实现了与现代图像生成模型相当的性能，为传统token化方法提供了一种可扩展且高效的替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [DidSee: Diffusion-Based Depth Completion for Material-Agnostic Robotic Perception and Manipulation](https://arxiv.org/abs/2506.21034)
> *DidSee：基于扩散的深度补全用于材料无关的机器人感知与操作*

*Wenzhou Lyu, Jialing Lin, Wenqi Ren, Ruihao Xia, Feng Qian, Yang Tang* | **Category: cs.CV**

**Keywords:** 深度补全, 扩散模型, 非朗伯体, 机器人感知, 语义分割

**Comment:** 

> **TL;DR:** DidSee是一个基于扩散的深度补全框架，专门用于解决非朗伯体物体的深度图噪声和不完整问题。它通过引入重新缩放的噪声调度器、单步训练和语义增强器来解决现有扩散模型的偏差和泛化问题，实现了最先进的性能，并提升了机器人感知和操作能力。

**AI_Comments:** DidSee创新性地应用并改进了扩散模型进行深度补全，特别解决了现实世界机器人应用中常见的非朗伯表面这一挑战性问题。其在解决扩散模型偏差（信号泄漏、曝光偏差）和整合语义信息方面的贡献具有重要意义。在下游机器人任务中表现出的改进突显了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 商用RGB-D相机为非朗伯体物体生成的深度图通常噪声大且不完整。传统深度补全方法因训练数据多样性和规模有限而难以泛化。虽然预训练扩散模型能增强泛化能力，但其训练-推理不匹配导致的偏差（如信号泄漏和曝光偏差）以及非朗伯区域缺乏独特视觉特征，显著损害了深度补全性能。

**Method:** DidSee是一个基于扩散的非朗伯体物体深度补全框架。它主要包含：1. 集成一个重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差。2. 设计一个与噪声无关的单步训练公式，以减轻由曝光偏差引起的误差累积，并使用任务特定损失进行优化。3. 结合一个语义增强器，实现联合深度补全和语义分割，以区分物体和背景，生成精确、细粒度的深度图。

**Result:** DidSee在多个基准测试中取得了最先进的性能，展示了强大的真实世界泛化能力，并有效改进了下游任务，例如类别级姿态估计和机器人抓取。

**Conclusion:** DidSee通过改进扩散模型，有效解决了非朗伯体物体深度补全的挑战，实现了最先进的性能，并显著提升了机器人感知和操作等下游任务的效率和准确性。

> **ai_Abstract:** 本论文提出DidSee，一个新颖的基于扩散的框架，旨在为非朗伯体物体提供鲁棒的深度补全。为了解决现有RGB-D相机深度图噪声大、传统方法泛化能力差以及香草扩散模型中训练-推理不匹配导致的偏差等问题，DidSee集成了重新缩放的噪声调度器、与噪声无关的单步训练公式和语义增强器。这种方法有效缓解了信号泄漏和曝光偏差，并实现了联合深度补全和语义分割。DidSee在多个基准测试中达到了最先进的性能，展现了强大的真实世界泛化能力，并显著提升了如姿态估计和抓取等下游机器人感知和操作任务。

> **摘要翻译:** 商用RGB-D相机通常会为非朗伯体物体生成噪声大、不完整的深度图。传统深度补全方法由于训练数据的多样性和规模有限，难以泛化。最近的进展利用预训练文本到图像扩散模型中的视觉先验来增强密集预测任务的泛化能力。然而，我们发现香草扩散框架中由训练-推理不匹配引起的偏差显著损害了深度补全性能。此外，非朗伯区域缺乏独特的视觉特征进一步阻碍了精确预测。为了解决这些问题，我们提出了\textbf{DidSee}，一个基于扩散的非朗伯体物体深度补全框架。首先，我们整合了一个重新缩放的噪声调度器，强制零终端信噪比以消除信号泄漏偏差。其次，我们设计了一个与噪声无关的单步训练公式，以减轻由曝光偏差引起的误差累积，并使用任务特定损失优化模型。最后，我们结合了一个语义增强器，实现联合深度补全和语义分割，区分物体和背景，并产生精确、细粒度的深度图。DidSee在多个基准测试中取得了最先进的性能，展示了强大的真实世界泛化能力，并有效改进了下游任务，例如类别级姿态估计和机器人抓取。项目页面：https://wenzhoulyu.github.io/DidSee/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [344] [Boosting Domain Generalized and Adaptive Detection with Diffusion Models: Fitness, Generalization, and Transferability](https://arxiv.org/abs/2506.21042)
> *利用扩散模型提升域泛化和自适应检测：适应性、泛化性和可迁移性*

*Boyong He, Yuxiang Ji, Zhuoyue Tan, Liaoni Wu* | **Category: cs.CV**

**Keywords:** 扩散模型, 域泛化, 域适应, 目标检测, 特征学习

**Comment:** Accepted by ICCV2025. arXiv admin note: text overlap with
  arXiv:2503.02101

> **TL;DR:** 本文提出了一种利用扩散模型的新方法，通过从单步扩散中提取中间特征、构建以对象为中心的辅助分支以及引导标准检测器，以提高域泛化和自适应检测的性能，同时显著降低推理成本。

**AI_Comments:** 本文创新性地将扩散模型应用于域泛化和自适应检测，并有效解决了现有方法推理成本高的问题。通过引入“适应性”、“泛化性”和“可迁移性”三个核心概念，并设计相应的技术模块（单步扩散特征提取、对象中心辅助分支、特征/对象级对齐），实现了性能的全面提升。特别是在效率方面的提升（推理时间减少75%）和在大域偏移、低数据场景下的表现，使其具有重要的实际应用价值。该研究为扩散模型在视觉感知任务中的应用提供了新的视角和宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检测器在训练和测试数据之间存在域差距时性能会下降。最近将扩散模型应用于域泛化（DG）和域适应（DA）任务的方法，仍然存在推理成本高的问题，并且未能充分利用扩散模型的潜力。

**Method:** 本文通过以下方法解决问题：1) 从单步扩散过程中提取中间特征，改进特征收集和融合，从而将推理时间减少75%，并提高源域性能（适应性）。2) 通过对带有类别提示的框掩蔽图像应用以对象为中心的辅助分支，提取鲁棒和域不变的特征。同时应用一致性损失来对齐辅助分支和普通分支，平衡适应性和泛化性，防止过拟合，并提高目标域性能（泛化性）。3) 在统一框架内，通过在源域（针对DG）和未标记目标域（针对DA）上的特征级和对象级对齐，由扩散检测器引导标准检测器，从而提高跨域检测性能（可迁移性）。

**Result:** 本文方法在3个DA基准和5个DG基准上取得了有竞争力的结果。此外，在COCO泛化基准上的实验表明，该方法在大域偏移和低数据场景下保持显著优势，并显示出卓越的效率。

**Conclusion:** 本文工作展示了将扩散模型应用于域泛化和自适应检测任务的优越性，并为跨不同领域的视觉感知任务提供了宝贵的见解。

> **ai_Abstract:** 本文提出了一种利用扩散模型的新颖方法，旨在解决域泛化（DG）和域适应（DA）任务中检测器的性能下降问题以及扩散模型推理成本高、能力未充分利用的挑战。该方法通过从单步扩散中提取中间特征以提高源域性能并大幅降低推理时间（适应性），构建以对象为中心的辅助分支和应用一致性损失来增强目标域的泛化能力（泛化性），并通过特征级和对象级对齐引导标准检测器以提升跨域检测性能（可迁移性）。实验证明，该方法在多个DG和DA基准上表现出色，尤其在大域偏移和低数据场景下展现出显著优势和高效率。

> **摘要翻译:** 检测器常常由于训练和测试数据之间的域差距而导致性能下降。最近的方法探索将扩散模型应用于域泛化（DG）和域适应（DA）任务，但仍然面临高昂的推理成本，并且尚未充分利用扩散模型的能力。我们提出通过从单步扩散过程中提取中间特征来解决这些问题，改进特征收集和融合，从而将推理时间减少75%，同时提高源域性能（即适应性）。然后，我们通过对带有类别提示的框掩蔽图像应用以对象为中心的辅助分支来提取鲁棒和域不变的聚焦于对象的特征。我们还应用一致性损失来对齐辅助分支和普通分支，平衡适应性和泛化性，同时防止过拟合并提高目标域性能（即泛化性）。此外，在一个统一的框架内，通过在源域（针对DG）和未标记目标域（针对DA）上的特征级和对象级对齐，标准检测器受到扩散检测器的引导，从而提高跨域检测性能（即可迁移性）。我们的方法在3个DA基准和5个DG基准上取得了有竞争力的结果。此外，在COCO泛化基准上的实验表明，我们的方法保持显著优势，并在大域偏移和低数据场景中显示出卓越的效率。我们的工作展示了将扩散模型应用于域泛化和自适应检测任务的优越性，并为跨不同领域的视觉感知任务提供了宝贵的见解。代码可在https://github.com/heboyong/Fitness-Generalization-Transferability 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [346] [Improving Diffusion-Based Image Editing Faithfulness via Guidance and Scheduling](https://arxiv.org/abs/2506.21045)
> *通过引导和调度提高基于扩散的图像编辑保真度*

*Hansam Cho, Seoung Bum Kim* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 扩散模型, 图像编辑, 保真度, 引导, 调度

**Comment:** preprint

> **TL;DR:** 本文提出FGS，一种新的方法，通过引入保真度引导和调度策略，在保持可编辑性的同时显著提高基于扩散的图像编辑的保真度。

**AI_Comments:** 该论文通过引入保真度引导和调度策略，巧妙地解决了扩散模型图像编辑中长期存在的保真度与可编辑性之间的矛盾，为提高图像编辑质量提供了一个有效且通用的解决方案。其创新性在于提出了一种平衡机制，而不是简单地牺牲其中一个方面。

<details>
  <summary>Details</summary>

**Motivation:** 在基于扩散的图像编辑中，可编辑性（修改程度）和保真度（未改变元素的保留程度）之间存在固有的权衡，导致难以获得最佳结果。本文旨在解决这一问题，在最小化对可编辑性影响的同时增强保真度。

**Method:** 本文提出了保真度引导和调度（FGS）方法。FGS结合了保真度引导来加强输入图像信息的保存，并引入了调度策略来解决可编辑性和保真度之间的错位问题。

**Result:** 实验结果表明，FGS在保持可编辑性的同时，实现了卓越的保真度。此外，FGS与各种编辑方法兼容，能够在不同任务中实现精确、高质量的图像编辑。

**Conclusion:** FGS通过引入保真度引导和调度策略，有效解决了扩散模型图像编辑中保真度和可编辑性之间的权衡问题，显著提高了图像编辑的质量和精确性，并具有广泛的兼容性。

> **ai_Abstract:** 本文提出了一种名为FGS（Faithfulness Guidance and Scheduling）的新方法，旨在解决基于扩散的图像编辑中可编辑性和保真度之间的权衡问题。FGS通过引入保真度引导来增强原始图像信息的保留，并采用调度策略来协调可编辑性和保真度。实验证明，FGS在保持良好可编辑性的同时，显著提高了图像编辑的保真度，并且能够兼容多种编辑方法，实现高质量的图像编辑。

> **摘要翻译:** 文本引导的扩散模型已成为高质量图像合成的关键，实现了动态图像编辑。在图像编辑中，两个关键方面是可编辑性（决定修改程度）和保真度（反映未改变元素的保留程度）。然而，由于可编辑性和保真度之间固有的权衡，实现最佳结果具有挑战性。为了解决这个问题，我们提出了保真度引导和调度（FGS），它在最小化对可编辑性影响的同时增强了保真度。FGS结合了保真度引导以加强输入图像信息的保存，并引入了调度策略以解决可编辑性和保真度之间的错位。实验结果表明，FGS在保持可编辑性的同时实现了卓越的保真度。此外，它与各种编辑方法的兼容性使其能够在不同任务中实现精确、高质量的图像编辑。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [349] [Class-Agnostic Region-of-Interest Matching in Document Images](https://arxiv.org/abs/2506.21055)
> *文档图像中类别无关的感兴趣区域匹配*

*Demin Zhang, Jiahao Lyu, Zhijie Shen, Yu Zhou* | **Category: cs.CV**

**Keywords:** 文档理解, 感兴趣区域匹配, 类别无关, 孪生网络, 文档分析

**Comment:** Accepted by ICDAR2025

> **TL;DR:** 现有文档分析解决方案缺乏灵活性。本文提出了一项名为“类别无关感兴趣区域匹配”（RoI-Matching）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配自定义区域。为此，构建了基准测试RoI-Matching-Bench，并提出了基于孪生网络和交叉注意力的RoI-Matcher框架。实验证明该方法有效，可作为后续研究的基线。

**AI_Comments:** 本文通过定义一个全新的“类别无关感兴趣区域匹配”任务，有效解决了现有文档分析在灵活性和用户定制方面的局限性。其创新之处在于提出了开放集、多粒度的匹配范式，并为此任务构建了专门的基准测试和评估指标，这对于该领域后续研究具有重要的奠基意义。RoI-Matcher框架结合孪生网络和交叉注意力，提供了一个简洁而有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有文档分析解决方案（如文档版面分析和关键信息提取）仅适用于固定的类别定义和粒度，无法实现用户定制的灵活应用。

**Method:** 本文定义了一项新任务，即“类别无关感兴趣区域匹配”（RoI-Matching），旨在以灵活、高效、多粒度和开放集的方式匹配自定义区域。模型输入为参考文档和目标文档图像的视觉提示，输出为目标文档图像中对应的边界框。为满足需求，构建了包含三个难度级别的基准测试RoI-Matching-Bench，并提出了宏观和微观评估指标。此外，还提出了一个新的框架RoI-Matcher，该框架采用孪生网络来提取参考域和目标域中的多级特征，并利用交叉注意力层来整合和对齐不同域中的相似语义。

**Result:** 实验表明，本文提出的方法RoI-Matcher在RoI-Matching-Bench上效果显著，且过程简单。

**Conclusion:** 本文提出的方法可以作为RoI-Matching任务的基线，供进一步研究。

> **ai_Abstract:** 为解决现有文档分析方案缺乏用户定制灵活性问题，本文提出了“类别无关感兴趣区域匹配”（RoI-Matching）的新任务，旨在实现灵活、高效、多粒度和开放集的定制区域匹配。为此，论文构建了RoI-Matching-Bench基准测试，并提出了基于孪生网络和交叉注意力的RoI-Matcher框架。实验证明RoI-Matcher简单且有效，可作为该任务的基线。

> **摘要翻译:** 文档理解和分析因其广泛应用而受到广泛关注。然而，现有的文档分析解决方案，如文档版面分析和关键信息提取，仅适用于固定的类别定义和粒度，无法实现用户定制的灵活应用。因此，本文定义了一项名为“类别无关感兴趣区域匹配”（简称“RoI-Matching”）的新任务，旨在以灵活、高效、多粒度和开放集的方式匹配自定义区域。参考文档和目标文档图像的视觉提示被输入到我们的模型中，输出是目标文档图像中相应的边界框。为了满足上述要求，我们构建了一个基准测试RoI-Matching-Bench，该基准测试根据实际情况设置了三个难度级别，并提出了宏观和微观指标进行评估。此外，我们还提出了一个新的框架RoI-Matcher，该框架采用孪生网络来提取参考域和目标域中的多级特征，并利用交叉注意力层来整合和对齐不同域中的相似语义。实验表明，我们的方法过程简单，在RoI-Matching-Bench上是有效的，并可作为进一步研究的基线。代码可在https://github.com/pd162/RoI-Matching 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [351] [SAMURAI: Shape-Aware Multimodal Retrieval for 3D Object Identification](https://arxiv.org/abs/2506.21056)
> *SAMURAI：用于3D物体识别的形状感知多模态检索*

*Dinh-Khoi Vo, Van-Loc Nguyen, Minh-Triet Tran, Trung-Nghia Le* | **Category: cs.CV**

**Keywords:** 3D物体检索, 多模态检索, 形状感知, CLIP, ROOMELSA

**Comment:** 

> **TL;DR:** SAMURAI通过结合CLIP语义匹配和形状引导重排序，解决了在复杂室内环境中仅使用2D图像和自然语言描述检索3D物体的挑战。

**AI_Comments:** 该论文的创新点在于其混合检索框架，巧妙地结合了基于CLIP的语言语义理解和形状引导的几何信息，以克服2D图像和语言描述在3D物体检索中的局限性。特别是，利用二值轮廓进行形状引导重排序和多数投票策略，以及专门的掩模预处理，都增强了系统的鲁棒性。这种多模态融合的方法对于开放世界3D物体检索具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂室内环境中，仅使用遮罩的2D图像和自然语言描述检索3D物体存在显著挑战，尤其是在ROOMELSA挑战中，由于缺乏完整的3D场景上下文、扭曲的视角、无纹理的遮罩区域、模糊的语言提示和嘈杂的分割掩模，使得推理物体外观、几何和语义变得复杂。

**Method:** 本文提出了SAMURAI（Shape-Aware Multimodal Retrieval for 3D Object Identification），它将基于CLIP的语义匹配与从遮罩区域的二值轮廓导出的形状引导重排序相结合，并辅以鲁棒的多数投票策略。此外，一个专门的预处理管道通过提取最大连通分量和去除背景噪声来提高掩模质量。该混合检索框架利用语言和形状线索。

**Result:** SAMURAI在ROOMELSA私人测试集上取得了有竞争力的性能。

**Conclusion:** 这些结果强调了将形状先验与语言理解相结合对于鲁士开放世界3D物体检索的重要性。

> **ai_Abstract:** 本文提出了SAMURAI，一个用于3D物体识别的形状感知多模态检索框架。该框架旨在解决在复杂室内环境中仅使用2D遮罩图像和自然语言描述进行3D物体检索的难题。SAMURAI结合了CLIP的语义匹配和基于二值轮廓的形状引导重排序，并辅以多数投票策略。它还包括一个预处理管道来优化掩模质量。该方法通过融合语言和形状线索，在ROOMELSA挑战中表现出色，证明了形状先验与语言理解结合对于鲁棒3D物体检索的关键作用。

> **摘要翻译:** 仅使用遮罩的2D图像和自然语言描述在复杂室内环境中检索3D物体带来了显著挑战。ROOMELSA挑战限制了对完整3D场景上下文的访问，使推理物体外观、几何和语义变得复杂。这些挑战因扭曲的视角、无纹理的遮罩区域、模糊的语言提示和嘈杂的分割掩模而加剧。为了解决这个问题，我们提出了SAMURAI：用于3D物体识别的形状感知多模态检索。SAMURAI将基于CLIP的语义匹配与从遮罩区域的二值轮廓导出的形状引导重排序以及鲁棒的多数投票策略相结合。一个专门的预处理管道通过提取最大连通分量和去除背景噪声来提高掩模质量。我们的混合检索框架利用语言和形状线索，在ROOMELSA私人测试集上取得了有竞争力的性能。这些结果突出了将形状先验与语言理解相结合对于鲁士开放世界3D物体检索的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [354] [PoseMaster: Generating 3D Characters in Arbitrary Poses from a Single Image](https://arxiv.org/abs/2506.21076)
> *PoseMaster：从单张图像生成任意姿态的3D角色*

*Hongyu Yan, Kunming Luo, Weiyu Li, Yixun Liang, Shengming Li, Jingwei Huang, Chunchao Guo, Ping Tan* | **Category: cs.CV**

**Keywords:** 3D角色生成, 姿态控制, 单图像, 端到端, 骨骼条件

**Comment:** 

> **TL;DR:** PoseMaster是一个端到端可控的3D角色生成框架，能从单张图像生成任意姿态的3D角色，解决了现有方法中姿态标准化导致的图像失真和几何质量问题。

**AI_Comments:** PoseMaster的创新之处在于其端到端的框架设计，将姿态变换和3D生成无缝整合，有效解决了传统分阶段方法的弊端。利用3D骨骼作为姿态条件实现了高精度的任意姿态控制，而随机清空条件的训练策略则显著增强了模型的泛化能力。高质量数据集的构建也为此类研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高3D角色建模效率，现有基于图像的方法使用两个独立模型进行姿态标准化和3D重建，但在姿态标准化阶段易产生扭曲和退化的图像，影响后续重建的几何质量。

**Method:** 我们提出了PoseMaster，一个端到端可控的3D角色生成框架。它将姿态变换和3D角色生成统一到基于流的3D原生生成框架中。为实现精确的任意姿态控制，我们利用可动画角色骨架中的3D身体骨骼作为姿态条件。此外，在训练过程中随机清空姿态条件和图像条件，以提高姿态控制的有效性和泛化性。最后，我们创建了一个高质量的姿态控制数据集，源自真实的字符动画数据，使模型学习骨骼和蒙皮权重之间的隐含关系。

**Result:** 大量的实验表明，PoseMaster在A姿态角色生成方面，无论在定性还是定量评估中，都优于当前的最新技术，同时展示了其对任意姿态实现精确控制的强大能力。

**Conclusion:** PoseMaster成功地解决了现有方法在3D角色生成中遇到的挑战，通过其端到端框架和精确的姿态控制能力，显著提升了从单张图像生成高质量任意姿态3D角色的效果。

> **ai_Abstract:** PoseMaster是一个端到端可控的3D角色生成框架，旨在从单张图像生成任意姿态的3D角色。它通过将姿态变换和3D角色生成统一到基于流的3D原生框架中，解决了现有方法在姿态标准化阶段的图像失真和几何质量问题。该方法利用3D身体骨骼作为姿态条件实现精确控制，并通过随机清空条件来提高泛化性，同时构建了高质量的姿态控制数据集。实验证明，PoseMaster在生成A姿态角色和实现任意姿态精确控制方面均优于现有技术。

> **摘要翻译:** 3D角色在我们的日常娱乐中扮演着至关重要的角色。为了提高3D角色建模的效率，最近基于图像的方法使用两个独立的模型来实现A姿态角色的姿态标准化和3D重建。然而，这些方法在姿态标准化阶段由于自遮挡和视角问题，容易生成扭曲和退化的图像，这进一步影响了后续重建过程的几何质量。为了解决这些问题，我们提出了PoseMaster，一个端到端可控的3D角色生成框架。具体而言，我们将姿态变换和3D角色生成统一到一个基于流的3D原生生成框架中。为了实现精确的任意姿态控制，我们建议利用可动画角色骨架中存在的3D身体骨骼作为姿态条件。此外，考虑到多条件控制的特殊性，我们在训练过程中随机清空姿态条件和图像条件，以提高姿态控制的有效性和泛化性。最后，我们创建了一个高质量的姿态控制数据集，源自真实的字符动画数据，使模型学习骨骼和蒙皮权重之间的隐含关系。大量的实验表明，PoseMaster在A姿态角色生成方面，无论在定性还是定量评估中，都优于当前的最新技术，同时展示了其对任意姿态实现精确控制的强大能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [357] [EgoAdapt: Adaptive Multisensory Distillation and Policy Learning for Efficient Egocentric Perception](https://arxiv.org/abs/2506.21080)
> *EgoAdapt：面向高效以自我为中心的感知的自适应多感官蒸馏与策略学习*

*Sanjoy Chowdhury, Subrata Biswas, Sayan Nag, Tushar Nagarajan, Calvin Murdock, Ishwarya Ananthabhotla, Yijun Qian, Vamsi Krishna Ithapu, Dinesh Manocha, Ruohan Gao* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 以自我为中心感知, 多感官, 蒸馏, 策略学习, 效率

**Comment:** Accepted at ICCV 2025

> **TL;DR:** EgoAdapt是一个框架，通过自适应跨模态蒸馏和策略学习，显著提高了以自我为中心感知任务（如动作识别、说话者定位、行为预测）的效率，同时保持或超越了最先进模型的性能。

**AI_Comments:** 该论文提出的EgoAdapt框架在解决以自我为中心感知模型的计算效率问题上具有重要意义。其创新点在于结合了自适应跨模态蒸馏和策略学习，使得模型在保持高性能的同时，大幅降低了GMACs、参数和能耗，这对于资源受限的实际部署场景（如可穿戴设备）至关重要。该方法的普适性（适用于不同任务）也增强了其价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代多感官以自我为中心的感知模型性能卓越，但计算成本高昂，难以在资源受限环境中部署。

**Method:** 本文提出了EgoAdapt框架，通过自适应地执行跨模态蒸馏和策略学习，实现不同以自我为中心感知任务的高效推理。其策略模块可适应特定任务的动作空间，具有广泛适用性。

**Result:** 在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个数据集上，EgoAdapt显著提高了效率，GMACs降低高达89.09%，参数减少高达82.02%，能耗降低高达9.6倍，同时性能与最先进模型持平或超越。

**Conclusion:** EgoAdapt通过自适应多感官蒸馏和策略学习，有效地解决了以自我为中心感知模型计算成本高的问题，实现了高效且高性能的推理，使其更适用于实际部署。

> **ai_Abstract:** EgoAdapt是一个为解决现代以自我为中心感知模型高计算成本问题而设计的框架。它通过自适应跨模态蒸馏和策略学习，显著提升了以自我为中心动作识别、主动说话者定位和行为预测等任务的推理效率，同时保持或超越了现有最先进模型的性能。实验证明，EgoAdapt在计算资源和能耗方面均有大幅优化，使其更适合资源受限环境下的实际部署。

> **摘要翻译:** 现代感知模型，特别是那些为多感官以自我为中心任务设计的模型，已经取得了显著的性能，但通常伴随着巨大的计算成本。这些高要求对实际部署构成了挑战，尤其是在资源受限的环境中。在本文中，我们引入了EgoAdapt，一个自适应执行跨模态蒸馏和策略学习的框架，旨在为不同的以自我为中心感知任务（包括以自我为中心的动作识别、主动说话者定位和行为预测）实现高效推理。我们提出的策略模块可适应特定任务的动作空间，使其具有广泛适用性。在EPIC-Kitchens、EasyCom和Aria Everyday Activities三个具有挑战性的以自我为中心数据集上的实验结果表明，我们的方法显著提高了效率，将GMACs降低高达89.09%，参数减少高达82.02%，能耗降低高达9.6倍，同时性能与相应的最先进模型持平，并且在许多情况下表现更优。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [358] [HumanOmniV2: From Understanding to Omni-Modal Reasoning with Context](https://arxiv.org/abs/2506.21277)
> *HumanOmniV2：从理解到结合上下文的全模态推理*

*Qize Yang, Shimin Yao, Weixuan Chen, Shenghao Fu, Detao Bai, Jiaxing Zhao, Boyuan Sun, Bowen Yin, Xihan Wei, Jingren Zhou* | **Category: cs.CV, cs.CL**

**Keywords:** 全模态推理, 上下文理解, 强化学习, 大语言模型, IntentBench

**Comment:** 

> **TL;DR:** 本文提出了HumanOmniV2，一种通过引入上下文奖励和逻辑奖励来解决多模态大语言模型中上下文理解不足和捷径问题的方法，并引入了一个新的基准IntentBench，以提高全模态推理能力。

**AI_Comments:** 本文创新性地将强化学习中的奖励机制应用于多模态大语言模型，特别是引入了由LLM判断的上下文奖励和逻辑奖励，以解决多模态推理中的核心问题。提出的IntentBench基准也对评估复杂人类意图理解具有重要意义。该工作对于提升多模态LLM的鲁棒性和准确性具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着多模态大语言模型的快速发展，深入理解和解释人类意图的能力变得至关重要，这需要详细和周密的推理。尽管强化学习在增强大语言模型的推理能力方面展现了潜力，但将其适应多模态数据和格式的挑战仍未得到充分解决。现有模型存在两个问题：全局上下文理解不足和捷径问题。

**Method:** 为了解决上下文理解不足和捷径问题，本文强调模型需要对多模态输入中的全局上下文有清晰的理解。通过大语言模型判断的上下文奖励、格式奖励和准确性奖励来确保多模态上下文信息的准确解释。此外，利用大语言模型评估逻辑奖励，以提高复杂的推理能力。论文还引入了一个名为IntentBench的推理全模态基准，旨在评估模型理解复杂人类意图和情感的能力。

**Result:** 本文提出的方法在多个全模态基准测试中，相比其他开源全模态模型，展现出更先进的性能。

**Conclusion:** 本文通过引入上下文奖励和逻辑奖励，并提出新的评估基准IntentBench，有效解决了多模态推理中的上下文理解不足和捷径问题，显著提升了全模态模型的推理能力。

> **ai_Abstract:** 本文提出了HumanOmniV2，旨在解决多模态大语言模型在理解人类意图时存在的全局上下文理解不足和捷径问题。研究强调了全局上下文理解的重要性，并引入了由大语言模型判断的上下文奖励、格式奖励、准确性奖励以及逻辑奖励来增强模型的推理能力。此外，论文还提出了一个名为IntentBench的新型全模态推理基准。实验结果表明，HumanOmniV2在多个全模态基准测试中表现优于其他开源模型。

> **摘要翻译:** 随着多模态大语言模型的快速发展，深入理解和解释人类意图的能力已成为一项关键能力，这需要详细而周密的推理。在最近的研究中，强化学习（RL）已展示出增强大语言模型（LLMs）推理能力的潜力。然而，将RL适应多模态数据和格式的相关挑战在很大程度上仍未解决。在本文中，我们识别了现有多模态推理模型中的两个问题：全局上下文理解不足和捷径问题。当模型误解多模态上下文时，可能发生上下文理解不足，导致不正确的答案。捷径问题发生时，模型会忽略多模态输入中的关键线索，直接回答查询而不考虑多模态信息。为了解决这些问题，我们强调模型必须在清晰理解多模态输入中全局上下文的情况下进行推理。这种全局上下文理解可以有效防止模型忽略关键多模态线索，并确保彻底的推理过程。为了确保多模态上下文信息的准确解释，我们实现了由大语言模型判断的上下文奖励，以及格式和准确性奖励。此外，为了提高复杂推理能力，我们采用LLM来评估逻辑奖励，判断推理过程是否成功地将多模态信息与逻辑方法相结合。我们还引入了一个推理全模态基准IntentBench，旨在评估模型理解复杂人类意图和情感的能力。我们提出的方法在多个全模态基准测试中，相比其他开源全模态模型，展现出更先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [360] [ESMStereo: Enhanced ShuffleMixer Disparity Upsampling for Real-Time and Accurate Stereo Matching](https://arxiv.org/abs/2506.21091)
> *ESMStereo：用于实时和精确立体匹配的增强型ShuffleMixer视差上采样*

*Mahmoud Tahmasebi, Saif Huq, Kevin Meehan, Marion McAfee* | **Category: cs.CV**

**Keywords:** 立体匹配, 视差上采样, 实时性能, ShuffleMixer, 深度学习

**Comment:** Under peer review

> **TL;DR:** ESMStereo提出增强型Shuffle Mixer (ESM) 解决实时立体匹配中小型代价体信息损失问题，通过特征融合和精炼实现高精度和实时性能，在高端GPU上达116 FPS。

**AI_Comments:** ESMStereo的创新点在于其提出的ESM模块，巧妙地解决了小型代价体在实时立体匹配中精度不足的问题。通过有效的特征融合和精炼策略，该模型在保持计算效率的同时，显著提升了视差估计的细节恢复能力。其在嵌入式设备上的出色表现（如AGX Orin上的91 FPS）也凸显了其在实际应用中的巨大潜力，对于自主系统等对实时性要求高的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代自主系统中，开发同时具备高精度和实时性能的深度学习立体匹配模型是一个重大挑战。大型代价体虽然精确但计算成本高难以实时；小型代价体虽然实时但精度不足。

**Method:** 论文提出了增强型Shuffle Mixer (ESM) 来弥补小型代价体的信息损失。ESM通过将主要特征整合到视差上采样单元中来恢复关键细节。它快速从初始视差估计中提取特征并与图像特征融合，通过混洗和层分割混合这些特征，然后通过一个紧凑的特征引导沙漏网络进行精炼，以恢复更详细的场景几何。ESM关注局部上下文连接性，具有大感受野和低计算成本。

**Result:** ESMStereo实现了高精度视差图的实时重建。紧凑版ESMStereo在高端GPU上达到116 FPS的推理速度，在AGX Orin上达到91 FPS。

**Conclusion:** ESMStereo成功解决了立体匹配中实现实时性能和高精度并存的挑战，通过其创新的ESM模块有效缓解了小型代价体的信息损失问题。

> **ai_Abstract:** 本文提出了ESMStereo，一种用于实时高精度立体匹配的模型，旨在解决现有方法在实时性和精度之间的权衡问题。通过引入增强型Shuffle Mixer (ESM) 模块，ESMStereo能够有效弥补小型代价体带来的信息损失，通过特征融合、混洗和精炼恢复关键细节。该方法在保证高精度的同时，实现了显著的实时性能，其紧凑版在高端GPU上可达116 FPS。

> **摘要翻译:** 立体匹配已成为现代自主系统日益重要的组成部分。开发能够提供高精度同时实时运行的基于深度学习的立体匹配模型仍然是计算机视觉领域的一大挑战。在基于代价体的立体匹配领域，精确的视差估计严重依赖于大规模代价体。然而，这些大规模代价体存储了大量的冗余信息，并且需要计算密集型的聚合单元进行处理和回归，使得实时性能无法实现。相反，小型代价体随后跟随着轻量级聚合单元为实时性能提供了一条有前景的途径，但缺乏足够的信息来确保高精度的视差估计。为了解决这一挑战，我们提出了增强型Shuffle Mixer (ESM) 来缓解与小型代价体相关的信息损失。ESM通过将主要特征整合到视差上采样单元中来恢复关键细节。它快速从初始视差估计中提取特征并将其与图像特征融合。这些特征通过混洗和层分割进行混合，然后通过一个紧凑的特征引导沙漏网络进行精炼，以恢复更详细的场景几何。ESM专注于具有大感受野和低计算成本的局部上下文连接性，从而实现了高精度视差图的实时重建。ESMStereo的紧凑版本在高端GPU上实现了116 FPS的推理速度，在AGX Orin上实现了91 FPS。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [362] [OracleFusion: Assisting the Decipherment of Oracle Bone Script with Structurally Constrained Semantic Typography](https://arxiv.org/abs/2506.21101)
> *OracleFusion：通过结构约束语义排版辅助甲骨文破译*

*Caoshuo Li, Zengmao Ding, Xiaobin Hu, Bang Li, Donghao Luo, AndyPian Wu, Chaoyang Wang, Chengjie Wang, Taisong Jin, SevenShu, Yunsheng Wu, Yongge Liu, Rongrong Ji* | **Category: cs.CV**

**Keywords:** 甲骨文破译, 语义排版, 多模态大语言模型, 结构约束, 矢量字体

**Comment:** Accepted to ICCV 2025

> **TL;DR:** OracleFusion利用MLLM和结构约束语义排版辅助甲骨文破译，超越现有模型并提供专家级见解。

**AI_Comments:** 该论文提出了一种创新的结合多模态大语言模型与结构约束语义排版的方法来辅助甲骨文破译，具有重要的文化和历史意义。其亮点在于引入了结构约束以保持字形完整性，并能为专家提供未见字符的见解，这对于古文字研究领域是一个重大进步。

<details>
  <summary>Details</summary>

**Motivation:** 甲骨文作为最早的古老语言之一，约4500个字符中仅有1600个被破译。未破译的字符结构复杂、图像抽象，给解读带来巨大挑战。

**Method:** 本文提出了一种名为OracleFusion的新颖两阶段语义排版框架。第一阶段利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）分析甲骨文字形结构并进行关键组件的视觉定位。第二阶段引入甲骨文结构向量融合（OSVF），结合字形结构约束和字形维护约束，确保准确生成语义丰富的矢量字体。

**Result:** 广泛的定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形维护方面均优于最先进的基线模型，显著提升了可读性和美学质量。此外，OracleFusion能为未见的甲骨文字符提供专家般的见解。

**Conclusion:** OracleFusion是一种有价值的工具，可推动甲骨文的破译工作。

> **ai_Abstract:** 本文提出OracleFusion，一个两阶段语义排版框架，旨在辅助甲骨文的破译。它首先利用MLLM进行字形结构分析和组件定位，然后通过OSVF生成结构约束的语义矢量字体。实验证明，OracleFusion在语义、视觉和字形维护方面优于现有模型，显著提高了可读性和美学质量，并能为未见字符提供专家级见解，是推动甲骨文破译的宝贵工具。

> **摘要翻译:** 甲骨文作为最早的古老语言之一，承载着古代文明的文化记录和思想表达。尽管已发现约4500个甲骨文字符，但只有约1600个被破译。其余未破译的字符，其复杂的结构和抽象的图像，给解读带来了巨大的挑战。为了应对这些挑战，本文提出了一种新颖的两阶段语义排版框架，名为OracleFusion。在第一阶段，该方法利用增强空间感知推理（SAR）的多模态大语言模型（MLLM）分析甲骨文字形结构并进行关键组件的视觉定位。在第二阶段，我们引入甲骨文结构向量融合（OSVF），结合字形结构约束和字形维护约束，以确保准确生成语义丰富的矢量字体。这种方法保持了字形结构的客观完整性，提供了视觉增强的表示，辅助专家破译甲骨文。广泛的定性和定量实验表明，OracleFusion在语义、视觉吸引力和字形维护方面均优于最先进的基线模型，显著提升了可读性和美学质量。此外，OracleFusion能为未见的甲骨文字符提供专家般的见解，使其成为推动甲骨文破译工作的宝贵工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [365] [Pushing Trade-Off Boundaries: Compact yet Effective Remote Sensing Change Detection](https://arxiv.org/abs/2506.21109)
> *突破权衡界限：紧凑而有效的遥感变化检测*

*Luosheng Xu, Dalin Zhang, Zhaohui Song* | **Category: cs.CV, cs.LG**

**Keywords:** 遥感变化检测, 轻量级模型, 性能-资源权衡, FlickCD, 深度学习

**Comment:** 12 pages

> **TL;DR:** FlickCD是一种新的轻量级遥感变化检测模型，在大幅降低计算和存储开销的同时，保持了最先进的性能。

**AI_Comments:** 该论文的创新点在于其FlickCD模型在遥感变化检测领域对性能-资源权衡的突破。通过设计轻量级但高效的架构，FlickCD显著降低了计算和存储成本，同时保持了高精度，这对于资源受限的星载处理应用具有重要意义。EDM和局部-全局融合块的设计是其成功的关键。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习彻底改变了变化检测，但现代模型日益增长的复杂性和计算需求并未带来显著的精度提升。本研究旨在探索一种更高效的方法，专注于轻量级模型，以在最小化资源消耗的同时保持高精度，这对于卫星处理至关重要。

**Method:** 本研究提出了FlickCD模型，它引入了增强差异模块（EDM）来放大时间相位间的关键特征差异，同时抑制光照和天气变化等无关变异，从而降低后续变化解码器的计算成本。此外，FlickCD解码器结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）来有效捕获多尺度语义信息，保留粗粒度和细粒度的变化。

**Result:** 在四个基准数据集上的大量实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最先进（SOTA）的性能或仅带来微小的（<1% F1）精度权衡。

**Conclusion:** FlickCD通过在大幅降低资源消耗的同时保持高精度，成功突破了遥感变化检测领域的性能-资源权衡界限，特别适合星载处理。

> **ai_Abstract:** 该研究提出了一种名为FlickCD的轻量级遥感变化检测模型，旨在解决现有深度学习模型计算复杂性高但精度提升有限的问题。FlickCD通过引入增强差异模块（EDM）来有效识别关键特征差异，并利用包含移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）的局部-全局融合块来捕获多尺度语义信息。实验结果表明，FlickCD在大幅降低计算和存储开销的同时，实现了与最先进模型相当的性能。

> **摘要翻译:** 遥感变化检测对于监测城市扩张、灾害评估和资源管理至关重要，它能为动态景观转变提供及时、准确和大规模的洞察。尽管深度学习彻底改变了变化检测，但现代模型日益增长的复杂性和计算需求并未必然转化为显著的精度提升。本研究并未追随这一趋势，而是探索了一种更高效的方法，专注于轻量级模型，以在最小化资源消耗的同时保持高精度，这对于卫星处理是必不可少的。为此，我们提出了FlickCD，意为“快速一瞥即可获得出色结果”，它突破了性能-资源权衡的界限。FlickCD引入了一个增强差异模块（EDM）来放大时间相位间的关键特征差异，同时抑制光照和天气变化等无关变异，从而降低后续变化解码器的计算成本。此外，FlickCD解码器结合了局部-全局融合块，利用移位窗口自注意力（SWSA）和增强全局自注意力（EGSA）来有效捕获多尺度语义信息，保留粗粒度和细粒度的变化。在四个基准数据集上的大量实验表明，FlickCD将计算和存储开销降低了一个数量级以上，同时实现了最先进（SOTA）的性能或仅带来微小的（<1% F1）精度权衡。实现代码已在https://github.com/xulsh8/FlickCD 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [366] [IPFormer-VideoLLM: Enhancing Multi-modal Video Understanding for Multi-shot Scenes](https://arxiv.org/abs/2506.21116)
> *IPFormer-VideoLLM：增强多镜头场景下的多模态视频理解*

*Yujia Liang, Jile Jiao, Zhicheng Wang, Xuetao Feng, Zixuan Ye, Yuan Wang, Hao Lu* | **Category: cs.CV, cs.AI**

**Keywords:** 视频大语言模型, 多镜头理解, 数据集, 实例级特征, IPFormer-VideoLLM

**Comment:** 

> **TL;DR:** IPFormer-VideoLLM 引入了新的 MultiClip-Bench 数据集和 IPFormer-VideoLLM 模型，通过实例级特征注入，显著提升了视频大语言模型在多镜头场景下的视频理解能力，解决了现有模型在处理复杂场景时实例识别遗忘和关键帧忽视的问题。

**AI_Comments:** 这项工作在解决视频大语言模型处理复杂多镜头场景时的核心挑战方面具有创新性。通过引入专门的数据集 MultiClip-Bench，它弥补了现有数据标注的空白，为模型学习多镜头理解提供了宝贵资源。同时，IPFormer-VideoLLM 模型通过实例级特征注入的机制，有效解决了实例身份遗忘和信息丢失的问题，这对于提升视频理解的精细度和鲁棒性至关重要。其创新点在于从数据和模型两个层面同时进行改进，形成协同效应。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频大语言模型在处理多镜头场景（如包含不同摄像机角度或场景变化的视频片段）时表现不佳，导致实例身份遗忘和关键帧忽视等问题。本文认为这是由于现有数据集中缺乏多镜头标注造成的，并且当前模型编码实例特征的方式是离散或有损的，存在丢失身份信息的风险。

**Method:** 1. 引入了一个新的数据集 MultiClip-Bench，该数据集具有密集的描述和针对多镜头场景的基于指令的问题-回答对。2. 提出了一个新的模型 IPFormer-VideoLLM，其核心思想是通过一个高效的基于注意力的连接器，将实例级特征作为实例提示注入，从而聚合跨场景的实例特定信息。

**Result:** 实验表明，所提出的数据集和模型不仅显著增强了多场景视频理解能力，而且在各种视频基准测试中也展现出明显的优势。训练集显著提升了多镜头性能，测试基准提供了可靠的模型能力衡量标准。

**Conclusion:** IPFormer-VideoLLM 通过引入专门的数据集 MultiClip-Bench 和创新的模型架构，有效解决了视频大语言模型在多镜头场景理解中的挑战，显著提升了模型的性能和鲁棒性。

> **ai_Abstract:** 本文针对视频大语言模型在多镜头场景理解中面临的挑战，提出了两项关键贡献：首先，引入了 MultiClip-Bench 数据集，该数据集专门为多镜头场景设计，包含丰富的描述和问答对，旨在弥补现有数据集中多镜头标注的不足。其次，提出了 IPFormer-VideoLLM 模型，该模型通过一个注意力连接器将实例级特征注入为实例提示，有效聚合跨场景的实例信息，解决了现有模型在处理多镜头时实例识别困难和信息丢失的问题。实验证明，该数据集和模型显著提升了多场景视频理解能力，并在多个视频基准上表现出色。

> **摘要翻译:** 视频大语言模型（VideoLLMs）展现了卓越的理解能力，但在处理多镜头场景时（例如，包含不同摄像机角度或场景变化的视频片段）却发现它们力不从心。这一挑战可能导致实例身份遗忘和关键帧忽视等失败。在这项工作中，我们首先将这一挑战归因于现有数据集中缺乏多镜头标注，因此我们引入了一个名为 MultiClip-Bench 的新数据集，该数据集具有密集的描述和专为多镜头场景量身定制的基于指令的问题-回答对。我们凭经验发现，训练集显著提升了多镜头性能，而测试基准则提供了衡量模型在多镜头场景中能力的可靠方法。通过进一步分析和发现当前模型仅以离散或有损的方式编码实例特征，存在丢失身份信息的风险，我们随后贡献了一个新模型 IPFormer-VideoLLM。其核心思想是通过一个高效的基于注意力的连接器，将实例级特征作为实例提示注入。这允许聚合跨场景的实例特定信息。实验表明，我们提出的数据集和模型不仅显著增强了多场景视频理解能力，而且在各种视频基准测试中也提供了明显的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [368] [CL-Splats: Continual Learning of Gaussian Splatting with Local Optimization](https://arxiv.org/abs/2506.21117)
> *CL-Splats：基于局部优化的持续高斯泼溅学习*

*Jan Ackermann, Jonas Kulhanek, Shengqu Cai, Haofei Xu, Marc Pollefeys, Gordon Wetzstein, Leonidas Guibas, Songyou Peng* | **Category: cs.CV**

**Keywords:** 持续学习, 高斯泼溅, 3D重建, 局部优化, 变化检测

**Comment:** ICCV 2025, Project Page: https://cl-splats.github.io

> **TL;DR:** CL-Splats通过局部优化和变化检测，高效地持续更新3D高斯泼溅场景表示，无需重新优化整个场景。

**AI_Comments:** 这篇论文通过引入局部优化和变化检测模块，解决了动态3D场景中高斯泼溅表示的持续更新效率问题，避免了传统方法中全场景重新优化的巨大计算开销。其创新点在于对场景变化进行精细化管理，并支持历史状态恢复，这对于实时应用和场景分析具有重要意义。该方法有望推动3D重建技术在动态环境中的实用化。

<details>
  <summary>Details</summary>

**Motivation:** 在动态3D环境中，实时准确更新场景表示对于机器人、混合现实和具身AI应用至关重要。需要高效的方法来整合变化，以维护高质量的重建，同时避免重新优化整个场景的计算开销。

**Method:** 本文提出了CL-Splats，它从稀疏场景捕获中增量更新基于高斯泼溅的3D表示。CL-Splats集成了一个鲁棒的变化检测模块，该模块能分割场景中更新和静态的组件，从而实现集中的局部优化，避免不必要的重复计算。此外，CL-Splats支持存储和恢复先前的场景状态，有助于时间分割和新的场景分析应用。

**Result:** 广泛的实验表明，CL-Splats实现了高效的更新，并且重建质量优于现有技术。

**Conclusion:** CL-Splats为未来3D场景重建任务中的实时适应性奠定了坚实的基础。

> **ai_Abstract:** CL-Splats是一种用于动态3D环境的持续学习方法，它通过增量更新高斯泼溅表示来高效地维护高质量的场景重建。该方法采用变化检测模块进行局部优化，避免全场景重新计算，并支持场景状态的存储和恢复。实验证明其更新效率和重建质量均优于现有技术，为实时3D场景适应性提供了基础。

> **摘要翻译:** 在动态3D环境中，随时间准确更新场景表示对于机器人、混合现实和具身AI应用至关重要。随着场景的演变，需要高效的方法来整合变化，以维护最新的高质量重建，同时避免重新优化整个场景的计算开销。本文介绍了CL-Splats，它从稀疏场景捕获中增量更新基于高斯泼溅的3D表示。CL-Splats集成了一个鲁棒的变化检测模块，该模块能分割场景中更新和静态的组件，从而实现集中的局部优化，避免不必要的重复计算。此外，CL-Splats支持存储和恢复先前的场景状态，有助于时间分割和新的场景分析应用。我们广泛的实验表明，CL-Splats实现了高效的更新，并且重建质量优于现有技术。这为未来3D场景重建任务中的实时适应性奠定了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [370] [Logios : An open source Greek Polytonic Optical Character Recognition system](https://arxiv.org/abs/2506.21474)
> *Logios：一个开源的希腊语多音素光学字符识别系统*

*Perifanos Konstantinos, Goutsos Dionisis* | **Category: cs.CV, cs.CL**

**Keywords:** 希腊语多音素, OCR, 光学字符识别, 深度学习, 开源

**Comment:** 

> **TL;DR:** Logios是一个开源的希腊语多音素OCR系统，结合卷积层和循环层，旨在提高希腊语多音素文本的识别准确性和效率。

**AI_Comments:** 该论文的创新之处在于其专门针对希腊语多音素文字的OCR解决方案，并结合了深度学习中的卷积层和循环层来处理其复杂性。作为开源项目发布，将极大地促进相关领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的OCR方法在处理希腊语多音素文本时存在局限性，本系统旨在解决希腊语多音素文本的准确识别和数字化所带来的独特挑战。

**Method:** 该系统结合了卷积层进行特征提取和循环层进行序列学习，以处理希腊语多音素文字的独特挑战。

**Result:** 该系统显著提高了识别准确性和效率。研究者发布了底层模型作为开源库，并提供了OCR平台供学术使用。

**Conclusion:** Logios系统通过结合卷积层和循环层，有效克服了传统OCR方法的局限性，在希腊语多音素文本的准确识别和数字化方面取得了显著改进。

> **ai_Abstract:** Logios是一个专门为希腊语多音素文本设计的开源OCR系统。它结合了卷积层进行特征提取和循环层进行序列学习，旨在克服传统OCR方法的局限性，显著提高希腊语多音素文本的识别准确性和效率。该系统已作为开源库发布，并提供平台供学术使用。

> **摘要翻译:** 本文介绍了一个专门为希腊语多音素文本的准确识别和数字化而设计的光学字符识别（OCR）系统。通过利用卷积层进行特征提取和循环层进行序列学习的综合优势，我们的系统解决了希腊语多音素文字所带来的独特挑战。这种方法旨在克服传统OCR方法的局限性，在准确性和效率方面提供了显著改进。我们将底层模型作为一个开源库发布，并使我们的OCR平台可供学术使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [371] [Learning to See in the Extremely Dark](https://arxiv.org/abs/2506.21132)
> *在极暗环境下学习可见*

*Hai Jiang, Binhao Guan, Zhen Liu, Xiaohong Liu, Jian Yu, Zheng Liu, Songchen Han, Shuaicheng Liu* | **Category: cs.CV**

**Keywords:** 极暗图像增强, RAW图像, 数据集合成, 扩散模型, 低光照

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本文提出了一个数据合成管道，用于生成极低光RAW图像数据集SIED，并提出了一种基于扩散模型的框架，通过自适应光照校正模块和颜色一致性损失来增强极低信噪比图像，有效解决了极暗场景下的图像增强问题。

**AI_Comments:** 本文的创新点在于构建了首个针对极暗场景的大规模成对数据集SIED，填补了该领域数据稀缺的空白。同时，将扩散模型应用于极低信噪比的RAW图像增强，并引入了AICM和颜色一致性损失，有效利用了扩散模型的去噪和生成能力，为极暗环境下的图像恢复提供了新的解决方案，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于学习的方法在极暗场景（照度低至0.0001 lux）下的RAW图像增强能力尚未被充分探索，主要原因是缺乏相应的极暗场景数据集。

**Method:** 本文提出了一个成对数据合成管道，能够生成三种精确照度范围（0.01-0.1 lux, 0.001-0.01 lux, 0.0001-0.001 lux）的校准良好的极低光RAW图像，并结合高质量sRGB参考图像，构建了一个名为See-in-the-Extremely-Dark (SIED)的大规模成对数据集。此外，本文还提出了一种基于扩散模型的框架，利用扩散模型的生成能力和内在去噪特性，从极低信噪比的RAW输入中恢复视觉上令人满意的结果，该框架引入了自适应光照校正模块（AICM）和颜色一致性损失，以确保准确的曝光校正和颜色恢复。

**Result:** 在所提出的SIED数据集和公开基准数据集上进行的广泛实验证明了本文方法的有效性。

**Conclusion:** 本文成功构建了极暗场景数据集SIED并提出了一种有效的基于扩散模型的图像增强框架，解决了极暗环境下图像增强的挑战。

> **ai_Abstract:** 本文针对极暗场景下（照度低至0.0001 lux）RAW图像增强缺乏数据集和有效方法的问题，提出了一个成对数据合成管道，构建了大规模极低光RAW图像数据集SIED。同时，提出了一种基于扩散模型的框架，该框架通过引入自适应光照校正模块和颜色一致性损失，能够从极低信噪比的RAW输入中恢复高质量图像。实验证明了该方法在SIED和公共基准上的有效性。

> **摘要翻译:** 基于学习的方法在低光RAW图像增强方面取得了可喜的进展，但由于缺乏相应的数据集，它们在环境照度低至0.0001 lux的极暗场景中的能力仍有待探索。为此，我们提出了一个成对数据合成管道，能够生成三种精确照度范围（0.01-0.1 lux、0.001-0.01 lux和0.0001-0.001 lux）的校准良好的极低光RAW图像，并结合高质量的sRGB参考图像，构成了一个名为See-in-the-Extremely-Dark (SIED)的大规模成对数据集，用于评估低光RAW图像增强方法。此外，我们提出了一种基于扩散模型的框架，该框架利用扩散模型的生成能力和内在去噪特性，从极低信噪比的RAW输入中恢复视觉上令人满意的结果，其中引入了自适应光照校正模块（AICM）和颜色一致性损失，以确保准确的曝光校正和颜色恢复。在所提出的SIED和公开可用基准数据集上进行的广泛实验证明了我们方法的有效性。代码和数据集可在https://github.com/JianghaiSCU/SIED上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [373] [YOLO-FDA: Integrating Hierarchical Attention and Detail Enhancement for Surface Defect Detection](https://arxiv.org/abs/2506.21135)
> *YOLO-FDA：融合分层注意力与细节增强的表面缺陷检测*

*Jiawei Hu* | **Category: cs.CV**

**Keywords:** 表面缺陷检测, YOLO, 细节增强, 注意力机制, 特征融合

**Comment:** 14 pages, 6 figures. Submitted to The 8th Chinese Conference on
  Pattern Recognition and Computer Vision

> **TL;DR:** YOLO-FDA是一种新的基于YOLO的表面缺陷检测框架，通过细节增强和注意力引导的特征融合，解决了现有方法在多尺度条件下的冗余特征、细节敏感性不足和鲁棒性差的问题，并在基准数据集上表现出SOTA性能。

**AI_Comments:** YOLO-FDA的创新点在于其结合了细节增强模块（DDFM）和多种注意力机制（AC, CAF），以优化YOLOv5骨干网络的特征表示，特别针对工业缺陷检测中对精细细节捕捉和多尺度鲁棒性的高要求。BiFPN风格的集成也进一步强化了特征聚合能力，使其在复杂工业场景中表现出卓越性能。

<details>
  <summary>Details</summary>

**Motivation:** 工业场景中的表面缺陷检测具有挑战性，因为缺陷类型多变、形状不规则、尺寸各异、要求精细且材料纹理复杂。尽管AI检测器有所改进，但现有方法常存在冗余特征、细节敏感性有限以及多尺度条件下鲁棒性差的问题。

**Method:** 本文提出了YOLO-FDA框架，一个基于YOLO的检测框架，其核心在于集成细粒度细节增强和注意力引导的特征融合。具体方法包括：1. 采用BiFPN风格的架构，加强YOLOv5骨干网络内的双向多级特征聚合。2. 引入细节方向融合模块（DDFM），在倒数第二层引入方向性不对称卷积以丰富空间细节，并将倒数第二层与低级特征融合以增强语义一致性。3. 提出两种新颖的基于注意力的融合策略：注意力加权拼接（AC）和跨层注意力融合（CAF），以改善上下文表示并减少特征噪声。

**Result:** 在基准数据集上的大量实验表明，YOLO-FDA在各种缺陷类型和尺度上，在准确性和鲁棒性方面始终优于现有的最先进方法。

**Conclusion:** YOLO-FDA通过其创新性的细节增强和注意力引导特征融合策略，有效解决了工业表面缺陷检测的挑战，并在性能上超越了现有SOTA方法。

> **ai_Abstract:** 本文提出了YOLO-FDA，一个基于YOLO的表面缺陷检测新框架，旨在解决工业场景中缺陷检测的挑战，如冗余特征、细节敏感性不足和多尺度鲁棒性差。YOLO-FDA通过集成BiFPN风格的双向特征聚合、引入细节方向融合模块（DDFM）以增强细节捕捉，以及提出注意力加权拼接（AC）和跨层注意力融合（CAF）两种注意力融合策略来优化特征表示。实验结果表明，YOLO-FDA在准确性和鲁棒性方面均超越了现有SOTA方法。

> **摘要翻译:** 工业场景中的表面缺陷检测既关键又具技术挑战性，因为缺陷类型广泛多样、形状和尺寸不规则、要求精细且材料纹理复杂。尽管近期基于AI的检测器取得了进展，但现有方法常受限于冗余特征、细节敏感性不足以及多尺度条件下的鲁棒性差。为解决这些挑战，我们提出了YOLO-FDA，一种新颖的基于YOLO的检测框架，它集成了细粒度细节增强和注意力引导的特征融合。具体而言，我们采用BiFPN风格的架构来加强YOLOv5骨干网络内的双向多级特征聚合。为了更好地捕获精细结构变化，我们引入了一个细节方向融合模块（DDFM），该模块在倒数第二层引入方向性不对称卷积以丰富空间细节，并将倒数第二层与低级特征融合以增强语义一致性。此外，我们提出了两种新颖的基于注意力的融合策略，即注意力加权拼接（AC）和跨层注意力融合（CAF），以改善上下文表示并减少特征噪声。在基准数据集上的大量实验表明，YOLO-FDA在各种缺陷类型和尺度上，在准确性和鲁棒性方面始终优于现有的最先进方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [HalluSegBench: Counterfactual Visual Reasoning for Segmentation Hallucination Evaluation](https://arxiv.org/abs/2506.21546)
> *HalluSegBench：用于分割幻觉评估的反事实视觉推理*

*Xinzhuo Li, Adheesh Juvekar, Xingyou Liu, Muntasir Wahed, Kiet A. Nguyen, Ismini Lourentzou* | **Category: cs.CV, cs.AI, cs.CL, cs.LG**

**Keywords:** 分割幻觉, 反事实推理, 视觉-语言分割, 基准测试, HalluSegBench

**Comment:** Project webpage: https://plan-lab.github.io/hallusegbench/

> **TL;DR:** 提出HalluSegBench，首个用于评估视觉-语言分割模型幻觉的基准，通过反事实视觉推理揭示视觉驱动幻觉比标签驱动更普遍。

**AI_Comments:** 该论文的创新点在于首次引入反事实视觉推理来评估视觉-语言分割中的幻觉，填补了现有评估协议的空白。其重要性在于揭示了视觉驱动幻觉的普遍性，并提出了更有效的诊断工具，对未来鲁棒视觉-语言模型的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言分割模型经常产生幻觉，即为图像中不存在的对象生成分割掩码或错误标记无关区域。现有评估协议主要关注标签或文本幻觉，但未操纵视觉上下文，限制了诊断关键故障的能力。

**Method:** 引入HalluSegBench，这是第一个专门设计用于通过反事实视觉推理评估视觉基础中幻觉的基准。该基准包含一个由1340对反事实实例（涵盖281个独特对象类别）组成的新数据集，以及一套量化视觉连贯场景编辑下幻觉敏感度的新指标。

**Result:** 在HalluSegBench上对最先进的视觉-语言分割模型进行的实验表明，视觉驱动的幻觉比标签驱动的幻觉更为普遍，模型通常会持续错误的分割。

**Conclusion:** 强调了需要反事实推理来诊断视觉基础的保真度。

> **ai_Abstract:** 本文介绍了HalluSegBench，一个用于评估视觉-语言分割模型中视觉基础幻觉的首个基准。针对现有评估方法无法充分诊断视觉幻觉的问题，HalluSegBench利用反事实视觉推理，构建了一个包含1340对反事实实例的新数据集和一套新指标。实验结果显示，视觉驱动的幻觉比标签驱动的幻觉更普遍，模型常出现持续性错误分割，突显了反事实推理在诊断视觉基础保真度方面的重要性。

> **摘要翻译:** 视觉-语言分割的最新进展显著推动了扎根视觉理解。然而，这些模型经常通过为不基于图像内容的对象生成分割掩码或错误标记无关区域来表现出幻觉。现有的分割幻觉评估协议主要关注标签或文本幻觉，而没有操纵视觉上下文，这限制了它们诊断关键故障的能力。为此，我们引入了HalluSegBench，这是第一个专门设计用于通过反事实视觉推理来评估视觉基础中幻觉的基准。我们的基准包含一个由1340对反事实实例组成的新数据集，涵盖281个独特的对象类别，以及一套新引入的指标，用于量化在视觉连贯场景编辑下的幻觉敏感度。在HalluSegBench上对最先进的视觉-语言分割模型进行的实验表明，视觉驱动的幻觉比标签驱动的幻觉更为普遍，模型通常会持续错误的分割，这突出表明需要反事实推理来诊断基础的保真度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [375] [Tree-based Semantic Losses: Application to Sparsely-supervised Large Multi-class Hyperspectral Segmentation](https://arxiv.org/abs/2506.21150)
> *基于树的语义损失：应用于稀疏监督的大规模多类别高光谱图像分割*

*Junwen Wang, Oscar Maccormac, William Rochford, Aaron Kujawa, Jonathan Shapey, Tom Vercauteren* | **Category: cs.CV**

**Keywords:** 高光谱图像分割, 语义损失, 树结构, 稀疏监督, 分布外检测

**Comment:** 

> **TL;DR:** 本文提出了两种基于树的语义损失函数，用于稀疏监督的高光谱图像分割，利用标签的层次结构，在包含107个类别的稀疏标注高光谱数据集上达到了最先进的性能，并能有效检测OOD像素。

**AI_Comments:** 这项工作通过引入基于树的语义损失，巧妙地解决了高光谱图像分割中类别多且细微、传统损失函数无法利用类间语义的痛点。其创新性在于将标签的层次结构融入损失函数设计，这对于处理大规模多类别分类问题尤为重要。同时，该方法在稀疏标注数据集上的SOTA表现以及OOD检测能力，进一步凸显了其实用价值和潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱成像在外科应用中潜力巨大，但现有的生物医学分割方法对所有错误同等惩罚，未能利用标签空间中的类间语义信息，导致在区分大量细微变化的类别时效果不佳。

**Method:** 本文提出了两种基于树的语义损失函数，利用标签的层次结构。这些损失函数被整合到一个最近提出的用于稀疏、无背景注释训练的方法中。

**Result:** 在包含107个类别的临床定义语义树结构高光谱图像数据集上，本文提出的方法达到了最先进的性能。此外，该方法能够在不影响分布内（ID）像素分割性能的情况下，有效检测分布外（OOD）像素。

**Conclusion:** 本文提出的基于树的语义损失函数，通过利用标签的层次结构，显著提升了稀疏监督大规模多类别高光谱图像分割的性能，并增强了对分布外像素的检测能力。

> **ai_Abstract:** 本文针对高光谱成像（HSI）在外科应用中细致区分大量类别的挑战，提出了两种基于树的语义损失函数。这些损失函数利用标签的层次结构，解决了传统方法忽视类间语义信息的问题。结合稀疏标注训练方法，本研究在高光谱数据集上实现了最先进的分割性能，并有效检测了分布外像素，为生物医学图像分割提供了新途径。

> **摘要翻译:** 高光谱成像（HSI）在外科应用中展现出巨大潜力，能够提供超越肉眼所能感知的生物组织差异的详细信息。目前正在进行精细的标注工作，以训练视觉系统区分大量细微变化的类别。然而，生物医学分割任务中常用的学习方法对所有错误给予同等惩罚，因此未能利用标签空间中的任何类间语义。在这项工作中，我们引入了两种基于树的语义损失函数，它们利用了标签的层次组织。我们进一步将我们的损失函数整合到一个最近提出的利用稀疏、无背景注释进行训练的方法中。大量的实验表明，我们提出的方法在包含107个类别、以临床定义语义树结构组织的高光谱图像稀疏标注数据集上达到了最先进的性能。此外，我们的方法能够在不影响分布内（ID）像素分割性能的情况下，有效检测分布外（OOD）像素。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [376] [Robust Deep Learning for Myocardial Scar Segmentation in Cardiac MRI with Noisy Labels](https://arxiv.org/abs/2506.21151)
> *针对心脏MRI中含噪声标签的心肌瘢痕分割的鲁棒深度学习*

*Aida Moafi, Danial Moafi, Evgeny M. Mirkes, Gerry P. McCann, Abbas S. Alatrany, Jayanth R. Arnold, Mostafa Mehdipour Ghazi* | **Category: cs.CV, cs.AI**

**Keywords:** 心肌瘢痕分割, 深度学习, 标签噪声, 心脏MRI, 鲁棒性

**Comment:** MICCAI 2025

> **TL;DR:** 本研究提出了一种鲁棒的深度学习方法，用于在存在噪声标签的情况下，准确分割心脏MRI中的心肌瘢痕，并优于现有技术。

**AI_Comments:** 这篇论文的创新点在于其鲁棒的深度学习流程，特别是在处理医疗图像中常见的标签噪声（来自半自动标注）、数据异质性和类别不平衡问题上。通过采用KL损失和数据增强，该方法显著提升了模型在真实世界数据中的实用性。其超越nnU-Net并展现出强大泛化能力的表现，使其在临床应用中具有重要意义，尤其是在需要高精度和可靠性的诊断领域。

<details>
  <summary>Details</summary>

**Motivation:** 准确分割心脏MRI中的心肌瘢痕对于临床评估和治疗规划至关重要。

**Method:** 本研究提出一个鲁棒的深度学习流程，通过微调最先进的模型，明确解决了半自动标注、数据异质性和类别不平衡带来的标签噪声挑战。具体方法包括使用Kullback-Leibler损失和大量数据增强。

**Result:** 模型在急性病例和慢性病例上都表现出准确和平滑的分割，即使存在噪声标签。该方法优于nnU-Net等最先进模型，并在分布外测试集上显示出强大的泛化能力，突出了其在各种成像条件和临床任务中的鲁棒性。

**Conclusion:** 这些结果为自动化心肌瘢痕量化奠定了可靠基础，并支持深度学习在心脏成像中更广泛的临床应用。

> **ai_Abstract:** 本研究提出了一种针对心脏MRI中肌瘢痕分割的鲁棒深度学习方法。该方法通过微调现有模型并结合Kullback-Leibler损失和数据增强，有效解决了半自动标注中的标签噪声、数据异质性和类别不平衡问题。实验证明，即使在噪声标签下，该方法也能实现准确平滑的分割，并且在泛化能力和性能上优于现有技术，为心肌瘢痕的自动化量化和深度学习在心脏成像领域的临床应用奠定了基础。

> **摘要翻译:** 心肌瘢痕在心脏MRI中的精确分割对于临床评估和治疗规划至关重要。在这项研究中，我们提出了一种鲁棒的深度学习流程，通过微调最先进的模型，实现全自动心肌瘢痕检测和分割。该方法通过使用Kullback-Leibler损失和广泛的数据增强，明确解决了半自动标注、数据异质性和类别不平衡带来的标签噪声挑战。我们在急性病例和慢性病例上评估了模型的性能，并展示了其在存在噪声标签的情况下也能产生准确和平滑分割的能力。特别是，我们的方法优于nnU-Net等最先进模型，并在分布外测试集上显示出强大的泛化能力，突出了其在各种成像条件和临床任务中的鲁棒性。这些结果为自动化心肌瘢痕量化奠定了可靠基础，并支持深度学习在心脏成像中更广泛的临床应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [378] [Geometry and Perception Guided Gaussians for Multiview-consistent 3D Generation from a Single Image](https://arxiv.org/abs/2506.21152)
> *几何与感知引导的高斯用于单图多视角一致性三维生成*

*Pufan Li, Bi'an Du, Wei Hu* | **Category: cs.CV, 68, I.4.0**

**Keywords:** 3D生成, 单视图, 高斯散射, 多视角一致性, 几何先验, 感知先验

**Comment:** 10 pages, 5 figures

> **TL;DR:** 本文提出一种新方法，通过结合几何和感知先验，从单张图像生成多视角一致且细节丰富的3D对象，无需额外模型训练。

**AI_Comments:** 这篇论文的创新点在于它无需额外的模型训练，而是通过巧妙地结合几何先验和感知先验来增强3D高斯模型，从而解决了单视图3D生成中长期存在的多视角不一致和细节缺失问题。其引入的三个高斯分支以及几何与感知之间的相互作用机制是关键，特别是利用2D预训练扩散模型作为感知先验来增强多视角信息，这提供了一个有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有从单视图图像生成3D对象的方法通常存在多视角一致性差和几何细节不足的问题，且难以捕捉未见区域的多种合理解释。

**Method:** 本文提出一种新颖的方法，无需额外模型训练即可无缝整合几何和感知先验，以从单张图像重建详细的3D对象。具体地，训练三个不同高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验用于捕获粗略的3D形状，感知先验利用2D预训练扩散模型增强多视角信息。随后，通过几何和感知先验之间的相互作用以及基于重投影的策略加强深度一致性，进一步细化3D高斯分支。

**Result:** 实验证明，该方法实现了更高保真度的重建结果，在新视图合成和3D重建方面优于现有方法，展示了鲁棒且一致的3D对象生成。

**Conclusion:** 本文提出的几何与感知引导的高斯方法有效解决了单视图3D生成中多视角一致性和几何细节不足的问题，实现了高质量的3D对象重建。

> **ai_Abstract:** 本文提出一种创新的单视图3D生成方法，旨在解决现有技术在多视角一致性和几何细节方面的不足。该方法通过整合几何和感知先验，并利用三个独立初始化的高斯分支（分别来自几何先验、感知先验和高斯噪声）进行3D对象重建，且无需额外的模型训练。几何先验用于捕捉粗略3D形状，感知先验则通过2D预训练扩散模型增强多视角信息。通过两者间的相互作用和基于重投影的深度一致性策略，对3D高斯分支进行细化。实验结果表明，该方法在3D重建和新视图合成方面表现出更高保真度和一致性，优于现有方法。

> **摘要翻译:** 从单视图图像生成逼真的3D对象需要自然的视觉外观、3D一致性以及捕捉未见区域多种合理解释的能力。现有方法通常依赖于微调预训练的2D扩散模型或通过快速网络推理或3D高斯散射直接生成3D信息，但它们的结果普遍存在多视角一致性差和几何细节不足的问题。为了解决这些问题，我们提出了一种新颖的方法，该方法无需额外的模型训练即可无缝整合几何和感知先验，以从单张图像重建详细的3D对象。具体而言，我们训练了三个不同高斯分支，分别从几何先验、感知先验和高斯噪声初始化。几何先验捕获粗略的3D形状，而感知先验则利用2D预训练扩散模型来增强多视角信息。随后，我们通过几何和感知先验之间的相互作用进一步细化3D高斯分支，并通过基于重投影的策略加强深度一致性。实验表明，我们的方法实现了更高保真度的重建结果，在新型视图合成和3D重建方面优于现有方法，展示了鲁棒且一致的3D对象生成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [379] [Topology-Aware Modeling for Unsupervised Simulation-to-Reality Point Cloud Recognition](https://arxiv.org/abs/2506.21165)
> *用于无监督模拟到现实点云识别的拓扑感知建模*

*Longkun Zou, Kangjun Liu, Ke Chen, Kailing Guo, Kui Jia, Yaowei Wang* | **Category: cs.CV**

**Keywords:** 点云识别, 模拟到现实, 无监督域适应, 拓扑感知建模, 领域差距

**Comment:** 

> **TL;DR:** 本文提出了一种名为拓扑感知建模（TAM）的新框架，用于解决3D点云识别中模拟到现实的领域差距问题，通过利用全局空间拓扑和局部几何特征的拓扑关系，并结合先进的自训练策略，在多个基准测试中取得了优于现有方法的性能。

**AI_Comments:** 该论文通过引入拓扑感知建模，有效地解决了点云Sim2Real领域适应中全局拓扑信息缺失的关键问题，并结合创新的自监督和自训练策略，显著提升了模型在跨域识别上的泛化能力。其创新点在于对拓扑信息的深度利用和对伪标签噪声的鲁棒性处理。

<details>
  <summary>Details</summary>

**Motivation:** 由于数据采集方法的差异，3D物体形状点集学习语义表示面临显著的几何变异挑战，导致模拟数据与真实数据之间存在模拟到现实（Sim2Real）领域差距，这限制了点分类器的泛化能力。现有无监督域适应（UDA）技术难以应对这一差距，因为它们缺乏能够捕获全局拓扑信息的鲁棒、领域不敏感的描述符，导致对源域有限语义模式的过拟合。

**Method:** 本文提出了一种新颖的拓扑感知建模（TAM）框架，用于解决对象点云的Sim2Real UDA问题。该方法通过利用低级、高频3D结构表征的全局空间拓扑，并通过新颖的自监督学习任务建模局部几何特征的拓扑关系来缩小领域差距。此外，还提出了一种先进的自训练策略，结合跨域对比学习和自训练，有效减少了噪声伪标签的影响并增强了适应过程的鲁棒性。

**Result:** 在三个公共Sim2Real基准测试上的实验结果验证了TAM框架的有效性，在所有评估任务中均显示出对现有最先进方法的一致改进。

**Conclusion:** 通过引入拓扑感知建模（TAM）框架，该研究成功地解决了3D点云识别中的模拟到现实领域差距问题，并显著提高了无监督域适应的性能。

> **ai_Abstract:** 本研究提出了一种名为拓扑感知建模（TAM）的新框架，旨在解决3D点云识别中模拟到现实（Sim2Real）的领域差距问题。针对现有无监督域适应（UDA）方法在处理几何变异和缺乏全局拓扑信息描述符方面的不足，TAM框架通过利用全局空间拓扑和建模局部几何特征的拓扑关系来缓解领域差距。此外，该框架结合了跨域对比学习和自训练的先进自训练策略，以提高适应过程的鲁棒性并减少噪声伪标签的影响。实验结果表明，TAM在多个Sim2Real基准测试上均优于现有最先进方法。

> **摘要翻译:** 从3D物体形状的点集中学习语义表示通常受到显著几何变化的挑战，这主要是由于数据采集方法的差异。通常，训练数据是使用点模拟器生成的，而测试数据是使用不同的3D传感器收集的，这导致了模拟到现实（Sim2Real）的领域差距，限制了点分类器的泛化能力。当前的无监督域适应（UDA）技术难以应对这一差距，因为它们通常缺乏能够捕获全局拓扑信息的鲁棒、领域不敏感的描述符，导致对源域有限语义模式的过拟合。为了解决这个问题，我们引入了一种新颖的拓扑感知建模（TAM）框架，用于对象点云的Sim2Real UDA。我们的方法通过利用由低级、高频3D结构表征的全局空间拓扑，并通过新颖的自监督学习任务建模局部几何特征的拓扑关系来缩小领域差距。此外，我们提出了一种先进的自训练策略，结合跨域对比学习和自训练，有效减少了噪声伪标签的影响并增强了适应过程的鲁棒性。在三个公共Sim2Real基准测试上的实验结果验证了我们TAM框架的有效性，在所有评估任务中均显示出对现有最先进方法的一致改进。这项工作的源代码将在https://github.com/zou-longkun/TAG.git上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [381] [Task-Aware KV Compression For Cost-Effective Long Video Understanding](https://arxiv.org/abs/2506.21184)
> *任务感知型KV压缩，用于经济高效的长视频理解*

*Minghao Qin, Yan Shu, Peitian Zhang, Kun Lun, Huaying Yuan, Juenjie Zhou, Shitao Xiao, Bo Zhao, Zheng Liu* | **Category: cs.CV, cs.AI**

**Keywords:** 长视频理解, KV压缩, 多模态大型语言模型, 计算成本, 任务感知

**Comment:** 14 pages, 3 figures, 6 tables

> **TL;DR:** Video-X^2L提出了一种任务感知的双层KV压缩和选择性KV重载方法，显著提升了长视频理解的效率和性能，且无需额外训练。

**AI_Comments:** Video-X^2L的创新之处在于其“任务感知”的双层KV压缩和选择性重载机制，这有效地解决了长视频理解中计算效率与信息保留之间的矛盾。其无需额外训练即可兼容现有模型的特点，大大降低了其应用门槛，使其具有很强的实用价值和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型多模态语言模型（MLLMs）在长视频理解（LVU）方面面临巨大的计算成本挑战，尽管KV压缩方法有所探索，但在高压缩比下常导致严重信息损失。

**Method:** 本文引入了Video-X^2L，它包含两个关键操作：1) 双层KV压缩：在MLLM的预填充阶段生成低压缩（L-KVs）和高压缩（H-KVs）两种KVs，分别捕获细粒度细节和提供紧凑表示。2) 选择性KV重载：在MLLM的解码阶段，选择性地为最关键的视频块重载L-KVs，而对不重要的部分使用H-KVs，从而在保持整体紧凑性的同时充分利用任务特定信息。

**Result:** Video-X^2L在VideoMME、MLVU、LongVideoBench和VNBench等多个流行LVU基准测试中进行了评估。实验结果表明，Video-X^2L在大幅节省计算成本的同时，以巨大优势超越了现有的KV压缩方法。

**Conclusion:** Video-X^2L是一种简单而有效的方法，它无需额外训练，并直接兼容现有的KV可压缩MLLMs，显著提升了长视频理解的性能和效率。

> **ai_Abstract:** 本文提出了一种名为Video-X^2L的新方法，旨在解决长视频理解中大型多模态语言模型（MLLMs）面临的高计算成本和信息损失问题。Video-X^2L通过引入双层KV压缩（生成低压缩和高压缩KVs）和选择性KV重载机制（根据视频块的重要性选择性加载KVs）来优化KV压缩。这种方法能够在不进行额外训练的情况下，有效保留关键视频信息，显著降低计算成本，并在多个长视频理解基准测试中表现优于现有KV压缩技术。

> **摘要翻译:** 长视频理解（LVU）对于现有的大型多模态语言模型（MLLMs）来说仍然是一个严峻的挑战，这主要是由于其高昂的计算成本。最近的方法探索了KV压缩来缓解这个问题，但它们在高压缩比下常常遭受严重的信息损失。在本文中，我们介绍了Video-X^2L，它能灵活地为每个LVU任务保留关键的视频信息。Video-X^2L涉及两个关键操作。第一个称为双层KV压缩。在MLLM的预填充阶段，Video-X^2L生成两种类型的压缩KVs：低压缩KVs（L-KVs）用于捕获细粒度的视频细节，高压缩KVs（H-KVs）用于提供紧凑的视频表示。第二个称为选择性KV重载。在MLLM的解码阶段，Video-X^2L选择性地为最关键的视频块重载L-KVs，同时对其他不那么重要的部分使用H-KVs。这使得MLLM能够充分利用任务特定信息，同时保持整体的紧凑性。Video-X^2L简单而有效：它无需额外训练，并直接兼容现有的KV可压缩MLLMs。我们使用各种流行的LVU基准测试对Video-X^2L进行了评估，包括VideoMME、MLVU、LongVideoBench和VNBench。我们的实验结果表明，Video-X^2L以巨大的优势超越了现有的KV压缩方法，同时大幅节省了计算成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [384] [GroundFlow: A Plug-in Module for Temporal Reasoning on 3D Point Cloud Sequential Grounding](https://arxiv.org/abs/2506.21188)
> *GroundFlow：一个用于三维点云序列化定位中时序推理的插件模块*

*Zijun Lin, Shuting He, Cheston Tan, Bihan Wen* | **Category: cs.CV**

**Keywords:** 三维点云, 时序推理, 序列化定位, 视觉定位, 插件模块

**Comment:** 

> **TL;DR:** GroundFlow是一个插件模块，通过有效整合短期和长期历史信息，显著提升了三维点云序列化定位（SG3D）任务中现有三维视觉定位（3DVG）方法的性能，解决了现有方法在处理带有代词的指令时缺乏时序推理能力的问题。

**AI_Comments:** GroundFlow的创新之处在于其作为插件模块，能够为现有3DVG模型引入急需的时序推理能力，有效解决了SG3D任务中代词和上下文理解的挑战。其通过选择性地整合短期和长期历史信息的方法，使其在处理复杂序列指令时表现出色，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有三维视觉定位（3DVG）方法在处理包含多步骤指令的文本时，未能有效提取时序信息，尤其是在指令中包含“它”、“这里”和“相同”等代词时，需要理解上下文并从之前的步骤中检索相关信息。由于缺乏有效的历史信息收集模块，现有3DVG方法难以适应三维点云序列化定位（SG3D）任务。

**Method:** 本文提出了GroundFlow，一个用于三维点云序列化定位中时序推理的插件模块。GroundFlow能够选择性地提取与当前指令相关的短期和长期步骤信息，从而全面利用历史信息。

**Result:** GroundFlow模块显著提升了基线3DVG方法在SG3D基准测试中的任务准确率（分别提高了7.5%和10.2%），甚至超越了在各种数据集上预训练的三维大型语言模型。GroundFlow在步骤数量增加时，仍能保持其时序理解优势，并在五个数据集的SG3D基准测试中取得了最先进的性能。

**Conclusion:** GroundFlow模块成功地为现有3DVG模型引入了时序推理能力，并在三维点云序列化定位任务中实现了最先进的性能。

> **ai_Abstract:** 本文提出了GroundFlow，一个用于三维点云序列化定位（SG3D）的插件模块，旨在解决现有三维视觉定位（3DVG）方法在处理多步骤文本指令时缺乏时序推理能力的问题。GroundFlow通过选择性地提取和整合短期及长期历史信息，显著提升了基线3DVG模型在SG3D任务上的准确性，并在多项基准测试中超越了预训练的三维大型语言模型，实现了最先进的性能。

> **摘要翻译:** 三维点云序列化定位（SG3D）是指通过遵循详细步骤的日常活动文本指令来定位一系列对象。当前的三维视觉定位（3DVG）方法将包含多个步骤的文本指令作为一个整体处理，而没有从每个步骤中提取有用的时序信息。然而，SG3D中的指令通常包含“它”、“这里”和“相同”等代词，以使语言表达简洁。这要求定位方法理解上下文并从之前的步骤中检索相关信息，以正确地定位对象序列。由于缺乏有效的模块来收集相关的历史信息，最先进的3DVG方法在适应SG3D任务时面临重大挑战。为了填补这一空白，我们提出了GroundFlow——一个用于三维点云序列化定位中时序推理的插件模块。首先，我们证明了在SG3D基准测试中，集成GroundFlow可以大幅提高3DVG基线方法的任务准确率（+7.5%和+10.2%），甚至优于在各种数据集上预训练的三维大型语言模型。此外，我们根据其与当前指令的相关性，选择性地提取短期和长期步骤信息，使GroundFlow能够全面审视历史信息，并在步骤数量增加时保持其时序理解优势。总的来说，我们的工作为现有3DVG模型引入了时序推理能力，并在五个数据集的SG3D基准测试中取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [389] [BitMark for Infinity: Watermarking Bitwise Autoregressive Image Generative Models](https://arxiv.org/abs/2506.21209)
> *BitMark for Infinity：比特级自回归图像生成模型的水印技术*

*Louis Kerner, Michel Meintz, Bihe Zhao, Franziska Boenisch, Adam Dziedzic* | **Category: cs.CV, cs.AI**

**Keywords:** 水印, 模型崩溃, 图像生成模型, 比特级自回归, 内容识别

**Comment:** 

> **TL;DR:** 针对Infinity等比特级自回归图像生成模型，研究人员提出了BitMark水印框架，通过在比特层面嵌入水印，有效防止模型崩溃，并具有高放射性，即使训练新的模型也能检测到水印。

**AI_Comments:** 这篇论文解决了当前AI生成内容面临的一个重要问题，即“模型崩溃”。BitMark的创新之处在于其比特级的水印嵌入方式，以及其“放射性”特性，这使得水印不仅能识别原始生成内容，还能追踪其被用于训练新模型后的传播，这对于内容溯源和版权保护具有重要意义。该方法兼顾了水印的隐蔽性、鲁棒性和检测性，是防止AI模型生态系统退化的一个关键进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像生成模型（如Infinity）能生成逼真的图像，但其输出被重复用作训练数据会导致“模型崩溃”，性能逐渐下降。水印技术是一种有前途的缓解策略，可以识别生成内容。

**Method:** 本文引入了BitMark，一个针对Infinity的鲁棒比特级水印框架。该方法在Infinity图像生成过程中，直接在令牌流的比特级别跨多个尺度嵌入水印。BitMark通过微妙地影响比特来保持视觉保真度和生成速度。

**Result:** BitMark水印对多种移除技术具有鲁棒性。它还表现出高放射性，即当带有水印的生成图像被用于训练另一个图像生成模型时，第二个模型的输出也将携带该水印，即使仅对扩散模型或图像自回归模型进行微调，水印痕迹仍然可检测。

**Conclusion:** BitMark提供了一种原则性的方法，通过可靠地检测生成输出，从而有效防止图像生成模型中的模型崩溃。

> **ai_Abstract:** 本文提出了BitMark，一种针对Infinity等比特级自回归图像生成模型的鲁棒水印框架。BitMark在图像生成过程中直接在比特级别嵌入水印，旨在防止模型崩溃——一种由于生成内容被重复用于训练而导致的性能下降现象。该水印技术在保持图像质量和生成速度的同时，对移除攻击具有鲁棒性，并展现出“放射性”，即即使使用带水印的图像训练新的模型，水印仍可被检测到，从而实现对生成内容的可靠识别。

> **摘要翻译:** 像Infinity这样的最先进文本到图像模型以史无前例的速度生成逼真的图像。这些模型以比特级自回归方式在离散的、实际上无限大小的令牌集上运行。然而，它们令人印象深刻的生成能力伴随着日益增长的风险：随着它们的输出越来越多地充斥互联网，它们很可能被抓取并重新用作训练数据——甚至可能被同一模型使用。这种现象已被证明会导致模型崩溃，即重复使用生成内容进行训练，尤其是来自模型自身先前版本的生成内容，会导致性能逐渐下降。一种有前景的缓解策略是水印技术，它将人眼不可察觉但可检测的信号嵌入到生成图像中，从而能够识别生成内容。在这项工作中，我们引入了BitMark，一个针对Infinity的鲁棒比特级水印框架。我们的方法在Infinity的图像生成过程中，直接在令牌流的比特级别跨多个尺度（也称为分辨率）嵌入水印。我们的比特级水印微妙地影响比特，以保持视觉保真度和生成速度，同时对一系列移除技术保持鲁棒性。此外，它还表现出高放射性，即当带有水印的生成图像被用于训练另一个图像生成模型时，第二个模型的输出也将携带该水印。即使仅使用我们的BitMark水印的图像对扩散或图像自回归模型进行微调，放射性痕迹仍然可检测。总的来说，我们的方法通过实现对生成输出的可靠检测，为防止图像生成模型中的模型崩溃提供了原则性的一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [390] [ReME: A Data-Centric Framework for Training-Free Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.21233)
> *ReME：一个用于免训练开放词汇分割的数据中心框架*

*Xiwei Xuan, Ziquan Deng, Kwan-Liu Ma* | **Category: cs.CV**

**Keywords:** 开放词汇分割, 免训练, 数据中心, 语义分割, 参考集

**Comment:** Accepted to ICCV 2025

> **TL;DR:** ReME是一个数据中心框架，通过构建高质量的参考集和简单的相似性检索，显著提升了免训练开放词汇语义分割的性能，超越了现有方法。

**AI_Comments:** 本文的创新点在于将研究重心从复杂的模型设计转向了数据质量，特别是在免训练开放词汇分割这一领域，强调了高质量参考集的重要性。这种“数据中心”的方法为OVS提供了一个新的视角和有效的解决方案，其简单而有效的设计理念值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的免训练开放词汇语义分割（OVS）解决方案性能受限于其依赖模型的能力或参考集的次优质量。本文旨在解决这一被忽视的数据质量问题，以提升OVS性能。

**Method:** 本文提出了一个以数据质量为导向的框架ReME，包含一个数据管道用于构建具有良好配对片段-文本嵌入的参考集，以及一个简单的基于相似性的检索方法来揭示数据的本质作用。

**Result:** 在十个基准数据集上进行的广泛评估表明，ReME方法优于所有现有的免训练OVS方法。

**Conclusion:** 高质量的参考集和以数据为中心的设计对于推进免训练开放词汇语义分割至关重要。

> **ai_Abstract:** 该论文提出了ReME，一个用于免训练开放词汇语义分割的数据中心框架。针对现有方法受限于模型能力或参考集质量的问题，ReME关注数据质量，通过构建高质量的参考集和采用简单的相似性检索，显著提升了分割性能。实验证明，ReME在多个基准数据集上超越了现有所有免训练OVS方法，强调了数据中心设计的重要性。

> **摘要翻译:** 免训练开放词汇语义分割（OVS）旨在在不进行昂贵的模型微调的情况下，根据一组任意的文本类别对图像进行分割。现有解决方案通常探索预训练模型（如CLIP）的注意力机制，或者生成合成数据并设计复杂的检索过程来执行OVS。然而，它们的性能受限于所依赖模型的能力或参考集的次优质量。在这项工作中，我们研究了针对这一具有挑战性的密集场景理解任务中，在很大程度上被忽视的数据质量问题，并发现高质量的参考集可以显著有益于免训练OVS。基于这一观察，我们引入了一个以数据质量为导向的框架，包括一个数据管道来构建具有良好配对片段-文本嵌入的参考集，以及一个简单的基于相似性的检索来揭示数据的本质作用。值得注意的是，在十个基准数据集上的广泛评估表明，我们的方法优于所有现有的免训练OVS方法，突显了以数据为中心的设计对于无需训练即可推进OVS的重要性。我们的代码可在https://github.com/xiweix/ReME 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [392] [DiMPLe -- Disentangled Multi-Modal Prompt Learning: Enhancing Out-Of-Distribution Alignment with Invariant and Spurious Feature Separation](https://arxiv.org/abs/2506.21237)
> *DiMPLe -- 解耦多模态提示学习：通过不变性和虚假特征分离增强分布外对齐*

*Umaima Rahman, Mohammad Yaqub, Dwarikanath Mahapatra* | **Category: cs.CV**

**Keywords:** 多模态学习, 特征解耦, 分布外泛化, 提示学习, 虚假相关性

**Comment:** 

> **TL;DR:** DiMPLe通过解耦视觉和语言模态中的不变性和虚假特征，提高了多模态学习的分布外泛化能力。

**AI_Comments:** DiMPLe的创新之处在于其首次提出了在多模态学习中同时在模态内和跨模态解耦不变和虚假特征的方法，这对于提升模型在复杂真实世界场景中的分布外泛化能力和鲁棒性至关重要。其三项关键目标的设计也体现了对特征鲁棒性和判别性的深刻理解。

<details>
  <summary>Details</summary>

**Motivation:** 视觉数据中的虚假相关性阻碍了分布外（OOD）性能，现有方法主要关注图像特征，未能有效解决跨模态的特征解耦问题。

**Method:** DiMPLe结合了三个关键目标：1) 不变特征和虚假特征之间的互信息最小化；2) 虚假特征正则化；3) 不变特征上的对比学习。它在模态内和跨模态解耦特征，同时保持一致的对齐。

**Result:** DiMPLe在11个不同数据集上的平均表现优于CoOp-OOD，在基类准确率上取得了15.27的绝对增益，在新类准确率上取得了44.31的绝对增益。

**Conclusion:** DiMPLe通过有效解耦多模态数据中的不变性和虚假特征，显著提升了模型在分布外场景下的泛化能力和鲁棒性。

> **ai_Abstract:** 本文提出了DiMPLe，一种解耦多模态提示学习方法，旨在解决多模态学习中视觉和语言模态间的虚假相关性问题。DiMPLe通过在模态内和跨模态分离不变和虚假特征，并结合互信息最小化、虚假特征正则化和对比学习，显著提升了模型在分布外场景下对新类别的泛化能力和对分布偏移的鲁棒性。实验证明DiMPLe在多项数据集上表现优异，尤其在新旧类别准确率上取得显著提升。

> **摘要翻译:** 我们引入了DiMPLe（解耦多模态提示学习），这是一种在多模态学习中解耦视觉和语言模态中的不变特征和虚假特征的新方法。视觉数据中的虚假相关性通常会阻碍分布外（OOD）性能。与以往仅关注图像特征的方法不同，DiMPLe在模态内部和跨模态解耦特征，同时保持一致的对齐，从而能够更好地泛化到新类别并对分布偏移具有鲁棒性。我们的方法结合了三个关键目标：（1）不变特征和虚假特征之间的互信息最小化，（2）虚假特征正则化，以及（3）不变特征上的对比学习。广泛的实验表明，DiMPLe在11个不同数据集上的平均表现优于CoOp-OOD，并在基类准确率上取得了15.27的绝对增益，在新类准确率上取得了44.31的绝对增益。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [Temporal Rate Reduction Clustering for Human Motion Segmentation](https://arxiv.org/abs/2506.21249)
> *用于人体运动分割的时间速率降低聚类*

*Xianghan Meng, Zhengyu Tong, Zhiyuan Huang, Chun-Guang Li* | **Category: cs.CV**

**Keywords:** 人体运动分割, 时间速率降低聚类, 子空间聚类, 结构化表示, 视频分析

**Comment:** The paper is accepted by ICCV 2025. The first two authors are equally
  contributed

> **TL;DR:** 针对人体运动分割，本文提出了一种名为TR2C的新方法，通过学习结构化表示和亲和力来解决传统子空间聚类在复杂背景下UoS假设不佳的问题，并在基准数据集上取得了最先进的性能。

**AI_Comments:** 这篇论文的创新点在于提出了TR2C，它通过联合学习结构化表示和亲和力来克服传统子空间聚类方法在处理复杂人体运动和杂乱背景时UoS假设失效的局限性。其核心思想是学习到时间一致且与UoS结构良好对齐的表示，这对于提高人体运动分割的准确性至关重要。论文通过在多个基准数据集上取得最先进的性能，验证了其方法的有效性和普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体运动分割（HMS）方法主要由子空间聚类方法主导，这些方法基于高维时间数据与子空间联合（UoS）分布对齐的假设。然而，在具有杂乱背景的视频中捕获复杂人体运动的帧可能无法很好地与UoS分布对齐，这限制了现有方法的性能。

**Method:** 本文提出了一种新颖的HMS方法，命名为时间速率降低聚类（Temporal Rate Reduction Clustering, TR2C）。TR2C通过联合学习结构化表示和亲和力来分割视频中的帧序列。具体而言，TR2C学习到的结构化表示能够保持时间上的一致性，并良好地与UoS结构对齐，这有利于HMS任务。

**Result:** TR2C在五个基准HMS数据集上进行了广泛的实验，并使用不同的特征提取器取得了最先进的性能。

**Conclusion:** TR2C通过学习时间一致且与UoS结构良好对齐的结构化表示，有效解决了复杂背景下人体运动分割的挑战，并在多个基准数据集上展现出卓越的性能。

> **ai_Abstract:** 本文提出了一种新颖的人体运动分割（HMS）方法——时间速率降低聚类（TR2C），旨在解决传统子空间聚类方法在复杂背景下UoS假设失效的问题。TR2C通过联合学习时间一致且与UoS结构良好对齐的结构化表示以及亲和力，实现对视频帧序列的有效分割。实验结果表明，TR2C在多个基准HMS数据集上均达到了最先进的性能。

> **摘要翻译:** 人体运动分割（HMS）旨在将视频划分为非重叠的人体运动，最近引起了越来越多的研究关注。现有的HMS方法主要由子空间聚类方法主导，这些方法基于高维时间数据与子空间联合（UoS）分布对齐的假设。然而，在具有杂乱背景的视频中捕获复杂人体运动的帧可能无法很好地与UoS分布对齐。在本文中，我们提出了一种新颖的HMS方法，命名为时间速率降低聚类（Temporal Rate Reduction Clustering, TR2C），该方法联合学习结构化表示和亲和力以分割视频中的帧序列。具体而言，TR2C学习到的结构化表示保持时间上的一致性，并良好地与UoS结构对齐，这有利于HMS任务。我们在五个基准HMS数据集上进行了广泛的实验，并使用不同的特征提取器取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [395] [DuET: Dual Incremental Object Detection via Exemplar-Free Task Arithmetic](https://arxiv.org/abs/2506.21260)
> *DuET：通过无样本任务算术的双增量目标检测*

*Munish Monga, Vishal Chudasama, Pankaj Wasnik, Biplab Banerjee* | **Category: cs.CV**

**Keywords:** 双增量目标检测, 任务算术, 无样本, 灾难性遗忘, 域适应

**Comment:** Accepted at ICCV 2025

> **TL;DR:** DuET提出了一种双增量目标检测（DuIOD）的新范式，旨在同时处理类别和域的增量学习，且无需样本。它引入了基于任务算术的模型合并框架DuET和新的评估指标RAI，实验证明其在保留能力和适应性方面均优于现有方法。

**AI_Comments:** 这篇论文通过引入双增量目标检测（DuIOD）这一新颖且更符合现实的设定，解决了当前增量目标检测领域的关键挑战。DuET作为其提出的解决方案，其基于任务算术的模型合并框架具有创新性，并且其检测器无关的特性大大增强了实用性。此外，引入保留-适应性指数（RAI）为全面评估增量学习系统提供了一个新的、更完善的度量标准，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有目标检测系统在现实世界中需要持续学习新类别并适应环境变化，但现有的类别增量目标检测（CIOD）和域增量目标检测（DIOD）方法各自存在局限性：CIOD在未见过的域中表现不佳，而DIOD在学习新类别时面临灾难性遗忘。为了解决这些问题，论文提出了更实用的双增量目标检测（DuIOD）设置，以同时处理类别和域的变化。

**Method:** 论文提出了DuET，一个基于任务算术的模型合并框架，该框架通过新颖的方向一致性损失（Directional Consistency Loss）来缓解符号冲突，从而实现稳定的增量学习。DuET是检测器无关的，能够将YOLO11和RT-DETR等模型用作实时增量目标检测器。为了全面评估模型的保留能力和适应性，论文引入了保留-适应性指数（RAI），该指数结合了用于灾难性遗忘的平均保留指数（Avg RI）和用于域适应性的平均泛化指数。

**Result:** 在Pascal系列（4个任务）和多样化天气系列（3个任务）上的大量实验表明DuET的有效性。DuET在Pascal系列上实现了+13.12%的RAI提升，同时保持了89.3%的Avg RI；在多样化天气系列上实现了+11.39%的RAI提升，同时保持了88.57%的Avg RI，均优于现有方法。

**Conclusion:** DuET有效解决了双增量目标检测的挑战，通过其基于任务算术的框架和新评估指标，在同时处理类别和域变化方面表现出色，显著优于现有方法。

> **ai_Abstract:** DuET解决了现有增量目标检测方法在同时处理类别和域变化方面的局限性。论文提出了双增量目标检测（DuIOD）这一更实用的设置，并引入了DuET，一个基于任务算术、检测器无关的模型合并框架，该框架利用方向一致性损失来稳定学习。此外，还提出了保留-适应性指数（RAI）以全面评估模型性能。实验结果表明，DuET在多项任务中显著提高了RAI，并有效保持了对旧知识的保留能力，性能优于现有方法。

> **摘要翻译:** 现实世界中的目标检测系统，例如自动驾驶和监控系统中的，必须持续学习新的目标类别并同时适应不断变化的环境条件。现有的方法，即类别增量目标检测（CIOD）和域增量目标检测（DIOD）仅解决了这一挑战的一个方面。CIOD在未见过的域中表现不佳，而DIOD在学习新类别时遭受灾难性遗忘，这限制了它们在现实世界中的适用性。为了克服这些限制，我们引入了双增量目标检测（DuIOD），这是一种更实用的设置，可以以无样本的方式同时处理类别和域的漂移。我们提出了DuET，一个基于任务算术的模型合并框架，该框架通过新颖的方向一致性损失（Directional Consistency Loss）来缓解符号冲突，从而实现稳定的增量学习。与现有方法不同，DuET是检测器无关的，允许YOLO11和RT-DETR等模型作为实时增量目标检测器运行。为了全面评估保留能力和适应性，我们引入了保留-适应性指数（RAI），该指数将用于灾难性遗忘的平均保留指数（Avg RI）和用于域适应性的平均泛化指数结合到一个共同的基础中。在Pascal系列和多样化天气系列上的大量实验证明了DuET的有效性，在Pascal系列（4个任务）上实现了+13.12%的RAI提升，同时保持了89.3%的Avg RI，以及在多样化天气系列（3个任务）上实现了+11.39%的RAI提升，同时保持了88.57%的Avg RI，均优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [397] [Video Virtual Try-on with Conditional Diffusion Transformer Inpainter](https://arxiv.org/abs/2506.21270)
> *基于条件扩散Transformer修复器的视频虚拟试穿*

*Cheng Zou, Senlin Cheng, Bolei Xu, Dandan Zheng, Xiaobo Li, Jingdong Chen, Ming Yang* | **Category: cs.CV**

**Keywords:** 视频虚拟试穿, 条件扩散Transformer, 视频修复, 时空一致性, ViTI

**Comment:** 10 pages, 6 figures

> **TL;DR:** 本文提出ViTI，一个将视频虚拟试穿视为条件视频修复任务的新方法，通过扩散Transformer实现，解决了现有方法的时空不一致问题并提升了试穿效果。

**AI_Comments:** ViTI的创新之处在于将视频虚拟试穿任务从传统的图像或简单视频适应方法，转换到更根本的条件视频修复问题。通过利用扩散Transformer的3D时空注意力，它从根本上解决了视频任务中常见的时空不一致性问题，这比简单地添加时间注意力更具优势。多阶段训练和遮罩策略的结合也显示了其在处理复杂视频内容方面的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 视频虚拟试穿是一个挑战性任务，要求输出视频具有良好的时空一致性，并保留服装细节。现有图像基或扩散基方法在帧间一致性上存在问题。

**Method:** 本文提出ViTI（Video Try-on Inpainter），将视频虚拟试穿建模为条件视频修复任务。首先，构建基于具有3D时空注意力的扩散Transformer的视频修复框架；然后，通过一系列遮罩策略和多阶段训练，逐步将其应用于视频服装修复，以在遮罩区域填充适当的服装像素并保持良好的时空一致性；最后，加入服装条件以确保修复后的服装外观和细节符合预期。

**Result:** 定量和定性实验结果表明，ViTI优于现有工作。

**Conclusion:** ViTI通过将视频虚拟试穿重新定义为条件视频修复任务，并利用扩散Transformer和多阶段训练，有效地解决了时空一致性问题，显著提升了视频虚拟试穿的效果。

> **ai_Abstract:** 本文提出了一种名为ViTI的视频虚拟试穿新方法，将该任务重新定义为条件视频修复。针对现有方法在时空一致性上的不足，ViTI基于扩散Transformer构建了一个具有完整3D时空注意力的视频修复框架，并通过多阶段训练和遮罩策略逐步适应服装修复。该方法从视频生成角度出发，有效解决了帧间不一致性问题，并能根据服装条件生成高质量的试穿视频，实验证明其性能优于现有技术。

> **摘要翻译:** 视频虚拟试穿旨在将一件服装自然地适配到连续视频帧中的目标人物。这是一项具有挑战性的任务，一方面，输出视频应具有良好的时空一致性；另一方面，给定服装的细节需要在所有帧中得到很好的保留。简单地逐帧使用基于图像的试穿方法会因为严重的不一致性而得到糟糕的结果。最近基于扩散的视频试穿方法，尽管数量很少，却不约而同地采用了一种相似的解决方案：在基于图像的试穿模型中插入时间注意力以使其适应视频试穿任务，这虽然有所改进，但仍然存在不一致性问题。在本文中，我们提出了ViTI（Video Try-on Inpainter），将视频虚拟试穿表述并实现为条件视频修复任务，这与以往的方法不同。通过这种方式，我们从视频生成问题而不是基于图像的试穿问题开始，这从一开始就具有更好的时空一致性。具体来说，我们首先构建了一个基于具有完整3D时空注意力的扩散Transformer的视频修复框架，然后通过一系列遮罩策略和多阶段训练，逐步将其应用于视频服装修复。经过这些步骤后，模型可以根据提示使用适当的服装像素修复遮罩的服装区域，并具有良好的时空一致性。最后，像其他试穿方法一样，将服装条件添加到模型中，以确保修复后的服装外观和细节符合预期。定量和定性实验结果均表明ViTI优于现有工作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [399] [WordCon: Word-level Typography Control in Scene Text Rendering](https://arxiv.org/abs/2506.21276)
> *WordCon：场景文本渲染中的词级排版控制*

*Wenda Shi, Yiren Song, Zihan Rao, Dengming Zhang, Jiaming Liu, Xingxing Zou* | **Category: cs.CV**

**Keywords:** 词级排版控制, 场景文本渲染, 参数高效微调, 文本-图像对齐, WordCon

**Comment:** 

> **TL;DR:** 提出了WordCon，一种混合PEFT方法，用于解决生成图像中词级排版控制的挑战，通过新的数据集、TIA框架和特定损失函数，实现了优于现有技术的效果。

**AI_Comments:** 这篇论文通过引入新的数据集、创新的TIA框架以及高效的WordCon PEFT方法，显著提升了生成图像中词级排版控制的能力。其对效率和可移植性的关注，以及通过特定损失函数（掩蔽损失和联合注意力损失）增强可控性的设计，都体现了其创新性。该方法在艺术文本渲染、文本编辑等领域的潜在应用价值很高，解决了文本生成领域的一个重要痛点。

<details>
  <summary>Details</summary>

**Motivation:** 在生成的图像中实现精确的词级排版控制仍然是一个持续存在的挑战。

**Method:** 1. 构建了一个新的词级受控场景文本数据集。2. 引入了文本-图像对齐（TIA）框架，该框架利用接地模型提供的文本和局部图像区域之间的跨模态对应关系来增强文本到图像（T2I）模型的训练。3. 提出了WordCon，一种混合参数高效微调（PEFT）方法，通过重新参数化选择性关键参数来提高效率和可移植性。4. 应用潜在层面的掩蔽损失来引导模型专注于学习图像中的文本区域。5. 应用联合注意力损失提供特征级监督，以促进不同单词之间的解耦。

**Result:** 定性和定量结果均表明该方法优于现有技术。

**Conclusion:** 通过构建新的数据集、引入TIA框架和提出WordCon（一种混合PEFT方法），并结合特定的损失函数，成功解决了生成图像中词级排版控制的挑战，并实现了最先进的性能。

> **ai_Abstract:** 本文旨在解决生成图像中词级排版控制的难题。为此，作者构建了一个新的词级受控场景文本数据集，并提出了文本-图像对齐（TIA）框架，该框架利用跨模态对应关系增强T2I模型训练。此外，还引入了WordCon，一种混合参数高效微调（PEFT）方法，通过重新参数化关键参数提升效率和可移植性，使其可集成到多种文本渲染和编辑流程中。为了增强控制力，模型还采用了潜在层面的掩蔽损失和联合注意力损失。实验结果表明，该方法在定性和定量上均优于现有技术。

> **摘要翻译:** 在生成的图像中实现精确的词级排版控制仍然是一个持续存在的挑战。为了解决这个问题，我们新建了一个词级受控场景文本数据集，并引入了文本-图像对齐（TIA）框架。该框架利用接地模型提供的文本和局部图像区域之间的跨模态对应关系，以增强文本到图像（T2I）模型的训练。此外，我们提出了WordCon，一种混合参数高效微调（PEFT）方法。WordCon重新参数化选择性关键参数，提高了效率和可移植性。这使得它能够无缝集成到各种管道中，包括艺术文本渲染、文本编辑和图像条件文本渲染。为了进一步增强可控性，应用了潜在层面的掩蔽损失来引导模型集中学习图像中的文本区域，并且联合注意力损失提供了特征级监督，以促进不同单词之间的解耦。定性和定量结果均表明我们的方法优于现有技术。数据集和源代码将可用于学术用途。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [401] [HieraSurg: Hierarchy-Aware Diffusion Model for Surgical Video Generation](https://arxiv.org/abs/2506.21287)
> *HieraSurg：层级感知扩散模型用于外科手术视频生成*

*Diego Biagini, Nassir Navab, Azade Farshad* | **Category: cs.CV**

**Keywords:** 外科手术视频生成, 扩散模型, 层级感知, 语义分割, 视频合成

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** HieraSurg是一个层级感知的扩散模型，用于生成高质量的外科手术视频，解决了现有模型缺乏手术理解和精细指导的问题，并通过两阶段扩散模型整合了粗粒度语义变化和细粒度视觉特征。

**AI_Comments:** HieraSurg的创新之处在于其“层级感知”的设计，通过结合粗粒度语义预测和细粒度视觉渲染，有效地解决了传统扩散模型在外科手术视频生成中缺乏手术理解和一致性的问题。这种分阶段、多层次信息整合的方法显著提升了生成视频的真实性和实用性，为外科手术模拟和训练提供了更可靠的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有外科手术视频生成方法大多是无条件的，无法保持与手术动作和阶段的一致性，缺乏手术理解和精细指导，导致模拟不够真实。

**Method:** 提出HieraSurg框架，包含两个专门的扩散模型。首先，给定手术阶段和初始帧，一个分割预测模型预测未来粗粒度语义变化。然后，第二个模型通过细化这些时间分割图的视觉特征，生成最终视频，实现有效的纹理渲染和语义信息整合。该方法利用了手术阶段、动作三元组和全景分割图等多层次抽象的手术信息。

**Result:** 在胆囊切除术视频生成上的实验结果表明，该模型在定量和定性上均显著优于现有工作，显示出强大的泛化能力和生成更高帧率视频的能力。在提供现有分割图时，模型表现出特别精细的依从性。

**Conclusion:** HieraSurg通过整合多层级手术信息，能够生成高质量、高帧率且与手术过程高度一致的视频，在外科手术模拟和实际应用中具有巨大潜力。

> **ai_Abstract:** HieraSurg是一个创新的层级感知扩散模型框架，旨在解决现有外科手术视频生成模型在手术一致性和精细指导方面的不足。它通过两阶段扩散过程，首先预测粗粒度语义变化，然后整合细粒度视觉特征，利用多层次手术信息（如阶段、动作、分割图）生成高质量、与手术过程一致的视频。实验证明，HieraSurg在性能上显著优于现有方法，并展现出在实际外科应用中的巨大潜力。

> **摘要翻译:** 外科手术视频合成已成为一个有前景的研究方向，这得益于扩散模型在通用领域视频生成方面的成功。尽管现有方法实现了高质量的视频生成，但大多数是无条件的，未能保持与手术动作和阶段的一致性，缺乏外科理解和精细指导，这对于真实的模拟是必需的。我们通过提出HieraSurg来解决这些挑战，HieraSurg是一个层级感知的外科手术视频生成框架，由两个专门的扩散模型组成。给定一个手术阶段和初始帧，HieraSurg首先通过一个分割预测模型预测未来的粗粒度语义变化。然后，第二个模型通过用细粒度视觉特征增强这些时间分割图来生成最终视频，从而在视频空间中实现有效的纹理渲染和语义信息整合。我们的方法利用了多层抽象的手术信息，包括手术阶段、动作三元组和全景分割图。在胆囊切除术外科手术视频生成上的实验结果表明，该模型在定量和定性上均显著优于现有工作，显示出强大的泛化能力和生成更高帧率视频的能力。当提供现有分割图时，模型表现出特别精细的依从性，这表明其在实际外科手术应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [403] [Continual Self-Supervised Learning with Masked Autoencoders in Remote Sensing](https://arxiv.org/abs/2506.21312)
> *遥感中基于掩码自编码器的持续自监督学习*

*Lars Möllenbrok, Behnood Rasti, Begüm Demir* | **Category: cs.CV**

**Keywords:** 持续学习, 自监督学习, 掩码自编码器, 遥感, 灾难性遗忘

**Comment:** Accepted to IEEE Geoscience and Remote Sensing Letters. Our code is
  available at https://git.tu-berlin.de/rsim/CoSMAE

> **TL;DR:** 本文提出CoSMAE，一种用于遥感的持续自监督学习方法，通过数据混合和模型混合知识蒸馏，在不依赖大量标注数据的情况下，有效缓解灾难性遗忘，并显著提升了性能。

**AI_Comments:** CoSMAE的创新之处在于将自监督学习与持续学习相结合，并通过独特的数据混合和模型混合知识蒸馏策略，在不依赖大量标注数据的情况下有效解决了灾难性遗忘问题。这对于遥感这种数据标注成本高昂的领域具有重要意义。该方法通过在数据和模型双重层面进行正则化，为持续学习提供了一种新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有的遥感持续学习（CL）方法在学习新任务时，虽然能增强对灾难性遗忘的鲁棒性，但需要大量标注训练样本，这在遥感领域成本高昂且不总是可行。

**Method:** 提出了一种名为CoSMAE的持续自监督学习方法，该方法基于掩码自编码器（MAE），包含两个主要组件：1）数据混合：通过插值当前任务图像与之前任务图像来保留先前数据分布的信息；2）模型混合知识蒸馏：通过插值过去模型和当前模型的权重来形成一个教师模型，从而同时从它们中提取知识。这两个组件相互补充，在数据和模型层面规范MAE，以促进更好的跨任务泛化并降低灾难性遗忘的风险。

**Result:** 实验结果表明，CoSMAE比应用于MAE的现有最先进的持续学习方法实现了显著改进，性能提升高达4.94%。

**Conclusion:** CoSMAE通过数据混合和模型混合知识蒸馏，在数据和模型层面有效规范了掩码自编码器，从而在遥感持续学习中，无需大量标注样本即可有效缓解灾难性遗忘并提升跨任务泛化能力。

> **ai_Abstract:** 本文针对遥感领域持续学习中对大量标注数据的依赖问题，提出了一种名为CoSMAE的持续自监督学习方法。CoSMAE基于掩码自编码器，并通过数据混合和模型混合知识蒸馏两个核心组件来缓解灾难性遗忘。数据混合通过插值不同任务数据来保留旧知识，模型混合知识蒸馏则通过组合新旧模型权重来指导学习。实验证明，CoSMAE在性能上优于现有方法，提升高达4.94%，有效提高了跨任务泛化能力。

> **摘要翻译:** 持续学习（CL）方法的发展在遥感（RS）领域受到了广泛关注，其目标是以序列方式从持续获取的训练数据中学习新任务。遥感中现有的CL方法在学习新任务时，增强了对灾难性遗忘的鲁棒性。这通常通过使用大量标注训练样本来实现，但这在遥感中成本高昂且不总是可行。为了解决这个问题，我们提出了一种在掩码自编码器背景下的新型持续自监督学习方法（记为CoSMAE）。所提出的CoSMAE包含两个组件：i）数据混合；ii）模型混合知识蒸馏。数据混合与通过插值当前任务的图像与先前任务的图像来保留先前数据分布信息有关。模型混合知识蒸馏与通过插值过去模型和当前模型的权重来形成一个用于知识蒸馏的教师模型，从而同时从它们中提取知识有关。这两个组件相互补充，在数据和模型层面规范MAE，以促进更好的跨任务泛化并降低灾难性遗忘的风险。实验结果表明，CoSMAE比应用于MAE的最先进的CL方法实现了显著改进，性能提升高达4.94%。我们的代码已公开可用：https://git.tu-berlin.de/rsim/CoSMAE。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [DrishtiKon: Multi-Granular Visual Grounding for Text-Rich Document Images](https://arxiv.org/abs/2506.21316)
> *DrishtiKon: 文本丰富文档图像的多粒度视觉定位*

*Badri Vishal Kasuba, Parag Chaudhuri, Ganesh Ramakrishnan* | **Category: cs.CV**

**Keywords:** 视觉定位, 文档图像, 多粒度, 视觉问答, OCR

**Comment:** Work in progress

> **TL;DR:** DrishtiKon是一个多粒度视觉定位框架，用于提高文本丰富文档图像中VQA的可解释性和准确性。

**AI_Comments:** 这篇论文的创新点在于提出了一个多粒度视觉定位框架DrishtiKon，能够处理文本丰富的文档图像，并在不同粒度级别（块、行、单词、点）进行精确的答案定位。其结合多语言OCR、LLM和新颖区域匹配算法的方法是独到的。该研究通过解决当前VLM在精确本地化方面的局限性，显著提升了文档理解和VQA系统的性能和可解释性，对于现实世界的文本中心应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 文本丰富文档图像中的视觉定位是文档智能和视觉问答（VQA）系统中的一个关键但尚未充分探索的挑战。现有视觉-语言模型（VLM）在精确本地化方面存在局限性。

**Method:** 提出了DrishtiKon框架，该框架集成了强大的多语言OCR、大型语言模型和新颖的区域匹配算法，以在块、行、单词和点级别准确本地化答案跨度。同时，从CircularsVQA测试集中整理了一个新的基准数据集，提供了细粒度、人工验证的注释。

**Result:** 该方法实现了最先进的定位精度，其中行级别粒度在精度和召回率之间提供了最佳权衡。消融研究进一步突出了多块和多行推理的好处。与领先的视觉-语言模型进行比较评估，揭示了当前VLM在精确本地化方面的局限性，并突显了DrishtiKon结构化、基于对齐的方法的有效性。

**Conclusion:** DrishtiKon为在现实世界的文本中心场景中构建更稳健和可解释的文档理解系统铺平了道路。

> **ai_Abstract:** 本文提出了DrishtiKon，一个用于文本丰富文档图像的多粒度视觉定位框架，旨在提高视觉问答（VQA）系统的可解释性和信任度。该框架结合了多语言OCR、大型语言模型和新颖的区域匹配算法，能够在块、行、单词和点等不同粒度级别精确本地化答案。通过创建新的基准数据集并进行广泛实验，DrishtiKon展示了最先进的定位精度，特别是在行级别粒度上表现出最佳的精度与召回率平衡，并优于现有视觉-语言模型，为更稳健的文档理解系统奠定了基础。

> **摘要翻译:** 文本丰富文档图像中的视觉定位是文档智能和视觉问答（VQA）系统中的一个关键但尚未充分探索的挑战。我们提出了\drishtikon，一个多粒度视觉定位框架，旨在增强复杂多语言文档中VQA的可解释性和信任度。我们的方法集成了强大的多语言OCR、大型语言模型和新颖的区域匹配算法，以在块、行、单词和点级别准确本地化答案跨度。我们从CircularsVQA测试集中整理了一个新的基准数据集，提供了跨多个粒度的细粒度、人工验证的注释。大量的实验表明，我们的方法实现了最先进的定位精度，其中行级别粒度在精度和召回率之间提供了最佳权衡。消融研究进一步强调了多块和多行推理的好处。与领先的视觉-语言模型的比较评估揭示了当前VLM在精确本地化方面的局限性，突显了我们结构化、基于对齐的方法的有效性。我们的发现为在现实世界的文本中心场景中构建更稳健和可解释的文档理解系统铺平了道路。代码和数据集已在https://github.com/kasuba-badri-vishal/DhrishtiKon 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [Transferring disentangled representations: bridging the gap between synthetic and real images](https://arxiv.org/abs/2409.18017)
> *解耦表示迁移：弥合合成图像与真实图像之间的鸿沟*

*Jacopo Dapueto, Nicoletta Noceti, Francesca Odone* | **Category: cs.CV, cs.AI, cs.LG**

**Keywords:** 解耦表示学习, 合成数据, 真实图像, 迁移学习, 评估指标

**Comment:** Accepted to NeurIPS, 2024

> **TL;DR:** 研究如何将从合成数据中学到的解耦表示迁移到真实图像，并提出新的评估指标，结果表明这种迁移是可行且有效的。

**AI_Comments:** 该论文的创新点在于提出了将解耦表示从合成数据迁移到真实图像的策略，并引入了新的评估指标。这对于解决真实世界数据中解耦表示学习的挑战具有重要意义，尤其是在真实标签稀缺的场景下。其贡献在于证明了在一定程度上，合成数据可以作为真实数据解耦表示学习的有效替代或辅助。

<details>
  <summary>Details</summary>

**Motivation:** 解耦表示学习在真实图像上未能充分发挥潜力，因为生成因素相关、分辨率问题以及难以获取真实标签。本文旨在利用合成数据学习通用解耦表示并应用于真实数据，以弥合合成与真实图像之间的差距。

**Method:** 通过广泛的实证研究，探讨了利用合成数据学习通用解耦表示并应用于真实数据的可能性，讨论了微调的效果以及迁移后解耦属性的保留情况。此外，提出了一种新的基于干预的可解释度量来衡量表示中因子编码的质量。

**Result:** 结果表明，将解耦表示从合成数据迁移到真实数据在一定程度上是可能且有效的。

**Conclusion:** 从合成数据迁移解耦表示到真实数据是可行且有效的，这有助于解决真实图像上解耦表示学习的挑战。

> **ai_Abstract:** 该研究探讨了如何将从合成数据中学到的解耦表示迁移到真实图像，以克服真实图像中解耦学习面临的挑战，如相关生成因素和缺乏真实标签。文章通过广泛的实证研究，分析了微调和解耦属性的保留情况，并提出了一种新的基于干预的可解释度量来评估因子编码质量。研究结果表明，将解耦表示从合成数据迁移到真实数据是可行且有效的，为弥合合成与真实图像之间的差距提供了新途径。

> **摘要翻译:** 开发有意义且高效的表示，以分离数据生成机制的基本结构，在表示学习中至关重要。然而，解耦表示学习尚未在真实图像上充分展示其潜力，原因在于生成因素相关性、其分辨率以及真实标签的有限获取。特别是针对后者，我们研究了利用合成数据学习适用于真实数据的通用解耦表示的可能性，讨论了微调的效果以及迁移后解耦属性的保留情况。我们提供了广泛的实证研究来解决这些问题。此外，我们提出了一种新的可解释的基于干预的度量，用于衡量表示中因子编码的质量。我们的结果表明，将解耦表示从合成数据迁移到真实数据，在一定程度上是可能且有效的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [408] [LLaVA-Pose: Enhancing Human Pose and Action Understanding via Keypoint-Integrated Instruction Tuning](https://arxiv.org/abs/2506.21317)
> *LLaVA-Pose：通过关键点集成指令微调增强人体姿态和动作理解*

*Dewen Zhang, Tahir Hussain, Wangpeng An, Hayaru Shouno* | **Category: cs.CV**

**Keywords:** 视觉语言模型, 人体姿态, 动作理解, 关键点集成, 指令微调

**Comment:** arXiv admin note: substantial text overlap with arXiv:2409.09306

> **TL;DR:** LLaVA-Pose通过整合人体关键点数据对VLM进行指令微调，显著提升了模型在人体姿态和动作理解上的表现，相比LLaVA-1.5-7B有33.2%的提升。

**AI_Comments:** 这篇论文的创新点在于提出了将人体关键点集成到视觉-语言指令微调数据中的方法，从而专门解决了现有VLM在人体姿态和动作理解方面的局限性。通过构建大规模的专业数据集和新的评估基准（E-HPAUB），为该领域的研究提供了宝贵的资源和评估工具。其显著的性能提升证明了这种数据集成策略的有效性，对于推动以人为中心的视觉理解任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前视觉语言模型（VLMs）在处理复杂的人体姿态和动作相关视觉任务时表现不足，主要原因是缺乏专门的视觉语言指令遵循数据。

**Method:** 提出了一种通过将人体关键点与传统视觉特征（如图像标题和边界框）结合来生成专业数据的方法。构建了一个包含200,328个样本的数据集，用于微调模型，专注于对话、详细描述和复杂推理。建立了扩展人体姿态和动作理解基准（E-HPAUB）来评估模型性能。使用该数据集微调了LLaVA-1.5-7B模型，并将其命名为LLaVA-Pose。

**Result:** LLaVA-Pose模型在E-HPAUB基准测试中取得了显著改进，相比原始的LLaVA-1.5-7B模型，整体性能提升了33.2%。

**Conclusion:** 实验结果表明，关键点集成数据在增强多模态模型进行以人为中心的视觉理解方面是有效的。

> **ai_Abstract:** 本文针对现有视觉语言模型在人体姿态和动作理解任务上的不足，提出LLaVA-Pose模型。通过创新性地将人体关键点与传统视觉特征结合，生成了包含20万余样本的专业指令遵循数据集，并构建了E-HPAUB基准。基于该数据集对LLaVA-1.5-7B进行微调后，LLaVA-Pose在人体中心视觉理解任务上实现了33.2%的性能提升，验证了关键点集成数据在增强多模态模型方面的有效性。

> **摘要翻译:** 当前的视觉语言模型（VLMs）已很好地适应了通用视觉理解任务。然而，由于缺乏专门的视觉语言指令遵循数据，它们在处理与人体姿态和动作相关的复杂视觉任务时表现不足。我们引入了一种通过将人体关键点与传统视觉特征（如图像标题和边界框）相结合来生成此类数据的方法，从而能够更精确地理解以人为中心的场景。我们的方法构建了一个包含200,328个样本的数据集，专门用于微调以人为中心任务的模型，重点关注三个领域：对话、详细描述和复杂推理。我们建立了扩展人体姿态和动作理解基准（E-HPAUB）来评估模型在人体姿态和动作理解方面的性能。我们使用该数据集微调了LLaVA-1.5-7B模型，并在基准测试中评估了我们生成的LLaVA-Pose模型，取得了显著改进。实验结果显示，与原始的LLaVA-1.5-7B模型相比，整体性能提升了33.2%。这些发现突出了关键点集成数据在增强多模态模型以实现以人为中心的视觉理解方面的有效性。代码可在https://github.com/Ody-trek/LLaVA-Pose 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [410] [Holistic Surgical Phase Recognition with Hierarchical Input Dependent State Space Models](https://arxiv.org/abs/2506.21330)
> *基于分层输入依赖状态空间模型的整体手术阶段识别*

*Haoyang Wu, Tsun-Hsuan Wang, Mathias Lechner, Ramin Hasani, Jennifer A. Eckhoff, Paul Pak, Ozanan R. Meireles, Guy Rosman, Yutong Ban, Daniela Rus* | **Category: cs.CV, cs.AI**

**Keywords:** 手术阶段识别, 状态空间模型, 手术工作流分析, 长视频分析, 分层模型

**Comment:** 

> **TL;DR:** 本文提出了一种新型分层输入依赖状态空间模型，用于整体手术阶段识别，该模型能有效处理长视频，并在多个数据集上显著优于现有SOTA方法。

**AI_Comments:** 该论文的创新之处在于将状态空间模型应用于手术视频分析，尤其有效解决了长时序视频分析中变压器模型存在的二次复杂度问题。其分层结构设计和混合监督策略是亮点，能够同时捕获精细的局部动态和宏观的全局时间依赖。实验结果的显著提升表明了该方法在机器人辅助手术领域实际应用的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 手术工作流分析在机器人辅助手术中至关重要，但手术时长导致全面的视频分析面临巨大挑战，特别是变压器模型由于其二次注意力机制难以有效处理长时间的手术视频。

**Method:** 本文提出了一种新型分层输入依赖状态空间模型，利用状态空间模型的线性缩放特性，实现对全长视频的决策，并捕获局部和全局动态。该框架包含一个时间一致的视觉特征提取器，它在视觉特征提取器后附加一个状态空间模型头部以传播时间信息。该模型由两个关键模块组成：一个局部聚合状态空间模型块，有效捕获复杂的局部动态；一个全局关系状态空间模型块，建模整个视频的时间依赖性。模型采用混合离散-连续监督策略进行训练，其中离散阶段标签和连续阶段进度信号都通过网络传播。

**Result:** 实验表明，我们的方法在Cholec80数据集上超越现有最先进方法2.8%，在MICCAI2016数据集上超越4.3%，在Heichole数据集上超越12.9%。

**Conclusion:** 本文提出的分层输入依赖状态空间模型有效解决了长手术视频分析的挑战，通过高效捕获局部和全局动态，在整体手术阶段识别方面取得了卓越的性能。

> **ai_Abstract:** 本文提出了一种新颖的分层输入依赖状态空间模型，用于整体手术阶段识别，旨在克服传统变压器模型处理长手术视频的效率限制。该模型利用状态空间模型的线性缩放特性，能够捕捉视频的局部和全局动态。其核心包含一个时间一致的视觉特征提取器以及两个专门的状态空间模块：一个用于局部聚合，另一个用于全局关系建模。通过混合离散-连续监督策略进行训练，该方法在Cholec80、MICCAI2016和Heichole等数据集上均显著优于现有最先进的方法。

> **摘要翻译:** 手术工作流分析在机器人辅助手术中至关重要，但此类手术的长时间特性对全面的视频分析构成了重大挑战。最近的方法主要依赖于变压器模型；然而，它们的二次注意力机制限制了对冗长手术视频的有效处理。在本文中，我们提出了一种新型分层输入依赖状态空间模型，该模型利用状态空间模型的线性缩放特性，能够对全长视频进行决策，同时捕获局部和全局动态。我们的框架包含一个时间一致的视觉特征提取器，它在视觉特征提取器后附加一个状态空间模型头部以传播时间信息。所提出的模型由两个关键模块组成：一个局部聚合状态空间模型块，有效捕获复杂的局部动态；以及一个全局关系状态空间模型块，建模整个视频的时间依赖性。该模型采用混合离散-连续监督策略进行训练，其中离散阶段标签和连续阶段进度信号都通过网络传播。实验表明，我们的方法在Cholec80数据集上以2.8%的显著优势超越了当前最先进的方法，在MICCAI2016数据集上以4.3%的优势超越，在Heichole数据集上以12.9%的优势超越。代码将在论文接收后公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [411] [PanSt3R: Multi-view Consistent Panoptic Segmentation](https://arxiv.org/abs/2506.21348)
> *PanSt3R：多视角一致全景分割*

*Lojze Zust, Yohann Cabon, Juliette Marrie, Leonid Antsfeld, Boris Chidlovskii, Jerome Revaud, Gabriela Csurka* | **Category: cs.CV**

**Keywords:** 全景分割, 3D重建, 多视角一致性, 深度学习, PanSt3R

**Comment:** Accepted at ICCV 2025

> **TL;DR:** PanSt3R提出了一种统一且集成的3D全景分割方法，无需测试时优化，比现有方法快几个数量级，并在多个基准上达到最先进的性能。

**AI_Comments:** PanSt3R的创新之处在于其统一且集成的端到端方法，避免了传统方法中昂贵的测试时优化和对2D分割的次优依赖。通过将3D几何和多视角全景分割结合在单次前向传播中，该方法显著提高了效率和性能。其可扩展性以及在多个基准上达到SOTA性能，使其在3D场景理解领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D场景全景分割方法通常依赖于2D全景分割，然后进行昂贵的测试时优化来融合预测，这未能充分利用跨视图的空间关系，且计算成本高昂。

**Method:** 本文提出了PanSt3R，一种统一且集成的3D全景分割方法。它在单次前向传播中联合预测3D几何和多视角全景分割，消除了测试时优化的需求。PanSt3R基于MUSt3R（DUSt3R的可扩展多视图版本）并增强了语义感知和多视图全景分割能力。此外，它改进了标准的后处理掩码合并程序，并引入了一种基于PanSt3R和Vanilla 3DGS生成新视角预测的简单方法。

**Result:** PanSt3R在多个基准测试中取得了最先进的性能，并且比现有方法快了几个数量级。

**Conclusion:** PanSt3R是一种概念简单、快速、可扩展的3D全景分割方法，通过统一的端到端预测，解决了现有方法的效率和性能瓶颈，实现了卓越的性能。

> **ai_Abstract:** PanSt3R是一种新颖的3D场景多视角全景分割方法，旨在克服现有方法对2D分割的依赖和高昂的测试时优化成本。该方法在单次前向传播中联合预测3D几何和多视角全景分割，无需额外的优化步骤。PanSt3R基于MUSt3R并增强了语义感知能力，同时改进了多视角分割的后处理流程。它还提供了一种生成新视角预测的方法。PanSt3R在速度和可扩展性方面显著优于现有技术，并在多个基准测试中达到了最先进的性能。

> **摘要翻译:** 3D场景的全景分割，涉及场景密集3D重建中对象实例的分割和分类，是一个具有挑战性的问题，尤其是在仅依赖未定位的2D图像时。现有方法通常利用现成的模型提取每帧2D全景分割，然后优化隐式几何表示（通常基于NeRF）以整合和融合2D预测。我们认为，对于一个本质上是3D和多视角的问题，依赖2D全景分割可能不是最优的，因为它未能充分利用跨视图空间关系的全部潜力。除了需要相机参数外，这些方法还需要对每个场景进行计算成本高昂的测试时优化。相反，在这项工作中，我们提出了一种统一且集成的方法PanSt3R，它通过在单次前向传播中联合预测3D几何和多视角全景分割，消除了测试时优化的需求。我们的方法建立在3D重建的最新进展之上，特别是基于MUSt3R（DUSt3R的可扩展多视图版本），并增强了语义感知和多视角全景分割能力。我们还重新审视了标准的后处理掩码合并过程，并引入了一种更原则性的多视角分割方法。我们还介绍了一种基于PanSt3R和Vanilla 3DGS的预测生成新视角预测的简单方法。总的来说，所提出的PanSt3R概念简单，但快速且可扩展，并在多个基准上实现了最先进的性能，同时比现有方法快了几个数量级。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [ShotBench: Expert-Level Cinematic Understanding in Vision-Language Models](https://arxiv.org/abs/2506.21356)
> *ShotBench：视觉语言模型中的专家级电影理解*

*Hongbo Liu, Jingwen He, Yi Jin, Dian Zheng, Yuhao Dong, Fan Zhang, Ziqi Huang, Yinan He, Yangguang Li, Weichao Chen, Yu Qiao, Wanli Ouyang, Shengjie Zhao, Ziwei Liu* | **Category: cs.CV**

**Keywords:** 电影理解, 视觉语言模型, 基准测试, 数据集, 电影摄影

**Comment:** 

> **TL;DR:** 本文介绍了ShotBench，一个用于评估视觉语言模型（VLMs）电影理解能力的基准，发现现有VLMs表现不佳。为解决此问题，构建了ShotQA数据集并开发了ShotVL模型，显著提升了电影理解的最新水平。

**AI_Comments:** 本文通过引入专门的基准测试和大规模数据集，系统地揭示了现有视觉语言模型在电影理解这一特定且复杂的领域中的局限性。其创新点在于将电影摄影的专业知识量化为可评估的维度，并提出了一个有效提升模型性能的方法，对推动AI在电影内容创作和分析方面的应用具有重要意义。开源数据和模型的举措将极大促进该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉语言模型（VLMs）在理解电影中细致的电影语法方面能力不足且缺乏稳健的评估，这限制了细粒度视觉理解和AI辅助视频生成的精度。

**Method:** 引入了ShotBench，一个包含3.5k专家标注QA对的综合电影语言理解基准。构建了ShotQA，一个包含约70k电影QA对的大规模多模态数据集。利用ShotQA，通过监督微调和群组相对策略优化开发了ShotVL模型。

**Result:** 在ShotBench上评估了24个领先的VLM，发现它们存在显著局限性，即使表现最好的模型平均准确率也低于60%，尤其在细粒度视觉线索和复杂空间推理方面表现不佳。ShotVL在ShotBench上显著优于所有现有开源和专有模型，建立了新的最先进（SOTA）性能。

**Conclusion:** 现有VLMs在电影理解方面存在显著不足。本文引入的ShotBench、ShotQA和ShotVL为推动AI驱动的电影理解和生成领域的进步提供了关键的工具和方法。

> **ai_Abstract:** 本文介绍了ShotBench，一个用于评估视觉语言模型（VLMs）电影理解能力的综合基准，并揭示了现有VLMs在该领域的显著不足。为弥补这一差距，作者构建了大规模电影问答数据集ShotQA，并基于此开发了ShotVL模型。ShotVL通过监督微调和群组相对策略优化，在ShotBench上取得了超越现有模型的SOTA性能，为AI驱动的电影理解和生成提供了重要进展。

> **摘要翻译:** 电影摄影作为电影最基本的视觉语言，对于传达叙事、情感和美学质量至关重要。尽管最近的视觉语言模型（VLMs）在通用视觉理解方面表现出强大的能力，但它们在理解单个镜头中嵌入的细致电影语法方面的熟练程度在很大程度上尚未被探索，并且缺乏稳健的评估。这一关键差距限制了细粒度的视觉理解以及AI辅助视频生成的精度。为了解决这个问题，我们引入了\textbf{ShotBench}，一个专门为电影语言理解设计的综合基准。它包含来自图像和视频片段的3.5k多个专家标注的问答对，这些问答对经过精心策划，来源于200多部著名（主要是奥斯卡提名）电影，并涵盖了八个关键的电影摄影维度。我们对ShotBench上24个领先的VLM的评估揭示了它们存在的实质性局限性：即使是表现最好的模型也只达到了不到60%的平均准确率，尤其是在细粒度视觉线索和复杂空间推理方面表现挣扎。为了促进该领域的进步，我们构建了\textbf{ShotQA}，一个包含大约70k电影问答对的大规模多模态数据集。利用ShotQA，我们通过监督微调和群组相对策略优化开发了\textbf{ShotVL}。ShotVL在ShotBench上显著优于所有现有开源和专有模型，建立了新的\textbf{最先进}性能。我们开源了我们的模型、数据和代码，以促进AI驱动的电影理解和生成这一关键领域的快速发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [414] [CoPa-SG: Dense Scene Graphs with Parametric and Proto-Relations](https://arxiv.org/abs/2506.21357)
> *CoPa-SG: 密集场景图与参数化和原型关系*

*Julian Lorenz, Mrunmai Phatak, Robin Schön, Katja Ludwig, Nico Hörmann, Annemarie Friedrich, Rainer Lienhart* | **Category: cs.CV**

**Keywords:** 场景图, CoPa-SG, 参数化关系, 原型关系, 数据集

**Comment:** 

> **TL;DR:** CoPa-SG引入了一个新的合成场景图数据集，并提出了参数化关系和原型关系两种新概念，以解决现有场景图数据不足和表示粒度不够的问题，并增强下游应用能力。

**AI_Comments:** CoPa-SG通过提供一个高度精确且详尽标注的合成数据集，创新性地解决了场景图数据稀缺的瓶颈问题。更重要的是，引入参数化和原型关系的概念，极大地丰富了场景图的表达能力。参数化关系使得场景图能够捕获更细致的空间或语义信息，而原型关系则为场景图提供了预测和推理未来场景变化的能力，这对于增强规划和机器人等下游应用的智能至关重要。这项工作为未来场景图的研究和应用开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有2D场景图缺乏准确的数据，且传统关系表示粒度不够细致，无法充分支持场景理解、规划和推理。

**Method:** 1. 提出了CoPa-SG，一个合成场景图数据集，具有高精度真值和对象间详尽的关系标注。2. 引入了两种新的基本场景图概念：参数化关系（用角度、距离等参数丰富关系）和原型关系（编码假设关系，描述新对象放置时关系如何形成）。3. 使用CoPa-SG数据集比较了各种场景图生成模型的性能。4. 演示了如何将新关系类型集成到下游应用中以增强规划和推理能力。

**Result:** 1. 创建了一个具有高精度真值和详尽关系的合成场景图数据集CoPa-SG。2. 提出了参数化关系和原型关系，这两种新概念能够提供更细粒度的表示和编码假设关系。3. 使用CoPa-SG数据集比较了不同场景图生成模型的性能。4. 证明了新关系类型可以增强下游应用的规划和推理能力。

**Conclusion:** CoPa-SG数据集和提出的参数化与原型关系概念，为解决现有场景图数据不足和表示能力限制提供了有效途径，并有望提升场景理解、规划和推理等下游应用的性能。

> **ai_Abstract:** 本文针对2D场景图数据不足和关系表示粒度不够的问题，提出了CoPa-SG数据集，该数据集包含高精度真值和详尽的关系标注。同时，引入了参数化关系和原型关系两种新概念：参数化关系通过添加角度、距离等参数提供更细粒度的关系表示；原型关系编码假设性关系，描述新对象加入时关系的变化。研究使用CoPa-SG比较了现有场景图生成模型，并展示了新关系类型如何提升下游应用的规划和推理能力。

> **摘要翻译:** 2D场景图为场景理解提供了一个结构化且可解释的框架。然而，当前的工作仍在努力解决场景图数据缺乏准确性的问题。为了克服这一数据瓶颈，我们提出了CoPa-SG，一个合成场景图数据集，具有高度精确的地面真值和所有对象之间详尽的关系标注。此外，我们引入了参数化关系和原型关系，这是场景图的两个新的基本概念。前者通过用角度或距离等附加参数丰富关系，提供了比传统对应物更细粒度的表示。后者在场景图中编码假设关系，并描述了如果新对象放置在场景中，关系将如何形成。使用CoPa-SG，我们比较了各种场景图生成模型的性能。我们演示了如何将我们的新关系类型集成到下游应用中，以增强规划和推理能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [417] [CA-I2P: Channel-Adaptive Registration Network with Global Optimal Selection](https://arxiv.org/abs/2506.21364)
> *CA-I2P：通道自适应配准网络与全局最优选择*

*Zhixin Cheng, Jiacheng Deng, Xinjun Li, Xiaotian Yin, Bohao Liao, Baoqun Yin, Wenfei Yang, Tianzhu Zhang* | **Category: cs.CV, cs.AI**

**Keywords:** 图像到点云配准, 通道自适应, 全局最优选择, 跨模态匹配, CA-I2P

**Comment:** ICCV 2025 accepted

> **TL;DR:** CA-I2P通过通道自适应调整和全局最优选择，解决了图像与点云配准中的特征通道注意力差异和冗余对应问题，达到了最先进的配准性能。

**AI_Comments:** 本文通过引入通道自适应调整和全局最优选择机制，有效地解决了图像与点云配准中常见的特征差异和冗余对应问题，提升了跨模态配准的鲁棒性和准确性，具有重要的创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检测无关方法在图像和点云之间特征通道注意力差异较大，以及场景中相似结构可能导致跨模态匹配中的冗余对应，从而影响配准精度。

**Method:** 本文提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA旨在增强模态内特征并抑制跨模态敏感性，而GOS则将局部选择替换为全局优化。

**Result:** 在RGB-D Scenes V2和7-Scenes数据集上的实验表明，CA-I2P方法具有优越性，并在图像到点云配准中达到了最先进的性能。

**Conclusion:** CA-I2P通过引入通道自适应调整模块（CAA）和全局最优选择模块（GOS），有效地解决了图像到点云配准中存在的特征通道注意力差异和冗余对应问题，显著提高了配准精度。

> **ai_Abstract:** 本文提出了CA-I2P网络，旨在解决图像到点云配准中特征通道注意力差异和冗余对应问题。为此，引入了通道自适应调整模块（CAA）以增强模态内特征并抑制跨模态敏感性，以及全局最优选择模块（GOS）以取代局部选择实现全局优化。实验结果表明，CA-I2P在图像到点云配准任务上取得了最先进的性能。

> **摘要翻译:** 无检测方法通常遵循从粗到精的流程，提取图像和点云特征进行块级匹配并细化密集的像素到点对应。然而，图像和点云之间特征通道注意力的差异可能导致匹配结果退化，最终损害配准精度。此外，场景中相似的结构可能导致跨模态匹配中的冗余对应。为了解决这些问题，我们提出了通道自适应调整模块（CAA）和全局最优选择模块（GOS）。CAA增强了模态内特征并抑制了跨模态敏感性，而GOS则用全局优化取代了局部选择。在RGB-D Scenes V2和7-Scenes上的实验证明了我们方法的优越性，在图像到点云配准中达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [418] [GenFlow: Interactive Modular System for Image Generation](https://arxiv.org/abs/2506.21369)
> *GenFlow：图像生成交互式模块化系统*

*Duc-Hung Nguyen, Huu-Phuc Huynh, Minh-Triet Tran, Trung-Nghia Le* | **Category: cs.CV**

**Keywords:** 生成艺术, 模块化系统, 图像生成, 用户体验, 可访问性

**Comment:** 

> **TL;DR:** GenFlow是一个交互式模块化系统，旨在通过简化工作流程和降低技术门槛，让所有人都能轻松生成图像。

**AI_Comments:** GenFlow的创新之处在于其将复杂的生成艺术工作流程模块化和用户友好化，通过节点编辑器和NLP助手显著降低了技术门槛。这对于普及生成艺术工具，让更多非专业人士参与创作具有重要意义。其关注用户体验和可访问性是其关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成艺术工具需要高级的技术专业知识，限制了其广泛应用。GenFlow旨在弥合这一差距，让所有技能水平的用户都能轻松生成图像。

**Method:** GenFlow是一个模块化框架，具有基于节点的编辑器用于定制，以及由自然语言处理提供支持的智能助手。它自动化部署过程并最小化技术障碍。

**Result:** 用户研究表明，GenFlow能够优化工作流程，缩短任务完成时间，并通过其直观的界面和自适应功能增强用户理解。

**Conclusion:** GenFlow是一个突破性的解决方案，重新定义了生成艺术领域的可访问性和效率。

> **ai_Abstract:** GenFlow是一个创新的模块化系统，旨在通过提供直观的基于节点的编辑器和智能助手，降低生成艺术的技术门槛。它自动化复杂流程，使用户能够轻松高效地生成图像。用户研究证实了其在优化工作流程、提高效率和用户理解方面的有效性，使其成为生成艺术领域可访问性的重要进步。

> **摘要翻译:** 生成艺术开启了无限的创意可能性，但由于高级架构概念和计算工作流程所需的技术专业知识，其全部潜力仍未被充分利用。为了弥合这一差距，我们推出了GenFlow，一个新颖的模块化框架，使所有技能水平的用户都能精确而轻松地生成图像。GenFlow拥有用于无缝定制的基于节点的编辑器和由自然语言处理提供支持的智能助手，将工作流程创建的复杂性转化为直观且易于访问的体验。通过自动化部署过程并最大程度地减少技术障碍，我们的框架使尖端的生成艺术工具可供所有人使用。一项用户研究表明，GenFlow通过其直观的界面和自适应功能，能够优化工作流程、缩短任务完成时间并增强用户理解。这些结果将GenFlow定位为一个突破性的解决方案，重新定义了生成艺术领域的可访问性和效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [419] [FastRef:Fast Prototype Refinement for Few-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.21398)
> *FastRef：用于少样本工业异常检测的快速原型细化*

*Long Tian, Yufei Li, Yuyang Dai, Wenchao Chen, Xiyang Liu, Bo Chen* | **Category: cs.CV**

**Keywords:** 少样本工业异常检测, 原型细化, 最优传输, 特征转移, 异常抑制

**Comment:** 18pages, 7figures, 6tables

> **TL;DR:** FastRef提出了一种新颖高效的原型细化框架，通过两阶段迭代过程解决了少样本工业异常检测中原型代表性不足的问题，并表现出高效和有效性。

**AI_Comments:** FastRef的创新之处在于其提出的两阶段迭代原型细化过程，特别是利用最优传输（OT）来解决少样本设置下异常更容易被重建的问题。该方法不仅提高了原型代表性，还兼顾了计算效率，这对于实际工业应用至关重要。与现有方法的集成能力也增强了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 少样本工业异常检测（FS-IAD）在数据稀缺环境下对实际自动化检测系统构成严峻挑战。现有方法主要关注从有限正常样本中提取原型，但通常忽略系统地结合查询图像统计信息来增强原型代表性。

**Method:** 提出FastRef，一个新颖高效的FS-IAD原型细化框架。该方法通过迭代的两阶段过程运行：1) 通过可优化变换矩阵将查询特征的特性转移到原型中（通过原型对查询特征的线性重建实现）；2) 通过原型对齐抑制异常（利用最优传输OT测量并最小化原型与其细化对应物之间的差距）。FastRef可与PatchCore、FastRecon、WinCLIP和AnomalyDINO等方法集成。

**Result:** 在MVTec、ViSA、MPDD和RealIAD四个基准数据集上的大量实验证明了该方法在1/2/4-shot设置下的有效性和计算效率。

**Conclusion:** 论文提出了FastRef，一个新颖高效的FS-IAD原型细化框架，通过两阶段迭代过程（特征转移和异常抑制）解决了原型代表性问题，并在多个基准数据集上验证了其有效性和计算效率。

> **ai_Abstract:** 本文提出了FastRef，一个用于少样本工业异常检测（FS-IAD）的新型高效原型细化框架。针对现有方法在数据稀缺环境下原型代表性不足的问题，FastRef采用迭代两阶段过程：首先通过可优化变换矩阵将查询特征的特性转移到原型，然后通过原型对齐抑制异常，其中利用最优传输（OT）处理非高斯特征。实验在MVTec、ViSA等四个基准数据集上验证了FastRef在1/2/4-shot设置下的有效性和计算效率，并可与现有SOTA方法集成。

> **摘要翻译:** 少样本工业异常检测（FS-IAD）对在数据稀缺环境中运行的实际自动化检测系统提出了严峻挑战。现有方法主要侧重于从有限的正常样本中获取原型，但通常忽略系统地整合查询图像统计信息以增强原型的代表性。为了解决这个问题，我们提出了FastRef，一个新颖高效的FS-IAD原型细化框架。我们的方法通过一个迭代的两阶段过程运行：（1）通过可优化的变换矩阵将查询特征的特性转移到原型中，以及（2）通过原型对齐抑制异常。特性转移是通过原型对查询特征的线性重建实现的，而异常抑制解决了FS-IAD中的一个关键观察，即与具有丰富正常原型的传统IAD不同，有限样本设置使得异常重建的可能性更大。因此，我们对非高斯采样特征采用最优传输（OT）来衡量和最小化原型与其细化对应物之间的差距以抑制异常。为了进行全面评估，我们将FastRef与三种有竞争力的基于原型的FS-IAD方法：PatchCore、FastRecon、WinCLIP和AnomalyDINO进行了集成。在MVTec、ViSA、MPDD和RealIAD四个基准数据集上进行的广泛实验证明了我们方法在1/2/4-shot设置下的有效性和计算效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [420] [Curve-Aware Gaussian Splatting for 3D Parametric Curve Reconstruction](https://arxiv.org/abs/2506.21401)
> *曲线感知高斯泼溅用于三维参数曲线重建*

*Zhirui Gao. Renjiao Yi, Yaqiao Dai, Xuening Zhu, Wei Chen, Chenyang Zhu, Kai Xu* | **Category: cs.CV**

**Keywords:** 三维参数曲线重建, 高斯泼溅, 可微分渲染, 边缘图, 单阶段优化

**Comment:** Code: https://github.com/zhirui-gao/Curve-Gaussian Accepted by ICCV
  2025

> **TL;DR:** 该论文提出了一种名为CurveGaussian的单阶段端到端框架，用于直接从多视图边缘图重建三维参数曲线，通过新颖的可微分表示和自适应拓扑优化，克服了传统两阶段方法的误差累积问题，实现了更高效、更鲁棒的重建。

**AI_Comments:** 该论文的创新之处在于提出了一个端到端的单阶段三维参数曲线重建框架，通过引入CurveGaussian这一新颖的可微分表示和自适应拓扑优化，有效解决了传统两阶段方法中存在的误差累积和优化鸿沟问题。其重要性在于实现了更精确、更鲁棒且更高效的三维曲线重建。

<details>
  <summary>Details</summary>

**Motivation:** 现有两阶段方法在“边缘点云重建和参数曲线拟合”的顺序管道中存在固有的优化差距，导致误差累积；同时，参数曲线本身不适合基于渲染的多视图优化。

**Method:** 提出了一种端到端单阶段框架。通过参数曲线和面向边缘的高斯分量之间的新型双向耦合机制，形成了“曲线感知高斯表示（CurveGaussian）”，实现了三维曲线的可微分渲染，从而可以直接通过多视图证据进行优化。此外，在训练过程中引入了动态自适应拓扑优化框架，通过线性化、合并、分裂和修剪操作来细化曲线结构。

**Result:** 在ABC数据集和真实世界基准测试中，该单阶段方法优于两阶段替代方案，尤其在生成更清晰、更鲁棒的重建方面表现出色。通过直接优化参数曲线，该方法显著减少了训练期间的参数数量，与现有方法相比，实现了更高的效率和卓越的性能。

**Conclusion:** 所提出的单阶段方法CurveGaussian通过直接从二维边缘图重建三维参数曲线，克服了两阶段方法的局限性，通过实现可微分优化，在效率和性能上均优于现有方法。

> **ai_Abstract:** 本文提出了一种名为CurveGaussian的新型单阶段端到端框架，用于直接从多视图边缘图重建三维参数曲线。与传统的两阶段方法不同，它通过引入一种新颖的曲线感知高斯表示来实现可微分渲染，从而避免了误差累积，并允许直接优化曲线。该方法还结合了自适应拓扑优化，并在实验中证明其在重建质量、鲁棒性和效率方面均优于现有两阶段方法。

> **摘要翻译:** 本文提出了一种端到端框架，用于直接从多视图边缘图重建三维参数曲线。与现有遵循“边缘点云重建和参数曲线拟合”顺序管道的两阶段方法形成对比，我们的一阶段方法直接从二维边缘图优化三维参数曲线，消除了由不连贯阶段之间固有的优化差距引起的误差累积。然而，参数曲线本身不适合基于渲染的多视图优化，因此需要一种互补的表示，既能保留其几何特性，又能实现可微分渲染。我们提出了一种参数曲线和面向边缘的高斯分量之间的新型双向耦合机制。这种紧密的对应关系形成了曲线感知高斯表示，即\textbf{CurveGaussian}，它能够实现三维曲线的可微分渲染，从而允许通过多视图证据直接进行优化。此外，我们在训练期间引入了动态自适应拓扑优化框架，通过线性化、合并、分裂和修剪操作来细化曲线结构。在ABC数据集和真实世界基准测试上的综合评估表明，我们的一阶段方法优于两阶段替代方案，特别是在生成更清晰、更鲁棒的重建方面。此外，通过直接优化参数曲线，我们的方法显著减少了训练期间的参数数量，与现有方法相比，实现了更高的效率和卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [XVerse: Consistent Multi-Subject Control of Identity and Semantic Attributes via DiT Modulation](https://arxiv.org/abs/2506.21416)
> *XVerse：通过DiT调制实现身份和语义属性的多主体一致性控制*

*Bowen Chen, Mengyi Zhao, Haomiao Sun, Li Chen, Xu Wang, Kang Du, Xinglong Wu* | **Category: cs.CV**

**Keywords:** 多主体控制, 文本到图像生成, Diffusion Transformers, 身份控制, 语义属性

**Comment:** Project Page: https://bytedance.github.io/XVerse Github Link:
  https://github.com/bytedance/XVerse

> **TL;DR:** XVerse是一个新的多主体图像生成模型，它通过将参考图像转换为文本流调制偏移量，解决了现有方法在多主体文本到图像生成中控制主体身份和语义属性时出现的编辑性差和属性纠缠问题，从而实现了高保真、可编辑的多主体图像合成。

**AI_Comments:** 该论文提出了一种创新的DiT调制方法，通过将参考图像转换为文本流偏移量，实现了对多主体图像生成中身份和语义属性的精细且独立控制。其核心创新在于解决了传统方法中常见的编辑性受损和属性纠缠问题，为个性化和复杂场景的生成提供了更强大的能力。

<details>
  <summary>Details</summary>

**Motivation:** 在文本到图像生成中，特别是在多主体场景下，对主体身份和语义属性（姿态、风格、光照）进行细粒度控制，往往会损害Diffusion Transformers（DiTs）的可编辑性和连贯性。许多现有方法会引入伪影或遭受属性纠缠。

**Method:** 我们提出了一种新颖的多主体受控生成模型XVerse。通过将参考图像转换为特定令牌文本流调制的偏移量，XVerse能够对特定主体进行精确和独立的控制，而不会破坏图像潜在特征或图像特征。

**Result:** XVerse提供了高保真、可编辑的多主体图像合成，并能对个体主体特征和语义属性进行稳健控制。

**Conclusion:** XVerse显著提高了个性化和复杂场景的生成能力，有效解决了多主体文本到图像生成中控制主体身份和语义属性的挑战。

> **ai_Abstract:** XVerse是一个创新的多主体文本到图像生成模型，旨在解决现有Diffusion Transformers在处理多主体时控制身份和语义属性（如姿态、风格、光照）的挑战，这些挑战通常导致编辑性差和属性纠缠。XVerse通过将参考图像转化为特定令牌文本流的调制偏移量，实现了对每个主体的精确独立控制，避免了对图像潜在特征的干扰。这使得XVerse能够生成高保真、可编辑的多主体图像，并对个体特征和语义属性具有强大的控制能力，从而显著提升了个性化和复杂场景的生成效果。

> **摘要翻译:** 在文本到图像生成中，特别是对于多个主体，对主体身份和语义属性（姿态、风格、光照）进行细粒度控制，往往会损害Diffusion Transformers（DiTs）的可编辑性和连贯性。许多方法会引入伪影或遭受属性纠缠。为了克服这些挑战，我们提出了一种新颖的多主体受控生成模型XVerse。通过将参考图像转换为特定令牌文本流调制的偏移量，XVerse能够对特定主体进行精确和独立的控制，而不会破坏图像潜在特征或图像特征。因此，XVerse提供了高保真、可编辑的多主体图像合成，并能对个体主体特征和语义属性进行稳健控制。这项进展显著提高了个性化和复杂场景的生成能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [HyperSORT: Self-Organising Robust Training with hyper-networks](https://arxiv.org/abs/2506.21430)
> *HyperSORT: 自组织鲁棒训练与超网络*

*Samuel Joutard, Marijn Stollenga, Marc Balle Sanchez, Mohammad Farid Azampour, Raphael Prevost* | **Category: cs.CV**

**Keywords:** 医学影像, 数据偏见, 超网络, 鲁棒训练, 深度分割

**Comment:** Accepted at MICCAI 2025

> **TL;DR:** HyperSORT使用超网络预测UNet参数，通过学习数据变异性来处理医学图像数据集中的偏见和错误，从而实现鲁棒分割并识别数据集中的系统性偏见。

**AI_Comments:** HyperSORT的创新之处在于其利用超网络和联合学习策略来处理医学影像数据中的异质性偏见，这不仅提升了分割的鲁棒性，更重要的是，它提供了一种结构化的方式来映射和理解数据集中的内在偏见和错误，这对于数据质量控制和模型可靠性评估具有重要意义。其能够识别系统性偏见和错误样本的能力是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像数据集常包含异质性偏见（如错误标签、不一致的标注风格），这些偏见会负面影响深度分割网络的性能。识别和表征这些偏见是特别繁琐和具有挑战性的任务。

**Method:** 本文引入了HyperSORT框架，该框架使用一个超网络从代表图像和标注变异性的潜在向量中预测UNet的参数。超网络参数和对应每个训练数据样本的潜在向量集合是联合学习的。因此，HyperSORT不是优化单个神经网络来拟合数据集，而是学习UNet参数的复杂分布，其中低密度区域可以捕获噪声特异性模式，而较大的模式则能以区分但有意义的方式鲁棒地分割器官。

**Result:** 该方法在两个3D腹部CT公共数据集（合成扰动的AMOS数据集和TotalSegmentator）上进行了验证。实验表明，HyperSORT创建了数据集的结构化映射，能够识别相关的系统性偏见和错误样本。潜在空间聚类产生的UNet参数能够根据学习到的潜在系统性偏见执行分割任务。

**Conclusion:** HyperSORT能够有效处理医学影像数据集中的偏见和错误，通过学习复杂的UNet参数分布，不仅实现了鲁棒分割，还能识别并表征数据集中的系统性偏见和异常样本。

> **ai_Abstract:** 本文提出了HyperSORT框架，旨在解决医学影像数据集中存在的异质性偏见对深度分割网络性能的影响。HyperSORT利用超网络从潜在向量中预测UNet参数，这些潜在向量捕获了图像和标注的变异性。通过联合学习超网络参数和数据样本的潜在向量，HyperSORT能够学习UNet参数的复杂分布，从而在实现鲁棒器官分割的同时，识别并表征数据集中的系统性偏见和异常样本。该方法在合成扰动数据集和大规模真实数据集上均得到了有效验证。

> **摘要翻译:** 医学影像数据集通常包含从错误标签到不一致标注风格的异质性偏见。这些偏见会对深度分割网络的性能产生负面影响。然而，识别和表征这些偏见是一项特别繁琐和具有挑战性的任务。在本文中，我们引入了HyperSORT，这是一个使用超网络根据代表图像和标注变异性的潜在向量预测UNets参数的框架。超网络参数和对应训练集中每个数据样本的潜在向量集合是联合学习的。因此，HyperSORT不是优化单个神经网络来拟合数据集，而是学习UNet参数的复杂分布，其中低密度区域可以捕获噪声特异性模式，而较大的模式则能以区分但有意义的方式鲁棒地分割器官。我们在两个3D腹部CT公共数据集上验证了我们的方法：首先是AMOS数据集的合成扰动版本，以及TotalSegmentator，一个包含真实未知偏见和错误的大规模数据集。我们的实验表明，HyperSORT创建了数据集的结构化映射，从而能够识别相关的系统性偏见和错误样本。潜在空间聚类产生了根据底层学习的系统性偏见执行分割任务的UNet参数。代码和我们对TotalSegmentator数据集的分析已公开：https://github.com/ImFusionGmbH/HyperSORT

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [426] [Benchmarking Deep Learning and Vision Foundation Models for Atypical vs. Normal Mitosis Classification with Cross-Dataset Evaluation](https://arxiv.org/abs/2506.21444)
> *深度学习和视觉基础模型在非典型与正常有丝分裂分类中的基准测试及跨数据集评估*

*Sweta Banerjee, Viktoria Weiss, Taryn A. Donovan, Rutger A. Fick, Thomas Conrad, Jonas Ammeling, Nils Porsche, Robert Klopfleisch, Christopher Kaltenecker, Katharina Breininger, Marc Aubreville, Christof A. Bertram* | **Category: cs.CV**

**Keywords:** 非典型有丝分裂分类, 深度学习, 视觉基础模型, 迁移学习, LoRA

**Comment:** 

> **TL;DR:** 该研究比较了深度学习和视觉基础模型在识别非典型有丝分裂方面的性能，并在多个数据集上进行了评估，发现LoRA微调的基础模型表现良好。

**AI_Comments:** 本文通过引入新的数据集和全面比较多种深度学习及基础模型，特别是在非典型有丝分裂分类这一病理诊断难题上，展示了迁移学习和LoRA微调的巨大潜力。其创新性在于对不同模型和适应策略进行了严格的跨数据集评估，为临床病理诊断的自动化提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 非典型有丝分裂是肿瘤恶性程度的独立预后相关标志物，但其识别具有挑战性，包括患病率低、形态差异细微、病理学家间一致性低以及数据集中类别不平衡。

**Method:** 本研究以乳腺癌非典型有丝分裂数据集（AMi-Br）为基础，全面比较了用于自动化非典型有丝分裂图像（AMF）分类的深度学习方法，包括基线模型、使用线性探测的基础模型以及使用低秩适应（LoRA）进行微调的基础模型。为了进行严格评估，引入了两个新的保留AMF数据集：AtNorM-Br（来自TCGA乳腺癌队列）和AtNorM-MD（来自MIDOG++训练集的多领域数据集）。

**Result:** 在域内AMi-Br数据集上，平均平衡准确率高达0.8135；在域外AtNorm-Br和AtNorM-MD数据集上，平均平衡准确率分别为0.7696和0.7705。特别是基于Virchow系列基础模型的LoRA适应性表现尤为出色。

**Conclusion:** 尽管非典型有丝分裂分类是一个具有挑战性的问题，但通过利用迁移学习和模型微调技术的最新进展可以有效解决。

> **ai_Abstract:** 本研究旨在解决非典型有丝分裂识别的挑战，通过对深度学习和视觉基础模型进行基准测试。研究比较了基线模型、线性探测和LoRA微调的基础模型在AMi-Br、AtNorM-Br和AtNorM-MD三个数据集上的性能。结果显示，LoRA微调的基础模型，特别是Virchow系列，在非典型有丝分裂分类上取得了良好的平衡准确率，证明了迁移学习和微调在解决此挑战性问题中的有效性。

> **摘要翻译:** 非典型有丝分裂标志着细胞分裂过程的偏差，其本身可以作为肿瘤恶性程度的独立预后相关标志物。然而，由于患病率低、有时与正常有丝分裂的形态差异细微、病理学家间判读一致性低以及数据集中类别不平衡，其识别仍然具有挑战性。本研究以乳腺癌非典型有丝分裂数据集（AMi-Br）为基础，提出了一个全面的基准测试，比较了用于自动化非典型有丝分裂图像（AMF）分类的深度学习方法，包括基线模型、使用线性探测的基础模型以及使用低秩适应（LoRA）进行微调的基础模型。为了进行严格评估，我们进一步引入了两个新的保留AMF数据集——AtNorM-Br（一个来自TCGA乳腺癌队列的有丝分裂数据集）和AtNorM-MD（一个来自MIDOG++训练集的多领域有丝分裂数据集）。我们发现，在域内AMi-Br数据集上，平均平衡准确率高达0.8135；在域外AtNorm-Br和AtNorM-MD数据集上，平均平衡准确率分别为0.7696和0.7705，其中基于Virchow系列基础模型的LoRA适应性表现尤为出色。我们的工作表明，非典型有丝分裂分类虽然是一个具有挑战性的问题，但可以通过利用迁移学习和模型微调技术的最新进展来有效解决。本论文中使用的所有代码和数据均可在以下GitHub仓库获取：https://github.com/DeepMicroscopy/AMi-Br_Benchmark。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [428] [Controllable 3D Placement of Objects with Scene-Aware Diffusion Models](https://arxiv.org/abs/2506.21446)
> *基于场景感知扩散模型的可控三维物体放置*

*Mohamed Omran, Dimitris Kalatzis, Jens Petersen, Amirhossein Habibian, Auke Wiggers* | **Category: cs.CV**

**Keywords:** 三维物体放置, 扩散模型, 场景感知, 图像编辑, 可控生成

**Comment:** 

> **TL;DR:** 该研究提出了一种利用精心设计的视觉地图和粗略物体掩码，通过场景感知扩散模型实现高精度、可控的三维物体放置方法，特别适用于汽车场景，并能保持背景不变。

**AI_Comments:** 这项工作在图像编辑领域，特别是在三维物体精确放置方面取得了重要进展。其创新点在于引入了结合视觉地图和粗略物体掩码的条件信号，有效解决了传统方法中对精确修复掩码或提示的依赖。通过基于修复模型的设计，确保了背景的完整性，这是一个重要的实际优势。该方法在汽车场景中的应用展示了其潜在的工业价值，并且对姿态和位置准确性的强调使其超越了单纯的外观生成。未来的工作可能探索其在更复杂、多样化场景中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像编辑方法虽然强大，但精确控制物体在环境中的位置和方向仍然具有挑战性，通常需要精心制作的修复掩码或提示。

**Method:** 本研究通过设计一种结合视觉地图和粗略物体掩码的条件信号，实现了高质量的物体放置。该条件信号能够解决歧义，并灵活支持形状或方向的改变。方法基于修复模型构建，旨在保持背景完整。

**Result:** 该方法在汽车场景中展示了其有效性，通过比较不同条件信号在新型物体放置任务中的表现。这些任务不仅评估外观质量，还衡量姿态和位置的准确性，包括需要非平凡形状变化的情况。此外，该方法还能将精细位置控制与外观控制相结合，以在场景中精确放置现有物体。

**Conclusion:** 该研究成功展示了一种通过精心设计的视觉地图和粗略物体掩码，结合场景感知扩散模型，实现高精度、可控三维物体放置的有效方法，解决了现有图像编辑方法在精确位置和方向控制上的挑战，并能保持背景不变。

> **ai_Abstract:** 本研究提出了一种利用场景感知扩散模型进行可控三维物体放置的新方法。通过结合精心设计的视觉地图和粗略物体掩码作为条件信号，该方法能够实现高精度的物体定位和姿态控制，同时保持背景不变。该方法在汽车场景中得到了验证，并能处理复杂的形状变化，展示了在精确位置和外观控制方面的强大能力。

> **摘要翻译:** 随着强大的文本条件生成模型的出现，图像编辑方法变得更加强大和灵活。然而，将物体以精确的位置和方向放置在环境中仍然是一个挑战，因为这通常需要精心制作的修复掩码或提示。在这项工作中，我们展示了精心设计的视觉地图与粗略物体掩码相结合，足以实现高质量的物体放置。我们设计了一种条件信号，它能解决歧义，同时足够灵活以允许改变形状或物体方向。通过建立在修复模型的基础上，我们特意保持背景完整，这与联合建模物体和背景的方法形成对比。我们在汽车环境中展示了我们方法的有效性，比较了新型物体放置任务中不同的条件信号。这些任务旨在不仅从外观方面，而且从姿态和位置准确性方面衡量编辑质量，包括需要非平凡形状变化的情况。最后，我们展示了精细位置控制可以与外观控制相结合，以将现有物体精确放置在场景中的特定位置。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [429] [A Comprehensive Dataset for Underground Miner Detection in Diverse Scenario](https://arxiv.org/abs/2506.21451)
> *针对多样化场景的地下矿工检测综合数据集*

*Cyrus Addy, Ajay Kumar Gurumadaiah, Yixiang Gao, Kwame Awuah-Offei* | **Category: cs.CV, cs.LG**

**Keywords:** 地下矿工检测, 热成像, 数据集, 目标检测, 采矿安全

**Comment:** 

> **TL;DR:** 本文提出了一个用于地下矿工热成像检测的综合数据集，以解决现有训练数据缺乏的问题，并为紧急情况下的矿工检测系统开发奠定基础。

**AI_Comments:** 这项工作通过构建专门针对地下采矿环境的热成像数据集，解决了深度学习在矿工检测应用中面临的关键数据稀缺问题，具有重要的实际意义。其创新之处在于专注于热成像数据，这对于在低光照或无光照的地下环境中进行检测至关重要。该数据集的发布及其基线评估为后续研究提供了宝贵的资源和起点，有望推动地下矿工安全检测技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 地下采矿作业面临严峻的安全挑战，需要可靠的应急响应能力。机器人辅助救援需要可靠的矿工检测能力，而深度学习算法虽有潜力，但缺乏针对地下采矿环境的综合训练数据集。

**Method:** 本文提出了一个专门为地下矿工检测设计的新型热成像数据集。系统地捕获了各种采矿活动和场景的热图像。为了建立基线性能指标，在该数据集上评估了几种最先进的目标检测算法，包括YOLOv8、YOLOv10、YOLO11和RT-DETR。

**Result:** 该数据集是开发可靠的基于热成像的矿工检测系统的关键第一步。研究结果证明了使用热成像进行矿工检测的可行性。

**Conclusion:** 该工作为未来在这一关键安全应用领域的研究奠定了基础，并有望最终部署到真实的紧急情况中。

> **ai_Abstract:** 本文针对地下采矿环境中缺乏用于深度学习的矿工检测数据集的问题，提出了一个新颖的、全面的热成像数据集。该数据集通过系统地捕获各种采矿场景的热图像构建，旨在支持紧急情况下矿工检测系统的开发和验证。研究人员使用YOLOv8、YOLOv10、YOLO11和RT-DETR等先进目标检测算法在该数据集上进行了基线性能评估，验证了热成像在矿工检测中的可行性，并为该领域的未来研究奠定了基础。

> **摘要翻译:** 地下采矿作业面临严峻的安全挑战，这使得应急响应能力至关重要。虽然机器人在搜索和救援行动中展现出前景，但其有效性取决于可靠的矿工检测能力。深度学习算法为自动化矿工检测提供了潜在解决方案，但需要全面的训练数据集，而目前地下采矿环境中缺乏此类数据。本文提出了一个新颖的热成像数据集，专门用于开发和验证针对潜在紧急应用的矿工检测系统。我们系统地捕获了各种采矿活动和场景的热图像，为检测算法创建了坚实的基础。为了建立基线性能指标，我们评估了数据集上的几种最先进的目标检测算法，包括YOLOv8、YOLOv10、YOLO11和RT-DETR。尽管该数据集并非涵盖所有可能的紧急情况，但它作为开发可靠的基于热成像的矿工检测系统的关键第一步，这些系统最终可能部署到真实的紧急场景中。这项工作证明了使用热成像进行矿工检测的可行性，并为未来在这一关键安全应用领域的研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [431] [Rethinking Oversaturation in Classifier-Free Guidance via Low Frequency](https://arxiv.org/abs/2506.21452)
> *通过低频重新思考无分类器引导中的过饱和问题*

*Kaiyu Song, Hanjiang Lai* | **Category: cs.CV**

**Keywords:** 无分类器引导, 低频, 过饱和, 扩散模型, LF-CFG

**Comment:** 

> **TL;DR:** 本文提出了一种基于低频信号的新方法LF-CFG，以解决无分类器引导（CFG）中高引导尺度导致的过饱和和不真实伪影问题，通过识别并降低冗余低频信息的影响来改善扩散模型性能。

**AI_Comments:** 该论文创新性地从低频信号视角重新审视了无分类器引导中的过饱和问题，并提出了LF-CFG这一有效解决方案。其核心贡献在于识别了低频冗余信息积累作为问题根源，并设计了自适应阈值和降权策略来缓解。这为提升扩散模型在高引导尺度下的生成质量提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 无分类器引导（CFG）在高引导尺度下常导致过饱和和不真实伪影，限制了其性能。

**Method:** 本文提出低频改进无分类器引导（LF-CFG）。通过分析先验步和当前步之间低频信息的变化率，引入自适应阈值测量来识别冗余信息的位置，并应用降权策略以减少低频信号中冗余信息的影响。

**Result:** 实验结果表明，LF-CFG有效缓解了包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL在内的各种扩散模型中的过饱和和不真实伪影问题。

**Conclusion:** LF-CFG通过解决低频信号中的冗余信息积累问题，成功改善了无分类器引导在高引导尺度下的性能，有效减轻了过饱和和不真实伪影。

> **ai_Abstract:** 本文针对无分类器引导（CFG）在高引导尺度下产生的过饱和及不真实伪影问题，提出了一种名为低频改进无分类器引导（LF-CFG）的新方法。研究发现，低频信号中冗余信息的积累是导致这些问题的关键。LF-CFG通过引入自适应阈值测量来识别冗余信息，并采用降权策略来降低其影响。实验证明，LF-CFG在多种扩散模型上有效改善了图像质量，缓解了过饱和和伪影。

> **摘要翻译:** 无分类器引导（CFG）成功应用于条件扩散模型，它使用引导尺度来平衡条件项和无条件项的影响。高引导尺度用于增强条件项的性能。然而，高引导尺度常常导致过饱和和不真实的伪影。在本文中，我们引入了一种基于低频信号的新视角，将这些信号中冗余信息的积累确定为导致过饱和和不真实伪影的关键因素。基于这一见解，我们提出了低频改进无分类器引导（LF-CFG）来缓解这些问题。具体来说，我们引入了一种基于自适应阈值的测量方法来精确定位冗余信息的位置。我们通过分析先验步和当前步之间低频信息的变化率来确定合理的阈值。然后，我们应用降权策略来减少低频信号中冗余信息的影响。实验结果表明，LF-CFG有效缓解了包括Stable Diffusion-XL、Stable Diffusion 2.1、3.0、3.5和SiT-XL在内的各种扩散模型中的过饱和和不真实伪影。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [433] [Evaluation of Traffic Signals for Daily Traffic Pattern](https://arxiv.org/abs/2506.21469)
> *日常交通模式下交通信号灯评估*

*Mohammad Shokrolah Shirazi, Hung-Fu Chang* | **Category: cs.CV, cs.LG**

**Keywords:** 交通信号, 转弯流量计数, SUMO, 混合方法, 交通模式

**Comment:** 

> **TL;DR:** 本研究评估了动态、静态和混合交通信号控制方法，利用真实交通数据和模拟，发现混合方法能更好地适应日常交通模式变化，有效管理高峰和非高峰时段的交通流。

**AI_Comments:** 本文通过将真实世界数据采集（基于视觉的TMC）与仿真（SUMO）相结合，并提出自适应的混合控制策略，为交通信号优化提供了一种实用方法。其创新之处在于混合方法能够响应日常交通的双峰特性，提供比纯静态或动态系统更灵活的解决方案。其重要性在于通过数据驱动和自适应的信号管理来解决现实世界的交通拥堵问题。一个潜在的局限性可能是研究结果的普遍性，因为该研究基于拉斯维加斯的特定交叉口，并且混合切换机制的实时实施可能存在复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 转弯流量计数数据对交通信号设计和交通流分析至关重要。鉴于日常交通流常呈现双峰模式，本研究旨在提出并评估一种能适应高峰和非高峰交通状况的混合信号方法，以改进流量管理。

**Method:** 1. 提出动态、静态和混合三种基于TMC的交通信号配置方法。2. 开发基于视觉的跟踪系统，利用交通摄像头估算拉斯维加斯六个交叉口的TMC数据。3. 将交叉口设计、路线和信号配置文件导入SUMO进行信号评估。4. 提出混合信号方法，在动态和静态方法之间切换，以适应高峰和非高峰交通。5. 内置交通生成器模块创建4小时（含高峰时段）车辆路线，信号设计模块生成静态、动态和混合方法的信号调度周期。6. 对不同区域（西、北、东、南）的车辆计数分布进行加权，生成多样化的交通模式。

**Result:** 1. 初步实验结果表明，90秒和120秒的周期时间对所有交叉口效果最佳。2. 四个交叉口在动态信号配时下表现更好，另两个表现较差的交叉口其总车辆数与总车道数比率较低。3. 扩展实验结果显示，基于区域的交通模式分布影响信号设计选择。4. 静态方法适用于均匀的区域交通分布。5. 混合方法对西-东和北-南区域交叉口对的高权重交通效果良好。

**Conclusion:** 交通信号设计的选择受区域交通模式分布的影响，其中混合方法对于日常交通流中常见的不平衡交通模式表现良好，能够有效适应高峰和非高峰交通状况。

> **ai_Abstract:** 本论文评估了动态、静态和混合三种交通信号控制方法。研究利用基于视觉的跟踪系统获取拉斯维加斯交叉口的真实转弯流量计数（TMC）数据，并在SUMO中进行仿真，以评估这些方法在各种日常交通模式（包括高峰和非高峰）下的性能。初步结果确定了最佳周期时间，扩展模拟表明，虽然静态方法适用于均匀的交通分布，但本文提出的混合方法，通过在动态和静态控制之间切换以适应双峰交通模式，在不平衡的区域性交通流中表现出色。

> **摘要翻译:** 转弯流量计数数据对于交通信号设计、交叉口几何规划、交通流和拥堵分析至关重要。这项工作提出了三种基于转弯流量计数（TMC）的交通信号方法：动态配置、静态配置和混合配置。开发了一个基于视觉的跟踪系统，利用交通摄像头估计拉斯维加斯六个交叉口的TMC。将交叉口设计、路线（例如车辆移动方向）和兼容格式的信号配置文件合成并导入到城市交通模拟器（Simulation of Urban MObility, SUMO）中，以使用真实数据进行信号评估。基于估计等待时间的初步实验结果表明，90秒和120秒的周期时间对所有交叉口效果最佳。此外，四个交叉口在动态信号配时配置下表现更好，而另外两个表现较差的交叉口，其总车辆数与交叉口支路总车道数的比率较低。由于日常交通流通常呈现双峰模式，我们提出了一种混合信号方法，在动态和静态方法之间切换，以适应高峰和非高峰交通状况，从而改进流量管理。因此，一个内置的交通生成器模块创建了4小时的车辆路线（包括高峰时段），一个信号设计模块根据静态、动态和混合方法生成信号调度周期。每个区域（即西、北、东、南）的车辆计数分布权重不同，以生成多样化的交通模式。针对6个交叉口进行4小时模拟时间的扩展实验结果表明，基于区域的交通模式分布会影响信号设计选择。尽管静态方法对于均匀的基于区域的交通分布效果很好，但混合方法对于西-东和北-南区域交叉口对的高权重交通效果良好。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [436] [Global and Local Entailment Learning for Natural World Imagery](https://arxiv.org/abs/2506.21476)
> *自然世界图像的全局和局部蕴涵学习*

*Srikumar Sastry, Aayush Dhakal, Eric Xing, Subash Khanal, Nathan Jacobs* | **Category: cs.CV**

**Keywords:** 蕴涵学习, 视觉-语言模型, 分层结构, 传递性, RCME

**Comment:** Accepted at ICCV 2025

> **TL;DR:** 本文提出了径向跨模态嵌入（RCME）框架，用于显式建模蕴涵的传递性，并在视觉-语言模型中优化概念的部分顺序，从而在分层物种分类和分层检索任务中实现了优于现有SOTA模型的性能。

**AI_Comments:** 本文的创新点在于提出了RCME框架，显式地解决了先前蕴涵学习方法未能建模蕴涵传递性的问题，这对于在视觉-语言模型中准确表示数据层次结构至关重要。通过优化概念的部分顺序，RCME提供了一种更鲁棒和语义一致的方式来学习和表示分层数据，对于生物分类等需要复杂层次关系的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在视觉-语言模型中学习数据的分层结构是一个重大挑战。现有方法未能明确建模蕴涵的传递性，而传递性建立了表示空间中顺序和语义之间的关系。

**Method:** 本文引入了径向跨模态嵌入（RCME）框架，该框架能够显式建模传递性强制的蕴涵。该框架优化了视觉-语言模型中概念的部分顺序。通过利用该框架，开发了一个能够表示生命之树中层次结构的分层视觉-语言基础模型。

**Result:** 在分层物种分类和分层检索任务上的实验表明，与现有最先进的模型相比，我们的模型性能有所增强。

**Conclusion:** RCME框架通过显式建模蕴涵的传递性，有效提升了视觉-语言模型中分层结构的表示能力，并在相关任务中取得了显著的性能提升。

> **ai_Abstract:** 本文针对视觉-语言模型中学习数据分层结构的挑战，提出了径向跨模态嵌入（RCME）框架。该框架创新性地显式建模了蕴涵的传递性，并优化了概念的部分顺序，以更好地表示层次结构。RCME被应用于构建一个能够表示生命之树层次结构的分层视觉-语言基础模型。实验结果表明，RCME在分层物种分类和分层检索任务中均优于现有最先进的模型。

> **摘要翻译:** 在视觉-语言模型中学习数据的分层结构是一个重大挑战。以往的工作试图通过采用蕴涵学习来解决这一挑战。然而，这些方法未能明确建模蕴涵的传递性，而蕴涵的传递性建立了表示空间中顺序和语义之间的关系。在这项工作中，我们引入了径向跨模态嵌入（RCME），这是一个能够显式建模传递性强制蕴涵的框架。我们提出的框架优化了视觉-语言模型中概念的部分顺序。通过利用我们的框架，我们开发了一个能够表示生命之树中层次结构的分层视觉-语言基础模型。我们在分层物种分类和分层检索任务上的实验表明，与现有最先进的模型相比，我们的模型性能有所增强。我们的代码和模型已在 https://vishu26.github.io/RCME/index.html 开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [437] [TITAN: Query-Token based Domain Adaptive Adversarial Learning](https://arxiv.org/abs/2506.21484)
> *TITAN：基于查询令牌的域自适应对抗学习*

*Tajamul Ashraf, Janibul Bashir* | **Category: cs.CV, cs.AI**

**Keywords:** 源自适应目标检测, 伪标签, 对抗学习, 查询令牌, 域适应

**Comment:** ICCV 2025

> **TL;DR:** TITAN提出了一种新的SF-DAOD方法，通过分离目标域的难易样本并结合查询令牌对抗模块，解决了伪标签噪声问题，显著提升了目标检测性能。

**AI_Comments:** TITAN的创新点在于其独特的两阶段目标域划分策略（基于方差估计的易难样本分离）和引入查询令牌对抗模块来弥补域差距。这有效解决了SF-DAOD中伪标签噪声和教师模型崩溃的核心问题，取得了显著的性能提升，尤其是在跨域检测方面表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 现有源数据不可用的域自适应目标检测（SF-DAOD）方法中，学生-教师框架生成的伪标签噪声过高（由于域偏差、差异和显著的域偏移），导致教师模型崩溃和学生模型性能急剧下降。

**Method:** 本文提出了一种名为Target-based Iterative Query-Token Adversarial Network (TITAN)的方法。该方法将目标图像分为与源域相似的（容易）和不相似的（困难）两个子集，并通过估计方差来划分目标域，利用高检测方差对应高召回率和与源域更高相似性的洞察。此外，TITAN将基于查询令牌的对抗模块整合到学生-教师基线框架中，以减少两种特征表示之间的域差距。

**Result:** 在四个自然图像数据集和两个具有挑战性的医学数据集上进行的实验表明，TITAN的性能优于现有最先进（SOTA）方法。具体地，在C2F、C2B、S2C和K2C基准上，mAP比当前SOTA分别提高了+22.7%、+22.2%、+21.1%和+3.7个百分点。

**Conclusion:** TITAN通过有效处理伪标签噪声和减少域差距，显著提升了源数据不可用时的域自适应目标检测性能，超越了现有最先进方法。

> **ai_Abstract:** 本文提出了TITAN（Target-based Iterative Query-Token Adversarial Network），旨在解决源数据不可用时的域自适应目标检测（SF-DAOD）问题。针对现有学生-教师框架中伪标签噪声导致性能下降的问题，TITAN通过将目标图像划分为易学和难学子集（基于检测方差），并引入基于查询令牌的对抗模块来减少域差距，从而生成更可靠的伪标签。实验证明，TITAN在多个数据集上显著优于现有SOTA方法。

> **摘要翻译:** 我们关注源数据在自适应期间不可用且模型必须适应未标记目标域的无源域自适应目标检测（SF-DAOD）问题。解决该问题的大多数方法都采用学生-教师（ST）框架下的自监督方法，其中通过源预训练模型生成伪标签以进行进一步微调。我们观察到，学生模型的性能通常会急剧下降，这是由于教师模型崩溃造成的，主要原因是伪标签中存在高噪声，而高噪声又源于域偏差、差异以及跨域的显著域偏移。为了获得可靠的伪标签，我们提出了一个基于目标的迭代查询令牌对抗网络（TITAN），它将目标图像分为两个子集：与源域相似的（容易）和不相似的（困难）。我们提出了一种估计方差的策略来划分目标域。这种方法利用了以下洞察：较高的检测方差对应较高的召回率和与源域的更大相似性。此外，我们将基于查询令牌的对抗模块整合到学生-教师基线框架中，以减少两种特征表示之间的域差距。在四个自然图像数据集和两个具有挑战性的医学数据集上进行的实验证明，TITAN的性能优于现有最先进（SOTA）方法。我们报告在C2F、C2B、S2C和K2C基准上，mAP比当前SOTA分别提高了+22.7、+22.2、+21.1和+3.7个百分点。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [438] [Towards Reliable Detection of Empty Space: Conditional Marked Point Processes for Object Detection](https://arxiv.org/abs/2506.21486)
> *迈向可靠的空旷空间检测：用于目标检测的条件标记点过程*

*Tobias J. Riedlinger, Kira Maag, Hanno Gottschalk* | **Category: cs.CV, cs.LG, math.PR**

**Keywords:** 空旷空间检测, 条件标记点过程, 目标检测, 不确定性量化, 空间统计学

**Comment:** 15 pages, 4 figures, 3 tables

> **TL;DR:** 本文提出了一种基于空间统计学和条件标记点过程的目标检测模型，旨在解决现有深度学习目标检测器在未检测区域（空旷空间）的不确定性量化问题，并为区域是否可驾驶提供明确的置信度估计。

**AI_Comments:** 该论文的创新点在于将空间统计学中的条件标记点过程引入到目标检测领域，以解决现有深度学习模型在量化未检测区域不确定性方面的不足。这对于自动驾驶等安全关键应用具有重要意义，因为它能提供对“空旷”区域的概率评估，从而提高系统的可靠性和安全性。这种将传统统计学方法与现代深度学习相结合的思路值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度神经网络在目标检测中表现出色，但其置信度估计常有偏差，且无法量化未检测区域（空旷空间）的不确定性。这在自动驾驶等应用中存在安全隐患，因为模型未能评估无障碍区域是否真正安全。

**Method:** 本文提出了一种基于空间统计学的方法。将边界框数据视为标记点过程的实现，其中边界框中心是空间点事件，标记用于描述边界框的空间扩展和类别。该统计框架支持基于似然的训练，并为区域是否可驾驶（即无物体）提供明确定义的置信度估计。

**Result:** 通过校准评估和性能评估，证明了该方法的有效性。

**Conclusion:** 该研究提出了一种基于空间统计学的目标检测模型，它能为未检测区域提供明确定义的置信度估计，从而提高了空旷空间检测的可靠性，对于自动驾驶等安全关键应用具有重要意义。

> **ai_Abstract:** 当前深度学习目标检测器在空旷区域的不确定性量化方面存在局限性，可能带来安全风险。本文提出了一种基于空间统计学的目标检测模型，利用条件标记点过程来建模边界框数据。该方法能够提供明确定义的置信度估计，判断一个区域是否无障碍物，并通过校准和性能评估验证了其有效性，旨在提高空旷空间检测的可靠性。

> **摘要翻译:** 深度神经网络在边界框检测和语义分割等计算机视觉任务中取得了最先进的成果。目标检测器和分割模型为预测分配置信度分数，反映了模型在目标检测或像素级分类中的不确定性。然而，这些置信度估计通常是未校准的，因为其架构和损失函数是为任务性能而非概率基础量身定制的。即使预测经过良好校准，目标检测器也无法量化检测到的边界框之外的不确定性，即模型未对没有检测到物体的区域是否真正没有障碍物进行概率评估。这在自动驾驶等应用中带来了安全风险，因为空旷区域的不确定性尚未被探索。在这项工作中，我们提出了一种基于空间统计学原理的目标检测模型。边界框数据与标记点过程的实现相匹配，该过程常用于描述被识别为边界框中心的空间点事件的概率发生，其中标记用于描述边界框和类别的空间扩展。我们的统计框架支持基于似然的训练，并为区域是否可驾驶（即无物体）提供明确定义的置信度估计。我们通过校准评估和性能评估展示了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [439] [Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration](https://arxiv.org/abs/2506.21509)
> *通过动态Logits校准缓解大型视觉-语言模型的幻觉*

*Jiahe Chen, Jiaying He, Qian Shao, Qiyuan Chen, Jiahe Ying, Hongxia Xu, Jintai Chen, Jianwei Zheng, Jian Wu* | **Category: cs.CV**

**Keywords:** 大型视觉-语言模型, 幻觉缓解, 动态Logits校准, 免训练解码, 视觉-语言对齐

**Comment:** 

> **TL;DR:** 本文提出了一种名为动态Logits校准（DLC）的新型免训练解码框架，用于在推理时动态地将文本生成与视觉证据对齐，有效缓解大型视觉-语言模型的幻觉。

**AI_Comments:** DLC的创新之处在于其动态调整logits的机制，通过实时评估视觉与文本的语义对齐来指导生成过程，克服了现有方法中静态约束和效率低下的问题。其免训练的特性以及避免多次前向传播的设计也大大提升了实用性。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLM）在多模态理解方面取得了显著进展，但经常受到幻觉的困扰，即生成与视觉输入矛盾的文本。现有的免训练解码策略存在局限性，包括使用不适应生成过程中语义漂移的静态约束、需要多次前向传播导致的低效率以及由于过于僵硬的干预规则导致的细节退化。

**Method:** 本文引入了动态Logits校准（DLC），一种新型的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步利用CLIP评估输入图像与生成的文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选tokens的相对视觉优势（RVA），自适应地调整输出logits以偏向视觉上接地气的tokens。此外，一个由实时上下文对齐分数提供信息的自适应加权机制，在平衡视觉指导的同时，确保文本输出的整体质量。

**Result:** 在各种基准和不同的LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的广泛实验表明，DLC显著减少了幻觉，优于现有方法，并通过避免多次前向传播保持了高推理效率。

**Conclusion:** 本文提出了一种有效且高效的解码时解决方案来缓解幻觉，从而增强了LVLM在更多实践中的可靠性。

> **ai_Abstract:** 本文提出了一种名为动态Logits校准（DLC）的新型免训练解码框架，旨在解决大型视觉-语言模型（LVLM）中常见的幻觉问题。DLC通过在解码阶段动态地使用CLIP评估视觉与文本的语义对齐，并基于相对视觉优势（RVA）和自适应加权机制调整输出logits，从而在推理时将文本生成与视觉证据对齐。实验证明，DLC能显著减少幻觉，优于现有方法，并保持高推理效率。

> **摘要翻译:** 大型视觉-语言模型（LVLM）在多模态理解方面取得了显著进展，但它们经常受到幻觉的困扰——生成与视觉输入矛盾的文本。现有的免训练解码策略表现出关键局限性，包括使用不适应生成过程中语义漂移的静态约束、需要多次前向传播导致的低效率以及由于过于僵硬的干预规则导致的细节退化。为了克服这些挑战，本文引入了动态Logits校准（DLC），一种新型的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步利用CLIP评估输入图像与生成的文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选tokens的相对视觉优势（RVA），自适应地调整输出logits以偏向视觉上接地气的tokens。此外，一个由实时上下文对齐分数提供信息的自适应加权机制，在平衡视觉指导的同时，确保文本输出的整体质量。在各种基准和不同的LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的广泛实验表明，DLC显著减少了幻觉，优于现有方法，并通过避免多次前向传播保持了高推理效率。总的来说，我们提出了一种有效且高效的解码时解决方案来缓解幻觉，从而增强了LVLM在更多实践中的可靠性。代码将在Github上发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [440] [GGTalker: Talking Head Systhesis with Generalizable Gaussian Priors and Identity-Specific Adaptation](https://arxiv.org/abs/2506.21513)
> *GGTalker：基于可泛化高斯先验和身份特异性适应的说话人脸合成*

*Wentao Hu, Shunkai Li, Ziqiao Peng, Haoxian Zhang, Fan Shi, Xiaoqiang Liu, Pengfei Wan, Di Zhang, Hui Tian* | **Category: cs.CV**

**Keywords:** 说话人脸合成, 3D先验, 高斯先验, 身份适应, 泛化性

**Comment:** ICCV 2025, Project page: https://vincenthu19.github.io/GGTalker/

> **TL;DR:** GGTalker通过结合可泛化高斯先验和身份特异性适应，解决了高质量、可泛化3D说话人脸合成中现有方法在头部大旋转和OOD音频上的局限性，并提高了训练效率和效果。

**AI_Comments:** 这项工作通过引入可泛化高斯先验和两阶段的适应策略，显著提升了3D说话人脸合成的泛化能力和鲁棒性，尤其是在处理大头部旋转和域外音频方面。其结合通用模式学习和个体细节建模的思路具有创新性，并且通过颜色MLP和身体修复器进一步增强了视觉真实感，为该领域树立了新的基准。

<details>
  <summary>Details</summary>

**Motivation:** 创建高质量、可泛化的语音驱动3D说话人脸合成仍然是一个挑战。现有方法在固定视角和小规模音频变化下表现尚可，但在大头部旋转和域外音频（OOD）下表现不佳，且需要耗时的身份特异性训练。核心问题在于缺乏足够的3D先验知识，限制了合成说话人脸的外推能力。

**Method:** 提出GGTalker，通过结合可泛化先验和身份特异性适应来合成说话人脸。引入两阶段的“先验-适应”训练策略：学习高斯头部先验并适应个体特征。训练音频-表情先验和表情-视觉先验，以捕获唇部运动的通用模式和头部纹理的通用分布。在定制适应阶段，精确建模个体说话风格和纹理细节。引入颜色MLP生成精细的、与运动对齐的纹理，并引入身体修复器（Body Inpainter）将渲染结果与背景融合，生成逼真的视频帧。

**Result:** GGTalker在渲染质量、3D一致性、唇形同步准确性和训练效率方面达到了最先进的性能。

**Conclusion:** GGTalker通过结合可泛化高斯先验和身份特异性适应，有效解决了语音驱动3D说话人脸合成中的泛化性、鲁棒性及训练效率问题，并取得了SOTA表现。

> **ai_Abstract:** 针对高质量、可泛化语音驱动3D说话人脸合成的挑战，特别是现有方法在大头部旋转和OOD音频下的不足以及耗时的身份特异性训练问题，本文提出了GGTalker。该方法结合了可泛化高斯先验和身份特异性适应，通过两阶段的“先验-适应”训练策略，学习通用模式并精细建模个体特征。GGTalker引入了颜色MLP和身体修复器以生成逼真视频帧，并在实验中展现出在渲染质量、3D一致性、唇形同步和训练效率方面的SOTA性能。

> **摘要翻译:** 创建高质量、可泛化的语音驱动3D说话人脸仍然是一个持续的挑战。现有方法在固定视角和小规模音频变化下取得了令人满意的结果，但它们在大头部旋转和域外（OOD）音频方面表现不佳。此外，它们受限于耗时的身份特异性训练。我们认为核心问题在于缺乏足够的3D先验知识，这限制了合成说话人脸的外推能力。为了解决这个问题，我们提出了GGTalker，它通过结合可泛化先验和身份特异性适应来合成说话人脸。我们引入了一种两阶段的“先验-适应”训练策略，以学习高斯头部先验并适应个体特征。我们训练音频-表情先验和表情-视觉先验，以捕捉唇部运动的通用模式和头部纹理的通用分布。在定制适应阶段，精确建模了个体说话风格和纹理细节。此外，我们引入了颜色MLP来生成精细的、与运动对齐的纹理，并引入了身体修复器（Body Inpainter）将渲染结果与背景融合，从而产生难以区分的、逼真的视频帧。综合实验表明，GGTalker在渲染质量、3D一致性、唇形同步准确性和训练效率方面达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [441] [G$^{2}$D: Boosting Multimodal Learning with Gradient-Guided Distillation](https://arxiv.org/abs/2506.21514)
> *G$^{2}$D：通过梯度引导蒸馏提升多模态学习*

*Mohammed Rakib, Arunkumar Bagavathi* | **Category: cs.CV**

**Keywords:** 多模态学习, 知识蒸馏, 模态不平衡, 梯度引导, 动态优先级

**Comment:** Accepted at ICCV 2025

> **TL;DR:** G$^{2}$D通过梯度引导蒸馏，结合定制损失函数和动态模态优先级技术，解决了多模态学习中的模态不平衡问题，并显著提升了模型性能。

**AI_Comments:** G$^{2}$D的创新之处在于其结合了知识蒸馏、定制损失函数以及动态序列模态优先级（SMP）技术，以直接解决多模态学习中的核心挑战——模态不平衡问题。这种方法有效避免了强模态对弱模态的掩盖，从而实现了更全面的特征学习和性能提升，对于推动多模态模型在实际应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统多模态模型常受模态不平衡困扰，导致特征表示不佳和弱模态未被充分利用，即一个或少数模态主导模型优化，进而影响整体性能。

**Method:** 本文引入了梯度引导蒸馏（G$^{2}$D），这是一个知识蒸馏框架，通过融合单模态和多模态目标的定制损失函数来优化多模态模型。G$^{2}$D还结合了动态序列模态优先级（SMP）技术，确保每个模态都能引导学习过程，避免强模态掩盖弱模态。

**Result:** G$^{2}$D在多个真实世界数据集上进行了验证，结果显示它在训练过程中增强了弱模态的重要性，并在分类和回归任务中超越了现有最先进的方法。

**Conclusion:** G$^{2}$D框架有效解决了多模态学习中的模态不平衡问题，通过其创新的蒸馏和模态优先级技术，显著提升了多模态模型的性能。

> **ai_Abstract:** 本文提出了一种名为梯度引导蒸馏（G$^{2}$D）的新型知识蒸馏框架，旨在解决多模态学习中常见的模态不平衡问题。G$^{2}$D通过设计一个融合了单模态和多模态目标的定制损失函数来优化模型，并引入了动态序列模态优先级（SMP）技术，以确保弱模态在学习过程中获得足够重视。实验结果表明，G$^{2}$D能够有效增强弱模态的重要性，并在分类和回归任务中超越了现有先进方法，从而提升了多模态模型的整体性能。

> **摘要翻译:** 多模态学习旨在利用来自不同数据模态的信息以实现更全面的性能。然而，传统的多模态模型常常受到模态不平衡的困扰，即一个或几个模态主导模型优化，导致次优的特征表示和弱模态的未充分利用。为了解决这一挑战，我们引入了梯度引导蒸馏（G$^{2}$D），这是一个知识蒸馏框架，通过定制的损失函数来优化多模态模型，该函数融合了单模态和多模态目标。G$^{2}$D在学习过程中进一步融入了动态序列模态优先级（SMP）技术，以确保每个模态都能引导学习过程，避免强模态掩盖弱模态的弊端。我们在多个真实世界数据集上验证了G$^{2}$D，结果表明G$^{2}$D在训练过程中增强了弱模态的重要性，并在分类和回归任务中超越了现有最先进的方法。我们的代码可在https://github.com/rAIson-Lab/G2D获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [443] [MADrive: Memory-Augmented Driving Scene Modeling](https://arxiv.org/abs/2506.21520)
> *MADrive：记忆增强的驾驶场景建模*

*Polina Karpikova, Daniil Selikhanovych, Kirill Struminsky, Ruslan Musaev, Maria Golitsyna, Dmitry Baranchuk* | **Category: cs.CV**

**Keywords:** 驾驶场景建模, 记忆增强, 3D高斯泼溅, 车辆合成, 自动驾驶

**Comment:** 

> **TL;DR:** MADrive是一个记忆增强的重建框架，通过从外部大型车辆资产库中检索并替换现有场景中的车辆，实现了自动驾驶环境中显著改变或新颖驾驶场景的光真实感合成。

**AI_Comments:** MADrive的创新点在于引入了“记忆增强”的概念，通过外部大规模3D资产库来增强场景重建的灵活性和真实感。它解决了现有方法难以合成大幅改变场景的痛点，通过MAD-Cars数据集和智能检索-集成模块，为自动驾驶环境的模拟和测试提供了新的、更强大的工具。这项工作在实际应用中具有重要意义，尤其是在需要生成多样化和极端驾驶场景进行自动驾驶系统训练和验证的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅场景重建方法虽然能实现高真实感建模，但重建结果与原始观测紧密相关，难以支持显著改变或新颖驾驶场景的光真实感合成。

**Method:** 本研究引入了MADrive框架，通过将观测到的车辆替换为从大型外部记忆库中检索到的视觉相似的3D资产来扩展现有场景重建方法的能力。具体地，发布了MAD-Cars数据集（包含约7万个360度野外捕获的汽车视频），并提出了一个检索模块，该模块能找到最相似的汽车实例，从视频中重建相应的3D资产，并通过方向对齐和重新打光将其整合到目标场景中。

**Result:** 替换后的车辆提供了场景中车辆的完整多视图表示，使得能够光真实感地合成大幅改变的配置。实验证明了这一点。

**Conclusion:** MADrive通过引入记忆增强的重建框架和大规模车辆资产库，成功克服了现有场景重建方法在支持复杂驾驶场景合成方面的局限性，实现了更高灵活度和真实感的场景建模。

> **ai_Abstract:** MADrive是一个记忆增强的框架，旨在解决现有3D场景重建方法在合成大幅改变或新颖驾驶场景时的局限性。它通过从包含7万个360度汽车视频的MAD-Cars数据集中检索视觉相似的3D车辆资产，并将其集成到目标场景中，从而实现对车辆的多视图、光真实感替换，极大地增强了自动驾驶环境的场景合成能力。

> **摘要翻译:** 标题：MADrive：记忆增强的驾驶场景建模

摘要：场景重建的最新进展推动了使用3D高斯泼溅技术对自动驾驶（AD）环境进行高度逼真的建模。然而，由此产生的重建结果仍然与原始观测紧密相关，难以支持显著改变或新颖驾驶场景的光真实感合成。这项工作引入了MADrive，一个记忆增强的重建框架，旨在通过用从大型外部记忆库中检索到的视觉相似的3D资产替换观察到的车辆来扩展现有场景重建方法的能力。具体来说，我们发布了MAD-Cars，一个精选的包含约7万个野外捕获的360度汽车视频的数据集，并提出了一个检索模块，该模块在记忆库中找到最相似的汽车实例，从视频中重建相应的3D资产，并通过方向对齐和重新打光将其整合到目标场景中。由此产生的替换提供了场景中车辆的完整多视图表示，使大幅改变配置的光真实感合成成为可能，这在我们的实验中得到了证明。项目页面：https://yandex-research.github.io/madrive/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [WAFT: Warping-Alone Field Transforms for Optical Flow](https://arxiv.org/abs/2506.21526)
> *WAFT：仅翘曲场变换实现光流估计*

*Yihan Wang, Jia Deng* | **Category: cs.CV**

**Keywords:** 光流, WAFT, 高分辨率翘曲, 成本体, 零样本泛化

**Comment:** 

> **TL;DR:** WAFT是一种简单有效的光流估计新方法，通过高分辨率翘曲取代成本体，实现了更高的精度、更低的内存消耗和更快的速度，并挑战了传统观念。

**AI_Comments:** 该论文通过提出WAFT，成功挑战了光流领域中长期以来关于成本体必要性的传统认知，这本身就是一项重要的创新。其“仅翘曲”的设计理念不仅简化了模型，还显著提升了效率和泛化能力，为光流估计方法的设计提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是挑战光流估计领域中“构建成本体对于获得强大性能是必要的”这一传统观念，旨在开发一种更简单、更高效的方法。

**Method:** WAFT（Warping-Alone Field Transforms）是一种用于光流估计的元架构。它类似于RAFT，但用高分辨率翘曲替代了成本体，从而降低了内存成本并提高了精度。WAFT设计简单灵活，具有最小的归纳偏置和对自定义设计的依赖。

**Result:** WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳的零样本泛化能力，并且比性能相似的方法快4.1倍。

**Conclusion:** WAFT证明了通过高分辨率翘曲替代成本体可以实现卓越的光流估计性能，这不仅挑战了领域内的传统认知，还提供了更高效、更通用的解决方案。

> **ai_Abstract:** WAFT（Warping-Alone Field Transforms）是一种新颖且高效的光流估计方法。它通过用高分辨率翘曲取代传统的成本体，在保持甚至提升精度的同时显著降低了内存消耗。该方法挑战了构建成本体是高性能必要条件的传统观点。WAFT作为一种简单灵活的元架构，在Spring和KITTI基准测试中表现优异，实现了最佳的零样本泛化，并且比同类方法快达4.1倍。

> **摘要翻译:** 我们引入了仅翘曲场变换（WAFT），这是一种简单有效的光流估计方法。WAFT类似于RAFT，但用高分辨率翘曲取代了成本体，以更低的内存成本实现了更高的精度。这种设计挑战了“构建成本体对于获得强大性能是必要的”这一传统观念。WAFT是一个简单灵活的元架构，具有最小的归纳偏置和对自定义设计的依赖。与现有方法相比，WAFT在Spring和KITTI基准测试中排名第一，在KITTI上实现了最佳的零样本泛化能力，同时比性能相似的方法快4.1倍。代码和模型权重可在 https://github.com/princeton-vl/WAFT 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [445] [StruMamba3D: Exploring Structural Mamba for Self-supervised Point Cloud Representation Learning](https://arxiv.org/abs/2506.21541)
> *StruMamba3D：探索结构化Mamba用于自监督点云表示学习*

*Chuxin Wang, Yixin Zha, Wenfei Yang, Tianzhu Zhang* | **Category: cs.CV**

**Keywords:** 点云, 自监督学习, Mamba, 状态空间模型, 表示学习

**Comment:** Accepted by ICCV 2025

> **TL;DR:** StruMamba3D通过引入空间状态和序列长度自适应策略，解决了现有基于Mamba的点云表示学习方法中三维点邻接性破坏和长序列记忆保留不足的问题，并在多个下游任务中取得了优越的性能和最先进的结果。

**AI_Comments:** 该论文的创新点在于为Mamba模型在点云学习中引入了空间状态概念，并结合了状态感知更新和轻量级卷积来更好地处理三维结构，同时提出的序列长度自适应策略增强了模型的实用性。其重要性在于显著提升了Mamba在点云表示学习领域的性能，并在关键数据集上达到了SOTA水平。抽象中未明确提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于Mamba的点云表示学习方法存在两个主要问题：在SSM处理过程中破坏三维点的邻接性，以及在下游任务中随着输入长度增加未能保留长序列记忆。

**Method:** 本文提出了StruMamba3D，一种新的自监督点云表示学习范式。它通过设计空间状态作为代理来保留点之间的空间依赖性；通过状态感知更新策略增强SSM，并结合轻量级卷积促进空间状态间的交互以进行高效结构建模；通过引入序列长度自适应策略，降低预训练的Mamba模型对不同输入长度的敏感性。

**Result:** StruMamba3D在四个下游任务中展示了优越的性能。在ModelNet40上达到了95.1%的最先进（SOTA）准确率，在ScanObjectNN最具挑战性的分割上（不使用投票策略）达到了92.75%的准确率。

**Conclusion:** StruMamba3D有效解决了现有基于Mamba的点云表示学习方法的局限性，在多个基准数据集上展现了卓越的性能和最先进的准确率。

> **ai_Abstract:** StruMamba3D提出了一种新颖的自监督点云表示学习范式，旨在解决现有基于Mamba方法在处理三维点云时面临的邻接性破坏和长序列记忆保留不足的问题。该方法通过引入空间状态来维护点间空间依赖，并结合状态感知更新策略和轻量级卷积来增强SSM的结构建模能力。此外，其序列长度自适应策略有效提升了模型对不同输入长度的鲁棒性。实验证明，StruMamba3D在多项下游任务中表现卓越，并在ModelNet40和ScanObjectNN数据集上取得了最先进的准确率。

> **摘要翻译:** 最近，基于Mamba的方法通过利用状态空间模型（SSM）高效的上下文建模能力和线性复杂度，在点云表示学习中展示了令人印象深刻的性能。然而，这些方法仍然面临两个限制SSM潜力的关键问题：在SSM处理过程中破坏三维点的邻接性，以及在下游任务中随着输入长度的增加未能保留长序列记忆。为了解决这些问题，我们提出了StruMamba3D，一种用于自监督点云表示学习的新范式。它具有多项优点。首先，我们设计了空间状态并将其用作代理以保留点之间的空间依赖性。其次，我们通过状态感知更新策略增强了SSM，并结合了轻量级卷积以促进空间状态之间的交互，从而实现高效的结构建模。第三，我们的方法通过引入序列长度自适应策略，降低了预训练的基于Mamba的模型对不同输入长度的敏感性。在四个下游任务上的实验结果展示了我们方法的优越性能。此外，我们的方法在ModelNet40上达到了95.1%的最先进准确率，在ScanObjectNN最具挑战性的分割上（不使用投票策略）达到了92.75%的准确率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [446] [DeOcc-1-to-3: 3D De-Occlusion from a Single Image via Self-Supervised Multi-View Diffusion](https://arxiv.org/abs/2506.21544)
> *DeOcc-1-to-3：基于自监督多视角扩散的单图像三维去遮挡*

*Yansong Qu, Shaohui Dai, Xinyang Li, Yuze Wang, You Shen, Liujuan Cao, Rongrong Ji* | **Category: cs.CV**

**Keywords:** 三维去遮挡, 单图像重建, 自监督学习, 多视角扩散, 基准测试

**Comment:** 

> **TL;DR:** DeOcc-1-to-3提出一个自监督多视角扩散框架，从单张遮挡图像生成一致的新视角以进行三维重建，并引入了一个新基准。

**AI_Comments:** 该论文的创新之处在于提出了一种自监督的多视角扩散框架，能够有效解决单图像三维重建中长期存在的遮挡问题。通过联合学习图像补全和多视角生成，显著提升了在部分遮挡条件下的三维重建质量。同时，引入首个遮挡感知重建基准，为该领域未来的研究提供了宝贵的评估工具和标准化协议，具有重要的实际应用价值和研究推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 从单张图像重建三维物体是一个长期存在的挑战，尤其是在真实世界的遮挡情况下。现有的基于扩散的视角合成模型在物体部分被遮挡时会失效，导致视角不一致和三维重建质量下降。

**Method:** 提出一个端到端、遮挡感知的多视角生成框架，直接从单张部分遮挡图像合成六个结构一致的新视角。该方法利用Pix2Gestalt数据集构建自监督训练流程，通过遮挡-非遮挡图像对和伪真值视角，训练模型学习结构感知补全和视角一致性。在不修改原始架构的情况下，全面微调视角合成模型以联合学习补全和多视角生成。此外，还引入了首个用于遮挡感知重建的基准。

**Result:** 该方法能够从单张部分遮挡图像直接合成六个结构一致的新视角，无需预先修复或手动标注即可进行后续的三维重建。同时，提出的基准为评估未来在部分遮挡下的方法提供了标准化协议。

**Conclusion:** 该论文提出了一个端到端的框架，用于从单张遮挡图像进行三维去遮挡和多视角生成，并通过自监督学习实现结构感知补全和视角一致性。同时，还引入了首个遮挡感知重建的基准，为该领域提供了标准化评估协议。

> **ai_Abstract:** 该论文提出了DeOcc-1-to-3，一个端到端的自监督多视角扩散框架，旨在解决从单张遮挡图像进行三维重建的挑战。针对现有扩散模型在遮挡场景下表现不佳的问题，该方法通过自监督学习，利用遮挡-非遮挡图像对和伪真值视角，从单张部分遮挡图像直接合成六个结构一致的新视角，从而实现高质量的三维重建，无需预先修复。此外，论文还首次引入了一个用于遮挡感知重建的基准，为该领域未来的研究提供了统一的评估标准。

> **摘要翻译:** 从单张图像重建三维物体是一个长期存在的挑战，尤其是在真实世界的遮挡情况下。虽然最近基于扩散的视角合成模型可以从单张RGB图像生成一致的新视角，但它们通常假设输入是完全可见的，并且当物体部分被遮挡时会失效。这导致视角不一致和三维重建质量下降。为了克服这一限制，我们提出了一个端到端的遮挡感知多视角生成框架。我们的方法直接从单张部分遮挡图像合成六个结构一致的新视角，无需预先修复或手动标注即可实现后续的三维重建。我们利用Pix2Gestalt数据集构建了一个自监督训练流程，利用遮挡-非遮挡图像对和伪真值视角来教导模型进行结构感知补全和视角一致性。在不修改原始架构的情况下，我们完全微调了视角合成模型，以联合学习补全和多视角生成。此外，我们引入了首个用于遮挡感知重建的基准，其涵盖了不同的遮挡级别、物体类别和遮罩模式。该基准为评估未来在部分遮挡下的方法提供了标准化协议。我们的代码可在 https://github.com/Quyans/DeOcc123 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [447] [SiM3D: Single-instance Multiview Multimodal and Multisetup 3D Anomaly Detection Benchmark](https://arxiv.org/abs/2506.21549)
> *SiM3D：单实例多视角多模态多设置三维异常检测基准*

*Alex Costanzino, Pierluigi Zama Ramirez, Luigi Lella, Matteo Ragaglia, Alessandro Oliva, Giuseppe Lisanti, Luigi Di Stefano* | **Category: cs.CV**

**Keywords:** 3D异常检测, 多模态, 多视角, 单实例学习, 基准数据集

**Comment:** 

> **TL;DR:** 提出了SiM3D，首个整合多视角和多模态信息的3D异常检测与分割基准，专注于制造业中单实例异常检测，并解决合成数据到真实数据的泛化挑战。

**AI_Comments:** SiM3D的创新之处在于它是首个将多视角和多模态信息整合到3D异常检测与分割领域的基准，并且特别关注了制造业中极具挑战性的单实例训练和合成到真实数据泛化问题。其提供的高质量数据集和评估方法为该领域未来的研究提供了宝贵的资源和标准。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D异常检测与分割缺乏整合多视角和多模态信息的基准。在制造业中，单实例异常检测（仅一个对象可用于训练）以及从合成数据到真实数据的泛化是重要的挑战。

**Method:** 提出了SiM3D，一个首次整合多视角和多模态信息的3D异常检测与分割基准。它包含一个使用顶级工业传感器和机器人获取的新颖多模态多视角数据集，该数据集包含333个实例的8种对象类型的高分辨率图像和点云，以及CAD模型和手动标注的3D分割真值。为了建立参考基线，论文还调整了著名的单视角方法，并使用新颖的异常体指标评估其性能。

**Result:** SiM3D提供了一个用于3D异常检测和分割的综合基准，包含一个多模态多视角数据集（高分辨率图像和点云，共333个实例，8种对象类型），以及用于异常测试样本的手动标注3D分割真值。此外，还建立了基于调整后单视角方法的参考基线，并引入了新的异常体评估指标。

**Conclusion:** SiM3D是首个将多视角和多模态信息整合到3D异常检测与分割中的基准，特别关注制造业中的单实例异常检测和合成到真实数据的泛化挑战，并提供了全面的数据集、真值和评估方法，为该领域的研究奠定了基础。

> **ai_Abstract:** 本文提出了SiM3D，一个开创性的3D异常检测与分割基准，首次整合了多视角和多模态信息。该基准特别关注制造业中的单实例异常检测场景，并解决了从合成数据到真实数据泛化的挑战。SiM3D包含一个新颖的多模态多视角数据集，该数据集通过工业级传感器和机器人采集，包含高分辨率图像、点云和CAD模型，并提供手动标注的3D分割真值。同时，论文还为多视角3D ADS任务建立了基线，并引入了新的评估指标。

> **摘要翻译:** 我们提出了SiM3D，这是第一个考虑整合多视角和多模态信息以进行全面三维异常检测和分割（ADS）的基准，其任务是生成基于体素的异常体。此外，SiM3D专注于制造业中一个备受关注的场景：单实例异常检测，即训练时只有一个对象可用，无论是真实的还是合成的。在这方面，SiM3D作为第一个解决从合成训练数据泛化到真实测试数据挑战的ADS基准脱颖而出。SiM3D包含一个使用顶级工业传感器和机器人获取的新颖多模态多视角数据集。该数据集包含333个实例的八种对象类型的多视角高分辨率图像（12 Mpx）和点云（7M点），以及每种类型的CAD模型。我们还为异常测试样本提供了手动标注的三维分割真值。为了为所提出的多视角三维ADS任务建立参考基线，我们调整了著名的单视角方法，并使用在异常体上操作的新颖指标评估了它们的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [10] [Exploring the Effects of Chatbot Anthropomorphism and Human Empathy on Human Prosocial Behavior Toward Chatbots](https://arxiv.org/abs/2506.20748)
> *探索聊天机器人拟人化和人类同理心对人类对聊天机器人亲社会行为的影响*

*Jingshu Li, Zicheng Zhu, Renwen Zhang, Yi-Chieh Lee* | **Category: cs.HC, cs.AI**

**Keywords:** 聊天机器人拟人化, 人类同理心, 亲社会行为, CASA框架, 人机交互

**Comment:** 

> **TL;DR:** 研究发现聊天机器人的拟人化（如人类身份和情感表达）能通过引发人类同理心来增加人类对聊天机器人的亲社会行为。

**AI_Comments:** 这项研究通过引入人类对聊天机器人“反向帮助”的概念，扩展了人机交互领域。它创新性地运用了CASA框架来解释拟人化和同理心在促进行为中的作用，为设计更具协作性和用户参与度的AI系统提供了重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究很少探讨促使人们帮助聊天机器人的因素，尽管人类帮助聊天机器人能带来性能提升和用户福祉等益处。

**Method:** 采用“计算机是社会行动者（CASA）”框架，通过一项在线实验（N=244），让聊天机器人在协作图像标注任务中犯错并解释原因，然后测量参与者对聊天机器人的亲社会行为和意图。还进行了定性分析。

**Result:** 聊天机器人的人类身份和情感表达增加了参与者对聊天机器人的亲社会行为和意图，其中同理心起中介作用。定性分析揭示了亲社会行为的两个动机：对聊天机器人的同理心和将聊天机器人视为类人。

**Conclusion:** 研究结果有助于理解和促进人类对聊天机器人的亲社会行为。

> **ai_Abstract:** 本研究基于“计算机是社会行动者”框架，探讨了聊天机器人拟人化（人类身份、情感表达）如何通过引发人类同理心来促进人类对聊天机器人的亲社会行为和意图。在线实验（N=244）显示，聊天机器人的人类身份和情感表达显著提升了用户的亲社会行为，且同理心是关键的中介因素。定性分析进一步揭示了同理心和类人感知是促使人们帮助聊天机器人的主要动机。

> **摘要翻译:** 聊天机器人越来越多地融入人们的生活，并被广泛用于帮助人们。最近，人们对相反的方向——人类帮助聊天机器人——的兴趣也日益增长，因为它带来了广泛的益处，包括更好的聊天机器人性能、人类福祉和协作成果。然而，很少有研究探讨促使人们帮助聊天机器人的因素。为了弥补这一空白，我们借鉴“计算机是社会行动者（CASA）”框架，研究聊天机器人拟人化——包括类人身份、情感表达和非语言表达——如何影响人类对聊天机器人的同理心及其随后的亲社会行为和意图。我们还探讨了人们对自己对聊天机器人亲社会行为的解释。我们进行了一项在线实验（N = 244），在实验中，聊天机器人在一项协作图像标注任务中犯了错误并向参与者解释了原因。然后我们测量了参与者对聊天机器人的亲社会行为和意图。我们的发现表明，聊天机器人的人类身份和情感表达增加了参与者对聊天机器人的亲社会行为和意图，其中同理心介导了这些影响。定性分析进一步确定了参与者亲社会行为的两个动机：对聊天机器人的同理心和将聊天机器人视为类人。我们讨论了这些结果对理解和促进人类对聊天机器人的亲社会行为的启示。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [35] ["TikTok, Do Your Thing": User Reactions to Social Surveillance in the Public Sphere](https://arxiv.org/abs/2506.20884)
> *“抖音，发挥你的作用”：用户对公共领域社会监控的反应*

*Meira Gilbert, Miranda Wei, Lindah Kotut* | **Category: cs.HC, cs.CY**

**Keywords:** TikTok, 社会监控, 用户反应, 众包, 隐私

**Comment:** 

> **TL;DR:** 一项对TikTok上“抖音，发挥你的作用”趋势的定性分析显示，尽管存在担忧，但用户对这种基于人群的陌生人识别行为普遍持支持态度，反映了人际监控的常态化。

**AI_Comments:** 这项研究通过定性分析揭示了社交媒体上人际监控的复杂用户反应，特别是在TikTok这一热门平台上。其创新之处在于关注“同伴监控”而非传统意义上的政府或企业监控，并揭示了用户对隐私和社区观念的演变。研究的重要性在于它触及了数字时代隐私边界模糊化的现实，以及用户在参与此类趋势时的内在矛盾心理。然而，研究的局限性可能在于其定性方法和样本量，可能无法完全代表所有TikTok用户的普遍看法。

<details>
  <summary>Details</summary>

**Motivation:** 了解用户对“抖音，发挥你的作用”这一病毒式趋势的反应，该趋势涉及在公共领域通过众包方式识别陌生人，通常出于浪漫目的。

**Method:** 对60个TikTok视频和1,901条用户评论进行了定性分析。

**Result:** 在审查的60个视频中，有19个人被成功识别。支持评论（n=883）是反对评论（n=310）的两倍多。支持评论表现出兴趣和同情，反映了社区和算法参与观念的演变；反对评论则关注不当关系、跟踪、同意和性别双重标准。

**Conclusion:** 本研究讨论了人际监控、在线跟踪的常态化，以及社会监控的演变，为用户在公共领域对人际监控和识别的看法提供了新视角。

> **ai_Abstract:** 本研究对TikTok上的“抖音，发挥你的作用”病毒式趋势进行了定性分析，该趋势涉及通过众包识别公共场合的陌生人。通过分析60个视频和1901条评论，研究发现尽管存在对跟踪和隐私的担忧，但用户对这种行为的支持度远超反对度，表明了人际监控的日益常态化以及社区和算法互动观念的转变。

> **摘要翻译:** “抖音，发挥你的作用”是一个病毒式趋势，用户试图通过信息众包来识别他们在公共场合看到的陌生人。该趋势早在2021年就开始了，用户通常出于浪漫目的参与其中（类似于“寻人启事”个人广告）。这种做法包括在公共领域的监控和识别行为，尽管是由同伴而非政府或公司进行的。为了了解用户对这一趋势的反应，我们对60个TikTok视频和1,901条用户评论进行了定性分析。在审查的60个视频中，我们发现有19个人被成功识别。我们还发现，尽管有表示反对的评论（n=310），但表示支持的评论（n=883）是其两倍多。支持性评论表现出真正的兴趣和同情，反映了社区和算法参与观念的演变。另一方面，反对性评论则强调了对不当关系、跟踪、同意和性别双重标准的担忧。我们结合人际监控、在线跟踪的常态化以及社会监控的演变来讨论这些见解，从而为用户在公共领域对人际监控和识别的看法提供新视角。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [59] [Effect of Haptic Feedback on Avoidance Behavior and Visual Exploration in Dynamic VR Pedestrian Environment](https://arxiv.org/abs/2506.20952)
> *触觉反馈对动态虚拟现实行人环境中避让行为和视觉探索的影响*

*Kyosuke Ishibashi, Atsushi Saito, Zin Y. Tun, Lucas Ray, Megan C. Coram, Akihiro Sakurai, Allison M. Okamura, Ko Yamamoto* | **Category: cs.HC, cs.RO**

**Keywords:** 触觉反馈, 虚拟现实, 避让行为, 行人模拟, 碰撞敏感性

**Comment:** 

> **TL;DR:** 本研究通过用户实验发现，在虚拟现实拥挤行人流中，触觉反馈会改变用户的避让行为和视觉探索，提高其对碰撞的敏感性。

**AI_Comments:** 本研究创新性地探讨了触觉反馈在VR行人模拟中的具体效果，填补了该领域的部分空白。其发现对于提升VR沉浸感和模拟真实行为具有重要意义，尤其是在应急训练和建筑设计评估等应用中。研究通过量化指标（如轨迹长度、骨盆角度）验证了触觉反馈对行为的影响，具有一定的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟现实中的人群模拟在应急疏散训练和建筑布局评估等领域具有潜在应用。尽管触觉反馈能增强VR沉浸感，但其对密集动态行人流中行走行为的影响尚不明确。

**Method:** 通过一项用户研究，调查了触觉反馈如何改变用户在虚拟现实拥挤行人流中的行走运动。

**Result:** 结果表明，触觉反馈改变了用户的碰撞避让动作，表现为行走轨迹长度增加和骨盆角度变化；即使NPC在视野内，用户对与NPC碰撞的瞬时反应中，其侧向位置和骨盆角度的位移也增加了；触觉反馈还增强了当NPC从侧面和后面接近时用户的意识和视觉探索；此外，行走速度的变化也因触觉反馈而增加。

**Conclusion:** 这些结果表明，触觉反馈增强了用户在虚拟现实环境中对碰撞的敏感性。

> **ai_Abstract:** 本研究旨在探究触觉反馈对虚拟现实（VR）中拥挤行人流中用户行走行为的影响。通过用户实验，研究发现触觉反馈显著改变了用户的碰撞避让动作，包括增加行走轨迹长度、改变骨盆角度，并增强了对非玩家角色（NPC）碰撞的瞬时反应（包括侧向位置和骨盆角度的位移），即使NPC在视野内。此外，触觉反馈还提升了用户在NPC从侧后方接近时的意识和视觉探索，并增加了行走速度的变化。研究结果表明，触觉反馈能有效提高用户在VR环境中对碰撞的敏感性。

> **摘要翻译:** 虚拟现实（VR）中的人群模拟是一个强大的工具，在应急疏散训练和建筑布局评估等方面具有潜在应用。虽然VR中的触觉反馈能增强沉浸式体验，但其对密集动态行人流中行走行为的影响尚不明确。通过一项用户研究，我们调查了触觉反馈如何改变用户在VR拥挤行人流中的行走运动。结果表明，触觉反馈改变了用户的碰撞避让动作，表现为行走轨迹长度增加和骨盆角度变化。即使NPC在视野内，用户对与NPC碰撞的瞬时反应中，其侧向位置和骨盆角度的位移也增加了。触觉反馈还增强了当NPC从侧面和后面接近时用户的意识和视觉探索。此外，行走速度的变化也因触觉反馈而增加。这些结果表明，触觉反馈增强了用户在VR环境中对碰撞的敏感性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [84] [Follow the user meaningfully and product growth will follow: A mixed methods case study tying UX Point of View & Growth leading to measurable impact](https://arxiv.org/abs/2506.21195)
> *有意义地跟随用户，产品增长随之而来：一项将用户体验视角与增长联系起来并产生可衡量影响的混合方法案例研究*

*Neha Raghuvanshi* | **Category: cs.HC**

**Keywords:** 混合方法, 用户体验研究（UXR）, 产品主导增长（PLG）, 用户价值, 业务增长

**Comment:** 

> **TL;DR:** 本案例研究展示了用户体验研究（UXR）和数据科学团队如何利用混合方法研究，战略性地影响产品主导增长（PLG），从而实现用户价值最大化和业务增长的平衡。

**AI_Comments:** 本研究的创新之处在于它将用户体验视角（UX POV）与实际的产品增长和可衡量的业务影响相结合，通过混合方法案例研究的形式提供了实用的指导。其重要性在于为跨职能团队提供了一个清晰的框架，以平衡用户价值和业务目标，这在当今以用户为中心的产品开发中至关重要。研究强调了用户体验研究和数据科学在实现双赢局面中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 跨职能团队如何在最大化用户价值和实现业务增长之间取得平衡，从而实现双赢局面？

**Method:** 用户体验研究（UXR）和数据科学团队对一个拥有百万级用户的密码管理器采用了混合方法研究，并结合用户体验视角金字塔（POV）的方法论，以战略性地影响产品主导增长（PLG）。

**Result:** 通过所采用的方法，用户、内部团队和业务都获得了成功，实现了用户价值和业务影响的可衡量。

**Conclusion:** 本案例研究提供了利用混合方法来最大化用户价值同时实现业务增长目标、影响跨职能团队以及衡量用户和业务影响的实用经验和技术。

> **ai_Abstract:** 本案例研究探讨了跨职能团队如何通过结合用户体验研究（UXR）和数据科学的混合方法，在一个拥有百万级用户的密码管理器中战略性地推动产品主导增长（PLG）。研究展示了如何平衡用户价值与业务增长，实现用户、团队和业务的三方共赢，并提供了衡量用户和业务影响的实用技术和经验，这些都与用户体验研究视角金字塔（POV）的方法论紧密关联。

> **摘要翻译:** 您是否曾好奇跨职能团队如何在最大化用户所获得价值和业务增长之间取得平衡，从而实现双赢局面？本案例研究展示了用户体验研究（UXR）和数据科学团队如何使用混合方法研究，战略性地影响一个拥有百万级用户密码管理器的产品主导增长（PLG），从而让我们的用户、内部团队和业务都获得成功。受众将从中获得利用混合方法的实用经验/技术，以：a. 在满足业务增长目标的同时最大化用户价值 b. 影响跨职能团队 c. 衡量用户和业务影响。本案例研究可以很容易地与用户体验研究视角金字塔（POV）[2]联系起来，该金字塔代表了一种构建视角的方法论，并进一步深入探讨如何将视角付诸行动以创造可衡量的用户和业务影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [108] [Subtitled Media Adaptations for People with Aphasia: Ongoing Accessibility Barriers and Emerging Design Practices](https://arxiv.org/abs/2506.21201)
> *失语症患者的字幕媒体改编：持续存在的无障碍障碍和新兴设计实践*

*Zihao You, Michael Crabb* | **Category: cs.HC**

**Keywords:** 失语症, 字幕, 无障碍, 个性化, 包容性设计

**Comment:** 3 pages, 1 figure, Access InContext Workshop at CHI 2025 on 26th of
  April

> **TL;DR:** 本研究呼吁为失语症患者开发个性化和包容性的字幕媒体解决方案，强调在系统设计过程中纳入他们的意见。

**AI_Comments:** 本文创新性地关注了失语症患者这一特定群体在字幕媒体消费中的无障碍问题，并提出了个性化和包容性设计的必要性。其重要性在于呼吁将受众群体（特别是残障人士）纳入设计过程，而非仅仅提供统一的辅助功能，这对于未来无障碍技术的发展具有指导意义。文章的局限性在于抽象中未提供具体的研究方法或初步结果，更多是提出问题和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的字幕“一刀切”方法无法满足具有复杂无障碍需求的人群，特别是失语症患者，他们在理解字幕文本方面面临重大挑战。因此，需要研究如何根据个人情况、内容和消费习惯对字幕进行个性化调整，以避免边缘化。

**Method:** 本研究致力于调查如何为失语症患者开发未来的媒体解决方案，以创建更具包容性的媒体观看环境。其关键在于使用合适的原型工具和方法，以实现在系统设计过程中的公平包容。

**Result:** Not mentioned in abstract

**Conclusion:** 本研究呼吁采取更具包容性的实践，重点关注如何将失语症患者的观点和意见纳入媒体研究，以开发更具包容性的媒体观看环境。

> **ai_Abstract:** 本研究关注字幕媒体对失语症患者造成的无障碍障碍，指出当前“一刀切”的字幕方法不适用，呼吁开发个性化且包容的媒体解决方案。文章强调将失语症患者的意见纳入媒体研究和系统设计过程的重要性，旨在通过合适的原型工具和方法，为他们创建更具包容性的媒体观看环境。

> **摘要翻译:** 通过电视、笔记本电脑和智能手机消费字幕有可能因其复杂的无障碍需求而边缘化人群。当前这种“一刀切”的无障碍辅助方法已不再适用，需要研究如何根据个人用户、上下文、内容和消费习惯进行个性化调整。例如，失语症患者在理解字幕文本方面遇到了重大挑战。
我们将我们的工作视为一项行动号召，旨在推动更具包容性的实践，重点关注如何将失语症患者的思想和意见纳入媒体研究。我们的工作旨在研究如何为失语症患者开发未来的媒体解决方案，以创建更具包容性的媒体观看环境。我们认为，实现这一目标的关键是适当的原型工具和方法，以实现在系统设计过程中的公平包容。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [129] [Multimodal LLMs for Visualization Reconstruction and Understanding](https://arxiv.org/abs/2506.21319)
> *多模态大语言模型用于可视化重建与理解*

*Can Liu, Chunlin Da, Xiaoxiao Long, Yuxiao Yang, Yu Zhang, Yong Wang* | **Category: cs.HC, cs.CV**

**Keywords:** 多模态大语言模型, 可视化理解, 数据提取, 图表重建, 矢量化表示

**Comment:** 

> **TL;DR:** 提出了一种新的数据集和专门训练的多模态可视化大语言模型，通过结合图表图像和矢量化表示来改进可视化理解、数据提取和图表重建。

**AI_Comments:** 这项工作通过引入专门的数据集和训练方法，有效地解决了现有通用多模态大模型在处理可视化数据时面临的挑战，特别是在解码数据到视觉映射和结构化信息提取方面的不足。其创新点在于结合了矢量化表示，这对于精确重建和理解图表至关重要。这对于数据分析和人机交互领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的多模态大语言模型在自然图像理解方面表现出色，但在可视化理解上存在困难，因为它们无法解码数据到视觉的映射规则并提取结构化信息。

**Method:** 研究人员提出了一个新的数据集，并训练了专门用于可视化理解的多模态可视化大语言模型。该方法将图表图像与其对应的矢量化表示、编码方案和数据特征相结合。提出的矢量格式能够紧凑而准确地重建可视化内容。

**Result:** 实验结果表明，在数据提取准确性和图表重建质量方面都有显著改进。

**Conclusion:** 通过专门的数据集和模型训练，多模态大语言模型能够显著提升对可视化的理解、数据提取和重建能力，克服了现有模型在这方面的局限性。

> **ai_Abstract:** 本文针对当前多模态大语言模型在可视化理解上的局限性，提出了一种新颖的方法。通过构建一个结合图表图像、矢量化表示、编码方案和数据特征的专用数据集，并训练了专门的多模态可视化大语言模型，显著提升了数据提取的准确性和图表重建的质量，实现了对可视化内容的有效理解和重建。

> **摘要翻译:** 可视化对于数据交流至关重要，但理解它们需要同时理解视觉元素及其底层数据关系。当前的多模态大模型虽然在自然图像理解方面表现出色，但在可视化方面却举步维艰，因为它们无法解码数据到视觉的映射规则并提取结构化信息。为了解决这些挑战，我们提出了一个新颖的数据集并训练了专门用于理解的多模态可视化大语言模型。我们的方法将图表图像与它们相应的矢量化表示、编码方案和数据特征相结合。所提出的矢量格式能够紧凑而准确地重建可视化内容。实验结果表明，在数据提取准确性和图表重建质量方面都有显著改进。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [147] ["Who Should I Believe?": User Interpretation and Decision-Making When a Family Healthcare Robot Contradicts Human Memory](https://arxiv.org/abs/2506.21322)
> *“我该相信谁？”：家庭医疗机器人与人类记忆矛盾时的用户解读与决策*

*Hong Wang, Natalia Calvo-Barajas, Katie Winkle, Ginevra Castellano* | **Category: cs.HC, cs.RO**

**Keywords:** 家庭医疗机器人, 用户信任, 透明度, 决策, 过度信任

**Comment:** 8 pages

> **TL;DR:** 本研究探讨了当家庭医疗机器人提供的信息与用户记忆矛盾时，用户如何解读信息并做出决策，以及机器人透明度和社交性对其信任的影响。结果显示，透明度影响用户对信息差异的解释，且用户倾向于过度信任机器人。

**AI_Comments:** 该研究揭示了在人机交互，特别是医疗健康领域中，机器人透明度对用户信任和决策的关键影响。其创新之处在于通过实验量化了透明度对信息差异解释的影响，并揭示了用户对机器人的过度信任倾向。这项工作对于未来家庭医疗机器人的设计，尤其是系统访问控制和避免用户过度依赖方面，具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着智能医疗机器人在家庭环境中部署的可能性日益增加，当机器人提供的信息与用户记忆矛盾时，如何处理用户信任和决策成为一个挑战。

**Method:** 本研究采用2x2被试间在线研究设计，共有176名参与者。参与者观看一个Furhat机器人作为家庭医疗助手的视频，该机器人建议虚构用户在与用户记忆不同的时间服药。研究考察了机器人透明度和社交性对用户解读、决策和感知信任的影响。

**Result:** 机器人透明度影响了用户对信息差异的解释：低透明度机器人下，用户最常假设是自己记错了时间；高透明度机器人下，参与者更倾向于将差异归因于外部因素（如伴侣修改了机器人信息）。此外，参与者表现出过度信任倾向，即使怀疑系统故障或第三方干扰，也常优先采纳机器人建议而非用户记忆。

**Conclusion:** 研究结果强调了机器人系统中透明度机制的影响，家庭环境中多用户机器人系统访问控制的复杂性和重要性，以及用户在医疗等敏感领域过度依赖机器人的潜在风险。

> **ai_Abstract:** 本研究探讨了当家庭医疗机器人提供的信息与用户记忆冲突时，机器人透明度和社交性对用户解读、决策和信任的影响。通过一项有176名参与者参与的在线实验，结果显示机器人透明度会影响用户对信息差异的归因，即低透明度导致用户怀疑自身记忆，高透明度则归因于外部因素。研究还发现，用户普遍存在过度信任机器人的倾向，即使面对潜在故障或第三方干扰，仍优先采纳机器人建议。这凸显了透明度机制、多用户系统访问控制的重要性，并警示了用户在医疗领域过度依赖机器人的风险。

> **摘要翻译:** “我该相信谁？”：家庭医疗机器人与人类记忆矛盾时的用户解读与决策

摘要：
机器人提供物理辅助、心理支持和日常健康管理的能力的进步，使得在不久的将来在家庭环境中部署智能医疗机器人变得越来越可行。然而，当这些机器人提供的信息与用户的记忆相矛盾时，就会出现挑战，引发用户信任和决策方面的担忧。本文提出了一项研究，探讨了当机器人提供冲突信息时，改变机器人的透明度和社交性水平如何影响用户的解读、决策和感知信任。在一项2x2被试间在线研究中，176名参与者观看了Furhat机器人作为家庭医疗助手的视频，该机器人建议一个虚构用户在与用户记忆不同的时间服药。结果表明，机器人透明度影响了用户对信息差异的解读：对于低透明度机器人，最常见的假设是用户没有正确记住时间，而对于高透明度机器人，参与者更有可能将差异归因于外部因素，例如伴侣或另一个家庭成员修改了机器人的信息。此外，参与者表现出过度信任的倾向，即使怀疑系统故障或第三方干扰，也常常优先采纳机器人的建议而非用户的记忆。这些发现强调了透明度机制在机器人系统中的影响，与家庭环境中部署的多用户机器人系统访问控制相关的复杂性和重要性，以及用户在医疗等敏感领域过度依赖机器人的潜在风险。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [155] [An evaluation of level of detail degradation in head-mounted display peripheries](https://arxiv.org/abs/2506.21441)
> *头戴式显示器外围细节层次降级的评估*

*Benjamin Watson, Neff Walker, Larry F Hodges, Martin Reddy* | **Category: cs.HC, cs.GR**

**Keywords:** 头戴式显示器, 细节层次, 虚拟环境, 用户研究, 性能评估

**Comment:** 

> **TL;DR:** 本研究评估了头戴式显示器中高细节插图对用户在搜索任务中表现的影响。结果显示，高细节显示器无论有无插图，在搜索时间或准确性上均无显著差异，仅无插图的低细节显示器表现出显著不同。

**AI_Comments:** 该研究通过严格的实验设计，对头戴式显示器中细节层次管理策略的实际效果进行了量化评估。其创新点在于提出了一个设计范式并进行了原型验证。结果表明，在特定任务下，高细节插图并未带来预期的性能提升，这挑战了直觉并对虚拟现实系统设计具有重要指导意义，提示开发者需谨慎评估细节优化策略。研究的局限性在于任务简单，未来工作将探索更复杂场景。

<details>
  <summary>Details</summary>

**Motivation:** 提出一种用于管理虚拟环境中细节层次的系统设计范例，并作为该范例中原型步骤的一个例子，评估头戴式显示器中使用高细节插图的有效性。

**Method:** 进行了一项用户研究，十名受试者执行简单的目标搜索和识别任务。受试者使用七种不同配置（在插图大小和外围细节上有所不同）的头戴式显示器。实验控制了帧率、目标位置、输入方法和显示器使用顺序。通过方差分析（ANOVAs）评估了搜索时间和正确识别率这两个主要因变量。

**Result:** ANOVA结果显示，无插图的高细节显示器与有插图的显示器相比，在搜索时间或准确性上没有显著差异。事实上，只有无插图的低细节显示器返回了显著不同的结果。

**Conclusion:** 在所测试的任务和条件下，头戴式显示器中高细节插图的使用并未显著改善用户在搜索任务中的表现。仅无插图的低细节显示器表现出显著差异，这表明并非所有细节层次的降级策略都对性能产生负面影响，或并非所有高细节的提供都能带来性能提升。

> **ai_Abstract:** 本研究提出了一种虚拟环境细节层次管理系统的设计范式，并以头戴式显示器为例，通过用户研究评估了高细节插图的有效性。实验中，10名受试者使用七种不同配置的显示器完成简单搜索任务。结果表明，高细节显示器无论是否包含插图，在搜索时间或准确性上均无显著差异，仅无插图的低细节显示器表现出显著不同。这提示在头戴式显示器中，并非所有细节层次的增加都能带来性能提升。

> **摘要翻译:** 提出了一个用于管理虚拟环境中细节层次的系统设计范例。作为该范例中原型步骤的一个例子，进行了一项用户研究，以评估与头戴式显示器一起使用的高细节插图的有效性。十名受试者被分配了一个简单的搜索任务，要求定位和识别一个单一的目标对象。所有受试者都使用了七种不同的显示器（自变量），这些显示器在插图大小和外围细节方面有所不同，以执行此任务。帧率、目标位置、受试者输入方法和显示器使用顺序都得到了控制。主要的因变量是正确识别试验的搜索时间，以及所有正确识别试验的百分比。结果的方差分析（ANOVAs）显示，无插图的高细节显示器与有插图的显示器相比，在搜索时间或准确性上没有显著差异。事实上，只有无插图的低细节显示器返回了显著不同的结果。正在进行进一步的研究，以检查不同任务复杂性、插图大小和细节层次的影响。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [164] [A Systematic Review of Human-AI Co-Creativity](https://arxiv.org/abs/2506.21333)
> *人机协同创造的系统综述*

*Saloni Singh, Koen Hndriks, Drik Heylen, Kim Baraka* | **Category: cs.HC, cs.AI, I.2.11**

**Keywords:** 人机协同创造, 系统综述, 协同创造系统, 用户控制, 设计考量

**Comment:** 

> **TL;DR:** 本文对62篇关于人机协同创造系统的论文进行了系统综述，识别了关键设计维度和24项设计考量，发现高用户控制度能提升满意度，自适应主动系统能增强协作，并指出了该领域的现有差距。

**AI_Comments:** 这篇系统综述为理解人机协同创造领域的设计挑战和机遇提供了全面的视角。其创新之处在于系统性地梳理了现有研究，并提炼出关键的设计维度和具体的设计考量，对未来协同创造系统的开发具有重要的指导意义。论文强调了用户控制和系统主动性的平衡，以及信任建立的重要性，这些都是人机协作中不可或缺的因素。然而，论文也指出了当前研究在支持早期创造阶段和用户适应性方面的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了给未来人机协同创造系统的设计提供有价值且高效的基础，本研究旨在通过系统文献综述来总结现有设计考量。

**Method:** 本研究对62篇关于协同创造系统的论文进行了系统文献综述，这些论文涵盖视觉艺术、设计和写作等应用领域，其中AI不仅是工具，更是创造过程中的积极协作者。

**Result:** 研究识别了与系统设计相关的几个关键维度：创造过程的阶段、创造性任务、系统的主动行为、用户控制、系统实体化和AI模型类型。研究发现，提供高用户控制的系统能带来更高的满意度、信任和对创造成果更强的归属感。此外，自适应且情境敏感的主动系统可以增强协作。研究还提取了24项设计考量，强调鼓励用户外化思考以及增加系统社交存在感和透明度以培养信任的价值。

**Conclusion:** 尽管近期取得了进展，但在人机协同创造领域仍存在重要空白，例如对问题澄清等早期创造阶段的支持有限，以及用户适应AI系统相关的挑战。

> **ai_Abstract:** 本文对62篇关于人机协同创造系统的文献进行了系统综述。研究旨在为未来系统设计提供基础，识别了创造过程阶段、任务、系统主动性、用户控制、系统实体化和AI模型类型等关键设计维度。研究发现，高用户控制能提升用户满意度和归属感，而自适应主动系统能增强协作。此外，还提取了24项设计考量，强调了外部化思考和系统透明度的重要性。研究同时指出了当前领域在早期创造阶段支持和用户适应性方面的不足。

> **摘要翻译:** 协同创造社区在开发更复杂和定制化的系统以支持和增强人类创造力方面取得了显著进展。先前的设计考量可以作为未来系统宝贵而高效的基础。为了支持这项工作，我们对62篇关于协同创造系统的论文进行了系统文献综述。这些论文涵盖了视觉艺术、设计和写作等广泛的应用领域，其中AI不仅作为工具，而且作为创造过程中的积极合作者。通过这次综述，我们确定了几个与系统设计相关的关键维度：创造过程的阶段、创造性任务、系统的主动行为、用户控制、系统实体化和AI模型类型。我们的研究结果表明，提供高用户控制的系统能带来更高的满意度、信任和对创造成果更强的归属感。此外，自适应且情境敏感的主动系统可以增强协作。我们还提取了24项设计考量，强调了鼓励用户外化思考以及增加系统社交存在感和透明度以培养信任的价值。尽管近期取得了进展，但仍存在重要的空白，例如对问题澄清等早期创造阶段的支持有限，以及用户适应AI系统相关的挑战。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [175] [Managing level of detail through head-tracked peripheral degradation: a model and resulting design principles](https://arxiv.org/abs/2506.21456)
> *通过头部追踪的周边降级管理细节水平：一个模型和设计原则*

*Benjamin Watson, Neff Walker, Larry F Hodges* | **Category: cs.HC, cs.GR**

**Keywords:** 细节水平管理, 周边降级, 头部追踪显示器, 心理物理学模型, 搜索性能

**Comment:** 

> **TL;DR:** 本文提出了一个基于眼/头运动权衡的心理物理学模型，解释了头部追踪大视场显示器中周边细节降级的有效性，并通过实验验证了模型，并提出了设计原则。

**AI_Comments:** 这项研究通过建立心理物理学模型并进行实验验证，为头部追踪大视场显示器中高效管理细节水平提供了理论基础和实用的设计原则。其创新点在于将眼/头运动权衡纳入模型，并明确了高细节区域的最小有效尺寸，这对于优化虚拟现实和增强现实等应用的用户体验和系统性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 先前工作表明在头部追踪的大视场显示器中，降低周边细节水平（LOD）是有用的，但需要一个解释其有效性并指导设计的模型。

**Method:** 本文提出了一个基于眼/头运动权衡的心理物理学模型，解释周边降级的有效性并指导设计。此外，还进行了一项实验，评估了周边降级显示器中高细节中心区域（内嵌区域）的形状和面积对搜索性能的影响。

**Result:** 实验结果表明，内嵌区域的形状对性能没有显著影响。然而，内嵌区域的面积是显著因素：当显示器内嵌区域的水平和垂直视角至少为30度时，其性能与未降级显示器的性能没有显著差异。这些结果与提出的模型一致。

**Conclusion:** 本文提出的心理物理学模型能够解释周边细节降级的有效性，并且实验结果验证了该模型，为周边降级显示器的设计提供了指导原则。

> **ai_Abstract:** 本文提出了一个基于眼/头运动权衡的心理物理学模型，以解释头部追踪大视场显示器中周边细节降级的有效性，并为设计周边降级显示器提供指导。通过实验评估内嵌区域形状和面积对搜索性能的影响，发现形状不重要，而内嵌区域面积至少达到30度视角时，性能与未降级显示器相当，验证了模型的有效性。

> **摘要翻译:** 先前的工作已经证明了在头部追踪的大视场显示器周边区域中降低细节水平（LOD）的实用性。本文提供了一个基于心理物理学的模型，该模型以眼/头运动权衡为中心，解释了周边降级的有效性，并提出了周边降级显示器应如何设计。进行了一项实验，评估了周边降级显示器中高细节中心区域（内嵌区域）的形状和面积对搜索性能的影响。结果表明，内嵌区域的形状对性能不是一个显著因素。然而，内嵌区域的面积是显著的：当显示器内嵌区域的水平和垂直视角至少为30度时，其性能与未降级显示器的性能没有显著差异。这些结果与所提出的模型一致。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [181] [Lightweight Fingernail Haptic Device: Unobstructed Fingerpad Force and Vibration Feedback for Enhanced Virtual Dexterous Manipulation](https://arxiv.org/abs/2506.21417)
> *轻量级指甲触觉设备：无障碍指尖力与振动反馈，增强虚拟灵巧操作*

*Yunxiu Xu, Siyu Wang, Shoichi Hasegawa* | **Category: cs.HC, H.5.2; I.3.6**

**Keywords:** 触觉设备, 指甲佩戴, 虚拟现实, 灵巧操作, 轻量级

**Comment:** 14 pages, 15 figures, 2 tables. Published in IEEE Transactions on
  Haptics (Early Access)

> **TL;DR:** 一种轻量级（指甲佩戴）触觉设备，提供力与振动反馈，显著提高虚拟操作效率，同时不影响真实世界互动。

**AI_Comments:** 该研究通过将触觉反馈设备创新性地附着在指甲上，有效解决了传统手套式设备阻碍指尖触觉和真实世界操作的问题，实现了轻量化和高可用性。其在虚拟操作效率提升方面的实证结果，展示了简洁机制下触觉反馈的巨大潜力，为未来人机交互界面的设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供不阻碍真实世界互动的虚拟灵巧操作触觉反馈，解决传统手套式设备的局限性。

**Method:** 开发了一种轻量级（每根手指1.55克）可穿戴指尖触觉设备，通过附着在指甲上的细绳和执行器实现。该设备集成了软件与物理引擎，提供握力、碰撞和滑动振动反馈。通过压力感知、滑动反馈、灵巧操作任务和日常操作评估其性能，并收集用户主观体验。

**Result:** 参与者能够感知并响应压力和振动反馈。微小的触觉提示显著提高了虚拟任务效率。该设备保留了触觉感知，最大限度地减少了对真实世界操作的阻碍，优于手套式触觉设备。

**Conclusion:** 这项研究为设计平衡了轻量化结构、灵巧操作触觉反馈和日常佩戴性的触觉界面提供了一个潜在的解决方案。

> **ai_Abstract:** 本研究介绍了一种创新的轻量级（1.55克/指）指甲佩戴式触觉设备，旨在为虚拟环境中的灵巧操作提供物理基础的力与振动反馈，同时不干扰真实世界互动。该设备通过将细绳和执行器连接到指甲实现，并与物理引擎集成以提供多种反馈。实验结果表明，该设备能有效传递压力和振动反馈，并显著提升虚拟任务效率。其主要优势在于轻量化设计和对真实世界操作的无阻碍，为平衡佩戴性、反馈效果和日常可用性的触觉界面设计提供了新途径。

> **摘要翻译:** 这项研究提出了一种轻量级、可穿戴的指尖触觉设备，可在虚拟环境中为灵巧操作提供基于物理的触觉反馈，同时不阻碍真实世界的互动。该设备采用附着在指甲上的细绳和执行器设计，确保了最小的重量（每根手指1.55克）并保持了手指的灵活性。将软件与物理引擎集成，可呈现多种类型的触觉反馈（握力、碰撞和滑动振动反馈）。我们评估了设备在压力感知、滑动反馈、典型的灵巧操作任务和日常操作中的性能，并通过主观评估收集了用户体验。我们的结果表明，参与者能够感知并响应压力和振动反馈。通过灵巧操作实验，我们进一步证明这些微小的触觉提示显著提高了虚拟任务效率，展示了轻量级触觉反馈如何在没有复杂机制的情况下增强操作性能。该设备在保留触觉感知和最大限度减少对真实世界操作的阻碍方面，相对于手套式触觉设备具有关键优势。这项研究为设计平衡了轻量化结构、灵巧操作触觉反馈和日常佩戴性的触觉界面提供了一个潜在的解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [8] [Domain Knowledge in Requirements Engineering: A Systematic Mapping Study](https://arxiv.org/abs/2506.20754)
> *需求工程中的领域知识：一项系统映射研究*

*Marina Araújo, Júlia Araújo, Romeu Oliveira, Lucas Romao, Marcos Kalinowski* | **Category: cs.SE**

**Keywords:** 领域知识, 需求工程, 系统映射研究, 知识管理, 需求规范

**Comment:** Accepted for publication at the 51st Euromicro Conference Series on
  Software Engineering and Advanced Applications (SEAA) 2025

> **TL;DR:** 该研究通过系统映射，提供了关于如何在需求工程中有效利用领域知识的全面概述，识别了现有方法、挑战和未来研究方向。

**AI_Comments:** 这项研究通过系统映射，有效地整合了需求工程领域中关于领域知识的现有文献，填补了该领域系统性总结的空白。其价值在于为研究人员和实践者提供了全面的知识图谱，不仅识别了成熟的方法，也清晰地指出了当前面临的挑战和未来值得探索的方向，特别是对自动化和可持续解决方案的强调，具有前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管领域知识对于需求工程的成功至关重要，但科学文献中仍缺乏关于如何有效使用和操作化领域知识的系统整合。本研究旨在填补这一空白，提供现有贡献的全面概述。

**Method:** 进行了一项系统映射研究，采用了混合搜索策略，结合了数据库搜索与迭代式前向和后向滚雪球方法。

**Result:** 共发现了75篇符合纳入标准的论文。分析强调了所解决的主要需求类型、最常考虑的质量属性，以及领域知识在形式化、获取和长期维护中反复出现的挑战。研究结果为研究人员和实践者识别既定方法和未解决问题提供了支持，并为未来研究指明了有前景的方向。

**Conclusion:** 本研究通过提供全面的概述，有助于为知识驱动的需求工程构建概念和方法论基础。

> **ai_Abstract:** 本系统映射研究旨在弥补需求工程（RE）领域知识应用系统整合的空白。通过对75篇相关论文的分析，该研究概述了现有方法、技术和工具，并识别了领域知识在RE中面临的主要挑战，如形式化、获取和维护。研究结果为研究人员和实践者提供了关于现有方法和未解决问题的洞察，并指出了未来研究的方向，特别是在开发可扩展、自动化和可持续的领域知识集成方案方面。本研究为知识驱动的需求工程奠定了概念和方法论基础。

> **摘要翻译:** [背景] 领域知识被认为是需求工程（RE）成功的关键组成部分，因为它提供了理解系统上下文、确保与利益相关者需求一致以及减少需求规范模糊性所需的概念支持。尽管其相关性，科学文献仍然缺乏对领域知识如何在需求工程中有效使用和操作化的系统整合。[目标] 本文通过提供现有贡献的全面概述，包括将领域知识纳入需求工程实践的方法、技术和工具，来解决这一空白。[方法] 我们采用混合搜索策略，结合数据库搜索与迭代式前向和后向滚雪球，进行了一项系统映射研究。[结果] 总共找到了75篇符合我们纳入标准的论文。分析强调了所解决的主要需求类型、最常考虑的质量属性，以及领域知识在形式化、获取和长期维护中反复出现的挑战。研究结果为研究人员和实践者识别既定方法和未解决问题提供了支持。该研究还概述了未来研究的有前景方向，强调开发可扩展、自动化和可持续的解决方案，以将领域知识整合到需求工程过程中。[结论] 该研究通过提供全面的概述，有助于为知识驱动的需求工程构建概念和方法论基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [33] [Agile Management for Machine Learning: A Systematic Mapping Study](https://arxiv.org/abs/2506.20759)
> *机器学习的敏捷管理：一项系统性映射研究*

*Lucas Romao, Hugo Villamizar, Romeu Oliveira, Silvio Alonso, Marcos Kalinowski* | **Category: cs.SE, cs.AI**

**Keywords:** 敏捷管理, 机器学习, 系统性映射研究, 项目管理, 软件工程

**Comment:** Accepted for publication at the 51st Euromicro Conference Series on
  Software Engineering and Advanced Applications (SEAA) 2025

> **TL;DR:** 本研究通过系统性映射研究，概述了机器学习系统敏捷管理的现状，识别了八个框架和八个关键主题，并指出主要挑战是ML任务的准确工作量估算，强调需要更多实证评估。

**AI_Comments:** 这项研究通过系统性映射，清晰地描绘了机器学习项目敏捷管理的当前图景，识别了现有框架和实践，并突出了工作量估算这一核心挑战，为未来的研究和实践提供了宝贵的起点。其创新之处在于将敏捷方法论与ML的独特动态性相结合进行审视，填补了这一交叉领域的知识空白。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习（ML）系统开发具有实验周期和数据快速变化的动态性，对传统项目管理构成挑战。尽管敏捷方法似乎适合，但如何有效应用于ML系统尚不明确，需要定制化方法。因此，本研究旨在概述ML系统敏捷管理的现状。

**Method:** 本研究采用系统性映射研究方法，结合数据库搜索以及前向和后向滚雪球迭代的混合搜索策略。

**Result:** 研究识别了2008年至2024年间发表的27篇论文。从中识别出八个框架，并将推荐和实践分为八个关键主题，例如迭代灵活性、创新性ML特定工件和最小可行模型。研究中发现的主要挑战是ML相关任务的准确工作量估算。

**Conclusion:** 本研究通过绘制该领域的现状图并识别开放差距做出了贡献。尽管存在相关工作，但仍需要更强有力的实证评估来验证这些贡献。

> **ai_Abstract:** 本文进行了一项系统性映射研究，旨在概述机器学习（ML）系统敏捷管理的现状。研究通过混合搜索策略筛选了2008年至2024年间的27篇论文，识别出八个敏捷管理框架，并归纳了八个关键主题，如迭代灵活性和ML特定工件。研究发现，ML任务的准确工作量估算是主要挑战。研究贡献在于描绘了该领域的现状并指出了现有差距，强调未来需要更多实证评估。

> **摘要翻译:** [背景] 机器学习（ML）驱动的系统存在于我们的社会中，推动着重大的数字化转型。ML开发动态性强，以实验周期和数据快速变化为特征，给传统项目管理带来了挑战。敏捷方法以其灵活性和增量交付，似乎非常适合应对这种动态性。然而，目前尚不清楚如何在ML驱动系统背景下有效应用这些方法，因为这些挑战需要定制化的方法。
[目标] 我们的目标是概述ML驱动系统敏捷管理的最新现状。[方法] 我们采用了一种系统性映射研究方法，该方法结合了数据库搜索与前向和后向滚雪球迭代的混合搜索策略。[结果] 我们的研究识别了2008年至2024年间发表的27篇论文。从中，我们识别了八个框架，并将推荐和实践分为八个关键主题，例如迭代灵活性、创新性ML特定工件和最小可行模型。研究中发现的主要挑战是ML相关任务的准确工作量估算。[结论] 本研究通过绘制该领域的现状图并识别开放差距做出了贡献。尽管存在相关工作，但仍需要更强有力的实证评估来验证这些贡献。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [57] [Generating Reliable Adverse event Profiles for Health through Automated Integrated Data (GRAPH-AID): A Semi-Automated Ontology Building Approach](https://arxiv.org/abs/2506.20851)
> *通过自动化集成数据生成可靠不良事件档案（GRAPH-AID）：一种半自动化本体构建方法*

*Srikar Reddy Gadusu, Larry Callahan, Samir Lababidi, Arunasri Nishtala, Sophia Healey, Hande McGinty* | **Category: cs.SE, cs.AI, cs.DB**

**Keywords:** 本体构建, Neo4j, OWL, Python, 不良事件, 数据集成

**Comment:** 

> **TL;DR:** 本研究提出了一种用户友好的半自动化方法，利用Python和rdflib库，将Neo4j数据库中的不良事件数据集成到OWL本体中，以克服现有方法对描述逻辑语法的要求，支持药物安全监测和公共卫生决策。

**AI_Comments:** 该研究的创新之处在于提出了一种用户友好的半自动化本体构建方法，克服了传统本体集成方法对描述逻辑语法的较高要求。通过利用Python和rdflib库，并针对实际的不良事件报告数据进行应用，该方法显著降低了本体开发的门槛，尤其是在处理大规模、动态变化的数据集时，具有重要的实用价值。它为药物安全监测和公共卫生领域的数据集成和知识表示提供了有效工具。

<details>
  <summary>Details</summary>

**Motivation:** 随着数据和知识的快速增长以及数据内容的频繁变化，本体生成和知识图谱构建面临挑战。具体而言，将Neo4j数据库与Web本体语言（OWL）无缝集成存在困难，且现有方法通常需要用户理解描述逻辑（DL）语法，这对于许多用户而言是一个障碍。

**Method:** 本研究提出了一种用户友好的方法，利用Python及其rdflib库来支持本体开发。通过一个集成了美国食品药品监督管理局（FDA）不良事件报告系统（FAERS）数据的Neo4j数据库，开发了一个Python脚本，该脚本能自动生成所需的类及其公理，从而促进Neo4j数据与OWL本体的集成。

**Result:** 该方法成功地将FDA不良事件报告系统（FAERS）的数据从Neo4j数据库集成到OWL本体中，并自动生成了所需的类及其公理，展示了其在快速增长的不良药物事件数据集背景下本体生成的实用性。

**Conclusion:** 本研究提供了一种实用的解决方案，克服了在快速增长的不良药物事件数据集背景下本体生成所面临的挑战，支持了改进的药物安全监测和公共卫生决策。

> **ai_Abstract:** 本论文提出了一种名为GRAPH-AID的半自动化本体构建方法，旨在解决将Neo4j数据库中的不良事件数据无缝集成到OWL本体的挑战。针对现有方法需要用户理解复杂描述逻辑语法的问题，研究开发了一个利用Python和rdflib库的用户友好型脚本。该脚本能够自动从Neo4j数据库（包含FDA不良事件报告系统数据）生成本体所需的类和公理，从而简化了本体开发和数据集成过程。该方法为在不断增长的不良药物事件数据背景下，提高药物安全监测和公共卫生决策提供了实用支持。

> **摘要翻译:** 随着数据和知识的迅速扩展，采用系统化的本体生成方法变得至关重要。随着数据量的日常增加和内容的频繁变化，对存储和检索信息以创建知识图谱的数据库的需求变得日益紧迫。先前建立的知识获取与表示方法（KNARM）概述了一种系统化的方法来应对这些挑战并创建知识图谱。然而，遵循这种方法凸显了将Neo4j数据库与Web本体语言（OWL）无缝集成的现有挑战。之前已讨论过将Neo4j数据集成到本体中的尝试，但这些方法通常需要理解描述逻辑（DL）语法，这可能对许多用户不熟悉。因此，需要一种更易于访问的方法来弥补这一差距。本文提出了一种用户友好的方法，该方法利用Python及其rdflib库来支持本体开发。我们通过一个我们创建的Neo4j数据库展示了我们的新颖方法，该数据库通过集成来自美国食品药品监督管理局（FDA）不良事件报告系统（FAERS）数据库的数据而构建。利用此数据集，我们开发了一个Python脚本，该脚本自动生成所需的类及其公理，从而促进了更顺畅的集成过程。这种方法为在快速增长的不良药物事件数据集背景下本体生成所面临的挑战提供了一个实用解决方案，支持改进的药物安全监测和公共卫生决策。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [82] [Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation](https://arxiv.org/abs/2506.20869)
> *为实际应用设计、开发和评估RAG系统*

*Md Toufique Hasan, Muhammad Waseem, Kai-Kristian Kemell, Ayman Asad Khan, Mika Saari, Pekka Abrahamsson* | **Category: cs.SE, cs.AI, cs.IR, D.2.11; I.2.6; H.3.3**

**Keywords:** RAG系统, 大型语言模型, 真实应用, 用户评估, 经验教训

**Comment:** Accepted as a full paper to the 51st Euromicro Conference on Software
  Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This
  is the preprint version and not the final camera ready version

> **TL;DR:** 本文介绍了为实际场景开发的五个RAG应用，评估了用户反馈，并总结了12条关于RAG系统在实际应用中的经验教训。

**AI_Comments:** 本文的创新之处在于其强调了RAG系统在真实世界应用中的工程实践和用户评估，填补了现有研究中缺乏实证数据的空白。通过跨多个领域的具体案例和系统性的经验教训总结，为RAG系统的设计、开发和评估提供了宝贵的实践指导。特别重要的是，它不仅关注技术挑战，还触及了操作和道德层面的问题，这对于RAG系统的实际落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** RAG系统是LLM结合外部知识的关键方法，但目前缺乏基于真实用例、通过用户评估且系统记录经验的实证研究。本文旨在填补这一空白，通过开发和评估实际RAG应用来提供经验。

**Method:** 开发了五个针对治理、网络安全、农业、工业研究和医学诊断等领域特定真实场景的RAG应用。每个系统都包含多语言OCR、通过向量嵌入的语义检索和领域适应的LLM，并通过本地服务器或云API部署。通过包含100名参与者的网络评估，从六个维度（易用性、相关性、透明度、响应性、准确性和推荐可能性）评估了系统。根据用户反馈和开发经验，记录了12条关键经验教训。

**Result:** 开发了五个领域特定的RAG应用，并成功进行了包含100名参与者的网络评估，评估了系统在六个维度上的表现。研究总结了12条关键经验教训，强调了影响RAG系统在实践中可靠性和可用性的技术、操作和道德挑战。

**Conclusion:** 本文通过开发和评估真实的RAG系统，提供了宝贵的实证数据和经验教训，揭示了在实际应用中部署RAG系统所面临的挑战，并为未来的RAG系统工程提供了指导和实践见解。

> **ai_Abstract:** 本文介绍了为治理、网络安全、农业、工业研究和医学诊断等五个真实场景开发的RAG系统。这些系统集成了多语言OCR、向量嵌入的语义检索和领域适应的LLM。通过100名用户参与的在线评估，从易用性、相关性、透明度、响应性、准确性和推荐可能性六个维度对系统进行了评估。研究总结了12条关键经验教训，涵盖了RAG系统在实际应用中面临的技术、操作和道德挑战，为RAG系统的实际部署提供了宝贵的见解。

> **摘要翻译:** 检索增强生成（RAG）系统正成为将大型语言模型（LLM）与外部知识相结合的关键方法，以解决事实准确性和上下文相关性方面的局限性。然而，目前缺乏基于真实用例、通过普通用户参与评估并伴有系统性经验教训记录的RAG实现开发方面的实证研究。本文介绍了为治理、网络安全、农业、工业研究和医学诊断等真实场景开发的五个领域特定RAG应用。每个系统都集成了多语言OCR、通过向量嵌入的语义检索和领域适应的LLM，并通过本地服务器或云API部署以满足不同的用户需求。一项涉及总共100名参与者的基于网络的评估从六个维度对系统进行了评估：(i)易用性、(ii)相关性、(iii)透明度、(iv)响应性、(v)准确性，以及(vi)推荐可能性。根据用户反馈和我们的开发经验，我们记录了十二条关键经验教训，强调了影响RAG系统在实践中可靠性和可用性的技术、操作和道德挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [106] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
> *复杂模型转换：基于不确定人类指导的强化学习*

*Kyanna Dagenais, Istvan David* | **Category: cs.SE, cs.AI, cs.LG**

**Keywords:** 模型转换, 强化学习, 人类指导, 模型驱动工程, 人机协作

**Comment:** Accepted for ACM/IEEE MODELS'25

> **TL;DR:** 本文提出一种利用强化学习（RL）并结合不确定人类指导的方法，以更高效地开发复杂的模型转换（MTs）。

**AI_Comments:** 本文的创新点在于将不确定的人类指导整合到强化学习中，以解决复杂模型转换的挑战。这种人机协作（human-in-the-loop）策略对于纯粹的强化学习难以应对复杂性问题至关重要，它利用了人类专业知识（即使不精确）来提供有价值的指导。对“不确定”指导的关注尤其具有洞察力，它承认了人类输入在现实世界中的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 模型驱动工程中手动开发复杂的模型转换（MTs）容易出错且通常不可行。尽管强化学习（RL）可以缓解这些问题，但其在复杂问题中表现出性能瓶颈。因此，需要引入人类指导来提升RL在复杂MT开发中的表现。

**Method:** 本文提出了一种方法和技术框架，通过强化学习（RL）在可能不确定的人类建议指导下开发复杂的MT序列。该框架允许将用户定义的MTs映射到RL原语，并将其作为RL程序执行，以找到最优的MT序列。

**Result:** 评估结果表明，即使是不确定的人类指导也能显著提高RL性能，并使得复杂MT的开发更加高效。

**Conclusion:** 通过在人类建议的确定性和及时性之间进行权衡，本文提出的方法是朝着RL驱动的人机协作工程方法迈出的一步。

> **ai_Abstract:** 本文旨在解决模型驱动工程中复杂模型转换（MTs）手动开发过程中的高错误率和不可行性问题。研究提出了一种新颖的方法，将强化学习（RL）与可能不确定的人类指导相结合，以自动化和优化MT序列的开发。该框架能够将用户定义的MTs映射为RL原语并执行。实验评估证明，即使是不确定的人类指导也能显著提升RL的性能和复杂MT的开发效率，从而推动了RL驱动的人机协作工程方法的发展。

> **摘要翻译:** 模型驱动工程问题通常需要复杂的模型转换（MTs），即需要大量序列链式连接的MTs。这类问题的相关例子包括模型同步、自动化模型修复和设计空间探索。手动开发复杂的MTs是一个容易出错且通常不可行的过程。强化学习（RL）是缓解这些问题的合适方法。在RL中，自主代理通过试错探索状态空间，以识别有益的动作序列，例如MTs。然而，RL方法在复杂问题中表现出性能问题。在这些情况下，人类指导具有很高的实用价值。在本文中，我们提出了一种通过强化学习开发复杂MT序列的方法和技术框架，该框架由可能不确定的人类建议指导。我们的框架允许将用户定义的MTs映射到RL原语上，并将其作为RL程序执行以找到最佳MT序列。我们的评估表明，人类指导，即使不确定，也能显著提高RL性能，并导致更高效的复杂MT开发。通过在人类建议的确定性和及时性之间进行权衡，我们的方法朝着RL驱动的人机协作工程方法迈进了一步。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [127] [Boosting Vulnerability Detection with Inter-function Multilateral Association Insights](https://arxiv.org/abs/2506.21014)
> *提升漏洞检测：基于函数间多边关联洞察*

*Shaojian Qiu, Mengyang Huang, Jiahao Cheng* | **Category: cs.SE**

**Keywords:** 漏洞检测, 函数间关联, 超图, 深度学习, 代码分析

**Comment:** 

> **TL;DR:** 本文提出了IFMA-VD框架，通过构建代码行为超图和利用超边卷积，有效提升了软件漏洞检测的性能，尤其解决了现有方法忽视函数间多边关联的问题。

**AI_Comments:** 本文通过使用超图明确建模函数间多边关联，提出了一种新颖的方法，这相对于仅关注单个函数的方法是一个重大进步。利用超图网络捕获复杂关系具有创新性，并且与理解跨多个函数的软件漏洞高度相关。这可能导致更健壮和准确的漏洞检测工具。

<details>
  <summary>Details</summary>

**Motivation:** 目前大多数基于深度学习的漏洞检测方法侧重于独立函数，忽视了复杂的函数间相互关系，特别是多边关联，这可能导致无法检测到这些关系中的漏洞。

**Method:** 本文提出了一个用于漏洞检测的函数间多边关联分析框架（IFMA-VD）。其核心在于构建代码行为超图并利用超边卷积来提取多边关联特征。具体步骤包括：首先将函数解析为代码属性图以生成函数内特征；然后通过分割程序依赖图来构建代码行为超图，将行为特征编码到超边中；最后利用超图网络捕获多边关联知识以增强漏洞检测。

**Result:** IFMA-VD 在三个广泛使用的漏洞数据集上进行了评估，与基线方法相比，F-measure 和 Recall 均有所改进。此外，研究表明多边关联特征可以增强代码特征表示，并验证了 IFMA-VD 在真实世界数据集上的有效性。

**Conclusion:** 通过结合函数间多边关联洞察和超图分析，所提出的 IFMA-VD 框架显著增强了漏洞检测能力，弥补了先前方法的一个关键局限性。

> **ai_Abstract:** 本文提出了 IFMA-VD，一个用于漏洞检测的新颖框架，旨在解决现有深度学习方法忽略函数间多边关联的局限性。IFMA-VD 通过构建代码行为超图并使用超边卷积来提取这些关键特征，并将其与来自代码属性图的函数内特征相结合。在三个数据集上进行评估，IFMA-VD 显示出 F-measure 和 Recall 的改进，证明了结合多边关联洞察以增强代码特征表示和漏洞检测的有效性。

> **摘要翻译:** 漏洞检测是确保软件系统安全的关键但具有挑战性的技术。目前，大多数基于深度学习的漏洞检测方法侧重于独立函数，忽视了复杂的函数间相互关系，特别是多边关联。这种疏忽可能导致无法检测到这些相互关系中的漏洞。为了弥补这一空白，我们提出了一个用于漏洞检测的函数间多边关联分析框架（IFMA-VD）。IFMA-VD 的基石在于构建代码行为超图并利用超边卷积来提取多边关联特征。具体来说，我们首先将函数解析为代码属性图以生成函数内特征。在此之后，我们通过分割程序依赖图来构建代码行为超图，以隔离并将行为特征编码到超边中。最后，我们利用超图网络捕获多边关联知识，以增强漏洞检测。我们在三个广泛使用的漏洞数据集上评估了 IFMA-VD，并展示了与基线方法相比，F-measure 和 Recall 方面的改进。此外，我们还说明了多边关联特征可以增强代码特征表示，并验证了 IFMA-VD 在真实世界数据集上的有效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [145] [How Good Are Synthetic Requirements ? Evaluating LLM-Generated Datasets for AI4RE](https://arxiv.org/abs/2506.21138)
> *合成需求有多好？评估LLM为AI4RE生成的数据集*

*Abdelkarim El-Hajjami, Camille Salinesi* | **Category: cs.SE, cs.AI**

**Keywords:** 合成需求, LLM, AI4RE, 数据集生成, 提示工程

**Comment:** 

> **TL;DR:** 本文介绍了Synthline v1，一种增强的产品线方法，用于生成合成需求数据，旨在解决AI4RE领域公共标记数据集的短缺问题。研究评估了提示策略、自动提示优化和后生成策展对数据质量的影响，并表明合成需求在特定任务上可以与人工编写的需求相媲美甚至超越。

**AI_Comments:** 本文创新性地提出了Synthline v1框架，结合了先进的生成策略和策展技术来优化LLM生成的合成需求数据质量。其重要性在于为解决AI4RE领域长期存在的数据集稀缺问题提供了一条有前景的路径。研究不仅验证了合成数据在某些任务上的有效性，甚至超越了人工数据，还深入探讨了不同生成和优化策略对数据质量的影响，为未来LLM在需求工程中的应用提供了宝贵的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在需求工程（AI4RE）领域的发展面临公共可用、带标签的需求数据集严重短缺的障碍。大型语言模型（LLMs）提供了生成合成数据的潜力，但如何系统地控制和优化生成需求的质量仍未得到充分探索。

**Method:** 本文提出了Synthline v1，一种增强的产品线方法，用于生成合成需求数据，该方法在早期v0版本的基础上增加了高级生成策略和策展技术。研究通过四个研究问题，评估了提示策略、自动化提示优化（使用PACE）和后生成策展如何影响四种分类任务（缺陷检测、功能性与非功能性、质量与非质量、安全性与非安全性）的数据质量。

**Result:** 多样本提示显著提高了效用和多样性，F1分数提高了6到44个点。使用PACE进行自动提示优化产生了任务依赖的结果，在功能分类上大幅提高（+32.5点），但在其他任务上降低了性能。基于相似性的策展提高了多样性，但通常损害了分类性能。最重要的是，合成需求在特定任务上可以与人工编写的需求相媲美或超越，在安全性（+7.8点）和缺陷分类（+15.4点）方面，合成数据甚至优于人工数据。

**Conclusion:** 合成需求能够匹配甚至在某些特定任务上超越人工编写的需求，为通过系统化的合成生成来缓解数据集稀缺性提供了一条可行的途径。这些发现为AI4RE提供了实用的见解。

> **ai_Abstract:** 本文介绍了Synthline v1，一个用于生成合成需求数据的增强型产品线方法，旨在解决AI4RE领域中标记数据集的稀缺问题。研究通过四个分类任务评估了不同的LLM提示策略、自动化提示优化和后生成策展对数据质量的影响。结果显示，多样本提示显著提升数据质量和多样性，且合成数据在特定任务（如安全和缺陷分类）上表现优于人工数据。这为通过系统生成合成数据以缓解数据集不足提供了可行方案。

> **摘要翻译:** 公共可用、带标签的需求数据集的短缺仍然是推进需求工程人工智能（AI4RE）的主要障碍。虽然大型语言模型为合成数据生成提供了有前景的能力，但控制和优化生成需求质量的系统方法仍未得到充分探索。本文提出了Synthline v1，一种增强的产品线方法，用于生成合成需求数据，该方法通过高级生成策略和策展技术扩展了我们早期的v0版本。我们调查了四个研究问题，评估了提示策略、自动化提示优化和后生成策展如何影响四种分类任务（缺陷检测、功能性与非功能性、质量与非质量、安全性与非安全性）的数据质量。我们的评估表明，多样本提示显著提高了单样本生成的效用和多样性，F1分数提高了6到44个点。使用PACE（提示行动者-评论家编辑）进行自动化提示优化产生了任务依赖的结果，大大改善了功能分类（+32.5点），但降低了其他任务的性能。有趣的是，基于相似性的策展提高了多样性，但通常损害了分类性能，这表明一些冗余可能有助于机器学习模型。最重要的是，我们的结果表明，合成需求在特定任务上可以与人工编写的需求相媲美或超越，其中合成数据在安全性（+7.8点）和缺陷分类（+15.4点）方面超越了人工数据。这些发现为AI4RE提供了实用的见解，并为通过系统化的合成生成来缓解数据集稀缺性描绘了一条可行的路径。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [162] [$T^3$: Multi-level Tree-based Automatic Program Repair with Large Language Models](https://arxiv.org/abs/2506.21211)
> *T³：基于多级树的大语言模型自动程序修复*

*Quanming Liu, Xupeng Bu, Zhichao Yan, Ru Li* | **Category: cs.SE, cs.AI**

**Keywords:** 自动程序修复, 大语言模型, 思维链, 树搜索, 自动化调试

**Comment:** 

> **TL;DR:** 本文提出了T³框架，它结合大语言模型和树搜索，显著提高了自动程序修复中生成候选修复方案的精度，并为优化修复策略提供了指导。

**AI_Comments:** 该论文的创新点在于将大语言模型（LLMs）的推理能力与树搜索技术相结合，以解决自动程序修复（APR）中复杂的多步推理挑战。这种结合不仅提高了修复方案的生成精度，还为APR策略优化提供了新思路，对自动化调试领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型（LLMs）和思维链（CoT）技术在推理能力上取得了显著进展，但由于自动程序修复（APR）任务的复杂逻辑和多步推理需求，CoT技术在APR领域的应用仍然不足。

**Method:** 本文系统评估了几种常见的CoT技术在APR任务中的表现，并提出了创新的T³框架。T³将LLMs强大的推理能力与树搜索相结合。

**Result:** T³框架有效提高了生成候选修复方案的精度，并为APR任务中优化样本选择和修复策略提供了宝贵的指导。

**Conclusion:** T³框架为实现高效的自动化调试建立了一个强大的基础。

> **ai_Abstract:** 本文提出了一个名为T³的创新框架，旨在通过结合大语言模型（LLMs）的强大推理能力和树搜索技术，解决自动程序修复（APR）中思维链（CoT）技术应用不足的问题。研究评估了现有CoT技术在APR中的表现，并展示了T³如何有效提高候选修复方案的生成精度，同时为优化APR任务中的样本选择和修复策略提供了指导，从而建立了一个高效自动化调试的强大框架。

> **摘要翻译:** 自动程序修复（APR）是软件开发和维护中的一项核心技术，旨在通过最少的人工干预实现自动化缺陷修复。近年来，大型语言模型（LLMs）和思维链（CoT）技术的巨大进步显著增强了这些模型的推理能力。然而，由于所需的复杂逻辑和多步推理能力，CoT技术在APR领域的应用仍然不足。本研究系统评估了几种常见的CoT技术在APR任务中的表现，并提出了一个创新的T³框架，该框架将LLMs强大的推理能力与树搜索相结合，有效提高了生成候选修复方案的精度。此外，T³为优化APR任务中的样本选择和修复策略提供了宝贵的指导，为实现高效的自动化调试建立了一个强大的框架。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [179] [KOALA: a Configurable Tool for Collecting IDE Data When Solving Programming Tasks](https://arxiv.org/abs/2506.21266)
> *KOALA：一个用于在解决编程任务时收集IDE数据的可配置工具*

*Daniil Karol, Elizaveta Artser, Ilya Vlasov, Yaroslav Golubev, Hieke Keuning, Anastasiia Birillo* | **Category: cs.SE, cs.CY**

**Keywords:** KOALA, IDE数据收集, 编程任务, JetBrains, 可配置工具

**Comment:** Accepted to CompEd'25, 7 pages, 4 figures

> **TL;DR:** KOALA是一个高度可配置的工具，用于从学生在JetBrains IDE中解决编程任务时收集代码快照和功能使用数据，克服了现有数据收集工具的局限性。

**AI_Comments:** KOALA的创新之处在于其高度可配置性，解决了现有工具在数据粒度控制和特定事件收集方面的不足。它能够收集更细致、更全面的学生编程行为数据，特别是热键使用和文件焦点切换等先前未被广泛收集的数据，这对于深入理解学生学习过程和发现编程误区具有重要意义。该工具的插件形式和数据标准化能力也增强了其实用性和互操作性。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据收集工具在代码粒度控制、特定编程环境事件收集以及配置难度方面存在局限性，导致研究人员和教育工作者难以有效收集学生解决编程任务的数据。

**Method:** KOALA是一个JetBrains IDE插件，可配置以提供任务、启用/禁用IDE功能和运行调查。它收集配置粒度的代码快照、所有IDE操作（如运行和调试）、热键使用和文件焦点切换等数据。收集到的数据发送到配套服务器，存储并可转换为ProgSnap2格式。

**Result:** 该工具已用于收集28名学生在两个课程中解决IDE任务的数据，并从中获得了一些见解。

**Conclusion:** KOALA成功克服了现有数据收集工具的局限性，能够方便、高度可配置地收集学生在JetBrains IDE中解决编程任务的详细数据，并展示了从这些数据中获取洞察的能力。

> **ai_Abstract:** KOALA是一个为研究人员和教育工作者设计的可配置工具，旨在解决现有编程任务数据收集工具的局限性。它作为一个JetBrains IDE插件，能够以可控的粒度收集学生在解决编程任务时的代码快照、IDE操作、热键使用和文件焦点切换等详细数据。KOALA支持任务配置、IDE功能控制和调查运行，并将收集的数据存储在配套服务器上，可转换为ProgSnap2格式。该工具已成功用于从28名学生那里收集数据，并从中获得了有价值的见解。

> **摘要翻译:** 收集学生解决编程任务的数据对研究人员和教育工作者来说非常有价值。它有助于验证学生是否正确应用了所学的功能和概念，或发现学生的错误概念。然而，现有数据收集工具存在局限性，例如无法控制收集代码的粒度、不收集所用编程环境的特定事件，以及整体配置困难。
为了克服这些局限性，我们提出了KOALA，一个方便且高度可配置的工具，用于收集学生在JetBrains IDE中解决编程任务时的代码快照和功能使用情况。该插件可以安装在IDE中，并配置为向学生提供必要的任务、启用或禁用某些IDE功能（如代码补全），以及运行调查。在解决问题期间，该插件会以配置的粒度收集代码快照、所有IDE操作（如运行和调试），以及一些先前工作中未收集的数据，例如使用的热键和文件之间的焦点切换。收集到的数据会发送到工具附带的服务器，在那里存储并可以转换为标准化的ProgSnap2格式。为了展示该工具，我们收集了28名学生在IDE中解决两门课程任务的数据，并强调了这些数据的一些见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [194] [Exploring Micro Frontends: A Case Study Application in E-Commerce](https://arxiv.org/abs/2506.21297)
> *探索微前端：电子商务中的案例研究应用*

*Ricardo Hideki Hangai Kojo, Luiz Fernando Corte Real, Renato Cordeiro Ferreira, Thatiane de Oliveira Rosa, Alfredo Goldman* | **Category: cs.SE, cs.DC, D.2.11; D.2.13; D.2.7**

**Keywords:** 微前端, 电子商务, 案例研究, 架构, 微服务

**Comment:** 11 pages, 2 figures (2 diagrams), submitted to the workshop AMP 2025

> **TL;DR:** 本文通过对现有文献的调查和在一个已采用微服务的电商平台进行案例研究，评估了微前端架构的适用性。研究发现，虽然微前端的采用是成功的，但并非总是必需的，其便利性主要源于与现有微服务和单体解耦策略的协同作用。

**AI_Comments:** 该论文通过实际案例研究，深入探讨了微前端在工业场景下的适用性，而非仅仅停留在理论层面。其创新之处在于，它不仅验证了微前端的可行性，更重要的是，它指出了微前端并非总是最佳或唯一方案，而是其价值会随着现有架构基础（如微服务和单体解耦）而显著提升。这为企业在考虑微前端转型时提供了宝贵的实践指导，强调了背景和协同效应的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 了解在何种情况下值得采用微前端架构，特别是在工业环境中。研究动机源于一家电商平台面临的挑战，包括其主系统与前端系统之间的紧密耦合、技术过时以及开发者体验不佳等问题。

**Method:** 首先，对微前端的最新技术现状进行了调查，包括学术文献和灰色文献。接着，在一个已使用微服务的电商平台中实施了微前端架构，并结合了API网关和前端后端（BFF）模式，以及Svelte和Fastify等技术。最后，通过对开发人员进行半开放式问卷调查来评估实施效果。

**Result:** 微前端的采用是成功的，但并非严格必要以满足公司需求。分析混合问卷反馈表明，其他替代方案（如单体前端）可能也能达到类似效果。在公司背景下，采用微前端最方便的原因是单体解耦和微服务的采用，这通过基础设施重用和团队间的知识共享促进了实施。

**Conclusion:** 微前端架构的成功采用并非总是严格必需的，其他替代方案可能也能达到类似效果。然而，当公司已有单体解耦和微服务等现有架构模式时，微前端的采用会变得更加便利和高效，因为它能促进基础设施重用和知识共享。

> **ai_Abstract:** 本文探讨了微前端架构在电子商务领域的应用，并通过一个真实案例研究评估了其适用性。研究首先调查了微前端的最新进展，随后在一个已采用微服务的电商平台实施了微前端，并使用问卷调查对开发者进行了评估。结果显示，尽管微前端的实施是成功的，但并非公司解决现有架构问题的唯一或严格必需的方案。其便利性主要体现在与现有微服务架构和单体解耦策略的协同作用，这有助于基础设施复用和知识共享。

> **摘要翻译:** 在微前端架构风格中，前端被划分为更小的组件，范围可以从简单的按钮到整个页面。其目标是提高可扩展性、弹性以及团队独立性，尽管代价是增加了复杂性和基础设施需求。本文旨在理解何时值得采纳微前端，特别是在工业背景下。为此，我们对微前端的最新技术现状进行了调查，基于学术和灰色文献。随后，我们在一个已使用微服务的手工制品市场中实施了这种架构风格。最后，我们通过对开发人员进行半开放式问卷调查来评估了此次实施。在所研究的市场公司中，由于其主系统（一个Java单体）与专用前端系统之间紧密耦合，以及存在废弃技术和糟糕的开发者体验，因此出现了架构变革的需求。为解决这些问题，采用了微前端架构，同时结合了API网关和前端后端（Backend for Frontend）模式，以及Svelte和Fastify等技术。尽管微前端的采用是成功的，但它并非严格必要以满足公司的需求。根据对混合问卷反馈的分析，其他替代方案，例如单体前端，可能也能达到类似效果。在公司背景下，使微前端成为最便捷选择的原因是单体解耦和微服务的采用，这通过基础设施重用和团队间的知识共享促进了实施。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [208] [An object-centric core metamodel for IoT-enhanced event logs](https://arxiv.org/abs/2506.21300)
> *一种面向物联网增强事件日志的以对象为中心的核心元模型*

*Yannis Bertrand, Christian Imenkamp, Lukas Malburg, Matthias Ehrendorfer, Marco Franceschetti, Joscha Grüger, Francesco Leotta, Jürgen Mangler, Ronny Seiger, Agnes Koschmider, Stefanie Rinderle-Ma, Barbara Weber, Estefania Serral* | **Category: cs.SE**

**Keywords:** 物联网, 流程挖掘, 数据集成, 元模型, 事件日志

**Comment:** 

> **TL;DR:** 该论文提出了一种以对象为中心的核心元模型，用于整合物联网数据与过程事件数据，从而促进流程挖掘领域的数据共享和协作。

**AI_Comments:** 该论文的创新之处在于提出了一种综合性的核心元模型，以解决物联网数据与流程数据集成中的碎片化问题，这对于推动物联网背景下的流程挖掘至关重要。其价值在于显著提升了数据交换和协作效率，为该领域的研究和应用奠定了更好的基础。

<details>
  <summary>Details</summary>

**Motivation:** 物联网技术的发展使得物联网设备与业务流程的整合日益增多，产生了大量物联网数据，有助于通过流程挖掘技术发现新的业务洞察。然而，由于物联网数据和传统过程数据（事件数据）的特性差异（如粒度级别），二者的结合面临挑战。现有数据模型的分散性阻碍了流程挖掘领域的数据交换和协作。

**Method:** 本文提出了一种核心模型，该模型综合了现有数据模型最重要的特性，并基于共同需求构建。通过一个原型Python实现来评估该模型，并证明其满足这些共同需求。

**Result:** 该核心模型极大地促进了流程挖掘领域的数据共享和协作。通过原型Python实现，证明了该模型满足了各种用例的共同需求。

**Conclusion:** 本文提出的以对象为中心的核心元模型通过整合现有数据模型的关键特性，有效解决了物联网数据与过程数据集成中的挑战，显著促进了流程挖掘领域的数据共享与协作。

> **ai_Abstract:** 该论文旨在解决物联网数据与传统流程数据在流程挖掘中集成时面临的挑战，这些挑战源于数据特性差异和现有模型碎片化。为此，文章提出了一种以对象为中心的核心元模型，该模型综合了现有数据模型的关键特性，并基于通用需求构建。通过一个原型Python实现，该模型在多种用例中进行了评估，并被证明能够有效促进流程挖掘领域的数据共享与协作。

> **摘要翻译:** 物联网（IoT）技术的进步促使物联网设备与各行各业（如制造业、医疗保健和智能空间）的业务流程（BPs）进行集成。物联网设备的普及产生了大量的物联网数据，为业务流程的物理上下文提供了窗口，这有助于利用流程挖掘（PM）技术发现关于业务流程的新见解。然而，为了实现这些益处，物联网数据需要与传统过程（事件）数据相结合，这由于物联网数据和过程数据截然不同的特性（例如粒度级别）而具有挑战性。最近，提出了几种数据模型来整合物联网数据与过程数据，每种模型都基于不同的假设和要求，侧重于数据集成的不同方面。这种碎片化阻碍了流程挖掘领域的数据交换和协作，例如，使得研究人员共享数据变得繁琐。在本文中，我们提出了一种核心模型，该模型综合了现有数据模型中最重要的特性。由于该核心模型基于共同需求，因此它极大地促进了该领域的数据共享和协作。使用原型Python实现对该模型进行了评估，以应对各种用例，并证明它满足这些共同需求。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [7] [Establishing validated standards for Home and Work location Detection](https://arxiv.org/abs/2506.20679)
> *建立家庭和工作地点检测的验证标准*

*Silvia de Sojo, Lorenzo Lucchini, Ollin D. Langle-Chimal, Samuel P. Fraiberger, Laura Alessandretti* | **Category: cs.SI, cs.CY**

**Keywords:** 家庭工作地点检测, 移动数据, HoWDe, 验证标准, 准确性

**Comment:** 

> **TL;DR:** HoWDe是一种鲁棒算法，用于从移动数据中识别家庭和工作地点，解决了现有方法缺乏标准化框架和地面真实验证的问题，并在全球范围内实现了高精度。

**AI_Comments:** HoWDe的创新之处在于其明确设计用于处理移动数据中的缺失和质量差异，并首次通过大规模多国地面真实数据集进行了严格验证。这解决了现有方法在标准化、可比性和可重复性方面的关键局限性。其高准确率和在不同人口群体中的一致性表现，使其在城市规划、交通分析和人口统计等领域具有重要应用价值。此外，它支持隐私保护数据共享的潜力也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 智能手机位置数据为城市交通研究带来了变革，但大规模利用位置数据存在方法学挑战。准确识别个人家庭和工作地点对于通勤分析、失业率估计和城市可达性研究至关重要。然而，现有的家庭-工作地点检测方法缺乏考虑数据质量差异并经过地面真实观测验证的标准化框架，这限制了研究结果的可比性和可重复性。

**Method:** 本论文提出了HoWDe，一种鲁棒的算法，用于从移动数据中识别家庭和工作地点。该算法明确设计用于处理缺失数据和个体间不同的数据质量。研究使用了两个独特的地面真实数据集，包含来自80多个国家的5100多名个体。

**Result:** HoWDe在家庭和工作地点检测方面分别达到了高达97%和88%的准确率，并且在不同国家和人口群体中表现一致。研究还探讨了参数选择如何影响准确性和用户保留之间的权衡，并展示了这些方法学决策如何影响下游应用，如就业估计和通勤模式分析。

**Conclusion:** HoWDe工具和研究结果建立了方法学标准，支持在个体和城市层面进行更稳健、可扩展和可重复的移动性研究。它通过透明和经过验证的管道支持内部预处理，促进了隐私保护移动数据的共享。

> **ai_Abstract:** 本研究提出了一种名为HoWDe的鲁棒算法，用于从智能手机移动数据中准确识别家庭和工作地点。该算法旨在解决现有方法缺乏标准化和地面真实验证的问题，并能有效处理数据缺失和质量差异。通过在包含来自80多个国家的5100多名个体的地面真实数据集上进行验证，HoWDe在家庭和工作地点检测方面分别实现了高达97%和88%的准确率，并在不同群体中表现一致。该研究还探讨了参数选择对准确性和数据保留的影响，并强调了其对就业估计和通勤分析等下游应用的重要性。HoWDe通过提供透明且经过验证的预处理流程，为移动性研究建立了新的方法学标准，从而支持更可靠、可扩展和可重复的分析。

> **摘要翻译:** 智能手机位置数据已经改变了城市出行研究，为人们如何在城市中导航和互动提供了前所未有的洞察。然而，大规模利用位置数据带来了方法学挑战。准确识别个人的家庭和工作地点对于一系列应用至关重要，包括通勤分析、失业估计和城市可达性研究。尽管被广泛使用，但家庭-工作地点检测方法缺乏一个考虑不同数据质量并经过地面真实观测验证的标准化框架。这限制了研究结果在不同研究和数据集之间的可比性和可重复性。在本文中，我们提出了HoWDe，一种从移动数据中识别家庭和工作地点的鲁棒算法，明确设计用于处理缺失数据和个体间不同的数据质量。通过使用两个独特的地面真实数据集，包含来自80多个国家的5100多名个体，HoWDe在家庭和工作地点检测方面分别达到了高达97%和88%的准确率，并且在不同国家和人口群体中表现一致。我们研究了参数选择如何影响准确性和用户保留之间的权衡，并展示了这些方法学决策如何影响下游应用，如就业估计和通勤模式分析。通过透明和经过验证的管道支持内部预处理，HoWDe还促进了隐私保护移动数据的共享。总而言之，我们的工具和发现建立了方法学标准，支持在个体和城市层面进行更稳健、可扩展和可重复的移动性研究。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [32] [Malicious earworms and useful memes, how the far-right surfs on TikTok audio trends](https://arxiv.org/abs/2506.20695)
> *恶意耳虫与有用迷因：极右翼如何利用TikTok音频趋势*

*Marloes Geboers, Marcus Bösch* | **Category: cs.SI, cs.CY**

**Keywords:** TikTok, 极右翼, 音频趋势, 模因, 仇外内容

**Comment:** 

> **TL;DR:** 本研究探讨了极右翼势力如何在TikTok上利用音频趋势传播仇外内容，即使这些内容通过模糊的迷因和用户生成的声音进行伪装，并绕过平台的部分审查机制。

**AI_Comments:** 该研究揭示了社交媒体平台在内容审核方面面临的复杂挑战，特别是当恶意内容通过模糊和非传统方式（如音频趋势和模因）传播时。它强调了仅仅关注显性有害内容不足以遏制极端主义，需要更深入理解内容在不同媒介中的伪装和传播机制。创新点在于其聚焦TikTok的声音基础设施和模因文化，揭示了这些技术特性如何被滥用。

<details>
  <summary>Details</summary>

**Motivation:** TikTok作为模因制作和传播的平台，其声音基础设施被发现允许仇外内容的持续存在，即使平台已加强内容审核。本研究旨在探讨极右翼极端主义组织如何利用TikTok的声音功能及其与模糊模因的交叉点，尤其是在2024年德国州选举背景下。

**Method:** 该研究聚焦于声音的作用及其与模糊迷因的交叉点，通过分析与2024年德国州选举相关的右翼极端主义形成，来揭示TikTok声音基础设施如何助长仇外内容的传播。

**Result:** 分析表明，TikTok的声音基础设施使得仇外内容能够持续存在，这些内容通常通过本土化的交流方式进行伪装。这些伪装手段受益于一个允许用户生成声音持续发布并迅速传播（通过“使用此声音”按钮）的声音基础设施。这些声音往往不易被识别为极端主义内容的传播者。包含仇恨歌词的歌曲虽然不符合个性化推送的条件，但仍在线上存在，并与良性模因趋势交叉，使其在搜索结果中可见。

**Conclusion:** TikTok的声音基础设施为极右翼势力提供了一个传播仇外内容的有效渠道，即使平台实施了审核措施，通过模糊的模因和用户生成的声音，这些内容仍能持续存在并被发现。

> **ai_Abstract:** 本研究分析了极右翼势力如何在TikTok上利用其独特的声音基础设施和模因传播机制来扩散仇外内容。尽管TikTok已加强内容审核并引入新功能以应对非法内容，但研究发现，通过模糊的模因、用户生成的声音以及与良性趋势的交叉，仇外信息仍能持续存在并被发现，尤其是在2024年德国州选举的背景下。

> **摘要翻译:** 凭借其混音功能，TikTok是模因制作和传播的指定平台。视频、表情符号和滤镜的创意组合，使得由声音驱动的模因和趋势源源不断。该平台一直专注于维护人身安全，因此投资于有害挑战的检测。为了响应《数字服务法案》（DSA），TikTok实施了个性化推送的退出选项，并提供了允许用户举报非法内容的功能。与此同时，该平台仍受到严格审查。本研究以声音的作用及其与模糊模因的交叉点为中心，探讨了与2024年德国州选举相关的右翼极端主义形成。分析表明，TikTok的声音基础设施如何使得仇外内容持续存在，这些内容通常通过本土化的交流方式进行伪装。这些伪装做法得益于一个声音基础设施，该基础设施允许用户生成的声音持续发布，并通过“使用此声音”按钮即时传播。重要的是，这些声音通常无法清晰识别为极端主义内容的网络传播者。确实包含仇恨歌词的歌曲不符合个性化推送的条件，但它们仍在线上存在，并受益于与良性模因趋势的交叉，使其在搜索结果中可见。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [56] [Where is AIED Headed? Key Topics and Emerging Frontiers (2020-2024)](https://arxiv.org/abs/2506.20971)
> *AIED 将走向何方？关键主题与新兴前沿（2020-2024）*

*Shihui Feng, Huilin Zhang, Dragan Gašević* | **Category: cs.SI**

**Keywords:** AIED, LLMs, GenAI, 知识共现网络分析, 新兴前沿

**Comment:** 

> **TL;DR:** 本研究分析了2020-2024年间2398篇教育人工智能（AIED）领域的论文，揭示了其技术导向性、持续主题和LLMs、GenAI等新兴前沿，并强调了以人为中心的AI发展趋势。

**AI_Comments:** 本研究通过对大量文献的系统性分析，提供了对教育人工智能（AIED）领域在GenAI时代转型前沿的及时和全面洞察。其创新之处在于首次提供了大规模的领域级映射，并明确指出了新兴前沿，这对指导未来AIED的研究方向和教育实践具有重要价值。数据量大且分析方法严谨，增强了研究的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过分析大量研究文章，揭示教育人工智能（AIED）领域的知识结构、演变中的知识群集和新兴前沿，尤其是在生成式人工智能（GenAI）时代，并提供首次大规模的领域级映射，以指导未来的研究发展和教育实践。

**Method:** 本研究分析了2020年至2024年间在八个核心场所发表的2,398篇教育人工智能（AIED）研究文章。采用三步知识共现网络分析方法，分析了该领域的知识结构、演变中的知识群集和新兴前沿。

**Result:** 研究发现AIED研究仍然高度关注技术，持续主题包括智能辅导系统、学习分析和自然语言处理。同时，对大型语言模型（LLMs）和生成式人工智能（GenAI）的兴趣日益增长。通过追踪桥接关键词，确定了AIED的四个新兴前沿：LLMs、GenAI、多模态学习分析和人机协作。GenAI目前的研究兴趣集中在GAI驱动的个性化、自主学习、反馈、评估、动机和伦理方面。

**Conclusion:** AIED的关键研究兴趣和新兴前沿反映了对共同适应的、以人为中心的教育人工智能日益增长的重视。本研究首次提供了AIED在GenAI时代转型的大规模领域级映射，为未来的研究发展和教育实践提供了启示。

> **ai_Abstract:** 该研究通过对2020-2024年间2398篇教育人工智能（AIED）领域论文进行三步知识共现网络分析，揭示了AIED研究的技术导向性，识别出智能辅导系统、学习分析和自然语言处理等持续主题，以及大型语言模型（LLMs）、生成式人工智能（GenAI）、多模态学习分析和人机协作等新兴前沿。研究强调AIED正日益重视协同适应的、以人为中心的教育AI，并首次提供了AIED在GenAI时代转型的大规模领域级映射，为未来研究和实践指明方向。

> **摘要翻译:** 本研究分析了2020年至2024年间在八个与教育人工智能（AIED）领域相关的核心场所发表的2,398篇研究文章。我们使用三步知识共现网络分析方法，分析了该领域的知识结构、演变中的知识群集以及新兴前沿。我们的研究结果显示，AIED研究仍然高度关注技术，持续的主题包括智能辅导系统、学习分析和自然语言处理，同时对大型语言模型（LLMs）和生成式人工智能（GenAI）的兴趣日益增长。通过追踪过去五年中的桥接关键词，我们确定了AIED的四个新兴前沿——LLMs、GenAI、多模态学习分析和人机协作。目前GenAI的研究兴趣集中在GAI驱动的个性化、自主学习、反馈、评估、动机和伦理方面。AIED的关键研究兴趣和新兴前沿反映了对共同适应的、以人为中心的教育人工智能日益增长的重视。本研究首次对AIED在GenAI时代转型进行了大规模领域级映射，并为未来的研究发展和教育实践提供了启示。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [81] [Enhancing Homophily-Heterophily Separation: Relation-Aware Learning in Heterogeneous Graphs](https://arxiv.org/abs/2506.20980)
> *增强同质性-异质性分离：异构图中的关系感知学习*

*Ziyu Zheng, Yaming Yang, Ziyu Guan, Wei Zhao, Weigang Lu* | **Category: cs.SI, cs.AI**

**Keywords:** 异构图, 节点异质性, 对比学习, 同质性分离, 关系感知

**Comment:** accepted by KDD 2025

> **TL;DR:** RASH是一个新的对比学习框架，用于在异构图中有效分离同质性和异质性模式，通过双重异构超图和多关系对比损失来解决异构性和异质性挑战，并在基准数据集上表现出色。

**AI_Comments:** 该论文提出了一种新颖的对比学习方法RASH，用于解决异构图中同质性与异质性分离的难题。其创新点在于引入双重异构超图来编码多关系信息，并动态构建同质/异质图，同时设计了多关系对比损失来最大化互信息，有效避免了现有方法在异构到同质转换中信息丢失的问题。这项工作对于理解和处理复杂异构网络中的异质性模式具有重要意义，并为相关下游任务提供了强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 真实世界网络存在节点异质性，即相连节点特征或标签不同。同质图中的异质性问题已广泛研究，但在异构图（包含多种节点和边类型）中仍未充分探索。现有方法通常将异构图转换为同质图来学习节点异质性，但这会丢失异构关系所蕴含的潜在异质性。因此，需要一种能够同时考虑节点/边异构性和节点异质性的方法来捕获异构图中的节点异质性。

**Method:** 本文提出了关系感知同质性与异质性分离（RASH）框架，这是一种新颖的对比学习方法。RASH通过引入双重异构超图来编码多关系二分图，并基于关系重要性动态构建同质图和异质图。此外，设计了一种多关系对比损失，通过最大化互信息来对齐异构视图以及同质/异质视图，从而显式建模异构交互的高阶语义并自适应地分离同质和异质模式。

**Result:** RASH框架同时解决了异构图中的异构性和异质性挑战。在基准数据集上进行的广泛实验证明了RASH在各种下游任务中的有效性。

**Conclusion:** RASH通过其新颖的关系感知对比学习框架，成功地在异构图中实现了同质性与异质性的有效分离，解决了异构性和异质性共存的挑战，并在多个下游任务中取得了显著的性能提升。

> **ai_Abstract:** 本文提出RASH（关系感知同质性与异质性分离），一个针对异构图的对比学习框架，旨在解决异构图中节点异质性捕获的挑战。RASH通过引入双重异构超图和设计多关系对比损失，有效建模异构交互的高阶语义，并自适应地分离同质和异质模式，从而同时处理异构性和异质性问题。实验证明其在多个下游任务上的有效性。

> **摘要翻译:** 真实世界网络通常具有节点异质性，即相连的节点通常具有不同的特征或不同的标签。这种异质性问题已在同质图中得到广泛研究，但在异构图（其中存在多种类型的节点和边）中仍未充分探索。在异构图中捕获节点异质性非常具有挑战性，因为节点/边异构性和节点异质性都应仔细考虑。现有方法通常将异构图转换为同质图来学习节点异质性，这不可避免地会丢失异构关系所传达的潜在异质性。为了弥补这一差距，我们提出了关系感知同质性与异质性分离（RASH），这是一种新颖的对比学习框架，它明确地建模异构交互的高阶语义并自适应地分离同质和异质模式。特别是，RASH引入了双重异构超图来编码多关系二分图，并根据关系重要性动态构建同质图和异质图。设计了一种多关系对比损失，通过最大化互信息来对齐异构视图以及同质/异质视图。通过这种方式，RASH同时解决了异构图中异构性和异质性的挑战。在基准数据集上进行的广泛实验证明了RASH在各种下游任务中的有效性。代码可在：https://github.com/zhengziyu77/RASH 获取。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [11] [Drift-Adaptive Slicing-Based Resource Management for Cooperative ISAC Networks](https://arxiv.org/abs/2506.20762)
> *协同ISAC网络中基于漂移自适应切片的资源管理*

*Shisheng Hu, Jie Gao, Xue Qin, Conghao Zhou, Xinyu Huang, Mushu Li, Mingcheng He, Xuemin Shen* | **Category: cs.NI, eess.SP**

**Keywords:** 漂移自适应, 切片, 资源管理, ISAC, 数字孪生

**Comment:** Accepted by IEEE Transactions on Cognitive Communications and
  Networking

> **TL;DR:** 本文提出了一种新颖的基于漂移自适应切片的协同集成感知与通信（ISAC）网络资源管理方案，通过构建数字孪生来应对移动设备和感知目标的非平稳空间分布，显著提高了服务满意度并降低了资源消耗。

**AI_Comments:** 该论文的创新点在于引入了“漂移自适应”的概念，并通过数字孪生技术来应对ISAC网络中移动设备和感知目标的非平稳空间分布问题。这种方法有效地解决了传统资源管理方案在动态环境中可能出现的建模漂移和规划失效问题，具有重要的理论和实际意义。其提出的切片化和数字孪生结合的方案，为未来ISAC网络的智能化管理提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对移动设备和感知目标的非平稳空间分布导致建模漂移和规划决策无效的问题。

**Method:** 本文提出了一种新颖的漂移自适应切片式资源管理方案，用于协同ISAC网络。该方案建立了感知和通信两个网络切片，并在大时间尺度规划中划分感知区域并预留资源。为应对非平稳空间分布，为每个切片构建了数字孪生（DT），其中包含漂移自适应统计模型和仿真功能，以实现闭式决策和高效验证。

**Result:** 数值结果表明，与基准方案相比，所提出的漂移自适应切片式资源管理方案可以将服务满意度提高多达18%，并将资源消耗降低多达13.1%。

**Conclusion:** 所提出的漂移自适应切片式资源管理方案能够有效提升协同ISAC网络的服务满意度并降低资源消耗，通过引入数字孪生和漂移自适应模型成功应对了非平稳空间分布带来的挑战。

> **ai_Abstract:** 本文提出了一种用于协同ISAC网络的新型漂移自适应切片式资源管理方案。该方案通过建立感知和通信切片，并在大时间尺度上进行资源规划。为解决移动设备和感知目标非平稳空间分布导致的建模漂移问题，引入数字孪生技术，在每个数字孪生中开发漂移自适应统计模型和仿真功能。数值结果证明，该方案能显著提高服务满意度并降低资源消耗。

> **摘要翻译:** 在本文中，我们提出了一种新颖的漂移自适应切片式资源管理方案，用于协同集成感知与通信（ISAC）网络。特别是，我们建立了两个网络切片，分别提供感知和通信服务。在切片的大时间尺度规划中，我们划分了每个移动设备的感兴趣感知区域（RoI），并相应地预留了网络资源，从而促进了小时间尺度下基于距离的低复杂度感知目标分配。为了应对移动设备和感知目标的非平稳空间分布（这可能导致建模分布的漂移和无效的规划决策），我们构建了切片的数字孪生（DTs）。在每个DT中，分别为相应切片中的空间分布开发了漂移自适应统计模型和仿真功能，这分别有助于闭式决策和规划决策的有效验证。数值结果表明，与基准方案相比，所提出的漂移自适应切片式资源管理方案可以将服务满意度提高多达18%，并将资源消耗降低多达13.1%。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [36] [Flowcut Switching: High-Performance Adaptive Routing with In-Order Delivery Guarantees](https://arxiv.org/abs/2506.21406)
> *Flowcut Switching：高性能自适应路由与顺序交付保证*

*Tommaso Bonato, Daniele De Sensi, Salvatore Di Girolamo, Abdulla Bataineh, David Hewson, Duncan Roweth, Torsten Hoefler* | **Category: cs.NI**

**Keywords:** Flowcut Switching, 自适应路由, 按序交付, 网络延迟, 超级计算机

**Comment:** 

> **TL;DR:** Flowcut Switching是一种新的自适应路由算法，它能确保在任何网络条件下数据包的按序交付，解决了现有自适应路由可能导致乱序包的问题，尤其适用于非突发流量。

**AI_Comments:** 该论文的创新点在于提出了Flowcut Switching，一种能够保证在任何网络条件下按序交付数据包的自适应路由算法。这解决了现有自适应路由方案在处理对乱序敏感协议（如TCP、QUIC、RoCE）时可能导致的性能下降和CPU利用率增加的问题。其重要性在于，它为高性能计算环境（特别是RDMA应用）提供了更可靠和高效的网络通信，因为该方案对非突发流量也有效，且不依赖于突发流量的假设，这在网络通信中具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自适应路由算法虽然能通过在不同可用路径上路由数据包来减少网络延迟并提高网络利用率，但如果同一网络流的数据包通过不同路径传输，它们可能会因路径延迟差异而乱序到达目的地。对于TCP、QUIC和RoCE等传输协议，乱序（OOO）数据包可能导致性能大幅下降或显著增加CPU利用率。

**Method:** 本文提出了一种名为flowcut switching的新型自适应路由算法。与现有解决方案（如flowlet switching）不同，flowcut switching不依赖于突发流量的假设，且能在任何网络条件下保证数据包的按序交付，同时对非突发流量（如RDMA）也有效。

**Result:** Flowcut switching能够提供高性能的按序数据包交付。它在任何网络条件下都能保证按序交付，并且对非突发流量（如RDMA）也有效。

**Conclusion:** Flowcut switching是一种能够解决自适应路由中乱序包问题的创新方法，它通过保证在任何网络条件下的按序交付，为高性能计算环境中的网络通信提供了更可靠和高效的解决方案，尤其适用于对乱序敏感的应用和非突发流量。

> **ai_Abstract:** 本文提出了一种名为Flowcut Switching的新型自适应路由算法，旨在解决现有自适应路由在超级计算机网络中可能导致数据包乱序的问题。该算法承诺在任何网络条件下提供高性能的按序数据包交付，并且对非突发流量（如RDMA）同样有效，克服了传统方法（如Flowlet Switching）对突发流量的依赖及其潜在的乱序问题，从而提升了对乱序敏感协议的性能和CPU利用率。

> **摘要翻译:** 网络延迟严重影响超级计算机上运行应用程序的性能。自适应路由算法通过在不同可用路径上路由数据包来减少延迟并提高网络利用率。然而，如果交换机将属于同一网络流的数据包路由到不同路径，由于这些路径的延迟差异，它们可能会乱序到达目的地。对于TCP、QUIC和RoCE等某些传输协议，乱序（OOO）数据包可能导致性能大幅下降或显著增加CPU利用率。在这项工作中，我们提出了flowcut switching，这是一种新的自适应路由算法，可提供高性能的按序数据包交付。与现有解决方案（如flowlet switching）不同，后者基于突发流量的假设并且可能仍然会重新排序数据包，flowcut switching在任何网络条件下都能保证按序交付，并且对非突发流量也有效，例如RDMA通常就是这种情况。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [12] [Entropic additive energy and entropy inequalities for sums and products](https://arxiv.org/abs/2506.20813)
> *熵加性能量与和积的熵不等式*

*Rupert Li, Lampros Gavalakis, Ioannis Kontoyiannis* | **Category: cs.IT, math.CO, math.IT, 94A17 (Primary) 11B13 (Secondary)**

**Keywords:** 熵加性能量, 熵不等式, 和积现象, 加性组合学, 微分熵

**Comment:** 26 pages, no figures

> **TL;DR:** 本文引入了连续随机变量的熵加性能量，证明了其与和的熵之间的关系，建立了积与和积组合的新的熵不等式，并讨论了离散熵和熵和积现象。

**AI_Comments:** 本文通过将加性组合学的核心概念（如加性能量和Balog-Szemerédi-Gowers定理）扩展到连续随机变量的微分熵领域，做出了重要贡献。环Plünnecke-Ruzsa熵不等式的引入是一项显著的创新。对熵和积现象的探索及其与组合版本的比较，突出了熵背景下重要的差异和潜在限制。这项工作连接了两个不同的数学领域，为分析随机变量的结构提供了新的工具和见解。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机源于过去15年里，通过加性组合学的方法和工具建立熵不等式的研究日益增多，以及Goh关于“加性能量”离散熵版本的近期工作，还有Máthé和O'Regan关于积的熵不等式的近期工作。

**Method:** 本文引入了连续随机变量对的加性能量，并证明了“加性能量大当且仅当和的熵小”的各种版本，以及微分熵的Balog-Szemerédi-Gowers定理的一个版本。同时，建立了连续随机变量的积及和积组合的一系列新的微分熵不等式，特别是证明了一个新的、普适的环Plünnecke-Ruzsa熵不等式。此外，还对具有“大倍增”的离散随机变量进行了特征描述，并考虑了整数值随机变量的Erdős-Szemerédi和积现象的熵模拟。

**Result:** 获得了连续随机变量的和、积以及和积组合的微分熵的许多新界限；证明了“加性能量大当且仅当和的熵小”的各种版本；建立了微分熵的Balog-Szemerédi-Gowers定理的一个版本；建立了一系列新的积及和积组合的微分熵不等式，包括一个新的、普适的环Plünnecke-Ruzsa熵不等式；提供了具有“大倍增”的离散随机变量的特征；并指出，如果熵Erdős-Szemerédi和积现象成立，其参数范围将比其组合对应物受到更显著的限制。

**Conclusion:** 本文建立了连续随机变量的熵加性能量与熵之间的关系及新的熵不等式，将加性组合学的概念扩展到熵领域。研究还对离散熵和熵和积现象提供了见解，并发现熵和积现象的参数范围比其组合对应物更受限制。

> **ai_Abstract:** 本文将加性组合学扩展到熵领域，引入了连续随机变量的熵加性能量，并揭示了其与和的熵之间的反向关系，包括一个Balog-Szemerédi-Gowers定理的类比。研究还为积与和积组合建立了新的微分熵不等式，其中值得注意的是一个普适的环Plünnecke-Ruzsa不等式。此外，本文还对具有“大倍增”的离散随机变量进行了特征描述，并分析了熵Erdős-Szemerédi和积现象，发现其参数范围比组合对应物更为受限。

> **摘要翻译:** 在过去15年里，越来越多的研究通过加性组合学的思想和工具建立了熵不等式，在此背景下，本工作为连续随机变量的和、积以及和积组合的微分熵获得了许多新的界限。部分受Goh关于“加性能量”概念的离散熵版本近期工作启发，我们引入了连续随机变量对的加性能量，并证明了“加性能量大当且仅当和的熵小”这一论断的各种版本，以及微分熵的Balog-Szemerédi-Gowers定理的一个版本。接着，部分受Máthé和O'Regan近期工作的启发，我们为连续随机变量的积及和积组合建立了一系列新的微分熵不等式。特别地，我们证明了一个新的、普适的环Plünnecke-Ruzsa熵不等式。我们简要地回到离散熵的情况，并提供了具有“大倍增”的离散随机变量的特征，这类似于Tao针对小倍增情况的Freiman型逆和集理论。最后，我们考虑了整数值随机变量的Erdős-Szemerédi和积现象的自然熵模拟。我们表明，如果它确实成立，那么其成立的参数范围必然比其预期的组合对应物受到更显著的限制。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [37] [Constant Modulus Waveforms for IoT-Centric Integrated Sensing and Communications](https://arxiv.org/abs/2506.21078)
> *用于以物联网为中心的集成传感与通信的恒模波形*

*Tian Han, Shalanika Dayarathna, Rajitha Senanayake, Peter Smith, Aryan Kaushik, Alain Mourad, Richard A. Stirling-Gallacher, Jamie Evans* | **Category: cs.IT, eess.SP, math.IT**

**Keywords:** 恒模波形, 集成传感与通信, 物联网, 高峰均功率比, 单载波调制

**Comment:** Submitted for publication to IEEE Communications Standards Magazine

> **TL;DR:** OFDM在ISAC中PAPR高不适合IoT，本文提出并分析了恒模波形作为替代方案，以适应资源受限的IoT设备。

**AI_Comments:** 这篇论文的创新点在于提出了适用于IoT场景的恒模波形设计，解决了传统OFDM波形在资源受限设备中PAPR过高的问题。其重要性在于为未来IoT-ISAC系统的波形选择提供了新的方向，有望降低系统复杂性和成本。

<details>
  <summary>Details</summary>

**Motivation:** 集成传感与通信（ISAC）是物联网（IoT）应用的关键技术，但传统多载波波形（如OFDM）的高峰均功率比（PAPR）导致性能下降或系统复杂性增加，使其不适用于功率、系统复杂性、硬件尺寸或成本受限的IoT应用。

**Method:** 本文提出了以物联网为中心的恒模波形设计，利用其单位高峰均功率比（PAPR）的优势。具体考虑了几种单载波频率和/或相位调制波形，并基于雷达模糊函数、带宽特性、数据速率和通信接收器复杂性等性能指标，对其雷达传感和通信性能进行了全面讨论。

**Result:** 论文对所提出的恒模波形的雷达传感和通信性能进行了综合讨论，并基于雷达模糊函数、带宽特性、数据速率和通信接收器复杂性等多个性能指标进行了评估。

**Conclusion:** 恒模波形因其单位PAPR特性，比传统OFDM波形更适合资源受限的IoT场景中的集成传感与通信（ISAC）应用。

> **ai_Abstract:** 本文针对物联网（IoT）中集成传感与通信（ISAC）应用中OFDM波形高峰均功率比（PAPR）不适用于资源受限设备的问题，提出并设计了以IoT为中心的恒模波形。通过利用恒模波形单位PAPR的优势，使其更适合资源有限的IoT场景。文章详细讨论了几种单载波频率和/或相位调制波形的雷达传感和通信性能，并基于雷达模糊函数、带宽特性、数据速率和通信接收器复杂性等关键指标进行了评估。

> **摘要翻译:** 集成传感与通信（ISAC）被认为是支持物联网（IoT）等应用场景的关键使能技术，在这些场景中，通信和传感都扮演着重要角色。多载波波形，例如正交频分复用（OFDM），因其高通信数据速率和良好的传感时间带宽特性，被认为是ISAC的良好候选。然而，其高峰均功率比（PAPR）值导致性能下降或系统复杂性增加。这使得OFDM可能不适合在功率、系统复杂性、硬件尺寸或成本方面资源不足的物联网应用。本文提供了以物联网为中心的恒模波形设计，利用单位PAPR的优势，因此更适合资源受限的场景。更具体地说，本文考虑了几种单载波频率和/或相位调制波形。基于雷达模糊函数、带宽特性、数据速率和通信接收器复杂性等性能指标，对它们的雷达传感和通信性能进行了全面讨论。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [61] [Semantic-aware Digital Twin for AI-based CSI Acquisition](https://arxiv.org/abs/2506.21126)
> *用于基于AI的CSI获取的语义感知数字孪生*

*Jiajia Guo, Yiming Cui, Shi Jin* | **Category: cs.IT, math.IT**

**Keywords:** 语义感知数字孪生, AI, CSI获取, 无线通信, 部署

**Comment:** This article has been accepted by IEEE Communications Standards
  Magazine

> **TL;DR:** 本文探讨了语义感知数字孪生如何通过解决其局限性并辅助部署来增强基于AI的信道状态信息(CSI)获取。

**AI_Comments:** 本文提出了一种将语义感知数字孪生与基于AI的CSI获取相结合的探索性框架，旨在解决AI在无线通信中实际应用所面临的数据集收集和部署等挑战。其创新性在于探索了数字孪生与人工智能在无线通信领域协同作用的新途径，为提升CSI获取性能提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于人工智能(AI)的信道状态信息(CSI)获取性能虽有显著提升，但受限于对单一模态信息的依赖以及部署挑战，特别是在数据集收集方面。

**Method:** 本文研究了语义感知数字孪生(DT)在增强基于AI的CSI获取中的应用。首先介绍了AI驱动CSI获取和语义感知DT在空口应用中的动机和进展，然后深入探讨了语义感知DT如何增强基于AI的CSI获取。研究将语义感知DT用于AI-based CSI获取分为两类：通过与DT集成增强AI-based CSI获取，以及使用DT辅助AI-based CSI部署。文中详细介绍了潜在的集成框架。

**Result:** 摘要中未提及具体结果。

**Conclusion:** 本文通过概述语义感知数字孪生辅助的基于AI的CSI获取的潜在研究方向作为总结。

> **ai_Abstract:** 本文探讨了语义感知数字孪生(DT)如何增强基于AI的信道状态信息(CSI)获取，旨在克服AI在CSI获取中面临的单一模态信息依赖和部署挑战。研究将语义感知DT的应用分为两类：通过集成DT来增强AI-based CSI获取，以及利用DT辅助AI-based CSI的部署，并详细介绍了潜在的集成框架。文章最后指出了该领域未来的研究方向。

> **摘要翻译:** 人工智能(AI)显著提升了信道状态信息(CSI)获取性能，但受限于对单一模态信息的依赖以及部署挑战，特别是在数据集收集方面。本文研究了语义感知数字孪生(DT)在增强基于AI的CSI获取中的应用。我们首先简要介绍了AI驱动CSI获取和语义感知DT在空口应用中的动机和最新进展。然后，我们深入探讨了语义感知DT如何增强基于AI的CSI获取。我们将用于基于AI的CSI获取的语义感知DT分为两类：通过与DT集成增强AI-based CSI获取，以及使用DT辅助AI-based CSI部署。文中详细介绍了潜在的集成框架。最后，我们通过概述语义感知DT辅助的基于AI的CSI获取的潜在研究方向作为总结。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [86] [Cluster-Aware Two-Stage Method for Fast Iterative MIMO Detection in LEO Satellite Communications](https://arxiv.org/abs/2506.21370)
> *考虑簇的双阶段方法，用于LEO卫星通信中的快速迭代MIMO检测*

*Jiuyu Liu, Yi Ma, Qihao Peng, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT**

**Keywords:** MIMO检测, LEO卫星通信, 迭代检测, 双阶段方法, 簇感知

**Comment:** This work has been accepted by IEEE/CIC ICCC 2025

> **TL;DR:** 本文提出了一种考虑簇的双阶段MIMO检测方法，用于LEO卫星通信，通过利用卫星MIMO信道的特性，显著加速了迭代检测器的收敛，即使存在信道估计误差也表现出鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了一个双阶段的MIMO检测方法，巧妙地利用了卫星MIMO信道中同簇信道相关的特性。通过将干扰消除分解为簇内和簇间两个阶段，并引入小矩阵求逆来提高计算效率，有效解决了传统迭代检测器在收敛性上的问题。其在收敛速度上的显著提升，即使在非理想条件下也保持了良好性能，显示了其在实际低轨卫星MIMO通信系统中的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统迭代MIMO检测器在卫星MIMO信道中，由于同一地理簇内用户信道特性高度相关，通常会阻碍收敛。本文旨在利用这一特性，提高计算效率并加速收敛。

**Method:** 本文提出了一种双阶段策略。第一阶段，通过计算高效的小矩阵求逆来消除簇内干扰；第二阶段，利用这些预计算的矩阵加速标准迭代MIMO检测器（如高斯-赛德尔和对称逐次超松弛），以有效消除簇间干扰。

**Result:** 计算机仿真表明，在完美信道状态信息下，所提方法实现了超过12倍的收敛速度提升。即使考虑信道估计误差，该方法也能保持9倍的收敛速度提升。

**Conclusion:** 所提出的方法通过利用卫星MIMO信道的特性，有效解决了传统迭代MIMO检测器在收敛方面的挑战，表现出鲁棒性和有效性，适用于下一代卫星MIMO通信。

> **ai_Abstract:** 本文针对LEO卫星通信中的MIMO检测，提出了一种考虑簇的双阶段方法。该方法利用卫星MIMO信道中同簇用户信道高度相关的特性，首先通过小矩阵求逆消除簇内干扰，然后利用预计算的矩阵加速标准迭代检测器来消除簇间干扰。仿真结果显示，该方法在完美信道信息下收敛速度提升12倍以上，在存在信道估计误差时也能提升9倍，展现了其在下一代卫星MIMO通信中的高效性和鲁棒性。

> **摘要翻译:** 本文提出了一种考虑簇的双输入多输出（MIMO）检测方法，用于直连蜂窝卫星通信。该方法通过利用卫星MIMO信道的独特特性来实现计算效率：同一地理簇内的用户由于物理接近而表现出高度相关的信道特性，这通常会阻碍传统迭代MIMO检测器的收敛。所提出的方法采用双阶段策略，首先使用计算高效的小矩阵求逆消除簇内干扰，然后利用这些预计算的矩阵加速标准迭代MIMO检测器，如高斯-赛德尔（GS）和对称逐次超松弛（SSOR），以有效消除簇间干扰。计算机仿真表明，在完美信道状态信息下，所提出的方法实现了超过12倍的收敛速度。即使考虑到信道估计误差，该方法也能保持9倍的收敛速度，这表明其在下一代卫星MIMO通信中的鲁棒性和有效性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [29] [Post-Quantum and Blockchain-Based Attestation for Trusted FPGAs in B5G Networks](https://arxiv.org/abs/2506.21073)
> *B5G网络中可信FPGA的后量子和基于区块链的认证*

*Ilias Papalamprou, Nikolaos Fotos, Nikolaos Chatzivasileiadis, Anna Angelogianni, Dimosthenis Masouros, Dimitrios Soudris* | **Category: cs.AR**

**Keywords:** 后量子密码, 区块链, FPGA, 远程认证, B5G网络

**Comment:** 

> **TL;DR:** 本论文提出了一种混合软硬件解决方案，利用远程认证、后量子密码算法和区块链基础设施，为B5G网络中部署在非保护环境下的FPGA提供安全配置，并实现了低开销。

**AI_Comments:** 该论文的创新点在于将后量子密码与区块链技术结合应用于FPGA的远程认证和安全配置，有效应对了量子计算威胁和非信任环境下的硬件安全挑战。其低开销的评估结果也显示了方案的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 5G及未来网络的发展需要FPGA等专用硬件来满足性能要求，但FPGA常部署在非保护环境中，易受攻击。量子计算的兴起对现有密码算法构成威胁，因此需要更强大的安全基础设施。

**Method:** 论文提出了一种混合软硬件解决方案，利用远程认证安全配置FPGA，并集成了后量子密码（PQC）算法以增强安全性。此外，为确保整个边缘计算连续体的可信度，解决方案还集成了区块链基础设施，用于安全存储任何安全证据。

**Result:** 在两种FPGA系列中，使用不同PQC算法对所提出的安全配置过程进行评估，结果显示与非PQC方法相比，开销仅为2%。

**Conclusion:** 该研究成功地提出并验证了一种针对B5G网络中FPGA的安全配置方案，该方案结合了后量子密码和区块链技术，在保证安全性的同时保持了较低的性能开销，有效应对了量子计算威胁和FPGA部署环境的安全挑战。

> **ai_Abstract:** 本文针对B5G网络中FPGA在非保护环境下易受攻击且面临量子计算威胁的问题，提出了一种混合软硬件安全配置方案。该方案结合了远程认证、后量子密码算法和区块链技术，旨在安全配置FPGA并安全存储安全证据。实验评估表明，与非PQC方法相比，该方案仅产生2%的开销，证明了其在提供增强安全性的同时具有高效性。

> **摘要翻译:** 5G及未来网络的出现带来了性能提升的网络，促进了服务更接近用户的部署。为了满足性能要求，这些服务需要专用硬件，例如现场可编程门阵列（FPGA）。然而，FPGA通常部署在非保护环境中，使用户的应用程序容易受到多种攻击。随着量子计算的兴起，它威胁着广泛使用的加密算法的完整性，对健壮安全基础设施的需求变得更加关键。本文介绍了一种混合软硬件解决方案，利用远程认证安全配置FPGA，同时集成后量子密码（PQC）算法以增强安全性。此外，为了实现整个边缘计算连续体的可信度，我们的解决方案集成了一个区块链基础设施，确保任何安全证据的安全存储。我们在两种FPGA系列中，使用不同PQC算法对所提出的安全配置过程进行了评估，结果显示与非PQC方法相比，开销仅为2%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [53] [Accelerating GNN Training through Locality-aware Dropout and Merge](https://arxiv.org/abs/2506.21414)
> *通过局部性感知Dropout和合并加速GNN训练*

*Gongjian Sun, Mingyu Yan, Dengke Han, Runzhen Xue, Duo Wang, Xiaochun Ye, Dongrui Fan* | **Category: cs.AR**

**Keywords:** GNN训练, 数据局部性, 硬件加速, Dropout, 内存合并

**Comment:** under review in TPDS. extend version of DATE 2025

> **TL;DR:** LiGNN是一种硬件加速方案，通过局部性感知的特征丢弃和DRAM行级内存访问合并，显著提升GNN训练速度并减少DRAM访问，同时保持模型精度。

**AI_Comments:** LiGNN的创新之处在于将硬件加速与算法优化相结合，特别是引入了“局部性感知”的Dropout机制，这与传统Dropout仅关注精度不同，它同时考虑了硬件效率。此外，DRAM行级内存访问合并也极大地提升了数据局部性，有效解决了GNN训练中长期存在的内存访问效率低下的问题。这项工作为未来的GNN加速器设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNN）在图学习中取得巨大成功，但顶点间的不规则连接导致低效的邻居聚合，产生大量不规则和粗粒度的DRAM访问，缺乏数据局部性，从而降低性能。现有加速器设计未能完全解决不规则DRAM访问问题。

**Method:** 本研究提出了LiGNN，一种硬件加速方案，通过在邻居聚合过程中应用局部性感知Dropout和合并技术来提高数据局部性。LiGNN引入了一种局部性感知的特征丢弃机制，选择性地丢弃节点特征，有效减少不规则DRAM访问而不损害模型精度。此外，LiGNN利用内存布局和组织知识，在DRAM行级别战略性地合并邻居聚合期间的内存访问。

**Result:** 在常用的0.5丢弃率下，LiGNN比现有最佳方法提速1.48~3.02倍，将DRAM访问减少34%~55%，DRAM行激活减少59%~82%，同时保持模型精度。

**Conclusion:** LiGNN通过硬件级的局部性感知Dropout和内存访问合并，有效解决了GNN训练中数据局部性差导致性能下降的问题，显著加速了GNN训练并降低了DRAM能耗，同时保持了模型精度。

> **ai_Abstract:** 本论文提出LiGNN，一种硬件加速方案，旨在解决GNN训练中因不规则连接导致的低效邻居聚合和DRAM访问问题。LiGNN通过引入局部性感知特征丢弃机制，选择性地减少不规则DRAM访问，并在DRAM行级别战略性合并内存访问，以提高数据局部性。实验结果表明，LiGNN在保持模型精度的同时，显著加速了GNN训练，并大幅减少了DRAM访问和行激活。

> **摘要翻译:** 图神经网络（GNNs）在图学习中取得了显著成功，并被广泛应用于各种关键领域。然而，顶点之间不规则的连接导致低效的邻居聚合，从而产生大量的非规则和粗粒度的DRAM访问。这种数据局部性的缺乏给执行平台带来了重大挑战，最终降低了性能。虽然之前的加速器设计利用了片上内存和数据访问调度策略来解决这个问题，但它们仍然不可避免地从DRAM以不规则地址访问特征。在这项工作中，我们提出了LiGNN，一种基于硬件的解决方案，通过在邻居聚合期间应用丢弃（dropout）和合并（merge）技术来提高数据局部性，从而加速GNN训练。与主要旨在提高精度而忽视硬件成本的传统算法级丢弃方法不同，LiGNN引入了一种局部性感知的特征丢弃机制。这种方法选择性地丢弃具有数据局部性意识的节点特征，在不损害模型精度的情况下有效减少不规则DRAM访问。此外，通过利用内存布局和组织（包括关键对齐约束）的详细知识，LiGNN在GNN级语义的指导下，在DRAM行级别战略性地合并邻居聚合期间的内存访问。这种优化以最小的额外成本显著提高了数据局部性。在常用的0.5丢弃率下，LiGNN优于现有最先进的方法，实现了1.48~3.02倍的加速，将DRAM访问减少了34%~55%，并将DRAM行激活降低了59%~82%，同时保持了模型精度。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [78] [OptGM: An Optimized Gate Merging Method to Mitigate NBTI in Digital Circuits](https://arxiv.org/abs/2506.21487)
> *OptGM：一种优化门合并方法以减轻数字电路中的NBTI效应*

*Maryam Ghane, Amir M. Hajisadeghi, Hamid R. Zarandi* | **Category: cs.AR**

**Keywords:** NBTI, 门合并, 数字电路, 可靠性, 延迟退化

**Comment:** 

> **TL;DR:** OptGM是一种优化的门合并方法，通过识别并合并NBTI关键节点相关的门，有效减轻数字电路中的NBTI效应，显著降低NBTI关键晶体管数量和延迟退化。

**AI_Comments:** 该论文提出了一种新颖的门合并方法OptGM来解决数字电路中的NBTI效应。其创新点在于识别NBTI关键节点并进行有针对性的门合并，有效降低了NBTI关键晶体管数量和延迟退化，同时保持了较低的面积开销和提高了性能成本比，显示出其在可靠性设计中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 数字电路中负偏置温度不稳定性（NBTI）问题导致性能下降，需要一种有效的方法来减轻其影响。

**Method:** OptGM首先识别信号概率超过预定义阈值的NBTI关键内部节点。然后，基于优化算法，将驱动关键节点的敏感门和被关键节点馈送的敏感门合并成一个新的复杂门，该复杂门保留原始逻辑并消除NBTI关键节点。

**Result:** OptGM在组合和时序基准电路上进行评估。仿真结果显示，NBTI关键晶体管数量平均减少89.29%，NBTI引起的延迟退化平均减少23.87%，总晶体管数量平均减少6.47%。此外，性能成本（PPC）平均提高12.8%，面积开销极小。

**Conclusion:** OptGM是一种有效的NBTI缓解方法，能够显著减少NBTI关键晶体管、降低延迟退化，并提高性能成本比，同时保持较低的面积开销。

> **ai_Abstract:** 本文提出OptGM，一种优化的门合并方法，旨在减轻数字电路中的NBTI效应。该方法通过识别NBTI关键内部节点，并将驱动和被馈送这些关键节点的门合并成新的复杂门，从而消除关键节点并保持原有逻辑。实验结果表明，OptGM显著减少了NBTI关键晶体管数量、延迟退化和总晶体管数量，并提高了性能成本比，同时保持最小的面积开销。

> **摘要翻译:** 本文提出OptGM，一种优化的门合并方法，旨在减轻数字电路中的负偏置温度不稳定性（NBTI）。首先，所提出的方法有效识别NBTI关键内部节点，这些节点被定义为信号概率超过预定义阈值的节点。其次，基于所提出的优化算法，将敏感门（驱动关键节点的门）和被关键节点馈送的敏感门合并成一个新的复杂门。这个复杂门保留了原始逻辑，同时消除了NBTI关键节点。最后，为了评估OptGM的有效性，我们在几个组合和时序基准电路上对其进行了评估。仿真结果表明，NBTI关键晶体管（即连接到关键节点的PMOS晶体管）的数量、NBTI引起的延迟退化以及总晶体管数量平均分别减少了89.29%、23.87%和6.47%。此外，OptGM平均将性能成本（PPC）提高了12.8%，且面积开销极小。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [13] [ClusterRCA: Network Failure Diagnosis in HPC Systems Using Multimodal Data](https://arxiv.org/abs/2506.20673)
> *ClusterRCA：使用多模态数据在HPC系统中进行网络故障诊断*

*Yongqian Sun, Xijie Pan, Xiao Xiong, Lei Tao, Jiaju Wang, Shenglin Zhang, Yuan Yuan, Yuqi Li, Kunlin Jian* | **Category: cs.DC, cs.AI**

**Keywords:** 网络故障诊断, HPC系统, 多模态数据, 故障定位, 随机游走

**Comment:** 

> **TL;DR:** ClusterRCA是一个用于HPC系统网络故障诊断的新框架，它结合了分类器和图方法，利用多模态数据来高精度地定位故障节点并确定故障类型。

**AI_Comments:** ClusterRCA的创新之处在于其结合了分类器和图方法的混合诊断策略，并能有效处理HPC系统中复杂的多模态数据。其重要性体现在解决了HPC系统网络故障诊断的关键挑战，提升了诊断的准确性和鲁棒性。该方法对于维护大型复杂计算系统的稳定运行具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 网络故障诊断对高性能计算（HPC）系统来说既具有挑战性又至关重要。现有方法由于数据异构性和准确性不足，无法直接应用于HPC场景。

**Method:** 本文提出了一个名为ClusterRCA的新框架，通过利用多模态数据来定位故障节点并确定故障类型。ClusterRCA从拓扑连接的网络接口控制器（NIC）对中提取特征，以分析HPC系统中多样化的多模态数据。为了准确地定位故障节点并确定故障类型，ClusterRCA结合了基于分类器和基于图的方法。它根据状态分类器的输出构建一个故障图，然后在图上执行定制的随机游走来定位根本原因。

**Result:** 在由一家顶级全球HPC设备供应商收集的数据集上进行的实验表明，ClusterRCA在诊断HPC系统网络故障方面取得了高精度，并且在不同应用场景中保持了鲁棒的性能。

**Conclusion:** ClusterRCA为HPC系统提供了一种高精度、鲁棒的网络故障诊断方法，有效解决了现有方法在数据异构性和准确性方面的不足。

> **ai_Abstract:** ClusterRCA是一个针对HPC系统网络故障诊断的新型框架，旨在克服现有方法在数据异构性和准确性方面的不足。它通过从NIC对中提取特征来处理多模态数据，并结合分类器和图方法。具体而言，它构建故障图并执行定制的随机游走来定位根本原因。实验证明，ClusterRCA在HPC系统网络故障诊断中表现出高精度和鲁棒性。

> **摘要翻译:** 网络故障诊断对于高性能计算（HPC）系统来说既具有挑战性又至关重要。由于数据异构性和准确性不足，现有方法无法直接应用于HPC场景。本文提出了一种新颖的框架，名为ClusterRCA，通过利用多模态数据来定位故障节点并确定故障类型。ClusterRCA从拓扑连接的网络接口控制器（NIC）对中提取特征，以分析HPC系统中多样化的多模态数据。为了准确地定位故障节点并确定故障类型，ClusterRCA结合了基于分类器和基于图的方法。它根据状态分类器的输出构建一个故障图，然后在图上执行定制的随机游走来定位根本原因。在由一家顶级全球HPC设备供应商收集的数据集上进行的实验表明，ClusterRCA在诊断HPC系统网络故障方面取得了高精度。ClusterRCA还在不同应用场景中保持了鲁棒的性能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [38] [Scalable GPU Performance Variability Analysis framework](https://arxiv.org/abs/2506.20674)
> *可扩展的GPU性能变异性分析框架*

*Ankur Lahiry, Ayush Pokharel, Seth Ockerman, Amal Gueroudji, Line Pouchard, Tanzima Z. Islam* | **Category: cs.DC, cs.PF**

**Keywords:** GPU性能, 分布式分析, 性能变异性, HPC, AI工作负载

**Comment:** 

> **TL;DR:** 该论文介绍了一个分布式数据分析框架，用于解决大规模GPU性能日志分析中内存和运行时限制的问题，通过数据分片和并行处理实现可扩展性，并成功诊断了HPC和AI工作负载中的性能变异性。

**AI_Comments:** 这项工作通过引入分布式数据分析框架，创新性地解决了大规模GPU性能分析面临的内存和运行时瓶颈问题。其将数据集分片并并行处理的方法，有效提升了分析的可扩展性和效率，对于HPC和AI等需要处理海量性能数据的领域具有重要意义。该框架能够诊断性能变异性并揭示深层性能因素，为优化GPU工作负载提供了宝贵工具。

<details>
  <summary>Details</summary>

**Motivation:** 分析来自GPU性能分析器的大规模性能日志通常需要大量的内存和运行时，即使是基本摘要也需要太字节内存和数小时运行时间。这些限制阻碍了及时洞察和性能分析集成到自动化工作流中。现有分析工具通常顺序处理数据，不适用于日益增长的跟踪复杂性和数据量的HPC工作流。

**Method:** 我们引入了一个分布式数据分析框架，该框架可随数据集大小和计算可用性进行扩展。该系统不将数据集视为一个单一实体，而是将其划分为可独立分析的分片，并跨MPI等级并行处理它们。这种设计减少了每个节点的内存压力，避免了中心瓶颈，并实现了对高维跟踪数据的低延迟探索。

**Result:** 该框架应用于真实HPC和AI工作负载的端到端Nsight Compute跟踪，展示了其诊断性能变异性的能力，并揭示了内存传输延迟对GPU内核行为的影响。

**Conclusion:** 该分布式数据分析框架有效解决了大规模GPU性能日志分析的挑战，通过其可扩展的设计，能够成功诊断性能变异性并揭示关键性能因素，从而为HPC和AI工作负载提供及时洞察。

> **ai_Abstract:** 本文提出了一个可扩展的分布式数据分析框架，旨在解决大规模GPU性能日志分析中遇到的内存和运行时限制。该框架通过将数据集分片并利用MPI并行处理，有效降低了内存压力并消除了中心瓶颈，从而实现了对高维跟踪数据的低延迟探索。实验证明，该框架能成功诊断HPC和AI工作负载中的GPU性能变异性，并揭示了内存传输延迟对GPU内核行为的具体影响。

> **摘要翻译:** 分析来自GPU性能分析器的大规模性能日志通常需要太字节的内存和数小时的运行时间，即使是基本摘要也如此。这些限制阻碍了及时洞察，并阻碍了性能分析集成到自动化工作流中。现有分析工具通常顺序处理数据，使其不适合处理日益增长的跟踪复杂性和数据量的HPC工作流。我们引入了一个分布式数据分析框架，该框架可随数据集大小和计算可用性进行扩展。该系统不将数据集视为一个单一实体，而是将其划分为可独立分析的分片，并跨MPI等级并行处理它们。这种设计减少了每个节点的内存压力，避免了中心瓶颈，并实现了对高维跟踪数据的低延迟探索。我们将该框架应用于真实HPC和AI工作负载的端到端Nsight Compute跟踪，展示了其诊断性能变异性的能力，并揭示了内存传输延迟对GPU内核行为的影响。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [62] [Utility-Driven Speculative Decoding for Mixture-of-Experts](https://arxiv.org/abs/2506.20675)
> *面向混合专家模型的效用驱动推测解码*

*Anish Saxena, Po-An Tsai, Hritvik Taneja, Aamer Jaleel, Moinuddin Qureshi* | **Category: cs.DC, cs.AI, cs.LG**

**Keywords:** 推测解码, 混合专家模型, LLM推理, GPU内存, 吞吐量优化

**Comment:** 

> **TL;DR:** 推测解码对混合专家模型（MoE）无效，因为它会增加数据移动和验证时间。本文提出了Cascade框架，通过动态调整推测解码参数，使其适用于MoE模型，从而限制性能下降并提高吞吐量。

**AI_Comments:** 这项工作的创新之处在于识别了推测解码在MoE模型中的局限性，并提出了一个基于效用的动态自适应框架来解决这一问题。其重要性在于，它将一种高效的推理优化技术（推测解码）扩展到了新兴且日益重要的MoE模型架构上，这对于提升MoE模型的实际应用性能至关重要。通过动态调整K值和启用/禁用推测解码的策略，Cascade能够适应不同的任务和工作负载，这是一个非常巧妙且实用的设计。

<details>
  <summary>Details</summary>

**Motivation:** GPU内存带宽是大型语言模型（LLM）推理的主要瓶颈。推测解码通过利用空闲GPU计算来提高密集型LLM的吞吐量。然而，本文发现推测解码对MoE模型无效，因为它会导致数据移动和验证时间增加2-3倍，可能导致高达1.5倍的减速。此外，最佳的推测K值因任务、模型甚至请求和迭代而异。因此，尽管在密集型LLM中广泛使用，推测解码在领先的MoE模型中仍然不实用。本文旨在解决这一问题，使推测解码在MoE模型中变得实用。

**Method:** 本文提出了Cascade，一个效用驱动的框架，用于选择性地启用推测解码以避免减速，并动态调整K值以加速MoE服务。Cascade使用一个轻量级指标——推测效用，即令牌增益与验证成本之比，该指标显示出迭代级别的局部性，通过短测试阶段和长设置阶段实现周期性决策。对于每个请求，如果测试期间效用降至1以下，Cascade会禁用推测解码；当效用超过1时，它会测试多个K值，以选择在设置阶段实现效用最大化的K值。该框架在vLLM中实现，并在五个流行的MoE模型上进行了评估，涵盖了代码、数学、提取和混合任务的工作负载。

**Result:** Cascade将减速限制在5%（相比之下，未经优化的推测解码可能导致1.5倍的减速），并且比静态K值提高了7-14%的吞吐量。

**Conclusion:** Cascade框架使得推测解码在混合专家模型（MoE）中变得实用。

> **ai_Abstract:** 推测解码在密集型大型语言模型（LLM）中有效，但本文指出其在混合专家（MoE）模型中效率低下，因为它会导致数据移动和验证时间增加，从而降低性能。为解决此问题，论文提出了Cascade框架。Cascade是一个效用驱动的系统，它通过引入“推测效用”这一轻量级指标，动态地决定何时启用推测解码以及如何优化草稿令牌数量（K值）。通过周期性的测试和设置阶段，Cascade能够根据效用值自适应地调整策略，从而避免减速并提高吞吐量。实验结果表明，Cascade成功将MoE模型中的推测解码所导致的减速限制在5%以内，并相对于静态K值方案实现了7-14%的吞吐量提升，使得推测解码在MoE模型中变得可行和实用。

> **摘要翻译:** GPU内存带宽是低延迟大型语言模型（LLM）推理的主要瓶颈。推测解码通过使用轻量级草稿器提出K个令牌来利用空闲GPU计算，LLM并行验证这些令牌，从而提高令牌吞吐量。在传统的密集型LLM中，每次迭代都会获取所有模型权重，因此推测不会增加延迟开销。新兴的混合专家（MoE）模型每个令牌仅激活部分权重，大大减少了数据移动。然而，我们表明推测解码对MoE模型无效：草稿令牌共同激活更多权重，使数据移动和验证时间增加2-3倍。当令牌吞吐量增益无法抵消此开销时，推测会导致高达1.5倍的减速，使其不可行。即使有用，最佳的K值也因任务、模型，甚至请求和迭代而异。因此，尽管在密集型LLM中广泛使用，推测解码在领先的MoE模型中仍然不实用。
我们提出了Cascade，一个效用驱动的框架，它选择性地启用推测解码以避免减速，并动态调整K值以加速MoE服务。Cascade使用一个轻量级指标——推测效用，即令牌增益与验证成本之比，该指标显示出迭代级别的局部性，通过短测试阶段和长设置阶段实现周期性决策。对于每个请求，如果测试期间效用降至1以下，Cascade会禁用推测解码；当效用超过1时，它会测试多个K值，以选择在设置阶段实现效用最大化的K值。我们在vLLM中实现了Cascade，并在五个流行的MoE模型上进行了评估，涵盖了代码、数学、提取和混合任务的工作负载。Cascade将减速限制在5%（相比1.5倍），并比静态K值提高了7-14%的吞吐量，使推测解码对MoE模型变得实用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [87] [ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks](https://arxiv.org/abs/2506.20938)
> *ParEval-Repo: 一个用于评估大型语言模型在仓库级高性能计算翻译任务中的基准套件*

*Joshua H. Davis, Daniel Nichols, Ishan Khillan, Abhinav Bhatele* | **Category: cs.DC**

**Keywords:** LLM, 代码翻译, GPGPU, 基准测试, 高性能计算

**Comment:** 11 pages, 5 figures

> **TL;DR:** ParEval-Repo是一个新基准，用于评估LLM自动翻译GPGPU代码库的有效性。研究发现LLM对小型程序翻译可行，但处理大型代码库的构建系统和跨文件依赖存在困难。

**AI_Comments:** ParEval-Repo的创新之处在于它提供了一个专门的基准，用于评估LLM在实际且复杂的仓库级高性能计算代码翻译任务中的能力。它关注的难点，如构建系统和跨文件依赖，是代码翻译中真实存在的挑战，也揭示了当前LLM在处理这类复杂工程任务时的局限性。这项工作为未来LLM在软件工程领域的应用提供了重要的方向和改进空间。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，GPGPU架构日益多样化，导致出现了多种专门的编程模型和软件栈。尽管存在可移植的执行模型，但将代码移植并优化到不同硬件架构仍需要大量开发人员的努力。大型语言模型的最新进展有望减轻部分程序员负担。

**Method:** 本文提出了一个名为ParEval-Repo的新型基准和测试框架，用于评估基于LLM的方法在自动翻译整个GPGPU执行模型代码库方面的有效性。ParEval-Repo包含多个科学计算和AI迷你应用程序，涵盖多种编程模型和仓库复杂性级别。研究使用ParEval-Repo评估了一系列最先进的开源和商业LLM，包括非代理和自顶向下代理方法。评估了LLM生成的代码在可编译性、功能正确性、构建错误类别以及翻译成本（推理令牌数量）方面的表现。

**Result:** 研究结果表明，LLM翻译科学应用程序对于小型程序是可行的，但生成功能性构建系统和处理跨文件依赖方面的困难，给扩展到更大的代码库带来了挑战。

**Conclusion:** 尽管大型语言模型在小型程序的高性能计算代码翻译方面显示出潜力，但它们在处理复杂构建系统和跨文件依赖方面的局限性，使得将这些技术扩展到大型、实际的代码库仍然是一个重大挑战。

> **ai_Abstract:** 本文介绍了ParEval-Repo，一个用于评估大型语言模型（LLM）在GPGPU代码库翻译任务中表现的新基准套件。该基准包含不同复杂度的科学计算和AI迷你应用程序。研究使用ParEval-Repo评估了多种LLM，并发现LLM在翻译小型程序方面是可行的，但在处理功能性构建系统和跨文件依赖时面临挑战，这限制了它们扩展到大型代码库的能力。

> **摘要翻译:** 近年来，GPGPU架构变得日益多样化，这导致了各种专门的编程模型和软件栈的出现以支持它们。尽管存在可移植的执行模型，但它们仍然需要开发人员付出巨大的努力才能移植到不同的硬件架构并进行优化。大型语言模型（LLM）的最新进展可以帮助我们减轻程序员的这种负担。在本文中，我们提出了一个新的基准和测试框架ParEval-Repo，它可以用于评估基于LLM的方法在自动翻译整个GPGPU执行模型代码库方面的有效性。ParEval-Repo包含一系列编程模型和仓库复杂性级别的多个科学计算和AI迷你应用程序。我们使用ParEval-Repo评估了一系列最先进的开源和商业LLM，采用了非代理和自顶向下代理两种方法。我们从可编译性、功能正确性、构建错误类别以及翻译成本（推理令牌数量）方面评估了LLM和方法生成的代码。我们的结果表明，LLM翻译科学应用程序对于小型程序是可行的，但生成功能性构建系统和跨文件依赖方面的困难给扩展到更大的代码库带来了挑战。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [110] [Portable High-Performance Kernel Generation for a Computational Fluid Dynamics Code with DaCe](https://arxiv.org/abs/2506.20994)
> *适用于计算流体动力学代码的DaCe可移植高性能内核生成*

*Måns I. Andersson, Martin Karp, Niclas Jansson, Stefano Markidis* | **Category: cs.DC, cs.PF**

**Keywords:** DaCe, 高性能计算, 自动代码生成, 计算流体动力学, 可移植性

**Comment:** 

> **TL;DR:** 本文利用DaCe框架，实现了计算流体动力学（CFD）代码的高性能内核自动化生成，解决了多硬件架构下的代码移植和性能优化挑战，并展示了其在不同GPU平台上的可移植性和竞争力性能。

**AI_Comments:** 该论文的创新点在于利用DaCe这一数据中心并行编程框架，有效地解决了高性能计算（HPC）领域中异构硬件架构下代码移植和性能优化的难题。它通过自动化内核生成，显著减轻了开发者为不同架构重写代码的负担，提升了大型科学应用（如CFD）的可持续性。其重要性在于为未来HPC应用开发提供了一种更高效、更具可移植性的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 随着新型高性能计算（HPC）加速器的出现，高效地针对多样化硬件架构成为HPC应用开发者的主要挑战。HPC系统中日益增长的硬件多样性常常需要开发针对特定架构的代码，这阻碍了大型科学应用的可持续性。

**Method:** 本研究利用数据中心并行编程框架DaCe来自动化生成高性能内核。通过将DaCe的自动代码生成应用于计算流体动力学（CFD）中关键的计算内核，特别是Fortran基的Neko求解器（采用谱元法），并详细阐述了使用DaCe的Stateful Dataflow Multigraph (SDFG) 表示来构建计算内核的方法，以及将DaCe生成的代码无缝集成到Neko求解器的工作流程。

**Result:** 生成的代码在包括Nvidia GH200、Nvidia A100和AMD MI250X GPU在内的多个平台上展现出良好的可移植性和具有竞争力的性能。

**Conclusion:** 通过展示自动代码生成的潜力，本研究强调了使用可移植解决方案确保大型科学应用长期可持续性的可行性。

> **ai_Abstract:** 本文利用数据中心并行编程框架DaCe，实现了计算流体动力学（CFD）代码高性能内核的自动化生成，旨在解决HPC领域日益增长的硬件多样性带来的代码开发和维护挑战。研究通过将DaCe应用于基于Fortran的Neko求解器中的关键计算内核，展示了其在多核处理器和多种加速器上自动生成代码的能力。结果表明，DaCe生成的代码在包括Nvidia和AMD GPU在内的多种平台上具有良好的可移植性和竞争力性能，证明了自动化代码生成在保障大型科学应用长期可持续性方面的潜力。

> **摘要翻译:** 随着Nvidia和AMD GPU等新型高性能计算（HPC）加速器的出现，高效地针对多样化硬件架构已成为HPC应用开发者的主要挑战。HPC系统中日益增长的硬件多样性常常需要开发针对特定架构的代码，这阻碍了大型科学应用的可持续性。在这项工作中，我们利用DaCe（一个以数据为中心的并行编程框架）来自动化生成高性能内核。DaCe能够为多核处理器和各种加速器自动生成代码，从而减轻了开发者为每种新架构重写代码的负担。我们的研究通过将DaCe的自动代码生成应用于计算流体动力学（CFD）中使用的关键计算内核，展示了DaCe的能力。具体来说，我们专注于Neko，一个基于Fortran的求解器，它采用谱元法，依赖于小型张量操作。我们详细阐述了使用DaCe的Stateful Dataflow Multigraph (SDFG) 表示来构建这个计算内核，并讨论了这种方法如何促进高性能代码生成。此外，我们概述了将DaCe生成的代码无缝集成到Neko求解器中的工作流程。我们的结果突出了生成代码在多个平台上的可移植性和性能，包括Nvidia GH200、Nvidia A100和AMD MI250X GPU，并取得了有竞争力的性能结果。通过展示自动代码生成的潜力，我们强调了使用可移植解决方案确保大型科学应用长期可持续性的可行性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [131] [BLOCKS: Blockchain-supported Cross-Silo Knowledge Sharing for Efficient LLM Services](https://arxiv.org/abs/2506.21033)
> *BLOCKS：区块链支持的跨孤岛知识共享，实现高效LLM服务*

*Zhaojiacheng Zhou, Hongze Liu, Shijing Yuan, Hanning Zhang, Jiong Lou, Chentao Wu, Jie Li* | **Category: cs.DC**

**Keywords:** 区块链, 知识共享, 大型语言模型, 幻觉问题, 数据安全

**Comment:** 

> **TL;DR:** BLOCKS是一个基于区块链的框架，通过协调分散的知识孤岛，为大型语言模型（LLMs）提供可靠的外部知识，以解决幻觉问题，同时确保数据安全和知识质量。

**AI_Comments:** 该论文的创新点在于将区块链技术应用于解决LLM的知识幻觉问题，通过构建一个去中心化的知识共享框架，有效克服了传统知识共享中存在的隐私和安全障碍。声誉机制和交叉验证的引入，是确保共享知识质量和激励用户参与的关键，这对于构建一个可持续的知识生态系统至关重要。该方法为未来LLM的知识增强和应用提供了新的思路，特别是在需要处理敏感或分布式数据的场景下具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的幻觉问题日益受到关注。通过外部知识增强LLMs是解决此问题的一个有前景的方案。然而，由于隐私和安全问题，大量下游任务相关的知识分散并隔离在不同的“孤岛”中，难以访问。

**Method:** 我们提出了一个基于区块链的外部知识框架，协调多个知识孤岛，为大型模型检索提供可靠的基础知识，同时确保数据安全。技术上，我们从本地数据中提取知识到提示中，并在区块链上执行交易和记录。此外，我们引入了声誉机制和交叉验证来确保知识质量并激励参与。我们还设计了一个查询生成框架，为大型模型检索提供直接的API接口。

**Result:** 实验结果表明，所提出的框架在区块链环境中实现了高效的LLM服务知识共享。

**Conclusion:** 该论文提出了BLOCKS框架，一个基于区块链的解决方案，用于解决LLM的幻觉问题，通过安全地汇集和共享跨孤岛的外部知识，并引入机制确保知识质量和参与激励，最终实现了高效的LLM服务知识共享。

> **ai_Abstract:** 本文提出了BLOCKS框架，一个基于区块链的解决方案，旨在通过安全、高效地共享分散在不同“孤岛”中的外部知识来解决大型语言模型（LLMs）的幻觉问题。该框架利用区块链记录知识交易，通过提示从本地数据中提取知识，并结合声誉机制和交叉验证确保知识质量和激励参与。它还提供了一个查询生成API接口，实验证明其在区块链环境下实现了高效的LLM服务知识共享。

> **摘要翻译:** 大型语言模型（LLMs）的幻觉问题日益受到关注。通过外部知识增强LLMs是解决此问题的一个有前景的方案。然而，由于隐私和安全问题，大量下游任务相关的知识分散并隔离在各种“孤岛”中，难以访问。为了弥补这一知识鸿沟，我们提出了一个基于区块链的外部知识框架，该框架协调多个知识孤岛，为大型模型检索提供可靠的基础知识，同时确保数据安全。技术上，我们从本地数据中提取知识到提示中，并在区块链上执行交易和记录。此外，我们引入了声誉机制和交叉验证来确保知识质量并激励参与。此外，我们设计了一个查询生成框架，为大型模型检索提供直接的API接口。为了评估我们提出的框架的性能，我们对各种知识源进行了广泛的实验。结果表明，所提出的框架在区块链环境中实现了高效的LLM服务知识共享。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [149] [Bridding OT and PaaS in Edge-to-Cloud Continuum](https://arxiv.org/abs/2506.21072)
> *将OT和PaaS桥接到边缘到云的连续体中*

*Carlos J Barrios, Yves Denneulin* | **Category: cs.DC, cs.PF**

**Keywords:** 运营技术, 平台即服务, 边缘到云, 数据管理, 工业转型

**Comment:** 

> **TL;DR:** 论文介绍了运营技术即服务平台（OTPaaS），这是一个为工业转型提供高效数据管理、存储、安全、可靠性、数据主权和能效的框架，并展示了其在边缘和云环境中的成功部署和应用管理。

**AI_Comments:** 这篇论文通过提出OTPaaS，有效地将运营技术（OT）与平台即服务（PaaS）模型结合，为边缘到云的连续体中的数据管理和存储提供了一个全面的解决方案。其创新点在于强调了数据主权、能源效率等工业转型中的关键要素，并展示了实际部署和对挑战的解决，显示了其在工业物联网和云计算融合领域的潜在重要性。

<details>
  <summary>Details</summary>

**Motivation:** 工业转型和数据主权对数据管理、存储、安全性、可靠性、数据和技术主权、鲁棒性及能源效率有高要求，OTPaaS旨在提供一个结构化框架来满足这些关键需求。

**Method:** 本文提出了运营技术即服务平台（OTPaaS）倡议，该倡议提供了一个结构化的数据高效管理和存储框架。它利用了平台即服务（PaaS）模型的优势，并阐述了成功的部署、可适应的应用程序管理以及针对边缘和云环境的各种集成组件，同时解决了特定用例的关键挑战。

**Result:** OTPaaS实现了成功的部署、可适应的应用管理和针对边缘及云环境的多种集成组件。它显著提升了数据管理和存储的效率，并改善了响应时间、安全性、可靠性、数据和技术主权、鲁棒性以及能源效率。

**Conclusion:** 运营技术即服务平台（OTPaaS）通过提供一个结构化框架并解决关键挑战，成功地将运营技术（OT）与平台即服务（PaaS）模型结合，为边缘到云的连续体中的数据高效管理和存储提供了解决方案，并提升了多项关键性能指标，对工业转型和数据主权至关重要。

> **ai_Abstract:** 本文介绍了运营技术即服务平台（OTPaaS）倡议，该倡议提供了一个结构化框架，旨在高效管理和存储数据，同时提升响应时间、安全性、可靠性、数据和技术主权、鲁棒性以及能源效率。OTPaaS对于工业转型和数据主权至关重要，论文展示了其在边缘和云环境中的成功部署、灵活的应用管理和多种集成组件，并通过利用PaaS模型解决了特定用例中的关键挑战。

> **摘要翻译:** 运营技术即服务平台 (OTPaaS) 倡议提供了一个结构化的框架，用于高效的数据管理和存储。它确保了出色的响应时间，同时提高了安全性、可靠性、数据和技术主权、鲁棒性以及能源效率，这些对于工业转型和数据主权至关重要。本文阐述了成功的部署、可适应的应用程序管理以及满足边缘和云环境的各种集成组件。它利用了平台即服务模型的优势，并强调了针对特定用例已解决的关键挑战。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [166] [Enabling Bitcoin Smart Contracts on the Internet Computer](https://arxiv.org/abs/2506.21327)
> *在互联网计算机上实现比特币智能合约*

*Ryan Croote, Islam El-Ashi, Thomas Locher, Yvonne-Anne Pignolet* | **Category: cs.DC**

**Keywords:** 比特币智能合约, 互联网计算机, 直接集成, 去中心化应用, 区块链互操作性

**Comment:** Published at ICDCS 2025, waiting for DOI

> **TL;DR:** 本文提出了一种新架构，使比特币智能合约可以直接在互联网计算机（IC）上运行，通过节点直接交互而非桥接，提高了效率和安全性，并支持复杂的比特币去中心化应用。

**AI_Comments:** 这项工作通过实现互联网计算机与比特币的直接集成，提供了一种无需桥接即可在比特币上构建智能合约的创新方法，解决了现有方案的安全和效率问题。其核心创新在于协调了两种不同区块链的特性（比特币的概率性与IC的不可逆性）。这对于扩展比特币的实用性和推动更复杂的去中心化金融应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 比特币本身的可编程性有限，但市场对利用其价值进行编程访问的需求日益增长。现有方案（如在比特币之上构建新功能或通过桥接机制使用“封装”比特币）存在安全风险。

**Method:** 本文提出了一种新架构，使图灵完备的比特币智能合约能够在互联网计算机（IC）上执行。该架构通过IC和比特币节点之间的直接交互实现，避免了桥接机制带来的潜在安全风险。此外，它引入了新概念来协调比特币的概率性与IC上最终状态更改的不可逆性。

**Result:** 基于主网上的比特币集成测量结果显示，该集成可以在几秒内完成最终确定，且执行成本低。

**Conclusion:** 这种集成使得以前不切实际或不经济的复杂比特币去中心化应用成为可能。

> **ai_Abstract:** 本文提出了一种在互联网计算机（IC）上直接执行图灵完备比特币智能合约的新架构。该方案通过IC和比特币节点间的直接交互，避免了传统桥接机制带来的安全风险。为解决比特币的概率性与IC状态更改的不可逆性之间的冲突，文中引入了新颖概念。评估结果显示，该集成具有快速最终确定和低成本的优势，从而使复杂的比特币去中心化应用得以实现，克服了以往的实用性和经济性障碍。

> **摘要翻译:** 人们对比特币中锁定的价值进行编程访问的兴趣日益增长，众所周知，比特币本身提供的可编程性有限。近年来，各种方法层出不穷，绝大多数提出的机制要么在比特币之上构建新功能，要么利用桥接机制在完全不同的平台上实现使用“封装”比特币的智能合约。
在这项工作中，提出了一种采用不同方法的新架构。该架构使图灵完备的比特币智能合约能够在互联网计算机（IC）上执行，IC是一个用于托管和执行去中心化应用程序的区块链平台。IC和比特币节点之间直接交互，而不是使用桥接，从而消除了使用桥接可能带来的潜在安全风险。这种集成需要新颖的概念，特别是要协调比特币的概率性与IC上最终状态更改的不可逆性，这可能具有独立的意义。
除了架构的呈现，我们还提供了基于主网上比特币集成测量结果的评估。评估结果表明，通过几秒钟内的最终确定和低执行成本，这种集成使得以前不切实际或不经济的复杂比特币去中心化应用程序成为可能。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [183] [Carbon-Aware Microservice Deployment for Optimal User Experience on a Budget](https://arxiv.org/abs/2506.21422)
> *碳感知微服务部署，以预算内实现最佳用户体验*

*Kevin Kreutz, Philipp Wiesner, Monica Vitali* | **Category: cs.DC**

**Keywords:** 碳感知, 微服务, 用户体验, 部署, 碳足迹

**Comment:** LOCO 2024, December 3, 2024, Glasgow/Online

> **TL;DR:** 提出一种碳感知微服务部署方法，通过选择合适的版本和横向扩展，在碳预算内最大化用户体验和收入。

**AI_Comments:** 这项研究的创新之处在于将碳感知策略应用于对可用性和延迟有严格要求的微服务架构，填补了现有碳感知方法在这方面的空白。它提供了一种实际可行的方案，平衡了环境可持续性、用户体验和经济效益。其潜在局限性可能在于需要精确的碳强度预测和复杂的配置管理。

<details>
  <summary>Details</summary>

**Motivation:** 数据中心的碳足迹已成为关键问题。现有碳感知策略主要针对批处理，无法应用于需要实时可达和低延迟的服务导向型云应用。

**Method:** 提出一种碳感知方法，用于在每小时碳预算下运行微服务。该策略通过为每个微服务选择最合适的版本和横向扩展，在预算约束内最大化用户体验和收入。

**Result:** 跨各种应用配置和碳预算的实验表明，该方法能正确适应不断变化的工作负载和碳强度。

**Conclusion:** 该碳感知微服务部署方法能够在预算内有效管理碳足迹，同时优化用户体验和收入，并能适应动态环境。

> **ai_Abstract:** 本文提出了一种针对服务导向型云应用的碳感知微服务部署策略，以应对数据中心日益增长的碳足迹问题。不同于传统批处理的碳调度方法，该策略通过为每个微服务智能选择版本和横向扩展，旨在每小时碳预算内最大化用户体验和收入。实验证明，该方法能有效适应动态的工作负载和碳强度变化。

> **摘要翻译:** 数据中心的碳足迹最近已成为一个关键问题。迄今为止，大多数碳感知策略都专注于利用批处理调度决策的灵活性，通过改变工作负载执行的时间和地点。然而，此类方法无法应用于面向服务的云应用程序，因为它们必须在任何时间点都可达，并且通常需要低延迟。我们提出了一种碳感知方法，用于在每小时碳预算下运行微服务。通过为每个微服务选择最合适的版本和横向扩展，我们的策略在保持预算约束的同时，最大化用户体验和收入。跨各种应用配置和碳预算的实验表明，该方法能够正确适应不断变化的工作负载和碳强度。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [197] [exa-AMD: A Scalable Workflow for Accelerating AI-Assisted Materials Discovery and Design](https://arxiv.org/abs/2506.21449)
> *exa-AMD：一个用于加速AI辅助材料发现与设计的可扩展工作流*

*Maxim Moraru, Weiyi Xia, Zhuo Ye, Feng Zhang, Yongxin Yao, Ying Wai Li, Cai-Zhuang Wang* | **Category: cs.DC**

**Keywords:** 材料发现, AI/ML, 可扩展工作流, Parsl, 量子力学计算

**Comment:** We intend to publish the paper to the Journal of Open Source Software

> **TL;DR:** exa-AMD是一个基于Python的应用，利用Parsl加速AI辅助的材料发现与设计，实现从笔记本到超级计算机的可扩展工作流。

**AI_Comments:** exa-AMD的创新之处在于其通过Parsl库实现了AI辅助材料发现工作流的高度可扩展性和灵活性，这对于在不同计算环境下部署和加速材料研究至关重要。它解决了在多变计算资源上重新实现工作流的痛点。

<details>
  <summary>Details</summary>

**Motivation:** 旨在加速功能材料的发现与设计。

**Method:** exa-AMD是一个基于Python的应用，通过整合AI/ML工具、材料数据库和量子力学计算来创建可扩展、高性能的工作流。其执行模型依赖于Parsl，一个任务并行编程库，使得工作流逻辑与执行配置解耦，从而能在各种计算资源上灵活扩展。

**Result:** exa-AMD能够实现工作流在从笔记本到超级计算机的任何计算资源上的灵活执行和扩展，无需为每个系统重新实现工作流。

**Conclusion:** exa-AMD通过其可扩展的工作流和对Parsl的利用，显著简化并加速了AI辅助的材料发现与设计过程。

> **ai_Abstract:** exa-AMD是一个Python应用程序，旨在通过整合AI/ML工具、材料数据库和量子力学计算来加速功能材料的发现与设计。它利用Parsl任务并行库，实现了工作流逻辑与执行配置的分离，从而使研究人员能够在各种计算资源上轻松扩展其工作流，无需重复开发。

> **摘要翻译:** exa-AMD是一个基于Python的应用程序，旨在通过将AI/ML工具、材料数据库和量子力学计算集成到可扩展、高性能的工作流中，来加速功能材料的发现和设计。exa-AMD的执行模型依赖于Parsl，这是一个任务并行编程库，它能够使任务在从笔记本电脑到超级计算机的任何计算资源上灵活执行。通过使用Parsl，exa-AMD能够将工作流逻辑与执行配置解耦，从而使研究人员能够在不为每个系统重新实现工作流的情况下扩展其工作流。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [211] [Efficient and Reuseable Cloud Configuration Search Using Discovery Spaces](https://arxiv.org/abs/2506.21467)
> *使用发现空间进行高效可重用云配置搜索*

*Michael Johnston, Burkhard Ringlein, Christoph Hagleitner, Alessandro Pomponio, Vassilis Vassiliadis, Christian Pinto, Srikumar Venugopal* | **Category: cs.DC, C.4**

**Keywords:** 云配置, 优化, 发现空间, 知识重用, 搜索空间

**Comment:** 

> **TL;DR:** 本文提出了“发现空间”抽象，旨在形式化和高效解决复杂的云配置问题，通过实现数据共享和知识重用，将配置搜索速度提高90%以上。

**AI_Comments:** 该论文的创新之处在于通过“发现空间”的形式化方法来解决云配置问题，并明确地实现了搜索执行过程中的知识重用和数据共享。这通过显著减少冗余计算并加速最优配置的发现，解决了现代云部署复杂性和规模带来的关键挑战。所展示的显著加速效果充分证明了其在实际应用中的巨大价值。

<details>
  <summary>Details</summary>

**Motivation:** 寻找以最低成本部署给定工作负载并满足服务水平协议的最佳云资源集是当前活跃的研究领域。由于云提供商和应用程序参数的结合导致配置空间庞大，包含数百万种部署选项，因此找到最优配置极具挑战性。

**Method:** 本文提出了“发现空间”（Discovery Space），这是一种抽象，用于形式化工作负载配置问题的描述，并具备对大型搜索空间进行结构化、健壮和分布式调查所需的特性。文中描述了其具体实现，并证明其可推广到大型语言模型推理和大数据分析等多种工作负载。

**Result:** 该方法能够实现在最佳优化器执行之间安全、透明地共享数据，从而提高了大型搜索空间中最佳配置检测的效率。此外，“发现空间”还实现了在类似搜索空间之间知识的转移和重用，使配置搜索速度提升了90%以上。

**Conclusion:** “发现空间”提供了一个高效且可重用的云配置搜索框架，通过实现数据和知识共享，显著提高了优化效率和搜索速度。

> **ai_Abstract:** 本文引入了“发现空间”（Discovery Space），这是一种抽象，旨在形式化并高效解决复杂的云配置问题。面对数百万种潜在部署选项，该方法能够对大型搜索空间进行结构化探索，促进优化器之间安全的数据共享，并推动类似配置之间的知识重用。所提出的方法可推广到大型语言模型推理和大数据分析等多种工作负载，通过利用知识转移，将配置搜索速度提升了90%以上。

> **摘要翻译:** 寻找以最低成本部署给定工作负载并满足既定服务水平协议的最佳云资源集是一个活跃的研究领域。将云提供商提供的大量计算、存储和服务中的数十个参数与类似数量的特定于应用程序的参数相结合，导致配置空间具有数百万种部署选项。
在本文中，我们提出了“发现空间”（Discovery Space），这是一种抽象，它形式化了工作负载配置问题的描述，并展示了对大型搜索空间进行结构化、健壮和分布式调查所需的一组特性。我们描述了“发现空间”抽象的一个具体实现，并表明它可推广到各种工作负载，例如大型语言模型推理和大数据分析。
我们证明了我们的方法能够在最佳优化器执行之间安全、透明地共享数据，从而提高大型搜索空间中最佳配置检测的效率。我们还展示了“发现空间”如何实现在类似搜索空间之间知识的转移和重用，使配置搜索速度提高90%以上。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [16] [Our Coding Adventure: Using LLMs to Personalise the Narrative of a Tangible Programming Robot for Preschoolers](https://arxiv.org/abs/2506.20982)
> *我们的编程冒险：使用大型语言模型为学龄前儿童的实体编程机器人定制叙事*

*Martin Ruskov* | **Category: cs.CY, cs.RO, K.3.1**

**Keywords:** 大型语言模型, 个性化叙事, 实体编程机器人, 学龄前教育, 教师辅助

**Comment:** accepted at D-SAIL Workshop - Transformative Curriculum Design:
  Digitalization, Sustainability, and AI Literacy for 21st Century Learning

> **TL;DR:** 该研究提出了一种使用大型语言模型为学龄前儿童的实体编程机器人Cubetto生成个性化故事的方法，旨在帮助教师创建定制化教学内容，同时避免儿童直接接触LLM。

**AI_Comments:** 该论文的创新点在于提出了一个间接使用LLMs的教育框架，旨在为学龄前儿童提供个性化学习体验，同时规避了LLMs直接暴露给低龄儿童的潜在风险。其重要性体现在为实体编程教育引入了定制化叙事，有助于提升学习兴趣和效率。然而，研究也明确指出了LLMs在生成内容时的一致性和幻觉问题，这表明在实际应用中仍需教师进行干预和修正，是未来研究需要克服的限制。

<details>
  <summary>Details</summary>

**Motivation:** 在教育领域平衡使用大型语言模型（LLMs）面临挑战，尤其对于理解技术能力有限且易受影响的年幼儿童，他们还面临过度屏幕时间的问题。本研究旨在探索如何利用LLMs的能力，同时规避这些风险，特别是为学龄前儿童的实体编程机器人提供个性化叙事。

**Method:** 研究团队采用行动研究方法，开发了一种早期形式化的流程，用于为实体编程机器人Cubetto快速原型设计游戏故事。他们利用LLMs生成个性化故事，并使用开放权重模型确保结果可复现。该方法是模型无关的，通过测试5种不同的LLMs进行了验证。研究记录了过程、材料、提示以及学习经验和成果，并测试了模型在4种不同任务场景下的表现。

**Result:** 研究发现，LLMs生成的故事成功达到了作为教师辅助工具的预期目的。然而，在测试中也遇到了内容一致性和幻觉问题，研究记录了相应的评估过程以及克服这些问题的尝试（部分成功）。重要的是，该过程不直接让儿童接触LLMs，而是帮助教师轻松开发基于儿童偏好主题的个性化叙事。

**Conclusion:** 研究人员认为他们的方法适用于学龄前课堂，并计划在真实的教育环境中进行进一步的实验。该方法通过间接使用LLMs，成功地为学龄前儿童的实体编程机器人提供了个性化叙事支持，同时解决了直接接触LLMs的潜在风险。

> **ai_Abstract:** 本研究提出了一种利用大型语言模型（LLMs）为学龄前儿童的实体编程机器人Cubetto生成个性化教学叙事的方法。旨在解决LLMs在儿童教育中应用面临的风险和屏幕时间问题。通过行动研究和多模型测试，该方法帮助教师快速创建定制化故事，虽然遇到了一致性和幻觉问题，但仍被视为有效的教师辅助工具，且避免了儿童直接接触LLMs。研究认为此方法适用于学龄前教育，并计划进行实地验证。

> **摘要翻译:** 在教育领域平衡使用大型语言模型（LLMs）是一个挑战，因为存在对技术理解不足和受众易受影响的固有风险。对于年幼儿童来说尤其如此，他们已知在普遍的屏幕时间方面存在困难。我们与名为Cubetto的实体编程机器人合作，提出了一种方法，通过在个性化故事准备中使用LLMs来利用其能力，这对于学龄前儿童适应指挥机器人的实践是必要的。我们进行行动研究，开发了一个早期形式化的流程，用于快速原型设计Cubetto的游戏故事。我们的方法既有可复现的结果，因为它使用了开放权重模型，又是模型无关的，因为我们用5种不同的LLMs进行了测试。我们一方面记录了过程、使用的材料和提示，另一方面记录了学习经验和成果。我们认为生成对于将结果用作教师辅助工具的预期目的是成功的。在4种不同任务场景下测试模型时，我们遇到了内容一致性和幻觉问题，并记录了相应的评估过程和克服这些问题的尝试（有些成功，有些不成功）。重要的是，这个过程不会让儿童直接接触LLMs。相反，这项技术用于帮助教师轻松开发关于儿童偏好主题的个性化叙事。我们相信我们的方法适用于学龄前课堂，我们计划在真实的教育环境中进一步实验。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [224] [When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact](https://arxiv.org/abs/2506.20442)
> *当服务器遇到物种：计算对生物多样性影响的全生命周期视角*

*Tianyao Shi, Ritbik Kumar, Inez Hua, Yi Ding* | **Category: cs.CY, cs.AR, cs.DC**

**Keywords:** 生物多样性影响, 可持续计算, 全生命周期分析, EBI, OBI, FABRIC

**Comment:** Accepted by HotCarbon' 25

> **TL;DR:** 本文首次对计算系统对生物多样性的影响进行了端到端分析，提出了新的衡量指标和建模框架FABRIC，强调在可持续计算设计中需将生物多样性与碳和水一同考虑。

**AI_Comments:** 本文的创新之处在于首次将生物多样性与计算领域联系起来，并提出了具体的量化指标（EBI和OBI）和建模框架（FABRIC），填补了该领域的一个重要空白。这对于推动更全面的可持续计算具有重要意义，促使行业在关注碳足迹和水资源消耗的同时，也考虑其对生物多样性的影响。

<details>
  <summary>Details</summary>

**Motivation:** 生物多样性丧失是一个关键的地球边界问题，但其与计算领域之间的联系却在很大程度上未被研究。先前的计算可持续性努力主要关注碳和水，由于缺乏合适的衡量标准和建模框架，生物多样性一直被忽视。

**Method:** 本文提出了首次端到端分析计算系统对生物多样性影响的方法。引入了两个新的指标——具身生物多样性指数（Embodied Biodiversity Index, EBI）和运行生物多样性指数（Operational Biodiversity Index, OBI），以量化生命周期内的生物多样性影响。同时，提出了一个名为FABRIC的建模框架，将计算工作负载与生物多样性影响联系起来。

**Result:** 评估结果强调，在可持续计算设计和优化中，需要将生物多样性与碳和水一同考虑。

**Conclusion:** 本研究首次全面分析了计算系统对生物多样性的影响，并提出了量化和建模工具，得出结论认为生物多样性应被纳入可持续计算的设计和优化考量中，与碳和水同等重要。

> **ai_Abstract:** 本文首次全面探讨了计算系统对生物多样性的影响，指出以往的可持续计算研究忽视了这一方面。为填补空白，研究引入了具身生物多样性指数（EBI）和运行生物多样性指数（OBI）两个新指标，并开发了FABRIC建模框架，用于量化和关联计算活动与生物多样性影响。研究结果强调了在可持续计算设计中，将生物多样性与碳和水同等考虑的必要性。

> **摘要翻译:** 生物多样性丧失是一个关键的地球边界问题，但其与计算领域之间的联系却在很大程度上未被研究。先前的计算可持续性努力主要关注碳和水，由于缺乏合适的衡量标准和建模框架，生物多样性一直被忽视。本文首次对计算系统对生物多样性的影响进行了端到端分析。我们引入了两个新的指标——具身生物多样性指数（EBI）和运行生物多样性指数（OBI）——以量化生命周期内的生物多样性影响，并提出了FABRIC，一个将计算工作负载与生物多样性影响联系起来的建模框架。我们的评估强调，在可持续计算设计和优化中，需要将生物多样性与碳和水一同考虑。代码可在https://github.com/TianyaoShi/FABRIC获取。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [14] [A generalised framework for phase field-based modelling of coupled problems: application to thermo-mechanical fracture, hydraulic fracture, hydrogen embrittlement and corrosion](https://arxiv.org/abs/2506.20763)
> *耦合问题相场建模的通用框架：在热机械断裂、水力压裂、氢脆和腐蚀中的应用*

*Y. Navidtehrani, C. Betegón, E. Martínez-Pañeda* | **Category: cs.CE, cs.NA, math.NA, physics.app-ph**

**Keywords:** 相场建模, 耦合问题, 有限元, 结构完整性, 多物理场

**Comment:** 

> **TL;DR:** 本文提出了一个结合相场和多物理场建模的通用框架，用于处理耦合结构完整性问题，并演示了其在商用有限元软件中的实现，成功应用于热机械断裂、水力压裂、氢辅助开裂和金属腐蚀等问题，结果与实验数据和现有解决方案高度吻合。

**AI_Comments:** 本文的创新点在于提出了一个高度通用且易于在商用有限元软件中实现的耦合问题相场建模框架。通过利用热传递方程的通用性，并提供具体的UMAT/UMATHT子程序实现，极大地降低了复杂多物理场耦合问题建模的门槛。其对多种实际工程问题的成功应用及其与实验数据的高度吻合，证明了该方法的实用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 解决耦合结构完整性问题，并提供一个通用的、易于在商用有限元软件包中实现的建模方法。

**Method:** 提出了一种结合相场和多物理场建模的通用公式，该方法利用热传递方程的通用性，并通过在有限元软件包Abaqus中实现简单的UMAT和UMATHT子程序来演示其在集成点级别的实现。该框架被应用于热机械断裂、水力压裂、氢辅助开裂和金属腐蚀四种工程和科学相关问题。

**Result:** 所提出的框架在2D和3D问题上的结果显示与实验数据以及现有的数值和解析解具有非常好的一致性。

**Conclusion:** 本文提出了一个通用的理论和计算框架，能够有效地处理各种耦合结构完整性问题，并通过在商用有限元软件包中的实现展示了其广泛的适用性和准确性。

> **ai_Abstract:** 本文提出了一个创新的通用框架，结合相场和多物理场建模来解决复杂的耦合结构完整性问题。该方法基于热传递方程的通用性，易于在Abaqus等商用有限元软件中通过用户子程序实现。研究将此框架成功应用于热机械断裂、水力压裂、氢辅助开裂和金属腐蚀等多种工程问题，并在2D和3D条件下验证了其结果与实验数据及现有解决方案的高度吻合，展示了其广泛的适用性和准确性。

> **摘要翻译:** 我们提出了一种新颖的通用公式，通过结合相场和多物理场建模来处理耦合结构完整性问题。该方法利用了热传递方程的通用性，因此非常适合在商用有限元软件包中采用，仅需要集成点级别的实现。通过在有限元软件包Abaqus中通过简单的UMAT和UMATHT子程序实现耦合多变量现象，本文展示了这一点。所提出的通用理论和计算框架被具体应用于四个具有工程和科学相关性的问题：热机械断裂、水力压裂、氢辅助开裂和金属腐蚀。考虑了2D和3D问题。结果显示与实验数据以及现有的数值和解析解具有非常好的一致性。开发的用户子程序可在https://mechmat.web.ox.ac.uk/codes免费获取。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [39] [A Hereditary Integral, Transient Network Approach to Modeling Permanent Set and Viscoelastic Response in Polymers](https://arxiv.org/abs/2506.20773)
> *聚合物永久变形和粘弹性响应的遗传积分瞬态网络建模方法*

*Stephen T. Castonguay, Joshua B. Fernandes, Michael A. Puso, Sylvie Aubry* | **Category: cs.CE**

**Keywords:** 聚合物, 粘弹性, 永久变形, 瞬态网络理论, 遗传积分

**Comment:** 

> **TL;DR:** 本文提出了一种高效的数值框架，用于建模聚合物的粘弹性和永久变形。该方法基于瞬态网络理论的遗传积分形式，通过链段的不断解离和重新连接来描述材料行为，并能处理各种复杂的加载历史。

**AI_Comments:** 该论文提出了一种创新的数值框架，通过结合遗传积分和瞬态网络理论，有效地解决了聚合物粘弹性和永久变形的建模挑战。其通过递归关系避免了对整个时间历史的积分，显著提高了计算效率。该方法适用于多种材料模型，并能处理复杂的加载条件，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为聚合物的粘弹性和永久变形提供一个高效的数值建模框架。

**Method:** 该方法基于瞬态网络理论的遗传积分形式。聚合物链属于不同的网络，每个网络具有不同的自然平衡状态。链段不断从旧网络解离并以零应力状态重新连接到新网络。网络的自由能由相对于其形成时的构型变形梯度表示。通过对各种自由能核进行分解，建立了递归关系，从而避免了对整个时间历史进行积分。该技术适用于高度可压缩和近似不可压缩材料，并使用了neo-Hookean、Blatz-Ko、Yeoh和Ogden-Hill等材料模型。

**Result:** 该框架能够处理速率依赖性响应和复杂加载历史下的残余应变。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种基于遗传积分瞬态网络理论的数值框架，用于高效建模聚合物的粘弹性和永久变形。该模型通过描述聚合物链在不同网络间的解离与重连接过程来捕捉材料行为，并利用自由能核分解建立递归关系，避免了对完整时间历史的积分。该方法适用于多种材料模型，并成功展示了其在处理速率依赖性响应和复杂加载历史下残余应变方面的能力。

> **摘要翻译:** 本文提出了一种用于模拟聚合物粘弹性和永久变形的高效数值框架。它基于瞬态网络理论的遗传积分形式，其中聚合物链属于不同的网络，每个网络具有不同的自然平衡状态。链段不断从先前形成的网络中解离，并以零应力状态重新连接到新网络。这些网络的自由能根据相对于网络诞生时的构型变形梯度给出。各种自由能的核分解允许建立递归关系，从而避免了对所有时间历史进行积分。该技术通过使用neo-Hookean、Blatz-Ko、Yeoh和Ogden-Hill材料模型，适用于高度可压缩和近似不可压缩材料。本文提供了多个示例，展示了在复杂加载历史下处理速率依赖性响应和残余应变的能力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [63] [Counterfactual Voting Adjustment for Quality Assessment and Fairer Voting in Online Platforms with Helpfulness Evaluation](https://arxiv.org/abs/2506.21362)
> *反事实投票调整：用于在线平台中基于有用性评估的质量评估和更公平投票*

*Chang Liu, Yixin Wang, Moontae Lee* | **Category: cs.CE**

**Keywords:** 反事实投票调整, 因果推断, 偏差校正, 在线平台, 内容质量

**Comment:** 

> **TL;DR:** 本文提出反事实投票调整（CVA），一个因果框架，用于纠正在线有用性投票中的位置和羊群效应偏差，以实现更公平的内容质量评估和排名，并显示出与用户情感和GPT-4o评估的更好一致性。

**AI_Comments:** 本文的创新之处在于应用因果框架（CVA）来缓解在线投票系统中常见的偏差（位置和羊群效应），这对于公平的内容质量评估至关重要。其重要性体现在它证明了内容排名与用户情感和高级AI评估（GPT-4o）的更好一致性，表明其在增强在线平台效用方面的实际适用性。利用因果推断将真实质量从语境偏差中分离出来是一项重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在线平台中，用户对内容的有用性投票常常受到位置差异和先前投票级联影响的偏差，导致信息质量评估不公平。研究动机是为了促进更有用的信息，并实现对内容质量的更公平评估。

**Method:** 提出了反事实投票调整（CVA），这是一个考虑个体投票所处上下文的因果框架。

**Result:** CVA有效地建模了位置偏差和羊群效应偏差。在初步和半合成实验中，CVA准确恢复了预定义的内容质量。在真实实验中，基于CVA学习到的质量对内容进行重新排名，与用户情感和GPT-4o评估的质量表现出更强的一致性，优于基于汇总投票的系统排名和不含因果推断的模型重新排名。CVA的嵌入还提供了对120个主要StackExchange社区中专家用户群体行为动态的比较性见解。

**Conclusion:** CVA通过有效缓解投票偏差，为在线平台中更公平的质量评估和内容排名提供了一种稳健的方法，从而提高了与实际质量和用户情感的一致性，并提供了对用户行为的洞察。

> **ai_Abstract:** 本文提出了反事实投票调整（CVA），一个旨在解决在线平台中有用性投票中固有偏差（位置偏差和羊群效应偏差）的因果框架。CVA旨在提供更公平的信息质量评估。通过实验，CVA展示了其准确建模偏差和恢复内容质量的能力。当应用于真实世界的内容重新排名时，CVA与用户情感和基于AI的质量评估相比传统方法表现出卓越的一致性。此外，其嵌入还提供了对用户行为动态的洞察。

> **摘要翻译:** 在线平台高效获取高质量信息至关重要。为了推广更有用的信息，用户不仅创建新内容，还会评估现有内容，通常通过有用性投票。尽管汇总投票有助于服务提供商对用户内容进行排名，但这些投票常常因不同位置的可访问性差异和先前投票的级联影响而产生偏差。为了更公平地评估信息质量，我们提出了反事实投票调整（CVA），这是一个考虑个体投票所处上下文的因果框架。通过初步和半合成实验，我们表明CVA有效地建模了位置偏差和羊群效应偏差，准确地恢复了预定义的内容质量。在真实实验中，我们证明基于CVA学习到的质量对内容进行重新排名，与用户情感和GPT-4o评估的质量表现出更强的一致性，优于基于汇总投票的系统排名和不含因果推断的模型重新排名。除了个体质量推断，我们的嵌入还提供了对120个主要StackExchange社区中专家用户群体行为动态的比较性见解。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [17] [Distributed Lyapunov Functions for Nonlinear Networks](https://arxiv.org/abs/2506.20728)
> *非线性网络的分布式李雅普诺夫函数*

*Yiming Wang, Arthur N. Montanari, Adilson E. Motter* | **Category: eess.SY, cond-mat.dis-nn, cs.SY, math.DS**

**Keywords:** 分布式李雅普诺夫函数, 非线性网络, 吸引域, 平方和优化, 局部信息

**Comment:** Codes are available at our GitHub repository
  https://github.com/YimingSci/Distributed-Lya-Func

> **TL;DR:** 本文提出了一种基于局部信息的分布式方法来构建李雅普诺夫函数，以准确近似高维非线性网络中复杂吸引域的体积和形状，有效解决了传统方法在高维系统中的局限性。

**AI_Comments:** 本文的创新之处在于提出了一个分布式框架来构建李雅普诺夫函数，有效解决了高维非线性系统中吸引域表征的复杂性问题。通过利用局部信息和SOS优化，该方法克服了传统方法的局限性，为非线性系统的稳定性分析提供了新的工具。其贡献在于能够准确近似吸引域的形状和体积，对控制理论和复杂系统分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 非线性网络通常是多稳态的，其吸引域（ROAs）形态复杂且难以分析或计算表征。此外，状态空间的高维性使得使用现有最先进的优化方法（如平方和（SOS）编程）自动构建李雅普诺夫函数变得不可能。

**Method:** 本文提出了一种基于局部信息的分布式李雅普诺夫函数构建方法。通过建立一个增广比较引理，该引理刻画了部分李雅普诺夫函数的存在条件并考虑了维度降低的残余效应。基于此理论结果，研究者制定了一个SOS优化问题，迭代地构建这些部分函数，并将它们聚合形成一个复合李雅普诺夫函数。

**Result:** 所构建的复合李雅普诺夫函数能够对吸引域的体积和形状提供准确的凸近似。该方法在van der Pol和Ising振荡器网络上的验证表明，其在刻画具有非凸吸引域的高维系统方面是有效的。

**Conclusion:** 本文成功提出了一种分布式方法，用于构建非线性网络的李雅普诺夫函数，克服了高维状态空间下吸引域表征的挑战，并能准确近似吸引域的体积和形状，为复杂非线性系统的稳定性分析提供了新工具。

> **ai_Abstract:** 本文针对非线性网络中吸引域（ROA）难以表征的问题，提出了一种基于局部信息的分布式李雅普诺夫函数构建方法。该方法通过建立增广比较引理来确定部分李雅普诺夫函数的存在条件，并利用平方和（SOS）优化迭代地构建这些部分函数，最终聚合形成一个复合李雅普诺夫函数。实验结果表明，该复合函数能够准确地凸近似ROA的体积和形状，并在高维非凸ROA系统中展现出有效性。

> **摘要翻译:** 非线性网络通常是多稳态的，表现出共存的稳定状态和相互竞争的吸引域（ROA）。因此，吸引域可能具有复杂的“触手状”形态，难以进行分析或计算表征。此外，状态空间的高维性使得使用最先进的优化方法（如平方和（SOS）编程）自动构建李雅普诺夫函数变得不可能。在本文中，我们提出了一种基于局部信息的分布式方法来构建李雅普诺夫函数。为此，我们建立了一个增广比较引理，它刻画了部分李雅普诺夫函数的存在条件，同时考虑了由相关维度降低引起的残余效应。这些理论结果使我们能够制定一个SOS优化问题，迭代地构建这些部分函数，它们的聚合形成一个复合李雅普诺夫函数。由此产生的复合函数提供了对吸引域的体积和形状的精确凸近似。我们在van der Pol和Ising振荡器网络上验证了我们的方法，证明了其在刻画具有非凸吸引域的高维系统方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [41] [Noise-Tolerant Hybrid Approach for Data-Driven Predictive Control](https://arxiv.org/abs/2506.20780)
> *噪声容忍的混合数据驱动预测控制方法*

*Mahmood Mazare, Hossein Ramezani* | **Category: eess.SY, cs.SY**

**Keywords:** 数据驱动预测控制, 噪声容忍, Hankel矩阵, 奇异值分解, 混合方法

**Comment:** 

> **TL;DR:** 提出一种噪声容忍的数据驱动预测控制框架（NTDPC），利用SVD处理测量噪声，提高预测准确性和效率。

**AI_Comments:** 该论文的创新点在于提出了一个噪声容忍的混合数据驱动预测控制框架，通过集成奇异值分解有效解决了测量噪声对Hankel矩阵的影响，这在混合方法中常被忽视。其重要性在于提升了数据驱动预测控制在实际应用中的鲁棒性和效率，尤其是在存在测量噪声的环境下。引入的灵敏度指标也为实际应用提供了有益的指导。

<details>
  <summary>Details</summary>

**Motivation:** 混合数据驱动预测控制中，测量噪声对Hankel矩阵的影响是一个关键挑战，现有混合方法在轨迹估计过程中常忽视其影响。

**Method:** 提出噪声容忍数据驱动预测控制（NTDPC）框架，该框架通过集成奇异值分解（SVD）在降阶Hankel矩阵中分离系统动力学与噪声。同时引入一个灵敏度指标，以支持在不同噪声水平下的预测范围选择。

**Result:** 仿真结果表明，与现有混合方法相比，NTDPC提高了鲁棒性和效率。它能以更短的数据范围和更低的计算量实现精确预测。

**Conclusion:** 该论文成功开发了一种噪声容忍的混合数据驱动预测控制框架，有效解决了测量噪声问题，提升了控制性能。

> **ai_Abstract:** 本文提出一种噪声容忍的数据驱动预测控制（NTDPC）框架，旨在解决混合数据驱动预测控制中测量噪声对Hankel矩阵的影响问题。该框架通过在降阶Hankel矩阵中应用奇异值分解，有效分离系统动力学与噪声，从而在更短数据范围和更低计算量下实现精确预测。此外，引入了灵敏度指标以辅助不同噪声水平下的预测范围选择。仿真结果验证了NTDPC在鲁棒性和效率上优于现有混合方法。

> **摘要翻译:** 本文重点关注混合数据驱动预测控制中的一个关键挑战：测量噪声对Hankel矩阵的影响。虽然直接和间接方法能够处理噪声，但混合方法在轨迹估计过程中常常忽视其影响。我们提出了一种噪声容忍的数据驱动预测控制（NTDPC）框架，该框架集成了奇异值分解，以在降阶Hankel矩阵中将系统动力学与噪声分离。这使得在更短的数据范围和更低的计算量下实现精确预测成为可能。引入了一个灵敏度指标，以支持在不同噪声水平下的预测范围选择。仿真结果表明，与现有混合方法相比，该方法提高了鲁棒性和效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [65] [DPLib: A Standard Benchmark Library for Distributed Power System Analysis and Optimization](https://arxiv.org/abs/2506.20819)
> *DPLib：一个用于分布式电力系统分析和优化的标准基准库*

*Milad Hasanzadeh, Amin Kargarian* | **Category: eess.SY, cs.SY**

**Keywords:** 分布式电力系统, 基准库, 优化, MATLAB, ADMM

**Comment:** 

> **TL;DR:** DPLib是一个开源的MATLAB基准库，旨在支持分布式电力系统分析和优化研究，填补了该领域缺乏通用、可复现数据库的空白。

**AI_Comments:** DPLib的创新之处在于填补了分布式电力系统研究中缺乏通用、可复现数据基准库的空白。其重要性在于为分布式电力系统分析和优化提供了一个标准化的研究平台，促进了该领域的可复现性和进一步发展。通过提供多区域测试用例和分解工具，它降低了研究门槛，并支持了更复杂的分布式算法开发和验证。

<details>
  <summary>Details</summary>

**Motivation:** 目前，与MATPOWER等集中式工具不同，分布式电力系统研究缺乏通用的、可复现的数据库软件包。分布式和去中心化方法对于现代电力系统日益重要，因为它们提供了可扩展性、隐私保护和对单点故障的弹性。

**Method:** DPLib提供了一个标准电力系统库，包含20多个不同大小的多区域基准测试用例，以及一个基于图的划分工具包，可将任何MATPOWER测试系统分解为多个电气连贯的区域。此外，DPLib还提供了模块化、易于使用的分布式最优潮流（OPF）求解器：一个基于ADMM的DC-OPF求解器和一个基于ADMM的AC-OPF求解器。

**Result:** 数值结果验证了所生成的测试用例。

**Conclusion:** DPLib的创建为可复现的分布式电力系统研究奠定了基础。

> **ai_Abstract:** DPLib是一个开源的MATLAB基准库，旨在解决分布式电力系统分析和优化领域缺乏标准化、可复现数据工具的痛点。它提供了20多个多区域基准测试用例，一个用于系统分解的图划分工具包，以及基于ADMM的分布式最优潮流求解器。通过数值验证，DPLib为可复现的分布式电力系统研究奠定了基础。

> **摘要翻译:** DPLib是一个开源的、基于MATLAB的基准库，旨在支持分布式和去中心化电力系统分析与优化的研究与开发。分布式和去中心化方法提供了可扩展性、隐私保护以及对单点故障的弹性，使其对现代电力系统日益重要。然而，与MATPOWER等集中式工具不同，目前分布式电力系统研究尚缺乏通用、可复现的数据库软件包。DPLib通过提供一个标准电力系统库来填补这一空白，该库包含20多个不同大小的多区域基准测试用例，以及一个基于图的划分工具包，该工具包能够将任何MATPOWER测试系统分解为多个电气连贯的区域。该划分工具包是一个易于使用的MATLAB代码，可生成标准化的.mat和.m文件，并提供区域可视化以便直观理解。我们还提供了模块化、易于使用的分布式最优潮流（OPF）求解器：一个在YALMIP中实现的基于交替方向乘子法（ADMM）的DC-OPF求解器，以及一个利用IPOPT的基于ADMM的AC-OPF求解器。这些求解器验证了所生成的测试系统适用于分布式优化应用。数值结果验证了所生成的测试用例，从而确立了DPLib作为可复现分布式电力系统研究的基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [90] [Resilience Through Escalation: A Graph-Based PACE Architecture for Satellite Threat Response](https://arxiv.org/abs/2506.20882)
> *通过升级实现韧性：一种用于卫星威胁响应的基于图的PACE架构*

*Anouar Boumeftah, Sarah McKenzie-Picot, Peter Klimas, Gunes Karabulut Kurt* | **Category: eess.SY, cs.SY**

**Keywords:** 卫星系统, 韧性, PACE架构, 威胁响应, 后备机制

**Comment:** 

> **TL;DR:** 本文提出了一种基于PACE方法（源于军事战术通信）的韧性设计框架，用于增强卫星系统应对动态多向量威胁的韧性。通过分层状态转换模型和威胁评分框架，并引入动态韧性指数，评估了静态、自适应和基于softmax的PACE变体在不同中断场景下的表现，证明了轻量级、决策感知的后备机制能有效提高下一代空间资产的生存能力和运行连续性。

**AI_Comments:** 本文将源自军事战术通信的PACE方法论创造性地应用于卫星系统韧性设计，并结合威胁评分框架和动态韧性指数进行量化评估，提供了一种新颖的、系统性的方法来应对复杂的空间威胁。其创新点在于将成熟的军事策略与空间系统需求相结合，并通过多模型评估验证了轻量级后备机制的有效性，对于提升未来空间资产的生存能力和操作连续性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 卫星系统日益面临来自干扰、网络攻击和电磁中断的操作风险。传统的冗余策略在应对动态、多向量威胁时往往失效。

**Method:** 本文引入了一种基于PACE（Primary, Alternate, Contingency, Emergency）方法论的韧性设计框架，并将其应用于卫星系统。该框架通过分层状态转换模型，并结合CVSS、DREAD和NASA风险矩阵等威胁评分框架来指导。研究定义了一个动态韧性指数来量化系统适应性，并实现了三种PACE变体：静态、自适应和基于softmax的决策模型，以评估在不同中断场景下的韧性。

**Result:** 该方法突出了轻量级、决策感知的后备机制在提高下一代空间资产的生存能力和运行连续性方面的有效性。

**Conclusion:** 轻量级、决策感知的后备机制能有效提高下一代空间资产的生存能力和运行连续性，从而增强卫星系统应对动态多向量威胁的韧性。

> **ai_Abstract:** 本文提出了一种基于PACE（Primary, Alternate, Contingency, Emergency）方法论的韧性设计框架，旨在解决卫星系统在面对动态、多向量威胁时传统冗余策略失效的问题。该框架通过分层状态转换模型并结合威胁评分框架，为卫星系统提供韧性保障。研究定义了动态韧性指数，并评估了静态、自适应和基于softmax的PACE决策模型在不同中断场景下的表现，结果表明轻量级、决策感知的后备机制能有效提升下一代空间资产的生存能力和运行连续性。

> **摘要翻译:** 卫星系统日益面临来自干扰、网络攻击和电磁中断的操作风险。传统的冗余策略在应对动态、多向量威胁时往往失效。本文引入了一种基于PACE（Primary, Alternate, Contingency, Emergency）方法论的韧性设计框架，该方法最初是为军事行动中的战术通信开发的，通过受威胁评分框架（如CVSS、DREAD和NASA风险矩阵）启发的分层状态转换模型，将其应用于卫星系统。我们定义了一个动态韧性指数来量化系统适应性，并实现了三种PACE变体：静态、自适应和基于softmax的决策模型，以评估在不同中断场景下的韧性。所提出的方法突出了轻量级、决策感知的后备机制在提高下一代空间资产的生存能力和运行连续性方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [113] [Optimal Parameter Design for Power Electronic Converters Using a Probabilistic Learning-Based Stochastic Surrogate Model](https://arxiv.org/abs/2506.20987)
> *基于概率学习随机代理模型的电力电子变换器最佳参数设计*

*Akash Mahajan, Shivam Chaturvedi, Srijita Das, Wencong Su, Van-Hai Bui* | **Category: eess.SY, cs.SY**

**Keywords:** 电力电子变换器, 参数设计, 概率学习, 随机代理模型, 启发式优化

**Comment:** 

> **TL;DR:** 本文提出了一种基于概率学习的随机代理建模框架，用于电力电子变换器的最佳参数设计，以平衡效率和热约束，并显著缩短设计时间。

**AI_Comments:** 该论文的创新之处在于结合了概率学习和随机代理建模，以解决电力电子变换器参数设计的复杂性。通过引入神经网络分类器进行可行性过滤和概率预测模型量化不确定性，提高了设计的效率和鲁棒性。与传统优化算法的比较也验证了其优越性，为工业应用提供了有价值的工具。

<details>
  <summary>Details</summary>

**Motivation:** 电力电子变换器参数的最佳设计需要在效率和热约束之间取得平衡，以确保高性能和安全性。此外，传统设计过程耗时较长，需要显著缩短设计时间。

**Method:** 本文引入了一种基于概率学习的随机代理建模框架。首先，使用神经网络分类器评估参数配置的可行性，过滤不安全/不切实际的输入。其次，概率预测模型估计变换器的效率和温度，并量化预测不确定性。最后，采用基于启发式优化的模型来优化多目标函数，以在满足热约束的同时最大化效率，并加入惩罚项以避免不切实际的解决方案。该方法与遗传算法（GA）、粒子群优化（PSO）、模拟退火（SA）、禁忌搜索（TS）和随机爬山（SHC）等多种已知搜索算法进行了比较。

**Result:** 结果表明，该方法在预测精度和优化结果方面均有显著改进。

**Conclusion:** 该框架为推进电力电子设计提供了一个鲁棒的解决方案。

> **ai_Abstract:** 本文提出了一种基于概率学习的随机代理建模框架，用于电力电子变换器的最佳参数设计。该框架通过神经网络分类器筛选可行参数，接着利用概率预测模型估计效率和温度并量化不确定性，最后通过启发式优化模型在满足热约束下最大化效率。该方法显著缩短了设计时间，并在预测精度和优化结果上优于多种现有优化算法，为电力电子设计提供了一个鲁棒且高效的解决方案。

> **摘要翻译:** 电力电子变换器参数的最佳设计涉及平衡效率和热约束，以确保高性能而不损害安全性。本文介绍了一种基于概率学习的随机代理建模框架，以解决这一挑战并显著减少设计阶段所需的时间。该方法首先通过一个神经网络分类器评估参数配置的可行性，有效过滤掉不安全和/或不切实际的输入。随后，一个概率预测模型估计变换器的效率和温度，同时量化预测不确定性，提供性能洞察和可靠性指标。最后，采用基于启发式优化的模型来优化一个多目标函数，该函数在遵守热约束的同时最大化效率。优化过程结合了惩罚项，以阻止违反实际阈值的解决方案，确保可操作和实际的建议。使用先进的启发式优化方法寻找最优解，并与几种知名搜索算法进行比较，包括遗传算法（GA）、粒子群优化（PSO）、模拟退火（SA）、禁忌搜索（TS）和随机爬山（SHC）。结果表明，在预测精度和优化结果方面有显著改进，为推进电力电子设计提供了鲁棒的解决方案。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [133] [Coordinated Control of Autonomous Vehicles for Traffic Density Reduction at a Signalized Junction: An MPC Approach](https://arxiv.org/abs/2506.21302)
> *信号交叉口交通密度降低的自动驾驶车辆协同控制：一种MPC方法*

*Rudra Sen, Subashish Datta* | **Category: eess.SY, cs.SY**

**Keywords:** 联网自动驾驶车辆, 模型预测控制, 交通密度降低, 信号交叉口, 协作车道变换

**Comment:** 

> **TL;DR:** 本文提出了一种双模模型预测控制（MPC）架构，用于联网自动驾驶车辆（CAVs）在信号交叉口降低交通密度并实现协作车道变换，并通过数值模拟验证了其有效性。

**AI_Comments:** 本文的创新之处在于提出了一种专门针对信号交叉口联网自动驾驶车辆的双模MPC架构，同时解决了交通密度降低和协作车道变换的问题。通过整合在线计算的最大控制不变终端集来确保递归可行性和收敛性，增加了方案的鲁棒性。其重要性在于利用CAVs的能力来实现更智能的城市交通管理。

<details>
  <summary>Details</summary>

**Motivation:** 由于城市交通系统的快速发展，有效和安全地管理交通是一个关键问题。联网自动驾驶车辆（CAVs）为增强交通流和协调提供了新的机会。本工作的目标是通过促进CAVs的响应式决策，从而提高城市出行的效率和安全性，特别是在信号交叉口交通密度和高密度交通条件下的协作车道变换问题。

**Method:** 本文提出了一种双模模型预测控制（MPC）架构，用于解决信号交叉口交通密度缓解和高密度交通条件下的无缝协作车道变换问题。通过整合在线计算的最大控制不变终端集，确保了所提出MPC方案的递归可行性和收敛性。

**Result:** 所提出方法的有效性通过数值模拟得到了验证。

**Conclusion:** 本文提出的双模MPC方案通过缓解信号交叉口的交通密度和促进协作车道变换，有效提升了城市出行的效率和安全性，并经数值模拟验证。

> **ai_Abstract:** 本文提出了一种针对联网自动驾驶车辆（CAVs）的双模模型预测控制（MPC）架构，旨在解决信号交叉口的交通密度缓解问题，并促进高密度交通条件下的无缝协作车道变换。该方法通过促进CAVs的响应式决策，从而提高城市出行的效率和安全性。为确保方案的递归可行性和收敛性，集成了在线计算的最大控制不变终端集。所提出的方法已通过数值模拟验证其有效性。

> **摘要翻译:** 由于城市交通系统的快速发展，有效和安全地管理交通是一个关键问题。联网自动驾驶车辆（CAVs）具备相互连接和与相邻基础设施连接的能力，为增强交通流和协调提供了新的机会。这项工作提出了一种双模模型预测控制（MPC）架构，解决了两个相互关联的问题：减轻信号交叉口的交通密度和在高密度交通条件下促进无缝、协作的车道变换。这项工作的目标是促进CAVs的响应式决策，从而提高城市出行的效率和安全性。此外，我们通过整合在线计算的最大控制不变终端集，确保了所提出的MPC方案的递归可行性和收敛性。最后，通过数值模拟验证了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [150] [Estimating Technical Loss without Power Flows: A Practical, Data-Driven Approach for Loss Estimation in Distribution Grids](https://arxiv.org/abs/2506.21311)
> *无需潮流计算的技术损耗估算：一种针对配电网损耗估算的实用数据驱动方法*

*Mohini Bariya, Genevieve Flaspohler* | **Category: eess.SY, cs.SY**

**Keywords:** 技术损耗, 配电网, 数据驱动, 电压测量, 低收入和中等收入国家

**Comment:** 6 pages, 3 figures

> **TL;DR:** 发展中国家电网技术损耗高且缺乏测量数据，本文提出一种无需潮流计算，仅利用稀疏电压测量数据估算技术损耗的新方法，为LMIC电网的损耗估算和定位提供了关键工具。

**AI_Comments:** 该论文提出了一种创新且实用的方法，解决了低收入和中等收入国家（LMICs）电网在技术损耗估算方面的数据限制问题。其核心创新在于无需传统的潮流计算，转而利用更易获得的稀疏电压幅值测量数据。这对于基础设施薄弱、缺乏先进传感设备的LMIC电网具有重要意义，能够有效支持其减损干预措施的设计与实施，从而提升电网效率和韧性。然而，抽象中未详细说明所采用的具体数据驱动模型或其对测量数据稀疏性的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 全球低收入和中等收入国家（LMICs）的电网面临着巨大的技术损耗挑战，其损耗率远高于高收入国家。现有技术损耗估算方法依赖于昂贵且在LMIC电网中普遍缺乏的潮流传感数据，这阻碍了有效的损耗干预措施。因此，迫切需要一种无需潮流计算的实用损耗估算方法。

**Method:** 本文提出了一种新颖的技术损耗估算方法，该方法无需进行潮流计算。它利用电网中稀疏位置更容易获得的电压幅值测量数据来进行损耗估算和定位。

**Result:** 该估算器使全球低收入和中等收入国家电网的技术损耗估算和定位成为可能，并为损耗降低干预措施的有效设计、实施和评估提供了关键工具。

**Conclusion:** 该研究提供了一种无需昂贵潮流传感数据即可估算和定位配电网技术损耗的实用方法，特别适用于低收入和中等收入国家电网。这为加强这些电网的物理和经济实力，以及有效实施减损措施提供了关键支持。

> **ai_Abstract:** 本文关注低收入和中等收入国家（LMICs）电网面临的严重技术损耗问题，这些电网因基础设施薄弱而导致损耗远高于发达国家。针对现有损耗估算方法依赖昂贵且稀缺的潮流测量数据，该研究提出了一种创新方法。新方法无需潮流计算，而是利用电网中稀疏位置更容易获得的电压幅值测量数据来估算和定位技术损耗。该方法旨在为全球LMIC电网提供一个实用工具，以有效设计、实施和评估减损干预措施，从而增强电网的物理和经济韧性。

> **摘要翻译:** 全球低收入和中等收入国家（LMICs）的电网面临着严峻的挑战。为了支持全球脱碳努力并将数百万人从能源贫困中解救出来，这些电网必须在整合分布式可再生能源的同时承担巨大的负荷增长。然而，数十年来快速且资金不足的基础设施扩张，导致许多LMICs的国家电网紧张而脆弱，由老化、故障和规模不足的基础设施组成。这种脆弱性的一个原因和表现就是能源输送过程中电网基础设施内部，尤其是在配电层面的过度技术损耗；与高收入国家5%的基线相比，这些电网的损耗通常估计远超20%。通过有针对性的干预措施解决技术损耗对于增强电网的物理和经济实力至关重要。不幸的是，目前估算和定位技术损耗的方法需要昂贵、广泛的潮流传感，而这在LMIC配电系统中基本不存在。我们提出了一种无需潮流计算的技术损耗估算新方法，该方法利用电网中稀疏位置更容易获得的电压幅值测量数据。这种估算器使全球LMIC电网的损耗估算和定位成为可能，并为损耗降低干预措施的有效设计、实施和评估提供了关键工具。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [170] [Joint Scheduling of DER under Demand Charges: Structure and Approximation](https://arxiv.org/abs/2506.21510)
> *需求费用下分布式能源的联合调度：结构与近似*

*Ruixiao Yang, Gulai Shen, Ahmed S. Alahmed, Chuchu Fan* | **Category: eess.SY, cs.SY**

**Keywords:** 分布式能源调度, 需求费用, 随机动态规划, 近似算法, 电池储能

**Comment:** 15 pages, 4 tables, 4 figures

> **TL;DR:** 本文研究了在需求费用下对分布式能源（DERs）进行联合调度的问题，提出了一个基于阈值的最优控制策略，并针对其高计算复杂性开发了一种高效的近似算法，通过模拟验证了该算法的优越性。

**AI_Comments:** 本文创新性地解决了在需求费用下分布式能源联合调度的计算复杂性问题，通过提出一种高效的近似算法，使其在实际应用中更具可行性。其对最优控制策略结构的分析也具有重要的理论价值。该方法在模拟中表现出色，为未来的能源管理提供了有益的参考。

<details>
  <summary>Details</summary>

**Motivation:** 在具有需求费用的净计量框架下，对包括灵活负荷、可再生能源发电和电池储能系统在内的电表后分布式能源进行联合调度，以最大化预期运营盈余，同时考虑到可再生能源发电的不确定性。由于储能和需求费用约束的强时间耦合，导致最优控制策略的计算复杂度很高，需要克服这一挑战。

**Method:** 将问题表述为随机动态规划，旨在最大化预期运营盈余。分析性地描述了最优控制策略的结构，表明其具有基于阈值的形式。为解决高计算复杂性，提出了一种高效的近似算法，该算法在轻微放宽的问题下搜索峰值需求，并展示其计算复杂度与调度周期呈线性关系。

**Result:** 提出的近似算法的计算复杂度与调度周期呈线性关系。通过使用两个开源数据集进行的广泛模拟，验证了该算法的有效性，并显示其在不同的储能和费率参数下，相比于理论上限，能够实现相对较小的解决方案差距，性能优于包括强化学习在内的多种基准DER控制策略。

**Conclusion:** 论文成功地提出了一个高效的近似算法来解决需求费用下分布式能源的联合调度问题，克服了最优控制策略因强时间耦合导致的高计算复杂性，并在广泛模拟中证明了其在性能上优于现有基准方法。

> **ai_Abstract:** 本文研究了在需求费用下，包括灵活负荷、可再生能源和电池储能系统在内的分布式能源的联合调度问题。通过将其建模为随机动态规划，作者分析了最优控制策略的阈值结构。鉴于该策略因强时间耦合导致的高计算复杂性，论文提出了一种高效的近似算法，该算法在轻微放宽的问题下搜索峰值需求，并展示了其计算复杂度与调度周期呈线性关系。通过广泛的模拟，该算法在性能上超越了多种现有策略，并实现了接近理论最优的解决方案。

> **摘要翻译:** 我们研究了在具有需求费用的净计量框架下，电表后分布式能源（DERs）的联合调度，包括柔性负荷、可再生能源发电和电池储能系统。该问题被表述为一个随机动态规划，旨在最大化预期运营盈余，同时考虑可再生能源发电的不确定性。我们分析性地描述了最优控制策略的结构，并表明它具有基于阈值的形式。然而，由于储能和需求费用约束的强时间耦合，策略中的条件分支数量随调度周期呈组合式增长，因为它需要对未来状态进行展望。为了克服通用公式中的高计算复杂性，提出了一种高效的近似算法，该算法在轻微放宽的问题下搜索峰值需求。我们表明该算法的计算复杂度与调度周期呈线性关系。使用两个开源数据集进行的广泛模拟验证了所提出的算法，并将其性能与不同的DER控制策略（包括基于强化学习的策略）进行了比较。在不同的储能和费率参数下，结果表明，与理论上限相比，所提出的算法在实现相对较小的解决方案差距方面优于各种基准。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [21] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
> *基于幅度测量的DFT码本精确近场波束训练*

*Zijun Wang, Shawn Tsai, Rama Kiran, Rui Zhang* | **Category: eess.SP**

**Keywords:** 近场通信, 波束训练, DFT码本, 幅度测量, 极大规模天线阵列

**Comment:** 

> **TL;DR:** 本文提出了一种低复杂度的近场波束训练方案，利用现有DFT码本，通过分析近场波束模式、提出O(1)复杂度的距离估计方法和基于MLE的精确细化，实现了接近理想CSI的性能。

**AI_Comments:** 该论文的创新点在于其能够将为远场设计的传统DFT码本应用于复杂的近场环境，从而在保持低复杂度的同时实现高精度波束训练。特别是O(1)复杂度的距离估计方法和基于MLE的精确细化，是其显著的技术贡献。这种方法为未来大规模MIMO系统在近场区域的实际部署提供了有前景的解决方案，尤其是在资源受限的应用中。

<details>
  <summary>Details</summary>

**Motivation:** 极大规模天线阵列（ELAAs）在高频段运行促进了近场通信的发展，对波束训练和信号处理设计提出了新挑战。

**Method:** 本文提出了一种低复杂度的近场波束训练方案，充分利用了为远场用户设计的传统离散傅里叶变换（DFT）码本。首先分析了近场接收波束模式，推导了波束宽度和中心增益的闭合表达式。这些分析结果使得能够定义一个与角度相关的修正瑞利距离，有效区分近场和远场用户区域。在此基础上，开发了一种直接且计算高效的用户距离估计方法，复杂度为O(1)，并通过简单的细化提高了精度。为进一步提高估计精度，额外提出了一种基于最大似然估计（MLE）的细化方法，利用信号幅度的莱斯分布，实现了接近克拉默-拉奥下界（CRB）的精度。

**Result:** 仿真结果表明，在单用户和多用户设置中均获得了显著增益，信噪比（SNR）比穷举搜索提高了高达2.38 dB。仿真显示，单用户和多用户可达速率均能接近通过理想信道状态信息（CSI）获得的结果。

**Conclusion:** 所提出的低复杂度近场波束训练方案，通过利用传统DFT码本和先进的距离估计及细化方法，实现了接近理想信道状态信息的性能，显著提高了近场通信的波束训练效率和精度。

> **ai_Abstract:** 该论文提出了一种创新的低复杂度近场波束训练方案，该方案巧妙地利用了为远场设计的传统DFT码本。通过对近场波束模式的深入分析，定义了修正瑞利距离以区分近远场用户。核心贡献在于开发了一种计算效率极高的O(1)复杂度用户距离估计方法，并辅以简单的细化。为追求更高精度，还引入了基于莱斯分布的MLE细化方法，使其性能接近CRB。仿真结果证实了该方案在单用户和多用户场景下的显著性能提升，信噪比增益高达2.38 dB，且可达速率接近理想信道信息水平。

> **摘要翻译:** 极大规模天线阵列（ELAAs）在高频段运行，促进了近场通信的发展，推动了波束训练和信号处理设计的进步。在这项工作中，我们提出了一种低复杂度的近场波束训练方案，该方案充分利用了为远场用户设计的传统离散傅里叶变换（DFT）码本。我们首先分析了近场中的接收波束模式，并推导了波束宽度和中心增益的闭合表达式。这些分析结果使得能够定义一个与角度相关的修正瑞利距离，该距离有效地区分了近场和远场用户区域。在此分析的基础上，我们开发了一种直接且计算高效的用户距离估计方法，其复杂度为O(1)，并通过简单的细化进一步提高了其精度。仿真结果表明，在单用户和多用户设置中均获得了显著增益，信噪比（SNR）比穷举搜索提高了高达2.38 dB。为了进一步提高估计精度，我们额外提出了一种基于最大似然估计（MLE）的细化方法，该方法利用信号幅度的莱斯分布，实现了接近克拉默-拉奥下界（CRB）的精度。仿真显示，单用户和多用户可达速率均能接近通过理想信道状态信息获得的结果。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [45] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
> *基于纠缠的远距离卫星链路量子密钥分发的物理限制*

*Mohammad Taghi Dabiri, Mazen Hasna, Saif Al-Kuwari, Khalid Qaraqe* | **Category: eess.SP**

**Keywords:** 量子密钥分发, 卫星通信, 纠缠, 自由空间光, 物理限制

**Comment:** 

> **TL;DR:** 本文研究了基于纠缠的卫星量子密钥分发(SatQKD)在远距离星间链路中的物理限制，特别是光子损耗、指向误差和背景噪声的影响，并提供了全面的性能分析和设计指导。

**AI_Comments:** 该论文的创新点在于对基于纠缠的星间QKD在实际远距离链路中的物理限制进行了深入的光子级建模和分析，填补了现有文献在处理此类挑战方面的空白。其重要性在于为未来可靠高效的卫星量子通信系统设计提供了关键的理论基础和实践指导，特别是针对光子损耗和指向误差等实际工程问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文献没有解决在远距离星间自由空间光(FSO)信道中实现基于纠缠的QKD协议所面临的关键物理层挑战，特别是由于光束发散、指向误差和背景噪声引起的光子损耗会严重降低密钥生成速率和量子误码率(QBER)。

**Method:** 本文对基于纠缠的星间QKD进行了全面的性能分析，侧重于光子级建模和实际损伤（如光束发散、指向误差和背景噪声）的影响。开发了信号检测概率、背景光子影响、多对发射和QBER的解析表达式，并纳入了链路距离、发射器跟踪抖动、接收器失准和光子对生成速率等关键参数。通过仿真验证了模型。

**Result:** 仿真结果揭示了系统性能对跟踪误差和视场(FoV)限制的非线性敏感性，并突出了在保持QBER低于可接受阈值的同时共同最大化秘密密钥率的最佳参数范围。

**Conclusion:** 所提出的模型为可靠高效部署基于纠缠的卫星量子密钥分发(SatQKD)系统提供了可操作的设计见解。

> **ai_Abstract:** 本文对基于纠缠的星间量子密钥分发(SatQKD)系统在远距离自由空间光(FSO)链路中的性能进行了深入分析，旨在解决现有研究中未充分探讨的物理层挑战，包括光子损耗、指向误差和背景噪声。研究通过建立光子级模型和解析表达式，详细分析了这些实际损伤对密钥生成速率和量子误码率(QBER)的影响。仿真结果揭示了系统性能对跟踪误差和接收器视场的非线性敏感性，并确定了在满足QBER要求下实现最大秘密密钥率的最佳参数配置。该研究为未来基于纠缠的SatQKD系统的设计和可靠部署提供了重要的理论指导。

> **摘要翻译:** 基于纠缠的量子密钥分发（QKD）协议，如E91和BBM92，提供了强大的信息论安全性，并且天然适用于卫星到卫星的QKD（SatQKD）链路。然而，在远距离星间自由空间光（FSO）信道上实现这些协议带来了现有文献中未解决的关键物理层挑战。特别是，由于光束发散、指向误差和背景噪声导致的光子损耗会严重降低密钥生成速率和量子误码率（QBER），尤其是在窄接收器视场（FoV）限制下。本文对基于纠缠的星间QKD进行了全面的性能分析，重点关注光子级建模和实际损伤的影响。我们开发了信号检测概率、背景光子影响、多对发射和QBER的解析表达式，其中包含了链路距离、发射器跟踪抖动、接收器失准和光子对生成速率等关键参数。仿真结果揭示了系统性能对跟踪误差和FoV限制的非线性敏感性，并突出了在保持QBER低于可接受阈值的同时共同最大化秘密密钥率的最佳参数范围。所提出的模型为可靠高效部署基于纠缠的SatQKD系统提供了可操作的设计见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [69] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
> *紧凑型分析模型用于实时评估基于OAM的星间链路*

*Mohammad Taghi Dabiri, Mazen Hasna* | **Category: eess.SP**

**Keywords:** OAM, 星间链路, 分析模型, 指向误差, 实时评估

**Comment:** 

> **TL;DR:** 本文提出了一种紧凑的分析模型，用于快速准确地评估基于OAM的星间链路在指向误差下的性能，并支持实时优化。

**AI_Comments:** 本文的创新之处在于提出了一个紧凑且高效的分析模型，解决了传统蒙特卡洛方法在评估OAM星间链路性能时计算量大的问题。其重要性体现在为动态变化的LEO卫星星座提供了实时性能评估和参数优化的能力，这对于未来高移动性光无线通信系统的设计和部署具有重要意义。通过引入非对称OAM模式集，进一步提升了系统在实际指向误差下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的蒙特卡洛方法计算量大，难以满足动态低地球轨道（LEO）卫星星座中快速变化的拓扑和信道条件对实时链路适应性的需求。

**Method:** 开发了一个精确的分析模型来表征OAM星间链路中由波束失准引起的模间串扰；基于该模型，推导出高效的表达式来分析和优化误码率（BER）方面的系统性能；系统地设计和评估了非对称OAM模式集。

**Result:** 所提出的分析方法提供了准确的性能预测，显著减少了计算时间，同时保持了高精度；非对称OAM模式集在存在指向误差的情况下显著优于对称配置；研究结果揭示了波束发散、跟踪精度和链路距离之间相互作用的关键见解，实现了系统参数的实时高保真优化。

**Conclusion:** 所提出的分析模型能够快速准确地评估和优化基于OAM的星间链路性能，其分析结果通过蒙特卡洛仿真得到严格验证，证实了其在LEO卫星网络等高移动性光无线系统中的实际适用性。

> **ai_Abstract:** 本文提出了一种紧凑高效的分析模型，用于实时评估基于轨道角动量（OAM）的星间链路在指向误差下的性能。该模型通过表征模间串扰并推导误码率表达式，实现了比传统蒙特卡洛方法更快的计算速度和更高的精度。研究还设计并验证了性能更优的非对称OAM模式集，并揭示了影响链路性能的关键参数间的相互作用，为LEO卫星网络等动态光无线系统提供了实时优化能力。

> **摘要翻译:** 本文提出了一种高效的分析框架，用于评估在指向误差下利用轨道角动量（OAM）光束的星间通信系统的性能。首先，开发了一个精确的分析模型来表征基于OAM的星间链路中由光束失准引起的模间串扰。在此模型的基础上，我们推导出了高效的表达式，以误码率（BER）为指标分析和优化系统性能。与计算密集型的传统蒙特卡洛方法不同，所提出的方法提供了准确的性能预测。这使得计算时间大幅减少，同时由于使用了串扰和BER的分析表达式而保持了高精度。这种快速准确的评估能力对于动态低地球轨道（LEO）卫星星座尤其关键，因为在这些星座中，网络拓扑和信道条件变化迅速，需要实时链路适应。此外，我们系统地设计和评估了非对称OAM模式集，这些模式集在存在指向误差的情况下显著优于对称配置。我们的结果还揭示了光束发散、跟踪精度和链路距离之间相互作用的关键见解，表明所提出的框架能够以高保真度实现系统参数的实时优化。分析结果通过广泛的蒙特卡洛仿真进行了严格验证，证实了它们在LEO卫星网络等高移动性光无线系统中的实际适用性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [94] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
> *LoRa直连卫星通信中的多普勒估计与补偿技术*

*Jamil Farhat, Gianni Pasolini, Enrico Paolini, Muhammad Asad Ullah, Richard Demo Souza* | **Category: eess.SP**

**Keywords:** LoRa, 直连卫星通信, 多普勒效应, 多普勒补偿, 低地球轨道

**Comment:** 

> **TL;DR:** 本文提出了四种LoRa直连卫星通信中的多普勒估计与补偿框架，以解决LEO卫星移动性导致的多普勒效应对性能的显著影响，并分析了其性能和权衡。

**AI_Comments:** 该论文解决了LoRa直连卫星通信中的一个关键挑战——多普勒效应，这对于LEO卫星物联网应用至关重要。通过提出并比较多种估计和补偿框架，为实际系统设计提供了有价值的工程指导，特别是关于参数权衡的分析，具有创新性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）卫星的移动性导致的多普勒效应会显著降低LoRa直连卫星（DtS）通信的性能。

**Method:** 提出了四种用于LoRa直连卫星（DtS）连接中多普勒估计和补偿的框架，并将其性能与没有多普勒效应的理想场景进行了数值比较。此外，还通过分析扩频因子和与多普勒效应相关的其他关键参数之间的相互作用，研究了这些框架之间的权衡。

**Result:** 研究结果为如何实现LoRa直连卫星通信的鲁棒配置提供了见解。

**Conclusion:** 所提出的多普勒估计和补偿框架有助于实现LoRa直连卫星通信的鲁棒配置，以应对多普勒效应。

> **ai_Abstract:** 本文针对低地球轨道（LEO）卫星移动性导致的多普勒效应显著降低LoRa直连卫星（DtS）通信性能的问题，提出了四种多普勒估计与补偿框架。研究通过数值比较了这些框架在理想场景下的性能，并分析了扩频因子与其他多普勒相关参数之间的权衡，旨在为实现LoRa DtS通信的鲁棒配置提供指导。

> **摘要翻译:** 在LPWAN框架内，LoRaWAN技术所采用的LoRa调制因其提供低成本、低功耗和长距离通信的能力，作为物联网应用的连接解决方案受到了广泛关注。LoRa的一个新兴用例是直连卫星（DtS）连接，它将覆盖范围扩展到偏远地区以支持物联网操作。卫星物联网行业主要偏爱低地球轨道（LEO），因为它与地球静止轨道相比具有更低的发射成本和更小的路径损耗。然而，LEO卫星的一个主要缺点是其移动性引起的多普勒效应的影响。早期的研究已经证实，多普勒效应会显著降低LoRa DtS的性能。在本文中，我们提出了四种用于LoRa DtS连接中多普勒估计和补偿的框架，并将其性能与没有多普勒效应的理想场景进行了数值比较。此外，我们通过分析扩频因子以及与多普勒效应相关的其他关键参数之间的相互作用，研究了这些框架之间的权衡。结果提供了关于如何实现LoRa DtS连接的鲁棒配置的见解。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [117] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
> *量子加速无线通信：概念、连接和影响*

*Naoki Ishikawa, Giuseppe Thadeu Freitas de Abreu, Petar Popovski, Robert W. Heath Jr* | **Category: eess.SP, quant-ph**

**Keywords:** 量子计算, 无线通信, 跨学科研究, 量子加速, 经典启发式算法

**Comment:** 7 pages, 6 figures

> **TL;DR:** 本文探讨量子计算如何应用于无线通信，揭示量子与经典计算的互补优势，旨在促进跨学科研究。

**AI_Comments:** 这篇论文通过将复杂的量子计算概念以通信领域研究者熟悉的方式进行阐述，有效地降低了跨学科研究的门槛。其创新之处在于不仅探讨了量子加速通信的潜力，更强调了经典与量子计算的互补性，为实际应用提供了更具操作性的视角。这对于推动量子技术在无线通信领域的落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算有望重塑通信系统的算法基础，但如何将其优势转化为实际工程效益仍具挑战性。本文旨在为通信领域研究者阐明量子计算基础及其与无线系统的数学关联，以促进相关研究。

**Method:** 本文通过以通信领域研究者熟悉的方式介绍量子计算基础知识，概述容错量子计算的当前局限性，并揭示量子与无线系统之间的数学和谐。此外，还系统回顾了前沿研究，提炼了量子加速通信系统的设计趋势并总结了经验教训。

**Result:** 关键发现是经典启发式算法可以优化某些量子参数，突显了经典计算和量子计算的互补优势。

**Conclusion:** 本文旨在促进量子信息处理与未来通信系统前沿领域的跨学科研究。

> **ai_Abstract:** 本文探讨了量子计算如何应用于无线通信系统，旨在弥合量子计算与通信领域之间的知识鸿沟。文章介绍了量子计算的基础，分析了容错量子计算的局限性，并揭示了量子与无线系统之间的数学联系。通过系统回顾现有研究，作者提炼出量子加速通信系统的设计趋势和经验教训，并强调了经典启发式算法在优化量子参数方面的互补优势。该研究旨在促进量子信息处理与未来通信系统领域的跨学科合作。

> **摘要翻译:** 量子计算有望重新定义通信系统的算法基础。虽然量子叠加和纠缠能为特定问题带来二次方或指数级的加速，但识别这些优势能够产生工程效益的用例仍然并非易事。本文以通信领域熟悉的方式介绍了量子计算的基础知识，概述了容错量子计算的当前局限性，并揭示了量子与无线系统之间的数学和谐，这使得该主题对无线研究人员更具吸引力。基于对开创性和最先进研究的系统回顾，我们提炼出量子加速通信系统研究与开发的常见设计趋势，并强调了所汲取的经验教训。关键的洞察是经典启发式算法可以优化某些量子参数，突显了经典和量子计算的互补优势。本文旨在催化量子信息处理和未来通信系统前沿领域的跨学科研究。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [137] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
> *低空无线网络中感知、通信与控制的协同设计*

*Haijia Jin, Jun Wu, Weijie Yuan, Fan Liu, Yuanhao Cui* | **Category: eess.SP**

**Keywords:** 无人机, 低空无线网络, 感知-通信-控制协同设计, 有限块长传输, 非凸优化

**Comment:** 

> **TL;DR:** 本文研究了多无人机合作系统中集成感知、通信和控制的协同设计，旨在实现稳定的机器人控制和未知目标定位，并提出了一种基于交替优化和凸差分规划的非凸问题求解方法。

**AI_Comments:** 本文的创新点在于将感知、通信和控制进行协同设计，以解决低空无线网络中多无人机合作系统的复杂问题，尤其是在有限块长传输的约束下。通过将LQR成本和FIM行列式结合进行优化，并巧妙地利用交替优化、DC规划和PGD方法来处理非凸问题，提供了一个实用的解决方案。这项工作对于未来6G环境下的无人机应用，如机器人控制和目标定位，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 物联网服务和6G技术的快速发展使得无人机成为低空无线网络（LAWNs）的关键使能者。本研究旨在解决多无人机合作系统中，如何在有限块长传输条件下，协同设计感知、通信和控制（SC²），以确保机器人控制稳定并同时定位未知感知目标。

**Method:** 研究首先将控制和定位性能（分别用LQR成本和FIM行列式衡量）联合考虑，建立了一个加权优化问题，该问题是非凸的，涉及资源分配、无人机部署位置和多用户调度。为解决此问题，首先推导了LQR成本的闭式表达式。随后，利用交替优化（AO）方法将非凸问题分解为一系列子问题，并采用凸差分（DC）规划和投影梯度下降（PGD）方法获得高效的次优解。此外，还对所提算法的收敛性和计算复杂度进行了分析。

**Result:** 广泛的仿真结果验证了所提出方法相对于基准方案的有效性，并揭示了控制与感知性能之间的权衡。

**Conclusion:** 本文成功地提出了低空无线网络中感知、通信与控制的协同设计方案，通过优化资源分配、无人机部署和调度，实现了多无人机合作系统中机器人控制的稳定性和未知目标定位，并验证了其有效性。

> **ai_Abstract:** 本文针对低空无线网络中的多无人机合作系统，研究了集成感知、通信与控制（SC²）的协同设计，特别是在有限块长传输条件下。研究目标是确保地面机器人控制的稳定性，并同时实现未知感知目标的定位。为此，作者提出了一个联合考虑控制性能（LQR成本）和定位性能（FIM行列式）的加权非凸优化问题，该问题涉及资源分配、无人机部署和多用户调度。为解决此非凸问题，文中首先推导了LQR成本的闭式表达式，然后采用交替优化（AO）框架，结合凸差分（DC）规划和投影梯度下降（PGD）方法，得到了高效的次优解。仿真结果验证了所提方法的有效性，并分析了控制与感知性能的权衡。

> **摘要翻译:** 物联网（IoT）服务的快速发展以及向第六代（6G）的演进，已将无人机（UAV）定位为低空无线网络（LAWNs）的关键使能者。本工作研究了多无人机合作系统中，集成感知、通信和控制（SC²）在有限块长（FBL）传输条件下的协同设计。具体而言，无人机持续监测地面机器人的状态并将其观测结果传输给机器人控制器，以确保稳定控制，同时协同定位一个未知感知目标（ST）。为此，首先通过联合考虑线性二次调节器（LQR）成本和费舍尔信息矩阵（FIM）的行列式来衡量控制和定位性能，从而构建了一个加权优化问题。由此产生的优化资源分配、无人机部署位置和多用户调度的问题是非凸的。为了规避这一挑战，我们首先推导了LQR成本相对于其他变量的闭式表达式。随后，通过利用交替优化（AO）方法，将非凸优化问题分解为一系列子问题，其中采用凸差分（DC）规划和投影梯度下降（PGD）方法来获得高效的次优解。此外，还彻底分析了所提出算法的收敛性和计算复杂度。本文提供了大量的仿真结果，以验证我们提出的方法与基准方案相比的有效性，并揭示了控制和感知性能之间的权衡。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [154] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
> *线性差分麦克风阵列的零点相关波束图测量和信号量化效应分析*

*Shweta Pal, Arun Kumar, Monika Agrawal* | **Category: eess.SP**

**Keywords:** 差分麦克风阵列, 零点深度, 零点宽度, 波束图, 信号量化

**Comment:** 10 pages, 15 Figures, 3 Tables

> **TL;DR:** 本文提出了表征差分麦克风阵列（DMA）零点的新测量方法（零点深度和零点宽度），研究了信号量化对DMA的影响，并通过仿真和实验室实验验证了结果。

**AI_Comments:** 本文的创新之处在于引入了专门用于表征差分麦克风阵列中零点的新颖测量方法（零点深度和零点宽度），填补了现有文献的空白。其重要性在于提供了一种更直接、更定量的方式来评估DMA在消除干扰方面的性能，这对于需要精确干扰衰减的应用至关重要。研究中包含信号量化效应的分析以及通过仿真和实验进行的验证，增加了研究结果的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有文献缺乏直接评估差分麦克风阵列（DMA）零点效率的测量方法，并且尚未在DMA的背景下研究零点相关测量。本文旨在通过解决这一空白，提供关于DMA效用的新见解。

**Method:** 提出了表征DMA波束功率图中零点的新测量方法：零点深度（ND）和零点宽度（NW），并研究了它们作为深度水平函数的性能。研究了由于数据采集对一阶、二阶和三阶线性DMA以及不同波束图（偶极、心形、超心形和超指向性）的信号量化效应。推导了任意通用N阶DMA的量化波束形成输出的解析表达式。通过仿真和在全消声室中的实验室实验验证了研究结果。

**Result:** 仿真结果展示了零点深度随量化位数的变化以及零点宽度随深度的变化。实验室实验结果支持了仿真结果，测得的波束图显示出明显的零点深度，证实了实验设置的有效性。

**Conclusion:** 本文成功提出并评估了差分麦克风阵列的零点相关测量方法，研究了信号量化效应，并验证了研究结果，展示了DMA在零点消除应用中的实用性。

> **ai_Abstract:** 本文针对差分麦克风阵列（DMA）中零点评估缺乏专门测量方法的问题，提出了新的测量指标：零点深度（ND）和零点宽度（NW），以表征DMA波束功率图中的零点。研究探讨了信号量化效应对不同阶线性DMA和各种波束图的影响，并推导了量化输出的解析表达式。通过仿真和消声室实验验证了所提出的测量方法和研究发现，证实了DMA在干扰消除中的有效性。

> **摘要翻译:** 差分麦克风阵列（DMA）能够以相对较宽的波束功率图峰值为代价，获得更尖锐的零点，从而增强能力。这可用于需要消除或衰减干扰源的应用。据我们所知，现有文献缺乏直接评估零点效率的测量方法，并且尚未在差分麦克风阵列（DMA）的背景下研究零点相关测量。本文通过提出表征其波束功率图中零点的测量方法，提供了关于DMA效用的新见解。我们通过展示和评估零点相关测量，即零点深度（ND）和零点宽度（NW），作为相对于波束功率图最大值的深度水平函数，来研究差分波束形成器的性能。本文还介绍了由于数据采集对一阶、二阶和三阶线性DMA以及不同波束图（即偶极、心形、超心形和超指向性）的信号量化效应的研究。本文推导了任意通用N阶DMA的量化波束形成输出的解析表达式。还介绍了零点深度随量化位数变化的仿真结果和零点宽度随深度变化的仿真结果，并得出了推论。在全消声室中进行了实验室实验以支持仿真结果。测得的波束图显示出明显的零点深度，证实了实验设置的有效性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [174] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
> *基于点云环境的信道知识图谱构建*

*Yancheng Wang, Wei Guo, Guanying Chen, Ye Zhang, Shuguang Cui* | **Category: eess.SP**

**Keywords:** 信道知识图谱, 点云, 环境感知通信, 深度学习, 信道状态信息

**Comment:** 

> **TL;DR:** 本文提出了一种结合模型和数据驱动的方法，利用点云环境数据和少量信道信息样本来构建信道知识图谱，显著提高了精度。

**AI_Comments:** 本文的创新点在于将点云环境数据引入信道知识图谱的构建中，并结合了模型驱动的点选择与数据驱动的神经网络估计，有效地提升了CKM的精度。这种方法为环境感知通信提供了一种更准确的CSI获取手段，对于未来无线通信系统的设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信道知识图谱（CKM）构建方案采用过于简化的环境信息，这严重影响了其准确性，导致频繁获取信道状态信息（CSI）的开销较大。

**Method:** 本文提出了一种结合模型和数据驱动的方法来构建信道知识图谱（CKM）。首先，设计了一种点选择器，通过构建基于不同到达时间（ToA）的同焦点椭球体，识别包含与多径信道增益相关的环境信息的点云子集。然后，利用实地测量收集的包含环境点云和相应信道数据的真实世界数据集，训练了一个神经网络信道增益估计器，以学习每个选定子集与其对应信道增益之间的映射。

**Result:** 对于功率延迟剖面（PDP）的CKM构建，所提方法的均方根误差（RMSE）为2.95 dB，显著低于传统射线追踪方法的7.32 dB。对于接收功率值（即无线电地图）的CKM构建，其RMSE为1.04 dB，优于克里金插值方法的1.68 dB。

**Conclusion:** 结合模型和数据驱动的方法，利用点云环境数据构建信道知识图谱，能够显著提高信道知识图谱的构建精度，优于传统的射线追踪和克里金插值方法。

> **ai_Abstract:** 本文提出了一种新颖的结合模型和数据驱动的信道知识图谱（CKM）构建方法，旨在解决现有方法因环境信息简化导致精度不足的问题。该方法利用点云环境数据和少量位置标记的信道信息。核心在于引入一个点选择器，通过构建同焦点椭球体来筛选与多径信道增益相关的点云子集，随后训练一个神经网络估计器学习点云与信道增益的映射。实验结果表明，该方法在功率延迟剖面CKM构建和无线电地图构建方面均显著优于传统方法，分别实现了2.95 dB和1.04 dB的RMSE。

> **摘要翻译:** 信道知识图谱（CKM）为感兴趣区域提供一定水平的信道状态信息（CSI），通过减少频繁CSI获取的开销，成为环境感知通信的关键使能技术。然而，现有的CKM构建方案采用过于简化的环境信息，这显著影响了它们的准确性。为了解决这个问题，本文提出了一种结合模型和数据驱动的方法，通过利用点云环境数据以及少量位置标记的信道信息样本来构建CKM。首先，我们提出了一种新颖的点选择器，通过构建一组基于不同到达时间（ToA）的同焦点椭球体，来识别包含与多径信道增益相关的环境信息的点云子集。然后，我们利用通过实地测量收集的真实世界数据集（包含环境点云和相应的信道数据），训练了一个神经网络信道增益估计器，以学习每个选定子集与其对应信道增益之间的映射。最后，实验结果表明：对于功率延迟剖面（PDP）的CKM构建，所提方法的均方根误差（RMSE）为2.95 dB，显著低于传统射线追踪方法实现的7.32 dB；对于接收功率值（即无线电地图）的CKM构建，其RMSE为1.04 dB，超越了克里金插值方法的1.68 dB。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [189] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
> *Rydberg原子双频信号与双能级耦合的接收特性研究*

*Hao Wu, Chongwu Xie, Xinyuan Yao, Kang-Da Wu, Shanchi Wu, Rui Ni, Guo-Yong Xiang, Chen Gong* | **Category: eess.SP**

**Keywords:** Rydberg原子传感器, 多用户干扰, 双频信号, 误码率, 符号错误率

**Comment:** 

> **TL;DR:** 本文分析并验证了Rydberg原子传感器接收双频信号时，不同能级耦合引起的相互干扰和误码率。

**AI_Comments:** 本文解决了Rydberg原子传感器在多用户通信应用中的一个关键挑战（多用户干扰），这是迈向实际部署的重要一步。理论分析（联合响应系数、BER/SER）与实验验证的结合增强了研究结果的说服力。

<details>
  <summary>Details</summary>

**Motivation:** Rydberg原子传感器在多用户通信中具有多频传感潜力，但与传统天线不同，其接收的多频信号会同时下变频到基带，导致多用户干扰。本文旨在解决这一干扰问题。

**Method:** 本文分析了两个不同载波频率的射频信号耦合不同能级时的相互干扰特性。引入了基于接收器特性的联合响应系数，分析了一个用户对另一个用户的干扰。计算并实验验证了两个耦合不同能级的信号的误码率(BER)和符号错误率(SER)。

**Result:** 本文分析了两个耦合不同能级的信号的误码率(BER)和符号错误率(SER)，并通过实验验证了这些结果。

**Conclusion:** 本研究表征了Rydberg原子传感器在接收与不同能级耦合的双频信号时的干扰和误码率，为它们在多用户通信中的性能提供了见解。

> **ai_Abstract:** 本文研究了Rydberg原子传感器在接收与不同能级耦合的双频信号时出现的多用户干扰。它分析了相互干扰特性，引入了联合响应系数，并评估了此类信号的误码率(BER)和符号错误率(SER)。文中还提供了BER和SER结果的实验验证。

> **摘要翻译:** Rydberg原子传感器已被用于新颖的射频(RF)测量技术，其对多频信号的传感能力使其在多用户通信中具有吸引力。然而，与传统天线中多频信号正交不同，原子传感器接收到的对应不同能级的信号会同时下变频到基带，导致多用户干扰。因此，本文分析了两个不同载波频率的射频信号耦合不同能级时的相互干扰特性。我们基于接收器特性引入了联合响应系数，并分析了一个用户对另一个用户的干扰。我们分析了两个耦合不同能级的信号的误码率(BER)和符号错误率(SER)。我们还进行了实验来验证BER和SER的结果。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [203] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
> *对抗训练：增强无线资源分配学习的域外泛化能力*

*Shengjie Liu, Chenyang Yang* | **Category: eess.SP**

**Keywords:** 对抗训练, 域外泛化, 无线资源分配, 深度神经网络, 混合预编码

**Comment:** 

> **TL;DR:** 该文提出一种基于对抗训练的方法，用于提升深度神经网络在无线资源分配中对域外数据的泛化能力，并通过优化混合预编码验证了其有效性。

**AI_Comments:** 这篇论文通过引入对抗训练来解决深度神经网络在无线资源分配中域外泛化能力不足的问题，具有创新性。它针对数据分布偏移这一常见挑战提供了解决方案，尤其是在无线通信这种信道环境多变的领域，其重要性不言而喻。一步梯度上升法的提出也简化了训练过程。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在资源分配优化中广泛应用，但其性能易受训练和测试数据之间分布偏移（如信道变化）的影响。

**Method:** 本文采用对抗训练（AT）来增强无监督训练的深度神经网络的域外（OOD）泛化能力。具体地，重新构建了AT以捕捉OOD性能下降，并提出了一种一步梯度上升法进行AT。所提出的方法通过优化混合预编码进行验证。

**Result:** 仿真结果表明，当仅使用瑞利衰落信道进行训练时，所提出的方法在各种信道分布下显著提升了多种深度神经网络的OOD性能。

**Conclusion:** 对抗训练能够有效增强深度神经网络在无线资源分配任务中的域外泛化能力，即使训练数据有限，也能在不同信道分布下保持良好性能。

> **ai_Abstract:** 本文提出了一种基于对抗训练（AT）的新方法，旨在解决深度神经网络在无线资源分配任务中面临的训练与测试数据分布偏移问题，从而提升其域外（OOD）泛化能力。作者重新构建了AT以捕捉OOD退化，并引入一步梯度上升法。通过混合预编码的优化验证，仿真结果证实该方法显著增强了多种DNN在不同信道分布下的OOD性能，即使训练数据仅限于瑞利衰落信道。

> **摘要翻译:** 深度神经网络（DNNs）在优化资源分配方面有着广泛的应用。然而，它们的性能容易受到训练和测试数据之间分布偏移（例如信道）的影响。在这封信中，我们采用对抗训练（AT）来增强以无监督方式训练的DNNs的域外（OOD）泛化能力。我们重新构建了AT以捕捉OOD性能下降，并提出了一种一步梯度上升法进行AT。所提出的方法通过优化混合预编码得到了验证。仿真结果表明，当仅使用瑞利衰落信道进行训练时，多种深度神经网络在各种信道分布下都表现出增强的OOD性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [217] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
> *近场通信中基于定位的波束聚焦*

*Nima Mozaffarikhosravi, Prathapasinghe Dharmawansa, Italo Atzeni* | **Category: eess.SP**

**Keywords:** 近场通信, 波束聚焦, 定位, 2D-MUSIC, 6G, 视距传播

**Comment:** 

> **TL;DR:** 针对6G及以上高频段近场通信，提出一种基于定位（使用2D-MUSIC算法）的波束聚焦策略，数值结果表明其在视距主导、短相干块和强噪声环境下更有效。

**AI_Comments:** 这篇论文提出了一种创新的方法，将用户定位与波束聚焦相结合，以应对6G及以上高频段近场通信的挑战。其亮点在于利用了高频段特有的视距传播特性，并结合了2D-MUSIC算法进行定位。研究结果表明了其在特定条件下的优势，这对于未来高频通信系统的设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 6G及以上无线通信系统向更高频段发展以及大规模MIMO阵列的应用将扩展近场区域，进而影响波束赋形和用户定位方案。

**Method:** 提出一种利用毫米波和亚太赫兹频率下主导视距传播的基于定位的波束聚焦策略。为支持此方法，分析了用于距离估计的2D-MUSIC算法，并通过在简化、易处理的设置中检查其频谱。将该方法与基于导频信道估计的零迫使方案在下行链路总谱效率方面进行了比较。

**Result:** 数值结果表明，所提出的方法在视距主导传播、短相干块以及高载波频率和大带宽下出现的强噪声功率条件下更有效。

**Conclusion:** 基于定位的波束聚焦策略（利用2D-MUSIC进行定位）在特定高频段和噪声条件下，比传统的基于导频的零迫使方案表现出更好的频谱效率，特别是在视距主导的环境中。

> **ai_Abstract:** 本文针对6G及以上高频段近场通信中波束赋形和用户定位面临的挑战，提出了一种基于定位的波束聚焦策略。该策略利用毫米波和亚太赫兹频率下的视距传播优势，并通过分析2D-MUSIC算法进行距离估计。数值结果表明，在视距主导、短相干块和强噪声环境下，所提出的方法比传统的基于导频的零迫使方案在下行链路总谱效率方面更有效。

> **摘要翻译:** 将6G及以上无线通信系统转移到更高频段以及大规模多输入多输出阵列的利用将扩展近场区域，影响波束赋形和用户定位方案。在本文中，我们提出了一种基于定位的波束聚焦策略，该策略利用毫米波和亚太赫兹频率下出现的主导视距（LoS）传播。为了支持这种方法，我们通过在最小天线和用户数量的简化、易处理的设置中检查其频谱，分析了用于距离估计的2D-MUSIC算法。最后，我们比较了所提出的基于定位的波束聚焦（通过2D-MUSIC估计位置）与基于导频信道估计的零迫使在下行链路总谱效率方面的性能。我们的数值结果表明，所提出的方法在视距主导传播、短相干块以及高载波频率和大带宽下出现的强噪声功率条件下变得更有效。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [229] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
> *集成可移动天线和智能反射面以增强覆盖范围*

*Ying Gao, Qingqing Wu, Weidong Mei, Guangji Chen, Wen Chen, Ziyuan Zheng* | **Category: eess.SP**

**Keywords:** 可移动天线, 智能反射面, 覆盖增强, 最差情况信噪比, 联合优化

**Comment:** 13 pages, 8 figures, submitted to an IEEE journal for possible
  publication on on May 8, 2025

> **TL;DR:** 该论文研究了一种结合可移动天线（MA）和智能反射面（IRS）的系统，旨在通过联合优化MA位置、IRS反射系数和发射波束成形来最大化目标区域的最差情况信噪比（SNR），从而扩展无线覆盖。文章提出了三种覆盖增强方案和一个通用算法框架，并仿真表明MA方案优于固定位置天线（FPA）方案。

**AI_Comments:** 该论文创新性地将可移动天线与智能反射面相结合，以解决无线覆盖扩展这一未来通信系统的关键挑战。对MA位置、IRS系数和发射波束成形的联合优化方法复杂但前景广阔。提出的算法框架能够处理非凸问题，具有实用价值，即便其结果次优。关于成本-性能权衡的经验发现对于实际部署具有重要的参考意义。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在研究一种智能反射面（IRS）辅助的可移动天线（MA）系统，其中多个IRS与多MA基站协作，以将无线覆盖范围扩展到多个指定目标区域。目标是通过联合优化MA位置、IRS反射系数和发射波束成形，最大化这些区域内所有位置的最差情况信噪比（SNR）。

**Method:** 本文研究了IRS辅助的可移动天线（MA）系统，旨在通过联合优化MA位置、IRS反射系数和发射波束成形来最大化目标区域的最差情况信噪比（SNR）。为平衡性能与成本，提出了三种覆盖增强方案：区域自适应MA-IRS、区域自适应MA-staIRS和共享MA-staIRS。针对这些非凸优化问题，提出了一个通用的算法框架进行高效（尽管次优）求解。

**Result:** 1. 所提出的基于MA的方案在区域自适应和静态IRS配置下始终优于基于固定位置天线（FPA）的对应方案，其中区域自适应MA-IRS方案实现了最佳的最差情况SNR性能。
2. 由于发射天线数量通常远少于IRS单元，区域自适应MA-staIRS方案在最差情况SNR方面可能不如结合区域自适应IRS的基线FPA方案，但适度增加天线数量可以扭转这一趋势。
3. 在固定总成本下，经验发现用于最差情况SNR最大化的最优MA与IRS单元比例与其单位成本比的倒数成正比。

**Conclusion:** 本文证明，结合可移动天线和智能反射面能有效增强无线覆盖，特别是在最差情况信噪比方面，MA方案显著优于固定位置天线方案。研究还揭示了天线数量和成本对系统性能的影响，为实际部署提供了优化方向。

> **ai_Abstract:** 本文研究了一种IRS辅助的可移动天线（MA）系统，旨在扩展无线覆盖并最大化目标区域的最差情况信噪比。论文提出了三种新型覆盖增强方案（区域自适应MA-IRS、区域自适应MA-staIRS和共享MA-staIRS）以及一个通用的算法框架来解决由此产生的非凸优化问题。仿真结果表明，基于MA的方案显著优于固定位置天线方案，其中区域自适应MA-IRS方案表现最佳。研究还深入探讨了天线数量对性能的影响以及成本与性能之间的权衡，为最优系统设计提供了见解。

> **摘要翻译:** 本文研究了一种智能反射面（IRS）辅助的可移动天线（MA）系统，其中多个IRS与一个多MA基站协作，以将无线覆盖范围扩展到多个指定目标区域。目标是通过联合优化MA位置、IRS反射系数和发射波束成形，最大化这些区域内所有位置的最差情况信噪比（SNR）。为了在平衡性能-成本权衡的同时实现这一目标，我们提出了三种覆盖增强方案：区域自适应MA-IRS方案、区域自适应MA-staIRS方案和共享MA-staIRS方案，其中staIRS表示在安装时仅配置一次反射系数的静态IRS。这些方案导致具有隐式目标函数的挑战性非凸优化问题，难以找到最优解。为了解决这些问题，我们提出了一种通用的算法框架，可以有效地（尽管不是最优地）解决每个问题。仿真结果表明：1）所提出的基于MA的方案在区域自适应和静态IRS配置下始终优于其基于固定位置天线（FPA）的对应方案，其中区域自适应MA-IRS方案实现了最佳的最差情况SNR性能；2）由于发射天线通常远少于IRS单元，区域自适应MA-staIRS方案在最差情况SNR方面可能不如基线FPA方案与区域自适应IRS结合，但天线数量的适度增加可以扭转这一趋势；3）在固定总成本下，经验发现用于最差情况SNR最大化的最优MA与IRS单元比例与其单位成本比的倒数成正比。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [20] [Global and Local Contrastive Learning for Joint Representations from Cardiac MRI and ECG](https://arxiv.org/abs/2506.20683)
> *心脏MRI和心电图联合表征的全局与局部对比学习*

*Alexander Selivanov, Philip Müller, Özgün Turgut, Nil Stolt-Ansó, Daniel Rückert* | **Category: eess.IV, cs.AI, cs.CV, eess.SP**

**Keywords:** 对比学习, 心电图, 心脏磁共振, 多模态, 心脏功能

**Comment:** accepted to MICCAI 2025 (Springer LNCS)

> **TL;DR:** 该研究提出了PTACL，一个多模态对比学习框架，通过结合CMR的时空信息来增强ECG表征，从而在心脏表型检索和功能参数预测方面优于基线方法。

**AI_Comments:** 该论文的创新点在于提出了PTACL框架，通过结合全局和局部对比学习，有效地将昂贵的CMR数据中的空间和时间信息融入到经济的ECG表征中，显著提升了ECG的诊断价值。这种跨模态信息融合的方法，在不引入额外可学习参数的情况下，提高了心脏表型检索和功能参数预测的准确性，对于推动非侵入性心脏诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 心电图（ECG）成本低廉但无法直接测量心脏功能参数，而心脏磁共振（CMR）虽是金标准但昂贵且不易获取。本研究旨在弥合这一差距，通过整合CMR信息来增强ECG的诊断能力。

**Method:** 本研究提出了PTACL（Patient and Temporal Alignment Contrastive Learning），一个多模态对比学习框架。它使用全局患者级对比损失来对齐来自同一患者的ECG和CMR嵌入，并推开不同患者的嵌入。同时，使用局部时间级对比损失，通过对比编码的ECG片段与对应的编码CMR帧，来强制执行每个患者内部的精细时间对齐，且不引入新的可学习权重。

**Result:** 在英国生物样本库中27,951名受试者的配对ECG-CMR数据上评估了PTACL。与基线方法相比，PTACL在以下两个临床相关任务中取得了更好的性能：1）检索具有相似心脏表型的患者；2）预测CMR衍生的心脏功能参数，如心室容积和射血分数。

**Conclusion:** PTACL框架有潜力利用ECG增强非侵入性心脏诊断，通过结合CMR信息显著丰富了ECG表征的诊断信息，超越了单纯的电活动，并实现了模态间更深入的洞察力转移。

> **ai_Abstract:** 本研究提出了一种名为PTACL的多模态对比学习框架，旨在结合心脏磁共振（CMR）数据来增强心电图（ECG）的诊断能力，以弥补ECG在功能参数测量上的不足和CMR的高成本与低可及性。PTACL通过全局患者级和局部时间级对比损失，实现了ECG与CMR在患者和时间层面的对齐，从而丰富了ECG的表征。实验结果表明，PTACL在检索相似心脏表型患者和预测CMR衍生的心脏功能参数方面，均优于现有基线方法，突显了其在非侵入性心脏诊断中的应用潜力。

> **摘要翻译:** 心电图（ECG）是一种广泛使用、经济高效的工具，用于检测心脏的电异常。然而，它无法直接测量功能参数，如心室容积和射血分数，这些参数对于评估心脏功能至关重要。心脏磁共振（CMR）是这些测量的金标准，提供详细的结构和功能洞察，但成本高昂且可及性较低。为了弥合这一差距，我们提出了PTACL（Patient and Temporal Alignment Contrastive Learning），一个多模态对比学习框架，通过整合来自CMR的时空信息来增强ECG表征。PTACL使用全局患者级对比损失和局部时间级对比损失。全局损失通过将同一患者的ECG和CMR嵌入拉近，同时推开不同患者的嵌入来对齐患者级表征。局部损失通过对比编码的ECG片段与相应的编码CMR帧，在每个患者内部强制执行精细的时间对齐。这种方法用超出电活动的诊断信息丰富了ECG表征，并且比单独的全局对齐在模态之间转移了更多的洞察力，所有这些都没有引入新的可学习权重。我们在英国生物样本库中27,951名受试者的配对ECG-CMR数据上评估了PTACL。与基线方法相比，PTACL在两个临床相关任务中取得了更好的性能：1）检索具有相似心脏表型的患者；2）预测CMR衍生的心脏功能参数，如心室容积和射血分数。我们的结果突出了PTACL利用ECG增强非侵入性心脏诊断的潜力。代码可在：https://github.com/alsalivan/ecgcmr 获得。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [44] [Building Lightweight Semantic Segmentation Models for Aerial Images Using Dual Relation Distillation](https://arxiv.org/abs/2506.20688)
> *使用双重关系蒸馏构建轻量级航空图像语义分割模型*

*Minglong Li, Lianlei Shan, Weiqiang Wang, Ke Lv, Bin Luo, Si-Bao Chen* | **Category: eess.IV**

**Keywords:** 语义分割, 知识蒸馏, 双重关系蒸馏, 轻量级模型, 航空图像

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的双重关系蒸馏（DRD）技术，通过从繁琐的教师模型向紧凑的学生模型传输空间和通道关系，显著提高了轻量级语义分割模型的性能，且不增加计算开销。

**AI_Comments:** 这项工作在知识蒸馏领域提出了一种创新的双重关系蒸馏方法，同时考虑了空间和通道关系，这比传统的基于特征图或对数的方法更全面。它有效地解决了轻量级模型在语义分割中精度与效率的权衡问题，对于资源受限的实际应用具有重要意义。该方法在多个遥感和通用场景数据集上的验证，也证明了其泛化能力和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的CNN语义分割模型虽然精度高，但通常模型庞大且推理速度慢，限制了其在实际应用中的部署。知识蒸馏是一种有前景的方法，可以在分割精度和效率之间取得良好平衡。

**Method:** 本文提出了一种新颖的双重关系蒸馏（DRD）技术。该技术将特征图中的空间和通道关系从繁琐的教师模型传输到紧凑的学生模型。具体来说，分别计算教师和学生模型的空间和通道关系图，然后通过最小化它们之间的距离来对齐相应的关系图。

**Result:** 在三个分割数据集（包括Vaihingen、Potsdam和Cityscapes）上进行了综合实验。实验结果表明，所提出的新蒸馏框架可以显著提升学生网络的性能，且不会带来额外的计算开销。

**Conclusion:** 双重关系蒸馏（DRD）技术能够有效地将教师模型的丰富空间和通道相关性转移给学生模型，从而在不增加计算成本的情况下，显著提高轻量级学生模型在语义分割任务上的准确性，解决了模型效率与精度之间的权衡问题。

> **ai_Abstract:** 本文针对现有语义分割CNN模型在效率上的不足，提出了一种新颖的双重关系蒸馏（DRD）技术。该方法通过将教师模型的空间和通道关系图传输并对齐到学生模型，帮助轻量级学生模型更好地模仿教师的特征分布，从而提高其分割精度。实验证明，DRD框架能在不增加计算成本的情况下显著提升学生网络的性能，适用于航空图像及通用场景的语义分割。

> **摘要翻译:** 最近，CNN模型在语义分割精度方面取得了显著进步。然而，这些模型通常很重且推理速度慢，这限制了它们的实际应用。为了解决这个问题，知识蒸馏已成为一种有前景的方法，可以在分割精度和效率之间取得良好平衡。在本文中，我们提出了一种新颖的双重关系蒸馏（DRD）技术，该技术将特征图中的空间和通道关系从繁琐的模型（教师）传输到紧凑的模型（学生）。具体来说，我们分别为教师和学生模型计算空间和通道关系图，然后通过最小化它们之间的距离来对齐相应的关系图。由于教师模型通常比学生模型学习到更多信息并收集更丰富的空间和通道关联，因此将这些关联从教师传输到学生可以帮助学生在特征分布方面更好地模仿教师，从而提高学生模型的分割精度。我们在三个分割数据集上进行了综合实验，其中包括遥感领域中广泛采用的两个基准（Vaihingen和Potsdam数据集）和一个通用场景中的流行基准（Cityscapes数据集）。实验结果表明，我们新颖的蒸馏框架可以显著提升学生网络的性能，而不会带来额外的计算开销。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [68] [U-R-VEDA: Integrating UNET, Residual Links, Edge and Dual Attention, and Vision Transformer for Accurate Semantic Segmentation of CMRs](https://arxiv.org/abs/2506.20689)
> *U-R-VEDA：整合UNET、残差连接、边缘和双重注意力以及视觉Transformer，用于CMR的精确语义分割*

*Racheal Mukisa, Arvind K. Bansal* | **Category: eess.IV, cs.AI, cs.CV, cs.LG, I.4.6; I.2; I.5.2; I.5.1**

**Keywords:** 语义分割, 心脏磁共振, UNet, 视觉Transformer, 注意力机制

**Comment:** 15 pages, 3 figures

> **TL;DR:** 提出U-R-VEDA模型，结合UNet、Transformer、残差连接和双重注意力，显著提升CMR图像的语义分割精度。

**AI_Comments:** U-R-VEDA模型的创新之处在于其多组件集成策略，结合了UNet的结构优势、Transformer的全局建模能力、残差连接的信息流优化、双重注意力的特征增强以及边缘检测的细节保留。这种混合架构有效地解决了医学图像分割中局部细节与全局上下文理解的挑战，并通过明确引入边缘信息来弥补传统跳跃连接可能的信息损失，提升了分割精度，尤其是在复杂的心脏结构描绘上。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能在自动化医学图像分析中具有变革性作用，而心脏图像的精确自动描绘是心脏疾病量化和自动诊断的首要步骤。

**Method:** 提出U-R-VEDA深度学习模型，该模型是增强型UNet，整合了卷积变换、视觉Transformer、残差连接、通道注意力、空间注意力以及基于边缘检测的跳跃连接，用于CMR图像的精确全自动语义分割。模型通过结合卷积块、嵌入通道和空间注意力以及视觉Transformer来提取局部特征及其相互关系。结合边缘信息与通道和空间注意力作为跳跃连接，减少了卷积变换过程中的信息损失。

**Result:** U-R-VEDA模型在DSC指标下达到了平均95.2%的准确率。该模型在DSC和HD指标下，尤其是在右心室和左心室心肌的描绘方面，优于其他模型的准确性。

**Conclusion:** U-R-VEDA模型显著提高了CMR图像的语义分割精度，这对于改进医学图像分析至关重要，并且在分割性能上优于现有模型。

> **ai_Abstract:** 本文提出了一种名为U-R-VEDA的增强型UNet深度学习模型，旨在实现心脏磁共振（CMR）图像的精确全自动语义分割。该模型巧妙地结合了卷积变换、视觉Transformer、残差连接、双重注意力（通道和空间）以及基于边缘检测的跳跃连接，以有效提取局部特征并减少信息损失。实验结果表明，U-R-VEDA在DSC指标下达到了95.2%的平均准确率，并在右心室和左心室心肌的描绘方面表现出超越其他模型的优越性能，显著提升了医学图像分析的准确性。

> **摘要翻译:** 人工智能，包括深度学习模型，将在心脏疾病诊断和管理中的自动化医学图像分析方面发挥变革性作用。心脏图像的自动化精确描绘是心脏疾病量化和自动化诊断的首要必要步骤。在本文中，我们提出了一种基于深度学习的增强型UNet模型U-R-Veda，它整合了卷积变换、视觉Transformer、残差连接、通道注意力、空间注意力以及基于边缘检测的跳跃连接，用于心脏磁共振（CMR）图像的精确全自动语义分割。该模型通过一系列组合卷积块提取局部特征及其相互关系，其中卷积块中嵌入了通道和空间注意力，并结合了视觉Transformer。卷积块中通道和空间注意力的深度嵌入识别了重要的特征及其空间定位。结合边缘信息与通道和空间注意力作为跳跃连接，减少了卷积变换过程中的信息损失。整个模型显著改善了CMR图像的语义分割，这对于改进医学图像分析是必要的。本文还介绍了一种双重注意力模块（通道和空间注意力）的算法。性能结果显示，U-R-Veda在DSC指标下达到了平均95.2%的准确率。该模型在DSC和HD指标下，尤其是在右心室和左心室心肌的描绘方面，优于其他模型的准确性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [93] [Development of MR spectral analysis method robust against static magnetic field inhomogeneity](https://arxiv.org/abs/2506.20897)
> *开发一种对静磁场不均匀性具有鲁棒性的MR光谱分析方法*

*Shuki Maruyama, Hidenori Takeshima* | **Category: eess.IV, cs.CV**

**Keywords:** MR光谱分析, B0不均匀性, 深度学习, 建模光谱, 准确性

**Comment:** 11 pages, 6 figures

> **TL;DR:** 开发了一种基于深度学习的MR光谱分析方法，利用建模光谱进行训练，显著提高了在静磁场不均匀性下的分析准确性，优于现有方法。

**AI_Comments:** 本文的创新点在于提出了利用建模光谱来训练深度学习模型，以应对MR光谱分析中静磁场不均匀性带来的挑战。这种方法有效地扩大了训练数据集，显著提高了模型在复杂磁场环境下的鲁棒性和准确性。其重要性在于为MR光谱分析提供了一种更精确、更可靠的工具，这对于临床诊断和研究具有重要意义。该方法通过实验结果证明了其优于现有方法的性能，具有实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高在静磁场B0不均匀性存在下光谱分析的准确性。

**Method:** 作者提出了一种新的光谱分析方法，该方法利用深度学习模型，并使用能够一致表示B0不均匀性引起的光谱变化的建模光谱进行训练。这些建模光谱是根据健康人脑的B0图和代谢物比率生成的。B0图被划分为子区域，分别估计的代谢物和基线成分被平均并整合。建模光谱的质量通过视觉和定量方式与测量光谱进行评估。分析模型使用测量、模拟和建模光谱进行训练。通过代谢物比率的均方误差（MSEs）评估所提方法的性能，并与在两种B0不均匀性下采集的体模光谱分析中的LCModel的平均绝对百分比误差（MAPEs）进行比较。

**Result:** 建模光谱根据B0不均匀性表现出加宽和变窄的光谱峰，并且在定量上接近测量光谱。使用测量光谱和建模光谱训练的分析模型，与单独使用测量光谱训练的模型相比，MSEs提高了49.89%；与使用测量光谱和模拟光谱训练的模型相比，MSEs提高了26.66%。随着建模光谱数量从0增加到1,000，性能有所提高。该模型在两种B0不均匀性下均显示出比LCModel显著更低的MAPEs。

**Conclusion:** 开发了一种使用建模光谱进行训练的新的光谱分析深度学习模型。结果表明，所提出的方法通过增加光谱训练样本，有潜力提高光谱分析的准确性。

> **ai_Abstract:** 本研究旨在开发一种在静磁场B0不均匀性下提高MR光谱分析准确性的方法。作者提出了一种基于深度学习的新型光谱分析方法，该方法利用健康人脑的B0图和代谢物比率生成建模光谱，以模拟并表示B0不均匀性引起的光谱变化。这些建模光谱与测量光谱在视觉和定量上均表现出高度一致性。研究表明，使用建模光谱进行训练显著提高了深度学习模型的性能，与仅使用测量光谱或结合模拟光谱训练的模型相比，代谢物比率的均方误差分别降低了49.89%和26.66%。该方法在两种B0不均匀性下均显示出比传统LCModel更低的平均绝对百分比误差。结果表明，通过增加训练样本，该方法有望显著提高光谱分析的准确性。

> **摘要翻译:** 目的：开发一种在静磁场B0不均匀性存在下提高光谱分析准确性的方法。方法：作者提出了一种新的光谱分析方法，该方法利用一个深度学习模型，该模型通过对一致表示B0不均匀性引起的光谱变化的建模光谱进行训练。这些建模光谱是根据健康人脑的B0图和代谢物比率生成的。B0图被划分为补丁大小的子区域，并且分别估计的代谢物和基线成分被平均然后整合。建模光谱的质量通过视觉和定量方式与测量光谱进行评估。分析模型使用测量、模拟和建模光谱进行训练。所提出方法的性能通过代谢物比率的均方误差（MSEs）进行评估。在分析在两种B0不均匀性下采集的体模光谱时，代谢物比率的平均绝对百分比误差（MAPEs）也与LCModel进行了比较。结果：建模光谱根据B0不均匀性表现出加宽和变窄的光谱峰，并且在定量上接近测量光谱。与单独使用测量光谱训练的模型相比，使用测量光谱和建模光谱训练的分析模型将MSEs提高了49.89%；与使用测量光谱和模拟光谱训练的模型相比，提高了26.66%。性能随着建模光谱数量从0增加到1,000而提高。该模型在两种B0不均匀性下均显示出比LCModel显著更低的MAPEs。结论：开发了一种使用建模光谱进行训练的新的光谱分析深度学习模型。结果表明，所提出的方法通过增加光谱训练样本，有潜力提高光谱分析的准确性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [116] [A Novel Framework for Integrating 3D Ultrasound into Percutaneous Liver Tumour Ablation](https://arxiv.org/abs/2506.21162)
> *整合三维超声用于经皮肝肿瘤消融的新颖框架*

*Shuwei Xing, Derek W. Cool, David Tessier, Elvis C. S. Chen, Terry M. Peters, Aaron Fenster* | **Category: eess.IV, cs.AI**

**Keywords:** 3D超声, 肝肿瘤消融, 图像配准, 多模态图像, 介入治疗

**Comment:** 11 pages, 5 figures

> **TL;DR:** 提出一种将3D超声整合到肝肿瘤消融工作流程的新框架，通过2D超声-CT/MRI配准实现，有效提高了肿瘤消融的精度和效率。

**AI_Comments:** 本文提出了一种创新的方法，通过引入3D超声作为中介来简化2D超声与CT/MRI图像的配准，有效解决了3D超声在肝肿瘤消融中肿瘤识别的难题。其贡献在于提供了一个实用且高效的临床整合框架，显著提升了经皮肿瘤消融的精度和效率，有望扩大3D超声在介入治疗中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 3D超声对经皮肝肿瘤消融有益，但肿瘤识别困难阻碍其临床应用，需要将其整合到治疗领域。

**Method:** 提出了一个将3D超声整合到标准消融工作流程的新框架，核心是利用3D超声作为中介的2D超声-CT/MRI配准方法以降低复杂性，并提出了一种多模态图像可视化技术以验证配准工作流。

**Result:** 2D US-CT/MRI配准的标志点距离误差约为2-4毫米，每对图像运行时间0.22秒；非刚性配准将平均对齐误差比刚性配准降低了约40%。

**Conclusion:** 所提出的2D US-CT/MRI配准工作流是有效的，该整合框架提升了3D超声在改善经皮肿瘤消融方面的能力，并展示了扩展3D超声在临床干预中治疗作用的潜力。

> **ai_Abstract:** 本文提出了一种新颖的框架，旨在将3D超声成像技术整合到经皮肝肿瘤消融的标准工作流程中。为了解决3D超声在肿瘤识别方面的挑战并促进其临床应用，该框架的核心是一个临床可行的2D超声-CT/MRI配准方法，该方法利用3D超声作为中介以简化配准过程。研究结果表明，该配准方法具有高精度（2-4毫米误差）和高效率（0.22秒运行时间），并且非刚性配准显著降低了对齐误差。这表明所提出的整合框架能够有效提升3D超声在改善经皮肿瘤消融方面的能力，具有重要的临床应用潜力。

> **摘要翻译:** 三维超声（US）成像在提高经皮肝肿瘤消融效果方面显示出显著益处。其临床整合对于将三维超声转化为治疗领域至关重要。然而，超声图像中肿瘤识别的挑战持续阻碍其更广泛的应用。在这项工作中，我们提出了一种将三维超声整合到标准消融工作流程的新颖框架。我们提出了一个关键组件，即一种临床可行的二维超声-CT/MRI配准方法，该方法利用三维超声作为中介以降低配准复杂性。为了促进配准工作流程的有效验证，我们还提出了一种直观的多模态图像可视化技术。在我们的研究中，二维超声-CT/MRI配准实现了约2-4毫米的标志点距离误差，每对图像的运行时间为0.22秒。此外，与刚性配准相比，非刚性配准将平均对齐误差降低了约40%。结果证明了所提出的二维超声-CT/MRI配准工作流程的有效性。我们的整合框架提升了三维超声成像在改善经皮肿瘤消融方面的能力，展示了扩展三维超声在临床干预中治疗作用的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [136] [Uncover Treasures in DCT: Advancing JPEG Quality Enhancement by Exploiting Latent Correlations](https://arxiv.org/abs/2506.21171)
> *在DCT中发掘宝藏：通过利用潜在相关性推进JPEG图像质量增强*

*Jing Yang, Qunliang Xing, Mai Xu, Minglang Qiao* | **Category: eess.IV, cs.CV**

**Keywords:** JPEG质量增强, DCT域, 压缩伪影, 图像处理, 相关性

**Comment:** 

> **TL;DR:** 该研究提出了一种新的DCT域JPEG质量增强方法（AJQE），通过利用DCT系数中的潜在相关性，实现了比现有像素域方法更高的性能和更低的计算成本。

**AI_Comments:** 该论文的创新点在于识别并利用了DCT系数中的潜在相关性，从而成功地将像素域的先进模型应用于DCT域，实现了性能提升和计算效率的优化。这为JPEG图像质量增强提供了一个新的、高效的途径，对于资源受限的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** JPEG图像在离散余弦变换（DCT）系数量化过程中会引入压缩伪影。大多数现有像素域的JPEG质量增强方法计算成本高昂。因此，直接在DCT域进行增强受到了关注，但现有DCT域方法的性能有限。

**Method:** 该研究识别了JPEG图像DCT系数中的两种关键相关性。基于此，提出了一种先进的DCT域JPEG质量增强（AJQE）方法，充分利用这些相关性。AJQE方法能够将许多成熟的像素域模型应用于DCT域。

**Result:** 与像素域对应方法相比，通过该方法导出的DCT域模型在PSNR上平均提高了0.35 dB，增强吞吐量平均增加了60.5%。

**Conclusion:** 通过在DCT域中识别并利用潜在相关性，所提出的AJQE方法显著提高了JPEG图像质量增强的性能，并降低了计算复杂性，证明了DCT域增强的优越性。

> **ai_Abstract:** 本文提出了一种名为AJQE的先进DCT域JPEG质量增强方法，旨在解决现有像素域方法计算成本高和DCT域方法性能有限的问题。通过识别并充分利用JPEG图像DCT系数中的两种关键相关性，AJQE方法成功地将成熟的像素域模型迁移到DCT域，从而在提高图像质量的同时显著降低了计算开销。实验结果表明，该方法在PSNR和增强吞吐量方面均优于传统的像素域方法。

> **摘要翻译:** 联合图像专家组（JPEG）通过量化离散余弦变换（DCT）系数实现数据压缩，这不可避免地引入了压缩伪影。大多数现有的JPEG质量增强方法在像素域操作，但受限于解码的高计算成本。因此，直接在DCT域对JPEG图像进行增强受到了越来越多的关注。然而，当前的DCT域方法往往性能有限。为了解决这一挑战，我们识别了JPEG图像DCT系数中的两种关键相关性。基于这一洞察，我们提出了一种先进的DCT域JPEG质量增强（AJQE）方法，该方法充分利用了这些相关性。AJQE方法使得许多成熟的像素域模型能够适应DCT域，以更低的计算复杂性实现卓越的性能。与像素域对应方法相比，我们方法导出的DCT域模型在PSNR上平均提高了0.35 dB，增强吞吐量平均增加了60.5%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [153] [GANet-Seg: Adversarial Learning for Brain Tumor Segmentation with Hybrid Generative Models](https://arxiv.org/abs/2506.21245)
> *GANet-Seg：基于混合生成模型的脑肿瘤对抗学习分割*

*Qifei Cui, Xinyu Lu* | **Category: eess.IV, cs.CV**

**Keywords:** 脑肿瘤分割, 对抗学习, GAN, Unet, 数据增强

**Comment:** 

> **TL;DR:** GANet-Seg是一个利用预训练GAN和Unet的脑肿瘤分割新框架，通过对抗学习和合成数据增强，减少对完全标注数据的依赖，并在BraTS数据集上表现出色。

**AI_Comments:** 该论文的创新之处在于将GAN和Unet与异常检测及合成数据增强相结合，有效解决了医学图像领域标注数据稀缺的关键问题，使其在临床应用中具有高度实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发一种准确、鲁棒的脑肿瘤分割方法，并解决标注数据集有限的挑战。

**Method:** 提出GANet-Seg框架，结合预训练GAN和Unet架构。该模型通过全局异常检测模块和精细掩膜生成网络，利用对抗性损失约束迭代提高分割精度。同时采用多模态MRI数据和合成图像增强来提高鲁棒性并解决标注数据不足的问题。

**Result:** 在BraTS数据集上的实验结果表明，该方法有效，在病灶级Dice和HD95指标上均达到比基线更高的灵敏度和准确性。

**Conclusion:** GANet-Seg是一种可扩展的方法，最大限度地减少了对完全标注数据的依赖，为临床环境中的实际应用铺平了道路。

> **ai_Abstract:** GANet-Seg是一个新颖的脑肿瘤分割框架，它结合了预训练的GAN和Unet架构，并集成了一个全局异常检测模块和精细掩膜生成网络。该模型利用对抗性损失约束来提高分割精度，并通过多模态MRI数据和合成图像增强来解决有限标注数据集的问题。在BraTS数据集上的实验证明，该方法在灵敏度和准确性方面优于基线，为临床应用提供了一种可扩展且对标注数据依赖性较低的解决方案。

> **摘要翻译:** 这项工作引入了一种利用预训练GAN和Unet架构进行脑肿瘤分割的新颖框架。通过将全局异常检测模块与精细掩膜生成网络相结合，所提出的模型能够准确识别肿瘤敏感区域，并利用对抗性损失约束迭代增强分割精度。研究中采用了多模态MRI数据和合成图像增强，以提高鲁棒性并解决带注释数据集有限的挑战。在BraTS数据集上的实验结果表明，该方法有效，在病灶级Dice和HD95指标上均达到比基线更高的灵敏度和准确性。这种可扩展的方法最大限度地减少了对完全标注数据的依赖，为临床环境中的实际实际应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [173] [Lightweight Physics-Informed Zero-Shot Ultrasound Plane Wave Denoising](https://arxiv.org/abs/2506.21499)
> *轻量级物理信息零样本超声平面波去噪*

*Hojat Asgariandehkordi, Mostafa Sharifzadeh, Hassan Rivaz* | **Category: eess.IV, cs.CV**

**Keywords:** 超声去噪, 零样本学习, 相干平面波复合, 自监督学习, 物理信息引导

**Comment:** 

> **TL;DR:** 提出了一种轻量级、物理信息引导的零样本超声去噪框架，通过自监督学习在不依赖额外训练数据的情况下，有效提升低角度CPWC图像的对比度并保留结构。

**AI_Comments:** 该论文的创新点在于提出了一个零样本、物理信息引导的自监督去噪框架，解决了传统监督学习方法对大量标记数据依赖的问题。其轻量级架构和无需微调的特性使其在实际超声应用中具有很高的普适性和效率。通过巧妙地利用图像物理特性来生成训练数据，避免了采集昂贵且耗时的配对数据集。

<details>
  <summary>Details</summary>

**Motivation:** 超声相干平面波复合（CPWC）虽能增强图像对比度，但增加角度会降低帧率并引入运动伪影；在传输次数有限的情况下，复合图像易受噪声影响。

**Method:** 该方法针对低角度CPWC采集，将可用传输角度分为两个不相交的子集，每个子集用于形成包含更高噪声的复合图像。然后，这些新的复合图像通过自监督残差学习方案训练一个深度模型，使其能够抑制非相干噪声并保留解剖结构。利用子集间角度依赖伪影不同而底层组织响应相似的物理信息配对，使网络能够区分不一致的伪影和一致的组织信号。模型采用轻量级架构（仅包含两个卷积层），无需领域特定微调或配对数据。

**Result:** 在仿真、体模和体内数据上的评估表明，与经典和基于深度学习的去噪方法相比，该方法在对比度增强和结构保留方面表现出卓越的性能。

**Conclusion:** 该零样本去噪框架通过利用物理信息和自监督学习，为低角度CPWC超声图像去噪提供了一种高效、自适应且计算成本低廉的解决方案，显著提升了图像质量。

> **ai_Abstract:** 本研究提出了一种轻量级、物理信息引导的零样本去噪框架，专为低角度超声相干平面波复合（CPWC）图像设计。该方法通过将传输角度分为两个子集，并利用它们形成的带噪图像进行自监督残差学习，从而训练一个仅包含两个卷积层的深度模型。这种方法无需外部训练数据或领域特定微调，能够有效抑制非相干噪声，同时保留解剖结构。实验结果表明，该框架在对比度增强和结构保留方面优于现有去噪方法。

> **摘要翻译:** 超声相干平面波复合（CPWC）通过结合来自多个转向传输的回波来增强图像对比度。虽然增加角度数量通常能改善图像质量，但这会大幅降低帧率并可能在快速移动目标中引入模糊伪影。此外，复合图像仍然容易受到噪声影响，尤其是在传输次数有限的情况下采集时。我们提出了一种专为低角度CPWC采集量身定制的零样本去噪框架，该框架无需单独的训练数据集即可增强对比度。该方法将可用的传输角度分为两个不相交的子集，每个子集用于形成包含更高噪声水平的复合图像。然后，这些新的复合图像通过自监督残差学习方案训练一个深度模型，使其能够抑制非相干噪声，同时保留解剖结构。由于角度依赖性伪影在子集之间有所不同，而底层组织响应相似，这种物理信息引导的配对使得网络能够学习将不一致的伪影与一致的组织信号分离。与监督方法不同，我们的模型无需领域特定的微调或配对数据，使其能够适应不同的解剖区域和采集设置。由于采用了轻量级架构（仅包含两个卷积层），整个流程支持高效训练，计算成本低。在仿真、体模和体内数据上的评估表明，与经典和基于深度学习的去噪方法相比，该方法在对比度增强和结构保留方面表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [188] [Exploring the Design Space of 3D MLLMs for CT Report Generation](https://arxiv.org/abs/2506.21535)
> *探索用于CT报告生成的3D多模态大语言模型设计空间*

*Mohammed Baharoon, Jun Ma, Congyu Fang, Augustin Toma, Bo Wang* | **Category: eess.IV, cs.CV, cs.LG**

**Keywords:** 3D MLLMs, CT报告生成, 放射学, 设计空间, 知识增强

**Comment:** 

> **TL;DR:** 本文系统研究了用于CT报告生成的3D多模态大语言模型（MLLMs）的设计空间，并提出了知识增强方法，在MICCAI 2024 AMOS-MM挑战赛中取得第二名。研究发现，在相同训练协议下，放射报告生成（RRG）与LLM大小基本无关；若ViT在较小体积上预训练，则较大体积不总能提高性能；使用分割掩码可提升性能。

**AI_Comments:** 该论文系统性地探索了3D MLLMs的设计空间，为放射学报告生成领域提供了宝贵的指导。关于LLM大小独立性和ViT预训练对体积大小影响的发现，挑战了现有的一些普遍假设，具有重要的理论和实践意义。知识增强方法的引入也展示了创新性。

<details>
  <summary>Details</summary>

**Motivation:** 自动化放射学报告生成（RRG）是多模态大语言模型（MLLMs）的一个有前景的应用方向。本文旨在系统地探索用于3D CT报告生成的3D MLLMs的设计空间。

**Method:** 本文系统调查了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和微调技术。此外，还引入了两种基于知识的报告增强方法。研究在AMOS-MM数据集的1,687个病例上进行了评估。

**Result:** 基于知识的报告增强方法将GREEN分数提高了10%，在MICCAI 2024 AMOS-MM挑战赛中获得第二名。结果表明，在相同的训练协议下，放射学报告生成（RRG）在很大程度上独立于LLM的大小。研究还发现，如果原始ViT是在较小体积上预训练的，那么更大的体积并不总是能提高性能。最后，使用分割掩码与CT体积一起可以提高性能。

**Conclusion:** 本研究表明，通过系统探索3D MLLMs的设计空间并引入知识增强方法，可以显著提高CT报告生成的性能。关键发现包括LLM大小对RRG影响有限、体积大小与ViT预训练的关联性以及分割掩码的有效性。

> **ai_Abstract:** 本文系统探索了用于CT报告生成的3D多模态大语言模型（MLLMs）的设计空间，涵盖了视觉输入、投影器、LLMs和微调技术。研究引入了两种基于知识的报告增强方法，显著提升了性能，并在MICCAI 2024 AMOS-MM挑战赛中获得第二名。主要发现包括RRG与LLM大小的独立性、体积大小在ViT预训练背景下的细微影响，以及结合分割掩码的益处。

> **摘要翻译:** 多模态大语言模型（MLLMs）已成为自动化放射学报告生成（RRG）的一种有前景的方法。在这项工作中，我们系统地研究了3D MLLMs的设计空间，包括视觉输入表示、投影器、大语言模型（LLMs）和用于3D CT报告生成的微调技术。我们还引入了两种基于知识的报告增强方法，将GREEN分数提高了10%，在MICCAI 2024 AMOS-MM挑战赛中获得第二名。我们在AMOS-MM数据集的1,687个病例上的结果表明，在相同的训练协议下，RRG在很大程度上独立于LLM的大小。我们还表明，如果原始ViT是在较小体积上预训练的，那么更大的体积并不总是能提高性能。最后，我们表明使用分割掩码与CT体积一起可以提高性能。代码已公开在https://github.com/bowang-lab/AMOS-MM-Solution

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [23] [CodecSlime: Temporal Redundancy Compression of Neural Speech Codec via Dynamic Frame Rate](https://arxiv.org/abs/2506.21074)
> *CodecSlime：通过动态帧率实现神经语音编解码器的时间冗余压缩*

*Hankun Wang, Yiwei Guo, Chongtian Shao, Bohan Li, Xie Chen, Kai Yu* | **Category: eess.AS, cs.SD**

**Keywords:** 神经语音编解码器, 动态帧率, 时间冗余, 语音压缩, VQ-GAN

**Comment:** 16 pages, 5 figures, 9 tables

> **TL;DR:** 神经语音编解码器由于固定帧率，在稳态语音段上浪费了大量token。CodecSlime首次引入动态帧率（DFR）来压缩时间冗余，从而在相同或更低的比特率下实现更好的重建质量或更低的比特率。

**AI_Comments:** CodecSlime引入了一种新颖且实用的方法，通过解决时间冗余问题来提高神经语音编解码器的效率。其插件式、无监督和架构无关的特性使其具有高度适应性。词错误率（WER）的显著降低以及灵活的比特率-质量权衡表明了其在语音压缩和相关任务中的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 当前主流的神经语音编解码器采用固定帧率（FFR），为每个等时长片段分配相同数量的token。然而，语音在时间信息密度上本质上是非均匀的。因此，许多token被浪费在像长元音和静音这样的稳态段上。

**Method:** CodecSlime是一种插件式方法，首次通过支持神经语音编解码器上的动态帧率（DFR）来压缩时间冗余。该方法是无监督和架构无关的，结合了ScheDFR和Melt-and-Cool两项关键创新，分别用于推理和训练的适应。

**Result:** 当集成到典型的VQ-GAN编解码器主干并以40 Hz DFR（约600 bps）运行时，CodecSlime的重建WER相对于具有相同模型架构和相似比特率的传统FFR基线降低了高达46%，同时其他指标也具有竞争力。CodecSlime还支持重建质量和比特率之间的灵活权衡：单个模型支持以多个帧率进行推理，并在相应帧率下始终优于FFR模型。

**Conclusion:** CodecSlime通过支持动态帧率有效减少了神经语音编解码器的时间冗余，将重建词错误率（WER）降低了高达46%，并实现了质量与比特率之间的灵活权衡，显著优于固定帧率模型。

> **ai_Abstract:** CodecSlime通过引入动态帧率（DFR）方法，解决了固定帧率（FFR）神经语音编解码器在均匀语音段上浪费token的低效率问题。这种无监督、架构无关的插件方法，结合了ScheDFR和Melt-and-Cool，显著减少了时间冗余。实验表明，CodecSlime在相似比特率下，相对于FFR基线，重建WER降低了高达46%，并允许灵活的质量-比特率权衡。

> **摘要翻译:** 神经语音编解码器已广泛应用于音频压缩和各种下游任务。当前主流编解码器是固定帧率（FFR），它们为每个等时长片段分配相同数量的token。然而，语音在时间信息密度上本质上是非均匀的。因此，许多token被浪费在像长元音和静音这样的稳态段上。为了解决这种不匹配，我们提出了CodecSlime，这是一种插件式方法，首次通过支持神经语音编解码器上的动态帧率（DFR）来压缩时间冗余。我们的方法是无监督和架构无关的，结合了ScheDFR和Melt-and-Cool两项关键创新，分别用于推理和训练的适应。当集成到典型的VQ-GAN编解码器主干并以40 Hz DFR（约600 bps）运行时，CodecSlime的重建WER相对于具有相同模型架构和相似比特率的传统FFR基线降低了高达46%，同时其他指标也具有竞争力。CodecSlime还支持重建质量和比特率之间的灵活权衡：单个模型支持以多个帧率进行推理，并在相应帧率下始终优于FFR模型。音频样本可在https://acadarmeria.github.io/codecslime/获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [47] [Post-training for Deepfake Speech Detection](https://arxiv.org/abs/2506.21090)
> *深度伪造语音检测的后训练*

*Wanying Ge, Xin Wang, Xuechen Liu, Junichi Yamagishi* | **Category: eess.AS**

**Keywords:** 深度伪造语音检测, 后训练, 自监督学习, AntiDeepfake, 鲁棒性

**Comment:** 

> **TL;DR:** 本文介绍了一种后训练方法，通过弥合通用预训练和领域特定微调之间的差距，使自监督学习模型适应深度伪造语音检测。

**AI_Comments:** 这篇论文的创新点在于提出了“后训练”的概念，有效地将大规模通用预训练模型与特定领域的深度伪造检测任务相结合，弥补了二者之间的差距。通过利用大规模多语言数据集进行后训练，显著提升了模型的鲁棒性和泛化能力，为深度伪造语音检测领域提供了一种新的、更有效的方法。其成果超越了现有SOTA，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 为提升深度伪造语音检测模型的鲁棒性和泛化能力，弥补通用预训练与领域特定微调之间的差距。

**Method:** 引入一种后训练方法，使自监督学习（SSL）模型适应深度伪造语音检测。开发了AntiDeepfake模型，使用包含超过56,000小时真实语音和18,000小时带伪造痕迹语音的大规模多语言数据集进行后训练。

**Result:** 后训练模型对未见过的深度伪造语音表现出强大的鲁棒性和泛化能力。在Deepfake-Eval-2024数据集上进一步微调后，这些模型持续超越现有不使用后训练的最先进检测器。

**Conclusion:** 后训练方法显著提升了深度伪造语音检测模型的性能，使其在鲁棒性和泛化能力上优于现有技术。

> **ai_Abstract:** 本文提出了一种针对深度伪造语音检测的后训练方法，旨在弥合自监督学习模型在通用预训练和领域特定微调之间的鸿沟。研究团队开发了AntiDeepfake模型，利用一个大规模多语言数据集（包含超过5.6万小时真实语音和1.8万小时伪造语音）进行后训练。实验证明，这些后训练模型对未知深度伪造语音展现出卓越的鲁棒性和泛化能力，并在Deepfake-Eval-2024数据集上进一步微调后，性能超越了当前不采用后训练的最先进检测器。

> **摘要翻译:** 我们引入了一种后训练方法，通过弥合通用预训练和领域特定微调之间的差距，使自监督学习（SSL）模型适应深度伪造语音检测。我们提出了AntiDeepfake模型，这是一系列使用大规模多语言语音数据集开发的后训练模型，该数据集包含超过一百种语言的56,000小时真实语音和18,000小时带有各种伪造痕迹的语音。实验结果表明，后训练模型已经对未见过的深度伪造语音表现出强大的鲁棒性和泛化能力。当它们在Deepfake-Eval-2024数据集上进一步微调时，这些模型持续超越现有不利用后训练的最先进检测器。模型检查点和源代码已在线提供。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [71] [Performance improvement of spatial semantic segmentation with enriched audio features and agent-based error correction for DCASE 2025 Challenge Task 4](https://arxiv.org/abs/2506.21174)
> *DCASE 2025挑战任务4中通过丰富音频特征和基于代理的错误校正改进空间语义分割的性能*

*Jongyeon Park, Joonhee Lee, Do-Hyeon Lim, Hong Kook Kim, Hyeongcheol Geum, Jeong Eun Lim* | **Category: eess.AS, cs.LG**

**Keywords:** 空间语义分割, 音频特征, 错误校正, DCASE 2025, CA-SDRi

**Comment:** DCASE 2025 challenge Task4, 5 pages

> **TL;DR:** 该技术报告介绍了DCASE 2025挑战任务4的提交系统，通过整合额外的音频特征、应用基于代理的标签校正系统以及优化训练数据集来提高空间语义分割的性能，相对于基线系统，CA-SDRi指标提高了14.7%。

**AI_Comments:** 该论文通过多方面策略提升了声景空间语义分割的性能，其创新点在于结合了多源音频特征、引入了基于代理的后处理校正机制，并对数据进行了细致的清洗和增强。这些方法协同作用，有效解决了复杂声学场景中分类精度和假阳性问题，为DCASE挑战提供了有竞争力的解决方案。其系统性的优化方法值得借鉴。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高声景空间语义分割（S5）系统中音频标注模型的分类能力，因为混合音频中包含仅靠梅尔谱图难以捕捉的细微线索。此外，还需要减少假阳性并提升低性能类别的分类精度。

**Method:** 1. 将额外的音频特征（频谱滚降和色度特征）整合到从梅尔谱图特征中提取的嵌入特征中。2. 应用基于代理的标签校正系统对S5系统处理的输出进行校正，以减少假阳性。3. 通过移除不相关样本和纳入外部数据来优化训练数据集，以增强低性能类别的分类准确性。

**Result:** 与DCASE 2025挑战任务4的基线系统相比，所提交的系统在CA-SDRi指标上相对提高了高达14.7%。

**Conclusion:** 通过结合丰富的音频特征、基于代理的错误校正和优化的训练数据集，能够显著提高声景空间语义分割系统的性能，并在DCASE 2025挑战任务4中取得了显著的改进。

> **ai_Abstract:** 本文介绍了DCASE 2025挑战任务4的提交系统，旨在提高声景空间语义分割的性能。该系统通过整合频谱滚降和色度等额外音频特征来增强分类能力，并引入基于代理的标签校正系统以减少假阳性并提升CA-SDRi指标。此外，研究还优化了训练数据集，移除了不相关样本并加入了外部数据，以改善低性能类别的分类准确性。实验结果显示，相对于基线系统，这些方法使CA-SDRi指标提高了14.7%。

> **摘要翻译:** 本技术报告介绍了DCASE 2025挑战任务4的提交系统。该模型将额外的音频特征（频谱滚降和色度特征）整合到从梅尔谱图特征中提取的嵌入特征中，以提高声景空间语义分割（S5）系统中音频标注模型的分类能力。这种方法的原因是，混合音频通常包含仅靠梅尔谱图难以捕捉的细微线索。因此，这些额外的特征为模型提供了替代视角。其次，将基于代理的标签校正系统应用于S5系统处理的输出。该系统减少了假阳性，提高了最终的类别感知信号失真比改善（CA-SDRi）指标。最后，我们通过移除不相关样本和纳入外部数据来优化训练数据集，以提高低性能类别的分类准确性。也就是说，音频混合物是从有限的数据点生成的；因此，即使少量的不属于类内的数据点也可能降低模型性能。实验表明，采用这些方法的提交系统与DCASE 2025挑战任务4的基线系统相比，CA-SDRi相对提高了高达14.7%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [96] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
> *混合深度学习和信号处理在低资源环境下的阿拉伯语方言识别*

*Ghazal Al-Shwayyat, Omer Nezih Gerek* | **Category: eess.AS, cs.CL, cs.SD, eess.SP**

**Keywords:** 阿拉伯语方言识别, 深度学习, 信号处理, 低资源, MFCC, CNN

**Comment:** 

> **TL;DR:** 本研究将信号处理与深度学习相结合，以解决低资源环境下阿拉伯语方言识别的挑战。MFCC+CNN模型表现最佳，准确率达91.2%，优于DWT+RNN。

**AI_Comments:** 这篇论文为低资源阿拉伯语方言识别问题提供了一个实用的混合深度学习方法。MFCC与CNN的结合表现出显著的潜力。论文中对局限性的识别以及对未来研究方向（特别是自监督学习和Transformer）的建议，为该领域的进一步改进提供了清晰的路径，奠定了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 由于阿拉伯语的语言多样性以及大型标注数据集的稀缺性，特别是对于代表性不足的方言，阿拉伯语方言识别在语音技术中面临重大挑战。

**Method:** 开发并评估了两种混合模型：(1) 梅尔频率倒谱系数 (MFCC) 与卷积神经网络 (CNN) 结合，以及 (2) 离散小波变换 (DWT) 特征与循环神经网络 (RNN) 结合。模型在Common Voice 阿拉伯语数据集的方言过滤子集上进行训练。

**Result:** MFCC + CNN 架构取得了卓越的性能，准确率达到 91.2%，并具有强大的精确率、召回率和 F1 分数，显著优于小波 + RNN 配置，后者准确率为 66.5%。

**Conclusion:** MFCC + CNN 架构在低资源环境下对阿拉伯语方言识别是有效的。研究指出了数据集大小、潜在的地域标签重叠以及模型优化等局限性，并为未来的研究提出了建议，包括采用更大的标注语料库、整合自监督学习技术和探索更先进的神经网络架构。这项研究为资源受限环境下阿拉伯语方言识别的未来发展奠定了坚实的基础。

> **ai_Abstract:** 本研究旨在解决低资源环境下阿拉伯语方言识别的挑战，提出并评估了两种结合信号处理与深度学习的混合模型：MFCC+CNN和DWT+RNN。实验结果表明，MFCC+CNN模型表现最优，准确率达到91.2%，证明了频谱特征与卷积网络结合的有效性。研究还指出了当前方法的局限性，并为未来的研究方向提供了建议，包括使用更大的数据集和探索更先进的神经网络架构。

> **摘要翻译:** 阿拉伯语方言识别在语音技术中面临重大挑战，原因在于阿拉伯语的语言多样性以及大型标注数据集的稀缺性，特别是对于代表性不足的方言。本研究探讨了混合建模策略，该策略将经典信号处理技术与深度学习架构相结合，以解决低资源场景下的这一问题。开发并评估了两种混合模型：(1) 梅尔频率倒谱系数 (MFCC) 与卷积神经网络 (CNN) 结合，以及 (2) 离散小波变换 (DWT) 特征与循环神经网络 (RNN) 结合。这些模型在 Common Voice 阿拉伯语数据集的方言过滤子集上进行训练，方言标签根据说话人元数据分配。实验结果表明，MFCC + CNN 架构取得了卓越的性能，准确率达到 91.2%，并具有强大的精确率、召回率和 F1 分数，显著优于小波 + RNN 配置，后者准确率为 66.5%。这些发现强调了利用频谱特征与卷积模型进行阿拉伯语方言识别的有效性，尤其是在处理有限标注数据时。该研究还指出了与数据集大小、潜在的地域标签重叠以及模型优化相关的局限性，为未来的研究提供了路线图。进一步改进的建议包括采用更大的标注语料库、整合自监督学习技术以及探索更先进的神经网络架构，例如 Transformer。总的来说，这项研究为资源受限环境下阿拉伯语方言识别的未来发展奠定了坚实的基础。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [119] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
> *ThinkSound：多模态大型语言模型中用于音频生成和编辑的思维链推理*

*Huadai Liu, Jialei Wang, Kaicheng Luo, Wen Wang, Qian Chen, Zhou Zhao, Wei Xue* | **Category: eess.AS, cs.CV, cs.SD**

**Keywords:** 视频到音频生成, 思维链推理, 多模态大语言模型, 音频编辑, AudioCoT

**Comment:** 

> **TL;DR:** ThinkSound是一个利用思维链推理的多模态大语言模型框架，用于视频音频的逐步生成和编辑，实现了SOTA性能。

**AI_Comments:** ThinkSound的创新之处在于将思维链推理引入多模态大语言模型，以实现更精细、可控和交互式的视频音频生成和编辑。这种分阶段的方法模拟了专业人士的工作流，提高了生成音频的真实性和细节表现。引入AudioCoT数据集也为未来的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 尽管端到端视频到音频生成有所改进，但仍难以生成真实捕捉视觉内容细微差别的高保真音频，这需要对视觉动态、声学环境和时间关系进行复杂的推理。

**Method:** 提出ThinkSound框架，利用思维链（CoT）推理实现视频音频的逐步交互式生成和编辑。该方法分解为三个阶段：基础拟音生成、交互式以对象为中心的细化和自然语言指导的定向编辑。在每个阶段，多模态大语言模型生成CoT推理来指导统一的音频基础模型。此外，引入了AudioCoT数据集，用于连接视觉内容、文本描述和声音合成。

**Result:** ThinkSound在视频到音频生成方面实现了最先进的性能，无论是在音频指标还是CoT指标上，并且在分布外Movie Gen Audio基准测试中表现出色。

**Conclusion:** ThinkSound框架通过结合思维链推理和多模态大语言模型，显著提升了视频音频生成和编辑的质量和交互性，达到了SOTA水平。

> **ai_Abstract:** ThinkSound是一个创新的多模态大语言模型框架，通过引入思维链（CoT）推理，解决了视频到音频生成中高保真和细致推理的挑战。它将生成过程分为基础拟音、交互式细化和自然语言编辑三个阶段，并由CoT推理指导音频基础模型。该研究还提出了AudioCoT数据集。实验证明ThinkSound在视频到音频生成方面达到了最先进的性能。

> **摘要翻译:** 尽管端到端视频到音频生成已大大改进，但生成能真实捕捉视觉内容细微差别的高保真音频仍然具有挑战性。像创意产业的专业人士一样，这种生成需要对视觉动态、声学环境和时间关系等项目进行复杂的推理。我们提出了\textbf{ThinkSound}，一个新颖的框架，它利用思维链（CoT）推理来实现视频的逐步、交互式音频生成和编辑。我们的方法将过程分解为三个互补的阶段：创建语义连贯声景的基础拟音生成，通过精确用户交互进行的交互式以对象为中心的细化，以及由自然语言指令引导的定向编辑。在每个阶段，多模态大型语言模型生成与上下文对齐的CoT推理，以指导统一的音频基础模型。此外，我们引入了\textbf{AudioCoT}，一个包含结构化推理注释的综合数据集，它建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound在视频到音频生成方面在音频指标和CoT指标上都达到了最先进的性能，并在分布外Movie Gen Audio基准测试中表现出色。演示页面可在https://ThinkSound-Demo.github.io获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [26] [Towards Probabilistic Question Answering Over Tabular Data](https://arxiv.org/abs/2506.20747)
> *迈向表格数据的概率问答*

*Chen Shen, Sajjadur Rahman, Estevam Hruschka* | **Category: cs.CL, 68T50, 68T37, I.2.7**

**Keywords:** 表格数据问答, 概率问答, 贝叶斯网络, 大型语言模型, LUCARIO

**Comment:** 

> **TL;DR:** 提出LUCARIO基准和框架，用于表格数据的概率问答，通过贝叶斯网络和LLM实现混合推理，显著优于基线。

**AI_Comments:** 这篇论文的创新点在于提出了一个专门针对表格数据概率问答的框架和基准，解决了现有系统在处理不确定性推理方面的局限性。其结合贝叶斯网络（符号推理）和大型语言模型（神经推理）的方法是一种有前景的混合方法，有望在复杂问答场景中取得突破。

<details>
  <summary>Details</summary>

**Motivation:** 现有表格数据问答系统（如NL2SQL）在事实性问题上表现良好，但在需要不确定性推理的概率性问题上表现不足。

**Method:** 引入新的基准LUCARIO和一个概率问答框架。该方法从表格中推断贝叶斯网络，将自然语言查询转换为概率查询，并使用大型语言模型（LLMs）生成最终答案。

**Result:** 实验结果表明，与基线相比有显著改进。

**Conclusion:** 强调了混合符号-神经推理的优势。

> **ai_Abstract:** 本文针对现有表格数据问答系统在处理概率性问题上的不足，提出了一个新的基准LUCARIO和一个概率问答框架。该框架通过从表格中构建贝叶斯网络，将自然语言问题转化为概率查询，并结合大型语言模型生成答案，实现了表格数据的概率问答。实验证明，该方法在性能上显著优于现有基线，展现了混合符号-神经推理的有效性。

> **摘要翻译:** 当前针对表格数据的问答（QA）方法，例如NL2SQL系统，在答案可以直接从表格中检索的事实性问题上表现良好。然而，它们在需要不确定性推理的概率性问题上表现不足。在本文中，我们引入了一个新的基准LUCARIO和一个用于大型表格数据概率问答的框架。我们的方法从表格中推断贝叶斯网络，将自然语言查询转换为概率查询，并使用大型语言模型（LLMs）生成最终答案。实证结果表明，与基线相比有显著改进，突出了混合符号-神经推理的优势。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [50] [Multi-lingual Functional Evaluation for Large Language Models](https://arxiv.org/abs/2506.20793)
> *大型语言模型的多语言功能评估*

*Victor Ojewale, Inioluwa Deborah Raji, Suresh Venkatasubramanian* | **Category: cs.CL**

**Keywords:** 多语言评估, 大型语言模型, 功能基准, 鲁棒性, 跨语言

**Comment:** 

> **TL;DR:** 本文创建了新的多语言功能基准（CL-GSM Symbolic和CL-IFEval），通过将现有英文基准翻译成五种语言，以更好地评估大型语言模型在多语言环境下的实际性能和鲁棒性。研究发现，静态基准可能无法完全捕捉功能性能，且模型在不同语言间的鲁棒性差异显著。

**AI_Comments:** 本文的创新点在于提出了新的多语言功能评估基准，这对于更准确地理解大型语言模型在真实多语言场景下的表现至关重要。其重要性体现在揭示了现有静态基准的局限性，并为未来LLM的多语言能力评估提供了新的方向和工具。研究结果表明，仅依赖静态基准可能会高估或误判模型在实际应用中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的多语言能力评估通常依赖静态数据基准，但这些评估往往无法充分理解模型在多语言环境下的实际性能和鲁棒性。

**Method:** 研究人员通过将现有的英文功能基准模板翻译成法语、西班牙语、印地语、阿拉伯语和约鲁巴语五种额外语言，创建了多语言功能基准——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval）。

**Result:** 研究结果表明，一些静态多语言基准在捕捉功能性能方面与新基准差异显著（例如，M-GSM与CL-GSM Symbolic在英语、法语和西班牙语中的性能分别下降24%、17%和18%；Belebele与CL-IFEval在不同语言间有15-24%的性能下降；M-MMLU与CL-IFEval仅有0.5%至3%的性能下降）。同时发现，模型在不同语言间的鲁棒性差异显著，某些语言（如阿拉伯语、英语）在评估迭代中表现最为稳定。

**Conclusion:** 静态多语言基准可能无法完全反映大型语言模型的实际功能性能和鲁棒性。新创建的多语言功能基准提供了更深入的评估视角，揭示了模型在不同语言环境下的性能差异和鲁棒性问题。

> **ai_Abstract:** 本文针对现有静态多语言基准未能充分评估大型语言模型实际性能和鲁棒性的问题，提出了新的多语言功能基准CL-GSM Symbolic和CL-IFEval。通过将英文功能基准翻译成法语、西班牙语、印地语、阿拉伯语和约鲁巴语，研究发现静态基准与功能性能之间存在显著差异，且模型在不同语言间的鲁棒性表现不一，揭示了当前多语言LLM评估的局限性。

> **摘要翻译:** 大型语言模型的多语言能力通常通过静态数据基准进行评估，例如Belebele、M-MMLU和M-GSM。然而，这些评估往往未能充分理解模型在多语言环境下的实际性能和鲁棒性。为此，我们创建了多语言功能基准——跨语言小学数学符号（CL-GSM Symbolic）和跨语言指令遵循评估（CL-IFEval）——通过将现有英文功能基准模板翻译成五种额外的语言，这些语言涵盖了自然语言处理（NLP）可用资源的范围：法语、西班牙语、印地语、阿拉伯语和约鲁巴语。我们的结果显示，一些静态多语言基准比其他基准更能紧密地捕捉功能性能（即，在不同模型中，M-GSM与CL-GSM Symbolic在英语、法语和西班牙语中的性能分别下降24%、17%和18%；类似地，Belebele与CL-IFEval在不同语言间有15-24%的性能下降，而M-MMLU与CL-IFEval之间仅有0.5%至3%的性能下降）。同样，我们发现模型在不同语言间的鲁棒性差异显著，某些语言（例如阿拉伯语、英语）在评估迭代中表现最为稳定。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [74] [The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas](https://arxiv.org/abs/2506.20803)
> *构思-执行差距：大型语言模型生成与人类研究想法的执行结果*

*Chenglei Si, Tatsunori Hashimoto, Diyi Yang* | **Category: cs.CL, cs.AI, cs.CY, cs.HC, cs.LG**

**Keywords:** 大型语言模型, 科研想法, 执行研究, 构思-执行差距, 研究质量

**Comment:** main paper is 14 pages

> **TL;DR:** 本研究发现，尽管大型语言模型（LLM）生成的科研想法在构思阶段可能被认为更具新颖性，但在实际执行后，其研究质量（新颖性、兴奋度、有效性和整体评价）显著低于人类专家提出的想法，揭示了LLM在生成真正有效科研想法方面的局限性。

**AI_Comments:** 这项研究非常创新，它挑战了当前对LLM在科学研究中作用的普遍乐观预期。它不仅关注了想法的生成，更进一步深入到想法的“可执行性”和“执行结果”，填补了LLM研究领域的一个重要空白。其发现对于理解LLM在复杂、长期任务（如科研）中的真实能力具有重要意义，并为未来LLM辅助研究工具的开发提供了宝贵启示。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在加速科学研究流程方面显示出潜力，特别是在生成新颖研究想法方面。然而，先前研究发现LLM生成的想法在构思阶段被认为比人类专家想法更具新颖性，但一个好的想法不仅要新颖，还应在执行后产生更好的研究成果。因此，本研究旨在测试AI生成的想法是否能带来更好的研究成果，以弥补构思与执行之间的差距。

**Method:** 本研究进行了一项执行研究，招募了43位专家研究人员，随机分配他们执行由专家撰写或由LLM生成的想法。每位专家花费超过100小时实施想法，并撰写了一篇4页的短论文记录实验。所有执行的项目随后由专家NLP研究人员进行盲审。通过比较想法在执行前后的评审分数来评估。

**Result:** 与执行前相比，LLM生成的想法在执行后，其分数在所有评估指标（新颖性、兴奋度、有效性和整体评价；p < 0.05）上均显著下降，降幅远大于专家撰写的想法。这弥合了在构思阶段观察到的LLM与人类想法之间的差距。在比较执行研究的汇总评审分数时，甚至发现在许多指标上排名发生了逆转，人类想法得分高于LLM想法。

**Conclusion:** 本研究揭示了LLM在生成真正有效研究想法方面的局限性，并强调了在缺乏执行结果的情况下评估研究想法的挑战。大型语言模型在构思阶段看似新颖的想法，在实际执行后表现出明显的“构思-执行差距”，其研究成果质量低于人类专家。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）生成的科研想法与人类专家想法在实际执行后的质量差异。通过一项招募43位专家研究人员执行随机分配想法的实验，并对执行成果进行盲审，研究发现，尽管LLM想法在构思阶段可能被认为更具新颖性，但在执行后，其在所有评估指标（新颖性、兴奋度、有效性、整体评价）上的分数均显著低于人类想法，揭示了LLM在生成“可执行”且“有效”研究想法方面的局限性，并强调了评估研究想法时执行结果的重要性。

> **摘要翻译:** 大型语言模型（LLMs）在加速科学研究流程方面显示出潜力。这一过程的一个关键能力是生成新颖的研究想法，并且先前的研究发现，在某些情况下，LLM生成的想法被判断为比人类专家的想法更具新颖性。然而，一个好的想法不应仅仅看起来新颖，它还应该在执行后产生更好的研究成果。为了测试AI生成的想法是否能带来更好的研究成果，我们进行了一项执行研究，招募了43位专家研究人员来执行随机分配的想法，这些想法要么由专家撰写，要么由LLM生成。每位专家花费超过100小时实施该想法，并撰写了一篇4页的短论文来记录实验。所有执行的项目随后都由专家NLP研究人员进行盲审。比较想法在执行前后的评审分数，LLM生成的想法在所有评估指标（新颖性、兴奋度、有效性和整体评价；p < 0.05）上的分数下降幅度显著大于专家撰写的想法，从而弥合了在构思阶段观察到的LLM与人类想法之间的差距。在比较执行研究的汇总评审分数时，我们甚至观察到在许多指标上排名发生了逆转，人类想法得分高于LLM想法。这种构思-执行差距凸显了当前LLM在生成真正有效研究想法方面的局局限性，以及在缺乏执行结果的情况下评估研究想法的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [99] [MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering](https://arxiv.org/abs/2506.20821)
> *MultiFinRAG：一种优化的多模态检索增强生成（RAG）金融问答框架*

*Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh* | **Category: cs.CL, cs.AI, cs.CE, 68T50, 68T07 (Primary) 68P20, 91G15, 91G70, 68U10 (Secondary), I.2.7; I.2.10; H.3.3; H.2.8; I.5.4; J.1**

**Keywords:** 金融问答, 多模态RAG, 检索增强生成, 金融文档, 跨模态推理

**Comment:** Preprint Copy

> **TL;DR:** MultiFinRAG是一种专为金融问答设计的多模态检索增强生成（RAG）框架，通过优化多模态信息提取和检索策略，在处理包含文本、表格和图像的复杂金融文档时，比ChatGPT-4o（免费版）的准确率高出19个百分点，且可在商用硬件上运行。

**AI_Comments:** MultiFinRAG的创新性在于其为金融领域定制的多模态RAG框架，特别解决了金融文档固有的复杂性和多模态性。其通过轻量级MLLM进行多模态信息提取和智能的分层检索策略，有效克服了现有模型在处理长篇、多模态金融数据时的局限性。在商用硬件上实现显著优于ChatGPT-4o的性能，凸显了其在实际应用中的高效性和实用价值。这对于金融分析、风险评估等需要精确信息检索和推理的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 金融文档（如10-K、10-Q和投资者演示文稿）篇幅巨大且包含文本、表格、图表等多种模态信息。对这类内容进行问答通常需要跨模态的联合推理，而传统的大型语言模型（LLMs）和检索增强生成（RAG）管道因令牌限制、布局丢失和碎片化的跨模态上下文而难以有效处理。

**Method:** MultiFinRAG首先通过将表格和图表图像分批发送给轻量级、量化的开源多模态LLM进行多模态提取，生成结构化JSON输出和简洁的文本摘要。然后，这些输出与叙述性文本一起，通过模态感知的相似度阈值进行嵌入和索引，以实现精确检索。最后，采用分层回退策略，在必要时动态地将上下文从纯文本升级到文本+表格+图像，从而实现跨模态推理并减少不相关上下文。

**Result:** MultiFinRAG在涉及文本、表格、图像和组合多模态推理的复杂金融问答任务上，比ChatGPT-4o（免费版）的准确率高出19个百分点，并且可以在商用硬件上运行。

**Conclusion:** MultiFinRAG是一个有效且高效的框架，能够处理复杂的多模态金融问答任务，显著优于现有主流模型，证明了其在金融领域应用的潜力和价值。

> **ai_Abstract:** 本研究提出了MultiFinRAG，一个专为处理复杂金融文档问答而设计的优化多模态检索增强生成（RAG）框架。针对传统LLM和RAG在处理跨模态金融数据时面临的挑战，MultiFinRAG通过创新的多模态提取（利用轻量级MLLM生成结构化和文本摘要）、模态感知嵌入索引以及动态分层回退检索策略，有效整合文本、表格和图像信息。实验结果表明，MultiFinRAG在商用硬件上运行，却能在复杂金融问答任务中比ChatGPT-4o（免费版）实现19个百分点的准确率提升。

> **摘要翻译:** 金融文档——如10-K、10-Q和投资者演示文稿——跨越数百页，并结合了多样化的模态，包括密集的叙述性文本、结构化表格和复杂图表。对这类内容进行问答通常需要跨模态的联合推理，这由于令牌限制、布局丢失和碎片化的跨模态上下文而对传统的大型语言模型（LLMs）和检索增强生成（RAG）管道造成压力。我们引入了MultiFinRAG，一个专为金融问答构建的检索增强生成框架。MultiFinRAG首先通过将表格和图表图像分批发送到轻量级、量化的开源多模态LLM进行多模态提取，该LLM生成结构化JSON输出和简洁的文本摘要。这些输出与叙述性文本一起，通过模态感知的相似度阈值进行嵌入和索引，以实现精确检索。然后，分层回退策略在必要时动态地从纯文本上下文升级到文本+表格+图像上下文，从而实现跨模态推理同时减少不相关上下文。尽管在商用硬件上运行，MultiFinRAG在涉及文本、表格、图像和组合多模态推理的复杂金融问答任务上，比ChatGPT-4o（免费版）的准确率高出19个百分点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [122] [Uncovering Hidden Violent Tendencies in LLMs: A Demographic Analysis via Behavioral Vignettes](https://arxiv.org/abs/2506.20822)
> *揭示LLMs中隐藏的暴力倾向：通过行为小插曲进行人口统计学分析*

*Quintin Myers, Yanjun Gao* | **Category: cs.CL, cs.AI**

**Keywords:** LLMs, 暴力倾向, 行为小插曲, 人口统计学分析, 偏见

**Comment:** Under review

> **TL;DR:** 本研究首次使用经验证的社会科学工具（VBVQ）评估LLMs在处理日常冲突中的暴力倾向和潜在偏见。结果显示LLMs的表面文本生成与其内部暴力偏好存在差异，且其暴力倾向在不同人口统计学特征上表现出变化，这与现有犯罪学和社会科学发现相悖。

**AI_Comments:** 这项研究的创新之处在于首次将经过验证的社会科学测量工具（VBVQ）应用于LLMs的评估，以揭示其在道德模糊情境下的隐藏暴力倾向。通过引入人口统计学偏见的分析，它强调了LLMs在处理敏感内容时可能存在的深层偏见，这对于LLMs在内容审核和风险评估应用中的部署具有重要意义。研究结果对LLMs的可靠性和公平性提出了新的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）被越来越多地提议用于在线暴力内容的检测和响应，但它们对道德模糊、真实世界场景的推理能力尚未得到充分检验。

**Method:** 本研究首次使用经验证的社会科学工具“暴力行为小插曲问卷”（VBVQ）来评估LLMs，该问卷旨在衡量人类对日常冲突的反应。为评估潜在偏见，研究引入了基于角色的提示，在美国境内改变了种族、年龄和地理身份。研究在统一的零样本设置下，评估了来自不同地缘政治和组织背景的六个LLMs。

**Result:** 研究揭示了两个关键发现：（1）LLMs的表面文本生成常常与其内部对暴力反应的偏好存在分歧；（2）它们的暴力倾向因人口统计学特征而异，且经常与犯罪学、社会科学和心理学中已有的发现相矛盾。

**Conclusion:** LLMs在处理道德模糊情境时，其内部暴力倾向可能与其表面输出不一致，并且这些倾向表现出人口统计学偏见，这挑战了现有社会科学的发现，并暗示了LLMs在检测和响应暴力内容方面的复杂性和潜在风险。

> **ai_Abstract:** 本研究首次使用暴力行为小插曲问卷（VBVQ）这一经验证的社会科学工具，评估了LLMs在处理日常冲突中的推理能力。通过引入基于角色的提示来模拟不同人口统计学特征，研究发现LLMs的表面文本输出与其内部暴力倾向存在差异，且这些倾向在不同人口群体中表现出与现有社会科学理论相悖的偏见。这揭示了LLMs在理解和响应道德模糊情境时的复杂性和潜在风险。

> **摘要翻译:** 大型语言模型（LLMs）被越来越多地提议用于在线暴力内容的检测和响应，但它们对道德模糊、真实世界场景的推理能力尚未得到充分检验。我们首次提出一项研究，使用一个经过验证的社会科学工具来评估LLMs，该工具旨在衡量人类对日常冲突的反应，即暴力行为小插曲问卷（VBVQ）。为了评估潜在偏见，我们引入了基于角色的提示，在美国境内改变了种族、年龄和地理身份。在统一的零样本设置下，评估了来自不同地缘政治和组织背景的六个LLMs。我们的研究揭示了两个关键发现：（1）LLMs的表面文本生成常常与其内部对暴力反应的偏好存在分歧；（2）它们的暴力倾向因人口统计学特征而异，且经常与犯罪学、社会科学和心理学中已有的发现相矛盾。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [141] [Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine](https://arxiv.org/abs/2506.20876)
> *少做决策，多做沟通：论医学领域端到端事实核查的构念效度*

*Sebastian Joseph, Lily Chen, Barry Wei, Michael Mackert, Iain J. Marshall, Paul Pu Liang, Ramez Kouzy, Byron C. Wallace, Junyi Jessy Li* | **Category: cs.CL**

**Keywords:** 端到端事实核查, 医学, 构念效度, 医疗沟通, 临床专家

**Comment:** 

> **TL;DR:** 医学领域的端到端事实核查系统仍未被广泛使用，本研究揭示了其在应用中面临的挑战，并提出应将其视为交互式沟通问题。

**AI_Comments:** 该论文对当前流行的端到端AI解决方案在复杂且高风险领域（如医学）的应用提出了批判性视角。它强调了在处理真实世界、模糊和主观信息时，纯粹的自动化决策的局限性，并提出了一种更注重交互和沟通的范式，这对于未来AI在医疗健康领域的负责任发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学决策的重要性以及批判性评估大量医学文献的挑战，促使人们对在公共卫生和医学领域采用自动化事实核查系统产生了兴趣。然而，尽管有这些需求和技术进步，端到端事实核查系统在医学领域仍未被广泛使用。本研究旨在理解这一现象，并探讨其构念效度。

**Method:** 本研究首次通过分析临床专家如何合成医学证据来验证社交媒体上的真实声明，以理解端到端事实核查的上限。

**Result:** 研究揭示了在医学领域应用端到端事实核查的根本挑战，包括：难以将“野外”声明与临床试验形式的科学证据联系起来；不明确声明中的歧义以及意图不匹配；以及本质上主观的真实性标签。

**Conclusion:** 研究认为，事实核查应被视为一个交互式沟通问题来处理和评估，而非一个简单的端到端过程。

> **ai_Abstract:** 本研究探讨了医学领域端到端事实核查系统未被广泛使用的原因。通过分析临床专家如何验证社交媒体上的医学声明，研究揭示了当前端到端方法面临的挑战，包括连接声明与证据的困难、声明的歧义以及真实性标签的主观性。文章主张将事实核查视为一个交互式沟通问题，而非简单的端到端过程。

> **摘要翻译:** 技术进步已在自动事实核查等曾被视为具有挑战性的任务上取得了具体进展。鉴于医学决策的高风险性质以及批判性评估大量多样化医学文献的挑战，人们对在公共卫生和医学领域采用这些系统的兴趣日益增长。循证医学与每个人息息相关，但其本质高度专业化，使得大多数用户的医学素养不足以充分驾驭该领域。医学沟通的此类问题为端到端事实核查代理奠定了基础：针对当前医学文献核查声明并返回有证据支持的结论。然而，此类系统仍未被广泛使用。为了理解这一点，我们首次研究了临床专家如何通过综合医学证据来验证社交媒体上的真实声明。在寻找这一上限的过程中，我们揭示了端到端事实核查应用于医学时面临的根本挑战：将“野外”声明与临床试验形式的科学证据联系起来的困难；不明确声明中混杂着不匹配意图的歧义；以及本质上主观的真实性标签。我们认为，事实核查应被视为一个交互式沟通问题来处理和评估，而非一个端到端过程。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [159] [Optimising Language Models for Downstream Tasks: A Post-Training Perspective](https://arxiv.org/abs/2506.20917)
> *优化下游任务的语言模型：一个后训练视角*

*Zhengyan Shi* | **Category: cs.CL, cs.AI**

**Keywords:** 语言模型, 微调, 后训练, 无标签数据, 下游任务

**Comment:** PhD Thesis

> **TL;DR:** 本论文提出了优化语言模型后训练的方法，使其在下游任务中更鲁棒、高效和泛化。

**AI_Comments:** 该论文在优化语言模型的全面后训练方法上具有创新性，解决了数据利用、计算成本和稀缺标签数据适应性等关键问题。其专注于提高鲁棒性、效率和泛化能力以适应真实世界应用，对于语言模型的实际部署和通用人工智能的进步至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型在适应特定任务时面临挑战，原因包括对无标签数据利用不足、在小数据集上过拟合以及计算成本高昂，这些限制阻碍了它们在真实世界语言任务中的应用。

**Method:** 本论文提出了一系列方法：首先，引入了一种新颖的持续预训练技术，用于从无标签数据中提取任务相关知识；其次，提出了一种参数高效的微调方法，以降低内存和计算成本；再次，改进了监督微调方法，使语言模型更好地遵循指令，尤其是在标签数据稀缺时；最后，开发了新的评估方法和基准，如多跳空间推理任务，以全面评估语言模型的能力和适应性。

**Result:** 通过在各种NLP任务中进行广泛的实证研究，结果表明这些方法显著提高了语言模型的鲁棒性、效率和泛化能力，使其更能适应广泛的应用。

**Conclusion:** 这些进展标志着在构建更鲁棒、更高效的语言模型方面迈出了重要一步，使我们更接近通用人工智能的目标。

> **ai_Abstract:** 本论文旨在解决大型语言模型（LMs）在下游任务中高效和鲁棒适应的挑战。它提出了一系列新颖的后训练方法，包括一种利用无标签数据的持续预训练技术、一种参数高效的微调方法以及改进的监督微调方法以更好地遵循指令。研究还引入了新的评估基准。实证研究表明，这些方法显著增强了语言模型在各种NLP任务中的鲁棒性、效率和泛化能力，从而推动了通用人工智能的发展。

> **摘要翻译:** 语言模型（LMs）在自然语言处理（NLP）中展现出卓越的能力，但如何高效、鲁棒地将其适应特定任务仍然是一个挑战。随着其规模和复杂性的增长，在有标签数据上微调语言模型通常会低效利用可用的无标签数据，导致在小型任务特定数据集上过拟合，并带来显著的计算成本。这些局限性阻碍了它们在真实世界开放式语言任务中的应用。
本论文提出了一系列方法，以更好地使语言模型适应下游应用。首先，我们探索了从无标签数据中提取任务相关知识的策略，引入了一种新颖的持续预训练技术，该技术优于最先进的半监督方法。其次，我们提出了一种参数高效的微调方法，该方法在保持竞争力性能的同时，显著降低了内存和计算成本。我们还引入了改进的监督微调方法，使语言模型能够更好地遵循指令，尤其是在标签数据稀缺时，从而提高了它们在一系列NLP任务（包括开放式生成）中的性能。最后，我们开发了新的评估方法和基准，例如多跳空间推理任务，以更全面地评估语言模型的能力和适应性。
通过在各种NLP任务中进行广泛的实证研究，我们的结果表明这些方法显著提高了语言模型的鲁棒性、效率和泛化能力，使其更能适应广泛的应用。这些进展标志着在构建更鲁棒、更高效的语言模型方面迈出了重要一步，使我们更接近通用人工智能的目标。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [177] [FineWeb2: One Pipeline to Scale Them All -- Adapting Pre-Training Data Processing to Every Language](https://arxiv.org/abs/2506.20920)
> *FineWeb2: 一个可扩展所有语言的管道——将预训练数据处理适应到每种语言*

*Guilherme Penedo, Hynek Kydlíček, Vinko Sabolčec, Bettina Messmer, Negar Foroutan, Amir Hossein Kargaran, Colin Raffel, Martin Jaggi, Leandro Von Werra, Thomas Wolf* | **Category: cs.CL**

**Keywords:** 多语言LLM, 预训练数据, 数据整理, FineWeb2, 语言适应, 数据集重新平衡

**Comment:** 

> **TL;DR:** 该论文介绍了FineWeb2，一个用于创建高质量多语言预训练数据集的新数据管道，能够适应1000多种语言，并展示了其能提高模型性能。

**AI_Comments:** 该论文通过提供一个可扩展且语言无关的数据处理管道，对多语言LLM预训练领域做出了重要贡献。其自动适应能力和有原则的重新平衡方法具有创新性，解决了开发超越英语的高性能LLM的关键瓶颈。大规模FineWeb2数据集和相关代码库的发布对于开源社区来说非常有价值，将促进多语言AI领域的进一步研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 尽管高质量英语预训练数据集的开放开发取得了显著进展，但训练高性能多语言大型语言模型（LLM）仍然是一个挑战，主要原因是为大量语言定制过滤和去重管道存在固有的困难。

**Method:** 该研究引入了一种基于FineWeb的新型预训练数据整理管道，该管道能够自动适应并支持任何语言。通过在一组九种不同语言上广泛消融管道设计选择，并基于可衡量标准选择评估任务，验证了其有效性。此外，还引入了一种直接且有原则的数据集重新平衡方法，该方法同时考虑了重复计数和质量。最终，该管道被扩展到1000多种语言，使用了近100个Common Crawl快照，从而生成了FineWeb2数据集。

**Result:** 该管道能够创建非英语语料库，这些语料库产生的模型比现有数据集性能更高。所引入的数据集重新平衡方法提供了额外的性能提升。最终生成了FineWeb2，一个20TB（50亿文档）的多语言数据集，并随同管道、训练和评估代码库一起发布。

**Conclusion:** 该论文成功开发并扩展了一个语言无关的管道FineWeb2，用于创建高质量的多语言预训练数据集，显著提高了跨多种语言的LLM性能，并开源了数据集和相关代码库。

> **ai_Abstract:** 该论文提出了FineWeb2，一个新颖的、语言无关的预训练数据整理管道，旨在克服为大型语言模型（LLM）创建高质量多语言数据集的挑战。该管道基于FineWeb，能够自动调整过滤和去重过程以适应任何语言。通过对九种语言进行广泛的消融研究和引入新的数据集重新平衡技术，作者证明FineWeb2生成的非英语语料库能够使模型性能优于现有数据集。该管道已扩展到1000多种语言，生成了20TB、50亿文档的FineWeb2数据集，并随管道和代码库一起发布。

> **摘要翻译:** 预训练最先进的大型语言模型（LLM）需要大量干净多样化的文本数据。虽然高质量英语预训练数据集的开放开发最近取得了实质性进展，但训练高性能多语言LLM仍然是一个挑战，这主要是由于为大量语言定制过滤和去重管道固有的困难。在这项工作中，我们引入了一种基于FineWeb的新预训练数据集整理管道，该管道可以自动适应以支持任何语言。我们在一组九种不同语言上广泛消融了我们的管道设计选择，这些选择由一套有意义且信息丰富的评估任务指导，这些任务是通过基于可衡量标准的新颖选择过程选定的。最终，我们表明我们的管道可用于创建非英语语料库，这些语料库产生的模型比以前的数据集性能更高。我们还引入了一种直接且有原则的方法来重新平衡数据集，该方法考虑了重复计数和质量，从而提供了额外的性能提升。最后，我们使用近100个Common Crawl快照将我们的管道扩展到1000多种语言，从而生成了FineWeb2，这是一个新的20TB（50亿文档）多语言数据集，我们将其与我们的管道、训练和评估代码库一起发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [191] [KaLM-Embedding-V2: Superior Training Techniques and Data Inspire A Versatile Embedding Model](https://arxiv.org/abs/2506.20923)
> *KaLM-Embedding-V2：卓越的训练技术和数据启发了多功能嵌入模型*

*Xinping Zhao, Xinshuo Hu, Zifei Shan, Shouzheng Huang, Yao Zhou, Zetian Sun, Zhenyu Liu, Dongfang Li, Xinyuan Wei, Qian Chen, Youcheng Pan, Yang Xiang, Meishan Zhang, Haofen Wang, Jun Yu, Baotian Hu, Min Zhang* | **Category: cs.CL**

**Keywords:** 文本嵌入, KaLM-Embedding-V2, 多阶段训练, Transformer, 难负样本

**Comment:** Technical Report; 26 pages 12 tables 1 figure. arXiv admin note:
  substantial text overlap with arXiv:2501.01028

> **TL;DR:** KaLM-Embedding-V2通过优越的训练技术和大规模数据，实现了在通用文本嵌入任务中超越同类模型并媲美大型模型的性能，设定了紧凑型嵌入模型的新标准。

**AI_Comments:** 这篇论文通过结合架构创新（全双向Transformer）、精细的多阶段训练流程（预训练、微调、模型融合）、先进的学习策略（焦点重加权、在线难负样本）以及大规模多样化数据，成功地构建了一个在性能和效率之间取得极佳平衡的嵌入模型。其创新性在于将多种先进技术有效整合，显著提升了紧凑型模型的竞争力，使其能够与大型模型匹敌，这对于资源受限的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过利用卓越的训练技术和数据，开发一个多功能且紧凑的文本嵌入模型，以在通用文本嵌入任务中取得令人印象深刻的性能。

**Method:** 该模型通过以下创新实现：1) 架构改进，移除因果注意力掩码，采用全双向Transformer和均值池化生成固定长度嵌入。2) 多阶段训练流程，包括在大规模弱监督开源语料库上预训练，在高质量检索和非检索数据集上微调，以及使用模型融合（model-soup）进行参数平均以增强泛化能力。3) 引入焦点式重加权机制以集中学习困难样本，并采用在线难负样本混合策略持续丰富难负样本。4) 收集超过20类数据用于预训练，100类数据用于微调，以提升性能和泛化能力。

**Result:** 在海量文本嵌入基准（MTEB）中文和英文评估中，KaLM-Embedding-V2显著优于同等大小的其他模型，并能与3倍、14倍、18倍和26倍大的嵌入模型竞争，为参数小于1B的多功能紧凑型嵌入模型树立了新标准。

**Conclusion:** KaLM-Embedding-V2通过其创新的架构、多阶段训练方法、先进的学习策略和丰富的数据集，成功地在通用文本嵌入任务中实现了卓越的性能，并为紧凑型嵌入模型设立了新基准，证明了优越的训练技术和数据在构建高效能模型中的关键作用。

> **ai_Abstract:** KaLM-Embedding-V2是一种紧凑且多功能的文本嵌入模型，通过优化架构（全双向Transformer和均值池化）、采用多阶段训练（预训练、微调、模型融合）、引入焦点式重加权和在线难负样本混合策略，并利用大规模多样化数据集进行训练。该模型在MTEB中英文基准测试中表现出色，超越了同等大小的模型，并能与远大于其参数量的模型相媲美，为紧凑型高性能嵌入模型树立了新标准。

> **摘要翻译:** 在本文中，我们提出了KaLM-Embedding-V2，一个多功能且紧凑的嵌入模型，它通过利用卓越的训练技术和数据，在通用文本嵌入任务中取得了令人印象深刻的性能。我们的主要创新包括：(1) 为了更好地使架构与表示学习对齐，我们移除了因果注意力掩码，并采用了带有简单而有效的均值池化的全双向Transformer，以生成固定长度的嵌入；(2) 我们采用了多阶段训练流程：(i) 在大规模弱监督开源语料库上进行预训练；(ii) 在高质量检索和非检索数据集上进行微调；以及 (iii) 使用模型融合（model-soup）参数平均以实现鲁棒的泛化能力。此外，我们引入了一种焦点式重加权机制，将学习集中在困难样本上，以及一种在线难负样本混合策略，无需昂贵的离线挖掘即可持续丰富难负样本；(3) 我们收集了超过20类数据用于预训练，100类数据用于微调，以提升嵌入模型的性能和泛化能力。在海量文本嵌入基准（MTEB）中文和英文上的广泛评估表明，我们的模型显著优于同等大小的其他模型，并能与3倍、14倍、18倍和26倍大的嵌入模型竞争，为参数小于1B的多功能紧凑型嵌入模型树立了新标准。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [204] [Prompt-Guided Turn-Taking Prediction](https://arxiv.org/abs/2506.21191)
> *提示词引导的对话轮次预测*

*Koji Inoue, Mikey Elmers, Yahui Fu, Zi Haur Pang, Divesh Lala, Keiko Ochi, Tatsuya Kawahara* | **Category: cs.CL, cs.SD, eess.AS**

**Keywords:** 轮次预测, 文本提示, Transformer, 语音活动预测, 对话系统

**Comment:** This paper has been accepted for presentation at SIGdial Meeting on
  Discourse and Dialogue 2025 (SIGDIAL 2025) and represents the author's
  version of the work

> **TL;DR:** 该研究提出了一种基于Transformer的新型对话轮次预测模型，该模型可以通过文本提示（如“更快”、“更平静”）进行动态控制，提高了预测准确性并能有效调整轮次转换时机。

**AI_Comments:** 该研究的创新之处在于引入了通过文本提示动态、直观地控制对话轮次转换的能力，这对于构建更自然、更具适应性的对话系统具有重要意义。此外，利用大型语言模型生成合成提示数据，也为解决特定类型数据稀缺问题提供了一种实用的方法。

<details>
  <summary>Details</summary>

**Motivation:** 对话轮次预测模型是语音对话系统和会话机器人中的重要组成部分。当前的方法虽然利用基于Transformer的架构实时连续预测语音活动，但缺乏通过直观指令进行动态控制的能力。本研究旨在解决这一问题，通过文本提示实现对轮次预测的动态控制。

**Method:** 本研究提出了一种新模型，它建立在基于Transformer的语音活动预测（VAP）模型之上，并将文本提示嵌入到通道内Transformer和跨通道Transformer中。研究利用了超过950小时的人机对话数据进行评估，并由于现有数据集中缺乏文本提示数据，因此使用大型语言模型（LLM）生成了合成提示句。

**Result:** 实验结果表明，所提出的模型提高了预测准确性，并能根据文本提示有效地改变轮次转换的时机行为。

**Conclusion:** 该模型成功实现了通过文本提示动态控制对话轮次预测，提高了准确性和适应性。

> **ai_Abstract:** 本文提出了一种新颖的、基于Transformer的对话轮次预测模型，该模型允许通过“更快”或“更平静”等文本提示进行动态控制。该模型在Transformer-based语音活动预测（VAP）模型的基础上，将文本提示嵌入到通道内和跨通道Transformer中。研究在超过950小时的人机对话数据上进行了评估，并利用大型语言模型生成了合成提示数据。实验结果表明，该模型不仅提高了预测准确性，还能根据文本提示有效调整轮次转换的时机行为。

> **摘要翻译:** 对话轮次预测模型是语音对话系统和会话机器人中的重要组成部分。最近的方法利用基于Transformer的架构来持续实时地预测语音活动。在这项研究中，我们提出了一种新颖的模型，该模型能够通过文本提示动态控制对话轮次预测。这种方法允许通过“更快”或“更平静”等指令进行直观和明确的控制，从而动态适应对话伙伴和上下文。所提出的模型建立在基于Transformer的语音活动预测（VAP）模型之上，将文本提示嵌入到通道内Transformer和跨通道Transformer中。我们使用超过950小时的人机对话数据评估了我们方法的可行性。由于现有数据集中没有可用于所提出方法的文本提示数据，我们利用大型语言模型（LLM）生成了合成提示句。实验结果表明，所提出的模型提高了预测准确性，并能根据文本提示有效地改变对话轮次转换的时机行为。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [205] [A Semi-supervised Scalable Unified Framework for E-commerce Query Classification](https://arxiv.org/abs/2506.21049)
> *电子商务查询分类的半监督可扩展统一框架*

*Chunyuan Yuan, Chong Zhang, Zheng Fang, Ming Pang, Xue Jiang, Changping Peng, Zhangang Lin, Ching Law* | **Category: cs.CL, cs.AI, cs.IR**

**Keywords:** 查询分类, 半监督学习, 统一框架, 电子商务, 信息增强

**Comment:** Accepted by ACL 2025

> **TL;DR:** 提出SSUF半监督统一框架，通过知识、标签和结构增强模块解决电商查询分类中信息不足、依赖点击行为和缺乏统一框架的问题，效果显著优于SOTA模型。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一的半监督框架来解决电商查询分类的多个痛点。其模块化的设计（知识、标签、结构增强）使得框架具有高度的灵活性和可扩展性，能够适应不同的子任务需求。通过减少对后验点击行为的依赖和利用半监督信号，有效缓解了数据稀疏和马太效应问题，对于工业界应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有电商查询分类方法面临查询短、上下文不足、标签间信息无法利用导致先验信息不足的问题；多数方法依赖用户点击行为构建训练样本，导致马太效应；子任务缺乏统一框架，算法优化效率低。

**Method:** 提出半监督可扩展统一框架（SSUF），包含多个增强模块：知识增强模块利用世界知识增强查询表示；标签增强模块利用标签语义和半监督信号减少对后验标签的依赖；结构增强模块基于复杂标签关系增强标签表示。每个模块高度可插拔，可根据子任务增删输入特征。

**Result:** 广泛的离线和在线A/B实验结果表明，SSUF显著优于现有最先进的模型。

**Conclusion:** SSUF有效解决了电商查询分类中的多项挑战，并通过其统一和模块化的设计，实现了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为SSUF的半监督可扩展统一框架，旨在解决电子商务查询分类中存在的查询信息不足、过度依赖用户点击行为以及缺乏统一优化框架的问题。SSUF包含知识增强、标签增强和结构增强三大模块，分别通过引入世界知识、利用标签语义和半监督信号以及增强标签关系表示来提升分类效果。该框架具有高度可插拔性，并经实验证明，其性能显著优于现有先进模型。

> **摘要翻译:** 查询分类，包括意图和类别预测等多个子任务，对电子商务应用至关重要。电子商务查询通常较短且缺乏上下文，并且标签之间的信息无法利用，导致建模的先验信息不足。大多数现有的工业查询分类方法依赖于用户的后验点击行为来构建训练样本，导致马太效应的恶性循环。此外，查询分类的子任务缺乏统一的框架，导致算法优化效率低下。
在本文中，我们提出了一种新颖的半监督可扩展统一框架（SSUF），其中包含多个增强模块，以统一查询分类任务。知识增强模块利用世界知识来增强查询表示，解决查询信息不足的问题。标签增强模块利用标签语义和半监督信号来减少对后验标签的依赖。结构增强模块根据复杂的标签关系增强标签表示。每个模块都高度可插拔，可以根据每个子任务的需要添加或删除输入特征。我们进行了广泛的离线和在线A/B实验，结果表明SSUF显著优于最先进的模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [206] [Can Gradient Descent Simulate Prompting?](https://arxiv.org/abs/2506.20989)
> *梯度下降能否模拟提示？*

*Eric Zhang, Leshem Choshen, Jacob Andreas* | **Category: cs.CL, cs.LG**

**Keywords:** 梯度下降, 提示, 微调, 元学习, 语言模型

**Comment:** 14 pages, 2 figures

> **TL;DR:** 研究表明，通过元训练语言模型，梯度下降可以模拟提示的效果，从而在某些任务上恢复甚至超越提示模型的性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个新颖的元训练框架，使得参数更新（微调）能够模仿提示（prompting）的效果，从而结合了两者的优势。它解决了提示有效但微调成本高的问题，通过让模型学习如何通过梯度更新来“内化”提示信息，这对于理解模型学习机制和开发更高效的语言模型更新方法具有重要意义。特别是，它无需真实标签，仅依赖模型自身的提示预测作为目标，这大大降低了数据需求。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型整合新信息主要有两种方式：提示（prompting）和参数更新（如微调）。尽管提示在泛化和逻辑推理方面更有效，但参数更新没有长期存储成本。本文旨在探讨能否修改模型，使微调能够模拟提示的效果，以结合两者的优势。

**Method:** 本文描述了一种元训练语言模型的方法，使其梯度更新能够模拟对新信息进行条件化的效果。该方法利用基于梯度的元学习工具，但使用语言模型自身提示的预测作为目标，从而无需真实标签。

**Result:** 随后的梯度下降训练恢复了部分（有时是全部）提示模型的性能。具体表现为在“逆转诅咒”任务上显示出改进，并在单次梯度更新后能够回答关于文本段落的问题。

**Conclusion:** 研究结果表明，通过适当的初始化，梯度下降可以具有惊人的表达能力。这些发现为长上下文建模提供了新途径，并深入了解了基于梯度的学习的泛化能力。

> **ai_Abstract:** 本文探讨了梯度下降能否模拟语言模型中提示的效果。研究提出了一种元训练语言模型的方法，使其通过梯度更新模仿提示对新信息的适应。该方法利用基于梯度的元学习，并以模型自身的提示预测为目标，无需真实标签。实验结果显示，通过这种方式，梯度下降训练能恢复提示模型的性能，并在特定任务上展现出改进，表明适当初始化下梯度下降的强大表达能力，为长上下文建模和梯度学习的泛化提供了新见解。

> **摘要翻译:** 语言模型（LM）整合新信息主要有两种方式：改变其提示或改变其参数（例如通过微调）。参数更新不会产生模型更改的长期存储成本。然而，对于许多模型更新而言，提示明显更有效：提示模型可以从单个示例中稳健地泛化，并进行标准微调下不会出现的逻辑推理。那么，模型能否被修改，使得微调能够模拟提示呢？本文描述了一种元训练语言模型的方法，使得梯度更新能够模拟对新信息进行条件化的效果。我们的方法利用了基于梯度的元学习工具，但使用LM自身提示的预测作为目标，从而无需真实标签。随后的梯度下降训练恢复了部分（有时是全部）提示模型的性能——在“逆转诅咒”任务上显示出改进，并在单次梯度更新后回答了关于文本段落的问题。这些结果表明，通过适当的初始化，梯度下降可以具有惊人的表达能力。我们的结果为长上下文建模提供了新途径，并深入了解了基于梯度的学习的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [213] ["What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets](https://arxiv.org/abs/2506.21532)
> *"医生，你好吗？": 分析用户如何在大型会话式AI数据集中寻求健康信息*

*Akshay Paruchuri, Maryam Aziz, Rohit Vartak, Ayman Ali, Best Uchehara, Xin Liu, Ishan Chatterjee, Monica Agrawal* | **Category: cs.CL, cs.AI, cs.CY**

**Keywords:** 健康信息寻求, 大型语言模型, 会话式AI, 医疗聊天机器人, HealthChat-11K

**Comment:** 25 pages, 6 figures, 4 tables, corresponds to initial HealthChat-11K
  dataset release

> **TL;DR:** 本文通过构建HealthChat-11K数据集并结合临床医生分类法，系统研究了用户如何从大型语言模型中寻求健康信息，揭示了上下文不完整、情感行为和诱导奉承等问题，强调了改进LLM在医疗保健支持方面能力的必要性。

**AI_Comments:** 本文通过创建HealthChat-11K这一新颖、大规模且精心策划的数据集，为分析LLM在医疗保健相关对话中的表现做出了重要贡献。该数据集与临床医生驱动的分类法相结合，使得对用户在这一关键领域行为和挑战的系统深入研究成为可能。关于上下文不完整和奉承现象的发现尤为重要，它们直接指出了当前LLM在提供可靠和安全的医疗保健支持方面的不足之处，为未来负责任的医疗AI研究和开发指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 人们越来越多地通过交互式聊天机器人从大型语言模型（LLM）中寻求医疗保健信息，然而这些对话的性质和固有风险在很大程度上仍未被探索。

**Method:** 作者过滤了大规模会话式AI数据集，构建了一个包含1.1万个真实世界对话和2.5万条用户消息的精选数据集HealthChat-11K。随后，他们利用HealthChat-11K和一个由临床医生驱动的分类法，系统地研究了用户在21个不同健康专业领域与LLM互动以寻求医疗保健信息的方式。

**Result:** 分析揭示了用户如何以及为何寻求健康信息的本质，包括常见的交互模式、上下文不完整的情况、情感行为，以及可能诱导奉承的交互（例如，引导性问题）。

**Conclusion:** 研究结果强调了部署为会话式AI的大型语言模型在医疗保健支持能力方面需要改进。

> **ai_Abstract:** 本文旨在探究用户通过聊天机器人从大型语言模型（LLM）获取医疗健康信息的未探索性质和潜在风险。研究人员通过筛选大规模会话式AI数据集，构建了一个名为HealthChat-11K的精选数据集，其中包含1.1万个真实世界的医疗对话。利用此数据集和临床医生驱动的分类法，他们系统地分析了21个健康专业领域中用户的交互行为。分析结果揭示了用户寻求健康信息的方式和原因，识别出诸如上下文不完整、情感行为以及可能诱导LLM产生奉承的交互等问题，从而强调了提升LLM在医疗保健支持能力方面的迫切需求。

> **摘要翻译:** 人们越来越多地通过交互式聊天机器人从大型语言模型（LLM）中寻求医疗保健信息，然而这些对话的性质和固有风险在很大程度上仍未被探索。在本文中，我们过滤了大规模会话式AI数据集，以获得HealthChat-11K，这是一个包含1.1万个真实世界对话和2.5万条用户消息的精选数据集。我们使用HealthChat-11K和一个由临床医生驱动的用户与LLM互动寻求医疗保健信息的分类法，系统地研究了21个不同健康专业领域的用户交互。我们的分析揭示了用户如何以及为何寻求健康信息的本质，例如常见的交互、上下文不完整的情况、情感行为，以及可能导致奉承的交互（例如，引导性问题），这强调了部署为会话式AI的LLM在医疗保健支持能力方面需要改进。获取我们的分析并将其组合成精选数据集的代码和工件可以在这里找到：https://github.com/yahskapar/HealthChat

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [219] [SAC: A Framework for Measuring and Inducing Personality Traits in LLMs with Dynamic Intensity Control](https://arxiv.org/abs/2506.20993)
> *SAC：一种用于测量和诱导大型语言模型人格特质并进行动态强度控制的框架*

*Adithya Chittem, Aishna Shrivastava, Sai Tarun Pendela, Jagat Sesh Challa, Dhruv Kumar* | **Category: cs.CL, cs.AI, cs.HC**

**Keywords:** LLM人格, 16PF模型, SAC框架, 特质强度控制, 人机交互

**Comment:** Under review

> **TL;DR:** 本文提出了SAC框架，通过扩展16PF模型并引入动态强度控制，实现对LLM人格特质更精细的测量和诱导。

**AI_Comments:** 这项工作通过引入16PF模型和动态强度控制机制，显著提升了LLM人格建模的精细度和可控性。特别创新的是其提出的基于形容词的语义锚定和五个强度因子，这为量化和诱导人格特质提供了实用的方法。研究结果表明LLM能够理解并内化复杂的人格结构，这对于开发更具情商和适应性的AI具有重要意义。该框架在医疗、教育等领域的应用潜力巨大，有助于实现更自然、更有效的AI交互。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）人格建模方法主要依赖于粗粒度的“大五”（OCEAN）框架，并且缺乏对特质强度的有效控制机制。

**Method:** 本文通过扩展机器个性清单（MPI）以整合16人格因素（16PF）模型，从而实现了对十六种不同特质的表达性控制。同时，开发了名为特定属性控制（SAC）的结构化框架，用于评估和动态诱导LLM中的特质强度。该方法引入了基于形容词的语义锚定来指导特质强度表达，并利用行为问题在五个强度因子（频率、深度、阈值、努力、意愿）上进行评估。

**Result:** 实验发现，将特质强度建模为连续谱比二元特质切换能产生更一致和可控的个性表达。此外，研究观察到目标特质强度的变化会系统地影响心理学上密切相关的特质，这表明LLM内化了多维人格结构，而非孤立地处理特质。

**Conclusion:** 该工作为医疗保健、教育和面试等领域受控和细致的人机交互开辟了新途径，使我们离真正的类人社交机器更近一步。

> **ai_Abstract:** 本文提出了SAC（特定属性控制）框架，旨在解决现有LLM人格建模方法在特质粒度和强度控制方面的不足。通过将机器个性清单（MPI）扩展至16人格因素（16PF）模型，并引入基于形容词的语义锚定和五个强度因子，SAC实现了对LLM人格特质的精细测量和动态强度诱导。研究表明，连续谱的强度建模比二元切换更有效，且LLM能内化多维人格结构。该工作为实现更 nuanced 的人机交互提供了新途径。

> **摘要翻译:** 大型语言模型（LLM）近年来在广泛领域获得了显著关注。人们也越来越期望它们在交互过程中展现出类人的人格。为了满足这一期望，许多研究提出了通过心理测量评估来建模LLM人格的方法。然而，大多数现有模型面临两个主要限制：它们依赖于“大五”（OCEAN）框架，该框架仅提供粗粒度的人格维度；并且它们缺乏控制特质强度的机制。在本文中，我们通过扩展最初使用“大五”模型的机器个性清单（MPI），以整合16人格因素（16PF）模型来解决这一空白，从而实现对十六种不同特质的表达性控制。我们还开发了一个名为特定属性控制（SAC）的结构化框架，用于评估和动态诱导LLM中的特质强度。我们的方法引入了基于形容词的语义锚定来指导特质强度表达，并利用行为问题在五个强度因子：频率、深度、阈值、努力和意愿上进行评估。通过实验，我们发现将强度建模为连续谱比二元特质切换能产生更一致和可控的个性表达。此外，我们观察到目标特质强度的变化会系统地影响心理学上密切相关的特质，这表明LLM内化了多维人格结构，而不是孤立地处理特质。我们的工作为医疗保健、教育和面试等领域受控和细致的人机交互开辟了新途径，使我们离真正的类人社交机器更近一步。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [231] [Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval](https://arxiv.org/abs/2506.21222)
> *通过句法检索增强大语言模型的自动术语提取*

*Yongchan Chun, Minhyuk Kim, Dongjun Kim, Chanjun Park, Heuiseok Lim* | **Category: cs.CL, cs.IR**

**Keywords:** 自动术语提取, 大型语言模型, 句法检索, 少样本学习, 术语边界

**Comment:** 

> **TL;DR:** 该研究提出了一种基于句法检索的提示策略，用于在少样本设置下使用大型语言模型进行自动术语提取（ATE），并在三个专业ATE基准测试中表现出F1分数提升。

**AI_Comments:** 这篇论文的创新点在于提出了一个新颖的、领域无关的句法检索方法，用于增强LLMs在少样本ATE任务中的表现。它成功地将LLMs的强大能力应用于一个之前未充分探索的领域，并通过强调句法线索的重要性，为未来LLMs在术语提取及相关NLP任务中的应用提供了新的视角和方向。

<details>
  <summary>Details</summary>

**Motivation:** 自动术语提取（ATE）对于机器翻译和信息检索等下游任务至关重要。尽管大型语言模型（LLMs）已显著推动了各种NLP任务，但其在ATE方面的潜力尚未得到充分研究。

**Method:** 本研究提出了一种基于检索的提示策略，在少样本设置下，根据句法而非语义相似性选择演示。这种句法检索方法与领域无关，并为捕获术语边界提供了更可靠的指导。该方法在域内和跨域设置中进行了评估，并分析了查询句子与其检索示例之间的词汇重叠如何影响性能。

**Result:** 在三个专业ATE基准测试上的实验表明，句法检索提高了F1分数。

**Conclusion:** 研究结果强调了在将大型语言模型应用于术语提取任务时，句法线索的重要性。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在自动术语提取（ATE）中的应用潜力，提出了一种新颖的基于句法检索的提示策略。该策略在少样本学习环境下，通过选择句法相似而非语义相似的演示示例，为LLMs提供了更可靠的术语边界识别指导。实验结果表明，该方法在多个ATE基准测试中显著提升了F1分数，突出了句法信息在适应LLMs进行术语提取任务时的关键作用。

> **摘要翻译:** 自动术语提取（ATE）识别领域特定的表达，这些表达对于机器翻译和信息检索等下游任务至关重要。尽管大型语言模型（LLMs）已显著推动了各种NLP任务，但其在ATE方面的潜力尚未得到充分研究。我们提出了一种基于检索的提示策略，在少样本设置下，根据句法而非语义相似性选择演示。这种句法检索方法与领域无关，并为捕获术语边界提供了更可靠的指导。我们在域内和跨域设置中评估了该方法，分析了查询句子与其检索示例之间的词汇重叠如何影响性能。在三个专业ATE基准测试上的实验表明，句法检索提高了F1分数。这些发现强调了在将大型语言模型应用于术语提取任务时，句法线索的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [232] [Large Language Models Acing Chartered Accountancy](https://arxiv.org/abs/2506.21031)
> *大型语言模型在特许会计领域表现出色*

*Jatin Gupta, Akhil Sharma, Saransh Singhania, Mohammad Adnan, Sakshi Deo, Ali Imam Abidi, Keshav Gupta* | **Category: cs.CL, cs.AI**

**Keywords:** 大型语言模型, 特许会计, 金融推理, 基准测试, CA-Ben

**Comment:** Accepted for publication at MoStart 2025: International Conference on
  Digital Transformation in Education and Applications of Artificial
  Intelligence, Bosnia and Herzegovina, 2025

> **TL;DR:** 本研究引入了CA-Ben基准，用于评估大型语言模型在印度特许会计领域的金融、法律和定量推理能力，发现GPT-4o和Claude 3.5 Sonnet表现较好，但在数值计算和法律解释方面仍存在挑战。

**AI_Comments:** 该论文通过引入特定领域的CA-Ben基准，解决了大型语言模型在专业金融（特许会计）领域应用有效性评估的空白。其创新之处在于构建了一个结合金融、法律和定量推理的综合性数据集，并明确指出了当前LLMs在处理复杂数值计算和精确法律解释方面的局限性，为未来LLM在专业领域的优化提供了明确方向。这对于推动LLMs在金融等高风险领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）正在重塑金融实践，但它们在捕捉和应用领域特定金融知识方面的有效性仍不确定。为填补印度金融背景下的关键空白，本研究旨在评估LLMs在特许会计领域的表现。

**Method:** 本研究引入了CA-Ben，一个专门设计用于评估LLMs金融、法律和定量推理能力的特许会计基准。CA-Ben包含来源于印度特许会计师协会（ICAI）严格考试的结构化问答数据集。研究评估了六个主流LLMs（GPT 4o, LLAMA 3.3 70B, LLAMA 3.1 405B, MISTRAL Large, Claude 3.5 Sonnet, 和 Microsoft Phi 4），并采用标准化协议进行评估。

**Result:** 评估结果显示LLMs的性能存在差异，其中Claude 3.5 Sonnet和GPT-4o表现优于其他模型，尤其在概念和法律推理方面。然而，在数值计算和法律解释方面出现了显著挑战。

**Conclusion:** 研究结果强调了当前大型语言模型的优势和局限性，并建议未来通过混合推理和检索增强生成方法进行改进，特别是在定量分析和准确的法律解释方面。

> **ai_Abstract:** 本文介绍了CA-Ben，一个针对印度特许会计领域的全新基准，旨在评估大型语言模型（LLMs）的金融、法律和定量推理能力。该基准的数据集来源于印度特许会计师协会的考试。研究评估了GPT 4o、LLAMA 3.3、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4等六个主流LLMs，发现Claude 3.5 Sonnet和GPT-4o表现出色，尤其在概念和法律推理方面。然而，LLMs在数值计算和法律解释上仍面临挑战，研究建议未来可采用混合推理和检索增强生成方法进行改进。

> **摘要翻译:** 先进的智能系统，特别是大型语言模型（LLMs），正通过自然语言处理（NLP）的进步显著重塑金融实践。然而，这些模型有效捕捉和应用领域特定金融知识的程度仍不确定。为填补广阔的印度金融背景下的关键空白，本文引入了CA-Ben，一个专门设计用于评估LLMs金融、法律和定量推理能力的特许会计基准。CA-Ben包含来源于印度特许会计师协会（ICAI）严格考试的结构化问答数据集，涵盖基础、中级和高级特许会计课程阶段。研究使用标准化协议评估了六个主流LLMs，即GPT 4o、LLAMA 3.3 70B、LLAMA 3.1 405B、MISTRAL Large、Claude 3.5 Sonnet和Microsoft Phi 4。结果显示性能存在差异，其中Claude 3.5 Sonnet和GPT-4o表现优于其他模型，尤其在概念和法律推理方面。在数值计算和法律解释方面出现了显著挑战。研究结果强调了当前LLMs的优势和局限性，并建议未来通过混合推理和检索增强生成方法进行改进，特别是在定量分析和准确的法律解释方面。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [235] [Maintaining MTEB: Towards Long Term Usability and Reproducibility of Embedding Benchmarks](https://arxiv.org/abs/2506.21182)
> *维护MTEB：迈向嵌入基准的长期可用性和可复现性*

*Isaac Chung, Imene Kerboua, Marton Kardos, Roman Solomatin, Kenneth Enevoldsen* | **Category: cs.CL, cs.AI, cs.SE**

**Keywords:** MTEB, 文本嵌入, 基准测试, 可复现性, 工程维护

**Comment:** 

> **TL;DR:** 本文关注MTEB基准的工程维护，以确保其长期可复现性和可用性。

**AI_Comments:** 本文的创新之处在于将重点从基准方法论转移到其工程维护和可持续性上，这对于任何大型、持续发展的评估平台都至关重要。其重要性体现在确保MTEB作为行业标准的长期可靠性和可用性，并为其他基准项目提供了实践经验和指导。

<details>
  <summary>Details</summary>

**Motivation:** MTEB已成为文本嵌入模型的标准评估平台，但需要解决工程方面的问题，以确保其持续的可复现性和可扩展性。

**Method:** 维护健壮的持续集成管道来验证数据集完整性、自动化测试执行和评估基准结果的泛化能力；详细说明增强可复现性和可用性的设计选择；处理社区贡献和扩展基准的策略。

**Result:** 这些工程实践有助于MTEB变得更全面，同时保持质量和相关性。

**Conclusion:** 他们的经验为面临类似挑战的基准维护者提供了宝贵的见解，以确保机器学习评估框架的可复现性和可用性。

> **ai_Abstract:** 本文探讨了大规模文本嵌入基准（MTEB）的工程维护，旨在确保其长期可用性和可复现性。作者详细介绍了建立健壮的持续集成管道、优化设计选择以及管理社区贡献的策略，这些措施共同提升了基准的质量、广度和相关性。研究经验为其他机器学习评估框架的维护者提供了宝贵参考。

> **摘要翻译:** 大规模文本嵌入基准（MTEB）已成为文本嵌入模型的标准评估平台。虽然之前的工作已经建立了核心基准方法，但本文侧重于确保MTEB持续可复现性和可扩展性的工程方面。我们介绍了我们维护健壮的持续集成管道的方法，这些管道验证数据集完整性、自动化测试执行并评估基准结果的泛化能力。我们详细介绍了共同增强可复现性和可用性的设计选择。此外，我们讨论了处理社区贡献以及用新任务和数据集扩展基准的策略。这些工程实践在使MTEB变得更全面、同时保持质量并最终保持该领域的相关性方面发挥了重要作用。我们的经验为面临类似挑战的基准维护者提供了宝贵的见解，以确保机器学习评估框架中的可复现性和可用性。MTEB存储库可在：https://github.com/embeddings-benchmark/mteb 访问。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [243] [Small Encoders Can Rival Large Decoders in Detecting Groundedness](https://arxiv.org/abs/2506.21288)
> *小型编码器在检测“接地性”方面可与大型解码器媲美*

*Istabrak Abbes, Gabriele Prato, Quentin Fournier, Fernando Rodriguez, Alaa Boukhary, Adam Elwood, Sarath Chandar* | **Category: cs.CL, cs.AI, cs.IR, cs.LG**

**Keywords:** 接地性检测, 大型语言模型, 轻量级编码器, RoBERTa, NomicBERT, 幻觉

**Comment:** 

> **TL;DR:** 研究表明，轻量级编码器模型在检测大型语言模型（LLMs）回答的“接地性”（即是否基于给定上下文）方面，能达到与最先进LLMs相当的准确度，同时大幅降低推理时间和资源消耗。

**AI_Comments:** 这篇论文的创新点在于证明了在特定任务（接地性检测）上，轻量级编码器模型可以与大型、资源密集型的LLMs相媲美，甚至在效率上远超LLMs。这对于实际部署和资源受限的应用具有重要意义，提供了一种成本效益高的解决方案来提高LLM的可靠性和一致性。它挑战了“越大越好”的普遍观念，并为LLM应用中的“幻觉”问题提供了一个实用的预处理方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在处理外部上下文时表现出色，但当上下文信息不足时，它们容易产生不基于事实的推测或使用内部知识，导致“幻觉”问题。为了确保事实一致性和可信度，“接地性”（即回答严格基于上下文）至关重要。因此，在LLM生成答案之前检测查询的“接地性”可以显著减少推理时间和资源消耗。

**Method:** 本研究通过在精选数据集上微调轻量级、任务特定的编码器模型（如RoBERTa和NomicBERT），来检测给定查询是否基于提供的文档。

**Result:** 结果显示，与Llama3 8B和GPT4o等最先进的LLM相比，这些轻量级编码器模型在接地性检测方面达到了可媲美的准确度，同时将推理延迟降低了几个数量级。

**Conclusion:** 轻量级、任务特定的编码器模型可以作为高效且准确的替代方案，用于在昂贵的LLM答案生成之前检测查询的“接地性”。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLMs）在上下文信息不足时容易产生“幻觉”的问题，提出在LLM生成回答前检测查询的“接地性”。研究发现，通过在精选数据集上微调轻量级编码器模型（如RoBERTa和NomicBERT），可以在接地性检测任务上达到与先进LLMs（如Llama3 8B和GPT4o）相当的准确度，同时大幅度降低推理时间和资源消耗，证明小型编码器是更高效的选择。

> **摘要翻译:** 将大型语言模型（LLM）与外部上下文结合显著提升了它们在自然语言处理（NLP）任务中的性能。然而，当提供的上下文信息不足时，LLM难以可靠地回答查询，常常诉诸于不基于事实的推测或内部知识。“接地性”（即生成严格由上下文支持的回答）对于确保事实一致性和可信度至关重要。本研究侧重于在LLM进行昂贵的答案生成之前，检测给定查询是否基于提供的文档。这种检测机制可以显著减少推理时间和资源消耗。我们展示了轻量级、任务特定的编码器模型，如RoBERTa和NomicBERT，通过在精选数据集上进行微调，可以在接地性检测方面达到与Llama3 8B和GPT4o等最先进的LLM相当的准确度，同时将推理延迟降低了几个数量级。代码可在：https://github.com/chandarlab/Hallucinate-less 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [245] [Aligning Spoken Dialogue Models from User Interactions](https://arxiv.org/abs/2506.21463)
> *从用户交互中对齐语音对话模型*

*Anne Wu, Laurent Mazaré, Neil Zeghidour, Alexandre Défossez* | **Category: cs.CL, cs.LG, cs.SD, eess.AS**

**Keywords:** 语音对话模型, 偏好对齐, 实时交互, 语音到语音, 用户交互

**Comment:** Accepted at ICML 2025

> **TL;DR:** 本文提出了一个新颖的偏好对齐框架，通过用户交互改进实时语音对话模型。针对现有文本方法不适用于实时语音的复杂性，作者构建了一个包含15万+偏好对的大规模数据集，并使用离线对齐方法微调了一个全双工自回归语音到语音模型。实验证明该方法能有效提升对话模型的真实性、安全性和上下文对齐性，并强调了动态平衡对自然实时语音对话系统的重要性。

**AI_Comments:** 本文的创新点在于提出了一个专门针对实时语音对话的偏好对齐框架，解决了现有文本偏好学习方法无法处理语音交互复杂性的问题。通过构建大规模的语音偏好数据集和微调全双工语音到语音模型，为提升语音对话系统的自然度和实用性提供了有效途径。其对“各种动态之间平衡”的强调，对于未来语音AI系统的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前偏好学习方法主要集中于文本语言模型，不直接适用于实时语音交互的复杂性，例如更丰富的动态（如打断、插话）以及说话者轮次之间没有明确的分割。因此，需要一种新的框架来改善实时对话中的语音对话模型。

**Method:** 本文提出了一个新颖的偏好对齐框架。首先，构建了一个包含超过15万个偏好对的大规模数据集，这些数据来源于原始多轮语音对话，并用AI反馈进行标注，以覆盖语言内容和时间上下文的偏好。接着，利用离线对齐方法对一个全双工自回归语音到语音模型进行微调。最后，部署微调后的模型并进行整体的人工评估，以评估其在单轮对话之外的影响。

**Result:** 广泛的实验表明，对通用对话的反馈可以持续有效地改进语音对话模型，使其产生更真实、更安全、更符合上下文的交互。人工评估也证实了其在多轮对话中的积极影响。

**Conclusion:** 研究结果揭示了在各种动态之间实现良好平衡的重要性，这对于自然的实时语音对话系统至关重要。

> **ai_Abstract:** 本文提出了一种新颖的偏好对齐框架，旨在通过用户交互提升实时语音对话模型的性能。针对现有文本偏好学习方法在处理实时语音复杂性方面的不足，研究者构建了一个包含超过15万个偏好对的大规模数据集，并利用离线对齐技术对一个全双工自回归语音到语音模型进行了微调。实验结果表明，该方法能够有效提升语音对话模型的真实性、安全性及上下文对齐能力。研究强调了在各种对话动态之间实现平衡对于构建自然实时语音对话系统的重要性。

> **摘要翻译:** 我们提出了一个新颖的偏好对齐框架，旨在通过用户交互改进实时对话中的语音对话模型。当前的偏好学习方法主要关注基于文本的语言模型，不直接适用于实时语音交互的复杂性，后者具有更丰富的动态（例如打断、插话）且说话者轮次之间没有明确的分割。我们从原始多轮语音对话中创建了一个包含超过15万个偏好对的大规模数据集，并用AI反馈进行标注，以覆盖语言内容和时间上下文的偏好。我们利用离线对齐方法对一个全双工自回归语音到语音模型进行微调。广泛的实验表明，对通用对话的反馈可以持续有效地改进语音对话模型，使其产生更真实、更安全、更符合上下文的交互。我们部署了微调后的模型并进行了整体的人工评估，以评估其在单轮对话之外的影响。我们的发现揭示了在各种动态之间实现良好平衡的重要性，这对于自然的实时语音对话系统至关重要。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [252] [Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21384)
> *利用LLM辅助查询理解实现实时检索增强生成*

*Guanting Dong, Xiaoxi Li, Yuyao Zhang, Mengjie Deng* | **Category: cs.CL, cs.AI, cs.IR**

**Keywords:** RAG, 大型语言模型, 查询理解, 检索增强生成, 实时系统

**Comment:** Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)

> **TL;DR:** Omni-RAG是一个利用LLM辅助查询理解的框架，旨在提高实时RAG系统处理复杂和嘈杂查询的鲁棒性和有效性。

**AI_Comments:** Omni-RAG的创新点在于其多模块的LLM辅助查询理解方法，特别是将复杂查询分解为结构化子查询的能力，这对于提高RAG系统在真实世界嘈杂环境中的表现至关重要。该框架通过整合去噪、分解、意图感知检索和重排序等步骤，提供了一个全面的解决方案，以应对现有RAG系统处理复杂输入的局限性。其重要性体现在其直接针对LiveRAG挑战等实际应用需求，有望推动RAG技术在实际部署中的发展。

<details>
  <summary>Details</summary>

**Motivation:** 实时检索增强生成（RAG）系统在处理嘈杂、模糊和多意图的用户查询时面临巨大挑战，因为现有系统通常在更干净的数据上训练或评估，难以应对复杂的输入。

**Method:** 论文提出了Omni-RAG框架，通过LLM辅助查询理解来预处理用户输入。该框架包含三个核心模块：1) 深度查询理解与分解，利用LLM和定制提示进行查询去噪并将多意图查询分解为结构化子查询；2) 意图感知知识检索，对每个子查询从语料库中执行检索并聚合结果；3) 重排序与生成，使用重排序器优化文档选择，然后LLM利用思维链提示生成最终响应。

**Result:** Not mentioned in abstract

**Conclusion:** Omni-RAG框架通过LLM辅助的查询理解，能够鲁棒地处理复杂和嘈杂的查询，从而弥合了当前RAG系统能力与实时开放域应用需求之间的差距。

> **ai_Abstract:** 本文提出了一种名为Omni-RAG的新型框架，旨在解决实时RAG系统在处理嘈杂、模糊和多意图用户查询时面临的挑战。Omni-RAG通过LLM辅助的查询理解，包含深度查询理解与分解、意图感知知识检索以及重排序与生成三个模块，从而能够有效去噪、分解复杂查询、进行精准检索并生成高质量响应，以提升RAG系统在真实世界开放域环境中的鲁棒性和有效性。

> **摘要翻译:** 实时检索增强生成（RAG）系统在处理通常嘈杂、模糊且包含多个意图的用户查询时面临重大挑战。尽管RAG通过外部知识增强大型语言模型（LLMs），但当前系统通常难以处理此类复杂输入，因为它们通常在更干净的数据上进行训练或评估。本文介绍了一种新颖的框架Omni-RAG，旨在提高RAG系统在实时、开放域环境中的鲁棒性和有效性。Omni-RAG采用LLM辅助的查询理解，通过三个关键模块预处理用户输入：(1) 深度查询理解与分解，该模块利用LLM和定制提示来消除查询中的噪声（例如，纠正拼写错误）并将多意图查询分解为结构化子查询；(2) 意图感知知识检索，该模块对每个子查询从语料库（即使用OpenSearch的FineWeb）中执行检索并聚合结果；(3) 重排序与生成，其中重排序器（即BGE）在LLM（即Falcon-10B）使用思维链提示生成最终响应之前，精炼文档选择。Omni-RAG旨在通过鲁棒地处理复杂和嘈杂的查询，弥合当前RAG能力与实际应用需求之间的差距，例如SIGIR 2025 LiveRAG挑战赛所强调的需求。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [253] [MT2-CSD: A New Dataset and Multi-Semantic Knowledge Fusion Method for Conversational Stance Detection](https://arxiv.org/abs/2506.21053)
> *MT2-CSD：一种用于会话立场检测的新数据集和多语义知识融合方法*

*Fuqiang Niu, Genan Dai, Yisha Lu, Jiayu Liao, Xiang Li, Hu Huang, Bowen Zhang* | **Category: cs.CL**

**Keywords:** 会话立场检测, MT2-CSD, LLM-CRAN, 大型语言模型, 数据集

**Comment:** 

> **TL;DR:** 本文介绍了MT2-CSD，一个用于多目标、多轮会话立场检测的大型数据集，并提出了LLM-CRAN模型，该模型利用大型语言模型提升会话理解能力，在MT2-CSD数据集上表现优于现有基线模型。

**AI_Comments:** 该论文的创新点在于构建了迄今为止最大的多目标、多轮会话立场检测数据集MT2-CSD，解决了该领域长期存在的数据稀缺问题。同时，提出的LLM-CRAN模型巧妙地结合了大型语言模型的推理能力，为会话理解和立场检测提供了新的视角和有效方法。其重要性在于推动了会话立场检测领域的研究进展，为更真实、更复杂的社交媒体互动分析提供了基础数据和高性能模型。

<details>
  <summary>Details</summary>

**Motivation:** 在当代社交媒体中，自动立场检测对于意见挖掘至关重要，但传统研究主要针对独立实例，限制了其对多方讨论的建模能力。这一不足主要源于缺乏真实捕捉社交媒体互动动态的数据集，阻碍了会话立场检测的进展。

**Method:** 本文介绍了MT2-CSD，一个用于多目标、多轮会话立场检测的综合数据集，其包含24,457个标注实例，具有最大的会话深度。为解决挑战，提出了大型语言模型增强的会话关系注意力网络（LLM-CRAN），利用LLM的推理能力改进会话理解。

**Result:** 实验结果表明，LLM-CRAN在会话立场检测任务中显著优于强大的基线模型。

**Conclusion:** 本文引入了迄今为止最大的会话立场检测数据集MT2-CSD，并提出了LLM-CRAN模型，该模型利用LLM的推理能力有效提升了会话理解和立场检测性能，解决了现有数据集稀缺和模型能力不足的问题。

> **ai_Abstract:** 本文针对社交媒体中会话立场检测的数据集稀缺和模型能力不足问题，提出了MT2-CSD，一个迄今为止最大的多目标、多轮会话立场检测数据集。为应对数据集带来的新挑战，研究引入了LLM-CRAN模型，该模型通过利用大型语言模型（LLM）的推理能力来增强会话理解。实验证明，LLM-CRAN在MT2-CSD数据集上的表现显著优于现有的强基线模型。

> **摘要翻译:** 在当代社交媒体领域，自动立场检测对于意见挖掘至关重要，因为它综合并审查用户对有争议话题的观点，以揭示主流趋势和情绪。传统的立场检测研究通常针对单个实例，从而限制了其对真实社交媒体场景中典型的多方讨论进行建模的能力。这一缺点主要源于缺乏真实捕捉社交媒体互动动态的数据集，阻碍了会话立场检测的进展。在本文中，我们介绍了MT2-CSD，一个用于多目标、多轮会话立场检测的综合数据集。据我们所知，MT2-CSD是目前用于此目的的最大数据集，包含24,457个标注实例，并展现出最大的会话深度，从而为立场检测带来了新的挑战。为了应对这些挑战，我们提出了大型语言模型增强的会话关系注意力网络（LLM-CRAN），该网络利用LLM的推理能力来改善会话理解。我们进行了广泛的实验来评估LLM-CRAN在MT2-CSD数据集上的有效性。实验结果表明，LLM-CRAN在会话立场检测任务中显著优于强大的基线模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [260] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
> *CBF-AFA：基于分块的多自监督学习融合用于自动流利度评估*

*Papa Séga Wade, Mihai Andries, Ioannis Kanellos, Thierry Moudenc* | **Category: cs.CL, cs.AI, eess.AS**

**Keywords:** 自动流利度评估, 自监督学习, 语音分块, 多模态融合, 深度学习

**Comment:** 5 pages, accepted for presentation at EUSIPCO 2025

> **TL;DR:** CBF-AFA提出了一种基于分块的多自监督学习（SSL）融合方法，用于自动流利度评估，通过整合Wav2Vec2、HuBERT和WavLM模型并结合分层CNN-BiLSTM框架，显著提高了非母语使用者流利度评估的准确性。

**AI_Comments:** 该论文的创新点在于提出了基于分块的多自监督学习融合方法，有效结合了不同SSL模型的互补优势，并通过分层网络和细粒度特征增强，显著提升了自动流利度评估的性能。其在处理非母语使用者语音特点方面的表现尤为突出，具有重要的实际应用价值。未来的工作可以进一步探索其在不同方言和更复杂语境下的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 自动流利度评估（AFA）仍然具有挑战性，尤其是在捕捉非母语使用者的语速、停顿和不流利现象方面。

**Method:** 本文提出了一种基于分块的方法，将Wav2Vec2、HuBERT和WavLM等自监督学习（SSL）模型与分层CNN-BiLSTM框架集成。语音通过Silero语音活动检测（Silero-VAD）被分割成呼吸组分块，以实现细粒度时间分析并减少过度分割伪影。SSL嵌入通过可学习的加权机制融合，平衡声学和语言特征，并辅以分块级的流利度标记（如语速、停顿持续时间、n-gram重复）。CNN-BiLSTM用于捕捉分块之间的局部和长期依赖关系。

**Result:** 在Avalinguo和Speechocean762数据集上进行评估，与单SSL基线相比，我们的方法在Speechocean762上F1分数提高了2.8点，Pearson相关性提高了6.2点；在Avalinguo上F1分数提高了4.2点，Pearson相关性提高了4.0点，并且超越了基于Pyannote.audio的分割基线。

**Conclusion:** 这些发现突出了基于分块的多SSL融合在鲁棒流利度评估中的有效性，尽管未来的工作应探索其在具有不规则韵律的方言上的泛化能力。

> **ai_Abstract:** 本文提出CBF-AFA，一种用于自动流利度评估的基于分块的多自监督学习（SSL）融合方法。该方法将Wav2Vec2、HuBERT和WavLM等SSL模型与分层CNN-BiLSTM框架结合，通过Silero-VAD将语音分割成呼吸组分块进行细粒度分析。SSL嵌入通过加权机制融合，并结合分块级流利度标记。实验结果表明，该方法在Avalinguo和Speechocean762数据集上均显著优于单SSL基线和基于Pyannote.audio的分割基线，验证了其在鲁棒流利度评估方面的有效性。

> **摘要翻译:** 自动流利度评估（AFA）仍然具有挑战性，尤其是在捕捉非母语使用者的语速、停顿和不流利现象方面。我们引入了一种基于分块的方法，该方法集成了自监督学习（SSL）模型（Wav2Vec2、HuBERT和WavLM），这些模型因其在语音、韵律和嘈杂语音建模方面的互补优势而被选择，并结合了分层CNN-BiLSTM框架。语音使用Silero语音活动检测（Silero-VAD）被分割成呼吸组分块，从而实现细粒度时间分析，同时减轻过度分割的伪影。SSL嵌入通过可学习的加权机制进行融合，平衡声学和语言特征，并辅以分块级的流利度标记（例如，语速、停顿持续时间、n-gram重复）。CNN-BiLSTM捕捉分块之间的局部和长期依赖关系。在Avalinguo和Speechocean762数据集上进行评估，与单SSL基线相比，我们的方法在Speechocean762上F1分数提高了2.8点，Pearson相关性提高了6.2点，在Avalinguo上F1分数提高了4.2点，Pearson相关性提高了4.0点，并且超越了基于Pyannote.audio的分割基线。这些发现突出了基于分块的多SSL融合在鲁棒流利度评估中的有效性，尽管未来的工作应探索其在具有不规则韵律的方言上的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [261] [Text2Cypher Across Languages: Evaluating Foundational Models Beyond English](https://arxiv.org/abs/2506.21445)
> *跨语言Text2Cypher：评估超越英语的基础模型*

*Makbule Gulcin Ozsoy, William Tai* | **Category: cs.CL, cs.IR**

**Keywords:** Text2Cypher, 多语言, 基础模型, 数据库查询, 跨语言评估

**Comment:** 

> **TL;DR:** 研究评估了基础LLM在多语言Text2Cypher任务上的表现，发现英语表现最好，西班牙语次之，土耳其语最差，并发布了多语言测试集。

**AI_Comments:** 这篇论文通过创建多语言测试集并评估基础模型在Text2Cypher任务上的表现，填补了现有研究主要集中于英语的空白，具有重要的创新性。其发现揭示了不同语言间性能差异的原因，并指出了未来多语言查询生成领域发展方向，对提升数据库可访问性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注英语的自然语言到数据库查询转换（如Text2Cypher），而对其他语言的评估有限，因此需要调查基础LLM在多语言Text2Cypher任务上的性能。

**Method:** 创建并发布了一个多语言测试集，通过将英语问题翻译成西班牙语和土耳其语，同时保留原始Cypher查询，以实现公平的跨语言比较。使用标准化提示和指标评估了多个基础模型。

**Result:** 结果显示一致的性能模式：英语最高，其次是西班牙语，土耳其语最低。这归因于训练数据可用性和语言特征的差异。此外，将任务提示翻译成西班牙语和土耳其语对评估指标几乎没有影响，表明提示翻译影响很小。

**Conclusion:** 研究结果强调了在多语言查询生成中进行更具包容性的评估和开发的必要性。未来的工作包括模式本地化和跨不同语言的微调。

> **ai_Abstract:** 本文研究了基础大型语言模型在多语言Text2Cypher任务上的表现，旨在弥补现有研究主要集中于英语的不足。研究构建了一个包含英语、西班牙语和土耳其语的跨语言测试集，并评估了多个基础模型。结果显示，模型性能在英语上最高，西班牙语次之，土耳其语最低，这与训练数据和语言特性有关。此外，研究发现提示翻译对性能影响不大。论文强调了未来在多语言查询生成领域需要更具包容性的评估和开发。

> **摘要翻译:** 大型语言模型的最新进展使得自然语言接口能够将用户问题翻译成数据库查询，例如Text2SQL、Text2SPARQL和Text2Cypher。虽然这些接口增强了数据库的可访问性，但目前大多数研究仅关注英语，对其他语言的评估有限。本文研究了基础LLM在多语言Text2Cypher任务上的性能。我们通过将英语问题翻译成西班牙语和土耳其语，同时保留原始Cypher查询，创建并发布了一个多语言测试集，从而实现了公平的跨语言比较。我们使用标准化提示和指标评估了多个基础模型。我们的结果显示出一致的性能模式：英语表现最高，其次是西班牙语，土耳其语最低。我们将其归因于训练数据可用性和语言特征的差异。此外，我们探讨了将任务提示翻译成西班牙语和土耳其语的影响。结果显示评估指标几乎没有变化，表明提示翻译影响很小。我们的发现强调了在多语言查询生成中进行更具包容性的评估和开发的必要性。未来的工作包括模式本地化和跨不同语言的微调。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [262] [DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning](https://arxiv.org/abs/2506.21096)
> *DALR：用于多模态句子表示学习的双层对齐学习*

*Kang He, Yuzhe Ding. Haining Wang, Fei Li, Chong Teng, Donghong Ji* | **Category: cs.CL**

**Keywords:** 多模态学习, 句子表示, 对齐学习, 语义相似度, 排序蒸馏

**Comment:** Accepted by ACL 2025 Findings

> **TL;DR:** DALR提出双层对齐学习框架，通过细粒度跨模态对齐和模态内排序蒸馏解决多模态句子表示学习中的对齐问题，并在STS和TR任务上超越了现有SOTA方法。

**AI_Comments:** DALR的创新点在于其提出的双层对齐学习策略，特别是细粒度跨模态对齐中对负样本的处理和辅助任务的利用，以及模态内对齐中引入排序蒸馏来捕捉更复杂的句子关系。这些方法有效解决了多模态表示学习中的关键挑战，对于提升句子表示质量和多模态理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态句子表示学习方法主要在粗粒度上对齐图像和文本，面临跨模态错位偏差和模态内语义差异两大挑战，严重降低了句子表示质量。

**Method:** 提出DALR（用于多模态句子表示的双层对齐学习）框架。对于跨模态对齐，设计了一致性学习模块，通过软化负样本并利用辅助任务的语义相似性实现细粒度对齐。此外，通过将排序蒸馏与全局模态内对齐学习相结合，以更好地捕捉句子间复杂的排序关系，提升表示质量。

**Result:** 在语义文本相似度（STS）和迁移（TR）任务上的综合实验验证了所提方法的有效性，并持续展现出优于现有最先进基线的性能。

**Conclusion:** DALR框架通过双层对齐学习有效解决了多模态句子表示学习中的挑战，在语义文本相似度（STS）和迁移（TR）任务上均表现出优越性。

> **ai_Abstract:** 本文提出了DALR（双层对齐学习）框架，旨在解决现有多模态句子表示学习方法中粗粒度对齐所导致的跨模态错位偏差和模态内语义差异问题。DALR引入了一致性学习模块，通过软化负样本并利用辅助任务的语义相似性，实现了细粒度跨模态对齐。同时，为了更好地捕捉句子间复杂的排序关系，DALR将排序蒸馏与全局模态内对齐学习相结合。实验结果表明，DALR在语义文本相似度（STS）和迁移（TR）任务上均表现出优于现有先进基线的性能。

> **摘要翻译:** 以前的多模态句子表示学习方法已经取得了令人印象深刻的性能。然而，大多数方法都侧重于在粗粒度级别上对齐图像和文本，面临两个关键挑战：跨模态错位偏差和模态内语义差异，这显著降低了句子表示质量。为了解决这些挑战，我们提出了DALR（用于多模态句子表示的双层对齐学习）。对于跨模态对齐，我们提出了一致性学习模块，该模块软化负样本并利用辅助任务的语义相似性来实现细粒度的跨模态对齐。此外，我们认为句子关系超越了二元正负标签，呈现出更复杂的排序结构。为了更好地捕捉这些关系并提高表示质量，我们将排序蒸馏与全局模态内对齐学习相结合。在语义文本相似度（STS）和迁移（TR）任务上的综合实验验证了我们方法的有效性，并持续展示出其优于最先进基线的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [267] [skLEP: A Slovak General Language Understanding Benchmark](https://arxiv.org/abs/2506.21508)
> *skLEP：一个斯洛伐克通用语言理解基准*

*Marek Šuppa, Andrej Ridzik, Daniel Hládek, Tomáš Javůrek, Viktória Ondrejová, Kristína Sásiková, Martin Tamajka, Marián Šimko* | **Category: cs.CL, cs.AI, cs.IR, cs.LG, 68T50, I.2.7**

**Keywords:** 斯洛伐克语NLU, 语言理解基准, skLEP, 预训练模型, 自然语言处理

**Comment:** ACL 2025 Findings

> **TL;DR:** 引入了skLEP，首个斯洛伐克NLU综合基准，包含9项任务，并评估了多种预训练模型，同时发布了数据和工具以促进研究。

**AI_Comments:** skLEP的创新之处在于它是首个针对斯洛伐克语的综合NLU基准，填补了该领域的一个空白。其重要性体现在它为斯洛伐克语NLU模型提供了一个标准化的评估框架，并通过发布数据和工具促进了社区研究。这对于低资源语言的NLP发展尤为关键。

<details>
  <summary>Details</summary>

**Motivation:** 现有NLU模型缺乏专门针对斯洛伐克语的综合评估基准。

**Method:** 构建了skLEP，包含9项涵盖词级别、句子对级别和文档级别的多样化任务。策划了新的斯洛伐克语原创数据集，并精心翻译了已有的英语NLU资源。使用skLEP任务系统地评估了多种斯洛伐克语特有、多语言和英语预训练语言模型。发布了完整的基准数据、开源工具包和公共排行榜。

**Result:** 首次对多种斯洛伐克语特有、多语言和英语预训练语言模型进行了系统和广泛的评估。

**Conclusion:** skLEP作为首个斯洛伐克NLU综合基准，通过提供多样化的任务、数据集、评估结果和开源资源，旨在促进斯洛伐克语NLU领域的可复现性并推动未来的研究。

> **ai_Abstract:** 本文推出了skLEP，这是首个专门用于评估斯洛伐克语自然语言理解（NLU）模型的综合基准。skLEP包含九项多样化的任务，涵盖词级别、句子对级别和文档级别挑战，并通过结合原创斯洛伐克语数据集和翻译的英语NLU资源构建。研究人员使用skLEP对斯洛伐克语特有、多语言和英语预训练语言模型进行了首次系统评估。为了促进斯洛伐克语NLU领域的可复现性和研究发展，作者还发布了完整的基准数据、开源工具包和公共排行榜。

> **摘要翻译:** 在这项工作中，我们介绍了skLEP，这是第一个专门为评估斯洛伐克自然语言理解（NLU）模型而设计的综合基准。我们编译了skLEP，使其包含九项涵盖词级别、句子对级别和文档级别挑战的多样化任务，从而提供了对模型能力的全面评估。为了创建这个基准，我们策划了针对斯洛伐克语量身定制的全新原创数据集，并精心翻译了已有的英语NLU资源。在本文中，我们还首次使用skLEP任务对各种斯洛伐克语特有、多语言和英语预训练语言模型进行了系统而广泛的评估。最后，我们还发布了完整的基准数据、一个便于模型微调和评估的开源工具包，以及一个公共排行榜（网址：https://github.com/slovak-nlp/sklep），希望以此促进斯洛伐克NLU领域的可复现性并推动未来的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [268] [ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry](https://arxiv.org/abs/2506.21098)
> *ComRAG：用于工业实时社区问答的动态向量存储检索增强生成*

*Qinwen Chen, Wenbiao Tao, Zhiwei Zhu, Mingfan Xi, Liangzhong Guo, Yuan Wang, Wei Wang, Yunshi Lan* | **Category: cs.CL, cs.AI**

**Keywords:** 社区问答, 检索增强生成, 动态向量存储, 实时CQA, 质心记忆机制

**Comment:** 7 pages, 4 figures. Accepted at ACL 2025 Industry Track

> **TL;DR:** ComRAG是一个新的检索增强生成框架，通过动态向量存储和基于质心的记忆机制，显著提高了工业实时社区问答的性能和效率。

**AI_Comments:** ComRAG的创新之处在于其动态向量存储和基于质心的记忆机制，这使其能够有效处理实时变化的社区问答数据，并显著提升了工业应用中的效率和性能。它解决了现有RAG系统在动态知识更新和存储效率方面的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有社区问答（CQA）方法在实时利用历史交互和领域知识方面存在挑战，常未充分利用外部知识，未能整合动态历史QA上下文，或缺乏适用于工业部署的记忆机制。

**Method:** 本文提出ComRAG，一个用于实时工业CQA的检索增强生成框架。它通过一个为检索、生成和高效存储设计的基于质心的记忆机制，将静态知识与动态历史QA对集成。

**Result:** 在三个工业CQA数据集上，ComRAG持续优于所有基线，向量相似度提高高达25.9%，延迟降低8.7%至23.3%，迭代过程中块增长从20.23%降低到2.06%。

**Conclusion:** ComRAG显著提升了工业实时CQA的性能和效率，解决了现有方法的局限性，特别是在动态知识利用和存储优化方面。

> **ai_Abstract:** 本文提出了ComRAG，一个针对工业实时社区问答（CQA）的检索增强生成框架。该框架通过创新的基于质心的记忆机制，有效整合静态知识和动态历史问答对，以克服现有CQA方法在利用外部知识和动态上下文方面的不足。实验结果表明，ComRAG在向量相似度、延迟和存储效率方面均显著优于现有基线，为工业CQA提供了高效且高性能的解决方案。

> **摘要翻译:** 社区问答 (CQA) 平台可被视为社区中重要的知识库，但如何有效利用历史交互和领域知识仍是一个挑战。现有方法通常未充分利用外部知识，未能整合动态历史问答上下文，或缺乏适用于工业部署的记忆机制。我们提出了 ComRAG，一个用于实时工业 CQA 的检索增强生成框架，它通过一个为检索、生成和高效存储设计的基于质心的记忆机制，将静态知识与动态历史问答对集成。在三个工业 CQA 数据集上的评估显示，ComRAG 持续优于所有基线——向量相似度提高高达 25.9%，延迟降低 8.7% 至 23.3%，并且在迭代过程中块增长从 20.23% 降低到 2.06%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [275] [Progtuning: Progressive Fine-tuning Framework for Transformer-based Language Models](https://arxiv.org/abs/2506.21119)
> *Progtuning：面向Transformer语言模型的渐进式微调框架*

*Xiaoshuang Ji, Zhendong Zhao, Xiaojun Chen, Xin Zhao, Zeyao Liu* | **Category: cs.CL, cs.AI**

**Keywords:** Progtuning, 微调, Transformer, 语言模型, 参数高效

**Comment:** Accepted by ICONIP 2024

> **TL;DR:** Progtuning是一种新的微调框架，通过渐进式地减少更新的Transformer块数量，优化资源分配并减少参数更新，同时保持性能。

**AI_Comments:** Progtuning的创新之处在于引入了渐进式学习的理念，根据Transformer块的贡献度动态调整更新参数的数量，解决了现有微调方法资源分配不均的问题。这种方法在保持性能的同时显著降低了计算成本，对于大型语言模型的实际应用具有重要意义。其与现有参数高效微调方法的兼容性也增强了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有微调和大多数参数高效微调方法在更新参数时忽略了Transformer块间贡献不均，导致计算资源分配效率低下，且随着模型增大，更新所有参数成本高昂。

**Method:** 本文提出了Progtuning，一个结合渐进式学习的微调框架。Progtuning根据Transformer块的贡献，渐进式地减少需要更新的Transformer块数量。

**Result:** Progtuning优化了资源分配，减少了约25%的更新参数，同时保持了有竞争力的性能。它还与参数高效微调方法表现出高适应性，在各种适应场景下表现出色。

**Conclusion:** Progtuning通过渐进式地选择性更新Transformer块，有效解决了大规模语言模型微调中的资源分配效率问题，并在减少参数的同时保持了性能。

> **ai_Abstract:** 本文提出Progtuning，一种针对Transformer语言模型的渐进式微调框架。该方法通过根据贡献度渐进式地减少更新的Transformer块数量，解决了传统微调和参数高效微调方法中资源分配低效的问题。实验结果表明，Progtuning在减少约25%更新参数的同时，仍能保持竞争性性能，并与现有参数高效微调方法具有良好的兼容性。

> **摘要翻译:** 微调是利用基于Transformer的语言模型进行下游任务的一种有前景的技术。随着模型规模的不断增长，更新所有模型参数变得越来越昂贵。参数高效微调方法通过选择性地更新一小部分参数有效地解决了这个问题。然而，微调和大多数现有参数高效微调方法需要更新与初始规模相同数量的参数，忽略了Transformer块之间不平等的贡献，导致计算资源分配极其低效。在本文中，我们提出了Progtuning，这是一种结合渐进式学习的、用于基于Transformer的语言模型的新型微调框架。具体来说，Progtuning根据贡献渐进式地减少更新的Transformer块数量。值得注意的是，Progtuning优化了资源分配，并减少了大约25%的更新参数，同时仍保持了有竞争力的性能。它还与参数高效微调方法表现出高度适应性，在各种适应场景中展示了出色的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [279] [Compressed and Smooth Latent Space for Text Diffusion Modeling](https://arxiv.org/abs/2506.21170)
> *文本扩散建模的压缩平滑潜在空间*

*Viacheslav Meshchaninov, Egor Chimbulatov, Alexander Shabalin, Aleksandr Abramov, Dmitry Vetrov* | **Category: cs.CL**

**Keywords:** 文本扩散建模, 潜在空间, 自动编码器, 文本生成, 推理速度

**Comment:** 

> **TL;DR:** Cosmos是一个新的文本扩散模型，它在一个压缩平滑的潜在空间中操作，实现了更快的推理速度和可比或更优的生成质量。

**AI_Comments:** Cosmos的创新点在于将文本扩散模型引入到一个压缩且平滑的潜在空间中，这有效地克服了高维度表示的挑战，并显著提升了推理速度。该方法为文本生成领域提供了一个新的高效范式，尤其适用于需要并行生成和快速推理的应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 自回归语言模型存在解码速度慢和难以维持全局连贯性的局限性。扩散模型在文本生成中的应用受到token级表示高维度的阻碍。

**Method:** 本文引入了Cosmos，一种在为扩散量身定制的压缩、平滑潜在空间中进行文本生成的新方法。该潜在空间通过一个自动编码器学习，该编码器同时进行token级重建和与预训练语言编码器冻结激活的对齐。

**Result:** 文本表示可以被压缩8倍，同时保持与token级扩散模型相当的生成质量。增加潜在序列长度使Cosmos超越了扩散基线和自回归基线。在故事生成、问题生成、摘要和去毒化等四种生成任务上，Cosmos实现了可比或更优的生成质量，并提供超过2倍的推理速度。

**Conclusion:** Cosmos通过在压缩平滑的潜在空间中进行操作，有效地解决了现有文本生成模型在速度和连贯性方面的局限性，实现了在保持或提升生成质量的同时显著提高推理速度。

> **ai_Abstract:** Cosmos是一种新的文本扩散模型，旨在解决传统自回归模型速度慢和连贯性差的问题，以及扩散模型在高维度文本表示上的挑战。它通过学习一个压缩、平滑的潜在空间来操作，该空间由一个同时进行token级重建和语义对齐的自动编码器生成。实验证明，Cosmos能将文本表示压缩8倍，同时保持生成质量，并在多项生成任务上超越现有基线，推理速度提升超过2倍。

> **摘要翻译:** 自回归语言模型主导了现代文本生成，但其顺序性带来了根本性限制：解码速度慢，且难以保持全局连贯性。扩散模型通过实现并行生成和灵活控制提供了有前景的替代方案；然而，它们在文本生成中的应用受到token级表示高维度的阻碍。我们引入了Cosmos，一种在专门为扩散量身定制的压缩、平滑潜在空间中完全操作的文本生成新方法。这个空间是使用一个自动编码器学习的，该自动编码器同时进行token级重建和与预训练语言编码器冻结激活的对齐，从而提供强大的语义基础并实现有效的基于扰动的增强。经验上，我们证明文本表示可以被压缩8倍，同时保持与token级扩散模型相当的生成质量。此外，增加潜在序列长度使Cosmos超越了基于扩散和自回归的基线。我们在包括故事生成、问题生成、摘要和去毒化在内的四种多样化生成任务上评估了Cosmos，并将其与各种生成范式进行了比较。Cosmos实现了可比或更优的生成质量，同时提供了超过2倍的推理速度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [292] [Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents](https://arxiv.org/abs/2506.21252)
> *Agent-RewardBench：迈向真实世界多模态智能体在感知、规划和安全方面的统一奖励建模基准*

*Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao* | **Category: cs.CL, cs.AI**

**Keywords:** 多模态智能体, 奖励建模, 基准测试, 感知, 规划, 安全

**Comment:** ACL 2025 Main

> **TL;DR:** 提出Agent-RewardBench，一个用于评估多模态大语言模型在真实世界智能体任务中奖励建模能力的统一基准，发现当前模型性能有限，需专门训练。

**AI_Comments:** 该论文提出的Agent-RewardBench填补了多模态智能体奖励建模评估的空白，其多维度、步级评估和高质量数据确保了基准的全面性和有效性。发现现有模型性能不足，为未来研究指明了方向，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在真实世界任务中展现潜力，但缺乏外部反馈导致智能体难以自我纠正和泛化。奖励模型是一个有前景的方法，但缺乏如何为智能体选择奖励模型的明确指导，因此迫切需要构建一个针对智能体的奖励基准。

**Method:** 提出Agent-RewardBench基准。该基准具有三个关键特征：1) 涵盖感知、规划和安全等7个真实世界智能体场景的多维度评估；2) 步级奖励评估，提供更细粒度的性能视图；3) 适当难度和高质量，通过从10个不同模型中采样、难度控制和人工验证确保数据完整性。

**Result:** 实验表明，即使是最先进的多模态模型也表现出有限的性能。

**Conclusion:** 这凸显了在智能体奖励建模方面进行专门训练的必要性。

> **ai_Abstract:** 该论文提出了Agent-RewardBench，一个用于评估多模态大语言模型在真实世界多模态智能体中奖励建模能力的统一基准。该基准涵盖感知、规划和安全等多个维度，提供步级评估，并确保高质量和适当难度。实验结果表明，现有最先进模型在该基准上表现有限，强调了专门训练智能体奖励模型的必要性。

> **摘要翻译:** 随着多模态大语言模型（MLLMs）的进步，多模态智能体在网络导航和具身智能等真实世界任务中展现出前景。然而，由于缺乏外部反馈的限制，这些智能体在自我纠正和泛化方面面临困难。一个有前景的方法是使用奖励模型作为外部反馈，但目前尚不清楚如何为智能体选择奖励模型。因此，迫切需要建立一个针对智能体的奖励基准。为解决这些挑战，我们提出了Agent-RewardBench，一个旨在评估MLLMs中奖励建模能力的基准。该基准具有三个关键特征：(1) 多维度和真实世界智能体场景评估。它涵盖感知、规划和安全，包含7个场景；(2) 步级奖励评估。它允许评估任务中每个单独步骤的智能体能力，在规划过程中提供更细粒度的性能视图；(3) 适当难度和高质量。我们仔细从10个不同的模型中采样，通过难度控制来保持任务挑战性，并通过人工验证来确保数据的完整性。实验表明，即使是最先进的多模态模型也表现出有限的性能，这凸显了在智能体奖励建模方面进行专门训练的必要性。代码可在github上获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [295] [Cat and Mouse -- Can Fake Text Generation Outpace Detector Systems?](https://arxiv.org/abs/2506.21274)
> *猫鼠游戏——伪造文本生成能否超越检测系统？*

*Andrea McGlinchey, Peter J Barclay* | **Category: cs.CL**

**Keywords:** 伪造文本, 大型语言模型, 文本检测, 欺骗性, 统计分类器

**Comment:** (Submitted for publication)

> **TL;DR:** 研究发现，Gemini生成欺骗性文本的能力有所增强，而GPT则没有，这表明即使对于更大的模型，伪造文本的可靠检测可能仍然可行，但新的模型架构可能会提高其欺骗性。

**AI_Comments:** 该论文探讨了当前大型语言模型时代一个非常重要且紧迫的问题。其创新之处在于审视了“军备竞赛”的动态，并具体比较了不同LLM（Gemini与GPT）在特定文本风格下欺骗能力的演变。检测可能仍可行这一发现意义重大，但对新架构可能带来挑战的警告是未来研究的关键考量。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型能够生成令人信服的“伪造文本”，而检测这些文本的方法也在不断发展，这似乎预示着一场“军备竞赛”。该研究旨在探讨模型超越检测器的能力是否会达到一个平台期，特别是考虑到较简单分类器在资源有限的情况下也能达到良好的检测准确率。

**Method:** 研究人员通过检查统计分类器识别“伪造文本”的能力来探究模型能否击败检测器，这些伪造文本以经典侦探小说的风格生成。他们比较了Gemini和GPT模型在0.5版本升级后生成欺骗性文本的能力变化。

**Result:** 在0.5版本更新后，Gemini模型生成欺骗性文本的能力有所增强，而GPT模型则没有表现出这种增强。

**Conclusion:** 研究结果表明，即使对于越来越大的模型，可靠的伪造文本检测可能仍然可行。然而，新的模型架构可能会提高其欺骗性，这可能对未来的检测构成挑战。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）生成“伪造文本”与检测系统之间的“猫鼠游戏”。文章旨在探究LLMs欺骗检测器的能力是否会达到一个平台期，尤其考虑到简单的分类器也能有效检测。通过测试统计分类器在经典侦探小说风格的伪造文本上的表现，研究发现Gemini在0.5版本更新后生成欺骗性文本的能力有所提升，而GPT则没有。这表明，即使面对更大的模型，可靠的伪造文本检测可能仍具可行性，尽管新型模型架构可能会增加欺骗性。

> **摘要翻译:** 大型语言模型可以在学术写作、产品评论和政治新闻等领域生成令人信服的“伪造文本”。人们已经研究了许多检测人工智能生成文本的方法。虽然这似乎预示着一场无休止的“军备竞赛”，但我们注意到，较新的大型语言模型使用越来越多的参数、训练数据和能源，而相对简单的分类器则以适度的资源展示了良好的检测准确性。为了探讨模型击败检测器的能力是否会因此达到一个平台期，我们研究了统计分类器识别经典侦探小说风格的“伪造文本”的能力。在0.5版本更新后，我们发现Gemini生成欺骗性文本的能力有所增强，而GPT则没有。这表明，即使对于越来越大的模型，可靠的伪造文本检测可能仍然可行，尽管新的模型架构可能会提高它们的欺骗性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning](https://arxiv.org/abs/2506.21285)
> *双重检查器：通过自我批判微调增强慢思考大型语言模型的推理能力*

*Xin Xu, Tianhao Chen, Fan Zhang, Wanlong Liu, Pengxiang Li, Ajay Kumar Jaiswal, Yuchen Yan, Jishan Hu, Yang Wang, Hao Chen, Shiwei Liu, Shizhe Diao, Can Yang, Lu Yin* | **Category: cs.CL**

**Keywords:** 大型语言模型, 自我批判, 微调, 推理能力, 慢思考LLM

**Comment:** 10 pages

> **TL;DR:** 引入Double-Checker框架，通过自我批判微调显著提升慢思考大型语言模型（LLMs）的推理能力。

**AI_Comments:** 这篇论文的创新点在于引入了一个“自我批判”的微调机制，使LLMs能够像人类一样进行反思和迭代改进，而不是仅仅生成一次性答案。这种方法对于提升LLMs在复杂推理任务上的可靠性和准确性具有重要意义，尤其是在需要多步骤思考和错误纠正的场景中。其方法论清晰，并通过具体性能提升（如AIME上的显著提升）验证了其有效性，为未来开发更智能、更值得信赖的LLMs提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 慢思考大型语言模型（LLMs）虽然展现出反思性推理能力，但它们生成有信息量的批判和完善先前解决方案的能力有限。

**Method:** 本文引入了Double-Checker框架，通过在1,730个精心策划的自我批判实例上进行微调，使长链思维（long-CoT）LLMs能够在推理过程中迭代地批判和完善其输出，直到它们在自我生成的批判下评估解决方案是正确的。

**Result:** Double-Checker在全面的推理基准测试中表现出显著效果，迭代自我批判显著增强了长链思维（long-CoT）LLMs的推理能力。特别地，在具有挑战性的AIME基准测试中，其pass@1性能从原始长链思维（long-CoT）LLMs的4.4%提高到18.2%。

**Conclusion:** 这些结果表明，开发能够进行结构化自我批判的、更值得信赖和有效的LLMs是一个有前景的方向。

> **ai_Abstract:** 本文提出了Double-Checker框架，旨在通过自我批判微调提升慢思考大型语言模型（LLMs）的推理能力。该框架通过在1,730个自我批判实例上进行微调，使LLMs能够迭代地批判并完善其输出，直到自我评估为正确。实验结果表明，Double-Checker显著提高了长链思维（long-CoT）LLMs在各种推理基准上的性能，尤其是在AIME测试中将pass@1从4.4%提升至18.2%，展示了构建更可靠、能自我批判LLMs的潜力。

> **摘要翻译:** 尽管慢思考大型语言模型（LLMs）表现出类似反思的推理能力，通常被称为“顿悟时刻”，但它们生成有信息量的批判和完善先前解决方案的能力仍然有限。在本文中，我们引入了Double-Checker，一个旨在通过促进明确的自我批判和对其先前解决方案的迭代完善来增强慢思考LLMs推理能力的原则性框架。通过在我们精心策划的1,730个自我批判实例上进行微调，Double-Checker使长CoT LLMs能够在推理过程中迭代地批判和完善其输出，直到它们在自我生成的批判下评估其解决方案是正确的。我们在全面的推理基准测试套件中验证了Double-Checker的功效，证明迭代自我批判显著增强了长CoT LLMs的推理能力。值得注意的是，与原始的长CoT LLMs相比，我们的Double-Checker在具有挑战性的AIME基准测试中将pass@1性能从4.4%提高到18.2%。这些结果突出了开发更值得信赖和有效的、能够进行结构化自我批判的LLMs的一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [302] [Detecting Referring Expressions in Visually Grounded Dialogue with Autoregressive Language Models](https://arxiv.org/abs/2506.21294)
> *使用自回归语言模型检测视觉接地对话中的指称表达*

*Bram Willemsen, Gabriel Skantze* | **Category: cs.CL, cs.AI**

**Keywords:** 指称表达检测, 视觉接地对话, 自回归语言模型, 纯文本方法, 多模态问题

**Comment:** Accepted for publication at XLLM @ ACL 2025

> **TL;DR:** 本文探讨了使用纯文本自回归语言模型从视觉接地对话中提取指称表达，发现即使是文本-only方法在有限资源下也有效，但指出该任务本质上是多模态的。

**AI_Comments:** 本文的创新之处在于其反直觉地探索了在视觉接地对话中，仅依赖语言上下文来识别指称表达的可能性，而非直接采用多模态方法。研究结果显示了纯文本方法的有效性，这对于资源受限或需要快速部署的场景具有一定启发性。然而，论文也清醒地认识到并指出了其单模态方法的根本局限性，即该任务本质上是多模态的，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探究仅凭语言上下文能在多大程度上辅助检测视觉接地对话中的指称表达，即那些在视觉语境中有对应指代物的提及。

**Method:** 采用纯文本、自回归语言建模方法。具体地，通过适应预训练的大型语言模型（LLM），利用下一词元预测来粗粒度地标注对话中提及片段的边界，从而提取指称表达。

**Result:** 研究发现，即使使用中等规模的LLM、相对较小的数据集和参数高效的微调，纯文本方法仍然有效，这突显了语言上下文在该任务中的相对重要性。

**Conclusion:** 尽管纯文本方法有效，但作者认为该任务本质上是一个多模态问题，并讨论了单模态方法的根本局限性。

> **ai_Abstract:** 本研究探索了一种纯文本、自回归语言模型方法，用于从视觉接地对话中提取指称表达。通过调整预训练的LLM并利用下一词元预测进行提及片段标注，作者旨在评估语言上下文在检测视觉指代物方面的作用。结果表明，即使在资源有限的情况下，纯文本方法也表现出有效性，强调了语言上下文的重要性。然而，论文也指出该任务本质上是多模态的，并讨论了单模态方法的局限性。

> **摘要翻译:** 在本文中，我们探讨了使用纯文本、自回归语言建模方法从视觉接地对话中提取指称表达。更具体地说，目标是调查仅凭语言上下文能在多大程度上为检测在对话视觉上下文中具有（视觉上可感知）指代物的提及提供信息。为此，我们调整了一个预训练的大型语言模型（LLM），通过下一词元预测在文本中划定提及片段边界，从而在展开的对话中执行相对粗粒度的提及片段标注。我们的发现表明，即使使用中等规模的LLM、相对较小的数据集和参数高效的微调，纯文本方法也可以是有效的，这突出了语言上下文对于此任务的相对重要性。然而，我们认为该任务代表了一个固有的多模态问题，并讨论了单模态方法固有的局限性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [305] [Structuralist Approach to AI Literary Criticism: Leveraging Greimas Semiotic Square for Large Language Models](https://arxiv.org/abs/2506.21360)
> *人工智能文学批评的结构主义方法：利用格雷马斯符号方阵处理大型语言模型*

*Fangzhou Dong, Yifan Zeng, Yingpeng Sang, Hong Shen* | **Category: cs.CL**

**Keywords:** 大型语言模型, 文学批评, 格雷马斯符号方阵, 结构主义, 人工智能

**Comment:** Accepted in CogSci 2025

> **TL;DR:** 本文提出GLASS框架，一个基于格雷马斯符号方阵的结构化分析框架，旨在增强大型语言模型进行深度文学分析的能力，并构建了首个相关数据集和评估指标，实验证明其表现优异。

**AI_Comments:** 本文的创新之处在于将结构主义文学理论中的格雷马斯符号方阵引入到人工智能文学批评领域，并为大型语言模型提供了具体的分析框架GLASS。通过构建首个GSS文学批评数据集和量化评估指标，为LLMs进行深度文学分析提供了可操作的工具和评估标准，填补了现有研究空白。其重要性在于为AI文学研究和教育提供了新的可能性，并有助于理解文学参与的认知机制。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在理解和生成文本方面表现出色，但难以对具有深刻思想和复杂叙事的文学作品提供专业的文学批评。

**Method:** 本文提出了GLASS（通过符号方阵进行的格雷马斯文学分析）框架，这是一个基于格雷马斯符号方阵（GSS）的结构化分析框架。研究构建了首个用于GSS文学批评的数据集（包含48部作品的详细分析），并提出了使用“LLM作为评判者”范式进行GSS文学批评的量化指标。

**Result:** GLASS框架的结果与专家批评以及多个作品和大型语言模型的比较显示出高性能。此外，将GLASS应用于39部经典作品，产生了原创且高质量的分析，填补了现有研究空白。

**Conclusion:** 这项研究提供了一个基于人工智能的文学研究和教育工具，并为文学参与背后的认知机制提供了见解。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在专业文学批评方面的不足，提出了一种名为GLASS的结构化分析框架。GLASS基于格雷马斯符号方阵（GSS），旨在提升LLMs进行深度文学分析的能力。研究构建了首个GSS文学批评数据集，并引入了量化评估指标。实验结果表明，GLASS框架在与专家批评和多种LLMs的比较中表现出色，并成功应用于经典作品，产生了高质量的原创分析，为AI文学研究和教育提供了新工具。

> **摘要翻译:** 大型语言模型（LLMs）在理解和生成文本方面表现出色，但难以对具有深刻思想和复杂叙事的文学作品提供专业的文学批评。本文提出了GLASS（通过符号方阵进行的格雷马斯文学分析），一个基于格雷马斯符号方阵（GSS）的结构化分析框架，旨在增强LLMs进行深度文学分析的能力。GLASS有助于快速剖析叙事作品中的叙事结构和深层含义。我们提出了首个用于GSS文学批评的数据集，其中包含对48部作品的详细分析。然后，我们提出了使用“LLM作为评判者”范式进行GSS文学批评的量化指标。我们的框架结果与专家批评以及多个作品和LLMs的比较显示出高性能。最后，我们将GLASS应用于39部经典作品，产生了原创且高质量的分析，填补了现有研究空白。这项研究提供了一个基于人工智能的文学研究和教育工具，为文学参与背后的认知机制提供了见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [311] [Domain Knowledge-Enhanced LLMs for Fraud and Concept Drift Detection](https://arxiv.org/abs/2506.21443)
> *领域知识增强型LLM用于欺诈和概念漂移检测*

*Ali Şenol, Garima Agrawal, Huan Liu* | **Category: cs.CL, cs.AI**

**Keywords:** 欺诈检测, 概念漂移, 大型语言模型, 领域知识, 自然语言处理

**Comment:** 

> **TL;DR:** 提出一个领域知识增强型LLM框架，用于在动态平台检测欺诈对话和概念漂移，显著提高了检测准确性、可解释性和鲁棒性。

**AI_Comments:** 该论文的创新点在于将领域知识与大型语言模型结合，以应对高风险场景中欺诈检测和概念漂移的挑战。通过模块化设计，它不仅解决了LLM在上下文模糊性和幻觉方面的局限性，还提出了一个有效识别和分类概念漂移的方法。这对于动态平台上的安全性和内容管理具有重要意义，其高准确率和鲁棒性显示了该方法的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在动态平台检测欺骗性对话因语言模式演变和概念漂移（语义或主题变化）而日益困难。这些变化会模糊恶意意图或模仿正常对话，使准确分类具有挑战性。虽然大型语言模型（LLM）在自然语言任务中表现出色，但在风险敏感场景中常受上下文模糊性和幻觉困扰。

**Method:** 提出了一个领域知识（DK）增强型LLM框架，该框架将预训练的LLM与结构化、任务特定的洞察相结合，以执行欺诈和概念漂移检测。该架构包括三个主要组件：(1) DK-LLM模块用于检测虚假或欺骗性对话；(2) 漂移检测单元（OCDD）用于确定是否发生语义漂移；以及(3) 第二个DK-LLM模块用于将漂移分类为良性或欺诈性。

**Result:** 首先使用虚假评论数据集验证了领域知识的价值，然后将完整框架应用于SEConvo数据集。结果表明，该系统能高精度检测虚假对话并有效分类漂移的性质。在结构化提示引导下，基于LLaMA的实现达到了98%的分类准确率。与零样本基线的对比研究表明，结合领域知识和漂移感知显著提高了高风险NLP应用中的性能、可解释性及鲁棒性。

**Conclusion:** 结合领域知识和漂移感知可以显著提高大型语言模型在高风险自然语言处理应用中检测欺诈和概念漂移的性能、可解释性和鲁棒性。

> **ai_Abstract:** 本研究提出了一个领域知识（DK）增强型LLM框架，旨在解决动态平台中欺诈对话和概念漂移检测的挑战。该框架包含一个用于检测欺骗性对话的DK-LLM模块、一个用于识别语义漂移的OCDD单元，以及一个用于分类漂移性质的第二个DK-LLM模块。实验结果表明，该系统能够高精度检测虚假对话，有效分类漂移，并且基于LLaMA的实现达到了98%的准确率，证明了领域知识和漂移感知在提高高风险NLP应用性能、可解释性和鲁棒性方面的显著优势。

> **摘要翻译:** 在动态平台上检测欺骗性对话由于不断演变的语言模式和概念漂移（CD）——即随着时间推移改变交互上下文或意图的语义或主题变化——而日益困难。这些变化会模糊恶意意图或模仿正常对话，使准确分类具有挑战性。虽然大型语言模型（LLM）在自然语言任务中表现出色，但在风险敏感场景中它们经常面临上下文模糊性和幻觉问题。为了解决这些挑战，我们提出了一个领域知识（DK）增强型LLM框架，该框架将预训练的LLM与结构化、任务特定的洞察相结合，以执行欺诈和概念漂移检测。所提出的架构包括三个主要组件：(1) 一个DK-LLM模块用于检测虚假或欺骗性对话；(2) 一个漂移检测单元（OCDD）用于确定是否发生语义漂移；以及(3) 第二个DK-LLM模块用于将漂移分类为良性或欺诈性。我们首先使用一个虚假评论数据集验证了领域知识的价值，然后将我们的完整框架应用于SEConvo，这是一个多轮对话数据集，包含各种类型的欺诈和垃圾邮件攻击。结果显示，我们的系统能够高精度检测虚假对话并有效分类漂移的性质。在结构化提示的引导下，基于LLaMA的实现达到了98%的分类准确率。与零样本基线的对比研究表明，结合领域知识和漂移感知显著提高了高风险NLP应用中的性能、可解释性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [321] [TopK Language Models](https://arxiv.org/abs/2506.21468)
> *TopK 语言模型*

*Ryosuke Takahashi, Tatsuro Inaba, Kentaro Inui, Benjamin Heinzerling* | **Category: cs.CL**

**Keywords:** TopK语言模型, 稀疏自编码器, 语言模型解释性, Transformer架构, 神经元干预

**Comment:** 

> **TL;DR:** 本文引入了一种新的Transformer架构修改，即TopK语言模型，通过在选定层集成TopK激活函数，消除了对稀疏自编码器（SAEs）的后训练需求，同时提供了可比的解释性，并能保持原始模型能力。

**AI_Comments:** TopK语言模型提出了一种新颖且实用的方法，通过直接修改Transformer架构来解决稀疏自编码器（SAEs）的固有缺陷，特别是事后训练的限制和特征稳定性问题。其创新之处在于将可解释性直接嵌入到模型训练过程中，而非作为后处理步骤。这不仅提高了效率，也增强了特征的内在有效性和可比性。该方法在保持模型性能的同时，显著提升了可解释性，为理解大型语言模型内部工作机制提供了更稳定和可靠的工具，对于未来模型可控性和透明度的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏自编码器（SAEs）是分析和解释Transformer语言模型激活空间的重要工具，但存在局限性：它们是事后训练的，导致不清楚概念未被发现是SAE的问题还是底层LM未表示该概念；训练条件和架构选择会影响SAE学习的特征；特征稳定性不足导致难以比较不同检查点间的SAE特征，从而阻碍了对LM学习概念过程的追踪。

**Method:** 本文提出对Transformer架构进行修改，在选定的层中引入TopK激活函数，使得模型的隐藏状态等同于TopK稀疏自编码器的潜在特征。这种方法消除了对SAE进行事后训练的需要，同时提供了与SAE相当的解释性。

**Result:** TopK语言模型在模型大小、计算效率和可解释性之间提供了有利的权衡。尽管架构改动简单，TopK语言模型仍能保持其原有能力，并提供强大的可解释性优势。实验表明，TopK语言模型学习到的稀疏表示能够通过有针对性的神经元干预实现成功的引导，并有助于详细分析跨检查点和层的神经元形成过程。

**Conclusion:** TopK语言模型提供了一种稳定可靠的工具，用于理解语言模型如何学习和表示概念，有望显著推动未来在模型可解释性和可控性方面的研究。

> **ai_Abstract:** 本文针对稀疏自编码器（SAEs）在语言模型解释性方面存在的局限性，提出了一种名为TopK语言模型的新架构。通过在Transformer模型的选定层中直接集成TopK激活函数，该方法将模型的隐藏状态等同于TopK SAE的潜在特征，从而消除了SAE的后训练需求，并提供了与SAEs相当的可解释性。实验证明，TopK语言模型在保持原始能力的同时，提供了模型大小、计算效率和可解释性之间的良好平衡，并且其稀疏表示有助于实现成功的神经元干预和细致的神经元形成过程分析，有望成为理解语言模型学习和表示概念的稳定工具。

> **摘要翻译:** 稀疏自编码器（SAEs）已成为分析和解释基于Transformer的语言模型（LMs）激活空间的重要工具。然而，SAEs存在一些缺点，降低了它们的实用性和内部有效性。由于SAEs是事后训练的，因此不清楚未能发现特定概念是SAE的问题，还是底层语言模型未表示该概念。训练条件和架构选择影响SAE学习哪些特征，这使得问题更加严重。在追踪语言模型在训练过程中如何学习概念时，特征稳定性的缺乏也使得难以比较不同检查点之间的SAE特征。为了解决这些局限性，我们引入了一种对Transformer架构的修改，在选定的层中加入了TopK激活函数，使模型的隐藏状态等同于TopK SAE的潜在特征。这种方法消除了对事后训练的需求，同时提供了与SAEs相当的可解释性。由此产生的TopK语言模型在模型大小、计算效率和可解释性之间提供了有利的权衡。尽管进行了这种简单的架构改变，TopK语言模型仍保持了其原有能力，同时提供了强大的可解释性优势。我们的实验表明，TopK语言模型学习到的稀疏表示能够通过有针对性的神经元干预实现成功的引导，并有助于详细分析跨检查点和层的神经元形成过程。这些特性使得TopK语言模型成为理解语言模型如何学习和表示概念的稳定可靠的工具，我们相信这将显著推动未来在模型可解释性和可控性方面的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [324] [Bridging Offline and Online Reinforcement Learning for LLMs](https://arxiv.org/abs/2506.21495)
> *LLM离线与在线强化学习的桥接*

*Jack Lanchantin, Angelica Chen, Janice Lan, Xian Li, Swarnadeep Saha, Tianlu Wang, Jing Xu, Ping Yu, Weizhe Yuan, Jason E Weston, Sainbayar Sukhbaatar, Ilia Kulikov* | **Category: cs.CL**

**Keywords:** 强化学习, 大型语言模型, 在线学习, 离线学习, 微调

**Comment:** 

> **TL;DR:** 本文研究了LLM微调中强化学习方法从离线到半在线再到完全在线的有效性，发现在线和半在线方法优于离线方法，并且多任务学习能进一步提升性能。

**AI_Comments:** 本文的创新点在于系统地比较了不同在线程度的强化学习方法在LLM微调中的表现，并发现在线方法优于离线方法，同时指出了多任务学习的潜力。研究结果对于LLM的实际部署和持续学习具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 调查强化学习方法在LLM微调中，从离线到半在线再到完全在线场景的有效性。

**Method:** 实验涵盖可验证数学和不可验证指令遵循任务；比较了在线和半在线的直接偏好优化（Direct Preference Optimization）和群组奖励策略优化（Group Reward Policy Optimization）目标；分析了训练动态和超参数选择策略；尝试了可验证和不可验证奖励的多任务学习。

**Result:** 在线和半在线的DPO和GRPO变体表现和收敛性相似，且都显著优于离线方法。可验证和不可验证奖励的多任务学习能共同提升两种任务类型的性能。

**Conclusion:** 在线和半在线的强化学习方法在LLM微调中比离线方法更有效，且通过多任务学习可以进一步提升性能。

> **ai_Abstract:** 本文探讨了强化学习方法在大型语言模型微调中，从离线到在线不同阶段的有效性。研究对比了在线和半在线的DPO与GRPO目标，发现在线方法显著优于离线方法，且在线和半在线方法性能相似。此外，通过可验证和不可验证任务的多任务学习，模型性能得到进一步提升。

> **摘要翻译:** 我们研究了强化学习方法在微调大型语言模型时，从离线到半在线再到完全在线模式，针对可验证和不可验证任务的有效性。我们的实验涵盖了可验证数学和不可验证指令遵循的训练，并对两者进行了一系列基准评估。在这些设置中，我们广泛比较了在线和半在线的直接偏好优化（Direct Preference Optimization）和群组奖励策略优化（Group Reward Policy Optimization）目标，并惊讶地发现这些变体之间性能和收敛性相似，它们都显著优于离线方法。我们提供了训练动态和超参数选择策略的详细分析，以实现最佳结果。最后，我们展示了同时使用可验证和不可验证奖励进行多任务处理可以共同提高两种任务类型的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [327] [Enhancing User Engagement in Socially-Driven Dialogue through Interactive LLM Alignments](https://arxiv.org/abs/2506.21497)
> *通过交互式LLM对齐增强社交驱动对话中的用户参与度*

*Jiashuo Wang, Kaitao Song, Chunpu Xu, Changhe Song, Yang Xiao, Dongsheng Li, Lili Qiu, Wenjie Li* | **Category: cs.CL**

**Keywords:** 用户参与度, 社交对话, LLM对齐, i×MCTS, 直接偏好优化

**Comment:** 

> **TL;DR:** 通过利用用户意图反馈并结合用户模拟器和i×MCTS，本研究使用DPO对齐交互式LLM，从而有效提升社交驱动对话中的用户参与度。

**AI_Comments:** 本文的创新点在于引入了“用户交互后与对话意图相关的反应”作为直接的用户参与度指标，并通过用户模拟器和i×MCTS模拟交互过程来收集偏好数据，进而利用DPO对齐LLM。这种方法更直接地关注了用户行为反馈，而非仅仅依赖知识或对话行为规划，为提升社交对话LLM的实用性和用户体验提供了新的视角。其局限性可能在于用户模拟器的真实性以及所收集偏好数据的规模和多样性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究虽优化了LLM以推理相关知识或规划对话行为流，但用户参与度与知识或对话行为之间的关系微妙，无法保证社交驱动对话中的用户参与度。

**Method:** 本文通过利用对话未来发展的信号，使交互式LLM学习用户参与度。具体而言，采用用户交互后与对话意图相关的反应作为奖励信号来对齐交互式LLM。为此，开发了一个用户模拟器，并利用i×MCTS（交互式蒙特卡洛树搜索）来探索用户与LLM系统之间的交互，从而收集包含高质量和低质量体验的数据集，并使用直接偏好优化（DPO）对齐交互式LLM以实现高水平的用户参与度。

**Result:** 在情感支持对话和劝善等两种社交驱动对话场景中进行的实验表明，该方法有效地增强了交互式LLM中的用户参与度。

**Conclusion:** 本文提出的通过用户意图反馈和i×MCTS结合DPO对齐交互式LLM的方法，能够显著提升社交驱动对话中的用户参与度。

> **ai_Abstract:** 本文提出一种通过交互式LLM对齐来增强社交驱动对话中用户参与度的方法。针对现有方法无法保证用户参与度的问题，作者利用对话未来发展中的用户意图反馈作为奖励信号，通过开发用户模拟器和i×MCTS来探索用户与LLM的交互，从而收集高质量和低质量体验数据。随后，利用直接偏好优化（DPO）对齐交互式LLM。实验证明，该方法在情感支持和劝善对话场景中有效提升了用户参与度。

> **摘要翻译:** 标题：通过交互式LLM对齐增强社交驱动对话中的用户参与度

摘要：通过交互增强用户参与度在社交驱动对话中扮演着重要角色。虽然先前的研究已经优化了模型以推理相关知识或规划对话行为流，但用户参与度与知识或对话行为之间的关系是微妙的，并不能保证社交驱动对话中的用户参与度。为此，我们通过利用对话未来发展的信号，使交互式LLM能够学习用户参与度。具体而言，我们采用一个更直接和相关的用户参与度指标，即交互后用户与对话意图相关的反应，作为奖励来对齐交互式LLM。为了实现这一点，我们开发了一个用户模拟器与目标交互式LLM进行交互，并通过i×MCTS（交互式蒙特卡洛树搜索）探索用户与交互式LLM系统之间的交互。通过这种方式，我们收集了一个包含通过i×MCTS获得的更高和更低质量体验对的数据集，并相应地通过直接偏好优化（DPO）对齐交互式LLM以实现高水平的用户参与度。在两种社交驱动对话场景（情感支持对话和劝善）中进行的实验表明，我们的方法有效地增强了交互式LLM中的用户参与度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [332] [Potemkin Understanding in Large Language Models](https://arxiv.org/abs/2506.21521)
> *大型语言模型中的波将金式理解*

*Marina Mancoridis, Bec Weeks, Keyon Vafa, Sendhil Mullainathan* | **Category: cs.CL, cs.AI**

**Keywords:** 大型语言模型, 波将金式理解, 基准测试, 模型评估, 概念表征

**Comment:** 

> **TL;DR:** 本文提出并量化了大型语言模型中“波将金式理解”现象，即模型在基准测试上的成功可能只是理解的假象，源于与人类理解方式不符的内部不一致性。

**AI_Comments:** 本文创新性地提出了“波将金式理解”这一概念，深刻质疑了当前大型语言模型基准测试的有效性。它提醒我们，模型在表面上的成功可能掩盖了其深层理解的缺陷和内部不一致性，对LLMs的评估和未来发展方向具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）经常通过基准数据集进行评估，但作者质疑这种评估能否真正反映LLM的能力，特别是如果LLMs的错误理解方式与人类不同。

**Method:** 本文首先提出了一个形式化框架来解决评估有效性问题。然后，提出了两种量化“波将金式理解”存在的程序：一种是使用在三个领域专门设计的基准测试，另一种是提供其普遍性下限的通用程序。

**Result:** 研究发现，“波将金式理解”在不同模型、任务和领域中普遍存在。这些失败不仅反映了不正确的理解，还反映了概念表征中更深层次的内部不一致性。

**Conclusion:** 基准测试的成功可能仅是大型语言模型“波将金式理解”的体现，即一种理解的假象，其答案与人类对概念的解释方式不符，这揭示了模型内部概念表征的深层不连贯性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在基准测试上的表现是否真正反映了其理解能力。作者提出了“波将金式理解”的概念，指出如果LLMs的错误理解方式与人类不同，那么基准测试的成功可能只是理解的假象。通过引入形式化框架和两种量化程序，包括使用专门设计的基准测试和通用程序，研究发现“波将金式理解”在各种模型、任务和领域中普遍存在，并且揭示了模型内部概念表征的深层不一致性。

> **摘要翻译:** 大型语言模型（LLMs）通常使用基准数据集进行评估。但如何证明基于LLM对一组精心策划问题的回答来推断其能力的合理性？本文首先提出了一个形式化框架来解决这个问题。关键在于，用于测试LLMs的基准测试（如AP考试）也用于测试人类。然而，这带来了一个隐含的推论：只有当LLMs对概念的误解方式与人类的误解方式相似时，这些基准测试才是有效的。否则，在基准测试上的成功仅表明波将金式理解：一种理解的假象，由与任何人类解释概念的方式不符的答案所驱动。我们提出了两种量化波将金式现象存在的程序：一种是在三个领域使用专门设计的基准测试，另一种是提供其普遍性下限的通用程序。我们发现波将金式现象在不同模型、任务和领域中普遍存在。我们还发现，这些失败不仅反映了不正确的理解，还反映了概念表征中更深层次的内部不一致性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [337] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
> *语言模型训练中的数据效能*

*Yalun Dai, Yangyu Huang, Xin Zhang, Wenshan Wu, Chong Li, Wenhui Lu, Shijie Cao, Li Dong, Scarlett Li* | **Category: cs.CL**

**Keywords:** 数据效能, 语言模型, DELT, 数据组织, LQS, 折叠排序

**Comment:** 

> **TL;DR:** 本文提出了数据效能的概念，并引入了DELT框架，通过优化训练数据组织来提升语言模型性能，特别是通过LQS和FO方法。

**AI_Comments:** 本文创新性地提出了“数据效能”的概念，将研究焦点从数据“量”的筛选转移到数据“组织”的优化，为语言模型训练提供了新的视角。DELT框架及其LQS和FO组件为实现数据效能提供了具体方法，尤其是在不增加计算资源的情况下提升模型性能，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注数据效率（选择最小/最优数据子集），而数据效能（优化训练数据组织）相对未被充分探索，但对提升语言模型性能同样重要。

**Method:** 提出了一个通用的数据效能范式DELT，包含数据评分、数据选择和数据排序三个组件。其中，设计了学习质量评分（LQS）作为数据评分的新实例，从梯度一致性角度考虑数据样本的学习能力和质量；设计了折叠排序（FO）作为数据排序的新实例，解决模型遗忘和数据分布偏差问题。

**Result:** 1. DELT的各种实例在不增加数据规模和模型大小的情况下，不同程度地提升了语言模型性能。
2. LQS与FO的组合实现了最显著的性能提升。
3. 数据效能可以与数据效率（通过数据选择）结合实现。

**Conclusion:** 数据效能是语言模型训练中一个有前景的基础领域。

> **ai_Abstract:** 本文提出了“数据效能”的概念，旨在通过优化训练数据组织来提升语言模型性能。为此，作者引入了DELT通用范式，包含数据评分、数据选择和数据排序。特别地，他们设计了学习质量评分（LQS）和折叠排序（FO）两种新方法。实验证明，DELT及其组件能在不增加模型大小和数据规模的情况下有效提升LM性能，尤其是LQS与FO的结合效果最佳，并可与数据效率方法结合使用。

> **摘要翻译:** 数据是语言模型（LM）训练的基础。最近的研究致力于数据效率，旨在通过选择最小或最优的训练数据子集来最大化性能。数据过滤、采样和选择等技术在此领域发挥着关键作用。作为补充，我们定义了数据效能，它侧重于通过优化训练数据的组织来最大化性能，而这方面相对未被充分探索。这项工作引入了一个通用范式DELT，用于在LM训练中考虑数据效能，它强调了训练数据组织的重要性。DELT包括三个组件：数据评分、数据选择和数据排序。在这些组件中，我们设计了学习能力-质量评分（LQS）作为数据评分的一个新实例，它从梯度一致性的角度考虑了每个数据样本的学习能力和质量。我们还设计了折叠排序（FO）作为数据排序的一个新实例，它解决了模型遗忘和数据分布偏差等问题。全面的实验验证了LM训练中的数据效能，结果表明：首先，所提出的DELT的各种实例在不增加数据规模和模型大小的情况下，不同程度地提升了LM性能。其次，在这些实例中，我们提出的用于数据评分的LQS和用于数据排序的折叠排序的组合实现了最显著的改进。最后，数据效能可以通过应用数据选择与数据效率一起实现。因此，我们认为数据效能是LM训练中一个有前景的基础领域。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [24] [Adaptive Hybrid Sort: Dynamic Strategy Selection for Optimal Sorting Across Diverse Data Distributions](https://arxiv.org/abs/2506.20677)
> *自适应混合排序：针对不同数据分布的动态策略选择以实现最佳排序*

*Shrinivass Arunachalam Balasubramanian* | **Category: cs.DS, cs.DB, cs.PF**

**Keywords:** 自适应排序, 混合排序, 动态策略选择, 数据分布, XGBoost

**Comment:** 11 Pages, 5 figures

> **TL;DR:** 本文提出一种自适应混合排序范式，通过实时监测输入数据模式，动态选择计数排序、基数排序或快速排序，以优化不同数据分布下的排序性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个动态自适应的排序策略选择框架，通过实时分析数据特性来优化排序性能，而非依赖单一的静态算法。其结合特征提取和机器学习（XGBoost）进行决策的思路具有前瞻性，提升了排序算法的普适性和效率，对于需要处理多样化数据分布的系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的排序算法无法在所有数据分布下都达到最优性能，因此需要一种能根据数据特性动态选择最佳排序策略的方案。

**Method:** 提出一种自适应混合排序范式。该架构包含特征提取模块（计算数据量、值范围、熵等参数）和决策引擎（包含有限状态机和XGBoost分类器）。决策引擎根据提取的参数智能选择最佳排序策略：小键范围使用计数排序，大范围低熵结构化输入使用基数排序，通用排序使用快速排序。

**Result:** 在合成数据集和真实数据集上的实验结果表明，所提出的解决方案在执行时间、灵活性和效率方面明显优于传统的静态排序算法。

**Conclusion:** 所提出的框架提供了一个可扩展、高性能且适用于大数据分析、边缘计算和硬件受限系统等广泛数据处理操作的解决方案。

> **ai_Abstract:** 本文提出了一种名为“自适应混合排序”的新范式，旨在解决现有排序算法无法在所有数据分布下都达到最优性能的问题。该方法通过特征提取模块实时监测输入数据的特性（如数据量、值范围和熵），并利用包含有限状态机和XGBoost分类器的决策引擎，动态选择最适合的排序算法（计数排序、基数排序或快速排序）。实验结果表明，该自适应方法在执行时间、灵活性和效率方面显著优于传统静态排序算法，并适用于大数据分析和边缘计算等多种应用场景。

> **摘要翻译:** 排序是计算机科学中一项基本操作，直接影响大规模数据系统、实时系统和嵌入式计算的性能。然而，没有一种排序算法能在所有数据分布下都达到最优。本文提出的新型自适应混合排序范式，是一种能根据输入数据模式的实时监测，自动选择最有效的排序算法（计数排序、基数排序或快速排序）的范式。该架构首先通过特征提取模块计算数据量、值范围和熵等重要参数。这些参数被发送到包含有限状态机和XGBoost分类器的决策引擎，以辅助智能有效地选择最优排序策略。它在小键范围上实现计数排序，在大范围低熵结构化输入上实现基数排序，在通用排序上实现快速排序。合成数据集和真实数据集的实验结果证实，所提出的解决方案在执行时间、灵活性和效率方面，与传统的静态排序算法相比，确实表现出显著的优势。所提出的框架提供了一个可扩展、高性能且适用于大数据分析、边缘计算和硬件受限系统等广泛数据处理操作的解决方案。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [48] [Review of Three Variants of the k-d Tree](https://arxiv.org/abs/2506.20687)
> *k-d树三种变体的综述*

*Russell A. Brown* | **Category: cs.DS**

**Keywords:** k-d树, 数据结构, 分区, 计算复杂性, 性能

**Comment:** 29 pages, 11 figures, one listing, one table

> **TL;DR:** 本文综述并对比了k-d树的三种变体，重点关注它们的分区技术和计算复杂性，并提出并分析了其中一种变体的双线程执行。

**AI_Comments:** 这篇论文关注了k-d树的一个核心性能方面：分区策略。通过分析现有变体并提出像双线程执行这样的优化方案，对于实际应用中构建效率至关重要的k-d树实现具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** k-d树的原始描述指出，传统的再平衡技术不适用于k-d树，因此需要通过寻找中位数和数据集分区来构建平衡的k-d树。用于寻找中位数和分区的技术会强烈影响构建k-d树的计算复杂性，这促使了对不同变体的分析和比较。

**Method:** 本文描述并对比了k-d树的三种变体，这些变体在数据集分区技术上有所不同。论文比较了这些变体的性能，并为其中一种变体提出了双线程执行方案并进行了分析。

**Result:** 本文对比了k-d树三种变体的性能，并对其中一种变体的双线程执行进行了提案和分析。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文综述了k-d树的三种变体，这些变体主要在数据分区技术上有所区别。鉴于k-d树无法应用传统再平衡技术，构建平衡树需依赖中位数查找和数据集分区，而这些技术显著影响其计算复杂性。论文描述、对比并评估了这些变体的性能，同时还为其中一种变体提出并分析了双线程执行方案。

> **摘要翻译:** k-d树的原始描述认识到，像用于构建AVL树或红黑树那样的再平衡技术不适用于k-d树。因此，为了构建一个平衡的k-d树，有必要在每次递归细分数据集时找到该数据集的中位数。用于寻找中位数以及围绕该中位数分区数据集的排序或选择技术，强烈影响构建k-d树的计算复杂性。本文描述并对比了k-d树的三种变体，它们在用于分区数据集的技术上有所不同，并比较了这些变体的性能。此外，还针对这三种变体中的一种提出了双线程执行并进行了分析。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [72] [A Framework for Building Data Structures from Communication Protocols](https://arxiv.org/abs/2506.20761)
> *从通信协议构建数据结构的一个框架*

*Alexandr Andoni, Shunhua Jiang, Omri Weinstein* | **Category: cs.DS**

**Keywords:** 数据结构, 通信协议, 模式匹配, 部分匹配, 集合不交性

**Comment:** 53 pages, STOC 2025

> **TL;DR:** 本文提出了一个通用框架，通过通信模型设计高效的高维模式匹配数据结构，并将其应用于部分匹配问题，显著提高了查询时间，同时改进了集合不交性问题的通信协议。

**AI_Comments:** 该论文的创新点在于提出了一个通用的框架，将数据结构问题与通信复杂度理论相结合，特别是利用了UAM通信复杂度。其重要性体现在为高维模式匹配问题提供了更高效的解决方案，并通过改进底层通信协议（如集合不交性）为相关领域带来了理论上的进步。该方法对于处理数据依赖型数据结构具有启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为高维模式匹配问题设计高效的数据结构，特别是通过利用通信模型来解决这些问题。

**Method:** 提出一个通用框架，将数据结构问题归结为乘积分布下函数 $f(x,y)$ 的无歧义阿瑟-梅林（UAM）通信复杂度。具体地，开发了一种在乘积分布下具有 $	ilde{	heta}(\sqrt{d\log(1/\epsilon)})$ 复杂度的单边 $\epsilon$-误差集合不交性通信协议，并在此基础上证明了 $w$-稀疏集合不交性在乘积分布下的无歧义 AM 通信复杂度为 $\tilde{O}(\sqrt{w \log(1/\epsilon)})$。

**Result:** 将该框架应用于部分匹配问题，在查询中通配符数量为 $w = c\log n$ 时，实现了查询时间 $n^{1-1/(c \log^2 c)}$ 和接近线性的空间，显著优于现有最快的线性空间数据结构（查询时间为 $n^c$）。同时，改进了 Babai, Frankl 和 Simon (FOCS'86) 关于集合不交性通信协议的经典结果。

**Conclusion:** 该框架揭示了数据依赖型数据结构的强大能力，这对于简化到（更容易的）乘积分布情况至关重要。

> **ai_Abstract:** 本文提出了一种通用的框架，用于通过通信协议设计高维模式匹配问题的有效数据结构。该框架将数据结构问题转化为无歧义阿瑟-梅林（UAM）通信复杂度问题，并将其成功应用于部分匹配问题，显著提高了查询效率。为实现此目标，作者开发了一种改进的集合不交性通信协议，其复杂度优于现有成果。研究强调了数据依赖型数据结构在处理乘积分布情况下的重要性。

> **摘要翻译:** 我们提出了一个通用框架，用于通过通信模型设计高效的高维模式匹配问题的数据结构（$\\exists \\;? i\\in[n], f(x_i,y)=1$），其中 $f(x,y)$ 允许具有指数级小误差的亚线性通信协议。具体而言，我们将数据结构问题归结为乘积分布下 $f(x,y)$ 的无歧义阿瑟-梅林（UAM）通信复杂度。
我们将我们的框架应用于部分匹配问题（又称带通配符匹配），其底层通信问题是稀疏集合不交性。当数据库包含 $d$ 维的 $n$ 个点，并且查询中的星号数量至多为 $w = c\log n \\;(\\ll d)$ 时，已知最快的线性空间数据结构（Cole, Gottlieb 和 Lewenstein, STOC'04）的查询时间约为 $2^w = n^c$，这仅在 $c<1$ 时才非平凡。相比之下，我们的框架生成的数据结构具有 $n^{1-1/(c \log^2 c)}$ 的查询时间以及接近线性的空间。
为了实现这一点，我们开发了一种在乘积分布下具有 $\\tilde{\Theta}(\\sqrt{d\\log(1/\\epsilon)})$ 复杂度的单边 $\\epsilon$-误差集合不交性通信协议，改进了 Babai, Frankl 和 Simon (FOCS'86) 的经典结果。在此协议的基础上，我们表明在乘积分布下具有 $\\epsilon$-误差的 $w$-稀疏集合不交性的无歧义 AM 通信复杂度为 $\\tilde{O}(\\sqrt{w \\log(1/\\epsilon)})$，这与环境维度 $d$ 无关，这对于部分匹配结果至关重要。我们的框架进一步阐明了数据依赖型数据结构的强大能力，这对于简化到（更容易的）乘积分布情况至关重要。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [97] [Practical and Accurate Local Edge Differentially Private Graph Algorithms](https://arxiv.org/abs/2506.20828)
> *实用且精确的局部边差分隐私图算法*

*Pranay Mundra, Charalampos Papamanthou, Julian Shun, Quanquan C. Liu* | **Category: cs.DS, cs.CR, cs.DB**

**Keywords:** 局部差分隐私, 图算法, k-核分解, 三角形计数, 隐私保护

**Comment:** To appear in VLDB 2025

> **TL;DR:** 本文提出并评估了新的局部差分隐私（LDP）图算法，用于k-核分解和三角形计数，通过利用图的退化度和最大度，显著提高了准确性并收紧了误差界限。

**AI_Comments:** 本文的创新之处在于首次将局部差分隐私应用于k-核分解和三角形计数等核心图算法，并利用图的内在属性（如退化度和最大度）来优化误差界限，从而实现了显著的准确性提升。此外，本文首次在分布式模拟中验证了LDP图算法，增强了其实用性。其重要性在于为在大规模敏感图数据上进行隐私保护分析提供了更实用和精确的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大规模网络中的敏感数据涉及隐私问题，需要先进的图分析方法。传统的中心化模型假设存在可信的策展人，但局部差分隐私（LDP）在个体层面强制执行隐私，无需信任第三方实体，因此本文旨在解决LDP在图算法中的挑战。

**Method:** 本文提出了针对k-核分解和三角形计数的局部差分隐私（LDP）算法。该方法利用输入依赖的私有图属性，特别是图的退化度和最大度，以提高理论效用。对于三角形计数，该算法通过利用私有出度定向（Eden et al.随机响应技术的改进变体）和新颖的分析，实现了基于图退化度的误差界限。此外，本文首次在分布式模拟中评估了局部DP算法。

**Result:** 本文的算法实现了比先前工作更强的理论保证，误差界限由最大度而非总边数决定。对于k-核分解，误差在精确值的3倍以内，远优于基线的131倍误差。对于三角形计数，乘法近似误差减少了高达六个数量级，同时保持了有竞争力的运行时性能。

**Conclusion:** 本文提出了实用且精确的局部差分隐私图算法，通过利用图的内在属性，显著提高了k-核分解和三角形计数的准确性，并在分布式环境中进行了有效验证，为敏感图数据的隐私保护分析提供了更强的保证。

> **ai_Abstract:** 本文提出了一种新的局部差分隐私（LDP）图算法，用于k-核分解和三角形计数，旨在解决大规模网络中敏感数据分析的隐私问题。与现有方法不同，该算法通过利用图的退化度和最大度等输入依赖的私有属性，显著收紧了误差界限。实验结果表明，在k-核分解和三角形计数任务上，该算法在分布式模拟中表现出显著的准确性提升，误差远低于现有基线，同时保持了高效的运行时间。

> **摘要翻译:** 大规模网络在不同领域的兴起，需要复杂的图分析，这通常涉及敏感数据并引发隐私问题。本文使用局部差分隐私（LDP）来解决这些挑战，LDP在个体层面强制执行隐私，不像假设有可信策展人的中心化模型那样，不信任任何第三方实体。我们为两种基本图统计：k-核分解和三角形计数引入了新颖的LDP算法。我们的方法利用输入依赖的私有图属性，特别是图的退化度和最大度，以提高理论效用。与现有方法不同，我们的误差界限由最大度而不是总边数决定，从而产生了显著更紧密的保证。对于三角形计数，我们改进了Imola、Murakami和Chaudhury的工作，该工作将误差限制在边数方面。相反，我们的算法通过利用私有出度定向（Eden et al.随机响应技术的改进变体）和新颖的分析，实现了基于图退化度的界限，从而获得了比先前工作更强的保证。除了理论上的收益，我们首次在分布式模拟中评估了局部DP算法，这与先前在单个处理器上测试的工作不同。在真实世界图上的实验显示出显著的准确性提升：我们的k-核分解误差在精确值的3倍以内，远优于Dhulipala et al.基线的131倍误差。我们的三角形计数算法将乘法近似误差减少了高达六个数量级，同时保持了有竞争力的运行时性能。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [120] [Almost Tight Additive Guarantees for \boldmath $k$-Edge-Connectivity](https://arxiv.org/abs/2506.20906)
> *$k$-边连通性近似紧加性保证*

*Nikhil Kumar, Chaitanya Swamy* | **Category: cs.DS, F.2.2; G.2**

**Keywords:** k-边连通性, 生成子图, LP松弛, 近似算法, 度受限

**Comment:** 

> **TL;DR:** 该论文为 $k$-边连通生成子图 (kECSS) 和多图 (kECSM) 问题提供了多项式时间算法，实现了接近最优的加性连通性保证，成本至多或略高于 LP 松弛最优值。

**AI_Comments:** 该论文的创新之处在于，对于 NP-hard 问题如 kECSS，通过将成本控制在 LP 最优值或其附近，同时仅对连通性进行小常数放松，实现了接近最优的加性保证。将其扩展到带度限制的版本也是一项重要贡献，提供了此类形式的首批结果。文中提及算法和分析的简洁性也是一个优点。

<details>
  <summary>Details</summary>

**Motivation:** 该论文研究 $k$-边连通生成子图 (kECSS) 问题，该问题是 APX-hard。目标是找到一个成本最小的 $k$-边连通子图。作者旨在改进现有工作并首次解决带度限制的版本。

**Method:** 对于 kECSS，作者提出了一种多项式时间算法。对于偶数 $k$，算法计算一个 $(k-2)$-边连通子图；对于奇数 $k$，计算一个 $(k-3)$-边连通子图，其成本均至多为 LP 松弛最优值 $LP^*$。他们还提供了一种替代保证，即获得一个 $(k-1)$-边连通子图，成本至多为 $1.5	ext{·}LP^*$；对于单位边成本，该保证提高到 $(1+\frac{4}{3k})\text{·}LP^*$。他们的技术也适用于 kECSM 问题，对于偶数 $k$ 获得 $(1+2/k)$-近似算法，对于奇数 $k$ 获得 $(1+3/k)$-近似算法。此外，这些技术扩展到带度限制的 kECSS 和 kECSM 版本，在度限制上存在约 2 的加性违反。

**Result:** 对于 kECSS：偶数 $k$ 获得 $(k-2)$-边连通子图，成本 $\le LP^*$；奇数 $k$ 获得 $(k-3)$-边连通子图，成本 $\le LP^*$。替代方案是 $(k-1)$-边连通子图，成本 $\le 1.5\text{·}LP^*$；单位成本下，成本 $\le (1+\frac{4}{3k})\text{·}LP^*$。对于 kECSM：偶数 $k$ 获得 $(1+2/k)$-近似，奇数 $k$ 获得 $(1+3/k)$-近似。对于带度限制的版本，获得了与 kECSS/kECSM 相同的成本和连通性保证，但在度限制上存在约 2 的加性违反。

**Conclusion:** 该算法为 kECSS 提供了接近最优的加性保证，并显著改进了现有工作。它们还为 kECSM 带来了结果，并且是首次解决带度限制版本的问题，其解决方案成本至多为最优值，连通性约束仅受到加性常数违反。

> **ai_Abstract:** 本论文解决了 APX-hard 的 $k$-边连通生成子图 (kECSS) 和多图 (kECSM) 问题。作者提出了多项式时间算法，在成本至多或略高于 LP 松弛最优值的情况下，实现了接近最优的边连通性加性保证。具体而言，对于 kECSS，偶数 $k$ 获得 $(k-2)$-边连通性，奇数 $k$ 获得 $(k-3)$-边连通性，成本均不超过 $LP^*$。他们还提供了一种替代方案，即 $(k-1)$-边连通解，成本为 $1.5\text{·}LP^*$，对于单位成本则改进为 $(1+4/(3k))\text{·}LP^*$。对于 kECSM，偶数 $k$ 获得 $(1+2/k)$-近似，奇数 $k$ 获得 $(1+3/k)$-近似。此外，其技术扩展到这些问题的度受限版本，在度限制上存在小的加性违反，代表了此类变体的首批结果。

> **摘要翻译:** 我们考虑 $k$-边连通生成子图 (kECSS) 问题，其中给定一个无向图 $G = (V, E)$ 具有非负边成本 $\{c_e\}_{e\in E}$，我们寻求 $G$ 中成本最小的 $k$-边连通子图 $H$。对于偶数 $k$，我们提出了一种多项式时间算法，该算法计算一个 $(k-2)$-边连通子图，其成本至多为 kECSS 的自然 LP-松弛的最优值 $LP^*$；对于奇数 $k$，我们获得一个 $(k-3)$-边连通子图，其成本至多为 $LP^*$。由于 kECSS 对于所有 $k\geq 2$ 都是 APX-hard 的，我们的结果几乎是最优的。它们还在解决方案质量以及算法及其分析的简单性方面显著改进了 Hershkowitz 等人的最新工作。我们的技术也产生了另一种保证，即我们获得一个 $(k-1)$-边连通子图，其成本至多为 $1.5\text{·}LP^*$；对于单位边成本，成本保证提高到 $(1+\frac{4}{3k})\text{·}LP^*$，这改进了单位边成本的最先进近似，但边连通性损失了一个单位。
我们的 kECSS 结果也为 $k$-边连通生成多图 (kECSM) 问题带来了结果，其中可以选择边的多个副本：对于偶数 $k$，我们获得了 $(1+2/k)$-近似算法，对于奇数 $k$，我们获得了 $(1+3/k)$-近似算法。
我们的技术扩展到 kECSS 和 kECSM 的度受限版本，其中我们还对节点施加了度下限和上限。对于这些度受限版本，我们获得了相同的成本和连通性保证，但在度限制方面存在（大约）2 的加性违反。这些是度受限 \{kECSS,kECSM\} 的第一批结果，其形式是获得的解决方案成本至多为最优值，并且连通性约束被加性常数违反。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [139] [Courcelle's Theorem for Lipschitz Continuity](https://arxiv.org/abs/2506.21118)
> *关于Lipschitz连续性的Courcelle定理*

*Tatsuya Gima, Soh Kumabe, Yuichi Yoshida* | **Category: cs.DS**

**Keywords:** Lipschitz连续性, 算法元定理, Courcelle定理, 有界树宽, 单二阶逻辑

**Comment:** ESA 2025, 27 pages

> **TL;DR:** 本文提出了Lipschitz连续算法领域的第一个算法元定理，可以看作是Courcelle定理的Lipschitz连续模拟，为有界树宽和有界团宽图上满足MSO逻辑约束的问题提供了具有多对数Lipschitz常数的近似算法。

**AI_Comments:** 本文通过引入一个元定理，为Lipschitz连续算法领域做出了重要贡献，将范式从特定问题设计转变为更统一的框架。这可能加速在结构化图上为各种组合问题开发稳定算法。与Courcelle定理的类比突出了其理论深度和潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** Lipschitz连续性衡量算法对输入扰动的稳定性，具有小Lipschitz常数的算法是理想的。然而，现有Lipschitz连续算法都是针对特定问题设计的。本文旨在提供一个通用的算法元定理来解决这一问题。

**Method:** 本文提出了Lipschitz连续算法的第一个算法元定理，该定理是Courcelle定理的Lipschitz连续模拟。具体地，针对在有界树宽图上，在满足MSO_2逻辑约束下最大化或最小化总权重的顶点集问题，以及在有界团宽图上满足MSO_1逻辑约束的问题，应用此元定理。此外，利用该元定理作为子程序，构建了Baker分解的Lipschitz连续版本。

**Result:** 对于有界树宽图上满足MSO_2约束的问题，本文提出了一个具有多对数Lipschitz常数的$(1\pm \varepsilon)$-近似算法。该结果在近似性和/或Lipschitz连续性方面优于大多数现有Lipschitz连续算法。对于有界团宽图上满足MSO_1约束的问题，也得到了类似的结果。此外，成功构建了Baker分解的Lipschitz连续版本。

**Conclusion:** 本文提供了Lipschitz连续算法领域的第一个算法元定理，为在有界树宽和有界团宽图上设计稳定的近似算法提供了一个通用框架，并超越了现有针对特定问题的算法。

> **ai_Abstract:** 本文提出了Lipschitz连续算法领域的第一个算法元定理，该定理是Courcelle定理的Lipschitz连续模拟。它为在有界树宽和有界团宽图上，受单二阶逻辑（MSO）约束的问题，提供了具有多对数Lipschitz常数的$(1\pm \varepsilon)$-近似算法。这项工作通过提供一个通用的框架来解决现有Lipschitz连续算法的特定问题限制，并在稳定性和近似质量方面优于现有方法。该元定理还被用于构建Baker分解的Lipschitz连续版本。

> **摘要翻译:** Lipschitz连续性算法由Kumabe和Yoshida（FOCS'23）引入，衡量算法对抗小输入扰动的稳定性。具有小Lipschitz连续性的算法是理想的，因为它们确保了可靠的决策和可重复的科学研究。一些研究已经提出了针对各种组合优化问题的Lipschitz连续算法，但这些算法是针对特定问题的，每个问题都需要单独设计。
为了解决这个问题，我们提供了Lipschitz连续算法领域的第一个算法元定理。我们的结果可以看作是Courcelle定理的Lipschitz连续模拟，它为有界树宽图上的问题提供了Lipschitz连续算法。具体来说，我们考虑在图上找到一个顶点集，该顶点集在满足单二阶逻辑（MSO_2）表达的约束下最大化或最小化总权重的问题。我们表明，对于任何$\varepsilon>0$，存在一个$(1\pm \varepsilon)$-近似算法，其在有界树宽图上的Lipschitz常数为多对数。在这些图上，我们的结果在近似性和/或Lipschitz连续性方面优于大多数现有Lipschitz连续算法。此外，我们为受MSO_1表达约束的有界团宽图上的问题提供了类似的结果。此外，我们利用我们的元定理作为子程序，构建了Baker分解的Lipschitz连续版本。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [157] [On Minimizing Wiggle in Stacked Area Charts](https://arxiv.org/abs/2506.21175)
> *堆叠面积图中最小化摆动*

*Alexander Dobler, Martin Nöllenburg* | **Category: cs.DS**

**Keywords:** 堆叠面积图, 摆动最小化, NP难, 混合整数线性规划, 计算复杂性

**Comment:** 19 pages, 3 figures

> **TL;DR:** 本文证明了堆叠面积图中最小化摆动问题是NP难的，并且难以近似，同时提出了精确的混合整数线性规划（MILP）公式，并分析了一个特殊情况的复杂性。

**AI_Comments:** 本文的创新之处在于首次对堆叠面积图中的“摆动”最小化问题进行了严格的计算复杂性分析，填补了该领域的一个空白。证明其为NP难且难以近似，对未来算法设计具有重要指导意义。提出的混合整数线性规划（MILP）公式为解决该问题提供了一个精确的方法，尽管可能计算成本较高。将该问题与“最小化绝对前缀和之和”这一基础数学问题联系起来，也展现了深刻的理论洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 堆叠面积图是一种广泛使用的数值时间序列可视化技术，其可读性的主要美学标准是时间序列之间边界的垂直变化量，即“摆动”。尽管已开发出许多启发式算法来最小化摆动，但最小化摆动的计算复杂性尚未得到正式分析。

**Method:** 本文正式分析了摆动最小化问题的计算复杂性，证明了不同变体是NP难的且难以近似。提出了一个精确的混合整数线性规划（MILP）公式，并与最先进的启发式算法进行了实验比较。最后，考虑了一个特殊情况，即最小化一组数字的绝对前缀和之和的问题，并展示了其复杂性结果。

**Result:** 本文证明了摆动最小化问题的不同变体是NP难的，甚至难以近似。提出了一个精确的混合整数线性规划（MILP）公式，并在实验评估中将其性能与最先进的启发式算法进行了比较。此外，还展示了最小化绝对前缀和之和这一特殊情况的复杂性结果，这些结果也暗示了摆动最小化的一些难度。

**Conclusion:** 本文正式确立了堆叠面积图中摆动最小化问题的计算复杂性，证明其为NP难且难以近似。同时提供了一个精确的混合整数线性规划解决方案，并通过分析一个相关的基础问题深化了对该问题的理解。

> **ai_Abstract:** 本文深入探讨了堆叠面积图中“摆动”最小化的问题，该问题关乎图表的可读性。此前，尽管存在多种启发式算法，但其计算复杂性未被正式分析。本研究首次证明了摆动最小化问题的不同变体是NP难的，甚至难以近似。为此，作者提出了一个精确的混合整数线性规划（MILP）公式，并与现有最佳启发式算法进行了实验比较。此外，文章还分析了一个相关的特殊情况——最小化一组数字的绝对前缀和之和，并揭示了其复杂性，从而进一步支持了摆动最小化问题的难度结论。

> **摘要翻译:** 堆叠面积图是一种广泛使用的数值时间序列可视化技术。X轴表示时间，时间序列以水平、高度可变的层叠方式显示。每层的高度对应于每个时间点的时间序列值。优化堆叠面积图可读性的主要美学标准是可视化中时间序列之间边界的垂直变化量，称为“摆动”。虽然已经开发了许多启发式算法来最小化摆动，但最小化摆动的计算复杂性尚未得到正式分析。在本文中，我们证明了摆动最小化问题的不同变体是NP难的，甚至难以近似。我们还提出了一个精确的混合整数线性规划公式，并在实验评估中将其性能与最先进的启发式算法进行了比较。最后，我们考虑了摆动最小化的一种特殊情况，它对应于对一组数字进行排序以最小化其绝对前缀和之和这一根本有趣且自然的问题。我们展示了该问题的几个复杂性结果，这些结果也暗示了摆动最小化的一些难度。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [176] [Edge Clique Partition and Cover Beyond Independence](https://arxiv.org/abs/2506.21216)
> *边团划分与覆盖超越独立集*

*Fedor V. Fomin, Petr A. Golovach, Danil Sagunov, Kirill Simonov* | **Category: cs.DS, cs.DM**

**Keywords:** 边团覆盖, 边团划分, 固定参数可解性, 独立集, 图论

**Comment:** An extended abstract of this paper appears in the proceedings of ESA
  2025

> **TL;DR:** 本文研究了边团覆盖和划分问题在最大独立集大小之上的参数化，揭示了两种变体不同的复杂性，并展示了在额外参数下边团覆盖问题的固定参数可解性。

**AI_Comments:** 本文提出了一种新颖的参数化方法，即“超越独立集”，这对于稀疏图比传统的总团数参数化更具意义。它揭示了在这一新视角下，边团覆盖和边团划分问题之间存在显著的复杂性差异，特别是ECC/α的NP完全性与ECP/α的FPT特性形成对比。针对k + ω(G)的参数化结果具有重要的实践价值，尤其适用于ω较小的稀疏图。

<details>
  <summary>Details</summary>

**Motivation:** 经典的边团覆盖和划分问题，当以团的总数作为参数时，对于稀疏图通常不适用。在许多实际情况下，边覆盖或划分中的最小团数可能非常接近最大独立集的大小α(G)。受此观察启发，作者研究了边团覆盖和划分问题在α之上的参数化。

**Method:** 作者引入并研究了超越独立集的边团覆盖（ECC/α）和超越独立集的边团划分（ECP/α）问题，目标是使用至多α(G) + k个团来覆盖或划分图的所有边，其中k是参数。他们分析了这些变体的复杂性。此外，他们还证明了当以k + ω(G)（其中ω(G)是图G的最大团大小）作为参数时，ECC/α是固定参数可解的，并为H-minor自由图设计了一个次指数算法。

**Result:** ECP/α是固定参数可解的。ECC/α对于所有k ≥ 2都是NP完全的，但对于k ∈ {0,1}可以在多项式时间内解决。当以k + ω(G)作为参数时，ECC/α变为固定参数可解。对于H-minor自由图，设计了一个运行时间为f(H)^√k * n^O(1)的次指数算法。

**Conclusion:** 这些发现突出了在超越自然下界（α(G)）的参数化视角下，边团覆盖和边团划分这两个问题之间存在的显著差异。ECC/α的k + ω(G)参数化结果对于稀疏图尤其重要。

> **ai_Abstract:** 该论文通过引入一种新的“超越α(G)”（最大独立集大小）的参数化方法，重新审视了经典的边团覆盖（ECC/α）和边团划分（ECP/α）问题。研究发现，ECP/α是固定参数可解的，而ECC/α对于k ≥ 2是NP完全的，但在k ∈ {0,1}时可在多项式时间内解决。此外，论文还指出，当以k + ω(G)（最大团大小）作为参数时，ECC/α变为固定参数可解，这对于稀疏图尤为重要，并为H-minor自由图提供了一个次指数算法。这项工作揭示了在这新参数化视角下两种问题截然不同的复杂性特征。

> **摘要翻译:** 将图的边覆盖和划分为团是组合优化和图论交叉领域的经典问题，已经通过一系列算法和复杂性理论视角进行了研究。尽管这些问题在以团的总数作为参数时具有众所周知的固定参数可解性，但这种参数化对于稀疏图通常意义不大。另一方面，在许多实际情况下，边覆盖或划分中的最小团数可能非常接近最大独立集的大小α(G)。
受此观察启发，我们研究了边团覆盖和划分问题在α之上的参数化。具体来说，我们引入并研究了超越独立集的边团覆盖（ECC/α）和超越独立集的边团划分（ECP/α），其目标是使用至多α(G) + k个团来覆盖或划分图的所有边，其中k是参数。我们的主要结果揭示了两种变体截然不同的复杂性图景。我们证明了ECP/α是固定参数可解的，而ECC/α对于所有k ≥ 2都是NP完全的，但对于k ∈ {0,1}可以在多项式时间内解决。这些发现突出了在超越自然下界（α(G)）的参数化视角下，这两个问题之间存在的引人入胜的差异。
最后，我们证明了当以k + ω(G)作为参数时，ECC/α变为固定参数可解的，其中ω(G)是图G的最大团的大小。这一结果对于稀疏图尤其重要，因为在稀疏图中ω通常很小。对于H-minor自由图，我们设计了一个运行时间为f(H)^√k * n^O(1)的次指数算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [190] [Vantage Point Selection Algorithms for Bottleneck Capacity Estimation](https://arxiv.org/abs/2506.21418)
> *瓶颈容量估计的视点选择算法*

*Vikrant Ashvinkumar, Rezaul Chowdhury, Jie Gao, Mayank Goswami, Joseph S. B. Mitchell, Valentin Polishchuk* | **Category: cs.DS**

**Keywords:** 瓶颈容量估计, 视点选择, 近似算法, 网络测量, 图论

**Comment:** 

> **TL;DR:** 本文研究了互联网瓶颈容量估计中的视点选择问题，提出了在非自适应和自适应设置下的算法，并给出了近似性能保证和界限。

**AI_Comments:** 这篇论文通过将互联网瓶颈容量估计问题抽象为图论中的视点选择问题，提供了一个新颖的建模方法。其创新之处在于区分了非自适应和自适应两种探测策略，并在不同假设下提供了理论上的近似保证和界限，这对于理解和解决网络测量中的资源优化问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机是解决互联网上的瓶颈容量估计问题。具体目标是从图中选择 $k$ 个视点，以揭示最大数量的瓶颈边容量。

**Method:** 论文将问题建模为在给定图 $G=(V, E)$ 中选择 $k$ 个视点，通过从这些视点沿最短路径探测来揭示瓶颈边容量。研究了两种设置：1. 非自适应设置：在揭示任何容量之前选择所有 $k$ 个视点。在此设置下，针对边容量从随机排列中抽取的宽松模型，提出了一个 $1-1/e$ 近似算法。2. 自适应设置：每次视点选择后立即揭示瓶颈容量。在此设置下，采用边容量任意固定但未知的模型，并提供了实例最优近似算法的下界以及针对树和平面图的上界。

**Result:** 在非自适应设置中，对于边容量从随机排列中抽取的模型，提供了一个 $1-1/e$ 近似算法。在自适应设置中，对于边容量任意固定但未知的模型，给出了实例最优近似算法的下界，并为树和平面图提供了上界。

**Conclusion:** 论文为瓶颈容量估计的视点选择问题提供了理论框架和算法，在非自适应和自适应两种设置及不同模型下取得了近似性能保证和边界，对网络测量中的资源优化具有指导意义。

> **ai_Abstract:** 这篇论文探讨了互联网瓶颈容量估计中的视点选择问题。作者将问题建模为在给定图中选择 $k$ 个视点，以最大化通过最短路径探测所能揭示的瓶颈边容量数量。论文研究了非自适应和自适应两种设置。在非自适应设置下，提出了一个 $1-1/e$ 近似算法；在自适应设置下，为任意固定但未知容量的模型提供了实例最优近似算法的下界以及针对特定图类型（如树和平面图）的上界。

> **摘要翻译:** 标题翻译：瓶颈容量估计的视点选择算法

摘要翻译：受互联网瓶颈容量估计问题的启发，我们提出并研究了视点选择问题。我们给定一个图 $G=(V, E)$，其边 $E$ 具有待发现的未知容量值。从一个视点（即一个顶点 $v \in V$）沿着从 $v$ 到所有其他顶点的最短路径进行探测，可以揭示每条路径上的瓶颈边容量。我们的目标是从 $V$ 中选择 $k$ 个视点，以揭示最大数量的瓶颈边容量。

我们考虑了两种设置：非自适应设置，其中在揭示任何瓶颈容量之前选择所有 $k$ 个视点；以及自适应设置，其中每次视点选择会立即揭示从该点开始的所有最短路径上的瓶颈容量。在非自适应设置中，通过考虑一个宽松模型（其中边容量从随机排列中抽取，这仍然使得最大化揭示边期望数量的问题是NP-难的），我们能够给出一个 $1-1/e$ 近似算法。在自适应设置中，我们采用最不宽松的模型，其中边容量是任意固定但未知的。我们与特定输入实例的最佳解决方案（即通过枚举所有 $k$ 元组的选择）进行比较，并提供了实例最优近似算法的下界以及针对树和平面图的上界。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [196] [Succinct Preferential Attachment Graphs](https://arxiv.org/abs/2506.21436)
> *简洁的优先连接图*

*Ziad Ismaili Alaoui, Namrata, Sebastian Wild* | **Category: cs.DS, cs.IT, math.IT, math.PR**

**Keywords:** 简洁数据结构, 优先连接图, 图压缩, 实例最优空间

**Comment:** WG 2025

> **TL;DR:** 本文设计了一种新的图数据结构，其空间使用量能根据图的可压缩性自动优化，尤其适用于优先连接图，同时支持高效导航操作。

**AI_Comments:** 这项工作的创新之处在于其设计的图数据结构能够实现“实例最优”的空间使用，即空间效率随图的可压缩性而提高，而非依赖于最坏情况或特定图类。这对于处理具有不同可压缩性的实际图数据具有重要意义。对实例最优空间使用量的严格分析是其重要的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有压缩图数据结构通常局限于特定图类，并且对该类中的所有图都使用相同的最坏情况空间量。研究的动机在于设计一种空间使用量能随图可压缩性自动改进，并能高效支持查询操作的图数据结构。

**Method:** 本文设计了一种新的数据结构，其空间使用量能够随着给定图的可压缩性自动优化。研究方法包括分析该数据结构在经典Barabási-Albert优先连接图模型下的性能，证明其空间使用量接近实例最优空间，并验证其对任意图的适用性，保证大小不大于熵压缩的边列表。关键技术贡献是对实例最优空间使用量的仔细分析。

**Result:** 设计的数据结构在图根据经典Barabási-Albert优先连接图模型绘制时，其空间使用量接近实例最优空间。对于任意图，该数据结构保证其大小渐近不大于熵压缩的边列表。此外，它还能高效支持导航操作（模拟邻接表访问）。

**Conclusion:** 本文成功设计了一种图数据结构，该结构能够根据图的可压缩性自动优化空间使用，并在优先连接图上实现了接近实例最优的空间效率，同时保持了高效的导航操作支持。

> **ai_Abstract:** 本文提出了一种新颖的图数据结构，旨在克服现有简洁图结构在空间效率上的局限性。该数据结构能够根据图的可压缩性自动调整其空间使用量，特别是在Barabási-Albert优先连接图上实现了接近实例最优的空间效率，并对任意图保证了渐近高效的空间占用（不大于熵压缩的边列表）。同时，它能高效支持图的导航操作。

> **摘要翻译:** 对压缩数据进行计算结合了数据压缩的空间节省和直接在压缩表示上高效支持查询的优点。这类数据结构广泛应用于文本索引，并已成功推广到树。对于图，对压缩数据进行计算的支持仍然不完善；简洁数据结构领域的典型结果仅限于特定类别的图，并且对该类别中的任何图都使用相同的最坏情况空间量。
在这项工作中，我们设计了一种数据结构，其空间使用量会随着当前图的可压缩性自动提高，同时有效支持导航操作（模拟邻接表访问）。具体来说，我们表明当图根据经典的Barabási-Albert优先连接图模型绘制时，其空间使用量接近实例最优空间。我们的数据结构技术也适用于任意图，保证其大小渐近不大于熵压缩的边列表。一个关键的技术贡献是对实例最优空间使用量的仔细分析。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [22] [Generative Blocks World: Moving Things Around in Pictures](https://arxiv.org/abs/2506.20703)
> *生成式积木世界：在图片中移动物体*

*Vaibhav Vavilala, Seemandhar Jain, Rahul Vasanth, D. A. Forsyth, Anand Bhattad* | **Category: cs.GR, cs.CV**

**Keywords:** 生成式积木世界, 图像编辑, 3D基元, 纹理一致性, 流模型

**Comment:** 23 pages, 16 figures, 2 tables

> **TL;DR:** 该论文介绍了“生成式积木世界”，通过操作简单的几何抽象来编辑生成图像的场景。该方法将场景表示为凸面3D基元的组合，并通过基于流的方法生成图像，该方法以深度和纹理提示为条件，从而提高了视觉保真度、可编辑性和组合泛化能力。

**AI_Comments:** 该论文的创新之处在于其“生成式积木世界”概念，通过将场景抽象为可操作的3D基元，极大地提升了生成图像的可编辑性。特别是其改进的纹理提示机制，超越了传统的缓存技术，在编辑过程中保持了卓越的纹理一致性和物体身份，这对于实现逼真且可控的图像编辑至关重要。其对视觉保真度、可编辑性和组合泛化能力的全面提升，使其在图像生成和编辑领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在通过操纵简单的几何抽象来与生成图像的场景进行交互，允许编辑者移动整个结构或小细节，并解决现有纹理一致性技术的不足。

**Method:** 该方法将场景表示为凸面3D基元的组合，同一个场景可以用不同数量的基元表示。场景几何编辑后，图像通过基于流的方法生成，该方法以深度和纹理提示为条件。纹理提示考虑了修改后的3D基元，超越了现有键值缓存技术提供的纹理一致性。

**Result:** 该方法允许精确的物体和相机移动，并在很大程度上保留了所描绘物体的身份。定量和定性实验表明，该方法在视觉保真度、可编辑性和组合泛化方面优于现有工作。

**Conclusion:** 该论文提出的“生成式积木世界”方法通过操纵简单的几何抽象，有效实现了对生成图像场景的交互和编辑，在视觉保真度、可编辑性和组合泛化方面均优于现有方法。

> **ai_Abstract:** 本文提出了“生成式积木世界”，一种通过操纵简单3D几何基元来编辑生成图像场景的方法。该方法将场景表示为可变数量的凸面3D基元，支持从整体到细节的编辑。图像生成采用基于流的方法，并结合了创新的纹理提示，该提示考虑了修改后的3D基元，有效提升了纹理一致性。实验证明，该方法在视觉保真度、可编辑性和组合泛化能力上均优于现有技术，同时能准确移动物体和相机并保持物体身份。

> **摘要翻译:** 我们描述了生成式积木世界，通过操纵简单的几何抽象来与生成图像的场景进行交互。我们的方法将场景表示为凸面3D基元的组合，同一个场景可以用不同数量的基元表示，允许编辑者移动整个结构或小细节。一旦场景几何被编辑，图像将通过基于流的方法生成，该方法以深度和纹理提示为条件。我们的纹理提示考虑了修改后的3D基元，超越了现有键值缓存技术提供的纹理一致性。这些纹理提示(a)允许精确的物体和相机移动，(b)在很大程度上保留了所描绘物体的身份。定量和定性实验表明，我们的方法在视觉保真度、可编辑性和组合泛化方面优于现有工作。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [46] [3DGH: 3D Head Generation with Composable Hair and Face](https://arxiv.org/abs/2506.20875)
> *3DGH：可组合发型和面部的三维头部生成*

*Chengan He, Junxuan Li, Tobias Kirschstein, Artem Sevastopolsky, Shunsuke Saito, Qingyang Tan, Javier Romero, Chen Cao, Holly Rushmeier, Giljoo Nam* | **Category: cs.GR, cs.CV**

**Keywords:** 三维头部生成, 生成模型, 高斯溅射, 可组合, 头发-面部分离

**Comment:** Accepted to SIGGRAPH 2025. Project page:
  https://c-he.github.io/projects/3dgh/

> **TL;DR:** 3DGH是一个生成模型，可以生成具有可组合发型和面部组件的三维人头，解决了以往方法中头发和面部纠缠的问题。

**AI_Comments:** 该论文的创新之处在于成功地将三维头部生成中的头发和面部组件解耦，这对于实现更可控和可组合的三维资产创建具有重要意义。在三维高斯溅射中引入可变形头发几何体以及使用带有交叉注意力机制的双生成器GAN是其关键的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 以往的工作将头发和面部的建模纠缠在一起，限制了三维头部生成的可组合性。

**Method:** 提出了一种使用基于模板的三维高斯溅射的新型数据表示，引入可变形头发几何体以捕获发型变化。基于此，设计了具有双生成器的三维GAN架构，并采用交叉注意力机制建模头发和面部之间的相关性。模型在合成渲染图上训练，并使用精心设计的目标函数以稳定训练和促进头发-面部分离。

**Result:** 在无条件全头图像合成和可组合三维发型编辑方面表现出有效性。通过与几种最先进的三维GAN方法进行定性和定量比较，验证了其设计选择和有效性。

**Conclusion:** 3DGH成功地提出了一个新颖的无条件生成模型，用于生成具有解耦和可组合头发与面部组件的三维人头，在性能和编辑能力上优于现有方法。

> **ai_Abstract:** 3DGH提出了一种新颖的无条件三维人头生成模型，该模型将头发和面部组件解耦。它采用基于模板的三维高斯溅射表示（包含可变形头发几何体）以及具有双生成器和交叉注意力机制的三维GAN架构。3DGH在合成数据上训练，能够有效地进行全头合成和可组合发型编辑，优于现有三维GAN方法。

> **摘要翻译:** 我们提出了3DGH，一个用于生成具有可组合发型和面部组件的三维人头的无条件生成模型。与以往将头发和面部建模纠缠在一起的工作不同，我们提出使用一种基于模板的三维高斯溅射的新型数据表示来分离它们，其中引入了可变形头发几何体以捕获不同发型之间的几何变化。基于这种数据表示，我们设计了一种具有双生成器的三维GAN架构，并采用交叉注意力机制来模拟头发和面部之间固有的相关性。该模型在合成渲染图上进行训练，并采用精心设计的目标函数以稳定训练并促进头发-面部分离。我们进行了广泛的实验来验证3DGH的设计选择，并通过与几种最先进的三维GAN方法进行比较，对其进行了定性和定量评估，证明了其在无条件全头图像合成和可组合三维发型编辑方面的有效性。更多详情将在我们的项目页面上提供：https://c-he.github.io/projects/3dgh/。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [70] [Data Visualization for Improving Financial Literacy: A Systematic Review](https://arxiv.org/abs/2506.20901)
> *数据可视化在提升金融素养方面的应用：一项系统综述*

*Meng Du, Robert Amor, Kwan-Liu Ma, Burkhard C. Wünsche* | **Category: cs.GR**

**Keywords:** 数据可视化, 金融素养, 系统综述, 金融教育, 视觉分析

**Comment:** 

> **TL;DR:** 本系统综述分析了37篇研究论文，探讨了数据可视化在金融教育中的应用，并将其分为五个关键领域，旨在识别研究空白并为教育者和专业人士提供实用见解，以提高金融素养。

**AI_Comments:** 该论文通过系统综述的方法，全面梳理了数据可视化在金融素养领域的研究现状，其创新之处在于对现有文献进行了细致的分类和归纳，并明确指出了研究空白和未来发展方向。这对于推动金融教育领域的数据可视化应用具有重要的指导意义。其局限性可能在于仅限于现有文献的分析，未涉及实证研究。

<details>
  <summary>Details</summary>

**Motivation:** 许多人觉得理解金融概念很困难，且只有一半的美国成年人被认为是具备金融素养的。数据可视化能够简化这些概念，使其更易于理解和吸引人。

**Method:** 本研究进行了一项系统综述，分析了37篇探讨数据可视化和视觉分析在金融教育及素养提升中应用的研究论文。这些研究被分为五个关键领域进行分类：可视化使用的时间和空间演变、使用可视化工具的动机、涉及的金融主题和教学方法、应用的工具和技术类型，以及教学干预有效性的评估方式。

**Result:** 研究结果识别了数据可视化在金融素养领域的研究空白，并强调了进一步发展的机会。此外，研究发现为教育者和专业人士提供了实用见解，以有效利用或设计视觉工具来提升金融素养。

**Conclusion:** 本系统综述的结论是，通过分析现有研究，识别了数据可视化在金融素养领域的研究空白和发展机遇，并为教育者和专业人士提供了利用视觉工具提升金融素养的实用指导。

> **ai_Abstract:** 本系统综述探讨了数据可视化在提升金融素养方面的应用。针对金融概念理解困难及金融素养普遍不足的问题，研究分析了37篇相关论文，并将其归类为五个方面：可视化演变、使用动机、主题与方法、工具与技术以及效果评估。研究旨在识别现有研究空白并提供实用见解，以帮助教育者和专业人士有效利用视觉工具促进金融素养的提升。

> **摘要翻译:** 金融素养使个人能够做出明智有效的金融决策，从而改善他们的整体财务福祉和安全。然而，对许多人来说，理解金融概念可能令人望而生畏，而且只有一半的美国成年人被认为是具备金融素养的。数据可视化简化了这些概念，使所有年龄段的学习者都能轻松接触并参与其中。本系统综述分析了37篇研究论文，探讨了数据可视化和视觉分析在金融教育和素养提升中的应用。我们将这些研究分为五个关键领域：(1) 可视化使用随时间和空间的演变，(2) 使用可视化工具的动机，(3) 所涉及的金融主题和所使用的教学方法，(4) 所应用的工具和技术类型，以及 (5) 教学干预有效性的评估方式。此外，我们还识别了研究空白，并强调了提升金融素养的机会。我们的研究结果为教育者和专业人士有效利用或设计视觉工具以提升金融素养提供了实用见解。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [95] [Consistent Zero-shot 3D Texture Synthesis Using Geometry-aware Diffusion and Temporal Video Models](https://arxiv.org/abs/2506.20946)
> *使用几何感知扩散和时间视频模型实现一致的零样本3D纹理合成*

*Donggoo Kang, Jangyeong Kim, Dasol Jeong, Junyoung Choi, Jeonga Wi, Hyunmin Lee, Joonho Gwon, Joonki Paik* | **Category: cs.GR, cs.AI, cs.CV, 68T45, 68U05, I.3.7; I.4.10; I.2.10**

**Keywords:** 3D纹理合成, 视频生成模型, 几何感知扩散, 时间一致性, 零样本

**Comment:** 

> **TL;DR:** VideoTex利用视频生成模型和几何感知扩散，解决了3D纹理合成中的空间和时间不一致问题，生成高质量、稳定的纹理。

**AI_Comments:** 该论文通过将视频生成模型引入3D纹理合成，巧妙地解决了传统方法中存在的空间和时间不一致性问题，具有创新性。其引入的几何感知条件和结构化UV扩散策略，有效提升了纹理质量，尤其是在复杂几何体的处理上。VideoTex的成功为实时3D渲染和动态应用开辟了新的可能性，前景广阔。

<details>
  <summary>Details</summary>

**Motivation:** 当前纹理合成方法因缺乏全局上下文和几何理解，在固定视角下生成纹理时存在不一致性。

**Method:** 本文引入VideoTex框架，利用视频生成模型解决3D纹理的空间和时间不一致性。该方法结合几何感知条件以精确利用3D网格结构，并提出结构化UV扩散策略，通过保留语义信息增强遮挡区域生成，从而产生更平滑、更连贯的纹理。

**Result:** VideoTex实现了UV边界间的平滑过渡，并确保了视频帧间高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法。

**Conclusion:** VideoTex为需要视觉质量和时间连贯性的动态实时应用铺平了道路。

> **ai_Abstract:** VideoTex是一个新颖的3D纹理合成框架，它利用视频生成模型和几何感知条件来解决当前方法中存在的空间和时间不一致性。通过引入结构化UV扩散策略，VideoTex能生成更平滑、连贯的纹理，尤其是在遮挡区域。实验证明，VideoTex在纹理质量、接缝处理和时间稳定性上均优于现有技术，为实时动态应用提供了高质量的视觉和时间连贯性。

> **摘要翻译:** 当前从固定视角生成纹理的方法，由于缺乏全局上下文和几何理解，存在不一致性问题。同时，视频生成模型的最新进展在实现时间上一致的视频方面取得了显著成功。在本文中，我们引入了VideoTex，一个用于无缝纹理合成的新颖框架，它利用视频生成模型来解决3D纹理中的空间和时间不一致性。我们的方法结合了几何感知条件，能够精确利用3D网格结构。此外，我们提出了一种结构化UV扩散策略，通过保留语义信息来增强遮挡区域的生成，从而产生更平滑、更连贯的纹理。VideoTex不仅实现了UV边界间的平滑过渡，还确保了视频帧间高质量、时间稳定的纹理。大量实验表明，VideoTex在纹理保真度、接缝融合和稳定性方面优于现有方法，为需要视觉质量和时间连贯性的动态实时应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [118] [FairyGen: Storied Cartoon Video from a Single Child-Drawn Character](https://arxiv.org/abs/2506.21272)
> *FairyGen：从单个儿童绘画角色生成故事卡通视频*

*Jiayi Zheng, Xiaodong Cun* | **Category: cs.GR, cs.CV, cs.MM**

**Keywords:** 卡通视频生成, 儿童绘画, 风格迁移, 故事驱动动画, 扩散模型

**Comment:** Project Page: https://jayleejia.github.io/FairyGen/ ; Code:
  https://github.com/GVCLab/FairyGen

> **TL;DR:** FairyGen是一个自动系统，能从单个儿童绘画角色生成故事驱动的卡通视频，同时忠实保留其独特艺术风格。

**AI_Comments:** FairyGen的创新之处在于其能够从单个儿童绘画中生成复杂的、故事驱动的卡通视频，同时忠实地保留原始艺术风格。它通过将角色建模与背景生成解耦、引入电影镜头设计以及采用先进的扩散模型和运动定制技术，显著提升了自动化故事动画的质量和表现力。这对于个性化内容创作和教育领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 与之前主要关注角色一致性和基本运动的讲故事方法不同，FairyGen旨在解决现有方法在风格化背景生成和电影镜头设计方面的不足，以支持更具表现力和连贯性的故事讲述。

**Method:** FairyGen首先利用MLLM从单个角色草图生成带镜头描述的结构化故事板。为确保视觉一致性，引入了风格传播适配器，将角色视觉风格应用于背景。镜头设计模块通过画面裁剪和多视角合成增强视觉多样性和电影质量。为动画化故事，系统重建角色的3D代理以导出物理上合理的运动序列，并用于微调基于MMDiT的图像到视频扩散模型。此外，提出了一个两阶段运动定制适配器，第一阶段从无序帧中学习外观特征以解耦身份和运动，第二阶段使用时间步移位策略建模时间动态。

**Result:** FairyGen系统生成的动画在风格上忠实于原始绘画，叙事结构化，并具有自然的运动。

**Conclusion:** FairyGen系统展示了其在个性化和引人入胜的故事动画方面的巨大潜力。

> **ai_Abstract:** FairyGen是一个创新的自动化系统，能够将儿童的单个绘画角色转化为风格忠实且叙事驱动的卡通视频。它通过解耦角色建模与风格化背景生成、整合电影镜头设计、利用MLLM生成故事板、以及通过3D代理和MMDiT扩散模型实现逼真动画来突破传统限制。该系统还引入了风格传播适配器和两阶段运动定制适配器，以确保视觉一致性和自然运动。实验证明，FairyGen能生成高质量、个性化且引人入胜的动画。

> **摘要翻译:** 我们提出了FairyGen，一个从单个儿童绘画生成故事驱动卡通视频的自动化系统，同时忠实保留其独特的艺术风格。与之前主要关注角色一致性和基本运动的讲故事方法不同，FairyGen明确地将角色建模与风格化背景生成解耦，并融入电影镜头设计以支持富有表现力和连贯性的故事讲述。给定一个单个角色草图，我们首先采用多模态大型语言模型（MLLM）生成一个结构化的故事板，其中包含指定环境设置、角色动作和摄像机视角的镜头级描述。为确保视觉一致性，我们引入了一个风格传播适配器，该适配器捕捉角色的视觉风格并将其应用于背景，忠实地保留角色的完整视觉特征，同时合成风格一致的场景。一个镜头设计模块通过基于故事板的画面裁剪和多视角合成进一步增强视觉多样性和电影质量。为了动画化故事，我们重建角色的3D代理以导出物理上合理的运动序列，然后用于微调基于MMDiT的图像到视频扩散模型。我们进一步提出了一个两阶段运动定制适配器：第一阶段从时间无序的帧中学习外观特征，将身份与运动解耦；第二阶段使用带有冻结身份权重的timestep-shift策略建模时间动态。一旦训练完成，FairyGen直接渲染与故事板对齐的各种连贯视频场景。大量的实验表明，我们的系统生成的动画在风格上忠实、叙事结构化且具有自然运动，突显了其在个性化和引人入胜的故事动画方面的潜力。代码将在https://github.com/GVCLab/FairyGen提供。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [138] [IDGraphs: Intrusion Detection and Analysis Using Stream Compositing](https://arxiv.org/abs/2506.21425)
> *IDGraphs：使用流合成的入侵检测与分析*

*Pin Ren, Yan Gao, Zhichun Li, Yan Chen, Benjamin Watson* | **Category: cs.GR, cs.CR**

**Keywords:** 入侵检测, 流量分析, 可视化, 流合成, 网络安全

**Comment:** 

> **TL;DR:** IDGraphs是一个交互式可视化系统，用于入侵检测，它通过流级跟踪的可视化和Histographs技术来检测和分析各种网络攻击和异常，解决了现有IDS的局限性。

**AI_Comments:** IDGraphs的创新之处在于其将交互式可视化与流级数据分析相结合，特别是引入了Histographs技术来高效处理和总结大规模网络流量数据，从而有效解决了传统IDS在分析复杂和分布式攻击方面的不足。其对实际大型网络数据集的应用验证了其有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有入侵检测系统在交互式检查入侵、分析蠕虫传播模式和发现相关攻击方面支持有限，且面对高速路由器流量增长时问题更加突出，因此需要一种新的解决方案。

**Method:** IDGraphs是一个交互式可视化系统，其核心是流级跟踪的可视化，以时间为横轴，聚合的未成功连接数为纵轴。系统使用Histographs技术总结大量跟踪，将数据频率映射到亮度，并允许用户交互式查询和分析摘要视图，例如通过关联矩阵视图突出显示相似模式的跟踪以发现分布式攻击。

**Result:** IDGraphs系统成功应用于包含1.79亿流级记录的真实网络路由器数据集，并成功检测并分析了多种攻击和异常，包括端口扫描、蠕虫爆发、隐蔽TCP SYN洪水和一些分布式攻击。

**Conclusion:** IDGraphs系统能够有效解决现有入侵检测系统面临的挑战，提供了一种准确、快速地检测和分析网络流量异常和攻击的方法。

> **ai_Abstract:** IDGraphs是一个创新的交互式可视化系统，旨在解决现有入侵检测系统在检测和分析网络入侵方面的局限性。它通过可视化流级跟踪并利用Histographs技术汇总大量数据，使用户能够交互式地识别和分析各种攻击模式，包括难以发现的分布式攻击。该系统在真实网络数据上的应用证明了其在检测端口扫描、蠕虫爆发和TCP SYN洪水等攻击方面的有效性。

> **摘要翻译:** 当今网络中，流量异常和攻击司空见惯，对于大型网络运营商而言，快速准确地识别它们至关重要。对于统计入侵检测系统（IDS）而言，在流级别进行检测对于准确检测和缓解至关重要。然而，现有IDS系统在以下方面提供的支持有限：1）交互式检查已检测到的入侵和异常，2）分析蠕虫传播模式，3）发现相关攻击。随着当今高速路由器上的流量持续增长，这些问题变得更加严峻。
IDGraphs是一个交互式可视化系统，用于入侵检测，旨在解决这些挑战。该系统的核心可视化是一个流级跟踪，以时间为横轴，聚合的未成功连接数为纵轴绘制。然后，我们使用Histographs [RW05] 技术总结了数万甚至数十万条此类跟踪，该技术将每个像素的数据频率映射到亮度。用户可以交互式查询摘要视图，通过突出显示跟踪的子集进行分析。例如，刷选链接的关联矩阵视图会突出显示具有相似模式的跟踪，从而揭示使用标准统计分析难以检测的分布式攻击。
我们将IDGraphs系统应用于一个真实的网络路由器数据集，该数据集包含1.79亿条流级记录，总流量为1.16TB。该系统成功检测并分析了各种攻击和异常，包括端口扫描、蠕虫爆发、隐蔽TCP SYN洪水以及一些分布式攻击。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [25] [RAG-VisualRec: An Open Resource for Vision- and Text-Enhanced Retrieval-Augmented Generation in Recommendation](https://arxiv.org/abs/2506.20817)
> *RAG-VisualRec：一个用于推荐系统中视觉和文本增强检索增强生成开放资源*

*Ali Tourani, Fatemeh Nazary, Yashar Deldjoo* | **Category: cs.IR, cs.MM**

**Keywords:** 多模态推荐, 检索增强生成, 视觉嵌入, 数据增强, 协同过滤

**Comment:** 20 pages, 6 figures, 5 tables

> **TL;DR:** 本文介绍了RAG-VisualRec，一个结合LLM生成的剧情描述和预告片视觉嵌入，以增强电影推荐系统中的检索增强生成和协同过滤的开放资源，尤其在元数据有限的情况下表现出色。

**AI_Comments:** 该论文通过结合文本和视觉信息，为多模态推荐系统提供了一个有价值的开放资源，尤其在解决电影领域元数据稀疏问题上具有创新性。其数据增强和多模态融合策略是亮点，为提升推荐质量提供了有效途径。该资源的开放性将有助于社区进一步研究和开发。

<details>
  <summary>Details</summary>

**Motivation:** 电影领域有限的元数据（如标题、类型）阻碍了鲁棒推荐系统的生成，因此需要开发多模态推荐系统来解决这一挑战。

**Method:** 引入了一个结合LLM生成的剧情描述和预告片衍生的视觉嵌入的统一管道，支持检索增强生成（RAG）和协同过滤。核心方法包括数据增强步骤（将稀疏元数据转化为更丰富的文本信号）和融合策略（如PCA、CCA）来整合视觉线索。

**Result:** 实验评估表明，与单模态基线相比，基于CCA的融合显著提高了召回率。LLM驱动的重排序步骤进一步改善了NDCG，特别是在文本数据有限的情况下。

**Conclusion:** 通过发布RAG-VisualRec框架，作者旨在邀请进一步探索针对冷启动、新颖性聚焦和领域特定设置的多模态推荐技术。

> **ai_Abstract:** 本文提出了RAG-VisualRec，一个针对电影推荐的多模态开放资源。它通过结合LLM生成的剧情描述和预告片视觉嵌入，解决了元数据稀疏的问题。该框架利用数据增强和CCA等融合策略，在RAG和协同过滤中提升了推荐性能，尤其在召回率和NDCG方面表现出色。研究成果旨在推动冷启动、新颖性及特定领域的多模态推荐技术发展。

> **摘要翻译:** 本文旨在解决电影领域开发多模态推荐系统所面临的挑战，在该领域，有限的元数据（例如，标题、类型）通常会阻碍鲁棒推荐的生成。我们引入了一种资源，它将LLM生成的剧情描述与预告片衍生的视觉嵌入结合在一个统一的管道中，支持检索增强生成（RAG）和协同过滤。我们方法的核心是一个数据增强步骤，它将稀疏元数据转换为更丰富的文本信号，同时采用融合策略（例如，PCA、CCA）来整合视觉线索。实验评估表明，与单模态基线相比，基于CCA的融合显著提高了召回率，而LLM驱动的重排序步骤进一步改善了NDCG，特别是在文本数据有限的情况下。通过发布此框架，我们邀请进一步探索针对冷启动、新颖性聚焦和领域特定设置的多模态推荐技术。所有代码、数据和详细文档均公开可用：https://github.com/RecSys-lab/RAG-VisualRec

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [49] [The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers](https://arxiv.org/abs/2506.20844)
> *科学事实核查的下一阶段：从复杂结构化学术论文中进行高级证据检索*

*Xingyu Deng, Xi Wang, Mark Stevenson* | **Category: cs.IR, H.3.3**

**Keywords:** 科学事实核查, 证据检索, 信息检索, 学术论文, 文档解析

**Comment:** Accepted for ACM SIGIR Conference on Innovative Concepts and Theories
  in Information Retrieval (ICTIR'25)

> **TL;DR:** 当前的科学事实核查系统在处理复杂的完整学术论文时面临挑战。本文揭示了证据检索的关键挑战，并提出需要一个专门的信息检索系统来推进科学事实核查。

**AI_Comments:** 该论文的创新之处在于将科学事实核查的焦点从简化的摘要层面转移到更具挑战性和现实意义的完整、复杂学术文档。它系统性地识别了证据检索中的关键技术和概念障碍，为未来构建鲁棒的、面向实际应用的科学事实核查系统提供了路线图。其对结构化解析、时间感知检索和多模态内容的强调尤其具有前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 现有科学事实核查方法侧重于简化问题和小型数据集（摘要），未能有效处理完整学术论文的结构复杂性、科学知识的演变性质以及多模态科学表达。因此，需要开发更先进的系统来克服这些局限性并提升性能。

**Method:** 本文审视了当前科学事实核查系统的局限性，揭示了可利用的潜在特征和资源。它识别了证据检索中的五大关键研究挑战（包括语义、时间、结构化解析、复杂表达和可信度评估），并进行了初步实验来证实这些挑战并确定潜在解决方案。这是一篇旨在通过专业信息检索系统推进科学事实核查的观点论文。

**Result:** 本文识别了科学事实核查中证据检索的五大关键研究挑战，并指出需要一个专门的信息检索系统来克服这些挑战。初步实验证实了这些挑战的存在并提供了潜在的解决方案方向。

**Conclusion:** 本文旨在通过开发一个为实际应用量身定制的专业信息检索系统，来推进科学事实核查的领域，从而克服当前系统在处理复杂学术论文方面的局限性。

> **ai_Abstract:** 这篇观点论文探讨了当前科学事实核查系统的局限性，指出它们未能有效处理完整学术论文的复杂性。文章识别了高级证据检索中的五大关键挑战，包括语义和时间问题、结构化文档解析、复杂科学表达处理以及可信度评估。论文强调，需要开发一个专门的信息检索系统，以应对这些挑战并推进科学事实核查在实际应用中的发展。初步实验支持了所识别的挑战和潜在解决方案。

> **摘要翻译:** 科学事实核查旨在通过从研究文献中检索和分析证据来确定科学主张的真实性。这个问题比一般的事实核查本质上更复杂，因为它必须适应科学知识的演变性质、学术文献的结构复杂性以及长篇、多模态科学表达带来的挑战。然而，现有方法侧重于基于小规模数据集（由摘要而非完整论文组成）的简化问题版本，从而避免了处理完整文档所带来的独特挑战。本文审视了当前科学事实核查系统的局限性，并揭示了许多可用于提升其性能的潜在特征和资源。它指出了证据检索中的关键研究挑战，包括 (1) 解决语义限制和主题不平衡的证据驱动检索，(2) 结合引文跟踪以缓解过时信息的时间感知证据检索，(3) 利用长程上下文的结构化文档解析，(4) 处理复杂的科学表达，包括表格、图表和领域特定术语，以及 (5) 评估科学文献的可信度。进行了初步实验以证实这些挑战并确定潜在解决方案。这篇观点论文旨在通过一个为实际应用量身定制的专业信息检索系统来推进科学事实核查。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [73] [Towards Two-Stage Counterfactual Learning to Rank](https://arxiv.org/abs/2506.20854)
> *面向两阶段反事实排序学习*

*Shashank Gupta, Yiming Liao, Maarten de Rijke* | **Category: cs.IR**

**Keywords:** 反事实排序学习, 两阶段排序, 偏差校正, 候选生成, 排序器优化

**Comment:** Accepted at ICTIR 2025 (co-located with SIGIR 2025)

> **TL;DR:** 针对大规模排序中单阶段反事实排序学习(CLTR)的不切实际性，本文提出了一种新颖的两阶段CLTR估计器和联合优化方法，用于同时训练候选生成器和排序器，并在半合成基准上验证了其有效性。

**AI_Comments:** 本文通过将反事实排序学习（CLTR）扩展到两阶段架构，并提出联合优化方法，成功地弥合了CLTR理论与大规模实际应用之间的鸿沟，是该领域的一项重要创新。其核心贡献在于首次提出了针对两阶段排序的CLTR估计器和学习方法，特别强调了阶段间交互和联合价值估计，这对于提升真实世界排序系统的性能至关重要。一个潜在的局限性是实验仅在“半合成基准”上进行，其结果可能无法完全代表复杂生产环境中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有反事实排序学习（CLTR）方法采用单阶段策略，在处理数百万文档的实际大规模排序系统时效率低下且不切实际。尽管实际系统采用两阶段架构，但现有针对两阶段离线排序系统的CLTR方法存在局限性（例如，只考虑前1个排序设置，且排序器固定），并且缺乏一种能够联合训练排序器和候选生成器的CLTR方法。

**Method:** 本文提出了一种两阶段CLTR估计器，该估计器考虑了两个阶段之间的交互作用，并能够离线估计两种策略的联合价值。此外，论文还提出了一种新颖的联合优化方法，用于分别训练候选生成器和排序器策略。

**Result:** 在半合成基准上的实验结果表明，所提出的联合CLTR方法比基线方法更有效。

**Conclusion:** 据作者所知，本文首次提出了一种针对两阶段排序系统的反事实排序学习估计器和学习方法，弥补了现有文献中在实际大规模应用方面的一个关键空白。

> **ai_Abstract:** 本论文旨在解决现有反事实排序学习（CLTR）方法在处理大规模真实世界排序系统时的局限性，因为这些系统通常包含数百万文档且采用两阶段架构。针对现有CLTR方法无法有效处理两阶段系统，尤其是缺乏联合训练候选生成器和排序器的方法，本文提出了一种新颖的两阶段CLTR估计器。该估计器考虑了两个阶段间的交互，并能离线估计两策略的联合价值。此外，论文还引入了一种联合优化方法来训练这两个阶段的策略。在半合成基准上的实验结果验证了所提出联合CLTR方法的有效性。

> **摘要翻译:** 反事实排序学习 (CLTR) 旨在从用户交互中学习排序策略，同时纠正交互数据中固有的偏差，例如位置偏差。现有的 CLTR 方法假设采用单一的排序策略，从整个文档候选集中选择前 K 个排序结果。在实际应用中，候选文档集可能达到数百万，这使得单一阶段的排序策略不切实际。为了扩展到数百万文档，实际的排序系统被设计成两阶段模式，即先有候选生成器，后有排序器。现有的针对两阶段离线排序系统的 CLTR 方法只考虑了前 1 个排序设置，并且只专注于训练候选生成器，而排序器是固定的。现有文献中缺乏一种用于联合训练排序器和候选生成器的 CLTR 方法。在本文中，我们提出了一种两阶段 CLTR 估计器，该估计器考虑了两个阶段之间的交互，并离线估计了两种策略的联合价值。此外，我们提出了一种新颖的联合优化方法，分别训练候选和排序器策略。据我们所知，我们是第一个提出两阶段排序的 CLTR 估计器和学习方法。在半合成基准上的实验结果表明，所提出的联合 CLTR 方法优于基线方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [98] [EraRAG: Efficient and Incremental Retrieval Augmented Generation for Growing Corpora](https://arxiv.org/abs/2506.20963)
> *EraRAG：面向不断增长语料库的高效增量检索增强生成*

*Fangyuan Zhang, Zhengjun Huang, Yingli Zhou, Qintian Guo, Zhixun Li, Wensheng Luo, Di Jiang, Yixiang Fang, Xiaofang Zhou* | **Category: cs.IR, cs.LG**

**Keywords:** 检索增强生成, 动态更新, 图神经网络, 局部敏感哈希, 可扩展性

**Comment:** Under review

> **TL;DR:** EraRAG是一种新型的多层图检索增强生成（Graph-RAG）框架，支持高效、可扩展的动态更新，解决了现有Graph-RAG在动态环境中需要昂贵全图重建的问题。

**AI_Comments:** 这项工作提出了一个解决Graph-RAG在动态语料库中扩展性问题的创新方法。通过引入基于LSH的多层图结构，它巧妙地实现了高效的增量更新，避免了传统方法的全图重建成本。这种设计在保持高检索性能的同时，显著提高了系统的实用性和部署潜力，尤其对于需要实时处理数据增长的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于图的检索增强生成（Graph-RAG）方法通常假设语料库是静态的，当有新文档到来时，需要进行昂贵的全图重建，这限制了它们在动态、不断演进环境中的可扩展性。

**Method:** EraRAG引入了一种新颖的多层Graph-RAG框架。它利用基于超平面的局部敏感哈希（LSH）将原始语料库分区并组织成层次图结构，从而实现新数据的高效局部插入，而无需破坏现有拓扑结构。该设计消除了再训练或昂贵重新计算的需要。

**Result:** 实验表明，与现有Graph-RAG系统相比，EraRAG在大型基准测试中将更新时间和token消耗降低了一个数量级，同时提供了卓越的准确性性能。

**Conclusion:** EraRAG为需要在持续增长语料库上运行的RAG系统提供了一条实用的前进道路，弥合了检索效率和适应性之间的差距。

> **ai_Abstract:** EraRAG是一个创新的多层图检索增强生成（Graph-RAG）框架，旨在解决现有Graph-RAG系统在处理动态、不断增长的语料库时效率低下的问题。通过采用基于超平面的局部敏感哈希（LSH）来构建层次图结构，EraRAG实现了新数据的高效增量插入，避免了昂贵的全图重建和再训练。实验证明，EraRAG在更新时间、token消耗和检索准确性方面均优于现有系统，为RAG系统在动态环境中的应用提供了可扩展的解决方案。

> **摘要翻译:** 基于图的检索增强生成（Graph-RAG）通过在外部语料库上构建检索结构来增强大型语言模型（LLMs）。然而，现有方法通常假设语料库是静态的，当有新文档到来时，需要进行昂贵的全图重建，这限制了它们在动态、不断演进环境中的可扩展性。为了解决这些限制，我们引入了EraRAG，一种新颖的多层Graph-RAG框架，支持高效和可扩展的动态更新。我们的方法利用基于超平面的局部敏感哈希（LSH）将原始语料库分区并组织成层次图结构，从而实现新数据的高效局部插入，而无需破坏现有拓扑结构。该设计消除了再训练或昂贵重新计算的需要，同时保持了高检索准确性和低延迟。大型基准测试的实验表明，与现有Graph-RAG系统相比，EraRAG将更新时间和token消耗降低了一个数量级，同时提供了卓越的准确性性能。这项工作为必须在持续增长语料库上运行的RAG系统提供了一条实用的前进道路，弥合了检索效率和适应性之间的差距。我们的代码和数据可在https://github.com/EverM0re/EraRAG-Official 获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [121] [Response Quality Assessment for Retrieval-Augmented Generation via Conditional Conformal Factuality](https://arxiv.org/abs/2506.20978)
> *基于条件保形事实性的检索增强生成响应质量评估*

*Naihe Feng, Yi Sui, Shiyi Hou, Jesse C. Cresswell, Ga Wu* | **Category: cs.IR, H.3.3**

**Keywords:** 检索增强生成, 保形预测, 响应质量评估, 事实性, 统计保证

**Comment:** Accepted by SIGIR 2025 short paper, 5 pages, Code is available at
  https://github.com/n4feng/ResponseQualityAssessment

> **TL;DR:** Conformal-RAG利用保形预测为RAG生成的响应子声明提供统计质量保证，无需真实标签，且比直接CP应用于LLMs效果更好。

**AI_Comments:** 这篇论文的创新点在于将保形预测应用于RAG的响应质量评估，特别是针对子声明的质量保证，解决了现有方法缺乏统计保证和对真实标签依赖的问题。其利用RAG内部信息来优化CP应用，提高了高质量子声明的保留率，对于提升RAG系统的可信度和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有RAG研究主要关注整体问答准确性，但忽视了子声明质量；现有自动评估方法缺乏概率保证或需要真实标签。

**Method:** 提出Conformal-RAG框架，它结合保形预测(CP)和RAG机制的内部信息，为响应质量提供统计保证。该方法确保跨多个子域的组条件覆盖，且无需手动标记保形集。

**Result:** Conformal-RAG在相同可靠性保证下，比直接将CP应用于LLMs多保留高达60%的高质量子声明。它为精炼子声明的质量提供统计保证，无需真实答案。

**Conclusion:** Conformal-RAG通过利用CP和RAG内部信息，有效解决了现有RAG评估方法的局限性，提供有统计保证的响应质量评估方法，并在保持可靠性的前提下显著提高了高质量子声明的保留率。

> **ai_Abstract:** 本文提出了Conformal-RAG框架，旨在解决现有检索增强生成（RAG）系统在评估响应子声明质量时缺乏统计保证和需要真实标签的问题。Conformal-RAG结合了保形预测（CP）和RAG内部信息，提供响应质量的统计保证，确保组条件覆盖，且无需手动标记。实验证明，Conformal-RAG在保持可靠性的同时，能比直接应用CP保留更多高质量子声明。

> **摘要翻译:** 现有关于检索增强生成（RAG）的研究主要集中在提高整体问答准确性，却常常忽视生成响应中子声明的质量。近期旨在提高RAG可信度的方法，例如通过自动评估指标，缺乏概率保证或需要真实答案。为了解决这些局限性，我们提出了Conformal-RAG，一个受最近保形预测（CP）在大型语言模型（LLMs）应用启发的新颖框架。Conformal-RAG利用CP和RAG机制的内部信息，为响应质量提供统计保证。它确保跨多个子域的组条件覆盖，且无需手动标记保形集，使其适用于复杂的RAG应用。与现有RAG自动评估方法相比，Conformal-RAG为精炼子声明的质量提供统计保证，确保响应可靠性而无需真实答案。此外，我们的实验表明，通过利用RAG系统的信息，Conformal-RAG在保持相同可靠性保证的情况下，比直接将CP应用于LLMs多保留高达60%的响应中的高质量子声明。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [140] [RecCoT: Enhancing Recommendation via Chain-of-Thought](https://arxiv.org/abs/2506.21032)
> *RecCoT：通过思维链增强推荐系统*

*Shuo Yang, Jiangxia Cao, Haipeng Li, Yuqi Mao, Shuchao Pang* | **Category: cs.IR**

**Keywords:** 推荐系统, 思维链, 隐式反馈, 解释性, 用户偏好

**Comment:** Work in progress

> **TL;DR:** 现有推荐系统难以解释用户偏好，因为它们侧重于二元反馈和行为共现，而非物品内容或提供人类可理解的解释。

**AI_Comments:** 该论文指出了当前推荐系统的一个关键局限性：缺乏可解释性以及对用户偏好的理解，而不仅仅是简单的共现。标题中提及的“思维链”方法预示着一种创新途径，有望弥补这一空白，从而实现更透明、更用户友好的推荐。论文的动机阐述清晰。

<details>
  <summary>Details</summary>

**Motivation:** 现代推荐系统主要依赖隐式二元反馈学习用户-物品协作信号，推荐相似物品。然而，这种方法不关注物品内容，而是优先考虑行为共现信号，导致系统难以理解用户喜欢或不喜欢某些物品的原因。现有利用内容评论的方法也多侧重于预测评分，未能提供人类可理解的解释。

**Method:** Not mentioned in abstract

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 现代推荐系统主要依赖隐式二元反馈来学习协作信号并推荐相似物品。然而，这种范式侧重于行为共现而非物品内容，导致系统难以理解用户偏好的深层原因。尽管一些方法尝试利用内容评论来捕获语义知识，但它们通常只预测评分，未能提供人类可理解的解释。

> **摘要翻译:** 在实际应用中，用户总是通过多个方面与物品进行互动，例如通过隐式二元反馈（如点击、不点赞、长时间观看）和显式反馈（如评论、评价）。现代推荐系统（RecSys）从这些隐式反馈信号中学习用户-物品协作信号，作为大规模的二元数据流，随后根据用户的个性化历史互动推荐其他高度相似的物品。然而，从这种协作连接的角度来看，推荐系统不关注物品本身的实际内容，而是优先考虑物品之间行为共现的更高概率信号。因此，在这种二元学习范式下，推荐系统难以理解用户喜欢或不喜欢某些物品的原因。为了缓解这个问题，一些工作尝试利用基于内容的评论来捕获语义知识，以增强推荐模型。然而，这些方法大多侧重于预测评论的评分，但没有提供人类可理解的解释。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [158] [Real-time and personalized product recommendations for large e-commerce platforms](https://arxiv.org/abs/2506.21368)
> *大型电商平台的实时个性化产品推荐*

*Matteo Tolloso, Davide Bacciu, Shahab Mokarizadeh, Marco Varesi* | **Category: cs.IR, cs.AI**

**Keywords:** 实时推荐, 个性化推荐, 电商平台, 图神经网络, 简约学习

**Comment:** This paper has been accepted for publication at the International
  Conference on Artificial Neural Networks (ICANN) 2025. The final
  authenticated version will be available for purchase through the publisher's
  website. The conference proceedings will be published by Springer in the
  Lecture Notes in Computer Science (LNCS) series

> **TL;DR:** 该研究提出一种针对大型电商平台（特别是时尚零售）的实时个性化产品推荐方法，该方法利用图神经网络和简约学习，在预测购买序列和处理多交互场景方面表现出有效性，实现了高效的个性化推荐。

**AI_Comments:** 这项研究的创新之处在于结合了图神经网络和简约学习来解决大型电商平台实时个性化推荐的挑战。其重要性在于能够在大规模数据集和严格的实时性要求下提供高效且准确的推荐，这对于提升用户体验和电商销售额至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为大型电商平台提供准确、可扩展、响应时间短的实时个性化产品推荐，以确保用户满意度。

**Method:** 采用图神经网络（Graph Neural Networks）和简约学习（parsimonious learning methodologies）。

**Result:** 在大型电商平台数据集上的广泛实验表明，该方法在预测购买序列和处理多交互场景方面有效，并在实际约束下实现了高效的个性化推荐。

**Conclusion:** 该方法能够为大型电商平台提供有效且高效的实时个性化产品推荐。

> **ai_Abstract:** 这篇论文提出了一种针对大型电商平台（特别是时尚零售）的实时个性化产品推荐方法。该方法结合了图神经网络和简约学习，旨在实现高准确度、高可扩展性和低响应时间。实验结果表明，该方法在预测购买序列和处理多交互场景方面表现出色，能够在真实世界约束下提供高效的个性化推荐。

> **摘要翻译:** 我们提出了一种为大型电商平台提供实时个性化产品推荐的方法，特别关注时尚零售。我们的方法旨在通过最小的响应时间实现准确和可扩展的推荐，确保用户满意度，并利用图神经网络和简约学习方法。通过来自最大电商平台之一的数据集进行广泛实验，证明了我们方法在预测购买序列和处理多交互场景方面的有效性，在实际约束下实现了高效的个性化推荐。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [6] [Spiking Neural Networks for SAR Interferometric Phase Unwrapping: A Theoretical Framework for Energy-Efficient Processing](https://arxiv.org/abs/2506.20782)
> *用于SAR干涉相位解缠的脉冲神经网络：一种节能处理的理论框架*

*Marc Bara* | **Category: cs.NE, cs.ET, cs.LG, eess.SP, 68T07, 94A08, I.2.6; G.1.6; B.7.1**

**Keywords:** 脉冲神经网络, SAR干涉测量, 相位解缠, 节能处理, 理论框架

**Comment:** 8 pages, 2 figures, patent pending

> **TL;DR:** 该研究提出了首个将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架，旨在为大规模InSAR处理提供节能且可持续的方法。

**AI_Comments:** 这项工作具有显著的创新性，因为它首次将脉冲神经网络引入SAR干涉相位解缠领域，填补了现有方法论的空白。其重要性在于，它提出了一种极具前景的节能处理方案，这对于处理指数级增长的地球观测数据至关重要，有望推动大规模InSAR处理的可持续发展。该研究为神经形态计算在地球科学应用中开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着地球观测数据量呈指数级增长，数据中心的可持续运营对节能处理的需求变得至关重要。传统的处理方法能耗高，而脉冲神经网络（SNNs）具有显著的节能潜力（30-100倍），同时保持可比的精度，但此前从未应用于相位解缠。

**Method:** 本研究为缠绕相位数据开发了脉冲编码方案，提出了利用相位解缠空间传播特性的SNN架构，并对计算复杂度和收敛性进行了理论分析。该框架展示了SNN固有的时间动力学如何自然地模拟相位解缠中空间连续性约束。

**Result:** 该框架展示了脉冲神经网络（SNNs）固有的时间动力学能够自然地模拟相位解缠中基本的空间连续性约束。

**Conclusion:** 这项工作为神经形态计算和SAR干涉测量交叉领域开辟了新的研究方向，为现有算法提供了一种补充方法，有望实现更可持续的大规模InSAR处理。

> **ai_Abstract:** 本研究首次提出了将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架。鉴于地球观测数据量激增对节能处理的需求，SNNs因其显著的节能潜力而备受关注。论文开发了专门的脉冲编码方案和SNN架构，并进行了理论分析，证明SNN的时间动力学能有效模拟相位解缠的空间连续性约束。这项工作为神经形态计算与SAR干涉测量结合开辟了新方向，有望实现更可持续的大规模InSAR处理。

> **摘要翻译:** 我们提出了首个将脉冲神经网络（SNNs）应用于合成孔径雷达（SAR）干涉相位解缠的理论框架。尽管这两个领域都有广泛的研究，但我们全面的文献综述证实，SNNs从未应用于相位解缠，这代表了当前方法论中的一个显著空白。随着地球观测数据量继续呈指数级增长（像NISAR这样的任务预计在两年内生成100PB数据），节能处理对于可持续的数据中心运营变得至关重要。SNNs凭借其事件驱动的计算模型，与传统方法相比，在保持可比精度的同时，可提供30-100倍的潜在节能。我们开发了专门为缠绕相位数据设计的脉冲编码方案，提出了利用相位解缠空间传播特性的SNN架构，并提供了计算复杂度和收敛特性的理论分析。我们的框架展示了SNN中固有的时间动力学如何自然地模拟相位解缠中基本的空间连续性约束。这项工作为神经形态计算和SAR干涉测量交叉领域开辟了新的研究方向，为现有算法提供了一种补充方法，有望实现更可持续的大规模InSAR处理。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [31] [Brain2Model Transfer: Training sensory and decision models with human neural activity as a teacher](https://arxiv.org/abs/2506.20834)
> *脑到模型迁移：以人类神经活动为教师训练感觉和决策模型*

*Tomas Gallo Aquino, Victoria Liu, Habiba Azab, Raissa Mathura, Andrew J Watrous, Eleonora Bartoli, Benjamin Y Hayden, Paul Sajda, Sameer A Sheth, Nuttida Rungratsameetaweemana* | **Category: cs.NE, cs.ET, q-bio.NC**

**Keywords:** 脑到模型迁移, 神经活动, 迁移学习, 人工神经网络, 决策模型

**Comment:** 15 pages, 4 figures

> **TL;DR:** 提出Brain2Model迁移学习框架，利用人类神经活动作为教师模型，显著加速人工神经网络训练并提高准确性。

**AI_Comments:** 这篇论文提出了一种新颖的迁移学习范式，即“脑到模型迁移”，其创新点在于将人脑的神经活动作为“教师”来指导人工神经网络的学习。这突破了传统迁移学习中仅使用人工模型作为教师的限制，利用了人脑在数据效率和计算效率上的优势。其重要性在于为未来构建更接近生物智能、更高效的人工智能系统提供了新的思路，尤其是在复杂决策和感知任务中，可以显著降低训练成本和时间。

<details>
  <summary>Details</summary>

**Motivation:** 人脑能以显著更少的数据和计算资源学习低维抽象表示，而现有的人工模型需要大量数据和计算且训练成本高昂。本文旨在利用人脑的这种高效学习能力来改进人工模型的训练，使其更高效、更经济。

**Method:** 本文引入了Brain2Model Transfer Learning (B2M) 框架，其中人类感觉和决策任务中的神经活动充当训练人工神经网络的教师模型。该框架提出两种策略：1) 脑对比迁移（Brain Contrastive Transfer），通过对比目标对齐大脑活动和网络激活；2) 脑潜在迁移（Brain Latent Transfer），通过对脑源特征进行监督回归，将类似认知任务的潜在动态投射到学生网络。研究在基于记忆的决策（使用循环神经网络）和自动驾驶场景重建（使用变分自编码器）中验证了B2M。

**Result:** 受益于基于大脑迁移的学生网络比单独训练的网络收敛更快，并达到更高的预测准确性。

**Conclusion:** 大脑的表示对人工学习者很有价值，为更有效地学习复杂决策表示铺平了道路，而这些表示通过纯人工训练将是昂贵或缓慢的。

> **ai_Abstract:** 本文提出了Brain2Model Transfer Learning (B2M) 框架，旨在利用人类神经活动作为教师模型来训练人工神经网络。该框架包含脑对比迁移和脑潜在迁移两种策略，旨在将人脑高效学习的低维、抽象表示能力迁移到人工模型中。实验结果表明，B2M能显著加速学生网络的收敛并提高预测准确性，证明了人脑表示对于构建更高效、更经济的人工智能模型具有重要价值。

> **摘要翻译:** 迁移学习通过利用大型预训练教师模型的丰富特征表示来增强新型感觉和决策模型的训练。认知神经科学表明，人脑为高效的感觉运动编码创建了低维、抽象的表示。重要的是，与人工智能模型所需的相比，大脑能够以显著更少的数据点和更低的计算能力学习这些表示。我们引入了脑到模型迁移学习（B2M），这是一个框架，其中人类感觉和决策任务中的神经活动充当训练人工神经网络的教师模型。我们提出了两种B2M策略：（1）脑对比迁移，它通过对比目标对齐大脑活动和网络激活；（2）脑潜在迁移，它通过对脑源特征的监督回归，将类似认知任务的潜在动态投射到学生网络上。我们在基于记忆的决策（使用循环神经网络）和自动驾驶场景重建（使用变分自编码器）中验证了B2M。结果表明，受益于基于大脑迁移的学生网络比单独训练的网络收敛更快，并达到更高的预测准确性。我们的发现表明，大脑的表示对人工学习者很有价值，为更有效地学习复杂决策表示铺平了道路，而这些表示通过纯人工训练将是昂贵或缓慢的。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [75] [Stochastic Quantum Spiking Neural Networks with Quantum Memory and Local Learning](https://arxiv.org/abs/2506.21324)
> *具有量子记忆和局部学习的随机量子脉冲神经网络*

*Jiechen Chen, Bipin Rajendran, Osvaldo Simeone* | **Category: cs.NE, cs.LG**

**Keywords:** 随机量子脉冲神经网络, 量子记忆, 局部学习, 神经形态计算, 量子计算

**Comment:** 

> **TL;DR:** 本文提出了一种新的随机量子脉冲（SQS）神经元模型及其网络（SQSNNs），该模型利用多量子比特电路实现内部量子记忆，并采用硬件友好的局部学习规则进行训练，克服了现有量子脉冲模型依赖经典记忆和反向传播的局限性，为可扩展的量子脉冲神经网络铺平了道路。

**AI_Comments:** 本文的创新之处在于提出了带有内部量子记忆的随机量子脉冲神经元，并通过局部学习规则实现了量子脉冲神经网络的训练，避免了传统方法中对经典记忆和全局反向传播的依赖。这对于在量子硬件上实现高效且可扩展的量子神经网络具有重要意义，是量子人工智能领域的一个关键进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的量子脉冲神经元实现存在局限性，它们依赖于单量子比特上的经典记忆机制，需要重复测量来估计脉冲概率，并且训练时使用经典模拟器上的传统反向传播算法。

**Method:** 本文提出了一种随机量子脉冲（SQS）神经元模型，该模型使用多量子比特量子电路实现具有内部量子记忆的脉冲单元，从而能够单次事件驱动地生成概率性脉冲。此外，还提出了SQS神经元网络（SQSNNs）可以通过硬件友好的局部学习规则进行训练，从而消除了对全局经典反向传播的需求。

**Result:** 提出的SQS神经元模型实现了单次事件驱动的概率性脉冲生成，并具有内部量子记忆。SQSNNs可以通过局部学习规则进行训练，融合了神经形态计算的时间序列效率和量子计算的指数级大内部状态空间。

**Conclusion:** 所提出的SQSNN模型融合了神经形态计算的时间序列效率与量子计算的指数级大内部状态空间，为构建模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络铺平了道路。

> **ai_Abstract:** 本文提出了一种随机量子脉冲（SQS）神经元模型及其网络（SQSNNs），旨在克服现有量子脉冲模型的局限性。SQS神经元利用多量子比特量子电路实现具有内部量子记忆的脉冲单元，能够单次实现事件驱动的概率性脉冲生成。此外，SQSNNs采用硬件友好的局部学习规则进行训练，无需传统的全局反向传播。该模型成功融合了神经形态计算的时间序列处理效率和量子计算的指数级状态空间探索能力，为构建可在量子硬件上进行训练的模块化、可扩展的量子脉冲神经网络奠定了基础。

> **摘要翻译:** 神经形态计算和量子计算最近已成为推动人工智能发展的有前景的范式，各自提供了互补的优势。基于脉冲神经元的神经形态系统擅长通过稀疏、事件驱动的计算有效地处理时间序列数据，仅在输入事件发生时才消耗能量。另一方面，量子计算利用叠加和纠缠来探索在量子比特数量上呈指数级增长的特征空间。结合这些范式的混合方法已开始显示出潜力，但现有的量子脉冲模型存在重要局限性。值得注意的是，先前的量子脉冲神经元实现依赖于单量子比特上的经典记忆机制，需要重复测量来估计脉冲概率，并且它们使用经典模拟器上的传统反向传播进行训练。本文提出了一种随机量子脉冲（SQS）神经元模型来解决这些挑战。SQS神经元使用多量子比特量子电路来实现具有内部量子记忆的脉冲单元，从而能够单次事件驱动地生成概率性脉冲。此外，我们概述了如何通过硬件友好的局部学习规则训练SQS神经元网络（称为SQSNNs），从而消除了对全局经典反向传播的需求。所提出的SQSNN模型融合了神经形态计算的时间序列效率与量子计算的指数级大内部状态空间，为构建模块化、可扩展且可在量子硬件上训练的量子脉冲神经网络铺平了道路。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [100] [Assessing an evolutionary search engine for small language models, prompts, and evaluation metrics](https://arxiv.org/abs/2506.21512)
> *评估用于小型语言模型、提示和评估指标的进化搜索引擎*

*Cláudio Lúcio do Val Lopes, Lucca Machado* | **Category: cs.NE**

**Keywords:** 进化搜索, 小型语言模型, 提示优化, NSGA-II, 双目标优化

**Comment:** 14 pages, 1 figure, 1 table

> **TL;DR:** 本文介绍并评估了一种双目标进化搜索引擎，用于同时优化小型语言模型和提示，以平衡任务准确性和令牌效率。

**AI_Comments:** 这项研究的创新之处在于提出了一个双目标进化搜索引擎，用于同时优化小型语言模型和提示，以解决性能和计算成本之间的权衡问题。通过自动化方法，它超越了传统的手动调优，为发现有效的人机交互模式提供了基础框架，对于部署高效AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型和指令提示的同步优化在部署高效、有效的AI系统时面临重大挑战，尤其是在平衡性能与计算成本（如令牌使用）时。

**Method:** 本文引入并评估了一种双目标进化搜索引擎，专门针对小型语言模型（SLMs）。该研究采用NSGA-II算法和提示语法，在推理任务中同时优化任务准确性和令牌效率。

**Result:** 研究成功识别了多样化、高性能的模型-提示组合，定量揭示了两个目标之间的关键权衡。研究还强调了特定SLM与提示结构（如指令、上下文、思维链）之间的任务特异性亲和力。

**Conclusion:** 生成的实用帕累托前沿为决策者提供了可根据其特定约束调整的优化解决方案组合。这种自动化方法超越了传统的手动调优，为发现有效的人机交互模式提供了基础框架。

> **ai_Abstract:** 本文介绍了一种用于小型语言模型（SLMs）和提示的双目标进化搜索引擎，旨在同时优化任务准确性和令牌效率。通过采用NSGA-II算法和提示语法，该研究成功识别了高性能的模型-提示组合，并揭示了性能与计算成本之间的权衡。此方法提供了一个自动化框架，用于生成适应特定约束的优化解决方案，从而改进人机交互模式。

> **摘要翻译:** 语言模型和指令提示的同步优化对部署高效、有效的AI系统提出了重大挑战，尤其是在平衡性能与计算成本（如令牌使用）时。本文介绍并评估了一种双目标进化搜索引擎，旨在解决这一复杂空间，并特别关注小型语言模型（SLMs）。我们采用NSGA-II算法和提示语法，在某些推理任务中同时优化任务准确性和令牌效率。我们的结果成功识别了多样化、高性能的模型-提示组合，定量揭示了两个目标之间的关键权衡。这项研究强调了特定SLM与提示结构（例如，指令、上下文、思维链）之间任务特异性亲和力。生成的实用帕累托前沿为决策者提供了一系列可根据其特定约束进行调整的优化解决方案组合。这种自动化方法超越了传统的手动调优，为发现有效的人机交互模式提供了基础框架。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [27] [Inverse initial data reconstruction for Maxwell's equations via time-dimensional reduction method](https://arxiv.org/abs/2506.20777)
> *麦克斯韦方程组初始数据逆重构的时间维度归约方法*

*Thuy T. Le, Cong B. Van, Trong D. Dang, Loc H. Nguyen* | **Category: math.NA, cs.NA**

**Keywords:** 麦克斯韦方程组, 逆问题, 初始数据重构, 时间维度归约, 准可逆性方法

**Comment:** 

> **TL;DR:** 本文提出一种时间维度归约方法，通过边界测量在非均匀各向异性介质中重构麦克斯韦方程组的初始电场，即使在有噪声数据下也表现出鲁棒性。

**AI_Comments:** 这篇论文的创新之处在于提出了一个时间维度归约方法来解决麦克斯韦方程组的初始数据逆问题，特别是采用了欠定公式以避免对初始磁场和电荷密度数据的依赖，这在实际应用中具有重要意义。该方法通过将复杂的时空问题转化为一系列空间问题，并结合准可逆性方法处理非唯一性，提高了计算效率和鲁棒性。其在噪声数据下的良好表现进一步证实了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在非均匀和各向异性介质中，需要通过边界测量重构麦克斯韦方程组的初始电场。现有的方法可能需要初始磁场数据和电荷密度信息，而本文旨在避免这些需求，采用欠定公式。

**Method:** 1. 采用麦克斯韦方程组的欠定公式，避免初始磁场数据和电荷密度信息。 2. 开发时间维度归约方法，将电场投影到有限维勒让德多项式-指数基上。 3. 将原始时空问题转化为一系列空间系统。 4. 使用最小范数框架内的准可逆性方法进行重构。 5. 证明了收敛定理。

**Result:** 证明了准可逆解在噪声和正则化参数消失时逼近真实解。在完全三维设置下的数值实验验证了方法的性能。即使数据中存在10%的噪声，重构的初始电场仍然准确。

**Conclusion:** 提出的时间维度归约方法能够鲁棒且准确地重构麦克斯韦方程组的初始电场，适用于实际的逆电磁问题，即使在存在噪声的情况下。

> **ai_Abstract:** 本文研究了在非均匀和各向异性介质中利用边界测量重构麦克斯韦方程组初始电场的逆问题。为避免对初始磁场和电荷密度数据的需求，作者提出了一种时间维度归约方法，将电场投影到有限维基上，并将时空问题转化为空间系统序列。重构采用最小范数框架下的准可逆性方法。数值实验表明，该方法即使在10%噪声下也能准确重构初始电场，验证了其鲁棒性和实用性。

> **摘要翻译:** 我们研究了非均匀和各向异性介质中随时间变化的麦克斯韦系统的一个逆问题。目标是利用在有限时间间隔内的电场及其法向导数的边界测量，恢复有界域 $\Omega \subset \mathbb{R}^3$ 中的初始电场 $\mathbf{E}_0$。根据实际约束，我们采用了麦克斯韦方程组的欠定公式，避免了对初始磁场数据和电荷密度信息的需要。为了解决这个逆问题，我们开发了一种时间维度归约方法，通过将电场投影到时间上的有限维勒让德多项式-指数基上。这使得原始时空问题被重新表述为一系列针对投影系数的空间系统。重构是在最小范数框架内使用准可逆性方法进行的，该方法适应了欠定设置固有的非唯一性。我们证明了一个收敛定理，确保当噪声和正则化参数消失时，准可逆解逼近真实解。在完全三维设置下的数值实验验证了该方法的性能。即使数据中存在10%的噪声，重构的初始电场仍然准确，这表明所提出方法对实际逆电磁问题的鲁棒性和适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [51] [Boundary integral equation analysis for spheroidal suspensions](https://arxiv.org/abs/2506.20809)
> *扁球体悬浮液的边界积分方程分析*

*Leo Crowder, Tianyue Li, Eduardo Corona, Shravan Veerapaneni* | **Category: math.NA, cs.NA, physics.comp-ph, physics.flu-dyn**

**Keywords:** 边界积分方程, 扁球体, 快速多极子方法, 拉普拉斯, 斯托克斯

**Comment:** Submitted to Journal of Computational Physics, June 2025

> **TL;DR:** 本文提出了一种快速、谱精确的方法，用于评估扁球体悬浮液上的边界积分算子（BIOs），并验证了其在拉普拉斯和斯托克斯问题中的准确性和效率。

**AI_Comments:** 这项工作提出了一种新颖且高效的计算框架，用于处理复杂形状粒子（扁球体）的边界积分算子问题。其创新点在于结合了不同尺度的分析和数值方法（近场解析表达式与远场FMM加速），实现了谱精确性和计算效率的平衡。该方法对理解和模拟流体中颗粒悬浮液的行为具有重要意义，尤其是在需要高精度计算的领域。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提供一种快速、谱精确的方法，用于评估长扁球体和扁扁球体悬浮液上的边界积分算子（BIOs）。

**Method:** 该方法首先推导了在适当扁球谐波基中展开积分密度的拉普拉斯方程标准层势算子的公式。这些公式进而得到固体谐波中的解析表达式，从而实现近场粒子相互作用的谱精确评估。远场相互作用则使用标准正交方案进行评估，并通过快速多极子方法加速。该方案通过连接斯托克斯和拉普拉斯势的标准公式，可应用于涉及颗粒悬浮流的问题。

**Result:** 通过大量数值测试案例，验证了该BIO评估框架在稠密、多分散扁球体悬浮液中的准确性和效率。对于拉普拉斯和斯托克斯问题，该方法能够在单个处理器上评估多达数百个粒子的悬浮液的BIOs。

**Conclusion:** 该研究提出了一种高效、精确的边界积分算子评估框架，适用于扁球体悬浮液，并能有效处理拉普拉斯和斯托克斯问题，显示出良好的可扩展性。

> **ai_Abstract:** 本文提出了一种用于评估扁球体悬浮液边界积分算子（BIOs）的快速、谱精确方法。该方法结合了基于扁球谐波和固体谐波的解析表达式用于近场相互作用，以及结合快速多极子方法的标准正交方案用于远场相互作用。数值测试验证了其在稠密、多分散悬浮液中的准确性和效率，并且该方案通过连接斯托克斯和拉普拉斯势的公式，能够处理颗粒悬浮流问题，并在单个处理器上支持多达数百个粒子。

> **摘要翻译:** 在这项工作中，我们提供了一种快速、谱精确的方法，用于评估长扁球体和扁扁球体悬浮液上的边界积分算子（BIOs）。我们首先推导了将积分密度在适当的扁球谐波基中展开后应用于拉普拉斯方程的标准层势算子的公式。这些公式进而得到了固体谐波中的解析表达式，从而实现了近场粒子相互作用的谱精确评估。最后，使用标准正交方案评估平滑的远场相互作用；这些相互作用随后通过快速多极子方法加速。
通过大量的数值测试案例，我们验证了我们的BIO评估框架在稠密、多分散的扁球体悬浮液中的准确性和效率。通过使用连接斯托克斯和拉普拉斯势的标准公式，我们表明我们的方案可以很容易地应用于涉及颗粒悬浮流的问题。对于拉普拉斯和斯托克斯问题，我们的方法允许我们在单个处理器上评估多达数百个粒子的悬浮液的BIOs。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [76] [Multicontinuum Homogenization for Poroelasticity Model](https://arxiv.org/abs/2506.20890)
> *多连续体均质化孔隙弹性模型*

*Dmitry Ammosov, Mohammed Al-Kobaisi, Yalchin Efendiev* | **Category: math.NA, cs.CE, cs.NA, physics.comp-ph**

**Keywords:** 多连续体, 均质化, 孔隙弹性, 多孔介质, 非均匀介质

**Comment:** 

> **TL;DR:** 本文提出了一种广义多连续体孔隙弹性模型，通过多连续体均质化方法解决标准均质化方法在处理高对比度孔隙弹性介质时面临的计算挑战和精度问题，并通过数值实验证明了其高精度。

**AI_Comments:** 本文通过引入多连续体均质化方法，有效地解决了标准均质化方法在处理高对比度孔隙弹性介质时的局限性，具有重要的理论和应用价值。其创新点在于提出了一种广义的多连续体孔隙弹性模型，并通过严格的推导和数值验证，展示了其在复杂介质中的高精度。

<details>
  <summary>Details</summary>

**Motivation:** 孔隙弹性模型在多孔介质中描述流固耦合过程被广泛应用，但在高对比度介质中存在严重的计算挑战。标准均质化方法因缺乏宏观参数而无法提供准确解。

**Method:** 本文采用多连续体均质化方法，推导了广义多连续体孔隙弹性模型。具体方法包括：在过采样区域建立耦合约束单元问题以考虑不同的均质化效应；获得精细尺度场的多连续体展开；假设宏观变量的平滑性来推导多连续体模型。

**Result:** 推导出了最通用的方程版本和基于数值实验的简化版本。数值结果表明，所提出的多连续体模型在不同非均匀介质情况下具有高精度。

**Conclusion:** 所提出的多连续体孔隙弹性模型能够有效解决高对比度多孔介质的计算挑战，并提供高精度的解决方案。

> **ai_Abstract:** 本文提出了一种基于多连续体均质化方法的广义多连续体孔隙弹性模型，旨在解决标准均质化方法在处理高对比度孔隙弹性介质时面临的计算挑战和精度不足问题。研究通过在过采样区域建立耦合约束单元问题、获取精细尺度场的多连续体展开以及假设宏观变量平滑性等步骤，严格推导了多连续体方程。数值实验结果验证了所提出模型在不同非均匀介质情况下的高精度。

> **摘要翻译:** 在本文中，我们使用多连续体均质化方法推导了多连续体孔隙弹性模型。孔隙弹性模型在科学和工程的许多领域被广泛用于描述多孔介质中的耦合流体和力学过程。然而，在许多应用中，孔隙弹性介质的性质具有高对比度，带来了严重的计算挑战。众所周知，由于缺乏宏观参数，标准均质化方法通常无法给出准确的解。多连续体方法通过定义几个称为连续体的平均状态，使我们能够考虑这种情况。在孔隙弹性领域，源自多孔介质理论的多网络模型是这些方法的代表。在这项工作中，我们通过推导广义多连续体孔隙弹性模型来扩展之前的研究发现。我们应用了最近开发的多连续体均质化方法，并提供了多连续体方程的严格推导。为此，我们在过采样区域中建立了耦合约束单元问题，以考虑不同的均质化效应。然后，我们获得了精细尺度场的多连续体展开，并在假设宏观变量平滑性的前提下推导了多连续体模型。我们根据数值实验提出了最通用的方程版本和简化版本。数值结果展示了不同非均匀介质情况下的应用，并证明了我们提出的多连续体模型具有高精度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [101] [Two-dimensional greedy randomized Kaczmarz methods for solving large-scale linear systems](https://arxiv.org/abs/2506.20940)
> *求解大规模线性系统的二维贪婪随机Kaczmarz方法*

*Tao Li, Meng-Long Xiao, Xin-Fang Zhang* | **Category: math.NA, cs.NA, 65F10, 65F20, 94A08**

**Keywords:** Kaczmarz方法, 大规模线性系统, 二维, 贪婪随机, 半随机

**Comment:** arXiv admin note: text overlap with arXiv:2506.16106

> **TL;DR:** 本文提出并分析了几种新型二维Kaczmarz方法，包括随机、贪婪随机和半随机变体，用于求解大规模线性系统。理论上证明了它们的收敛性，数值结果显示其在计算时间上优于现有方法。

**AI_Comments:** 本文的创新点在于将Kaczmarz方法推广到二维选择策略，并结合了贪婪、随机和半随机思想，这对于处理大规模线性系统，特别是大数据问题，具有重要意义。理论收敛性证明和数值性能提升，使其在实际应用中具有潜在的优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了有效求解大规模线性系统，并进一步改进现有Kaczmarz方法的性能，特别是针对大数据问题。

**Method:** 本文提出并研究了多种二维Kaczmarz方法：
1. 二维随机Kaczmarz方法及其改进版本（通过简单随机抽样选择两行，概率与交叉积常数的平方成正比）。
2. 二维贪婪随机Kaczmarz方法（通过贪婪选择策略，每次迭代选取残差向量中两个较大项）。
3. 受半随机Kaczmarz方法和切比雪夫大数定律启发，提出了二维半随机Kaczmarz方法及其改进版本（适用于大数据问题）。

**Result:** 理论上，证明了所提出的方法收敛到一致线性系统的唯一最小范数解。数值结果表明，在计算时间方面，所提出的方法优于一些现有方法。

**Conclusion:** 所提出的二维随机、贪婪随机和半随机Kaczmarz方法能够有效且高效地求解大规模线性系统，并在理论上保证收敛性，在实践中展现出卓越的计算性能。

> **ai_Abstract:** 本文介绍了几种新颖的二维Kaczmarz方法，用于高效求解大规模线性系统。这些方法包括二维随机Kaczmarz、二维贪婪随机Kaczmarz以及受半随机Kaczmarz和切比雪夫大数定律启发的二维半随机Kaczmarz及其变体。文章理论证明了这些方法能收敛到一致线性系统的唯一最小范数解，并通过数值实验验证了它们在计算时间上优于现有算法，特别适用于大数据场景。

> **摘要翻译:** 在本文中，我们考虑了一种新颖的二维随机Kaczmarz方法及其通过简单随机抽样改进的版本，该方法以与其叉积类常数平方成比例的概率选择两个活跃行，用于求解大规模线性系统。根据每次迭代中抓住残差向量中两个较大项的贪婪选择策略，我们随后设计了一种二维贪婪随机Kaczmarz方法。为了进一步改进上述方法，受半随机Kaczmarz方法和切比雪夫大数定律的启发，我们提出了一种二维半随机Kaczmarz方法及其通过简单随机抽样修改的版本，这对于大数据问题尤其有利。理论上，我们证明了所提出的方法收敛到一致线性系统的唯一最小范数解。在一些实际应用中的数值结果表明，与现有方法相比，所提出的方法在计算时间方面具有优越性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [123] [An energy-stable parametric finite element method for the Willmore flow in three dimensions](https://arxiv.org/abs/2506.21025)
> *三维Willmore流的一种能量稳定参数有限元方法*

*Weizhu Bao, Yifei Li, Dongmin Wang* | **Category: math.NA, cs.NA, 65M60, 65M12, 35K55, 53C44**

**Keywords:** Willmore流, 参数有限元方法, 能量稳定, 几何梯度流, 网格质量

**Comment:** 

> **TL;DR:** 本文提出了一种新的能量稳定参数有限元方法（ES-PFEM），用于三维Willmore流和曲率相关几何梯度流，通过引入两个新的几何恒等式和切向速度控制，实现了能量耗散性和良好的网格质量。

**AI_Comments:** 该论文的创新点在于引入了两个新颖的几何恒等式，从而实现了三维Willmore流的能量稳定参数有限元方法。同时，通过切向速度控制进一步提升了网格质量和方法的鲁棒性。其重要性体现在为处理复杂几何梯度流提供了稳定高效的数值工具，并扩展了PFEM在曲率流领域的应用，特别是首次应用于高斯曲率流。抽象中未明确提及方法的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决三维Willmore流和曲率相关几何梯度流中实现能量稳定性的挑战。

**Method:** 开发了能量稳定参数有限元方法（ES-PFEM），其关键在于使用了两个新的几何恒等式：(i) 法向速度场的重新公式化变分形式，以及 (ii) 将平均曲率的时间演化纳入控制方程。在此基础上，推导出了新的变分公式，并开发了隐式全离散方案。此外，应用了切向速度控制方法来改善网格质量。

**Result:** 所提出的方法在全离散层面保持了能量耗散特性。提供了关于设计ES-PFEM用于一般曲率相关几何梯度流的全面见解，并对PFEM中的网格质量改进有了新的理解。首次开发了用于高斯曲率流的PFEM。数值实验证实该方法在Willmore流下的表面演化中保持了能量耗散特性和良好的网格质量。

**Conclusion:** 提出的能量稳定参数有限元方法在三维Willmore流的数值模拟中表现出色，能够保持能量耗散特性并维持良好的网格质量。

> **ai_Abstract:** 本文提出了一种用于三维Willmore流和曲率相关几何梯度流的能量稳定参数有限元方法（ES-PFEM）。该方法通过引入两个创新的几何恒等式（重新公式化的法向速度变分形式和平均曲率时间演化纳入）来确保能量稳定性，并推导了新的变分公式和隐式全离散方案。此外，结合切向速度控制技术以优化网格质量。数值实验验证了该方法在保持能量耗散性和网格质量方面的有效性，并首次将其应用于高斯曲率流。

> **摘要翻译:** 这项工作开发了用于三维Willmore流和曲率相关几何梯度流的新型能量稳定参数有限元方法（ES-PFEM）。实现能量稳定性的关键在于使用了两个新的几何恒等式：(i) 法向速度场的重新公式化变分形式，以及 (ii) 将平均曲率的时间演化纳入控制方程。这些恒等式使得能够推导出一种新的变分公式。通过使用参数有限元方法，随后开发了一种隐式全离散方案，该方案在全离散层面保持了能量耗散特性。基于ES-PFEM，提供了关于设计用于一般曲率相关几何梯度流的ES-PFEM的全面见解，并对PFEM中的网格质量改进有了新的理解。特别是，我们开发了第一个用于表面高斯曲率流的PFEM。此外，应用了切向速度控制方法来改善网格质量并增强所提出的数值方法的鲁棒性。大量的数值实验证实，所提出的方法在Willmore流下的表面演化中保持了能量耗散特性并维持了良好的网格质量。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [142] [Entropy-stable in- and outflow boundary conditions for the compressible Navier-Stokes equations](https://arxiv.org/abs/2506.21065)
> *可压缩Navier-Stokes方程的熵稳定入流和出流边界条件*

*Magnus Svärd, Anita Gjesteland* | **Category: math.NA, cs.NA**

**Keywords:** 熵稳定, 边界条件, Navier-Stokes方程, 有限体积格式, 可压缩流

**Comment:** 

> **TL;DR:** 本文提出了可压缩Navier-Stokes方程的熵稳定入流和出流边界条件，证明了它们允许对熵、质量和总能量进行先验估计，并展示了如何将它们与熵稳定有限体积格式结合应用，通过数值计算验证了其鲁棒性。

**AI_Comments:** 本文的创新之处在于提出了能够保证熵稳定并允许先验估计的边界条件，这对于可压缩流体数值模拟的稳定性和准确性至关重要。同时，展示了这些条件与有限体积格式的兼容性及其鲁棒性，也是一项重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为可压缩Navier-Stokes方程提出入流和出流边界条件，并证明这些条件允许对熵、质量和总能量进行先验估计，同时展示如何将这些条件与熵稳定的有限体积格式结合使用，并通过数值计算验证其鲁棒性。

**Method:** 本文提出了可压缩Navier-Stokes方程的入流和出流边界条件。研究人员证明了这些条件允许对熵、质量和总能量进行先验估计。此外，他们展示了如何将这些边界条件与熵稳定的有限体积格式结合进行近似，并指出该方法也适用于其他类型的熵稳定格式。最后，通过使用有限体积格式进行数值计算来验证其鲁棒性。

**Result:** 所提出的边界条件允许对可压缩Navier-Stokes方程的熵、质量和总能量进行先验估计。与熵稳定的有限体积格式结合使用时，这些边界条件的近似方法通过数值计算验证了其鲁棒性。

**Conclusion:** 本文成功提出了并证明了可压缩Navier-Stokes方程的鲁棒熵稳定入流和出流边界条件，这些条件与熵稳定格式兼容，并允许重要的先验估计。

> **ai_Abstract:** 本文针对可压缩Navier-Stokes方程引入了新型熵稳定的入流和出流边界条件。研究证明这些条件能够实现熵、质量和总能量的先验估计。文中详细阐述了将这些条件与熵稳定有限体积格式（以及其他熵稳定格式）结合进行近似的方法，并通过数值计算验证了其鲁棒性。

> **摘要翻译:** 我们提出了可压缩Navier-Stokes方程的入流和出流边界条件，并证明它们允许对熵、质量和总能量进行先验估计。此外，我们展示了如何将这些边界条件与熵稳定的有限体积格式结合起来进行近似。该方法也适用于其他类型的熵稳定格式。最后，我们使用有限体积格式进行了一些数值计算，并证明了它们的鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [160] [Inverse source problem with a posteriori interior measurements for space-time fractional diffusion equations](https://arxiv.org/abs/2506.21070)
> *具有后验内部测量的时空分数阶扩散方程的逆源问题*

*Kai Yu, Zhiyuan Li, Yikan Liu* | **Category: math.NA, cs.NA, 35R30, 35R11**

**Keywords:** 逆源问题, 分数阶扩散方程, 唯一性, Tikhonov正则化, Levenberg-Marquardt方法

**Comment:** 14 pages, 2 figures, 2 tables

> **TL;DR:** 本文研究了时空分数阶扩散方程的逆源问题，通过分数阶导数的记忆效应和唯一延拓性质证明了唯一性，并利用Tikhonov正则化和Levenberg-Marquardt方法进行数值重建，数值例子验证了算法的有效性和准确性。

**AI_Comments:** 本文的创新点在于结合分数阶导数的记忆效应和唯一延拓性质来解决时空分数阶扩散方程的逆源问题的唯一性，并提出了一个基于Tikhonov正则化和Levenberg-Marquardt方法的数值重建框架，为解决这类复杂逆问题提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究时空分数阶扩散方程的逆源问题。

**Method:** 通过分数阶导数的记忆效应和唯一延拓性质建立了唯一性结果。对于数值重建，将逆问题重新表述为一个带有Tikhonov正则化的优化问题，并使用Levenberg-Marquardt方法从噪声测量中识别未知源。

**Result:** 建立了逆源问题的唯一性结果，并通过数值例子说明了所提出算法的效率和准确性。

**Conclusion:** 所提出的算法在从噪声测量中识别时空分数阶扩散方程的未知源方面是有效和准确的。

> **ai_Abstract:** 本文研究了时空分数阶扩散方程的逆源问题，利用分数阶导数的记忆效应和唯一延拓性质证明了唯一性。在数值重建方面，该问题被转化为一个带有Tikhonov正则化的优化问题，并采用Levenberg-Marquardt方法从噪声数据中识别未知源。数值实验验证了所提算法的有效性和准确性。

> **摘要翻译:** 本文研究了具有后验内部测量的时空分数阶扩散方程的逆源问题。通过分数阶导数的记忆效应和唯一延拓性质建立了唯一性结果。对于数值重建，将逆问题重新表述为带有Tikhonov正则化的优化问题。我们使用Levenberg-Marquardt方法从噪声测量中识别未知源。最后，我们给出了一些数值例子来说明所提出算法的效率和准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [178] [Robust space-time multiscale upscaling via multicontinuum homogenization for evolving perforated media](https://arxiv.org/abs/2506.21104)
> *演化穿孔介质中基于多连续体均匀化的鲁棒时空多尺度粗化*

*Wei Xie, Viet Ha Hoang, Yin Yang, Yunqing Huang* | **Category: math.NA, cs.NA**

**Keywords:** 多尺度建模, 多连续体均匀化, 时变介质, 穿孔域, 粗化

**Comment:** 

> **TL;DR:** 本文提出了一种基于多连续体均匀化的鲁棒多尺度建模框架，用于处理时变穿孔介质，通过推导宏观方程来解决动态精细尺度几何带来的计算挑战。

**AI_Comments:** 该论文的创新之处在于将多连续体均匀化方法扩展到时变穿孔介质，特别解决了动态精细尺度几何问题并整合了时间导数。这增强了多尺度建模在各种工程和地球科学领域中对复杂、演化系统的适用性。其鲁棒性和大规模模拟的适用性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 由于动态精细尺度几何形状，准确捕捉时变穿孔域的宏观行为带来了显著的计算挑战。这些域广泛存在于工程和地球科学应用中。

**Method:** 本文开发了一种基于多连续体均匀化的多尺度建模框架。该方法根据物理特性（如通道宽度）区分多个连续体，并通过在代表性体积单元上制定的时空局部单元问题将它们耦合起来。这些局部问题结合了时间导数和域演化，确保与底层精细尺度动力学的一致性。

**Result:** 该方法产生了一个鲁棒且可推广的粗化系统，具有可计算的宏观系数，适用于大规模模拟。数值实验验证了该方法的准确性、效率和潜在适用性。

**Conclusion:** 所开发的多连续体均匀化框架为时变穿孔介质的多尺度建模提供了一种准确、高效且适用的方法，能够实现大规模模拟。

> **ai_Abstract:** 本文提出了一种鲁棒且可推广的多尺度建模框架，利用多连续体均匀化处理时变穿孔介质。该框架通过推导有效的宏观方程，解决了动态精细尺度几何带来的计算难题。该方法根据物理特性区分多个连续体，并通过包含时间导数和域演化的时空局部单元问题进行耦合。由此产生的粗化系统具有可计算的宏观系数，适用于大规模模拟，其准确性、效率和适用性已通过数值实验验证。

> **摘要翻译:** 时变穿孔域出现在许多工程和地球科学应用中，包括多孔介质中的反应输运、颗粒沉积和结构退化。由于动态的精细尺度几何形状，准确捕捉此类系统的宏观行为带来了显著的计算挑战。在本文中，我们开发了一种基于多连续体均匀化的鲁棒且可推广的多尺度建模框架，以推导收缩域中的有效宏观方程。该方法根据物理特性（例如通道宽度）区分多个连续体，并通过在代表性体积单元上制定的时空局部单元问题将它们耦合起来。这些局部问题结合了时间导数和域演化，确保与底层精细尺度动力学的一致性。由此产生的粗化系统产生可计算的宏观系数，适用于大规模模拟。本文提出了几个数值实验，以验证该方法对复杂时变工程问题的准确性、效率和潜在适用性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [192] [Robust and efficient pre-processing techniques for particle-based methods including dynamic boundary generation](https://arxiv.org/abs/2506.21206)
> *用于粒子方法的鲁棒高效预处理技术，包括动态边界生成*

*Niklas S. Neher, Erik Faulhaber, Sven Berger, Christian Weißenfels, Gregor J. Gassner, Michael Schlottke-Lakemper* | **Category: math.NA, cs.NA**

**Keywords:** 粒子方法, 预处理, SPH, 粒子分布, 几何体处理

**Comment:** 

> **TL;DR:** 本文提出了一种用于2D和3D几何体的鲁棒高效预处理技术，旨在为SPH和其他粒子方法生成高质量的粒子分布，即使面对复杂或不完美的输入几何体也能有效工作。

**AI_Comments:** 该论文提出了一种创新的粒子预处理流程，其亮点在于解决了复杂几何体下粒子分布质量的挑战。方法结合了点云、符号距离场和改进的粒子松弛技术，实现了对不完美输入几何体的鲁棒性，并且无需网格连接信息，这大大简化了与现有粒子框架的集成。其高效性和对几何体收敛性的证明，使其在计算流体力学等领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为稳定准确的粒子基模拟获取高质量的粒子分布，特别是对于复杂几何体，面临重大挑战。

**Method:** 该方法首先生成几何体表面附近的分辨率自适应点云，然后利用该点云构建符号距离场。接着，应用分层缠绕数方法进行快速准确的内外分割，并使用SPH启发式方案松弛粒子位置，同时实现边界粒子填充，确保核函数支持和各向同性分布。

**Result:** 该技术能够生成高质量的粒子分布，即使对于不完美的输入几何体也具有鲁棒性，并且内存效率高。实验表明，随着分辨率的提高，所得粒子分布收敛于精确的几何形状。

**Conclusion:** 所提出的预处理方法不依赖连接信息，易于集成到现有粒子框架中。它对不完美的输入几何体具有鲁棒性，且内存高效，同时不影响性能，并能确保粒子分布在更高分辨率下收敛到精确几何体。

> **ai_Abstract:** 本文提出了一种针对2D和3D复杂几何体的鲁棒高效预处理技术，旨在为SPH及其他粒子基模拟生成高质量的粒子分布。该方法通过生成分辨率自适应点云、构建符号距离场、应用分层缠绕数进行内外分割，并采用SPH启发式方案松弛粒子及填充边界粒子，确保了粒子分布的均匀性和几何界面的保持。该技术不依赖网格连接信息，易于集成，对不完美输入具有鲁棒性，且内存高效，并能确保高分辨率下粒子分布收敛于精确几何体。

> **摘要翻译:** 为稳定准确的粒子基模拟获取高质量的粒子分布，特别是对于复杂几何体，面临重大挑战。我们介绍了一种针对2D和3D几何体的预处理技术，该技术针对光滑粒子流体动力学（SPH）和其他粒子基方法进行了优化。我们的流程始于在几何体表面附近生成分辨率自适应点云，该过程采用基于面的邻域搜索。该点云构成了符号距离场的基础，从而能够在表面区域附近进行高效的局部计算。为了创建初始粒子配置，我们应用了一种分层缠绕数方法进行快速准确的内外分割。然后，使用SPH启发式方案松弛粒子位置，该方案也用于填充边界粒子。这确保了完整的核函数支持并促进了各向同性分布，同时保留了几何界面。通过利用粒子基方法的无网格特性，我们的方法不需要连接信息，因此易于集成到现有的粒子基框架中。它对不完美的输入几何体具有鲁棒性，并且内存高效，而不影响性能。此外，我们的实验表明，随着分辨率的不断提高，所得粒子分布收敛于精确的几何形状。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [207] [On the coordinate system-dependence of the accuracy of symplectic numerical methods](https://arxiv.org/abs/2506.21241)
> *关于辛数值方法精度对坐标系的依赖性*

*Donát M. Takács, Tamás Fülöp* | **Category: math.NA, cs.NA, physics.class-ph, physics.comp-ph, 65P10, 70H15, 34A05**

**Keywords:** 辛数值方法, 坐标系依赖性, 修正哈密顿量, 第一积分, 精度

**Comment:** 24 pages, 7 figures

> **TL;DR:** 本文系统性地探讨了坐标系选择如何影响辛数值方法的精度，并给出了修正哈密顿量非不变性和第一积分非守恒的推导。

**AI_Comments:** 本文填补了辛数值方法在实际应用中关于坐标系选择影响精度这一研究空白，具有重要的实践意义。其创新之处在于系统性地分析了修正哈密顿量的非不变性和第一积分的非守恒性，并提出了通过坐标变换优化精度的思路。

<details>
  <summary>Details</summary>

**Motivation:** 辛数值方法在模拟哈密顿系统中应用广泛，但关于坐标系选择如何影响其精度这一实际问题，却鲜有关注。本文旨在填补这一空白。

**Method:** 本文系统性地概述了坐标变换如何影响辛数值方法模拟结果。具体方法包括：推导了辛方法修正哈密顿量在坐标变换下的非不变性；给出了辛欧拉方法对应循环坐标第一积分非守恒的充分条件；并探讨了寻找能提高数值方法精度的阶补偿坐标变换的可能性。

**Result:** 研究表明，辛方法的修正哈密顿量在坐标变换下是非不变的。对于辛欧拉方法，给出了对应循环坐标的第一积分非守恒的充分条件。文中还提出了寻找阶补偿坐标变换以提高精度的方法。

**Conclusion:** 本文系统地分析了辛数值方法精度对坐标系的依赖性，揭示了修正哈密顿量的非不变性和第一积分的非守恒性，并探讨了通过坐标变换提高精度的方法，强调了坐标系选择在实际应用中的重要性。

> **ai_Abstract:** 本文系统地探讨了坐标系选择对辛数值方法精度的影响。研究推导了修正哈密顿量在坐标变换下的非不变性，并给出了辛欧拉方法中循环坐标第一积分非守恒的充分条件。此外，文章还探讨了通过阶补偿坐标变换来提升数值方法精度的可能性，并通过数值例子验证了这些发现。

> **摘要翻译:** 辛数值方法已成为各种领域（包括天体力学、分子动力学和机器人技术）中哈密顿系统精确模拟的广泛选择。尽管它们的特性在数学上已得到充分理解，但通常很少有人关注坐标系选择如何影响数值结果的精度这一实际问题，尽管其后果可能在计算上非常显著。本文旨在通过系统地概述坐标变换如何影响使用辛方法进行的模拟结果来填补这一空白。我们推导了辛方法修正哈密顿量在坐标变换下的非不变性，以及辛欧拉方法对应循环坐标第一积分非守恒的充分条件。我们还考虑了寻找能够提高数值方法精度阶数的阶补偿坐标变换的可能性。文中提供了各种数值例子。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [220] [Runge--Kutta generalized Convolution Quadrature for sectorial problems](https://arxiv.org/abs/2506.21242)
> *Runge--Kutta 广义卷积积分法求解扇形问题*

*Jing Guo, Maria Lopez-Fernandez* | **Category: math.NA, cs.NA, 65R20, 65L06, 65M15, 26A33, 35R11**

**Keywords:** 广义卷积积分法, Runge--Kutta方法, 扇形问题, 收敛阶, 奇异性数据

**Comment:** 35 pages, 26 figures

> **TL;DR:** 本文研究了基于Runge--Kutta方法的广义卷积积分法（gCQ）在求解扇形问题上的应用，证明其能达到与原始卷积积分法相同的收敛阶，并能有效处理数据奇异性，实现快速高效的计算。

**AI_Comments:** 该研究的创新之处在于，它解决了Runge--Kutta基的广义卷积积分法（gCQ）在特定应用场景中收敛性次优的问题，证明了在扇形问题中可以实现与原始卷积积分法相同的最优收敛阶。尤其值得注意的是，它提出了处理数据奇异性的方法，通过优化时间网格来避免阶数降低，这在实际应用中非常重要。gCQ的快速和内存高效的实现也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 原始的卷积积分法（CQ）在均匀步长下表现良好，但其基于Runge--Kutta方法的高阶广义卷积积分法（gCQ）在一般设置下的稳定性和收敛性结果不如原始CQ，在收敛阶和数据正则性要求方面都次优。本文旨在解决gCQ在特定问题类别中的次优表现。

**Method:** 研究了基于Runge--Kutta方法的广义卷积积分法（gCQ）在求解一类重要的扇形问题中的应用。证明了在这些扇形问题中，gCQ在相同数据正则性假设和非常通用的时间网格下，可以达到与原始CQ相同的收敛阶。对于具有代数型奇异性的数据，展示了如何选择最优分级时间网格以实现最大阶收敛，克服了原始CQ在这些情况下的阶数降低问题。描述了Runge--Kutta基的gCQ的快速且无感知实现方法。通过数值实验验证了理论结果。

**Result:** 证明了Runge--Kutta基的gCQ在扇形问题中可以实现与原始CQ相同的收敛阶，且对数据正则性要求相同，并适用于非常通用的时间网格。对于具有代数型奇异性的数据，通过选择最优分级时间网格，gCQ能够实现最大阶收敛，克服了原始CQ在这些情况下的阶数降低问题。该gCQ方法允许快速且内存高效的实现。数值实验证实了理论结果。

**Conclusion:** 本文证明了基于Runge--Kutta方法的广义卷积积分法（gCQ）在求解一类重要的扇形问题时，能够达到与原始卷积积分法相同的最优收敛阶，即使对于具有奇异性的数据也能通过优化时间网格实现最大阶收敛，并且该方法具有快速和内存高效的实现优势。

> **ai_Abstract:** 本文研究了基于Runge--Kutta方法的广义卷积积分法（gCQ）在扇形问题中的应用。尽管gCQ在一般情况下收敛性次优，但作者证明了在特定扇形问题上，gCQ可以在通用时间网格和相同数据正则性假设下，达到与原始卷积积分法（CQ）相同的收敛阶。特别地，对于具有奇异性的数据，通过选择最优分级时间网格，gCQ能克服原始CQ的阶数降低问题，实现最大阶收敛。此外，该方法具有快速和内存高效的实现优势，并通过数值实验验证了理论结果。

> **摘要翻译:** 我们研究了基于Runge--Kutta方法的广义卷积积分法（gCQ）在逼近一类重要扇形问题解中的应用。gCQ将Lubich的原始卷积积分法（CQ）推广到可变步长。在过去十年中，基于某些Runge--Kutta方法，已经开发出了高阶版本的gCQ。迄今为止，基于Runge--Kutta的gCQ已在相当通用的设置中进行研究，其中包括波浪问题的边界积分公式应用。与均匀步长CQ的已知结果相比，这些新方法的可用稳定性和收敛性结果次优，无论是在收敛阶还是数据正则性要求方面。本文我们专注于一类特殊的扇形问题，并证明在这些重要应用中，在相同的数据正则性假设下，以及在非常通用的时间网格下，可以实现与原始CQ相同的收敛阶。在数据具有某些已知代数型奇异性的特殊情况下，我们还展示了如何选择最优分级时间网格以实现最大阶收敛，克服了原始CQ在这些情况下的众所周知的阶数降低问题。gCQ方法的一个重要优点是它允许快速且内存高效的实现。我们描述了如何实现快速且无感知的基于Runge--Kutta的gCQ，并通过几个数值实验说明了我们的理论结果。本文中实现示例的代码可在[13]中获取。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [233] [On Uniform Weighted Deep Polynomial approximation](https://arxiv.org/abs/2506.21306)
> *关于均匀加权深度多项式逼近*

*Kingsley Yeon, Steven B. Damelin* | **Category: math.NA, cs.AI, cs.LG, cs.NA, stat.ML**

**Keywords:** 深度多项式逼近, 加权逼近, 非光滑函数, 指数收敛, 参数化策略

**Comment:** 

> **TL;DR:** 本文引入并分析了一类加权深度多项式逼近器，专门用于逼近具有不对称行为的函数，并在数值上证明其优于传统方法。

**AI_Comments:** 本文的创新之处在于引入了加权深度多项式逼近器来处理非光滑和具有不对称行为的函数，这在传统多项式逼近中是一个挑战。通过结合深度学习的优势和加权方法，该研究为处理特定类型的复杂函数逼近问题提供了新的视角和有效工具。其数值结果表明了该方法的优越性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 经典的理性逼近理论表明，非光滑或奇异函数可以被有理函数高效逼近，收敛速度为根指数级，而多项式逼近仅能实现代数收敛。虽然最近的工作表明复合多项式结构可以恢复指数逼近率，但针对具有不对称行为（一侧无界增长，另一侧衰减）的函数，仍需要更高效的逼近方法。

**Method:** 本文引入并分析了一类加权深度多项式逼近器，通过将一个可学习的深度多项式与一个单侧权重相乘，以捕获局部非光滑性和全局增长。为了在实践中优化这些逼近器，提出了一种基于图的稳定参数化策略。

**Result:** 数值结果表明，该框架在参数数量相同的情况下，优于泰勒、切比雪夫和标准深度多项式逼近器。

**Conclusion:** 通过引入加权深度多项式逼近器和稳定的参数化策略，可以有效地逼近具有不对称行为的非光滑函数，并达到比传统多项式逼近方法更好的性能。

> **ai_Abstract:** 本文提出并分析了一种新的加权深度多项式逼近器，旨在高效逼近具有不对称行为（如一侧增长一侧衰减）的非光滑函数。通过结合深度多项式和单侧权重，该方法能够同时处理局部非光滑性和全局增长特性。数值实验表明，与传统的泰勒、切比雪夫和标准深度多项式逼近器相比，即使在参数数量相同的情况下，该方法也能取得更优的性能。此外，文章还提出了一种稳定的图基参数化策略以优化实际应用。

> **摘要翻译:** 在有理逼近理论中，一个经典结果是，某些非光滑或奇异函数，如 $|x|$ 和 $x^{1/p}$，可以使用有理函数高效逼近，其自由度方面具有根指数收敛速度 
\cite{Sta, GN}。相比之下，根据杰克逊定理 
\cite{Lub2}，多项式逼近仅能实现代数收敛。最近的工作表明，复合多项式结构即使在没有光滑性的情况下也能恢复指数逼近率 
\cite{KY}。在这项工作中，我们引入并分析了一类加权深度多项式逼近器，专门针对具有不对称行为——一侧无界增长，另一侧衰减的函数。通过将一个可学习的深度多项式与一个单侧权重相乘，我们捕获了局部非光滑性和全局增长。我们数值表明，即使所有方法使用相同数量的参数，该框架也优于泰勒、切比雪夫和标准深度多项式逼近器。为了在实践中优化这些逼近器，我们提出了一种基于图的稳定参数化策略，该策略建立在 
\cite{Jar} 的基础上。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [244] [A Sampling-Based Adaptive Rank Approach to the Wigner-Poisson System](https://arxiv.org/abs/2506.21314)
> *基于采样自适应秩方法的Wigner-Poisson系统*

*Andrew Christlieb, Sining Gong, Jing-Mei Qiu, Nanyi Zheng* | **Category: math.NA, cs.NA**

**Keywords:** Wigner-Poisson系统, 自适应秩, 暖密物质, 阻止本领, 量子动力学模拟

**Comment:** 

> **TL;DR:** 本文开发了一种针对一维一速Wigner-Poisson系统的质量守恒、自适应秩求解器，用于研究暖密物质中α粒子的阻止本领。该求解器实现了O(N)的计算复杂度，并能有效捕捉溶液结构，与全秩模拟结果在视觉上无异。

**AI_Comments:** 该论文在Wigner-Poisson系统求解方面取得了显著进展，尤其适用于暖密物质应用。其创新之处在于开发了一种自适应秩求解器，该求解器利用了观察到的解的低秩结构，从而实现了令人印象深刻的O(N)复杂度。这种高效率与质量守恒和精度相结合，使其成为复杂量子动力学模拟的强大工具，克服了系统非局部性带来的挑战。其在高维模拟方面的潜力是主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 该工作的动机是研究国家点火装置（NIF）中α粒子的阻止本领。在此状态下，电子处于暖密态，需要Wigner-Poisson系统来描述，因为它能捕捉量子不确定性效应。Wigner-Poisson系统的非局部性带来了挑战。此外，模拟中观察到的解的低秩结构也促使开发自适应秩求解器。

**Method:** 首先，基于二阶Strang分裂方法，设计了一个全秩求解器，该求解器采用结构保持傅里叶更新，确保中间解保持实值。其次，基于对解低秩结构的观察，开发了一个自适应秩求解器。该求解器结合了用于对流的半拉格朗日自适应秩（SLAR）方案和用于Wigner积分项的自适应秩、结构保持傅里叶更新，并提供了严格的结构保持性质证明。该求解器在存储和计算时间上均实现了O(N)的复杂度，同时保持质量守恒和动量精度。

**Result:** 全秩求解器通过确保实值中间解，改进了现有方法。模拟表明，对于中等到高维无量纲普朗克常数（H ≥ 0.1），解表现出低秩结构。自适应秩模拟在捕获解结构方面与全秩模拟在视觉上无法区分。该求解器在存储和计算时间上均达到了O(N)复杂度，同时保持质量守恒并维持动量精度。

**Conclusion:** 这些结果突出了自适应秩方法在高维Wigner-Poisson模拟中的潜力，为在暖密等离子体中进行阻止本领的完全动力学研究铺平了道路。

> **ai_Abstract:** 本文提出了一种用于1D1V Wigner-Poisson系统的质量守恒、自适应秩求解器，旨在研究暖密等离子体中α粒子的阻止本领。研究首先开发了一个基于二阶Strang分裂和结构保持傅里叶更新的全秩求解器。鉴于在特定普朗克常数下观察到的解的低秩结构，作者进一步提出了一个自适应秩求解器，该求解器利用半拉格朗日自适应秩（SLAR）方案和自适应秩、结构保持傅里叶更新。新求解器在存储和计算上均实现了O(N)复杂度，同时保持质量守恒和动量精度，并且其结果与全秩模拟在视觉上保持一致，展示了其在高维量子动力学模拟中的巨大潜力。

> **摘要翻译:** 我们开发了一个用于一维一速Wigner-Poisson系统的质量守恒、自适应秩求解器。我们的工作动机是应用于研究国家点火装置 (NIF) 中 $\alpha$ 粒子的阻止本领。在这种情况下，电子处于暖密态，需要超出标准动力学模型的描述。它们足够热，可以忽略泡利不相容原理，但又足够量子化，需要考虑不确定性。Wigner-Poisson系统捕获了这些效应，但由于其非局部性带来了挑战。基于二阶Strang分裂方法，我们首先设计了一个全秩求解器，该求解器具有结构保持傅里叶更新，确保中间解保持实值（达到机器精度），改进了以前的方法。模拟表明，对于中等到高维无量纲普朗克常数 ($H \ge 0.1$)，解表现出低秩结构。观察到的这种低秩结构促使我们开发了一种自适应秩求解器，该求解器基于用于对流的半拉格朗日自适应秩 (SLAR) 方案和用于Wigner积分项的自适应秩、结构保持傅里叶更新，并提供了结构保持性质的严格证明。我们的求解器在存储和计算时间上都达到了 $O(N)$ 复杂度，同时保持质量守恒并保持动量精度达到截断误差。自适应秩模拟在捕获解结构方面与全秩模拟在视觉上无法区分。这些结果凸显了自适应秩方法在高维Wigner-Poisson模拟中的潜力，为在暖密等离子体中进行阻止本领的完全动力学研究铺平了道路。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [254] [A discontinuous in time Streamline Diffusion Virtual Element Method for Darcy-transport problem](https://arxiv.org/abs/2506.21326)
> *达西输运问题中基于时间不连续流线扩散的虚单元法*

*R A Caraballo Diaz, F Dassi* | **Category: math.NA, cs.NA**

**Keywords:** Streamline Diffusion, Virtual Element Method, Discontinuous Galerkin, Darcy-transport, Advection-diffusion-reaction

**Comment:** 

> **TL;DR:** 本文首次数值研究了一种时间不连续的流线扩散虚单元法，用于模拟达西流场下的对流-扩散-反应系统，并通过数值实验验证了理论误差估计的任意阶精度。

**AI_Comments:** 这项工作创新性地将流线扩散法、虚单元法和时间不连续伽辽金方案结合起来，用于解决复杂的达西输运问题。其理论误差估计和数值实验验证了方法的精度，为相关领域的数值模拟提供了新的高效工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究涉及化学反应物种的输运现象，这些现象由达西定律控制的流场下的对流-扩散-反应系统建模。

**Method:** 采用流线扩散法，结合虚单元法计算速度场和物种浓度，并使用时间不连续伽辽金（Discontinuous Galerkin）方案处理时间。通过结合高斯-拉道插值和数值积分的特殊技术推导了抽象误差估计。

**Result:** 理论发现得到了数值实验的支持，这些实验在空间和时间上都显示出任意阶精度。

**Conclusion:** 所提出的时间不连续流线扩散虚单元法能够有效且准确地模拟达西-输运问题中的对流-扩散-反应系统，并在空间和时间上都达到了任意阶精度。

> **ai_Abstract:** 本文首次对达西定律控制下的对流-扩散-反应系统中的化学反应物种输运现象进行了数值研究。作者提出了一种时间不连续的流线扩散虚单元法，用于计算速度场和物种浓度。该方法在时间离散上采用了不连续伽辽金方案。通过结合高斯-拉道插值和数值积分，推导出了抽象误差估计，并通过数值实验验证了该方法在空间和时间上的任意阶精度。

> **摘要翻译:** 我们首次对涉及化学反应物种的输运现象进行了数值研究，这些现象由达西定律控制的流场下的对流-扩散-反应系统建模。在各种离散化方法中，我们考虑了流线扩散法。速度场和物种浓度都使用虚单元法计算，时间方面采用不连续伽辽金方案。通过结合高斯-拉道插值和数值积分的特殊技术，推导出了抽象误差估计。这些理论发现得到了数值实验的支持，数值实验在空间和时间上都显示出任意阶精度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [263] [Efficient parameter-robust preconditioners for linear poroelasticity and elasticity in the primal formulation](https://arxiv.org/abs/2506.21361)
> *原公式中线性多孔弹性与弹性高效参数鲁棒预处理器*

*Weizhang Huang, Zhuoran Wang* | **Category: math.NA, cs.NA, 65M60, 65F08, 65F10, 74F10**

**Keywords:** 多孔弹性, 预处理器, 鞍点系统, 参数鲁棒性, GMRES

**Comment:** 27 pages

> **TL;DR:** 为解决多孔弹性问题离散化导致的大规模鞍点系统在锁定情况下的奇异性问题，本文开发了参数鲁棒的非奇异预处理器，其特征值分布有助于GMRES快速收敛，并通过数值实验验证了其有效性。

**AI_Comments:** 该研究通过开发非奇异预处理器，巧妙地解决了多孔弹性问题在锁定情况下离散化所产生的奇异性难题。其创新点在于通过控制预处理系统特征值的分布来保证GMRES算法的快速收敛，并且实现了对网格尺寸、时间步长和锁定参数的鲁棒性，这对于实际工程应用具有重要意义。此外，预处理器无需精确求逆和计算Schur补的特性也提升了其计算效率和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 多孔弹性问题在工程、地球物理和生物应用中很重要，其完全离散化导致大规模鞍点系统，在锁定情况下会变得奇异，需要有效的预处理器进行快速迭代求解。

**Method:** 开发非奇异预处理器，使其预处理系统的特征值由围绕1的簇和数量级为1/λ的异常值组成。研究了二场和三场块三角Schur补预处理器。推导了特征值簇半径的上界，并证明其与inf-sup条件相关但与网格尺寸、时间步长和锁定参数无关。预处理器不需要计算Schur补，也不需要除首个块外的对角块的精确求逆。使用无锁定弱Galerkin有限元方法和隐式欧拉格式进行离散化。

**Result:** 预处理系统的特征值由围绕1的簇和数量级为1/λ的异常值组成，这有助于GMRES的收敛。获得了特征值簇半径的上界，并证明其与inf-sup条件相关但与网格尺寸、时间步长和锁定参数无关，这反映了预处理器对参数变化的鲁棒性。数值结果证实了所开发预处理器的有效性和参数鲁棒性。

**Conclusion:** 本文开发的高效参数鲁棒预处理器能有效解决多孔弹性问题离散化产生的大规模奇异鞍点系统，且对参数变化具有鲁棒性，为快速迭代求解提供了有效工具。

> **ai_Abstract:** 本文针对多孔弹性问题离散化后在锁定情况下出现的奇异大规模鞍点系统，提出了一种高效的参数鲁棒非奇异预处理器。该预处理器的设计使得预处理系统的特征值聚集在1附近，有助于GMRES方法的快速收敛。研究了二场和三场块三角Schur补预处理器，并证明其特征值簇半径的上界与网格尺寸、时间步长和锁定参数无关，体现了其对参数变化的鲁棒性。该方法无需计算Schur补，且除了首个块外，无需精确逆对角块。通过二维和三维数值实验验证了所开发预处理器的有效性和鲁棒性。

> **摘要翻译:** 多孔弹性问题在各种工程、地球物理和生物应用中扮演着重要角色。它们的完全离散化在每个时间步都会产生一个大规模的鞍点系统，该系统在锁定情况下会变得奇异，需要有效的预处理器来进行快速迭代求解。我们没有构建谱等价的预处理器，而是开发了非奇异预处理器，使得预处理系统的特征值由围绕1的簇和数量级为1/λ的异常值组成，其中λ是Lamé常数，在锁定情况下很大。已知GMRES的收敛因子受此类系统特征值簇半径的限制。本文研究了二场和三场块三角Schur补预处理器。获得了这些系统特征值簇半径的上界，并表明其与inf-sup条件相关，但独立于网格尺寸、时间步长和锁定参数，这反映了预处理器对参数变化的鲁棒性。此外，所开发的预处理器不需要计算Schur补，也不需要除首个块外的对角块的精确求逆。控制方程的离散化使用了无锁定弱Galerkin有限元方法和隐式欧拉格式。二维和三维数值结果都证实了所开发预处理器的有效性和参数鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [269] [Optimal solutions employing an algebraic Variational Multiscale approach Part II: Application to Navier-Stokes](https://arxiv.org/abs/2506.21395)
> *采用代数变分多尺度方法的优化解 第二部分：在Navier-Stokes方程中的应用*

*Suyash Shrestha, Marc Gerritsma, Gonzalo Rubio, Steven Hulshoff, Esteban Ferrer* | **Category: math.NA, cs.NA**

**Keywords:** 变分多尺度方法, Navier-Stokes方程, 非线性问题, 最优投影, 数值模拟

**Comment:** 

> **TL;DR:** 该工作将变分多尺度（VMS）方法扩展到非线性问题，特别是2D不可压缩Navier-Stokes方程，通过最优投影和格林函数近似实现了高阶精度、守恒性，并展示了其鲁棒性和准确性。

**AI_Comments:** 该论文的创新点在于将高阶变分多尺度（VMS）方法成功推广到非线性问题，特别是Navier-Stokes方程。通过引入最优投影器和细尺度格林函数近似，该方法在保持高阶精度的同时，有效处理了非线性，并展现出良好的守恒性。这对于解决复杂的非线性多尺度问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在将先前针对稳态线性问题引入的基于变分多尺度（VMS）方法的高阶离散化框架，扩展到非线性问题，特别是处理2D不可压缩Navier-Stokes方程。

**Method:** 该方法是变分多尺度（VMS）方法的非线性扩展，通过定义在控制算子对称部分上的最优投影器来泛化公式。它通过相关对称算子的近似细尺度格林函数来近似细尺度贡献，从而在保持高阶精度的同时，对非线性进行一致的变分处理。

**Result:** 该方法产生的数值解能够紧密近似连续/高分辨率解的最优投影，并继承了理想的守恒特性。数值结果证实了该框架的鲁棒性、准确性及其在广泛非线性多尺度问题中的应用潜力。

**Conclusion:** 该框架对于非线性多尺度问题具有鲁棒性、准确性，并具有广泛的应用潜力。

> **ai_Abstract:** 本研究将变分多尺度（VMS）方法从线性稳态问题推广到非线性问题，并应用于2D不可压缩Navier-Stokes方程。该方法利用最优投影器和近似细尺度格林函数，实现了已解析和未解析尺度的清晰分离，并能一致处理非线性，同时保持高阶精度。数值结果表明，该方法能产生接近最优投影的解，具有良好的守恒性、鲁棒性和准确性，适用于多种非线性多尺度问题。

> **摘要翻译:** 这项工作提出了对先前针对稳态线性问题引入的基于变分多尺度（VMS）方法的高阶离散化框架的非线性扩展。在通过控制算子对称部分定义的最优投影概念的基础上，我们将公式推广到处理2D不可压缩Navier-Stokes方程。该方法在已解析尺度和未解析尺度之间保持清晰的分离，其中细尺度贡献通过相关对称算子的近似细尺度格林函数进行近似。这使得非线性能够进行一致的变分处理，同时保持高阶精度。我们表明，该方法产生的数值解能够紧密近似连续/高分辨率解的最优投影，并继承了理想的守恒特性。数值结果证实了该框架的鲁棒性、准确性及其在广泛非线性多尺度问题中的应用潜力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [276] [An adaptive dynamical low-rank optimizer for solving kinetic parameter identification inverse problems](https://arxiv.org/abs/2506.21405)
> *一种用于求解动力学参数识别逆问题的自适应动态低秩优化器*

*Lena Baumann, Lukas Einkemmer, Christian Klingenberg, Jonas Kusch* | **Category: math.NA, cs.NA, 35Q49, 49M41, 65M22, 65M32**

**Keywords:** 动态低秩近似, 参数识别, 逆问题, 辐射传输方程, 计算成本

**Comment:** 

> **TL;DR:** 本文提出了一种自适应动态低秩近似（DLRA）方案，用于从宏观测量中重建辐射传输方程中的散射参数，该方案显著降低了计算和内存成本，并被证明是准确和高效的。

**AI_Comments:** 本文的创新点在于将动态低秩近似（DLRA）与自适应机制相结合，有效地解决了动力学参数识别逆问题中计算和内存成本高昂的挑战。特别是引入秩自适应基更新和线搜索方法，使得优化过程更加高效和鲁棒。这项工作对于处理大规模动力学逆问题具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 动力学方程的参数识别逆问题的数值解具有高计算和内存成本。

**Method:** 该方法首先在连续设置中通过PDE约束优化过程，并使用拉格朗日重构推导出伴随方程。对于散射系数，引入周期B样条逼近并制定了更新其系数的梯度下降步骤。离散化后，应用动态低秩近似（DLRA）。利用秩自适应基更新和伽辽金积分器，以及用于梯度下降步长和DLRA容差自适应改进的线搜索方法。

**Result:** 所提出的方案显著降低了内存和计算成本。使用不同初始条件计算的数值结果验证了所提出的DLRA方案与使用完整求解器计算的解决方案相比的准确性和效率。

**Conclusion:** 所提出的自适应动态低秩优化器在解决动力学参数识别逆问题时，能够显著降低计算和内存成本，并保持高精度和效率。

> **ai_Abstract:** 本文提出了一种自适应动态低秩近似（DLRA）方案，用于解决动力学方程中参数识别逆问题的高计算和内存成本。该方案通过PDE约束优化、拉格朗日重构、B样条逼近和梯度下降步骤来重建辐射传输方程中的散射参数。在离散化后，应用DLRA，并结合秩自适应基更新、伽辽金积分器和线搜索方法进行自适应改进。研究结果表明，该方案显著降低了计算和内存成本，并且在准确性和效率上优于传统的完整求解器。

> **摘要翻译:** 动力学方程参数识别逆问题的数值解可能表现出高计算和内存成本。在本文中，我们提出了一种动态低秩方案，用于从一些宏观时间无关测量中重建辐射传输方程中的散射参数。我们首先在连续设置中通过PDE约束优化过程，并使用拉格朗日重构推导出伴随方程。对于散射系数，引入周期B样条逼近，并制定了更新其系数的梯度下降步骤。离散化后，应用动态低秩近似（DLRA）。我们利用秩自适应基更新和伽辽金积分器，以及用于梯度下降步长和DLRA容差自适应改进的线搜索方法。我们证明了所提出的方案显著降低了内存和计算成本。使用不同初始条件计算的数值结果验证了所提出的DLRA方案与使用完整求解器计算的解决方案相比的准确性和效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [280] [An Iterative Methodology for Unitary Quantum Channel Search](https://arxiv.org/abs/2506.21455)
> *幺正量子信道搜索的迭代方法*

*Matthew M. Lin, Hao-Wei Huang, Bing-Ze Lu* | **Category: math.NA, cs.NA, quant-ph**

**Keywords:** 幺正量子信道, 迭代算法, 极分解, 量子态对, 搜索空间约简

**Comment:** 

> **TL;DR:** 本文提出了一种基于极分解的迭代算法，用于从输入输出量子态对中近似幺正量子信道，并从理论上证明了其在有限数据下的搜索空间约简和收敛性。

**AI_Comments:** 该论文的创新点在于提出了一个利用极分解的迭代算法来解决幺正量子信道近似问题，并在理论上证明了其在有限数据下的搜索空间优化和收敛性。特别是，通过生成等价类来显著减小搜索空间维度，显示了其在实际应用中的潜在效率提升。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一种迭代方法，通过输入输出量子态对来近似由单个幺正矩阵表征的量子信道。

**Method:** 本文提出了一种使用极分解的迭代算法，通过输入输出量子态对来近似由单个幺正矩阵表征的量子信道。在有限数据下，该方法利用一个具有特定结构的量子态对来生成一个等价类，从而显著减小搜索空间的维度。

**Result:** 研究证明，在有限数据下，使用特定结构的输入输出量子态对，从该方法获得的最佳解将生成一个等价类，从而显著减小搜索空间的维度。此外，还证明了描述同一信道的幺正矩阵仅相差一个模为1的复数。论文严格证明了所提出的算法最终可以识别一个临界点，该点也是所建立目标函数的局部最小值。

**Conclusion:** 该迭代算法能够有效地近似幺正量子信道，并在理论上被证明能够收敛到目标函数的局部最小值，同时在有限数据情况下显著优化了搜索效率。

> **ai_Abstract:** 本文提出了一种基于极分解的迭代算法，旨在通过输入输出量子态对来近似由单个幺正矩阵表示的量子信道。研究证明，在数据有限时，利用特定结构的输入输出对，该方法能生成等价类，从而大幅缩小搜索空间。此外，论文还证明了描述同一信道的幺正矩阵仅相差一个模为1的复数，并严格证明了所提算法能够收敛到目标函数的局部最小值。

> **摘要翻译:** 在本文中，我们提出了一种使用极分解的迭代算法，用于基于输入输出量子态对来近似由单个幺正矩阵表征的信道。在有限数据的情况下，我们阐述并证明了使用一个具有特定结构的量子态对从我们方法获得的最佳解将生成一个等价类，从而显著减小搜索空间的维度。此外，我们证明了描述相同信道的幺正矩阵相差一个模为1的复数。我们严格证明了我们提出的算法最终可以识别一个临界点，该点也是所建立目标函数的局部最小值。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [28] [A Multi-Stage Framework for Multimodal Controllable Speech Synthesis](https://arxiv.org/abs/2506.20945)
> *一种多模态可控语音合成的多阶段框架*

*Rui Niu, Weihao Wu, Jie Chen, Long Ma, Zhiyong Wu* | **Category: cs.SD, eess.AS**

**Keywords:** 可控语音合成, 多模态, 多阶段框架, 知识蒸馏, 语音合成

**Comment:** Accepted by ICME2025

> **TL;DR:** 本文提出了一种三阶段多模态可控语音合成框架，通过结合监督学习、知识蒸馏和多源数据训练，解决了现有方法在鲁棒性、泛化性和多样性方面的局限性，实现了高质量的语音合成。

**AI_Comments:** 该论文的创新点在于提出了一个多阶段框架，并通过结合多种技术（监督学习、知识蒸馏、多源数据训练）来解决多模态可控语音合成中的关键挑战，特别是针对数据质量和匹配度的问题。这对于提升语音合成的实用性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于面部的方法受数据质量限制，在鲁棒性和泛化性方面表现不佳；文本提示方法在多样性和细粒度控制方面有限；多模态方法则受限于对完全匹配训练数据的依赖。

**Method:** 本文提出一个三阶段多模态可控语音合成框架。针对面部编码器，采用监督学习和知识蒸馏解决泛化性问题。文本编码器则在文本-面部和文本-语音数据上进行训练，以增强生成语音的多样性。

**Result:** 实验结果表明，该方法在基于面部和基于文本提示的语音合成方面，均优于单模态基线方法。

**Conclusion:** 该多阶段多模态框架有效解决了现有可控语音合成方法的局限性，能够生成高质量的语音。

> **ai_Abstract:** 本文针对现有可控语音合成方法在鲁棒性、泛化性和多样性上的不足，提出了一种三阶段多模态框架。该框架通过对面部编码器采用监督学习和知识蒸馏，并对文本编码器利用多源数据训练，有效提升了合成语音的质量和多样性，并在实验中验证了其优于单模态基线方法的性能。

> **摘要翻译:** 可控语音合成旨在利用各种模态的参考输入来控制生成语音的风格。现有的基于面部的方法由于数据质量限制，在鲁棒性和泛化性方面存在困难，而文本提示方法提供的多样性和细粒度控制有限。尽管多模态方法旨在整合各种模态，但它们对完全匹配训练数据的依赖显著限制了其性能和适用性。本文提出一个三阶段多模态可控语音合成框架来解决这些挑战。对于面部编码器，我们使用监督学习和知识蒸馏来解决泛化问题。此外，文本编码器在文本-面部和文本-语音数据上进行训练，以增强生成语音的多样性。实验结果表明，该方法在基于面部和基于文本提示的语音合成方面均优于单模态基线方法，突出了其在生成高质量语音方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [52] [PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching](https://arxiv.org/abs/2506.21086)
> *PeakNetFP：基于峰值的神经音频指纹识别，对极端时间拉伸具有鲁棒性*

*Guillem Cortès-Sebastià, Benjamin Martin, Emilio Molina, Xavier Serra, Romain Hennequin* | **Category: cs.SD, cs.IR, eess.AS, H.3.1; H.3.3; H.3.4**

**Keywords:** 音频指纹识别, 神经网络, 频谱峰值, 时间拉伸, PeakNetFP

**Comment:** Accepted at ISMIR 2025

> **TL;DR:** PeakNetFP是一种新型的神经音频指纹识别系统，它结合了传统峰值方法的稀疏性与神经网络的适应性，在处理时间拉伸音频时性能优异，并且参数更少、输入数据更小。

**AI_Comments:** PeakNetFP的创新之处在于将传统的基于峰值的音频指纹识别的轻量级特性与神经网络的强大模式识别能力相结合，特别是在处理时间拉伸方面。其显著的效率提升（参数减少100倍，输入数据减少11倍）使其在实际应用中具有很高的价值和潜力，为音频指纹识别领域提供了一个可扩展且高效的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 传统的音频指纹识别方法在处理极端时间拉伸的音频数据时可能表现不佳。该研究旨在开发一种对时间拉伸具有鲁棒性的高效神经音频指纹识别系统。

**Method:** PeakNetFP是第一个专门围绕频谱峰值设计的神经音频指纹识别系统。它利用传统基于峰值的AFP方法计算的稀疏频谱坐标。系统采用类似于PointNet++的分层点特征提取技术，并使用对比学习进行训练，类似于NeuralFP。

**Result:** PeakNetFP在处理时间拉伸音频数据时，性能优于传统AFP系统，并与最先进的NeuralFP表现相当。在50%到200%的时间拉伸因子范围内，其Top-1命中率保持在90%以上。与NeuralFP相比，PeakNetFP的参数数量减少了100倍，输入数据量减少了11倍。

**Conclusion:** PeakNetFP成功地将基于峰值的AFP的轻量级特性与基于神经网络的方法的适应性和模式识别能力相结合，为未来的AFP技术提供了有前景的方向，有望实现更具可扩展性和效率的解决方案。

> **ai_Abstract:** PeakNetFP是一种创新的神经音频指纹识别（AFP）系统，它首次专门利用音频频谱峰值。该系统结合了PointNet++的分层特征提取和对比学习，旨在应对极端时间拉伸。实验证明，PeakNetFP在时间拉伸音频上性能优越，与NeuralFP相当，且在效率上具有显著优势，参数量和输入数据量大幅减少，使其成为轻量级高效的AFP解决方案。

> **摘要翻译:** 这项工作引入了PeakNetFP，这是第一个专门围绕频谱峰值设计的神经音频指纹识别（AFP）系统。这个新颖的系统旨在利用传统基于峰值的AFP方法通常计算的稀疏频谱坐标。PeakNetFP执行类似于计算机视觉模型PointNet++的分层点特征提取技术，并使用对比学习进行训练，如同最先进的深度学习AFP系统NeuralFP。这种组合使得PeakNetFP在处理具有挑战性的时间拉伸音频数据时，性能优于传统AFP系统，并实现了与NeuralFP相当的性能。在广泛的评估中，PeakNetFP在50%到200%的时间拉伸因子范围内保持了超过90%的Top-1命中率。此外，PeakNetFP提供了显著的效率优势：与NeuralFP相比，它的参数数量减少了100倍，输入数据量减少了11倍。这些特性使得PeakNetFP成为涉及时间拉伸的AFP任务的轻量级高效解决方案。总的来说，该系统代表了未来AFP技术的一个有前景的方向，因为它成功地将基于峰值的AFP的轻量级特性与基于神经网络的方法的适应性和模式识别能力相结合，为该领域更具可扩展性和效率的解决方案铺平了道路。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [77] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
> *一种用于少数乐器检测的分层深度学习方法*

*Dylan Sechet, Francesca Bugiotti, Matthieu Kowalski, Edouard d'Hérouville, Filip Langiewicz* | **Category: cs.SD, cs.AI, eess.AS**

**Keywords:** 分层深度学习, 乐器检测, 音乐信息检索, Hornbostel-Sachs分类, MedleyDB数据集

**Comment:** International Conference on Digital Audio Effects (DAFx)

> **TL;DR:** 本研究提出了一种分层深度学习方法，用于检测音乐中的乐器活动，特别是在数据稀缺的少数乐器类别中，通过弥合乐器级别和组级别识别之间的差距，实现了更可靠的粗粒度乐器检测。

**AI_Comments:** 这项研究的创新之处在于提出了一种分层深度学习方法来解决音乐信息检索中少数乐器检测的数据稀缺问题。通过利用分层分类系统和整合分层结构到模型中，该研究在有限的细粒度标注下实现了更可靠的粗粒度乐器检测，对音乐编目和发现具有重要意义，并为该领域的进一步发展提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在音乐信息检索中，识别音频片段中的乐器活动至关重要，对音乐编目和发现具有重要意义。然而，以往的深度学习在乐器识别方面主要侧重于数据充足的乐器类别，而对细粒度标注有限的少数乐器识别存在挑战。

**Method:** 本研究基于Hornbostel-Sachs分类系统，利用MedleyDB数据集评估了一种分层分类系统。该工作提出了多种策略将分层结构整合到模型中，并测试了一类新的分层音乐预测模型。

**Result:** 本研究通过弥合详细乐器识别和组级别识别之间的差距，展示了更可靠的粗粒度乐器检测。

**Conclusion:** 该研究通过引入分层深度学习方法，有效地解决了少数乐器检测中的数据稀缺问题，为该领域的进一步发展奠定了基础，实现了更可靠的粗粒度乐器检测。

> **ai_Abstract:** 本论文提出了一种新的分层深度学习方法，用于解决音乐信息检索中少数乐器检测的数据稀缺问题。研究基于Hornbostel-Sachs分类系统，在MedleyDB数据集上评估了分层分类系统，并提出了将分层结构整合到模型中的策略。结果表明，该方法能够实现更可靠的粗粒度乐器检测，弥合了详细乐器识别和组级别识别之间的差距。

> **摘要翻译:** 在音乐信息检索中，识别音频片段中的乐器活动至关重要，对音乐编目和发现具有重要意义。以往的音乐乐器识别深度学习研究主要强调数据充足的乐器类别。最近的研究表明，即使在乐器级别的细粒度标注有限的情况下，分层分类在管弦乐器活动检测中也具有适用性。本研究基于霍恩博斯特尔-萨克斯分类法，使用以其多样性和乐器、音乐流派丰富性而闻名的MedleyDB数据集评估了这种分层分类系统。这项工作提出了将分层结构整合到模型中的各种策略，并测试了一类新的分层音乐预测模型。本研究通过弥合详细乐器识别和组级别识别之间的差距，展示了更可靠的粗粒度乐器检测，为该领域的进一步发展铺平了道路。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [102] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
> *整合车辆声学数据以增强城市交通管理：以苏州为例的速度分类研究*

*Pengfei Fan, Yuli Zhang, Xinheng Wang, Ruiyuan Jiang, Hankang Gu, Dongyao Jia, Shangbo Wang* | **Category: cs.SD, cs.AI, eess.AS**

**Keywords:** 车辆声学数据, 速度分类, 深度学习, 交通管理, 城市规划

**Comment:** 

> **TL;DR:** 本研究发布了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一种双模态特征融合深度卷积神经网络（BMCNN），用于车辆噪声与驾驶速度的耦合建模，实现了高效的速度分类，可应用于智能城市交通管理。

**AI_Comments:** 该研究通过发布新的数据集和提出创新的双模态特征融合深度学习模型，为城市交通管理中的声学数据应用提供了重要基础。其创新点在于结合了MFCCs和小波包能量特征，并通过跨模态注意力机制进行融合，有效提升了速度分类的准确性和鲁棒性。该方法具有实际应用潜力，可帮助构建更智能、更可持续的城市交通系统。

<details>
  <summary>Details</summary>

**Motivation:** 为了建模车辆噪声和驾驶速度之间的耦合关系，并利用声学数据实现城市交通管理中的实时噪声监测和速度估计，从而优化交通流控制、减少路边噪音污染并支持可持续城市规划。

**Method:** 本研究发布了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一个双模态特征融合深度卷积神经网络（BMCNN）。预处理阶段采用自适应去噪和归一化策略抑制环境背景干扰；网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，并通过跨模态注意力机制在中间特征空间融合，以充分利用时频信息。

**Result:** BMCNN在SZUR-Acoustic Dataset上实现了87.56%的分类准确率，在公共IDMT-Traffic数据集上达到了96.28%。消融研究和鲁棒性测试进一步验证了各模块对性能提升和过拟合缓解的贡献。

**Conclusion:** 所提出的基于声学的速度分类方法可以整合到智能城市交通管理系统中，用于实时噪声监测和速度估计，从而优化交通流控制，减少路边噪音污染，并支持可持续城市规划。

> **ai_Abstract:** 本研究公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一种名为BMCNN的双模态特征融合深度卷积神经网络，用于建模车辆噪声与行驶速度的耦合关系。BMCNN通过自适应去噪、MFCCs和小波包能量特征提取及跨模态注意力融合，在速度分类任务上表现出色，尤其在SZUR-Acoustic和IDMT-Traffic数据集上分别达到87.56%和96.28%的准确率。该方法可应用于智能城市交通管理系统，实现实时噪声监测和速度估计，以优化交通流、减少噪音污染并支持可持续城市规划。

> **摘要翻译:** 本研究发布并公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），该数据集附有全面的数据采集协议和注释指南，以确保实验工作流程的透明性和可复现性。为了建模车辆噪声与驾驶速度之间的耦合关系，我们提出了一种双模态特征融合深度卷积神经网络（BMCNN）。在预处理过程中，采用自适应去噪和归一化策略来抑制环境背景干扰；在网络架构中，并行分支提取梅尔频率倒谱系数（MFCCs）和小波包能量特征，这些特征随后通过中间特征空间中的跨模态注意力机制进行融合，以充分利用时频信息。实验结果表明，BMCNN在SZUR-Acoustic Dataset上实现了87.56%的分类准确率，在公共IDMT-Traffic数据集上达到了96.28%。在苏州数据集上进行的消融研究和鲁棒性测试进一步验证了每个模块对性能改进和缓解过拟合的贡献。所提出的基于声学的速度分类方法可以整合到智能城市交通管理系统中，用于实时噪声监测和速度估计，从而优化交通流控制、减少路边噪音污染并支持可持续城市规划。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [124] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
> *探索低资源音乐生成中的适配器设计权衡*

*Atharva Mehta, Shivam Chauhan, Monojit Choudhury* | **Category: cs.SD, cs.AI, cs.CL, cs.LG, cs.MM, eess.AS**

**Keywords:** 适配器设计, 音乐生成, 低资源, PEFT, 模型权衡

**Comment:** 9 pages, 5 figures

> **TL;DR:** 本文研究了针对低资源音乐生成的适配器设计权衡，发现不同适配器类型各有优劣，并确定了中等大小适配器的最佳平衡点，同时比较了MusicGen和Mustango两种模型的性能。

**AI_Comments:** 本文的创新之处在于系统性地探索了在低资源音乐生成领域中适配器设计的具体权衡，并首次对比了不同适配器类型和两种主流AI音乐模型（自回归与扩散）在此背景下的性能差异。这对于优化音乐生成模型的部署和降低计算成本具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型音乐生成模型计算成本高昂。参数高效微调（PEFT）技术，特别是基于适配器的方法，虽有潜力，但其设计选择（架构、位置、大小）尚不明确，尤其是在低资源音乐流派中，何种组合能产生最佳适配器及其原因尚不清楚。

**Method:** 本文通过研究两种AI音乐模型（MusicGen和Mustango）在两种音乐流派（印度斯坦古典音乐和土耳其马卡姆音乐）上的各种适配器配置来回答上述问题。

**Result:** 卷积型适配器擅长捕捉精细的局部音乐细节（如装饰音和短旋律片段）；Transformer型适配器能更好地保持对结构化即兴创作至关重要的长程依赖；中等大小的适配器（40M参数）在表达能力和质量之间实现了最佳平衡；Mustango（基于扩散的模型）生成更多样化且更符合输入提示的输出，但在音符稳定性、节奏对齐和美学方面有所欠缺，且计算密集、训练时间长；MusicGen（自回归模型）训练更快、效率更高，能产生更高质量的输出，但生成内容冗余度略高。

**Conclusion:** 本研究揭示了低资源音乐生成中适配器设计的明显权衡，并分析了不同适配器类型和两种AI音乐模型（扩散型与自回归型）的性能特征，指出中等大小的适配器能达到最优平衡。

> **ai_Abstract:** 本文探讨了在低资源环境下，针对MusicGen和Mustango等大型音乐生成模型使用参数高效微调（PEFT）中的适配器设计权衡。研究比较了不同适配器配置（如卷积型和Transformer型）在捕捉音乐细节和保持长程依赖方面的表现，并分析了不同适配器规模的计算需求，发现中等大小的适配器（40M参数）能达到性能与资源消耗的最佳平衡。此外，论文还对比了Mustango（扩散模型）和MusicGen（自回归模型）在生成多样性、质量、效率和资源需求方面的特点。

> **摘要翻译:** 微调大规模音乐生成模型，如MusicGen和Mustango，是一个计算成本高昂的过程，通常需要更新数十亿参数，因此需要大量的硬件资源。参数高效微调（PEFT）技术，特别是基于适配器的方法，已成为一种有前景的替代方案，它能够以最少的训练参数进行适应，同时保持模型性能。然而，适配器的设计选择，包括其架构、位置和大小，数量众多，目前尚不清楚在给定低资源音乐流派的情况下，这些组合中的哪一种会产生最佳适配器以及原因。在本文中，我们试图通过研究两种AI音乐模型（MusicGen和Mustango）在两种流派：印度斯坦古典音乐和土耳其马卡姆音乐上的各种适配器配置来回答这个问题。
我们的研究结果揭示了明显的权衡：基于卷积的适配器擅长捕捉精细的局部音乐细节，如装饰音和短旋律片段，而基于Transformer的适配器能更好地保持对结构化即兴创作至关重要的长程依赖。此外，我们分析了不同适配器规模下的计算资源需求，表明中等大小的适配器（40M参数）在表达能力和质量之间实现了最佳平衡。此外，我们发现Mustango（一种基于扩散的模型）生成更多样化且更符合输入提示的输出，但在音符稳定性、节奏对齐和美学方面有所欠缺。同时，它计算密集，需要显著更长的训练时间。相比之下，像MusicGen这样的自回归模型提供更快的训练速度和更高的效率，并且可以产生更高质量的输出，但其生成内容冗余度略高。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [143] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
> *可学习自适应时频表示通过可微分短时傅里叶变换*

*Maxime Leiber, Yosra Marnissi, Axel Barrau, Sylvain Meignen, Laurent Massoulié* | **Category: cs.SD, cs.LG, eess.AS, eess.SP**

**Keywords:** 短时傅里叶变换, 可微分, 时频表示, 梯度优化, 神经网络

**Comment:** DSTFT, STFT, spectrogram, time-frequency, IEEE Transactions on Signal
  Processing, 10 pages

> **TL;DR:** 提出一种可微分短时傅里叶变换(STFT)公式，实现STFT参数的梯度优化，解决了传统STFT参数调优的局限性，并能与神经网络联合优化，有效提升时频表示和下游任务性能。

**AI_Comments:** 这篇论文的创新点在于提出了STFT的可微分形式，从而将传统上需要手动或启发式调优的参数纳入到梯度优化框架中。这一方法不仅解决了STFT参数敏感性的问题，还使其能够与深度学习模型进行端到端联合优化，极大地扩展了STFT在各种信号处理和机器学习任务中的应用潜力。其重要性在于为信号的时频分析提供了一个更灵活、更优化的工具，特别是对于非平稳信号的处理。

<details>
  <summary>Details</summary>

**Motivation:** 传统的短时傅里叶变换（STFT）在分析非平稳信号时，其性能对参数高度敏感，且手动或启发式调优常导致次优结果。传统的参数调优方法依赖计算密集型离散搜索，存在局限性。

**Method:** 本文提出了一种统一的可微分短时傅里叶变换（STFT）公式，该公式允许通过梯度优化来调整STFT参数。这种方法可以根据任意所需标准对时频表示（TFR）进行微调，并且能够与神经网络无缝集成，实现STFT参数和网络权重的联合优化。

**Result:** 所提出的可微分STFT在增强时频表示（TFRs）和改进下游任务性能方面表现出有效性，并通过在模拟和真实世界数据上的实验得到了证明。

**Conclusion:** 通过引入可微分STFT，可以有效地解决传统STFT参数调优的局限性，实现参数的梯度优化和与神经网络的联合优化，从而显著提升时频表示的质量和下游任务的性能。

> **ai_Abstract:** 本文提出了一种统一的可微分短时傅里叶变换（STFT）公式，旨在解决传统STFT参数敏感且调优困难的问题。该方法允许通过梯度优化来调整STFT参数，从而避免了计算密集型的离散搜索，并能根据特定标准微调时频表示（TFR）。此外，它能与神经网络无缝集成，实现参数和网络权重的联合优化。实验证明，该方法能有效提升TFR质量和下游任务性能。

> **摘要翻译:** 短时傅里叶变换（STFT）被广泛用于分析非平稳信号。然而，其性能对其参数高度敏感，并且手动或启发式调优常常导致次优结果。为了克服这一限制，我们提出了一种统一的可微分STFT公式，该公式能够实现其参数的基于梯度的优化。这种方法解决了传统STFT参数调优方法的局限性，这些方法通常依赖于计算密集型的离散搜索。它使得能够根据任何所需标准对时频表示（TFR）进行微调。此外，我们的方法与神经网络无缝集成，允许STFT参数和网络权重的联合优化。通过在模拟和真实世界数据上的实验，证明了所提出的可微分STFT在增强TFRs和改进下游任务性能方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [161] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
> *SmoothSinger：一种具有多分辨率架构的歌唱语音合成条件扩散模型*

*Kehan Sui, Jinxu Xiang, Fang Jin* | **Category: cs.SD, cs.AI**

**Keywords:** 歌唱语音合成, 条件扩散模型, 多分辨率架构, 音频细化, SmoothSinger

**Comment:** 

> **TL;DR:** SmoothSinger是一个条件扩散模型，通过直接在统一框架中优化低质量音频，并采用参考引导的双分支架构和增强的U-Net，实现了高质量和自然的歌唱语音合成，在Opencpop数据集上达到SOTA。

**AI_Comments:** SmoothSinger的创新之处在于其统一的直接音频细化框架，避免了传统声码器引入的失真。其参考引导的双分支架构和改进的U-Net（特别是并行低频上采样路径）是关键，有助于更好地捕捉音乐特性，如音高。解决了训练中参考与目标信号时间不匹配的问题也提升了模型性能。这项工作对于推动扩散模型在复杂音频生成领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 歌唱语音合成 (SVS) 需要精确建模音高、持续时间和发音，但基于扩散的模型在SVS中的应用仍具挑战性，常导致不自然的人工痕迹。现有方法依赖声码器作为最终阶段，容易引入失真。

**Method:** 提出SmoothSinger，一个条件扩散模型，用于合成高质量和自然的歌唱语音。它在统一框架中直接细化低质量合成音频，以减轻两阶段管道的退化。模型采用参考引导的双分支架构，使用低质量音频作为参考指导去噪过程。此外，它通过并行低频上采样路径增强了传统的U-Net，以更好地捕捉音高轮廓和长期频谱依赖。训练时，用降级的真实音频替代参考音频，以解决时间不匹配问题。

**Result:** 在Opencpop数据集上的实验表明，SmoothSinger在客观和主观评估中均取得了最先进的结果。广泛的消融研究证实了其在减少人工痕迹和提高合成语音自然度方面的有效性。

**Conclusion:** SmoothSinger通过其创新的架构和训练策略，成功解决了歌唱语音合成中扩散模型应用面临的挑战，实现了高质量和自然度的SVS，并达到了最先进的性能。

> **ai_Abstract:** SmoothSinger是一个用于歌唱语音合成的条件扩散模型，旨在克服现有扩散模型在SVS中生成人工痕迹和两阶段管道引入失真的问题。它通过直接在统一框架中细化低质量音频，并采用参考引导的双分支架构和增强的U-Net（带有并行低频上采样路径），实现了高质量和自然的歌唱声音。在Opencpop数据集上的实验证明，SmoothSinger在客观和主观评估中均达到了最先进的性能，并有效减少了人工痕迹，提高了合成语音的自然度。

> **摘要翻译:** 歌唱语音合成 (SVS) 旨在从乐谱生成富有表现力的高质量人声，需要对音高、持续时间和发音进行精确建模。虽然基于扩散的模型在图像和视频生成方面取得了显著成功，但由于歌唱复杂的声学和音乐特性，它们在SVS中的应用仍然具有挑战性，经常导致降低自然度的人工痕迹。在这项工作中，我们提出了 SmoothSinger，一个条件扩散模型，旨在合成高质量和自然的歌唱语音。与依赖声码器作为最终阶段并经常引入失真的先前方法不同，SmoothSinger 在统一框架中直接细化低质量合成音频，减轻了两阶段管道相关的退化。该模型采用参考引导的双分支架构，使用来自任何基线系统的低质量音频作为参考来指导去噪过程，从而实现更具表现力和上下文感知的合成。此外，它通过并行低频上采样路径增强了传统的 U-Net，使模型能够更好地捕捉音高轮廓和长期频谱依赖。为了在训练期间改善对齐，我们用降级的真实音频替换参考音频，解决了参考信号和目标信号之间的时间不匹配。在大型中文歌唱语料库 Opencpop 数据集上的实验表明，SmoothSinger 在客观和主观评估中均取得了最先进的结果。广泛的消融研究证实了其在减少人工痕迹和提高合成语音自然度方面的有效性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [251] [DRAGON: Distributional Rewards Optimize Diffusion Generative Models](https://arxiv.org/abs/2504.15217)
> *DRAGON：分布奖励优化扩散生成模型*

*Yatong Bai, Jonah Casebeer, Somayeh Sojoudi, Nicholas J. Bryan* | **Category: cs.SD, cs.AI, cs.LG, cs.MM**

**Keywords:** 生成模型, 扩散模型, 奖励优化, DRAGON, 分布式奖励

**Comment:** 

> **TL;DR:** DRAGON是一个灵活的框架，用于微调媒体生成模型，通过优化针对个体示例或其分布的奖励函数来提高生成质量，并在实验中取得了显著的胜率，甚至无需人类偏好标注即可提升人类感知质量。

**AI_Comments:** DRAGON的创新之处在于其对奖励函数的灵活性，能够处理个体示例和分布层面的奖励，这显著拓宽了生成模型优化的可能性。其无需人类偏好标注即可提升人类感知质量的能力，对于降低训练成本和提高模型实用性具有重要意义。该方法通过构建示例分布和对比学习的方式来优化扩散模型，提供了一个新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习与人类反馈（RLHF）或配对偏好方法（如直接偏好优化DPO）在微调媒体生成模型时不够灵活，无法优化评估个体示例或其分布的多种奖励函数。

**Method:** DRAGON（Distributional RewArds for Generative OptimizatioN）是一个通用的框架，它比传统的RLHF或DPO更灵活，能够优化评估个体示例或其分布的奖励函数。它兼容多种奖励类型：实例到实例、实例到分布、分布到分布。该方法通过选择编码器和参考示例来构建示例分布（当使用跨模态编码器如CLAP时，参考示例可以是不同模态的）。然后，DRAGON收集在线和策略内生成内容，对其进行评分以构建正面示范集和负面示范集，并利用两组之间的对比来最大化奖励。

**Result:** DRAGON在20种不同的目标奖励函数上实现了81.45%的平均胜率。基于示例集的奖励函数确实增强了生成效果，并且与基于模型的奖励效果相当。通过适当的示例集，DRAGON在没有人类偏好标注训练的情况下，实现了60.95%的人类投票音乐质量胜率。

**Conclusion:** DRAGON展示了一种设计和优化奖励函数的新方法，以提高人类感知质量。

> **ai_Abstract:** DRAGON是一种用于微调媒体生成模型的灵活框架，它通过优化评估个体示例或其分布的奖励函数来克服传统RLHF和DPO的局限性。该方法通过构建示例分布、收集在线生成内容并利用正负样本对比来最大化奖励。在对文本到音乐扩散模型的评估中，DRAGON在20种不同奖励函数上取得了81.45%的平均胜率，并且在不依赖人类偏好标注的情况下，通过适当的示例集实现了60.95%的人类投票音乐质量胜率，展示了其在提升人类感知质量方面的潜力。

> **摘要翻译:** 我们提出了DRAGON（分布奖励生成优化），一个用于微调媒体生成模型以达到预期结果的通用框架。与传统的基于人类反馈的强化学习（RLHF）或配对偏好方法（如直接偏好优化DPO）相比，DRAGON更加灵活。它既可以优化评估单个示例的奖励函数，也可以优化评估示例分布的奖励函数，这使得它与各种实例到实例、实例到分布以及分布到分布的奖励兼容。利用这种多功能性，我们通过选择编码器和一组参考示例来创建示例分布，从而构建了新颖的奖励函数。当使用CLAP等跨模态编码器时，参考示例可以是不同模态的（例如，文本与音频）。然后，DRAGON收集在线和策略内生成内容，对其进行评分以构建一个正面示范集和一个负面示范集，并利用两组之间的对比来最大化奖励。为了进行评估，我们使用20种不同的奖励函数微调了一个音频领域的文本到音乐扩散模型，其中包括一个自定义音乐美学模型、CLAP分数、Vendi多样性和Frechet音频距离（FAD）。我们还比较了实例级（每首歌曲）和全数据集FAD设置，同时消除了多个FAD编码器和参考集的影响。在所有20个目标奖励中，DRAGON实现了81.45%的平均胜率。此外，基于示例集的奖励函数确实增强了生成效果，并且与基于模型的奖励效果相当。通过适当的示例集，DRAGON在没有人类偏好标注训练的情况下，实现了60.95%的人类投票音乐质量胜率。因此，DRAGON展示了一种设计和优化奖励函数以提高人类感知质量的新方法。声音示例可在https://ml-dragon.github.io/web查阅。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [55] [Metadata Enrichment of Long Text Documents using Large Language Models](https://arxiv.org/abs/2506.20918)
> *使用大型语言模型对长文本文件进行元数据丰富*

*Manika Lamba, You Peng, Sophie Nikolov, Glen Layne-Worthey, J. Stephen Downie* | **Category: cs.DL, cs.ET, cs.IR**

**Keywords:** 元数据丰富, 大型语言模型, 数字图书馆, HathiTrust, 长文本文档

**Comment:** 

> **TL;DR:** 本文结合人工和大型语言模型，对HathiTrust数字图书馆的长文本文档元数据进行了语义丰富和增强，提高了数字存储库的搜索结果和可访问性。

**AI_Comments:** 该论文通过结合人工和大型语言模型，为数字图书馆的元数据丰富提供了一个实用的解决方案，尤其突出了LLM在处理现有数据缺失问题上的潜力。其创新性在于将LLM应用于特定领域的元数据增强，为数字人文和信息科学研究提供了新的工具和数据集。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提高HathiTrust数字图书馆中长文本文档（论文和学位论文）的元数据质量，以适应各种内容类型，并解决现有元数据字段中大量缺失数据的问题，从而促进计算社会科学、数字人文和信息科学等领域的研究。

**Method:** 通过结合人工努力和大型语言模型，对从HathiTrust数字图书馆检索到的1920年至2020年间出版的英文长文本文档、论文和学位论文的元数据进行语义丰富和增强。

**Result:** 该方法为数字存储库引入了额外的元数据访问点，增强了搜索结果，并提高了数字存储库的可访问性。所创建的数据集为计算社会科学、数字人文和信息科学等领域的研究提供了宝贵资源。

**Conclusion:** 使用大型语言模型丰富元数据对数字存储库特别有益，尤其是在现有元数据缺失严重的情况下，能够显著提高搜索效率和可访问性。

> **ai_Abstract:** 本文介绍了通过结合人工和大型语言模型，对HathiTrust数字图书馆中1920-2020年间的英文长文本文档（包括论文和学位论文）元数据进行语义丰富和增强的项目。研究表明，使用大型语言模型丰富元数据对数字存储库非常有益，尤其是在元数据缺失严重的情况下，能够增加访问点、提高搜索结果和可访问性。所创建的数据集对计算社会科学、数字人文和信息科学等领域的研究具有重要价值。

> **摘要翻译:** 在这个项目中，我们结合人工努力和大型语言模型，对从HathiTrust数字图书馆检索到的1920年至2020年间出版的英文长文本文档、论文和学位论文的元数据进行了语义丰富和增强。这个数据集为计算社会科学、数字人文和信息科学等领域的研究提供了宝贵的资源。我们的论文表明，使用大型语言模型丰富元数据对于数字存储库特别有益，它引入了最初可能未预见到的额外元数据访问点，以适应各种内容类型。这种方法对于现有元数据字段中存在大量缺失数据的存储库尤其有效，能够增强搜索结果并提高数字存储库的可访问性。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

### [450] [Automatic Reviewers Assignment to a Research Paper Based on Allied References and Publications Weight](https://arxiv.org/abs/2506.21331)
> *基于相关参考文献和出版物权重的研究论文自动审稿人分配*

*Tamim Al Mahmud, B M Mainul Hossain, Dilshad Ara* | **Category: cs.DL, cs.CV**

**Keywords:** 审稿人分配, 同行评审, H指数, i10指数, 文献计量学

**Comment:** IEEE Conference Proceedings (5 Pages)

> **TL;DR:** 该研究提出了一种基于参考文献、作者指标（h指数、i10指数、引用次数）和排除合著者来自动为研究论文分配最佳审稿人的系统。

**AI_Comments:** 该论文提出了一种创新的自动化审稿人分配方法，鉴于研究的指数级增长，这一点至关重要。其新颖之处在于结合了参考文献分析和网络抓取，以获取作者指标（h指数、i10指数、引用次数），并排除了利益冲突（合著者）。这种方法有望显著提高同行评审的效率和质量。然而，摘要中未提及所提出系统的任何评估或性能指标，这对于评估其有效性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 由于研究论文数量的急剧增加和新研究领域的不断涌现，高效地为研究论文选择合适的专家审稿人成为一项重大挑战，当前的同行评审过程可能无法总是选出最合适的审稿人。

**Method:** 该方法首先收集研究论文的参考文献，识别参考文献中至少有一篇论文的作者。然后，自动从网络提取研究主题关键词，并搜索特定主题的顶尖研究人员，统计他们的h指数、i10指数和引用次数。接着，根据得分对前n位作者进行排名，并自动浏览其主页以获取电子邮件地址。同时，系统还会检查并剔除合著者和同事，最终推荐剩余的顶尖作者作为最佳审稿人。

**Result:** Not mentioned in abstract

**Conclusion:** 本研究提出的策略通过利用作者的出版历史和指标，旨在识别并分配最适合研究论文的审稿人。

> **ai_Abstract:** 本研究旨在解决因研究量激增和专业领域细化而导致的论文审稿人高效分配难题。论文提出了一种自动化系统，通过分析论文参考文献、提取研究主题关键词，并基于h指数、i10指数和引用次数对顶尖研究人员进行排名来识别潜在审稿人。该系统还过滤掉合著者以确保评审独立性，旨在选出最合适的专家。

> **摘要翻译:** 每天，大量的研究文档被提交给会议、文集、期刊、通讯、年度报告、日报和各种期刊。许多此类出版物使用独立的外部专家来评审提交的稿件。这个过程被称为同行评审，审稿人被称为评审员。然而，并非总能为评审选择最佳评审员。此外，每个领域都在涌现新的研究领域，研究论文的数量急剧增加。为了评审所有这些论文，每本期刊都会分配一个小型评审团队，他们可能并非所有领域的专家。例如，一篇通信技术的研究论文应该由同一领域的专家评审。因此，高效地为研究论文选择最佳审稿人或评审员是一个巨大的挑战。
在这项研究中，我们提出并实现了一个程序，该程序使用一种新策略来自动选择研究论文的最佳审稿人。每篇研究论文的末尾都包含参考文献，通常来自同一领域。首先，我们收集参考文献并统计在参考文献中至少有一篇论文的作者。然后，我们自动浏览网页以提取研究主题关键词。接下来，我们搜索特定主题的顶尖研究人员，并统计前n位作者的h指数、i10指数和引用次数。之后，我们根据得分对前n位作者进行排名，并自动浏览他们的主页以检索电子邮件地址。我们还会在线检查他们的合著者和同事，并将其从列表中剔除。剩下的前n位作者（通常是教授）很可能是评审该研究论文的最佳评审员。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [60] [Rational Miner Behaviour, Protocol Stability, and Time Preference: An Austrian and Game-Theoretic Analysis of Bitcoin's Incentive Environment](https://arxiv.org/abs/2506.20965)
> *矿工理性行为、协议稳定性与时间偏好：比特币激励环境的奥地利学派与博弈论分析*

*Craig Steven Wright* | **Category: econ.GN, cs.CR, cs.GT, cs.NI, q-fin.EC, q-fin.GN, 91B42, 91A25, 91B50, K.4.4; J.4; C.2.4**

**Keywords:** 矿工行为, 协议稳定性, 时间偏好, 奥地利学派, 博弈论

**Comment:** Approximately 10,770 words, 0 figure, 0 table. Submitted to The
  Quarterly Journal of Austrian Economics

> **TL;DR:** 该论文结合奥地利资本理论和重复博弈论，分析了区块链系统中矿工的策略行为，指出可变协议会提高时间偏好，导致矿工转向寻租，而协议的不可变性对于维护网络稳定至关重要。

**AI_Comments:** 该论文通过将奥地利经济学（时间偏好、资本理论）与博弈论相结合，为分析区块链矿工行为提供了一种新颖的跨学科方法。其强调协议不可变性作为关键制度锚点的观点，为去中心化系统的基本设计原则提供了强有力的理论论证，将经济理论与实际的区块链治理联系起来，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在结合奥地利资本理论与重复博弈论，探讨区块链系统中矿工的策略行为，并分析协议规则可变性对长期规划、合作均衡以及矿工激励的影响。

**Method:** 本文整合了奥地利资本理论与重复博弈论，并运用形式化的博弈论分析和奥地利经济学原理来论证其观点。

**Result:** 研究表明，当协议规则可变时，有效时间偏好会上升，从而破坏理性的长期规划和合作均衡。此外，可变协议会将矿工的激励从生产性投资转向政治寻租和影响力博弈。原始比特币协议被视为一个固定规则集，能够实现可计算性和低时间偏好。

**Conclusion:** 协议的不可变性对于恢复战略一致性、创业信心和可持续网络均衡至关重要。

> **ai_Abstract:** 该论文结合奥地利资本理论和重复博弈论，分析了区块链系统中矿工的策略行为。研究发现，可变的协议规则会提高矿工的有效时间偏好，导致长期规划受损和合作均衡被破坏，并将矿工激励从生产性投资转向寻租。论文强调，比特币原始协议的固定规则集是稳定性的关键。最终得出结论，协议的不可变性对于维护区块链网络的战略一致性、创业信心和可持续均衡至关重要。

> **摘要翻译:** 本文将奥地利资本理论与重复博弈论相结合，考察了区块链系统在不同制度条件下的矿工策略行为。研究表明，当协议规则可变时，有效时间偏好上升，从而破坏了理性的长期规划和合作均衡。通过形式化的博弈论分析和奥地利经济学原理，本文论证了可变协议如何将矿工的激励从生产性投资转向政治寻租和影响力博弈。原始比特币协议被解释为一个制度锚点：一个固定的规则集，能够实现可计算性和低时间偏好。借鉴庞巴维克、米塞斯和哈耶克的研究成果，本文提出协议的不可变性对于恢复战略一致性、创业信心和可持续网络均衡至关重要。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

### [105] [Institutional Noise, Strategic Deviation, and Intertemporal Collapse: A Formal Model of Miner Behaviour under Protocol Uncertainty](https://arxiv.org/abs/2506.20992)
> *制度性噪音、策略性偏差与跨期崩溃：协议不确定性下矿工行为的正式模型*

*Craig Steven Wright* | **Category: econ.GN, cs.CE, cs.CY, cs.GT, cs.SI, q-fin.EC, 91A05, 91B42, 68M14, 91B62, J.4; C.2.4; K.4.1; F.1.1**

**Keywords:** 区块链, 协议不确定性, 矿工行为, 博弈论, 合作瓦解

**Comment:** 40 pages, submitted to QJAE

> **TL;DR:** 本文通过一个正式的博弈论模型，研究了区块链协议的不确定性如何破坏合作挖矿行为，发现即使是轻微的规则不确定性也会导致矿工的短期行为和合作关系的瓦解。

**AI_Comments:** 本文创新性地将博弈论应用于区块链协议的稳定性分析，强调了制度规则稳定性对去中心化系统长期合作的重要性。其结论对区块链协议的设计和治理提供了重要的理论指导，具有较强的现实意义。然而，模型可能未能完全捕捉现实世界中矿工行为的复杂性，且其奥地利经济学解释的适用性可能需要更广泛的讨论。

<details>
  <summary>Details</summary>

**Motivation:** 研究协议可变性如何扰乱区块链系统中的合作挖矿行为，并探讨其对矿工行为和系统稳定性的影响。

**Method:** 开发了一个正式的博弈论模型，并采用具有随机规则冲击的重复博弈框架进行分析和模拟。

**Result:** 即使是制度规则上的微小不确定性也会增加时间偏好并诱导策略性偏差。固定规则环境支持长期投资和稳定的均衡策略，而可变协议则导致短期主义、更高的贴现和协调参与的崩溃。模拟结果识别出参数空间中的不稳定区域，其中理性挖矿让位于掠夺性或套利行为。

**Conclusion:** 如果要在去中心化系统中实现可持续合作，协议设计必须被视为一种宪法经济约束，而不是一个可自由裁量的变量，因为可计算性需要规则稳定性且制度性噪音会破坏生产性行动的信息基础。

> **ai_Abstract:** 本文构建了一个正式的博弈论模型，以探讨区块链协议的不确定性如何影响矿工的合作行为。研究发现，协议规则的不确定性，即使是轻微的，也会导致矿工产生短期偏好和策略性偏差，进而破坏长期投资和合作稳定性。通过模拟，论文识别了理性挖矿行为转向掠夺或套利行为的不稳定区域。最终，论文强调协议设计应被视为去中心化系统实现可持续合作的宪法经济约束。

> **摘要翻译:** 本文开发了一个正式的博弈论模型，以研究协议可变性如何破坏区块链系统中的合作挖矿行为。通过使用一个具有随机规则冲击的重复博弈框架，我们表明，即使是制度规则上的微小不确定性也会增加时间偏好并诱导策略性偏差。固定规则环境支持长期投资和稳定的均衡策略；相反，可变协议导致短期主义、更高的贴现和协调参与的崩溃。模拟结果识别出参数空间中的不稳定区域，其中理性挖矿让位于掠夺性或套利行为。这些发现支持奥地利经济学的解释：可计算性需要规则稳定性。制度性噪音破坏了生产性行动的信息基础。我们得出结论，如果要在去中心化系统中实现可持续合作，协议设计必须被视为一种宪法经济约束，而不是一个可自由裁量的变量。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='q-finpm'></a>
## q-fin.PM 

### [80] [From On-chain to Macro: Assessing the Importance of Data Source Diversity in Cryptocurrency Market Forecasting](https://arxiv.org/abs/2506.21246)
> *从链上到宏观：评估数据源多样性在加密货币市场预测中的重要性*

*Giorgos Demosthenous, Chryssis Georgiou, Eliada Polydorou* | **Category: q-fin.PM, cs.AI, cs.ET, cs.LG, q-fin.ST**

**Keywords:** 加密货币预测, 数据源多样性, 链上指标, 宏观经济指标, 特征降维

**Comment:** 

> **TL;DR:** 本研究探讨了数据源多样性如何显著提升加密货币市场预测模型的性能，发现链上指标至关重要，传统市场和宏观指标对长期预测日益相关。

**AI_Comments:** 这篇论文的创新点在于系统地评估了不同类型数据源（特别是链上和宏观数据）对加密货币预测的综合影响，并提出了Crypto100指数和特征降维算法。其重要性在于为开发更全面、更准确的加密货币预测模型提供了实证依据和方法论。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过整合多种数据类别，探究数据源多样性对加密货币预测模型性能的影响，并揭示加密货币市场短期和长期驱动因素。

**Method:** 整合了技术指标、链上指标、情绪和兴趣指标、传统市场指数以及宏观经济指标等多种数据类别。引入了Crypto100指数，并提出了一种新的特征降维算法来识别最具影响力且稳健的特征。

**Result:** 数据源多样性显著提升了不同时间跨度下预测模型的性能。链上指标对短期和长期预测都至关重要。传统市场指数和宏观经济指标对长期预测的相关性日益增长。利用多样化数据源可显著提高模型准确性。

**Conclusion:** 数据源多样性对于构建更准确、更具韧性的加密货币市场预测模型至关重要，并且有助于理解市场驱动因素。

> **ai_Abstract:** 本研究探讨了数据源多样性对加密货币市场预测模型性能的重要性。通过整合链上数据、宏观经济指标等多种数据，并引入Crypto100指数及新型特征降维算法，实验证明数据源多样性显著提升了预测准确性。研究强调了链上指标的关键作用以及传统市场和宏观指标对长期预测日益增长的相关性，为构建更稳健的预测模型提供了基础。

> **摘要翻译:** 本研究通过整合多种数据类别，包括技术指标、链上指标、情绪和兴趣指标、传统市场指数以及宏观经济指标，调查了数据源多样性对加密货币预测模型性能的影响。我们引入了代表市值前100种加密货币的Crypto100指数，并提出了一种新颖的特征降维算法，以从多样化的数据源中识别出最具影响力且稳健的特征。我们的综合实验表明，数据源多样性显著提升了不同时间跨度下预测模型的预测性能。主要发现包括：链上指标对短期和长期预测都至关重要；传统市场指数和宏观经济指标对长期预测的相关性日益增长；以及利用多样化数据源可显著提高模型准确性。这些见解有助于揭示加密货币市场的短期和长期驱动因素，并为开发更准确、更具韧性的预测模型奠定了基础。

</details>

[⬆️ 返回分类顶部](#q-finpm) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [104] [ResQ: A Novel Framework to Implement Residual Neural Networks on Analog Rydberg Atom Quantum Computers](https://arxiv.org/abs/2506.21537)
> *ResQ：一种在模拟里德堡原子量子计算机上实现残差神经网络的新颖框架*

*Nicholas S. DiBrita, Jason Han, Tirthak Patel* | **Category: quant-ph, cs.CV, cs.ET**

**Keywords:** 量子机器学习, 残差神经网络, 里德堡原子量子计算机, 神经常微分方程, ResQ

**Comment:** ResQ will appear in the Proceedings of the IEEE International
  Conference on Computer Vision (ICCV), 2025

> **TL;DR:** ResQ是一个新框架，用于在模拟里德堡原子量子计算机上实现基于神经ODE的残差神经网络，以解决机器学习分类问题。

**AI_Comments:** 这篇论文的创新点在于将神经ODE 기반的残差神经网络与模拟里德堡原子量子计算机结合，并提出了一个名为ResQ的新颖框架。它探索了一个量子机器学习中尚未被充分研究的领域，并为在特定量子硬件上实现这类网络提供了潜在的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 量子机器学习正在快速发展，但基于神经ODE的残差神经网络（ResNets）在量子计算领域的探索尚不足。本研究旨在填补这一空白，并探讨模拟里德堡原子量子计算机为何特别适用于ResNets。

**Method:** 本文提出了ResQ框架，该框架利用模拟量子神经ODE优化里德堡原子量子计算机的动力学，以解决机器学习中的分类问题。

**Result:** ResQ框架旨在利用模拟里德堡原子量子计算机解决机器学习中的分类问题。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了ResQ，一个新颖的框架，旨在利用模拟里德堡原子量子计算机实现基于神经常微分方程（neural ODE）的残差神经网络（ResNets）。该研究探讨了模拟里德堡原子量子计算机适用于ResNets的原因，并提出了ResQ框架，通过优化量子计算机的动力学来解决机器学习中的分类问题。

> **摘要翻译:** 量子机器学习研究最近因量子计算加速机器学习的潜力而迅速发展。机器学习中一个尚未被探索的领域是基于神经常微分方程（neural ODE）的残差神经网络（ResNets），它旨在利用常微分方程的原理提高神经网络的有效性。在这项工作中，我们提出了关于模拟里德堡原子量子计算机为何特别适合ResNets的见解。我们还介绍了ResQ，这是一个新颖的框架，用于优化里德堡原子量子计算机的动力学，以使用模拟量子神经ODE解决机器学习中的分类问题。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [285] [Quantum Adaptive Search: A Hybrid Quantum-Classical Algorithm for Global Optimization of Multivariate Functions](https://arxiv.org/abs/2506.21124)
> *量子自适应搜索：一种用于多元函数全局优化的混合量子-经典算法*

*G. Intoccia, U. Chirico, V. Schiano Di Cola, G. Pepe, S. Cuomo* | **Category: quant-ph, cs.NA, math.NA, math.OC**

**Keywords:** 量子优化, 全局优化, 混合算法, 量子自适应搜索, 多元函数

**Comment:** 

> **TL;DR:** QAGS是一种混合量子-经典算法，通过自适应缩小搜索空间和局部经典优化来高效地全局优化多元函数。

**AI_Comments:** QAGS的创新之处在于结合了量子计算的潜力（通过量子态编码和量子估计概率分布）与经典优化器的局部搜索能力。这种混合方法有望克服纯经典方法在处理高维复杂优化问题时的局限性，特别是在全局收敛性和计算效率方面。其自适应缩小搜索空间机制是提高效率的关键。

<details>
  <summary>Details</summary>

**Motivation:** 解决多元函数的全局优化问题，并提高优化效率和准确性。

**Method:** QAGS采用自适应机制，根据目标函数的量子估计概率分布动态缩小搜索空间。量子态通过复振幅映射编码解的质量信息，以识别最有前景的区域并逐步收紧搜索边界。随后，经典优化器对解进行局部细化。

**Result:** 数值结果表明，与经典方法相比，QAGS在基准函数上实现了更高的精度，并在时间和空间复杂度方面具有优势。

**Conclusion:** QAGS确保搜索空间向全局最优收缩，计算复杂度可控，且在精度、时间和空间复杂度方面均优于经典方法。

> **ai_Abstract:** 本文提出了一种名为量子自适应搜索（QAGS）的混合量子-经典算法，用于多元函数的全局优化。该算法通过量子估计的概率分布自适应地缩小搜索空间，并利用量子态编码解的质量信息来识别有前景的区域，随后由经典优化器进行局部精修。QAGS被证明能有效收敛至全局最优，且具有受控的计算复杂度，并在数值实验中展现出比传统方法更高的精度以及时间和空间复杂度优势。

> **摘要翻译:** 这篇工作提出了量子自适应搜索（QAGS），一种用于多元函数全局优化的混合量子-经典算法。该方法采用一种自适应机制，根据目标函数的量子估计概率分布动态缩小搜索空间。量子态通过适当的复振幅映射编码解的质量信息，从而能够识别最有前景的区域，并因此逐步收紧搜索边界；然后，经典优化器对解进行局部细化。分析表明，QAGS确保搜索空间向全局最优收缩，且计算复杂度可控。在基准函数上的数值结果显示，与经典方法相比，QAGS实现了更高的精度，同时在时间和空间复杂度方面具有优势。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [432] [Quantum Reinforcement Learning Trading Agent for Sector Rotation in the Taiwan Stock Market](https://arxiv.org/abs/2506.20930)
> *量子强化学习交易代理在台湾股市板块轮动中的应用*

*Chi-Sheng Chen, Xinyu Zhang, Ya-Chuan Chen* | **Category: quant-ph, cs.LG, q-fin.CP**

**Keywords:** 量子强化学习, 板块轮动, 台湾股市, 代理奖励, 金融科技

**Comment:** 

> **TL;DR:** 该研究提出了一种混合量子-经典强化学习框架用于台湾股市板块轮动，发现量子增强模型在训练奖励上表现更好，但在实际投资指标（如累积回报和夏普比率）上不如经典模型，这揭示了强化学习在金融领域应用中代理奖励与真实投资目标不匹配的核心挑战。

**AI_Comments:** 该论文创新性地将量子强化学习应用于金融板块轮动，并提供了实证基准。其重要贡献在于揭示了量子增强模型在训练奖励与实际投资表现之间存在的“奖励-性能差距”，指出了当前强化学习在金融领域应用中，奖励设计可能导致过拟合短期波动而非优化风险调整回报的核心局限性。论文还讨论了NISQ环境下量子电路的挑战，并提出了未来改进方向，对该领域的研究具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决在台湾股市中进行板块轮动的问题，并探索混合量子-经典强化学习框架的应用潜力。同时，也旨在揭示强化学习在金融领域应用中面临的挑战，特别是代理奖励与真实投资目标之间的不匹配问题。

**Method:** 提出一个混合量子-经典强化学习框架，以PPO为核心算法，并结合经典架构（LSTM, Transformer）和量子增强模型（QNN, QRWKV, QASA）作为策略和价值网络。通过自动化特征工程提取金融指标。

**Result:** 经验回测显示，量子增强模型在训练奖励上持续获得更高分数，但在累积回报和夏普比率等实际投资指标上表现不如经典模型。这种差异表明代理奖励信号与真实投资目标之间存在不匹配。

**Conclusion:** 强化学习在金融领域应用中，当前奖励设计可能导致模型过拟合短期波动而非优化风险调整回报。NISQ约束下的量子电路固有的表达能力和优化不稳定性加剧了这一问题。研究强调了奖励-性能差距，并提出了未来改进方向，包括奖励塑造、模型正则化和基于验证的提前停止。

> **ai_Abstract:** 本研究提出了一个用于台湾股市板块轮动的混合量子-经典强化学习框架。该框架以PPO为基础，结合了经典（LSTM, Transformer）和量子增强（QNN, QRWKV, QASA）模型。回测结果显示，量子模型虽然训练奖励高，但在实际投资表现上逊于经典模型，揭示了金融RL中代理奖励与真实目标不匹配的问题。论文讨论了这种奖励-性能差距的含义，并提出了解决策略。

> **摘要翻译:** 我们提出了一种用于台湾股票市场板块轮动的混合量子-经典强化学习框架。我们的系统采用近端策略优化（PPO）作为核心算法，并集成了经典架构（LSTM、Transformer）和量子增强模型（QNN、QRWKV、QASA）作为策略和价值网络。一个自动化特征工程流程从资本份额数据中提取金融指标，以确保所有配置的模型输入一致。经验回测揭示了一个关键发现：尽管量子增强模型持续获得更高的训练奖励，但在累积回报和夏普比率等实际投资指标上，它们的表现不如经典模型。这种差异突出了将强化学习应用于金融领域的一个核心挑战——即代理奖励信号与真实投资目标之间的不匹配。我们的分析表明，当前的奖励设计可能激励模型过拟合短期波动，而不是优化风险调整后的回报。在噪声中等规模量子（NISQ）约束下，量子电路固有的表达能力和优化不稳定性加剧了这个问题。我们讨论了这种奖励-性能差距的影响，并提出了未来改进的方向，包括奖励塑造、模型正则化和基于验证的提前停止。我们的工作提供了一个可重现的基准，并为在实际金融中部署量子强化学习的实际挑战提供了关键见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matsoft'></a>
## cond-mat.soft 

### [111] [Pull-off strength of mushroom-shaped fibrils adhered to rigid substrates](https://arxiv.org/abs/2506.20745)
> *蘑菇状纤维粘附到刚性基底的脱离强度*

*C. Betegón, C. Rodríguez, E. Martínez-Pañeda, R. M. McMeeking* | **Category: cond-mat.soft, cond-mat.mtrl-sci, cs.CE, physics.app-ph, physics.bio-ph**

**Keywords:** 蘑菇状纤维, 脱离强度, 计算模型, 粘附, 仿生材料

**Comment:** 

> **TL;DR:** 本研究利用计算方法分析了蘑菇状纤维粘附到刚性基底时的脱离行为，发现分离过程在载荷控制下不稳定，宽而薄的蘑菇状帽可以增强粘附力，且粘附缺陷会显著降低脱离强度。

**AI_Comments:** 该研究通过计算方法深入探讨了蘑菇状纤维的脱离机制，创新性地揭示了分离过程的不稳定性以及帽形结构对粘附性能的影响。对于仿生粘合剂的设计和优化具有重要的指导意义，特别是其对缺陷敏感性的分析，为实际应用提供了宝贵的参考。

<details>
  <summary>Details</summary>

**Motivation:** 壁虎等生物纤维结构卓越的粘附特性启发了合成粘附表面的开发。其中，蘑菇状纤维相比其他几何形状表现出更优异的脱离强度，因此本研究旨在深入理解其脱离行为。

**Method:** 本研究采用基于Dugdale内聚力区模型的计算方法，分析了蘑菇状纤维粘附到刚性基底时的脱离行为。

**Result:** 研究结果提供了完整的脱离曲线，揭示了分离过程在载荷控制下本质上是不稳定的，无论脱离是从纤维边缘还是中心开始。研究发现，具有宽而薄的蘑菇状帽的纤维能有效减少应力集中并促进中心脱离，从而增强粘附力。然而，并非所有几何形状都观察到中心脱离，而在某些条件下所有情况下都可能发生边缘脱离。此外，粘附缺陷会显著降低脱离强度，尤其是在无量纲参数\c{hi}值较高时。

**Conclusion:** 这些研究结果有助于优化仿生粘合剂和微结构表面，以应用于各种工程领域。

> **ai_Abstract:** 本研究利用基于Dugdale内聚力区模型的计算方法，深入分析了蘑菇状纤维粘附到刚性基底时的脱离行为。研究发现，分离过程在载荷控制下本质上不稳定。具有宽而薄的蘑菇状帽的纤维能有效减少应力集中，促进中心脱离，从而增强粘附力。然而，中心脱离并非在所有几何形状中都出现，而边缘脱离在特定条件下总是可能发生。此外，纤维中心的粘附缺陷会显著降低脱离强度。这些发现为优化仿生粘合剂和微结构表面提供了重要见解。

> **摘要翻译:** 生物纤维结构（如壁虎的纤维结构）卓越的粘附特性启发了合成粘附表面的开发。其中，蘑菇状纤维相比其他几何形状表现出更优异的脱离强度。在本研究中，我们采用基于Dugdale内聚力区模型的计算方法，分析了这些纤维粘附到刚性基底时的脱离行为。结果提供了完整的脱离曲线，揭示了分离过程在载荷控制下本质上是不稳定的，无论脱离是从纤维边缘还是中心开始。我们的研究发现，具有宽而薄的蘑菇状帽的纤维能有效减少应力集中并促进中心脱离，从而增强粘附力。然而，并非所有几何形状都观察到中心脱离，而在某些条件下所有情况下都可能发生边缘脱离。此外，我们研究了纤维中心粘附缺陷的影响，结果表明它们会显著降低脱离强度，尤其是在无量纲参数\c{hi}值较高时。这些见解有助于优化仿生粘合剂和微结构表面，以应用于各种工程领域。

</details>

[⬆️ 返回分类顶部](#cond-matsoft) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [126] [Evolution and determinants of firm-level systemic risk in local production networks](https://arxiv.org/abs/2506.21426)
> *地方生产网络中企业层面系统性风险的演变与决定因素*

*Anna Mancini, Balázs Lengyel, Riccardo Di Clemente, Giulio Cimini* | **Category: physics.soc-ph, cs.SI, econ.GN, physics.data-an, q-fin.EC, q-fin.RM**

**Keywords:** 系统性风险, 生产网络, 企业适应性, 供应链韧性, COVID-19

**Comment:** 15 pages, 4 figures

> **TL;DR:** 研究了匈牙利生产网络中企业层面系统性风险的动态和决定因素，发现疫情期间企业适应性行为降低了系统性风险，并指出国际贸易量是重要预测因素。

**AI_Comments:** 这篇论文通过引入企业适应性行为来研究生产网络中的系统性风险，填补了现有研究中对企业自适应能力忽视的空白，提高了对经济韧性的理解。其使用匈牙利生产网络的实证数据，并结合最大熵零模型进行对比分析，验证了企业在危机中的动态响应对系统性风险的积极影响，具有重要的政策启示意义。

<details>
  <summary>Details</summary>

**Motivation:** 近期危机（如COVID-19大流行和地缘政治紧张）暴露了供应链脆弱性并导致经济不稳定，促使人们评估系统性风险。然而，企业通过重组供应链接来应对危机的能力被忽视，这限制了对生产网络韧性的理解。

**Method:** 研究了2015年至2022年匈牙利生产网络中企业层面系统性风险的动态和决定因素。使用启发式最大熵零模型作为基准，该模型通过保留每个企业在部门层面的总投入（需求）和产出（供应）来生成均衡生产网络集合。

**Result:** 1. 具有最高系统性风险的企业集合在COVID-19期间发生了结构性变化，促成经济交换的企业成为经济中的关键参与者，而零模型无法重现此结果。2. 在疫情爆发前，经验系统性风险与零模型值吻合良好，但之后显著减小，表明企业适应性行为使经济更具韧性。3. 企业的国际贸易量成为其系统性风险的重要预测因素。4. 国际联系无法明确解释观察到的趋势，因为进出口通过供需渠道对地方系统性风险产生相反影响。

**Conclusion:** 企业在危机中的适应性行为（如供应链重组）显著降低了系统性风险，增强了经济韧性。国际贸易量是系统性风险的预测因素，但其影响复杂且不明确。

> **ai_Abstract:** 本文研究了2015年至2022年匈牙利生产网络中企业层面系统性风险的演变和决定因素。研究发现，在COVID-19疫情期间，高系统性风险企业的结构发生了变化，且企业通过适应性行为（如重组供应链）显著降低了整体系统性风险，提升了经济韧性。此外，国际贸易量是系统性风险的重要预测因素，但进出口对系统性风险的影响是复杂且对立的。

> **摘要翻译:** 近期危机，如COVID-19大流行和地缘政治紧张，暴露了供应链的脆弱性并导致了中断，进而引发了产品短缺、成本增加和经济不稳定。这促使人们日益努力评估系统性风险，即企业中断对整个经济体的影响。然而，企业通过重组其供应链接来应对危机的能力在很大程度上被忽视，这限制了我们对生产网络韧性的理解。本文研究了2015年至2022年匈牙利生产网络中企业层面系统性风险的动态和决定因素。我们使用启发式最大熵零模型作为基准，该模型通过保留每个企业在部门层面的总投入（需求）和产出（供应）来生成一组处于均衡状态的生产网络。我们发现，在COVID-19期间，系统性风险最高的企业集合（一个相当稳定的群体）经历了结构性变化，因为那些促成经济交换的企业成为了经济中的关键参与者——这一结果并未被零模型重现。尽管在疫情爆发之前，经验系统性风险与零值吻合良好，但之后其显著减小，因为企业的适应性行为使得经济更具韧性。此外，企业的国际贸易量（作为中断的对象）成为其系统性风险的重要预测因素。然而，国际联系无法为观察到的趋势提供明确的解释，因为进出口通过供需渠道对地方系统性风险产生相反影响。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [165] [Linear codes arising from the point-hyperplane geometry-Part I: the Segre embedding](https://arxiv.org/abs/2506.21309)
> *点-超平面几何产生的线性码——第一部分：Segre嵌入*

*Ilaria Cardinali, Luca Giuzzi* | **Category: math.CO, cs.DM, cs.IT, math.IT, 51E22, 94B05, 14M12**

**Keywords:** 线性码, Segre嵌入, 点-超平面几何, 极小码, 权重列表

**Comment:** 29 pages

> **TL;DR:** 本文研究了由Segre嵌入中一个特定子簇产生的线性码，确定了其基本参数、权重列表和自同构群，并对其码字进行了几何刻画。

**AI_Comments:** 这篇论文在编码理论和代数几何的交叉领域做出了贡献，通过深入分析由Segre嵌入特定子簇产生的线性码，揭示了其重要的代数和几何性质。确定码的基本参数、权重列表和自同构群对于理解码的结构和性能至关重要，而几何刻画则提供了直观的理解。

<details>
  <summary>Details</summary>

**Motivation:** 研究由Segre几何中的特定子簇$\\Lambda_1$产生的线性码$\\mathcal{C}(\\Lambda_1)$的性质。

**Method:** 通过将$\\Lambda_1$视为射影系统，研究了由此产生的线性码$\\mathcal{C}(\\Lambda_1)$。具体方法包括确定其基本参数、完整的权重列表和线性自同构群，并对其最小、次低权重码字以及部分最大权重码字进行了几何刻画。

**Result:** 研究发现码$\\mathcal{C}(\\Lambda_1)$是极小码。文章确定了它的基本参数、完整的权重列表和线性自同构群。同时，对它的最小、次低权重码字以及部分最大权重码字给出了几何刻画。

**Conclusion:** 由Segre嵌入中特定子簇产生的线性码$\\mathcal{C}(\\Lambda_1)$是极小码，其各项基本参数、权重列表和自同构群已被确定，且其关键码字得到了几何刻画。

> **ai_Abstract:** 本文研究了由Segre几何中一个特定子簇$\\Lambda_1$（由满足$\\xi(x)=0$的纯张量$x\\otimes \\xi$构成）产生的线性码$\\mathcal{C}(\\Lambda_1)$。该研究确定了此极小码的基本参数、完整的权重列表和线性自同构群，并对其最小、次低以及部分最大权重码字进行了几何刻画。

> **摘要翻译:** 设$V$是有限域$\\mathbb{F}_q$上的向量空间，$\\Lambda$是Segre几何$\\mathrm{PG}(V)\\otimes\\mathrm{PG}(V^*)$在$\\mathrm{PG}(V\\otimes V^*)$中的像。考虑$\\Lambda$的子簇$\\Lambda_{1}$，它由纯张量$x\\otimes \\xi$表示，其中$x\\in V$和$\\xi\\in V^*$满足$\\xi(x)=0$。将$\\Lambda_1$视为$\\mathrm{PG}(V\\otimes V^*)$的一个射影系统，我们研究由此产生的线性码$\\mathcal{C}(\\Lambda_1)$。码$\\mathcal{C}(\\Lambda_1)$是极小码，我们确定了它的基本参数、完整的权重列表和线性自同构群。我们还对其最小和次低权重码字以及部分最大权重码字进行了几何刻画。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='mathds'></a>
## math.DS 

### [185] [Structural System Identification via Validation and Adaptation](https://arxiv.org/abs/2506.20799)
> *结构系统识别通过验证和适应*

*Cristian López, Keegan J. Moore* | **Category: math.DS, cs.LG, cs.SY, eess.SY**

**Keywords:** 结构系统识别, 不确定性量化, 神经网络, 生成模型, 模型验证

**Comment:** 

> **TL;DR:** 本文提出一种新的基于生成建模框架的结构系统识别方法，通过神经网络从数据中直接进行参数估计、不确定性量化和模型验证，并使用独立的验证数据集和判别器网络进行同步验证。

**AI_Comments:** 该研究创新性地将生成对抗网络（GAN）的思想引入结构系统识别领域，通过生成器和判别器的协同作用，实现了参数估计与模型验证的同步进行，提升了数据驱动型系统识别的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 整合实验数据与科学理论以理解、验证和预测复杂系统的动力学时，估计控制方程参数值至关重要。

**Method:** 提出一种新的结构系统识别（SI）、不确定性量化和验证方法。该方法受生成建模框架启发，使用神经网络将随机噪声映射到物理有意义的参数。这些参数用于已知的运动方程以生成“假”加速度，并与真实训练数据通过均方误差损失进行比较。为同时验证学习到的参数，使用独立的验证数据集，这些数据集生成的加速度由判别器网络评估，判别器判断输出是真实还是虚假，并指导参数生成器网络。

**Result:** 分析和真实实验表明了不同非线性结构系统的参数估计准确性和模型验证能力。

**Conclusion:** 该方法能够准确估计参数并有效验证模型，为结构系统识别提供了一个有前景的途径。

> **ai_Abstract:** 本文提出一种新的基于生成建模框架的结构系统识别方法，该方法通过神经网络将噪声转换为物理参数，并利用已知的运动方程生成加速度。通过均方误差与真实数据比较进行训练，并结合独立的验证数据集和判别器网络进行参数验证，实现了从数据中直接进行参数估计、不确定性量化和模型验证。实验证明了其在非线性结构系统中的准确性和有效性。

> **摘要翻译:** 估计控制方程参数值对于整合实验数据与科学理论以理解、验证和预测复杂系统的动力学至关重要。在这项工作中，我们提出了一种新的结构系统识别（SI）、不确定性量化和直接从数据中进行验证的方法。受生成建模框架的启发，神经网络将随机噪声映射到具有物理意义的参数。然后，这些参数用于已知的运动方程以获得“假”加速度，通过均方误差损失将其与真实训练数据进行比较。为了同时验证学习到的参数，我们使用独立的验证数据集。来自这些数据集生成的加速度由判别器网络评估，该网络确定输出是真实还是虚假，并指导参数生成器网络。分析和真实实验表明了不同非线性结构系统的参数估计准确性和模型验证能力。

</details>

[⬆️ 返回分类顶部](#mathds) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [202] [IMC-PINN-FE: A Physics-Informed Neural Network for Patient-Specific Left Ventricular Finite Element Modeling with Image Motion Consistency and Biomechanical Parameter Estimation](https://arxiv.org/abs/2506.20696)
> *IMC-PINN-FE：一种用于患者特异性左心室有限元建模的物理信息神经网络，具有图像运动一致性和生物力学参数估计功能*

*Siyu Mu, Wei Xuan Chan, Choon Hwai Yap* | **Category: physics.med-ph, cs.AI, eess.IV**

**Keywords:** 物理信息神经网络, 有限元建模, 左心室生物力学, 图像运动一致性, 患者特异性

**Comment:** 

> **TL;DR:** IMC-PINN-FE是一种新的PINN框架，结合图像运动一致性和有限元建模，可快速、准确地对患者特异性左心室生物力学进行建模和参数估计。

**AI_Comments:** IMC-PINN-FE的创新之处在于将图像运动一致性引入到物理信息神经网络中，以提高有限元模型的准确性和效率。它解决了传统FE方法计算成本高昂和运动匹配不足的痛点，通过快速参数估计和高效建模，实现了患者特异性心脏生物力学分析。其优势在于显著的计算加速（从数小时到数秒）和更高的运动保真度，同时减少了对大量训练数据的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 阐明心肌的生物力学行为对理解心脏生理至关重要，但临床成像无法直接推断，且传统的有限元方法计算成本高昂，且往往无法重现观察到的心脏运动。

**Method:** 本文提出IMC-PINN-FE，一个物理信息神经网络（PINN）框架，它将图像运动一致性（IMC）与有限元（FE）建模相结合，用于患者特异性左心室（LV）生物力学。首先，使用预训练的基于注意力网络或无监督循环正则化网络从MRI或超声心动图估计心脏运动，然后提取运动模式。IMC-PINN-FE通过拟合临床压力测量值，快速估计心肌刚度和主动张力，将计算时间从数小时缩短到数秒。基于这些参数，它以75倍的速度在心动周期内执行有限元建模。

**Result:** 相较于传统逆向有限元，计算速度从数小时缩短到数秒，FE建模速度提升75倍。通过运动约束，与图像位移匹配更准确，平均Dice系数从0.849提高到0.927，同时保持真实的压力-容积行为。通过单个受试者的运动重建形状模式，避免了对大型数据集的需求，并提高了患者特异性。

**Conclusion:** IMC-PINN-FE为快速、个性化和图像一致的心脏生物力学建模提供了一种稳健高效的方法。它通过引入材料属性的反向计算和更好的运动保真度，改进了以前的PINN-FE模型。

> **ai_Abstract:** 本文提出IMC-PINN-FE，一个结合物理信息神经网络、图像运动一致性和有限元建模的新框架，旨在解决传统有限元方法在患者特异性左心室生物力学建模中计算效率低和运动匹配不准确的问题。该方法通过从临床影像中估计心脏运动模式，并结合压力测量，快速估计心肌参数，显著加速计算并提高图像位移匹配精度（Dice系数从0.849提升至0.927）。IMC-PINN-FE无需大量数据集，增强了患者特异性，提供了一种高效、个性化且图像一致的心脏生物力学建模方案。

> **摘要翻译:** 阐明心肌的生物力学行为对于理解心脏生理至关重要，但无法直接从临床成像中推断，并且通常需要有限元（FE）模拟。然而，传统的有限元方法计算成本高昂，并且往往无法重现观察到的心脏运动。我们提出了IMC-PINN-FE，一个物理信息神经网络（PINN）框架，它将图像运动一致性（IMC）与有限元建模相结合，用于患者特异性左心室（LV）生物力学。心脏运动首先使用预训练的基于注意力网络或无监督循环正则化网络从MRI或超声心动图估计，然后提取运动模式。IMC-PINN-FE随后通过拟合临床压力测量值快速估计心肌刚度和主动张力，与传统逆向有限元相比，将计算时间从数小时缩短到数秒。基于这些参数，它以75倍的速度在心动周期内执行有限元建模。通过运动约束，它更准确地匹配图像位移，将平均Dice系数从0.849提高到0.927，同时保持真实的压力-容积行为。IMC-PINN-FE通过引入材料属性的反向计算和更好的运动保真度，改进了以前的PINN-FE模型。使用单个受试者的运动重建形状模式也避免了对大型数据集的需求，并提高了患者特异性。IMC-PINN-FE为快速、个性化和图像一致的心脏生物力学建模提供了一种稳健高效的方法。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [210] [Detecting weighted hidden cliques](https://arxiv.org/abs/2506.21543)
> *检测加权隐藏团*

*Urmisha Chatterjee, Karissa Huang, Ritabrata Karmakar, B. R. Vinay Kumar, Gábor Lugosi, Nandan Malhotra, Anirban Mandal, Maruf Alam Tarafdar* | **Category: math.ST, cs.IT, math.IT, math.PR, stat.TH, 62F03**

**Keywords:** 加权隐藏团, 假设检验, 谱测试, 统计极限, 图论

**Comment:** 

> **TL;DR:** 本文研究加权图中隐藏团的检测问题，将其建模为假设检验。在P和Q已知或部分已知的情况下，获得了可区分性的统计极限和最小风险界限，并提出了当隐藏团大小k达到$\Omega(\sqrt{n})$时计算高效的谱测试方法。

**AI_Comments:** 这篇论文将经典的隐藏团问题推广到更具挑战性的加权图设置，具有重要的理论和实际意义。通过引入假设检验框架，并区分P和Q已知与部分已知两种情况，使得研究更加全面。特别地，提出计算高效的谱测试方法并在k=$\Omega(\sqrt{n})$时实现区分，为解决这一复杂问题提供了实用的算法工具。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在将经典的隐藏团问题推广到具有实值边权的图，并将其形式化为一个假设检验问题。具体来说，目标是根据观察到的边权，判断它们是来自一个完全随机的图，还是存在一个由特定分布生成边权的隐藏子图（即隐藏团）。

**Method:** 研究采用假设检验框架。在零假设下，所有边权来自分布P；在备择假设下，k个顶点的边权来自分布Q，其余来自P。研究分两种场景进行：1) 分布P和Q完全已知；2) 分布P和Q只有部分信息。为了区分两种假设，论文提出了计算高效的谱测试方法。

**Result:** 在P和Q完全已知的情况下，论文获得了当两种假设可区分和不可区分时k的统计极限。当Q对P非绝对连续时，在两种场景下都给出了假设检验的最小风险界限。此外，在两种场景下，只要k达到$\Omega(\sqrt{n})$，所提出的计算高效的谱测试方法就能够区分两种假设。

**Conclusion:** 本研究成功地将经典的隐藏团问题推广到加权图，并通过严谨的假设检验框架，在不同信息完备度下，给出了区分加权隐藏团的统计界限和计算效率高的解决方案，特别是当隐藏团大小满足一定条件时。

> **ai_Abstract:** 本文研究了加权隐藏团的检测问题，将其形式化为一种假设检验。在零假设下，图的边权服从分布P；在备择假设下，存在一个由k个顶点组成的子图，其边权服从分布Q，其余边权服从P。研究涵盖了P和Q已知以及部分已知两种场景。结果包括了可区分性的统计极限、最小风险界限，并提出了在k达到$\Omega(\sqrt{n})$时计算高效的谱测试方法。

> **摘要翻译:** 我们研究了经典隐藏团问题在具有实值边权图上的推广。形式上，我们定义了一个假设检验问题。在零假设下，n个顶点的完全图的边权来自独立同分布P。在备择假设下，随机选择k个顶点，它们之间的边权来自分布Q，而其余边权从P中采样。目标是根据观察到的边权，判断它们是由哪种假设生成的。我们在两种不同的场景下研究了这个问题：(1) 当P和Q完全已知时，以及 (2) 当P和Q只有部分信息时。在第一种场景中，我们获得了当两种假设可区分和不可区分时k的统计极限。此外，在每种场景中，当Q对P非绝对连续时，我们给出了假设检验问题的最小风险界限。我们还提供了计算高效的谱测试方法，在两种场景下，只要k=$ \Omega(\sqrt{n})$，就能区分两种假设。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='physicsacc-ph'></a>
## physics.acc-ph 

### [214] [Estimation of superconducting cavity bandwidth and detuning using a Luenberger observer](https://arxiv.org/abs/2506.21207)
> *超导腔带宽和失谐的Luenberger观测器估计*

*Bozo Richter, Andrea Bellandi, Julien Branlard, Leon Speidel, Annika Eichler* | **Category: physics.acc-ph, cs.SY, eess.SY**

**Keywords:** 超导腔, 带宽估计, 失谐估计, Luenberger观测器, LLRF

**Comment:** 10 pages, 4 figures, to be published in APS Physical Review -
  Accelerator and Beams

> **TL;DR:** 本文提出使用Luenberger观测器估计超导腔带宽和失谐，该方法无需显式滤波即可在原始采样率下实现，且误差收敛可控。

**AI_Comments:** 这项工作通过引入Luenberger观测器为超导腔参数估计提供了一种新颖且高效的解决方案。其创新之处在于无需显式滤波即可在原生采样率下进行估计，并提供了直观的误差收敛控制，这对于需要低延迟和高精度的低电平射频（LLRF）系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 未来十年将出现多台连续波直线加速器，这些机器需要精确跟踪超导腔的带宽和失谐，以获取腔体超导状态信息并最小化运行功耗。现有参数估计方法在计算延迟方面存在局限。

**Method:** 本文提出了一种使用Luenberger观测器来计算超导腔带宽和失谐的方法。与现有方法不同，该状态观测器能在控制系统原始采样率下提供估计，无需显式滤波输入信号，并且可以通过调整增益参数直观地控制估计的误差收敛特性。

**Result:** 论文中展示了所推导观测器的实现考量和测试结果。

**Conclusion:** Luenberger观测器能够有效且高效地估计超导腔的带宽和失谐，具有无需滤波和误差收敛可控的优点，适用于未来的连续波直线加速器。

> **ai_Abstract:** 本文提出了一种基于Luenberger观测器的新方法，用于估计超导腔的带宽和失谐。该方法旨在满足未来连续波直线加速器对精确腔体参数跟踪的需求。与传统方法相比，其主要优势在于能够以控制系统原始采样率进行估计，无需对输入信号进行显式滤波，并且允许通过调整增益参数直观地控制估计误差的收敛性。论文详细介绍了该观测器的实现考虑并展示了测试结果。

> **摘要翻译:** 随着超导技术的进步，未来十年预计将出现多台连续波直线加速器。对于这些机器，跟踪主腔参数（如谐振腔带宽和失谐）至关重要。带宽提供了腔体超导状态的信息。应尽量减小失谐以限制操作腔体所需的功率。这些参数的估计通常在低电平射频（LLRF）控制系统的数字电子设备中实现，以最大限度地减少计算延迟。在本论文中，我们提出了一种使用Luenberger观测器计算带宽和失谐的方法。与以前的方法不同，状态观测器可以在原始控制系统采样率下产生估计，而无需显式滤波输入信号。此外，通过调整增益参数，可以直观地控制估计的误差收敛特性。手稿中介绍了派生观测器的实现考虑和测试结果。

</details>

[⬆️ 返回分类顶部](#physicsacc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [218] [Thinning to improve two-sample discrepancy](https://arxiv.org/abs/2506.20932)
> *稀疏化以改善两样本差异*

*Gleb Smirnov, Roman Vershynin* | **Category: math.PR, cs.DS**

**Keywords:** 两样本差异, 稀疏化, 在线算法, 差异降低, 数据抽样

**Comment:** 7 pages

> **TL;DR:** 提出一种在线算法，通过丢弃少量数据点，将两样本差异从O(√n)显著降低到O(log^(2d) n)。

**AI_Comments:** 这项工作通过一个简单的在线算法，显著改善了传统两样本差异的收敛速度，从多项式级别降低到对数级别，这在处理大数据集时可能具有重要意义。其创新之处在于通过“稀疏化”或“丢弃”部分点来优化差异，这是一种新颖且高效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 两个独立样本之间的差异通常为O(√n)，即使在低维度下也是如此，这表明样本差异较大，需要被改善。

**Method:** 本文提出了一个简单的在线算法，通过丢弃一小部分数据点来减少样本差异。

**Result:** 该算法成功地将两样本差异从典型的O(√n)量级降低到O(log^(2d) n)。

**Conclusion:** 通过一个简单的在线算法并丢弃一小部分数据点，可以显著地改善两个独立样本之间的差异。

> **ai_Abstract:** 本文针对两个独立样本之间普遍存在的O(√n)量级差异问题，提出了一种简单的在线算法。该算法通过策略性地丢弃一小部分样本点，成功地将样本差异显著降低至O(log^(2d) n)，从而有效地提升了样本间的匹配度。

> **摘要翻译:** 摘要：从$\\mathbb{R}^d$上的相同分布中抽取的两个独立样本\(X_1,\dots,X_n\)和\(Y_1,\dots,Y_n\)之间的差异，即使在一维情况下，通常也具有\(O(\\sqrt{n})\)的量级。我们提出了一种简单的在线算法，通过丢弃一小部分点，将差异降低到\(O(\\log^{2d} n)\\)。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [225] [Exact Time-Varying Turnpikes for Dynamic Operation of District Heating Networks](https://arxiv.org/abs/2506.21239)
> *区域供热网络动态运行的精确时变转轨*

*Max Rose, Hannes Gernandt, Timm Faulwasser, Johannes Schiffer* | **Category: math.OC, cs.SY, eess.SY**

**Keywords:** 区域供热网络, 转轨现象, 最优控制, 时变, 耗散性

**Comment:** 

> **TL;DR:** 本文研究了区域供热网络优化中的时变转轨现象，推导了其存在条件和闭式表达式，并展示了其与耗散性的关系。

**AI_Comments:** 本文的创新之处在于将时变转轨理论应用于区域供热网络的优化，解决了现有方法在处理时变因素上的局限性。这为DHNs的动态运行提供了更精确的理论基础，有助于提高其能源效率和脱碳潜力。该研究通过严谨的数学推导，不仅丰富了最优控制理论在实际工程中的应用，也为未来DHNs的智能控制提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 区域供热网络对供热部门脱碳至关重要，但其高效可靠运行需要协调多个热源并考虑未来需求。现有基于预测和优化的控制方法未考虑时变问题。

**Method:** 本文通过分析具有时变价格和需求的最优控制问题，研究了转轨现象在区域供热网络优化中的作用。具体地，推导了唯一时变奇异弧（即时变转轨）存在的条件及其闭式表达式。此外，还提出了逆向转轨结果，表明精确时变情况意味着最优控制问题的严格耗散性。

**Result:** 推导了唯一时变奇异弧（构成时变转轨）存在的条件，并提供了其闭式表达式。提出了逆向转轨结果，表明精确时变情况意味着最优控制问题的严格耗散性。通过数值例子验证了研究结果。

**Conclusion:** 本文为区域供热网络优化提供了精确的时变转轨，可作为模型预测控制设计和分析的基础，并揭示了其与最优控制问题严格耗散性的关系。

> **ai_Abstract:** 本文研究了区域供热网络（DHNs）在时变条件下的高效运行优化问题。针对现有控制方法未能考虑时变因素的不足，论文利用转轨现象作为理论基础，分析了DHNs的最优控制问题。研究推导了唯一时变奇异弧（即时变转轨）的存在条件及其闭式表达式，并进一步揭示了精确时变转轨与最优控制问题严格耗散性之间的关系。这些发现为DHNs的模型预测控制设计和分析提供了新的理论工具，并通过数值案例进行了验证。

> **摘要翻译:** 区域供热网络（DHNs）对于供热部门的脱碳至关重要。然而，其高效可靠的运行需要协调多个热生产者并考虑未来的需求。基于预测和优化的控制方法通常用于解决这项任务，但现有的DHNs研究结果没有考虑时变问题。由于转轨现象可以作为模型预测控制设计和分析的基础，本文通过分析具有时变价格和需求的基本最优控制问题，研究了其在DHN优化中的作用。也就是说，我们推导了唯一时变奇异弧存在的条件，该奇异弧构成了时变转轨，并提供了其闭式表达式。此外，我们还提出了逆向转轨结果，表明精确时变情况意味着最优控制问题的严格耗散性。一个数值例子说明了我们的发现。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [415] [Control and optimization for Neural Partial Differential Equations in Supervised Learning](https://arxiv.org/abs/2506.20764)
> *监督学习中神经偏微分方程的控制与优化*

*Alain Bensoussan, Minh-Binh Tran, Bangjie Wang* | **Category: math.OC, cs.LG**

**Keywords:** 神经网络, 偏微分方程, 控制理论, 优化, 监督学习

**Comment:** 

> **TL;DR:** 该论文探索了抛物线和双曲线偏微分方程系数的控制与优化，将神经网络解释为偏微分方程，并证明了这些控制问题的极小值解/解的存在性，这在偏微分方程控制理论中是新颖的。

**AI_Comments:** 这篇论文通过将神经网络与偏微分方程联系起来，提供了一个创新的视角，将监督学习中的核心问题（数据通过层传输）重新构建为偏微分方程控制问题。对算子系数优化的关注是控制理论中一个重要且未被充分探索的领域，尤其是在应用于神经网络时。极小值解和解存在性的理论证明是关键的基础步骤，尽管摘要暗示了未来对高效数值方案的工作，表明目前在实际实现上存在局限性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管关于抛物线和双曲线系统的控制和优化问题已有大量文献，但尚未彻底探讨这些系统中相关算子系数的控制和优化这一具体问题。这个问题在神经网络和监督学习中自然产生，且在偏微分方程控制理论中尚未得到系统性解决。

**Method:** 作者提出将神经网络解释为偏微分方程（PDEs），并将传统的常微分方程（ODEs）控制问题重新表述为偏微分方程的控制问题，特别针对抛物线和双曲线算子中系数的优化和控制。对于抛物线偏微分方程，他们提出了对偶系统公式并证明了极小值解的存在性。对于双曲线偏微分方程，他们研究了控制问题并证明了相应近似控制问题解的存在性。

**Result:** 他们为抛物线偏微分方程提出了一个对偶系统公式，并证明了极小值解的存在性。他们还研究了双曲线偏微分方程，并证明了近似控制问题解的存在性。

**Conclusion:** 该论文为偏微分方程系数的控制和优化奠定了基础，特别是在将神经网络解释为偏微分方程的背景下，并为这些新颖的控制问题提供了极小值解/解存在性的理论证明。

> **ai_Abstract:** 本文通过将神经网络解释为偏微分方程（PDEs），提出了一种新颖的神经网络控制和优化方法。它解决了在偏微分方程系统中控制和优化抛物线和双曲线算子系数这一未充分探索的问题，这与监督学习相关。作者为抛物线偏微分方程提出了一个对偶系统公式，并证明了极小值解的存在性；同时，也证明了涉及双曲线偏微分方程的近似控制问题解的存在性，为未来的数值方案奠定了理论基础。

> **摘要翻译:** 尽管关于抛物线和双曲线系统的控制和优化问题已有大量文献，但尚未彻底探讨这些系统中相关算子系数的控制和优化这一具体问题。在这项工作中，我们旨在开创控制理论中的一个研究方向，专注于优化和控制这些算子的系数——这是一个在神经网络和监督学习背景下自然产生的问题。
在监督学习中，主要目标是通过神经网络的层将初始数据传输到目标数据。我们提出了一种新颖的视角：神经网络可以被解释为偏微分方程（PDEs）。从这个观点出发，传统上在常微分方程（ODEs）背景下研究的控制问题被重新表述为偏微分方程的控制问题，特别是针对抛物线和双曲线算子中系数的优化和控制。据我们所知，这个问题在偏微分方程控制理论中尚未得到系统性的解决。
为此，我们提出了一个与抛物线偏微分方程相关的控制和优化问题的对偶系统公式，为未来研究中高效数值方案的开发奠定了基础。我们还提供了理论证明，表明抛物线偏微分方程的控制和优化问题存在极小值解。最后，我们研究了与双曲线偏微分方程相关的控制问题，并证明了相应近似控制问题的解的存在性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [427] [Faster Fixed-Point Methods for Multichain MDPs](https://arxiv.org/abs/2506.20910)
> *多链马尔可夫决策过程的更快不动点方法*

*Matthew Zurek, Yudong Chen* | **Category: math.OC, cs.LG, stat.ML**

**Keywords:** 多链MDPs, 平均奖励, 价值迭代, 不动点方法, 收敛速度

**Comment:** 

> **TL;DR:** 该研究为平均奖励准则下的多链马尔可夫决策过程（MDPs）开发了更快的价值迭代算法，通过更好地解决导航子问题，实现了更快的收敛速度和更清晰的复杂性度量。

**AI_Comments:** 本文通过解决多链MDPs中独特的导航子问题，创新性地提升了平均奖励准则下价值迭代算法的收敛速度和理论严谨性。其将平均奖励与折扣问题联系起来，并提出适用于更广泛空间的最优不动点方法，具有重要的理论和潜在实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 研究平均奖励准则下的多链马尔可夫决策过程（MDPs）是一个理论上具有挑战性的基本问题。除了所有平均奖励问题固有的非收缩性和贝尔曼算子解的非唯一性之外，多链设置中最佳策略还必须解决导航子问题，即引导至最佳连接组件，同时优化每个组件内的长期性能。

**Method:** 开发了新的算法，旨在更好地解决多链MDPs中的导航子问题。研究还包括平均奖励问题与折扣问题之间的新颖联系，扩展到一般巴拿赫空间的折扣价值迭代的最优不动点方法，折扣价值误差的新次线性收敛速率，以及多链MDPs的细化次优分解。

**Result:** 获得了比现有工作更快的收敛速度和更清晰的复杂性度量。整体结果提高了折扣和平均奖励问题的收敛速度。

**Conclusion:** 本研究的结果为折扣和平均奖励问题带来了更快的收敛速度，并扩展了价值迭代方法的理论基础。

> **ai_Abstract:** 本论文研究平均奖励准则下的多链马尔可夫决策过程（MDPs）的价值迭代算法。针对多链设置中导航子问题的挑战，作者开发了新算法，以实现更快的收敛速度和更精确的复杂性度量。研究还揭示了平均奖励与折扣问题的新联系，提出了适用于一般巴拿赫空间的最优不动点方法，并提供了折扣价值误差的次线性收敛率和多链MDPs的细化次优分解，从而提升了VI方法的理论基础。

> **摘要翻译:** 我们研究了在平均奖励准则下解决通用（又称多链）马尔可夫决策过程（MDPs）的价值迭代（VI）算法，这是一个基础但理论上具有挑战性的设置。除了所有平均奖励问题因缺乏收缩性和贝尔曼算子解的非唯一性而固有的困难之外，在多链设置中，最优策略除了优化每个组件内的长期性能外，还必须解决导航子问题，即引导至最佳连接组件。我们开发了能够更好地解决此导航子问题以实现多链MDPs更快收敛的算法，相对于先前的工作，获得了改进的收敛速度和更清晰的复杂性度量。我们结果的许多关键组成部分具有潜在的独立兴趣，包括平均奖励问题与折扣问题之间的新颖联系，扩展到一般巴拿赫空间的折扣VI的最优不动点方法，折扣价值误差的新次线性收敛速率，以及多链MDPs的细化次优分解。总的来说，我们的结果为折扣和平均奖励问题带来了更快的收敛速度，并扩展了VI方法的理论基础。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [230] [Guarding Offices with Maximum Dispersion](https://arxiv.org/abs/2506.21307)
> *以最大离散度守卫办公室*

*Sándor P. Fekete, Kai Kobbe, Dominik Krupke, Joseph S. B. Mitchell, Christian Rieck, Christian Scheffer* | **Category: cs.CG, cs.DS, F.2.2**

**Keywords:** 离散美术馆问题, 正交多边形, NP完全性, 算法, SAT求解器

**Comment:** 40 pages, 29 figures, to appear in the proceedings 50th International
  Symposium on Mathematical Foundations of Computer Science (MFCS 2025)

> **TL;DR:** 该论文研究了办公楼多边形中的离散美术馆问题，证明了某些离散距离的NP完全性，提供了其他距离的多项式时间算法，并展示了SAT求解器的实际可行性。

**AI_Comments:** 该论文对离散美术馆问题做出了重要贡献，扩展了复杂性结果，并为一类实用的多边形提供了高效算法。解决了开放问题以及使用现代求解器证明了实际可行性是其显著的创新点和重要性所在。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决离散美术馆问题，目标是最大化任意两个守卫之间的最小测地L1距离（称为离散距离），而不是最小化守卫数量。研究对象是反映真实世界平面图特性的办公楼式正交多边形，这些多边形由矩形房间和走廊组成。

**Method:** 研究证明了在办公楼式多边形中，确定顶点守卫集能否达到4的离散距离（顶点坐标为整数）是NP完全的，并提出了一个多项式时间的最坏情况最优算法，保证离散距离为3。对于顶点坐标允许为有理数的情况，证明了达到2+ε的离散距离是NP难的，并给出了一个多项式时间算法来计算离散距离为2的最坏情况最优解。对于无孔独立办公楼式多边形，提出了动态规划方法来计算最优解。此外，通过比较SAT、CP和MIP公式的求解器，证明了该问题对于任意正交多边形在实践中是可处理的。

**Result:** 1. 证明了在办公楼式多边形中，确定顶点守卫集能否达到4的离散距离（顶点坐标为整数）是NP完全的。2. 提出了一个简单的最坏情况最优算法，保证在多项式时间内达到3的离散距离。3. 复杂性结果扩展到多聚骨牌，解决了Rieck和Scheffer提出的一个开放问题。4. 证明了当顶点坐标为有理数时，达到2+ε的离散距离是NP难的。5. 提供了一个直接的多项式时间算法，计算离散距离为2的最坏情况最优解。6. 对于无孔独立办公楼式多边形，动态规划方法能够计算最优解。7. SAT求解器能够高效地计算随机生成实例的最优解，对于多达1600个顶点的实例，耗时不到15秒。

**Conclusion:** 该论文为办公楼式多边形在r-可见性下的离散美术馆问题提供了复杂性结果（NP完全性）和多项式时间算法。同时，通过使用SAT求解器，展示了该问题在处理大型实例时的实际可行性。

> **ai_Abstract:** 本论文研究了在办公楼式正交多边形中，使用顶点守卫和r-可见性的离散美术馆问题。研究确立了达到特定离散距离（整数坐标下为4，有理坐标下为2+ε）的NP完全性，并为其他距离（3和2）提供了多项式时间算法。对于更受限的情况，论文采用了动态规划方法，并通过比较SAT、CP和MIP求解器，展示了该问题对于任意正交多边形在实践中的可处理性，其中SAT求解器在大规模实例上表现出色。

> **摘要翻译:** 我们研究了在具有顶点守卫和矩形可见性（r-可见性）的离散美术馆问题，针对一类反映真实世界平面图特性的正交多边形：这些办公楼式多边形由矩形房间和走廊组成。在离散美术馆问题的变体中，目标不是最小化守卫数量，而是最大化任意两个守卫之间的最小测地L1距离，称为离散距离。
我们的主要贡献如下。我们证明了在办公楼式多边形中，确定顶点守卫集能否达到4的离散距离是NP完全的，其中多边形的顶点被限制为整数坐标。此外，我们提出了一个简单的最坏情况最优算法，保证在多项式时间内达到3的离散距离。我们的复杂性结果扩展到多聚骨牌，解决了Rieck和Scheffer（CGTA 2024）提出的一个开放问题。当顶点坐标允许为有理数时，我们建立了类似的结果，证明了对于任意ε > 0，达到2+ε的离散距离是NP难的，而经典美术馆问题对于这类多边形仍然可以在多项式时间内解决。此外，我们给出了一个直接的多项式时间算法，可以计算离散距离为2的最坏情况最优解。
另一方面，对于更受限制的无孔独立办公楼式多边形，我们提出了一种动态规划方法来计算最优解。此外，我们证明了该问题对于任意正交多边形在实践中是可处理的。为此，我们比较了基于SAT、CP和MIP公式的求解器。值得注意的是，SAT求解器能够高效地计算随机生成实例的最优解，对于多达1600个顶点的实例，耗时不到15秒。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [234] [E-FreeM2: Efficient Training-Free Multi-Scale and Cross-Modal News Verification via MLLMs](https://arxiv.org/abs/2506.20944)
> *E-FreeM2: 通过多模态大语言模型实现高效免训练多尺度跨模态新闻验证*

*Van-Hoang Phan, Long-Khanh Pham, Dang Vu, Anh-Duy Tran, Minh-Son Dao* | **Category: cs.MM, cs.CR**

**Keywords:** 多模态事实验证, 免训练, 检索式, 大型语言模型, 虚假信息检测

**Comment:** Accepted to AsiaCCS 2025 @ SCID

> **TL;DR:** E-FreeM2是一个免训练、基于检索的多模态事实验证系统，利用预训练视觉-语言模型和大型语言模型，通过动态检索和交叉引用可信数据源来检测虚假信息，并在移动和无线网络中实现SOTA性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个“免训练”的多模态事实验证系统，这显著降低了模型对大量标注数据的依赖，并增强了对对抗性攻击和数据投毒的鲁棒性。其轻量级设计使其适用于资源受限的边缘设备，具有很高的实用价值。在多模态大模型快速发展的背景下，这种将预训练MLLMs与检索机制结合的方式，为虚假信息检测提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 移动和无线网络中虚假信息的快速传播带来了严峻的安全挑战，传统的基于训练的模型容易受到对抗性攻击和数据投毒。

**Method:** 本研究提出了一个名为E-FreeM2的免训练、基于检索的多模态事实验证系统。该系统利用预训练的视觉-语言模型和大型语言模型进行可信度评估，通过动态检索和交叉引用可信数据源来规避传统训练模型的脆弱性。其轻量级设计使其能够无缝集成到边缘设备中，无需大量的设备内处理。

**Result:** 该系统在两个事实核查基准测试中取得了SOTA（State-of-the-Art）结果，证实了其在虚假信息检测方面的有效性以及对各种攻击向量的鲁棒性。

**Conclusion:** E-FreeM2系统通过其免训练、轻量级和鲁棒的特性，在移动和无线通信环境中具有增强安全性的巨大潜力。

> **ai_Abstract:** E-FreeM2是一个创新的免训练、基于检索的多模态事实验证系统，旨在应对移动和无线网络中的虚假信息问题。它利用预训练的视觉-语言模型和大型语言模型，通过动态检索和交叉引用可信数据源来评估信息可信度，从而规避了传统训练模型易受攻击的缺点。该系统设计轻量，易于集成到边缘设备。实验证明，E-FreeM2在事实核查基准测试中达到了最先进的性能，并展现出对各种攻击的强大鲁棒性，有望显著提升移动和无线通信环境的安全性。

> **摘要翻译:** 移动和无线网络中虚假信息的快速传播带来了严峻的安全挑战。本研究引入了一种免训练、基于检索的多模态事实验证系统，该系统利用预训练的视觉-语言模型和大型语言模型进行可信度评估。通过动态检索和交叉引用可信数据源，我们的方法减轻了传统基于训练模型的脆弱性，例如对抗性攻击和数据投毒。此外，其轻量级设计使得无需大量的设备内处理即可实现边缘设备的无缝集成。在两个事实核查基准测试上的实验取得了SOTA结果，证实了其在虚假信息检测方面的有效性以及对各种攻击向量的鲁棒性，突出了其在移动和无线通信环境中增强安全的潜力。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [237] [MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models](https://arxiv.org/abs/2506.20686)
> *MegaFold：加速蛋白质结构预测模型的系统级优化*

*Hoa La, Ahan Gupta, Alex Morehead, Jianlin Cheng, Minjia Zhang* | **Category: q-bio.BM, cs.DC, cs.LG, cs.PF**

**Keywords:** 蛋白质结构预测, AlphaFold3, 系统优化, 训练加速, 内存效率

**Comment:** 13 pages, 12 figures

> **TL;DR:** MegaFold通过系统级优化，显著加速并扩展了AlphaFold3等蛋白质结构预测模型的训练，解决了其高昂的系统成本和可扩展性问题。

**AI_Comments:** MegaFold的创新之处在于其针对蛋白质结构预测模型（尤其是AlphaFold3）训练中的特定系统瓶颈，提出了全面且高效的优化方案。通过在数据管道、内存管理和操作融合方面的改进，它直接解决了这些模型高昂的训练成本和可扩展性挑战。这对于推动生物分子建模的进一步研究和应用至关重要，因为它使得训练更复杂、更精确的模型变得更加可行。其跨平台支持也增加了其实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** AlphaFold3等蛋白质结构预测模型虽然在生物分子建模方面取得了突破，但其计算和内存密集型操作、2D注意力机制以及检索增强数据管道带来了高昂的系统成本，严重阻碍了训练的可扩展性。

**Method:** MegaFold通过以下系统级优化来解决关键瓶颈：1. 采用提前缓存（ahead-of-time caching）消除检索增强数据管道中的GPU空闲时间。2. 使用基于Triton的核（Triton-based kernels）实现异构设备上内存高效的EvoAttention。3. 对AlphaFold3中常见和关键的小型操作进行深度融合（deep fusion）。

**Result:** 在NVIDIA H200和AMD MI250 GPU上的评估显示，MegaFold将AlphaFold3训练的峰值内存使用量减少了高达1.23倍。它将每次迭代的训练时间分别提高了高达1.73倍和1.62倍。更重要的是，与PyTorch基线相比，MegaFold能够在不耗尽内存的情况下训练1.35倍更长的序列长度。

**Conclusion:** MegaFold显著提高了现代蛋白质折叠模型（如AlphaFold3）的可扩展性。

> **ai_Abstract:** MegaFold是一个为加速AlphaFold3等蛋白质结构预测模型训练而设计的跨平台系统。它通过引入多项系统级优化来解决现有模型训练中高昂的计算和内存成本问题，包括提前缓存以减少GPU空闲时间、基于Triton的内存高效EvoAttention核以及对关键操作的深度融合。实验证明，MegaFold显著降低了内存消耗，提升了训练速度，并支持更长序列的训练，从而极大地增强了现代蛋白质折叠模型的可扩展性。

> **摘要翻译:** 蛋白质结构预测模型，如AlphaFold3 (AF3)，通过将科学知情的架构变化融入Transformer架构，推动了生物分子建模的前沿。然而，这些进步带来了高昂的系统成本，包括：计算和内存密集型操作、2D注意力机制以及检索增强数据管道，这些共同阻碍了AF3训练的可扩展性。在这项工作中，我们提出了MegaFold，一个跨平台系统，用于加速AF3训练。MegaFold通过提前缓存（ahead-of-time caching）消除检索增强数据管道中的GPU空闲时间，基于Triton的核（Triton-based kernels）实现异构设备上内存高效的EvoAttention，以及对AF3中常见和关键的小型操作进行深度融合，解决了关键瓶颈。在NVIDIA H200和AMD MI250 GPU上的评估表明，MegaFold将AF3训练的峰值内存使用量减少了高达1.23倍，并将每次迭代的训练时间分别提高了高达1.73倍和1.62倍。更重要的是，与PyTorch基线相比，MegaFold能够在不耗尽内存的情况下训练1.35倍更长的序列长度，显著提高了现代蛋白质折叠模型的可扩展性。我们的代码已在https://github.com/Supercomputing-System-AI-Lab/MegaFold/ 开源。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

### [386] [CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions](https://arxiv.org/abs/2506.21085)
> *CovDocker：用任务、数据集和解决方案基准测试共价药物设计*

*Yangzhe Peng, Kaiyuan Gao, Liang He, Yuheng Cong, Haiguang Liu, Kun He, Lijun Wu* | **Category: q-bio.BM, cs.AI, cs.LG**

**Keywords:** 共价药物设计, 分子对接, 基准测试, CovDocker, 深度学习

**Comment:** Accepted to KDD 2025 Research Track

> **TL;DR:** CovDocker是一个用于共价对接的综合基准测试平台，旨在解决现有对接方法难以处理共价键形成的问题。它将共价对接分解为三个任务，并利用先进模型建立了基线性能，以推动共价药物设计研究。

**AI_Comments:** CovDocker的创新之处在于其首次为共价对接提供了一个全面且结构化的基准测试，填补了现有对接方法在处理共价相互作用方面的空白。通过将复杂的共价对接过程分解为多个子任务，并利用先进的深度学习模型建立基线，它为未来的研究提供了一个清晰的评估框架和发展方向。这对于加速共价药物的发现和开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数分子对接方法和深度学习方法很难考虑共价键的形成及其相关的结构变化，这限制了它们在预测配体与靶蛋白共价结合模式方面的应用。为了弥补这一空白，本研究引入了一个全面的共价对接基准测试平台CovDocker。

**Method:** 本研究引入了CovDocker，一个用于共价对接的综合基准测试平台，旨在更好地捕捉共价结合的复杂性。它将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过调整Uni-Mol和Chemformer等最先进的模型，建立了基线性能。

**Result:** CovDocker基准测试在准确预测相互作用位点和建模共价结合中涉及的分子转化方面展现了有效性。这些结果证实了该基准测试作为推进共价药物设计研究的严谨框架的作用。

**Conclusion:** 本研究推出的CovDocker基准测试为共价药物设计提供了一个严谨的框架，并强调了数据驱动方法在加速选择性共价抑制剂发现和解决治疗开发中关键挑战的潜力。

> **ai_Abstract:** CovDocker是一个为共价药物设计而开发的综合基准测试平台，旨在解决现有分子对接方法在处理共价键形成方面的不足。该平台将共价对接流程细分为反应位点预测、共价反应预测和共价对接三个核心任务。研究者通过整合并调整Uni-Mol和Chemformer等先进模型，建立了基线性能，并验证了CovDocker在准确预测相互作用位点和模拟分子转化方面的有效性。该基准测试被确认为推动共价药物设计研究的有力框架，有望加速选择性共价抑制剂的发现。

> **摘要翻译:** 分子对接在预测配体与靶蛋白的结合模式方面发挥着关键作用，而共价相互作用，即配体与靶标之间形成共价键，因其强大的、持久的结合性质而特别有价值。然而，大多数现有的对接方法和深度学习方法很难考虑共价键的形成及其相关的结构变化。为了弥补这一空白，我们引入了一个全面的共价对接基准测试平台CovDocker，旨在更好地捕捉共价结合的复杂性。我们将共价对接过程分解为三个主要任务：反应位点预测、共价反应预测和共价对接。通过调整Uni-Mol和Chemformer等最先进的模型，我们建立了基线性能，并展示了该基准测试在准确预测相互作用位点和建模共价结合中涉及的分子转化方面的有效性。这些结果证实了该基准测试作为推进共价药物设计研究的严谨框架的作用。它强调了数据驱动方法在加速选择性共价抑制剂发现和解决治疗开发中关键挑战的潜力。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsins-det'></a>
## physics.ins-det 

### [249] [Plasmonically Enhanced Flexural-Mode AlScN Nanoplate Resonator as Uncooled and Ultrafast IR Detector with High Responsivity](https://arxiv.org/abs/2506.21412)
> *等离子体增强挠曲模式AlScN纳米板谐振器作为非制冷超快高响应红外探测器*

*Aurelio Venditti, Walter Gubinelli, Enise F. Altin, Luca Colombo, Pietro Simeoni, Benyamin Davaji, Matteo Rinaldi* | **Category: physics.ins-det, cs.SY, eess.SY, physics.app-ph**

**Keywords:** AlScN纳米板, 红外探测器, 谐振器, 等离子体增强, 非制冷

**Comment:** This manuscript has been submitted to ACS Nano Letters for
  consideration

> **TL;DR:** 该研究介绍了一种基于等离子体增强的AlScN纳米板谐振器，作为一种小型化、非制冷、超快且高响应的红外探测器。

**AI_Comments:** 这项工作的创新之处在于首次将等离子体吸收器与AlScN纳米板谐振器结合，创造出一种新型的红外探测器。其重要性在于实现了小型化、非制冷、超快且高响应的性能，有望推动红外热成像技术的发展。该方法利用了AlScN优异的材料特性和等离子体增强效应，为未来高性能传感器设计提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有红外谐振热探测器（RTDs）的性能有待提升，尤其是在尺寸、响应速度、噪声和响应度方面。本文旨在通过利用AlScN纳米板的高机电耦合、良好热性能和增强的红外吸收，实现显著的性能突破。

**Method:** 该研究引入了一种基于30%掺杂的氮化铝钪（AlScN）纳米板的新型小型化、非制冷、超快红外谐振热探测器（RTDs）。该器件利用AlScN的高机电耦合、良好热性能和增强的红外吸收。此外，其弯曲模式的致动谐振特性支持干涉光学读出，并首次在谐振平台上集成了等离子体吸收器，以AlScN作为介电层。

**Result:** 该设备展示了约130 ppt/pW的高红外响应度，约330微秒的热时间常数，以及较大的面外位移。它结合了紧凑的尺寸、高光谱选择性和响应度、降低的噪声以及快速的热响应。

**Conclusion:** 该工作首次在谐振平台上实验性地集成了利用AlScN作为介电层的等离子体吸收器，并证明了基于AlScN纳米板谐振器的红外探测器在实现小型化、非制冷、超快和高响应方面具有巨大潜力，为创新的红外热成像仪发展铺平了道路。

> **ai_Abstract:** 该论文介绍了一种新型的、基于等离子体增强的挠曲模式AlScN纳米板谐振器，作为一种小型化、非制冷、超快且高响应的红外探测器。该器件利用AlScN的高机电耦合和热性能，并结合等离子体吸收器实现增强的红外吸收。实验结果显示，该探测器具有高红外响应度（约130 ppt/pW）和快速热响应（约330微秒），并支持干涉光学读出，为开发高性能红外热成像仪提供了潜力。

> **摘要翻译:** 这封信介绍了一种基于30%掺杂的氮化铝钪（AlScN）纳米板的新型小型化、非制冷、超快红外（IR）谐振热探测器（RTDs）。利用高机电耦合、良好热性能以及增强和选择性红外吸收，所提出的器件旨在展示相较于现有红外RTDs的显著进步。这种单像素结合了紧凑的尺寸、高光谱选择性和响应度、降低的噪声以及快速的热响应，从而为通过多像素集成开发创新的红外热成像仪提供了潜力。致动谐振模式的弯曲性质最终实现了干涉光学读出，为实现极低噪声等效功率水平铺平了道路。这些结果展示了约130 ppt/pW的高红外响应度、约330微秒的热时间常数以及较大的面外位移。这项工作代表了首次在谐振平台上实验性地集成利用AlScN作为介电层的等离子体吸收器。

</details>

[⬆️ 返回分类顶部](#physicsins-det) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [264] [Benchmarking and Parallelization of Electrostatic Particle-In-Cell for low-temperature Plasma Simulation by particle-thread Binding](https://arxiv.org/abs/2506.21524)
> *低温等离子体模拟中静电粒子-网格法的基准测试与粒子-线程绑定并行化*

*Libn Varghese, Bhaskar Chaudhury, Miral Shah, Mainak Bandyopadhyay* | **Category: physics.comp-ph, cs.DC, physics.plasm-ph**

**Keywords:** 粒子-网格法, 并行化, 粒子-线程绑定, 等离子体模拟, 电荷沉积

**Comment:** 

> **TL;DR:** 本文提出了一种基于粒子-线程绑定策略的静电粒子-网格法（PIC）并行化新方法，该方法通过减少私有网格数量来解决传统方法中电荷沉积（CD）子程序的瓶颈和可扩展性问题，并在共享内存和分布式内存系统上验证了其可扩展性和低硬件依赖性。

**AI_Comments:** 这项研究提出了一种创新的粒子-线程绑定策略，有效解决了传统PIC并行化中电荷沉积子程序的可扩展性瓶颈。其创新之处在于大幅减少了所需的私有网格数量（仅四个），这对于分布式和共享内存系统都是一个显著的改进。该方法的重要性在于它能在最小化对现有PIC代码修改的同时，实现高性能和高可扩展性，这对于实际应用具有重要意义。此外，其低硬件依赖性也增强了方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 粒子-网格法（PIC）在2D和3D设备级等离子体模拟中计算成本高昂，尤其电荷沉积（CD）子程序由于频繁的粒子-网格交互而成为并行化的瓶颈。传统并行化方法通过为每个核心生成私有网格来缓解依赖性，但这种方法面临可扩展性问题。

**Method:** 本文提出了一种基于粒子-线程绑定策略的新方法。该方法在分布式内存系统或共享内存系统中每个节点仅需要四个私有网格，从而增强了CD的可扩展性和性能。它保持了传统的粒子和网格数据结构，并对现有PIC代码的修改量极小。此外，该方法通过附加函数和标志确保并发线程对网格数据结构的完全可访问性，并避免了同一单元内粒子的同时访问。

**Result:** 在共享内存和分布式内存系统（1000个核心）上使用低温部分磁化E x B放电模拟的PIC基准测试进行了性能评估，结果表明该方法具有良好的可扩展性，并且硬件依赖性很小。

**Conclusion:** 所提出的粒子-线程绑定并行化方法有效解决了传统PIC模拟中电荷沉积子程序的可扩展性瓶颈，通过减少私有网格数量，在保持传统数据结构和最小化代码修改的同时，显著提升了性能，并展现出良好的可扩展性和低硬件依赖性。

> **ai_Abstract:** 本文针对低温等离子体模拟中粒子-网格法（PIC）的计算成本和电荷沉积（CD）子程序瓶颈，提出了一种新颖的粒子-线程绑定并行化策略。与传统为每个核心生成私有网格的方法不同，该方法仅需每个节点或系统四个私有网格，显著提升了CD的可扩展性和性能，同时保持了现有代码结构的兼容性。性能评估在共享和分布式内存系统上验证了其在千核规模下的可扩展性及低硬件依赖性。

> **摘要翻译:** 粒子-网格（PIC）方法用于等离子体模拟，利用粒子和网格数据结构跟踪粒子相空间信息。2D和3D设备级PIC模拟的高计算成本使得并行化成为必要，其中电荷沉积（CD）子程序由于频繁的粒子-网格交互而常常成为瓶颈。传统方法通过为每个核心生成私有网格来缓解依赖性，但这种方法面临可扩展性问题。我们提出了一种基于粒子-线程绑定策略的新方法，在分布式内存系统中每个节点仅需要四个私有网格，或在共享内存系统中需要四个私有网格，从而增强了CD的可扩展性和性能，同时保持了传统数据结构并对现有PIC代码的修改量极小。该方法确保并发线程对网格数据结构的完全可访问性，并使用附加函数和标志避免了同一单元内粒子的同时访问。在共享内存以及分布式内存系统（1000个核心）上使用低温部分磁化E x B放电模拟的PIC基准测试进行了性能评估，结果表明该方法具有可扩展性，此外，我们还展示了该方法几乎没有硬件依赖性。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [288] [Evaluating PDE discovery methods for multiscale modeling of biological signals](https://arxiv.org/abs/2506.20694)
> *评估用于生物信号多尺度建模的偏微分方程发现方法*

*Andréa Ducos, Audrey Denizot, Thomas Guyet, Hugues Berry* | **Category: q-bio.QM, cs.AI**

**Keywords:** PDE发现, 多尺度建模, 生物信号, 钙扩散, 星形胶质细胞

**Comment:** 

> **TL;DR:** 本研究评估了五种最先进的偏微分方程（PDE）发现方法，通过粒子模拟的星形胶质细胞中钙扩散来验证其在从微观数据中发现宏观生物系统动力学方面的潜力。

**AI_Comments:** 该论文的创新点在于将PDE发现方法应用于多尺度生物系统建模，并通过粒子模拟提供了一个受控的评估环境。其重要性在于为从微观数据推断宏观生物动力学提供了一种有前景的工具，有助于克服生物系统复杂性带来的建模挑战。目前仅限于初步实验和钙扩散的评估，未来的工作可能需要扩展到更复杂的生物过程和更广泛的数据集。

<details>
  <summary>Details</summary>

**Motivation:** 生物系统具有非线性、包含未观测变量、物理原理部分未知且其活动发生在多尺度上，这使得表征其行为极具挑战性。为了解决跨尺度连接的难题，本文利用偏微分方程（PDE）发现。

**Method:** 本文提出了一个结合粒子模拟和PDE发现的框架，并在受控环境下进行了初步实验，以评估方程发现的性能。研究评估了五种最先进的PDE发现方法，针对星形胶质细胞中钙扩散的粒子模拟数据。方法的性能从发现方程的形式和钙浓度的时间变化预测两方面进行评估。

**Result:** 研究结果表明，有几种方法能够准确地恢复扩散项。

**Conclusion:** 研究结果突出了偏微分方程发现从微观数据中捕获生物系统宏观动力学的潜力。

> **ai_Abstract:** 本研究旨在评估偏微分方程（PDE）发现方法在生物信号多尺度建模中的应用。鉴于生物系统固有的复杂性、非线性和多尺度特性，研究提出了一个结合粒子模拟和PDE发现的框架。通过对星形胶质细胞中钙扩散的粒子模拟数据，评估了五种主流PDE发现方法在方程形式恢复和时间变化预测方面的表现。结果表明，多种方法能够准确识别扩散项，证明了PDE发现从微观数据中提取生物系统宏观动力学的可行性与潜力。

> **摘要翻译:** 生物系统是非线性的，包含未观测变量，且支配其动力学的物理原理部分未知。这使得表征其行为极具挑战性。值得注意的是，它们的活动发生在多个相互依赖的空间和时间尺度上，需要跨尺度连接机制。为了解决弥合尺度间隙的挑战，我们利用偏微分方程（PDE）发现。PDE发现从微观数据中推断介观尺度的动力学特征。在本文中，我们提出了结合粒子模拟和PDE发现的框架，并进行了初步实验以评估受控环境下的方程发现。我们评估了五种最先进的PDE发现方法，针对星形胶质细胞中钙扩散的粒子模拟。方法的性能从发现方程的形式和钙浓度的时间变化预测两方面进行评估。我们的结果表明，有几种方法能够准确地恢复扩散项，突出了PDE发现从微观数据中捕获生物系统宏观动力学的潜力。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [289] [Surrogate normal-forms for the numerical bifurcation and stability analysis of navier-stokes flows via machine learning](https://arxiv.org/abs/2506.21275)
> *通过机器学习代理范式进行纳维-斯托克斯流的数值分岔与稳定性分析*

*Alessandro Della Pia, Dimitrios G. Patsatzis, Gianluigi Rozza, Lucia Russo, Constantinos Siettos* | **Category: physics.flu-dyn, cs.NA, math.NA**

**Keywords:** 纳维-斯托克斯流, 分岔分析, 机器学习, 降阶模型, 高斯过程回归

**Comment:** 26 pages, 14 figures

> **TL;DR:** 本文提出了一种基于机器学习的“嵌入-学习-提升”框架，通过构建代理范式（低维降阶模型）来高效准确地分析高维纳维-斯托克斯流的分岔和稳定性，解决了全空间计算成本过高的问题。

**AI_Comments:** 该论文的创新点在于将流形学习和高斯过程回归等机器学习技术融入到流体力学分岔分析中，有效地解决了高维纳维-斯托克斯方程在全空间进行分岔和稳定性分析时计算成本过高的问题。通过构建低维代理范式，不仅提高了分析效率，还使得原本难以处理的复杂动力学行为（如极限环）的追踪和稳定性分析成为可能。该方法为复杂系统的高效数值分析提供了一个有价值的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 在高维空间中对纳维-斯托克斯流进行分岔和稳定性分析因计算成本过高而难以实现，本文旨在通过构建代理范式来克服这一挑战，实现高效准确的分析。

**Method:** 该方法遵循“嵌入-学习-提升”框架的四个步骤：1) 流形学习揭示高维纳维-斯托克斯动力学的内在潜在维度；2) 使用高斯过程回归（GPR）在该潜在空间构建低维“范式”降阶模型；3) 利用这些模型，在潜在空间应用数值分岔工具计算分岔图并进行稳定性分析，包括追踪由Andronov-Hopf分岔引起的极限环；4) 解决原像问题以在原始高维空间中重建分岔结构。该方法在圆柱绕流和平面突扩流两种典型流动上进行了验证。

**Result:** 该方法成功识别了潜在维度，并构建了基于GPR的代理范式，从而能够追踪和稳定性分析分岔解，包括极限环、其周期及其通过Floquet乘子的稳定性。在圆柱绕流和平面突扩流两种典型流动上展示了该方法，它们分别呈现Andronov-Hopf和叉状分岔。

**Conclusion:** 本文提出的基于机器学习的代理范式方法，能够从高保真纳维-斯托克斯模拟中构建有效的降阶模型，从而实现高维流动的分岔和稳定性分析，解决了传统方法计算成本高昂的难题，提供了一种高效准确的分析工具。

> **ai_Abstract:** 本文提出了一种基于机器学习的“嵌入-学习-提升”框架，用于从高保真纳维-斯托克斯模拟中构建代理范式（最小维降阶模型），以实现高效准确的数值分岔和稳定性分析。该框架通过流形学习识别潜在维度，然后利用高斯过程回归在该潜在空间构建低维模型，再应用数值分岔工具进行分析，并最终在原始高维空间重建结果。该方法成功应用于圆柱绕流和平面突扩流，能够识别潜在维度并分析包括极限环在内的分岔解的稳定性，解决了高维流体动力学分析中计算成本高昂的问题。

> **摘要翻译:** 受无方程多尺度建模方法的启发，本文展示了“嵌入-学习-提升”框架如何能够从高保真纳维-斯托克斯模拟中构建代理范式，即最小维降阶模型（ROMs）。这些代理模型随后被用于高效准确的分岔和稳定性分析。该框架分为四个步骤。首先，流形学习揭示了跨参数空间的高维时空纳维-斯托克斯动力学的内在潜在维度。其次，我们使用高斯过程回归（GPR）在该潜在空间上构建了低维的“范式”类降阶模型，捕获了涌现动力学。第三，使用这些模型，我们应用数值分岔工具在潜在空间中计算分岔图并进行稳定性分析。这包括追踪由Andronov-Hopf分岔引起的极限环分支——这些任务在全空间中因计算成本过高而难以处理。最后，解决原像问题允许在原始高维空间中重建分岔结构。我们在两种典型流动上演示了该方法：无限圆柱体后的尾流和平面突扩通道流。随着雷诺数的增加，它们分别呈现Andronov-Hopf和叉状分岔。我们的方法识别了潜在维度并构建了基于GPR的代理范式，从而能够追踪和稳定性分析分岔解，包括极限环、其周期及其通过Floquet乘子的稳定性。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [406] [Transformer-Based Spatial-Temporal Counterfactual Outcomes Estimation](https://arxiv.org/abs/2506.21154)
> *基于Transformer的时空反事实结果估计*

*He Li, Haoang Chi, Mingyu Liu, Wanrong Huang, Liyang Xu, Wenjing Yang* | **Category: stat.ME, cs.AI, cs.LG**

**Keywords:** Transformer, 反事实估计, 时空, 因果推断, 森林损失

**Comment:** 24 pages, accepted at ICML 2025

> **TL;DR:** 本文提出了一种基于Transformer的新框架，用于估计具有时空属性的反事实结果，解决了传统统计模型在性能和泛化方面的局限性，并在模拟和真实数据实验中表现出更强的估计能力。

**AI_Comments:** 该论文创新性地将Transformer模型应用于时空反事实结果估计，解决了传统统计模型的局限性。其重要性在于提升了复杂时空因果推断的准确性和泛化能力，并提供了实际应用案例，具有较高的研究价值和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在时空维度下估计反事实结果是一个关键问题。然而，以往的方法基于经典统计模型，在性能和泛化方面仍存在局限性。

**Method:** 本文提出了一种基于Transformer的新颖框架，用于估计具有时空属性的反事实结果。在该框架下，所提出的估计器在温和假设下具有一致性和渐近正态性。

**Result:** 模拟实验表明，所提出的估计器比基线方法具有更强的估计能力。真实数据实验为哥伦比亚冲突对森林损失的因果效应提供了有价值的结论。

**Conclusion:** 基于Transformer的方法在时空反事实结果估计方面表现出更强的估计能力，并且可以用于分析实际的因果效应，例如哥伦比亚冲突对森林损失的影响。

> **ai_Abstract:** 本文针对时空反事实结果估计问题，提出了一种基于Transformer的新型框架，旨在克服传统统计模型的性能和泛化局限性。该框架下的估计器在温和假设下具有一致性和渐近正态性。通过模拟和真实数据实验（例如分析哥伦比亚冲突对森林损失的因果效应），验证了其优于基线方法的估计能力和有效性。

> **摘要翻译:** 现实世界天然具有时间和空间维度。因此，估计具有时空属性的反事实结果是一个关键问题。然而，以往的方法基于经典统计模型，在性能和泛化方面仍存在局限性。本文提出了一种基于Transformer的新颖框架，用于估计具有时空属性的反事实结果，展现出更强的估计能力。在温和假设下，该框架内提出的估计器具有一致性和渐近正态性。为了验证我们方法的有效性，我们进行了模拟实验和真实数据实验。模拟实验表明，我们的估计器比基线方法具有更强的估计能力。真实数据实验为哥伦比亚冲突对森林损失的因果效应提供了有价值的结论。源代码可在https://github.com/lihe-maxsize/DeppSTCI_Release_Version-master获取。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [409] [The final solution of the Hitchhiker's problem #5](https://arxiv.org/abs/2506.20672)
> *搭便车者问题#5的最终解决方案*

*Matjaž Omladič, Martin Vuk, Aljaž Zalar* | **Category: stat.ML, cs.LG, math.OC, math.ST, stat.TH**

**Keywords:** 拟合联结函数, 搭便车者指南, 开放问题5, 分析方法, 依赖性建模

**Comment:** 20 pages

> **TL;DR:** 本文利用分析方法，对“搭便车者指南”中关于多元拟合联结函数质量分布的极端值问题（开放问题5）提供了完整的解决方案，此前该问题曾通过线性规划方法部分解决并推翻了一个猜想。

**AI_Comments:** 本文的创新之处在于其采用分析方法彻底解决了之前只能通过线性规划部分解决的问题，并且推翻了相关猜想。这对于依赖性建模领域中拟合联结函数的研究具有重要意义，尤其是在缺乏统计解释的情况下提供了一个完整的理论解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 尽管拟合联结函数缺乏统计解释，但近期一项名为“搭便车者指南”的调查提高了其在依赖性建模领域中的关注度。作者先前的研究部分解决了指南中的开放问题5，但仍需一个完整的答案。

**Method:** 本文采用分析方法来提供对原始问题的完整解答。先前的相关工作曾使用线性规划方法。

**Result:** 本文利用分析方法，为“搭便车者指南”中的开放问题5提供了完整的答案。此前，作者通过线性规划方法已将该问题解决至维度d=17，并推翻了一个关于该问题解决方案的近期猜想。

**Conclusion:** 本文成功地通过分析方法，为“搭便车者指南”中的开放问题5提供了完整的解决方案。

> **ai_Abstract:** 本研究旨在为“搭便车者指南”中关于多元拟合联结函数质量分布极端值的开放问题5提供一个完整的分析解决方案。该问题因近期一项调查而备受关注。作者之前的研究曾利用线性规划方法部分解决了该问题，并推翻了相关猜想，但仅限于特定维度。本文通过采用纯粹的分析方法，最终为该长期未决的问题提供了全面的解答。

> **摘要翻译:** 近期一项名为“搭便车者指南”的调查（J.J. Arias-García, R. Mesiar, and B. De Baets, A hitchhiker's guide to quasi-copulas, Fuzzy Sets and Systems 393 (2020) 1-28）提高了拟合联结函数问题在依赖性建模社区中的评价，尽管拟合联结函数缺乏统计解释。在我们之前的工作中（arXiv:2410.19339，已在Fuzzy Sets and Systems接受），我们解决了与多元拟合联结函数相关的质量分布极端值问题。通过线性规划方法，我们能够将“指南”中的开放问题5解决至维度d=17，并推翻了一个关于该问题解决方案的近期猜想。在本文中，我们使用分析方法为原始问题提供了完整的答案。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [416] [Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon](https://arxiv.org/abs/2506.20779)
> *ReLU神经网络的稳定最小值遭受维度诅咒：神经破碎现象*

*Tongtong Liang, Dan Qiao, Yu-Xiang Wang, Rahul Parhi* | **Category: stat.ML, cs.LG**

**Keywords:** ReLU网络, 平坦最小值, 泛化, 维度诅咒, 神经破碎

**Comment:** Comments Welcome!

> **TL;DR:** 在ReLU网络中，平坦最小值虽然有助于泛化，但其收敛速度会随着输入维度的增加呈指数级恶化，这是一种“神经破碎”现象，与低范数解形成对比。

**AI_Comments:** 本文通过系统地解释了为何通常与良好泛化能力相关的平坦最小值，在ReLU网络的高维设置中可能出现反常的泛化失败，从而做出了重要的理论贡献。引入“神经破碎”现象为这种现象提供了一种新颖且直观的机制，区分了平坦解和低范数解。严谨的上下界证明与数值验证相结合，增强了研究结果的说服力，并填补了深度学习中隐式偏差理解的关键空白。

<details>
  <summary>Details</summary>

**Motivation:** 研究平坦度/低损失曲率的隐式偏差及其对具有多元输入的双层过参数ReLU网络泛化能力的影响，该问题受到梯度下降训练中最小值稳定性和边缘稳定性现象的启发。现有工作要么需要插值，要么只关注单变量输入。

**Method:** 通过理论分析，证明了平坦解的泛化差距和稳定最小值在非参数函数估计中均方误差的上下界。采用了一种基于边界局部化ReLU神经元的新颖填充论证来构建极小极大下界。通过大量的数值模拟来证实理论发现。

**Result:** 证明了虽然平坦度确实意味着泛化，但随着输入维度的增长，由此产生的收敛速度必然呈指数级恶化。揭示了平坦解与低范数解（即权重衰减）之间在维度诅咒方面的指数级分离。提出了“神经破碎”现象，即平坦解可以利用很少激活但具有高权重幅度的神经元，导致在高维度下性能不佳。

**Conclusion:** 本研究首次系统地解释了为什么平坦最小值在高维度下可能无法泛化，并将其与性能随维度呈指数级下降的“神经破碎”现象联系起来。

> **ai_Abstract:** 本文研究了具有多元输入的双层过参数ReLU网络中平坦/低曲率最小值的泛化性能，该主题受到梯度下降现象的启发。理论上证明，虽然平坦度有助于泛化，但其收敛速度会随着输入维度的增加呈指数级恶化，这与低范数解形成鲜明对比。论文引入了“神经破碎”现象，这是一种在高维度下平坦解依赖于很少激活但具有大权重的神经元的机制，从而导致性能不佳。这些理论发现得到了数值模拟的支持，为高维度下平坦最小值泛化失败提供了系统性解释。

> **摘要翻译:** 我们研究了平坦度/低（损失）曲率的隐式偏差及其对具有多元输入的双层过参数ReLU网络泛化能力的影响——这个问题受到梯度下降训练中最小值稳定性和边缘稳定性现象的充分启发。现有工作要么需要插值，要么只关注单变量输入。本文提出了针对多元输入的一些新颖且有些令人惊讶的理论结果。在两种自然设置下：（1）平坦解的泛化差距，以及（2）稳定最小值在非参数函数估计中的均方误差（MSE），我们证明了上下界，这些界限表明，虽然平坦度确实意味着泛化，但随着输入维度的增长，由此产生的收敛速度必然呈指数级恶化。这导致了平坦解与低范数解（即权重衰减）之间的指数级分离，众所周知，低范数解不会遭受维度诅咒。特别是，我们的极小极大下界构造，基于一种新颖的边界局部化ReLU神经元的填充论证，揭示了平坦解如何利用一种“神经破碎”现象，即神经元很少激活，但具有高权重幅度。这导致在高维度下性能不佳。我们通过大量的数值模拟证实了这些理论发现。据我们所知，我们的分析首次系统地解释了为什么平坦最小值在高维度下可能无法泛化。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [421] [Hyperspherical Variational Autoencoders Using Efficient Spherical Cauchy Distribution](https://arxiv.org/abs/2506.21278)
> *使用高效球面柯西分布的超球面变分自编码器*

*Lukas Sablica, Kurt Hornik* | **Category: stat.ML, cs.AI, cs.LG, math.ST, stat.TH**

**Keywords:** 变分自编码器, 球面柯西分布, 超球面表示, 重参数化技巧, 方向性数据

**Comment:** 

> **TL;DR:** 提出了一种使用球面柯西（spCauchy）潜在分布的新型变分自编码器（VAE）架构，它在超球面表示、避免过正则化、解决数值不稳定性和高效重参数化方面优于传统方法。

**AI_Comments:** 这项工作创新性地将球面柯西分布应用于变分自编码器（VAE）的潜在空间，解决了传统方法在处理超球面数据时的局限性和数值稳定性问题。其通过重尾特性防止过正则化，并利用莫比乌斯变换实现高效重参数化，显著提升了模型在方向性数据建模和高维生成任务中的性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的变分自编码器（VAE）中使用高斯潜在空间或广泛使用的von Mises-Fisher（vMF）分布存在局限性，例如不能很好地捕获方向性数据、可能导致过正则化以及vMF在计算归一化常数时存在数值不稳定性。因此，需要一种更自然、更稳定、更高效的超球面潜在变量表示。

**Method:** 本研究提出了一种新型的变分自编码器（VAE）架构，该架构采用球面柯西（spCauchy）作为潜在分布。spCauchy通过莫比乌斯变换实现完全可微分且高效的重参数化技巧，并且其KL散度可以通过快速收敛的幂级数计算。

**Result:** 球面柯西（spCauchy）潜在分布能够提供更自然的超球面表示，更好地捕获方向性数据，同时保持灵活性。其重尾性质防止了过正则化，确保了潜在空间的有效利用，并提供了更具表达力的表示。此外，spCauchy避免了vMF固有的数值不稳定性，实现了稳定和可扩展的训练。KL散度计算消除了下溢或上溢的担忧。

**Conclusion:** 球面柯西（spCauchy）分布是变分自编码器（VAE）的一个引人注目的替代方案，在高维生成建模中提供了理论优势和实际效率。

> **ai_Abstract:** 该论文提出了一种新的变分自编码器（VAE）架构，其核心是使用球面柯西（spCauchy）作为潜在分布。这种方法相较于传统的高斯或von Mises-Fisher（vMF）分布，能更自然地表示超球面潜在变量，有效捕获方向性数据，并避免过正则化。spCauchy通过莫比乌斯变换实现高效且稳定的重参数化，解决了vMF的数值不稳定问题，并且KL散度计算更加鲁棒。这些特性使其成为高维生成建模中一个具有理论和实践优势的替代方案。

> **摘要翻译:** 我们提出了一种新颖的变分自编码器（VAE）架构，该架构采用球面柯西（spCauchy）潜在分布。与传统的高斯潜在空间或广泛使用的von Mises-Fisher（vMF）分布不同，spCauchy提供了一种更自然的潜在变量超球面表示，能更好地捕获方向性数据，同时保持灵活性。其重尾性质防止了过正则化，确保了潜在空间的有效利用，同时提供了更具表达力的表示。此外，spCauchy避免了vMF固有的数值不稳定性，这些不稳定性源于计算涉及贝塞尔函数的归一化常数。相反，它通过莫比乌斯变换实现了完全可微分且高效的重参数化技巧，从而实现稳定和可扩展的训练。KL散度可以通过快速收敛的幂级数计算，消除了与超几何函数比值评估相关的下溢或上溢问题。这些特性使得spCauchy成为VAE的一个引人注目的替代方案，在高维生成建模中提供了理论优势和实际效率。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [430] [Active Learning for Manifold Gaussian Process Regression](https://arxiv.org/abs/2506.20928)
> *流形高斯过程回归的主动学习*

*Yuanxing Cheng, Lulu Kang, Yiwei Wang, Chun Liu* | **Category: stat.ML, cs.LG, 62, G.3**

**Keywords:** 主动学习, 流形高斯过程回归, 维度降低, 策略性数据选择, 高维空间

**Comment:** 13 pages, 6 figures

> **TL;DR:** 本文提出了一种结合流形学习和主动学习的框架，用于高维空间中的高斯过程回归，能有效提高精度并处理复杂函数。

**AI_Comments:** 该论文的创新点在于将流形学习与主动学习相结合，解决了高维空间中高斯过程回归的精度问题。通过联合优化降维网络和GP回归器，并在潜在空间中进行主动学习，提高了数据利用效率。其能够处理复杂不连续函数并保持计算可行性的特性，使其在实际工程和科学应用中具有重要意义。未来的可扩展性研究将进一步提升其应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在高维空间中提高高斯过程回归的准确性。

**Method:** 本文提出了一种主动学习框架，结合流形学习和策略性数据选择，共同优化用于降维的神经网络和潜在空间中的高斯过程回归器，并通过最小化全局预测误差的主动学习准则进行监督。

**Result:** 在合成数据上的实验表明，该方法性能优于随机序列学习。该框架能有效处理复杂、不连续的函数，同时保持计算可行性。

**Conclusion:** 该框架为科学和工程应用提供了实用价值。未来的工作将侧重于可扩展性和不确定性感知的流形学习。

> **ai_Abstract:** 本文提出了一种针对流形高斯过程回归的主动学习框架。该框架通过结合流形学习和策略性数据选择，旨在提高高维空间中的预测精度。其方法是联合优化一个用于降维的神经网络和一个在潜在空间中的高斯过程回归器，并由一个最小化全局预测误差的主动学习准则进行监督。实验结果显示，该方法在处理复杂、不连续函数时表现出优于随机序列学习的性能，同时保持了计算效率，具有重要的实际应用价值。

> **摘要翻译:** 本文介绍了一种用于流形高斯过程（GP）回归的主动学习框架，该框架结合了流形学习和策略性数据选择，以提高高维空间中的准确性。我们的方法共同优化了一个用于降维的神经网络和一个在潜在空间中的高斯过程回归器，并由一个最小化全局预测误差的主动学习准则进行监督。在合成数据上的实验表明，其性能优于随机序列学习。该框架能够高效处理复杂、不连续的函数，同时保持计算可行性，为科学和工程应用提供了实用价值。未来的工作将侧重于可扩展性和不确定性感知的流形学习。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [434] [Lower Bounds on the Size of Markov Equivalence Classes](https://arxiv.org/abs/2506.20933)
> *马尔可夫等价类大小的下界*

*Erik Jahn, Frederick Eberhardt, Leonard J. Schulman* | **Category: stat.ML, cs.LG, math.ST, stat.TH**

**Keywords:** 马尔可夫等价类, 因果发现, 下界, 有向无环图, 有向循环图

**Comment:** 

> **TL;DR:** 当放松无环性、因果充分性或统一模型先验假设时，马尔可夫等价类的预期大小不再平均较小，而是呈指数级增长。

**AI_Comments:** 该论文的创新之处在于挑战了马尔可夫等价类在一般情况下“平均较小”的传统认知。通过证明在放松关键假设（如无环性）时，等价类大小会呈指数级增长，它揭示了因果发现中基于纯观测数据的固有局限性在更广泛或复杂的模型设定下变得更加严峻。这对于理解因果推断的理论边界和指导实际算法设计具有重要意义，尤其是在处理包含循环或隐变量的复杂系统时。

<details>
  <summary>Details</summary>

**Motivation:** 了解因果发现算法在纯观测数据下能学到什么，以及马尔可夫等价类的大小如何反映这些限制。先前研究表明在特定假设下等价类平均较小，但本文旨在探索放松这些假设后的情况。

**Method:** 通过证明在三种不同设置（稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图）下，马尔可夫等价类的预期大小呈指数级增长的下界。

**Result:** 证明了当放松无环性、因果充分性或统一模型先验假设中的任何一个时，马尔可夫等价类的预期大小不再平均较小，而是呈指数级大。

**Conclusion:** 放松因果发现的常见假设（如无环性、因果充分性）会导致马尔可夫等价类的大小呈指数级增长，这表明在这些情况下，从纯观测数据中学习底层因果图的限制会大大增加。

> **ai_Abstract:** 本文研究了在放松因果发现的常见假设（如无环性、因果充分性和统一模型先验）时，马尔可夫等价类大小的变化。传统观点认为在这些假设下等价类平均较小，但作者证明了当任何一个假设被放松时，等价类的预期大小会呈指数级增长。具体地，研究在稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图三种情境下推导出了指数级下界，揭示了在更一般或复杂的因果模型中，仅凭观测数据推断因果结构的难度显著增加。

> **摘要翻译:** 因果发现算法通常只能恢复因果图到其马尔可夫等价类，除非做出额外的参数假设。这些等价类的大小反映了纯观测数据能从底层因果图中学习到的极限。在无环性、因果充分性和统一模型先验的假设下，已知马尔可夫等价类平均较小。在本文中，我们表明当放松这些假设中的任何一个时，情况不再如此。具体来说，我们在三种设置下证明了马尔可夫等价类预期大小的指数级大下界：稀疏随机有向无环图、均匀随机无环有向混合图和均匀随机有向循环图。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [435] [Forecasting Geopolitical Events with a Sparse Temporal Fusion Transformer and Gaussian Process Hybrid: A Case Study in Middle Eastern and U.S. Conflict Dynamics](https://arxiv.org/abs/2506.20935)
> *使用稀疏时间融合转换器和高斯过程混合模型预测地缘政治事件：中东和美国冲突动态的案例研究*

*Hsin-Hsiung Huang, Hayden Hampton* | **Category: stat.ML, cs.LG, stat.AP, stat.CO, 37M10, 62M10, 62P25, 65Y20**

**Keywords:** 地缘政治预测, 时间融合转换器, 高斯过程, 混合模型, 冲突动态

**Comment:** 

> **TL;DR:** 本文提出STFT-VNNGP，一种结合TFT和VNNGP的混合模型，通过准确预测稀疏、突发的地缘政治冲突（尤其是在长期预测方面）赢得了一项竞赛。

**AI_Comments:** 该论文的创新之处在于其混合架构（TFT与VNNGP结合），专门设计用于处理稀疏、突发和过度分散的数据。其两阶段处理过程有效结合了两种模型的优势（TFT用于时间动态捕获，VNNGP用于平滑和不确定性量化）。该研究解决了国家安全领域的一个关键挑战，并在2023年ATD竞赛中获胜，证明了其有效性。代码和工作流程的公开性增强了研究的可复现性和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 从GDELT等数据源预测地缘政治冲突对国家安全至关重要，但此类数据固有的稀疏性、突发性和过度分散性导致标准深度学习模型（如TFT）产生不可靠的长期预测。

**Method:** 本文引入STFT-VNNGP混合架构，采用两阶段过程：首先，TFT捕获复杂时间动态以生成多分位数预测；然后，这些分位数作为变分最近邻高斯过程（VNNGP）的输入，进行有原则的时空平滑和不确定性量化。

**Result:** 在中东和美国冲突动态的案例研究中，STFT-VNNGP持续优于独立的TFT模型，在预测突发事件的时间和幅度方面表现出卓越的能力，尤其是在长期预测方面。

**Conclusion:** 该工作提供了一个强大的框架，可以从具有挑战性的事件数据中生成更可靠和可操作的情报，并且所有代码和工作流程都已公开以确保可重现性。

> **ai_Abstract:** 本文旨在解决稀疏、突发地缘政治冲突数据预测的挑战，这类数据常导致TFT等标准深度学习模型在长期预测中表现不佳。作者提出了STFT-VNNGP混合模型，该模型赢得了2023年ATD竞赛。它采用两阶段方法：TFT生成多分位数预测，然后这些预测作为VNNGP的输入，用于时空平滑和不确定性量化。在中东和美国冲突动态的案例研究中，STFT-VNNGP持续优于独立的TFT模型，尤其在长期突发事件预测方面表现出色，为可操作情报提供了强大框架。

> **摘要翻译:** 从全球事件、语言和语调数据库（GDELT）等数据源预测地缘政治冲突是国家安全面临的一项严峻挑战。此类数据固有的稀疏性、突发性和过度分散性导致包括时间融合转换器（TFT）在内的标准深度学习模型产生不可靠的长期预测。我们引入了STFT-VNNGP，这是一种混合架构，通过克服这些限制赢得了2023年威胁检测算法（ATD）竞赛。为了弥补这一差距，我们的模型采用两阶段过程：首先，TFT捕获复杂的时间动态以生成多分位数预测。然后，这些分位数作为变分最近邻高斯过程（VNNGP）的输入，后者执行有原则的时空平滑和不确定性量化。在中东和美国冲突动态预测的案例研究中，STFT-VNNGP持续优于独立的TFT模型，在预测突发事件的时间和幅度方面表现出卓越的能力，尤其是在长期预测方面。这项工作为从具有挑战性的事件数据中生成更可靠和可操作的情报提供了一个强大的框架，所有代码和工作流程都已公开，以确保可重现性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [442] [Homogenization of Multi-agent Learning Dynamics in Finite-state Markov Games](https://arxiv.org/abs/2506.21079)
> *有限状态马尔可夫博弈中多智能体学习动力学的均匀化*

*Yann Kerzreho* | **Category: stat.ML, cs.LG, math.PR**

**Keywords:** 多智能体学习动力学, 马尔可夫博弈, 均匀化, 常微分方程, 强化学习

**Comment:** 

> **TL;DR:** 本文提出了一种新的方法，通过重缩放学习过程，将多智能体强化学习动力学近似为常微分方程（ODE），从而提供了一种可处理的确定性近似。

**AI_Comments:** 该论文的创新之处在于其提出的均匀化方法，通过将多智能体强化学习动力学近似为常微分方程，极大地简化了复杂系统的分析。这种方法提供了一个可处理的、确定性的模型，有望为多智能体RL理论和应用带来新的见解。其局限性可能在于对“温和假设”的具体要求以及该近似在实际复杂场景中的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为在有限状态马尔可夫博弈中交互的多个强化学习（RL）智能体的学习动力学提供一种新的近似方法。

**Method:** 该方法通过同时降低学习率和增加更新频率来重缩放学习过程，将智能体的参数视为受快速混合博弈状态影响的慢速演化变量。在状态过程遍历性和更新连续性的温和假设下，证明了重缩放过程收敛到一个常微分方程（ODE）。

**Result:** 重缩放过程收敛到一个常微分方程（ODE）。这个ODE为智能体的学习动力学提供了一个可处理的、确定性的近似。

**Conclusion:** 该研究成功地将多智能体学习动力学近似为常微分方程，为理解和分析复杂的RL系统提供了一种简化的确定性模型。

> **ai_Abstract:** 本文提出了一种新颖的方法，通过对学习过程进行重缩放，将有限状态马尔可夫博弈中多智能体强化学习的动力学近似为常微分方程（ODE）。通过降低学习率和提高更新频率，将智能体参数视为慢变量，并在温和假设下证明了该重缩放过程收敛到ODE。该ODE提供了一个可处理的、确定性的学习动力学近似。

> **摘要翻译:** 本文介绍了一种新的方法，用于近似在有限状态马尔可夫博弈中交互的多个强化学习（RL）智能体的学习动力学。其思想是通过同时降低学习率和增加更新频率来重缩放学习过程，有效地将智能体的参数视为受快速混合博弈状态影响的慢速演化变量。在温和假设——状态过程的遍历性和更新的连续性——下，我们证明了该重缩放过程收敛到一个常微分方程（ODE）。这个ODE为智能体的学习动力学提供了一个可处理的、确定性的近似。该框架的实现可在以下网址获取：https://github.com/yannKerzreho/MarkovGameApproximation

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [448] [Wild refitting for black box prediction](https://arxiv.org/abs/2506.21460)
> *黑盒预测的野性再拟合*

*Martin J. Wainwright* | **Category: stat.ML, cs.LG, math.ST, stat.TH**

**Keywords:** 黑盒预测, 野性再拟合, 预测误差界, 非参数估计, Rademacher对称化

**Comment:** 

> **TL;DR:** 本文提出了一种计算高效的“野性再拟合”过程，用于计算基于最小二乘法的惩罚非参数估计的实例级均方预测误差的高概率上限，适用于黑盒预测方法，并提供理论保证和实际应用示例。

**AI_Comments:** 该论文提出了一种创新且实用的方法，通过提供高概率上限来量化黑盒预测的不确定性。其核心优势在于计算效率高、仅依赖单一数据集且与黑盒模型兼容，这使其具有极高的实用价值。利用Rademacher残差对称化是野性自举原理的巧妙应用。在噪声异质性条件下的理论保证增强了其鲁棒性，而从分析中得出的实际指导对于方法设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 需要为基于最小二乘法惩罚非参数估计的实例级均方预测误差计算高概率上限，尤其是在只能进行黑盒访问的预测方法下。

**Method:** 该方法被称为“野性再拟合”，计算高效，仅需单个数据集和对预测方法的黑盒访问。它包含三个步骤：计算合适的残差；使用预因子$\rho$对残差进行对称化和缩放；使用这些残差定义和解决一个以当前估计为中心修改后的预测问题。它采用类似野性自举变体的Rademacher残差对称化。

**Result:** 在允许噪声异质性的相对温和条件下，该方法建立了其性能的高概率保证，表明通过适当选择的野性噪声尺度$\rho$的野性再拟合可以给出预测误差的上限。

**Conclusion:** 这项理论分析为此类程序的设计提供了指导，包括如何形成残差、野性子问题中为获得上限所需的噪声重标量以及黑盒程序的局部稳定性特性。该程序适用于各种问题，包括带结构化矩阵惩罚的非刚性运动恢复、带深度神经网络先验的即插即用图像恢复以及带核方法的随机草图。

> **ai_Abstract:** 本文介绍了一种名为“野性再拟合”的计算高效程序，用于为基于最小二乘法的惩罚非参数估计计算实例级均方预测误差的高概率上限，尤其适用于仅提供黑盒访问的预测方法。该方法通过三个核心步骤实现：计算残差、使用Rademacher对称化和缩放残差，并解决一个以当前估计为中心修改后的预测问题。理论分析表明，在存在噪声异质性的情况下，通过适当选择的噪声尺度，该方法能可靠地提供预测误差的上限，并为设计此类程序提供了有价值的指导。其适用性在非刚性结构恢复、图像修复和核方法等多个领域得到了验证。

> **摘要翻译:** 我们描述并分析了一种计算高效的再拟合过程，用于计算基于最小二乘法惩罚非参数估计的实例级均方预测误差的高概率上限。该过程仅需要一个数据集和对预测方法的黑盒访问，包含三个步骤：计算合适的残差；使用预因子$\rho$对其进行对称化和缩放；并使用它们定义和解决一个以当前估计为中心修改后的预测问题。我们称之为野性再拟合，因为它使用Rademacher残差对称化，类似于野性自举变体。在允许噪声异质性的相对温和条件下，我们建立了其性能的高概率保证，表明通过适当选择的野性噪声尺度$\rho$的野性再拟合可以给出预测误差的上限。这项理论分析为此类程序的设计提供了指导，包括如何形成残差、野性子问题中为获得上限所需的噪声重标量以及黑盒程序的局部稳定性特性。我们通过各种问题说明了该过程的适用性，包括带结构化矩阵惩罚的非刚性运动恢复；带深度神经网络先验的即插即用图像恢复；以及带核方法的随机草图。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [449] [Gaussian Invariant Markov Chain Monte Carlo](https://arxiv.org/abs/2506.21511)
> *高斯不变马尔可夫链蒙特卡罗*

*Michalis K. Titsias, Angelos Alexopoulos, Siran Liu, Petros Dellaportas* | **Category: stat.ML, cs.LG, stat.ME**

**Keywords:** 高斯不变性, 马尔可夫链蒙特卡罗, 采样方法, 统计效率, 控制变量

**Comment:** 29, 2 figures

> **TL;DR:** 本文开发了高斯不变采样方法，包括高斯不变RWM、MALA和二阶Hessian/Manifold MALA，这些方法在统计效率上有所提高，并通过控制变量法实现了方差减少，并在高维潜在高斯模型中取得了最先进的结果。

**AI_Comments:** 本文的创新之处在于引入了“高斯不变性”的概念，并将其应用于MCMC采样方法中，从而显著提高了采样效率和方差减少能力。通过利用高斯目标泊松方程的精确解析解来构建控制变量，为处理复杂和高维目标分布提供了强大的工具，尤其在潜在高斯模型中取得了突破性进展。这项工作对MCMC领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的随机游走 Metropolis (RWM) 和 Metropolis 调整 Langevin 算法 (MALA) 在统计效率方面可能存在局限性，特别是在处理复杂目标分布时。本文旨在开发能够提高统计效率的采样方法。

**Method:** 本文开发了高斯不变版本的随机游走 Metropolis (RWM)、Metropolis 调整 Langevin 算法 (MALA) 和二阶 Hessian 或 Manifold MALA 采样方法。这些方法利用高斯不变性，能够获得高斯目标泊松方程的精确解析解。这些解析解被用于构建高效且易于使用的控制变量，以减少在任何难以处理的目标下的估计器方差。文章还提供了关于几何遍历性的理论结果和最优尺度分析。

**Result:** 高斯不变采样方法与标准 RWM 和 MALA 相比，能够生成具有更高统计效率的遍历估计器。通过利用高斯不变性获得的泊松方程解析解，可以构建有效的控制变量来减少估计器的方差。在多个示例（包括高维潜在高斯模型）中，新采样器和估计器表现出色，并取得了与现有先进方法相比的最先进结果。理论分析揭示了几何遍历性，并且最优尺度分析表明最佳接受率依赖于目标的“高斯性”。

**Conclusion:** 本文开发的高斯不变采样方法在统计效率和方差减少方面优于传统方法，并在高维复杂模型中取得了最先进的性能。理论分析也支持了这些方法的有效性。

> **ai_Abstract:** 本文提出了一系列高斯不变的马尔可夫链蒙特卡罗（MCMC）采样方法，包括高斯不变的RWM、MALA及其高阶变体。研究表明，这些新方法相比传统RWM和MALA，能显著提高估计器的统计效率，主要得益于高斯不变性允许对高斯目标泊松方程进行精确解析求解。这些解析解被用于构建有效的控制变量，以降低复杂目标下估计器的方差。实验证明，在高维潜在高斯模型等应用中，新方法能达到最先进的性能。此外，论文还提供了关于几何遍历性和最优尺度分析的理论支撑。

> **摘要翻译:** 我们开发了采样方法，包括随机游走 Metropolis (RWM)、Metropolis 调整 Langevin 算法 (MALA) 和二阶 Hessian 或 Manifold MALA 的高斯不变版本。与标准的 RWM 和 MALA 不同，我们证明了高斯不变采样可以产生具有改进统计效率的遍历估计器。这归因于高斯不变性的一项显著特性，它使我们能够获得高斯目标泊松方程的精确解析解。这些解析解可用于构建高效且易于使用的控制变量，以减少任何难以处理目标下估计器的方差。我们在几个示例中展示了新的采样器和估计器，包括潜在高斯模型中的高维目标，在这些模型中我们与几种先进方法进行了比较，并获得了最先进的结果。我们还提供了关于几何遍历性的理论结果，以及显示最优接受率对目标高斯性依赖关系的最优尺度分析。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='q-biocb'></a>
## q-bio.CB 

### [413] [scMamba: A Scalable Foundation Model for Single-Cell Multi-Omics Integration Beyond Highly Variable Feature Selection](https://arxiv.org/abs/2506.20697)
> *scMamba：一种超越高变特征选择的单细胞多组学整合的可扩展基础模型*

*Zhen Yuan, Shaoqing Jiao, Yihang Xiao, Jiajie Peng* | **Category: q-bio.CB, cs.LG**

**Keywords:** 单细胞多组学整合, 基础模型, 特征选择, 对比学习, scMamba

**Comment:** 

> **TL;DR:** scMamba是一个新的基础模型，用于整合单细胞多组学数据，无需特征选择，并能保留基因组位置信息，在多项任务中表现优于现有方法。

**AI_Comments:** scMamba的创新之处在于其无需高变特征选择的整合策略，这避免了信息丢失。其将基因组区域视为词、细胞视为句子的标记化方法，以及结合状态空间对偶性和对比学习的设计，为处理大规模、高维单细胞数据提供了新的范式。该模型有望显著提升单细胞多组学数据分析的准确性和效率，推动生物学发现。

<details>
  <summary>Details</summary>

**Motivation:** 现有单细胞多组学整合方法通常依赖于高变基因或峰的选择，这可能会无意中丢弃关键的生物学信息，导致整合挑战。

**Method:** scMamba引入了一种基于补丁的细胞标记化策略，将基因组区域视为词（tokens），细胞视为句子。它基于状态空间对偶性，并采用了一种新颖的对比学习方法，辅以余弦相似度正则化，以实现更好的组学层对齐。其核心在于无需预先进行特征选择，同时保留基因组位置信息。

**Result:** scMamba在多个数据集上的系统基准测试表明，它在保留生物变异、对齐组学层以及增强下游任务（如聚类、细胞类型注释和轨迹推断）方面显著优于现有方法。

**Conclusion:** scMamba被定位为一种强大的工具，适用于大规模单细胞多组学整合，能够处理大型图谱并推动生物学发现。

> **ai_Abstract:** scMamba是一个新颖的基础模型，用于解决单细胞多组学数据整合中的挑战。它通过避免高变特征选择和保留基因组位置信息来克服传统方法的局限性。scMamba采用了一种独特的补丁式细胞标记化策略和增强的对比学习方法，能够从高维稀疏数据中提取生物学见解。基准测试显示，scMamba在数据整合、生物变异保留及下游任务表现上均优于现有方法，使其成为大规模单细胞多组学研究的有力工具。

> **摘要翻译:** 单细胞多组学技术的出现使得在单个细胞内同时分析不同的组学层成为可能。整合此类多模态数据为细胞身份、调控过程和疾病机制提供了前所未有的见解。然而，这仍然具有挑战性，因为当前的方法在预处理过程中通常依赖于选择高变基因或峰，这可能会无意中丢弃关键的生物学信息。在此，我们提出了scMamba，一个旨在整合单细胞多组学数据的基础模型，无需预先进行特征选择，同时保留基因组位置信息。scMamba引入了一种基于补丁的细胞标记化策略，将基因组区域视为词（tokens），细胞视为句子。基于状态空间对偶性的概念，scMamba从高维、稀疏的单细胞多组学数据中提炼出丰富的生物学见解。此外，我们新颖的对比学习方法，通过余弦相似度正则化得到增强，与传统方法相比，能够实现卓越的组学层对齐。在多个数据集上的系统基准测试表明，scMamba在保留生物变异、对齐组学层以及增强关键下游任务（如聚类、细胞类型注释和轨迹推断）方面显著优于最先进的方法。我们的研究结果将scMamba定位为一种用于大规模单细胞多组学整合的强大工具，能够处理大型图谱并推动生物学发现。

</details>

[⬆️ 返回分类顶部](#q-biocb) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [422] [Efficacy of Temporal Fusion Transformers for Runoff Simulation](https://arxiv.org/abs/2506.20831)
> *径流模拟中时态融合变换器的有效性*

*Sinan Rasiya Koya, Tirthankar Roy* | **Category: physics.geo-ph, cs.LG, stat.AP**

**Keywords:** 时态融合变换器, 径流模拟, 水文建模, LSTM, 可解释人工智能

**Comment:** 

> **TL;DR:** 时态融合变换器（TFT）在径流模拟中略优于长短期记忆网络（LSTM），特别是在处理峰值和长序列方面，且具有可解释性，尽管数据质量可能影响性能。

**AI_Comments:** 本文将时态融合变换器（TFTs）这一可解释的人工智能技术引入水文建模领域，并证明其在径流模拟中优于传统的LSTM模型，尤其在处理水文过程线峰值和长序列方面表现出色。TFT的可解释性为科学洞察提供了重要价值，是其创新之处。同时，研究指出了Caravan数据集可能存在的数据质量问题，这既是局限性，也为未来研究方向提供了线索。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于注意力机制与循环神经网络结合在序列建模（包括水文预测）中的价值，本研究旨在探讨时态融合变换器（TFTs）在降雨径流建模中相对于长短期记忆网络（LSTM）的优势。

**Method:** 研究在美国的531个CAMELS流域上训练了10个随机初始化的TFT和LSTM模型。随后，实验使用Caravan数据集的五个子集重复进行，这些子集分别代表美国、澳大利亚、巴西、英国和智利的流域。评估了模型的性能、其在流域属性方面的变异性以及不同数据集之间的差异。

**Result:** 研究发现，TFT略优于LSTM，尤其是在模拟水文过程线的中间部分和峰值方面。此外，TFT能够处理更长的序列，并且是更高或更大流域的更好选择。作为一种可解释的人工智能技术，TFT能够识别关键的动态和静态变量，提供有价值的科学见解。然而，TFT和LSTM在Caravan数据集上的性能均出现显著下降，这可能表明存在数据质量问题。

**Conclusion:** 这项研究突出了TFT在改进水文建模和理解方面的潜力。

> **ai_Abstract:** 本文探讨了时态融合变换器（TFTs）在降雨径流模拟中相较于长短期记忆网络（LSTM）的有效性。研究在美国CAMELS和全球Caravan数据集上进行了实验，结果显示TFTs性能略优于LSTMs，尤其是在模拟水文过程线峰值和处理长序列方面，并且TFTs作为可解释AI能提供有价值的科学洞察。尽管TFTs展现出改进水文建模的潜力，但研究也指出在特定数据集上模型性能下降，可能与数据质量问题有关。

> **摘要翻译:** 将注意力机制与循环神经网络相结合已被证明在序列建模（包括水文预测）中具有重要价值。本文探讨了时态融合变换器（TFTs）在降雨径流建模中相对于长短期记忆网络（LSTM）的优势。我们针对美国531个CAMELS流域，训练了10个随机初始化的TFT和LSTM模型。我们使用Caravan数据集的五个子集重复了实验，每个子集代表美国、澳大利亚、巴西、英国和智利的流域。然后，评估了模型的性能、它们在流域属性方面的变异性以及不同数据集之间的差异。我们的研究结果表明，TFT略优于LSTM，特别是在模拟水文过程线的中间部分和峰值方面。此外，我们展示了TFT处理更长序列的能力，以及为什么它可能成为更高或更大流域的更好选择。作为一种可解释的人工智能技术，TFT能够识别关键的动态和静态变量，提供有价值的科学见解。然而，TFT和LSTM在Caravan数据集上的性能均表现出相当大的下降，这表明可能存在数据质量问题。总的来说，这项研究强调了TFT在改进水文建模和理解方面的潜力。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [424] [Uncertainty-Aware Machine-Learning Framework for Predicting Dislocation Plasticity and Stress-Strain Response in FCC Alloys](https://arxiv.org/abs/2506.20839)
> *面向FCC合金位错塑性与应力-应变响应预测的不确定性感知机器学习框架*

*Jing Luo, Yejun Gu, Yanfei Wang, Xiaolong Ma, Jaafar. A El-Awady* | **Category: cond-mat.mtrl-sci, cs.LG**

**Keywords:** 不确定性量化, 机器学习, 位错塑性, 应力-应变响应, FCC合金

**Comment:** 

> **TL;DR:** 本研究提出了一种基于混合密度网络（MDN）的机器学习框架，能够预测FCC合金的位错塑性与应力-应变响应，并明确量化不确定性，从而提高材料性能预测的准确性和可靠性，并有助于合金设计优化。

**AI_Comments:** 本文的创新点在于提出了一个能够量化不确定性的机器学习框架，这在材料科学领域尤为重要，因为材料性能预测常伴随固有的不确定性。通过结合MDN模型和位错介导的塑性理论，该研究提供了一个更可靠的工具来预测材料行为，并有望加速新材料的发现和设计过程。其对位错密度作为潜在变量的预测，是理解微观机制与宏观性能之间关系的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习在结构材料理解和应用方面取得了显著进展，但需要进一步整合现有数据并量化预测模型中的不确定性。本研究旨在解决这一需求，提高机械性能预测的准确性和可靠性，并优化合金设计。

**Method:** 本研究采用混合密度网络（MDN）模型，利用大量实验数据进行训练。该方法独特地预测位错密度（推断为潜在变量）及其产生的晶粒级应力分布。通过将这些预测分布的统计参数整合到位错介导的塑性模型中，实现了对力学性能的准确预测并明确量化了不确定性。

**Result:** 该方法不仅提高了机械性能预测的准确性和可靠性，而且在优化合金设计方面发挥了关键作用。

**Conclusion:** 所提出的不确定性感知机器学习框架显著提升了FCC合金机械性能预测的准确性和可靠性，并为优化合金设计和加速新材料开发提供了有效途径。

> **ai_Abstract:** 本研究开发了一个不确定性感知的机器学习框架，利用混合密度网络（MDN）模型，通过预测位错密度和晶粒级应力分布，并结合位错介导的塑性模型，实现了对FCC合金应力-应变响应的准确预测和明确的不确定性量化。该方法显著提升了机械性能预测的准确性和可靠性，对合金设计优化和新材料开发具有重要意义。

> **摘要翻译:** 机器学习在理解和应用结构材料方面取得了显著进展，越来越强调整合现有数据并量化预测模型中的不确定性。本研究提出了一种综合方法，利用混合密度网络（MDN）模型，并基于文献中的大量实验数据进行训练。这种方法独特地预测位错密度（被推断为潜在变量）的分布以及由此产生的晶粒级应力分布。将这些预测分布的统计参数纳入位错介导的塑性模型中，可以实现准确的应力-应变预测，并明确量化不确定性。该策略不仅提高了机械性能预测的准确性和可靠性，而且在优化合金设计方面发挥了至关重要的作用，从而促进了快速发展行业中新材料的开发。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

