import json
import os
import sys
import argparse
import re
from collections import defaultdict
from datetime import datetime

def parse_arguments():
    """解析命令行参数，与 run.yml 工作流保持一致。"""
    parser = argparse.ArgumentParser(description="将JSONL文件转换为功能完善的Markdown报告。")
    parser.add_argument("--input", type=str, required=True, help="输入的 JSONL 文件路径")
    parser.add_argument("--template", type=str, required=True, help="单篇论文的模板文件路径")
    parser.add_argument("--output", type=str, required=True, help="输出的 Markdown 文件路径")
    return parser.parse_args()

def load_jsonl_data(file_path):
    """从JSONL文件加载数据，处理文件不存在或为空的情况。"""
    if not os.path.exists(file_path):
        print(f"信息: 输入文件未找到 {file_path}", file=sys.stdout)
        return None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = [json.loads(line) for line in f if line.strip()]
        if not data:
            print(f"信息: JSONL文件为空 {file_path}.", file=sys.stdout)
            return None
        return data
    except json.JSONDecodeError as e:
        print(f"错误: 解析JSONL文件失败 {file_path}: {e}", file=sys.stderr)
        return None

def load_template(file_path):
    """加载模板文件，处理文件未找到的错误。"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"错误: 模板文件未找到 {file_path}", file=sys.stderr)
        sys.exit(1)

def slugify(text):
    """为TOC创建健壮的、GitHub兼容的锚点链接。"""
    text = str(text).lower()
    text = re.sub(r'[^\w\s-]', '', text)
    text = re.sub(r'[\s]+', '-', text)
    return text

def main():
    """主函数，生成Markdown报告。"""
    args = parse_arguments()
    
    date_match = re.search(r'(\d{4}-\d{2}-\d{2})', args.output)
    date_str = date_match.group(1) if date_match else datetime.now().strftime('%Y-%m-%d')

    data = load_jsonl_data(args.input)
    paper_template = load_template(args.template)

    if not data:
        final_content = f"# AI-Enhanced arXiv Daily {date_str}\n\n"
        final_content += "### 今日没有找到新论文。\n"
        with open(args.output, "w", encoding='utf-8') as f:
            f.write(final_content)
        print(f"成功生成报告 (无新论文): {args.output}")
        sys.exit(0)

    # --- 数据分类和排序 ---
    preference_str = os.environ.get('CATEGORIES', 'cs.CV,cs.CL,cs.LG,cs.AI,stat.ML,eess.IV')
    preference = [cat.strip() for cat in preference_str.split(',')]
    def rank(category):
        try:
            return preference.index(category)
        except ValueError:
            return len(preference)

    papers_by_category = defaultdict(list)
    for paper in data:
        primary_category = (paper.get("categories") or [paper.get("cate")])[0] or "Uncategorized"
        papers_by_category[primary_category].append(paper)
    sorted_categories = sorted(papers_by_category.keys(), key=rank)

    # --- Markdown 内容生成 ---
    # 1. 预先渲染所有论文卡片
    rendered_papers = {}
    for idx, paper in enumerate(data):
        ai_data = paper.get('AI', {})
        primary_category = (paper.get("categories") or [paper.get("cate")])[0] or "Uncategorized"
        
        # **核心修正**: 调整context字典的键名，以精确匹配paper_template.md中的占位符
        context = {
            "idx": idx + 1,
            "id": paper.get("id", "N/A"),
            "title": paper.get("title", "N/A"),
            "authors": ", ".join(paper.get("authors", ["N/A"])),
            "comment": paper.get("comment", "无"), # 作者备注
            "cate": primary_category,
            "url": f"https://arxiv.org/abs/{paper.get('id', '')}",
            
            # AI 数据
            "title_translation": ai_data.get('title_translation', 'N/A'),
            "keywords": ai_data.get('keywords', 'N/A'),
            "tldr": ai_data.get('tldr', 'N/A'),
            "motivation": ai_data.get('motivation', 'N/A'),
            "method": ai_data.get('method', 'N/A'),
            "conclusion": ai_data.get('conclusion', 'N/A'),

            # --- 已修正以下键名以匹配模板 ---
            "ai_comment": ai_data.get('comments', 'N/A'),      # 模板需要 {ai_comment}
            "results": ai_data.get('result', 'N/A'),           # 模板需要 {results}
            "ai_Abstract": ai_data.get('summary', 'N/A'),      # 模板需要 {ai_Abstract}
            "abstract_translation": ai_data.get('translation', 'N/A'), # 模板需要 {abstract_translation}
        }
        
        # 填充模板
        temp_paper_content = paper_template
        for key, value in context.items():
            # 使用 str(value or '') 确保即使值为None也能安全替换为空字符串
            temp_paper_content = temp_paper_content.replace(f"{{{key}}}", str(value or ''))
        rendered_papers[paper.get("id")] = temp_paper_content

    # 2. 生成TOC (目录)
    toc_parts = [f"## 今日总计: {len(data)} 篇论文", "### 目录"]
    for cate in sorted_categories:
        slug = slugify(cate)
        toc_parts.append(f"- [{cate}](#{slug}) ({len(papers_by_category[cate])} 篇)")
    
    # 3. 按分类组装最终内容
    content_by_category_str = ""
    for cate in sorted_categories:
        slug = slugify(cate)
        # **已修改**: 使用 <small> 标签来缩小导航链接的字体
        content_by_category_str += f"<a id='{slug}'></a>\n## {cate}  <small>[⬆️ 返回目录](#toc)</small>\n\n"
        
        for paper_data in papers_by_category[cate]:
            paper_id = paper_data.get("id")
            if paper_id in rendered_papers:
                content_by_category_str += rendered_papers[paper_id]
                content_by_category_str += f"\n[⬆️ 返回分类顶部](#{slug}) | [⬆️ 返回总目录](#toc)\n\n---\n\n"

    # 4. 组装最终的完整Markdown页面
    report_title = f"# AI-Enhanced arXiv Daily {date_str}\n\n"
    toc_anchor = "<a id='toc'></a>\n"
    final_toc = "\n".join(toc_parts) + "\n\n---\n"
    
    final_content = report_title + toc_anchor + final_toc + content_by_category_str.strip().removesuffix('---')

    with open(args.output, "w", encoding='utf-8') as f:
        f.write(final_content)
    
    print(f"成功将 {len(data)} 篇论文转换为Markdown，并保存到 {args.output}")

if __name__ == "__main__":
    main()
